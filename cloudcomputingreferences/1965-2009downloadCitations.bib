@ARTICLE{5426484, 
author={J. Hayes}, 
journal={Engineering Technology}, 
title={Thin clients' fat challenge [IT Desktop Computing]}, 
year={2009}, 
volume={4}, 
number={21}, 
pages={52-53}, 
abstract={THE GRADUAL advance of the thin client has been one of IT's quieter revolutions, and one that tends to be cast in a subordinate role in debates around the future of Windows, Cloud Computing, and virtual desktops. Despite this it has the potential to radically reshape both the appearance and the economics of IT into the next decade.}, 
doi={10.1049/et.2009.2112}, 
ISSN={1750-9637}, 
month={Dec},}
@ARTICLE{5286166, 
journal={IEEE Intelligent Systems}, 
title={In the News}, 
year={2009}, 
volume={24}, 
number={5}, 
pages={5-8}, 
abstract={"AI and the Mobile Cloud," explores the growing use of cloud computing to deliver AI-empowered applications to mobile devices. Over time, mobile devices could become the principal means by which users interact with cloud-based, autonomously operating agents. "A Fish Called Filose" describes efforts of researchers at four European universities to design a fishlike marine robot that can navigate shallow waters or tricky currents. "Desktop Data Organization Grows Up" describes the emerging semantic desktop, a personal version of the Semantic Web for organizing an individual's thousands of files, e-mail messages, and other digital data in an graph of related items.}, 
keywords={Artificial intelligence;Cloud computing;Educational institutions;Electronic mail;Marine animals;Mobile computing;Navigation;Organizing;Robots;Semantic Web;Filose;In the News;Nepomuk;Semantic Web;cloud computing;mobile AI;mobile cloud;mobile computing;robotics;semantic desktop}, 
doi={10.1109/MIS.2009.99}, 
ISSN={1541-1672}, 
month={Sept},}
@INPROCEEDINGS{5395324, 
author={J. Arshad and P. Townend and J. Xu}, 
booktitle={2009 15th International Conference on Parallel and Distributed Systems}, 
title={Quantification of Security for Compute Intensive Workloads in Clouds}, 
year={2009}, 
pages={479-486}, 
abstract={Cloud computing is a promising technology to facilitate development of large-scale, on-demand, flexible computing infrastructures. However, improving dependability of cloud computing is critical for realization of its potential. In this paper, we describe our efforts to quantify security for Clouds to facilitate provision of assurance for quality of service, one of the factors contributing to dependability. This has profound implications for delivering customized security solutions such as effective intrusion prevention and detection which is the overall objective of our research. In order to demonstrate the applicability of our research, we have incorporated these requirements in the resource acquisition phase for Clouds. We also present experiments to demonstrate the effectiveness of our approach to address the random migration problem for virtualized computing environments.}, 
keywords={Internet;quality of service;security of data;cloud computing;cloud security;intrusion detection;intrusion prevention;quality of service;random migration problem;resource acquisition phase;virtualized computing environments;Cloud computing;Concurrent computing;Distributed computing;Grid computing;High performance computing;Large-scale systems;Memory;Quality of service;Security;Virtual machining}, 
doi={10.1109/ICPADS.2009.46}, 
ISSN={1521-9097}, 
month={Dec},}
@INPROCEEDINGS{5368024, 
author={Y. Han and P. Brezany and I. Janciak}, 
booktitle={2009 Fifth International Conference on Semantics, Knowledge and Grid}, 
title={Cloud-Enabled Scalable Decision Tree Construction}, 
year={2009}, 
pages={128-135}, 
abstract={Cloud computing, as a newly emerging technology, is an innovation providing dynamically scalable and virtualized resources as services. In this paper, we introduce our effort to build a service-oriented distributed computational system based on the cloud concepts named distributed computational service cloud. This kind of cloud hosts scalable grid services, which are implemented with Web-services-resource-framework-compliant (WSRF) Web services, enabling high-performance and distributed computing. We evaluate the cloud using scalable decision tree service, which provides computational intensive data mining algorithm. The architecture of the system as well as details of the distributed decision tree construction is the kernel content of this paper.}, 
keywords={Web services;data mining;decision trees;grid computing;software architecture;Web-services-resource-framework;cloud computing;computational intensive data mining algorithm;distributed computational service cloud;distributed decision tree construction;grid services;high-performance computing;scalable decision tree construction;service-oriented distributed computational system;system architecture;virtualized resources;Application software;Cloud computing;Computer science;Data mining;Decision trees;Distributed computing;High performance computing;Pricing;Scalability;Web services;Cloud Computing;Decision Tree;Web service;distributed computation}, 
doi={10.1109/SKG.2009.83}, 
month={Oct},}
@INPROCEEDINGS{5161234, 
author={J. Brandt and A. Gentile and J. Mayo and P. Pebay and D. Roe and D. Thompson and M. Wong}, 
booktitle={2009 IEEE International Symposium on Parallel Distributed Processing}, 
title={Resource monitoring and management with OVIS to enable HPC in cloud computing environments}, 
year={2009}, 
pages={1-8}, 
abstract={Using the cloud computing paradigm, a host of companies promise to make huge compute resources available to users on a pay-as-you-go basis. These resources can be configured on the fly to provide the hardware and operating system of choice to the customer on a large scale. While the current target market for these resources in the commercial space is Web development/hosting, this model has the lure of savings of ownership, operation, and maintenance costs, and thus sounds like an attractive solution for people who currently invest millions to hundreds of millions of dollars annually on high performance computing (HPC) platforms in order to support large-scale scientific simulation codes. Given the current interconnect bandwidth and topologies utilized in these commercial offerings, however, the only current viable market in HPC would be small-memory-footprint embarrassingly parallel or loosely coupled applications, which inherently require little to no inter-processor communication. While providing the appropriate resources (bandwidth, latency, memory, etc.) for the HPC community would increase the potential to enable HPC in cloud environments, this would not address the need for scalability and reliability, crucial to HPC applications. Providing for these needs is particularly difficult in commercial cloud offerings where the number of virtual resources can far outstrip the number of physical resources, the resources are shared among many users, and the resources may be heterogeneous. Advanced resource monitoring, analysis, and configuration tools can help address these issues, since they bring the ability to dynamically provide and respond to information about the platform and application state and would enable more appropriate, efficient, and flexible use of the resources key to enabling HPC. Additionally such tools could be of benefit to non-HPC cloud providers, users, and applications by providing more efficient resource utilization in general.}, 
keywords={Internet;operating systems (computers);system monitoring;OVIS;Web development;Web hosting;cloud computing environments;high performance computing platforms;operating system;pay-as-you-go basis;resource monitoring;scientific simulation codes;Bandwidth;Cloud computing;Costs;Environmental management;Hardware;High performance computing;Large-scale systems;Monitoring;Operating systems;Resource management}, 
doi={10.1109/IPDPS.2009.5161234}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{5159218, 
author={B. Ohlman and A. Eriksson and R. Rembarz}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={What Networking of Information Can Do for Cloud Computing}, 
year={2009}, 
pages={78-83}, 
abstract={Cloud computing is making it possible to separate the process of building an infrastructure for service provisioning from the business of providing end user services. Today, such infrastructures are normally provided in large data centres and the applications are executed remotely from the users. One reason for this is that cloud computing requires a reasonably stable infrastructure and networking environment, largely due to management reasons. Networking of Information (NetInf) is an information centric networking paradigm that can support cloud computing by providing new possibilities for network transport and storage. It offers direct access to information objects through a simple API, independent of their location in the network. This abstraction can hide much of the complexity of storage and network transport systems that cloud computing today has to deal with. In this paper we analyze how cloud computing and NetInf can be combined to make cloud computing infrastructures easier to manage, and potentially enable deployment in smaller and more dynamic networking environments. NetInf should thus be understood as an enhancement to the infrastructure for cloud computing rather than a change to cloud computing technology as such. To illustrate the approach taken by NetInf, we also describe how it can be implemented by introducing a specific name resolution and routing mechanism.}, 
keywords={Internet;Web services;Netlnf;cloud computing infrastructures;end user services;information access;information centric networking;infrastructure enhancement;network transport;service provisioning;Application software;Cloud computing;Computer network management;Environmental management;Hardware;Internet;Network servers;Routing;Uniform resource locators;Web server;Keywords-Cloud computing;Networking of Information (NetInf);name resolution;network architecture;routing}, 
doi={10.1109/WETICE.2009.27}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{4736822, 
author={S. Pallickara and J. Ekanayake and G. Fox}, 
booktitle={2008 IEEE Fourth International Conference on eScience}, 
title={An Overview of the Granules Runtime for Cloud Computing}, 
year={2008}, 
pages={412-413}, 
abstract={In this paper we present a short introduction to the granules system, which is a lightweight streaming-based runtime for cloud computing. This paper provides a summary of the capabilities supported by the runtime.}, 
keywords={Internet;cloud computing;granules runtime;streaming-based runtime;Application software;Cloud computing;Concurrent computing;Databases;File systems;Grid computing;Laboratories;Resource management;Runtime;USA Councils;cloud computing;map-reduce;runtime;streaming systems}, 
doi={10.1109/eScience.2008.101}, 
month={Dec},}
@INPROCEEDINGS{5161466, 
author={Z. Ganon and I. E. Zilbershtein}, 
booktitle={2009 IEEE 14th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks}, 
title={Cloud-based Performance Testing of Network Management Systems}, 
year={2009}, 
pages={1-6}, 
abstract={Network Management Systems are often challenged by the need to manage networks comprised of a very large number of elements. Effective testing of performance, capacity and stability of these management systems often requires significant and, at times, cost-prohibitive investment in equipment and computing resources. This paper presents a method which leverages commercial cloud computing services for conducting large-scale tests of Network Management Systems. This method involves instantiation of large numbers of virtual network elements via the cloud computing infrastructure. After the network of virtual elements is up, it can be used for performance testing of the Network Management System. Considerations for evaluating, planning and implementing this method are discussed. Finally, a case study demonstrating the application and effectiveness of this method is presented.}, 
keywords={program testing;telecommunication computing;telecommunication network management;cloud computing infrastructure;cloud computing services;cloud-based performance testing;computing resources;network management systems;virtual network elements;Buildings;Cloud computing;Computer network management;Computer networks;Delay;Large-scale systems;Pervasive computing;Protocols;Software testing;System testing}, 
doi={10.1109/CAMAD.2009.5161466}, 
ISSN={2378-4865}, 
month={June},}
@INPROCEEDINGS{4578535, 
author={S. Nepal and J. Zic}, 
booktitle={2008 IEEE International Conference on Services Computing}, 
title={A Conflict Neighbouring Negotiation Algorithm for Resource Services in Dynamic Collaborations}, 
year={2008}, 
volume={2}, 
pages={283-290}, 
abstract={Dynamic collaborations are the means by which a group of autonomous entities collaborate to achieve common objectives through sharing their own resources (e.g. specialised applications, controlled information and data, and storage and networking infrastructures). With the emergence of "cloud computing", it is now possible to share such resources as services. However, sharing such resource services requires that the participants agree to the terms and conditions of their responsibilities, as well as access to information and policies regulating their behaviour within the collaboration. This is done through the use of an eContract that captures the contributed resource-oriented services, as well as their respective service level agreements. One of the unique characteristics of the contract in dynamic collaborations is that each autonomous participant must agree with the services contributed by other participants against a set of its own policies. Within this context, this paper presents an efficient contract negotiation algorithm, called conflict neighbouring algorithm (CNA). We model and verify the algorithm using SPIN model checker, and compare its performance results with other alternative algorithms.}, 
keywords={Web services;SPIN model checker;cloud computing;conflict neighbouring algorithm;conflict neighbouring negotiation algorithm;contract negotiation algorithm;dynamic collaborations;eContract;networking infrastructures;resource-oriented services;respective service level agreements;Australia;Cloud computing;Collaborative work;Contracts;Electronic commerce;International collaboration;Motion pictures;Production;Protocols;Virtual enterprises;Dynamic Collaborations;Negotiation Algorithm}, 
doi={10.1109/SCC.2008.18}, 
month={July},}
@INPROCEEDINGS{5507535, 
author={S. J. Simske}, 
booktitle={2009 First IEEE International Conference on Biometrics, Identity and Security (BIdS)}, 
title={Dynamic biometrics: The case for a real-time solution to the problem of access control, privacy and security}, 
year={2009}, 
pages={1-10}, 
abstract={From a certain perspective, security is broken. The security authorization triangle (possession, knowledge, identity) has in some cases been reduced to a single point (knowledge) because of the limitations to possession attributable to virtualization, and because of the limitations to identity attributable to the use of static biometrics. This paper makes the case for a stronger security rights triangle-privacy, security and access control-underpinned by the resurrection of possession and identity through the use of dynamic biometrics. New technologies in mobile and cloud computing, pattern recognition and user interaction provide a potential path forward for an identity-matching ecosystem in which both privacy and security needs can be accommodated.}, 
keywords={authorisation;biometrics (access control);data privacy;access control;cloud computing;dynamic biometrics;mobile computing;pattern recognition;privacy;security authorization triangle;Access control;Authorization;Biometrics;Data security;Face recognition;Information security;Iris;Privacy;Shape measurement;Veins}, 
doi={10.1109/BIDS.2009.5507535}, 
ISSN={2163-4068}, 
month={Sept},}
@INPROCEEDINGS{5368023, 
author={X. Xie and K. Fan and X. Shi and S. Wu and H. Jin}, 
booktitle={2009 Fifth International Conference on Semantics, Knowledge and Grid}, 
title={SMU: Towards Cloud Oriented Service MashUp}, 
year={2009}, 
pages={136-143}, 
abstract={Based on increasing popularity of cloud computing, social computing and web 2.0 technology, Internet resources are extremely increasing. How to provide service invoking interfaces ceaselessly while minimizing the cost of service development, which can meet the growing needs of end users, becomes a challenging issue for service providers. Meanwhile, service mashup technology is getting more attention in both enterprise and academia for building new end users applications fast in the complex and heterogeneous network environment. Therefore, we propose a new method of service mashup with the advantages of the cloud, grid, web services and other technologies. We develop cloud oriented service mashup system prototype (SMU). In SMU, we support the service information interaction, classification, and process during the procedure of service mashup to meet various needs of the multi-level and the multi-role of service applications. Our experiments show that SMU can reach the purpose of building personal service applications quickly and easily.}, 
keywords={Internet;Web services;Internet resources;cloud computing;cloud oriented service mashup system prototype;personal service applications;service providers;social computing;web 2.0 technology;Cloud computing;Computer science;Costs;Grid computing;Mashups;Middleware;Prototypes;Social network services;Web and internet services;Web services;Web service;cloud computing;mashup}, 
doi={10.1109/SKG.2009.71}, 
month={Oct},}
@INPROCEEDINGS{5161233, 
author={J. Machina and A. Sodan}, 
booktitle={2009 IEEE International Symposium on Parallel Distributed Processing}, 
title={Predicting cache needs and cache sensitivity for applications in cloud computing on CMP servers with configurable caches}, 
year={2009}, 
pages={1-8}, 
abstract={QoS criteria in cloud computing require guarantees about application runtimes, even if CMP servers are shared among multiple parallel or serial applications. Performance of computation-intensive application depends significantly on memory performance and especially cache performance. Recent trends are toward configurable caches that can dynamically partition the cache among cores. Then, proper cache partitioning should consider the applications' different cache needs and their sensitivity towards insufficient cache space. We present a simple, yet effective and therefore practically feasible black-box model that describes application performance in dependence on allocated cache size and only needs three descriptive parameters. Learning these parameters can therefore be done with very few sample points. We demonstrate with the SPEC benchmarks that the model adequately describes application behavior and that curve fitting can accomplish very high accuracy, with mean relative error of 2.8% and maximum relative error of 17%.}, 
keywords={cache storage;multiprocessing systems;quality of service;storage management;CMP server;QoS criteria;application performance;application runtime;black box model;cache needs;cache partitioning;cache performance;cache sensitivity;cloud computing;computation intensive application;configurable cache;curve fitting;memory performance;Application software;Bandwidth;Cloud computing;Computer errors;Computer science;Counting circuits;Curve fitting;Hardware;Predictive models;Runtime;CMPs;QoS;SPEC benchmarks;cloud computing;configurable caches;multi-core CPUs;performance modelling}, 
doi={10.1109/IPDPS.2009.5161233}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{5366973, 
author={G. Wang and A. R. Butt and P. Pandey and K. Gupta}, 
booktitle={2009 IEEE International Symposium on Modeling, Analysis Simulation of Computer and Telecommunication Systems}, 
title={A simulation approach to evaluating design decisions in MapReduce setups}, 
year={2009}, 
pages={1-11}, 
abstract={MapReduce has emerged as a model of choice for supporting modern data-intensive applications. The model is easy-to-use and promising in reducing time-to-solution. It is also a key enabler for cloud computing, which provides transparent and flexible access to a large number of compute, storage and networking resources. Setting up and operating a large MapReduce cluster entails careful evaluation of various design choices and run-time parameters to achieve high efficiency. However, this design space has not been explored in detail. In this paper, we adopt a simulation approach to systematically understanding the performance of MapReduce setups. The resulting simulator, MRPerf, captures such aspects of these setups as node, rack and network configurations, disk parameters and performance, data layout and application I/O characteristics, among others, and uses this information to predict expected application performance. Specifically, we use MRPerf to explore the effect of several component inter-connect topologies, data locality, and software and hardware failures on overall application performance. MRPerf allows us to quantify the effect of these factors, and thus can serve as a tool for optimizing existing MapReduce setups as well as designing new ones.}, 
keywords={Internet;digital simulation;pattern clustering;scheduling;software engineering;MRPerf simulator;MapReduce setups;cloud computing;component inter-connect topologies;data locality;design decisions evaluation;hardware failures;modern data-intensive applications;simulation approach;software failures;time-to-solution reduction;Application software;Cloud computing;Computational modeling;Computer networks;Design optimization;Hardware;Network topology;Predictive models;Runtime;Software performance}, 
doi={10.1109/MASCOT.2009.5366973}, 
ISSN={1526-7539}, 
month={Sept},}
@INPROCEEDINGS{4738449, 
author={G. von Laszewski and L. E. Dilmanian}, 
booktitle={2008 Grid Computing Environments Workshop}, 
title={e-Science Project and Experiment Management with Microsoft Project}, 
year={2008}, 
pages={1-8}, 
abstract={The design, execution, and monitoring of challenging scientific applications is often a complex affair. To cope with the issue, several tools and frameworks have been designed and put into use. However, the entry barrier to using these tools productively is high, and may hinder the progress of many scientists or non-experts that develop workflows infrequently. As part of the Cyberaide framework, a workflow tool called grid manager had been developed and integrated using the Microsoft Project software package as an elementary component. The advantages of using such a tool are discussed in this paper. Microsoft project is a user friendly project management tool that is being used in a new context. It is being used to design and monitor the execution of grid based projects. The motivation for this choice is that many scientists are already familiar with Microsoft project. Grid Manager enables seamless access to and execution over computational Grids, such as the NSF sponsored TeraGrid. Our framework also allows integration with other resources, including Microsoft Windows HPC Server 2008 (HPC) clusters. We test our hypothesis of usability while evaluating the tool as part of several graduate level courses taught in the field of grid and cloud computing.}, 
keywords={grid computing;project management;software tools;Cyberaide framework;Microsoft Project software package;Microsoft Windows HPC Server 2008;Microsoft project;TeraGrid;cloud computing;e-science project;experiment management;grid manager;Costs;Engines;Grid computing;Instruments;Monitoring;Project management;Prototypes;Quality of service;Software packages;Technology management;CoG Kit;Grid Computing;Microsoft Project;Workflow}, 
doi={10.1109/GCE.2008.4738449}, 
ISSN={2152-1085}, 
month={Nov},}
@ARTICLE{4804043, 
author={J. Voas and J. Zhang}, 
journal={IT Professional}, 
title={Cloud Computing: New Wine or Just a New Bottle?}, 
year={2009}, 
volume={11}, 
number={2}, 
pages={15-17}, 
abstract={Cloud computing has evolved from previous computing paradigms going back as far to the days of mainframes, but is it really different? Do the explosive new capabilities from cloud computing solve any of the problems left unsolved from three decades ago? The authors in this issue discuss their views on what cloud computing is leaving the reader to decide for themselves.}, 
keywords={Business;Cloud computing;Computer applications;Computer architecture;Computer interfaces;Grid computing;Internet;Physics computing;Portable computers;User interfaces;IT Professional;Internet;cloud computing;clouds}, 
doi={10.1109/MITP.2009.23}, 
ISSN={1520-9202}, 
month={March},}
@INPROCEEDINGS{5380884, 
author={M. Tsugawa and A. Matsunaga and J. Fortes}, 
booktitle={2009 Fifth IEEE International Conference on e-Science}, 
title={User-Level Virtual Network Support for Sky Computing}, 
year={2009}, 
pages={72-79}, 
abstract={With the emergence of multiple cloud providers of Infrastructure-as-a-Service, it becomes possible to envision a near-future when high-performance computing users could combine services from different clouds to access huge numbers of resources. However, as more administrative privileges are exposed to end users, providers are required to deploy network security measures that present challenges to the network virtualization technologies that are needed to enable inter-cloud communication. This paper studies these challenges and proposes techniques to enable unmodified applications on resources across distinct clouds. The techniques are implemented in TinyViNe, an extension to ViNe, a virtual networking technology for distributed resources in different administrative domains. The results of evaluating TinyViNe on a WAN-based testbed across three sites are reported for a bioinformatics application (BLAST) and MPI benchmarks. The results confirm that TinyViNe enables cross-cloud computing while having little impact on application performance. TinyViNe also has auto-configuration and Â¿download-and-runÂ¿ capabilities for easy deployment by users who are not knowledgeable about networking.}, 
keywords={Internet;application program interfaces;bioinformatics;message passing;security of data;virtual machines;BLAST;MPI;TinyViNe;WAN-based testbed;bioinformatics application;infrastructure-as-a-service;inter-cloud communication;network security measures;network virtualization technologies;sky computing;user-level virtual network support;Bioinformatics;Cloud computing;Computer networks;Information systems;Isolation technology;Laboratories;Protection;USA Councils;Virtual manufacturing;Voice mail;bioinformatics;cloud computing;overlay networks;virtualization}, 
doi={10.1109/e-Science.2009.19}, 
month={Dec},}
@INPROCEEDINGS{5201385, 
author={Cong Wang and Qian Wang and Kui Ren and Wenjing Lou}, 
booktitle={2009 17th International Workshop on Quality of Service}, 
title={Ensuring data storage security in Cloud Computing}, 
year={2009}, 
pages={1-9}, 
abstract={Cloud computing has been envisioned as the next-generation architecture of IT enterprise. In contrast to traditional solutions, where the IT services are under proper physical, logical and personnel controls, cloud computing moves the application software and databases to the large data centers, where the management of the data and services may not be fully trustworthy. This unique attribute, however, poses many new security challenges which have not been well understood. In this article, we focus on cloud data storage security, which has always been an important aspect of quality of service. To ensure the correctness of users' data in the cloud, we propose an effective and flexible distributed scheme with two salient features, opposing to its predecessors. By utilizing the homomorphic token with distributed verification of erasure-coded data, our scheme achieves the integration of storage correctness insurance and data error localization, i.e., the identification of misbehaving server (s). Unlike most prior works, the new scheme further supports secure and efficient dynamic operations on data blocks, including: data update, delete and append. Extensive security and performance analysis shows that the proposed scheme is highly efficient and resilient against Byzantine failure, malicious data modification attack, and even server colluding attacks.}, 
keywords={Internet;matrix algebra;quality of service;security of data;storage management;Byzantine failure;IT enterprise;cloud computing;cloud data storage security;data error localization;data management;data modification attack;databases;erasure-coded data distributed verification;flexible distributed scheme;homomorphic token;large data center;next-generation architecture;quality of service;server colluding attack;storage correctness insurance;Application software;Cloud computing;Computer architecture;Data security;Databases;Error correction;Insurance;Memory;Personnel;Quality of service}, 
doi={10.1109/IWQoS.2009.5201385}, 
ISSN={1548-615X}, 
month={July},}
@ARTICLE{5233605, 
author={B. Leiba}, 
journal={IEEE Internet Computing}, 
title={Having One's Head in the Cloud}, 
year={2009}, 
volume={13}, 
number={5}, 
pages={4-6}, 
abstract={This paper talks about the cloud computing that had come full circle toward logically centralised administrative domains and shared computational resources. Distributed computing, cluster computing, grid computing, and cloud computing are all terms that have developed over the past few years. Each is distinct from the others in some ways, but there's a great deal of overlap. A turn-of-the-century distributed computing application that has the right profile could easily have morphed through the series, proudly calling itself a cloud computing application today.}, 
keywords={Internet;grid computing;cloud computing;cluster computing;computational resources;distributed computing;grid computing;Cloud computing;Distributed computing;Grid computing;centralized computational resources;cloud computing;grid computing}, 
doi={10.1109/MIC.2009.109}, 
ISSN={1089-7801}, 
month={Sept},}
@INPROCEEDINGS{4700484, 
author={W. Chou}, 
booktitle={2008 IEEE Congress on Services Part II (services-2 2008)}, 
title={Web Services: Software-as-a-Service (SaaS), Communication, and Beyond}, 
year={2008}, 
pages={1-1}, 
abstract={Web services is a fast moving research field with a profound impact to many critical research areas, ranging from software to communication, from server platforms to mobile endpoints. It emerges as a disruptive technology to various enterprises to deliver services, computing, communication and information to their customers and partners. This talk intends to capture some recent advances of Web services and new Web services applications in software-as-a-services, cloud computing, communication, message centric SOAP engine design, and mobile services computing endpoints.}, 
keywords={Web services;XML;mobile computing;Web services;cloud computing;communication;message centric SOAP engine design;mobile services computing endpoints;software-as-a-service;Application software;Books;Cloud computing;Computer industry;Electrical engineering;Mobile communication;Simple object access protocol;Telecommunication computing;USA Councils;Web services}, 
doi={10.1109/SERVICES-2.2008.46}, 
month={Sept},}
@INPROCEEDINGS{5284108, 
author={A. Malik and A. Park and R. Fujimoto}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={Optimistic Synchronization of Parallel Simulations in Cloud Computing Environments}, 
year={2009}, 
pages={49-56}, 
abstract={Cloud computing offers the potential to make parallel discrete event simulation capabilities more widely accessible to users who are not experts in this technology and do not have ready access to high performance computing equipment. Services hosted within the ldquocloudrdquo can potentially incur processing delays due to load sharing among other active services, and can cause optimistic simulation protocols to perform poorly. This paper proposes a mechanism termed the Time Warp Straggler Message Identification Protocol (TW-SMIP) to address optimistic synchronization and performance issues associated with executing parallel discrete event simulation in cloud computing environments.}, 
keywords={Internet;discrete event simulation;parallel processing;active services;cloud computing environments;load sharing;optimistic synchronization;parallel discrete event simulation;time warp straggler message identification protocol;Access protocols;Cloud computing;Computational modeling;Concurrent computing;Discrete event simulation;Grid computing;Hardware;High performance computing;Synchronization;USA Councils;Time Warp;optimistic synchronization;parallel discrete event simulation}, 
doi={10.1109/CLOUD.2009.79}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5207867, 
author={M. Xu and L. Cui and H. Wang and Y. Bi}, 
booktitle={2009 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
title={A Multiple QoS Constrained Scheduling Strategy of Multiple Workflows for Cloud Computing}, 
year={2009}, 
pages={629-634}, 
abstract={Cloud computing has gained popularity in recent times. As a cloud must provide services to many users at the same time and different users have different QoS requirements, the scheduling strategy should be developed for multiple workflows with different QoS requirements. In this paper, we introduce a multiple QoS constrained scheduling strategy of multi-workflows (MQMW) to address this problem. The strategy can schedule multiple workflows which are started at any time and the QoS requirements are taken into account. Experimentation shows that our strategy is able to increase the scheduling success rate significantly.}, 
keywords={Internet;quality of service;scheduling;workflow management software;cloud computing;multiple QoS constrained scheduling strategy;multiple workflows;Algorithm design and analysis;Application software;Bismuth;Cloud computing;Costs;Distributed processing;Partitioning algorithms;Processor scheduling;Quality of service;Scheduling algorithm;Cloud Computing;Multiple QoS Requirements;Multiple Workflows;Scheduling}, 
doi={10.1109/ISPA.2009.95}, 
ISSN={2158-9178}, 
month={Aug},}
@INPROCEEDINGS{5161232, 
author={S. Song and K. D. Ryu and D. D. Silva}, 
booktitle={2009 IEEE International Symposium on Parallel Distributed Processing}, 
title={Blue Eyes: Scalable and reliable system management for cloud computing}, 
year={2009}, 
pages={1-8}, 
abstract={With the advent of cloud computing, massive and automated system management has become more important for successful and economical operation of computing resources. However, traditional monolithic system management solutions are designed to scale to only hundreds or thousands of systems at most. In this paper, we present Blue Eyes, a new system management solution to handle hundreds of thousands of systems. Blue Eyes enables highly scalable and reliable system management with a multi-server scale-out architecture. In particular, we structure the management servers into a hierarchical tree to achieve scalability, and management information is replicated into secondary servers to provide reliability and high availability. In addition, Blue Eyes is designed to extend the existing single server implementation without significantly restructuring the code base. Several experimental results with the prototype have demonstrated that Blue Eyes can reliably handle typical management tasks for a large scale of endpoints with dynamic load-balancing across the servers, near linear performance gain with server additions, and an acceptable network overhead.}, 
keywords={Internet;file servers;resource allocation;Blue Eyes;Internet;automated system management;cloud computing;dynamic load-balancing;hierarchical tree;management information;management server;massive system management;multiserver scale-out architecture;network overhead;reliable system management;scalable system management;Availability;Cloud computing;Eyes;Information management;Large-scale systems;Network servers;Performance gain;Prototypes;Resource management;Scalability}, 
doi={10.1109/IPDPS.2009.5161232}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{5284212, 
author={H. Han and S. Kim and H. Jung and H. Y. Yeom and C. Yoon and J. Park and Y. Lee}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={A RESTful Approach to the Management of Cloud Infrastructure}, 
year={2009}, 
pages={139-142}, 
abstract={Recently, REpresentational State Transfer (REST) has been proposed as an alternative architecture for Web services.In the era of Cloud and Web 2.0, many complex Web service-based systems such as e-Business an de-Government applications have adopted REST. Unfortunately, the REST approach has been applied to few cases in management systems, especially for a management system for cloud computing infrastructures.In this paper, we design and implement a RESTful Cloud Management System (CMS).Managed elements can be modeled as resources in REST and operations in existing systems can be evaluated using four methods of REST or a combination of them.We also show how components of existing management systems can be realized as REST-style Web services.}, 
keywords={Web services;software architecture;RESTful approach;Web 2.0;Web services;alternative architecture;cloud infrastructure;cloud management system;representational state transfer;Application software;Cloud computing;Collision mitigation;Computer architecture;Computer network management;Representational state transfer;Resource management;Service oriented architecture;Simple object access protocol;Web services;Management System;REST}, 
doi={10.1109/CLOUD.2009.68}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5394134, 
author={S. Chaisiri and Bu-Sung Lee and D. Niyato}, 
booktitle={2009 IEEE Asia-Pacific Services Computing Conference (APSCC)}, 
title={Optimal virtual machine placement across multiple cloud providers}, 
year={2009}, 
pages={103-110}, 
abstract={Cloud computing provides users an efficient way to dynamically allocate computing resources to meet demands. Cloud providers can offer users two payment plans, i.e., reservation and on-demand plans for resource provisioning. Price of resources in reservation plan is generally cheaper than that in on-demand plan. However, since the reservation plan has to be acquired in advance, it may not fully meet future demands in which the on-demand plan can be used to guarantee the availability to the user. In this paper, we propose an optimal virtual machine placement (OVMP) algorithm. This algorithm can minimize the cost spending in each plan for hosting virtual machines in a multiple cloud provider environment under future demand and price uncertainty. OVMP algorithm makes a decision based on the optimal solution of stochastic integer programming (SIP) to rent resources from cloud providers. The performance of OVMP algorithm is evaluated by numerical studies and simulation. The results clearly show that the proposed OVMP algorithm can minimize users' budgets. This algorithm can be applied to provision resources in emerging cloud computing environments.}, 
keywords={Internet;costing;financial data processing;integer programming;stochastic programming;virtual machines;cloud computing;dynamic allocate computation;multiple cloud providers;on-demand plans;optimal virtual machine placement algorithm;payment plans;price uncertainty;reservation plan;resource provisioning;stochastic integer programming;user budget;Availability;Cloud computing;Computational modeling;Costs;Linear programming;Numerical simulation;Resource management;Stochastic processes;Uncertainty;Virtual machining}, 
doi={10.1109/APSCC.2009.5394134}, 
month={Dec},}
@INPROCEEDINGS{5159216, 
author={T. Singh and P. K. Vara}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={Smart Metering the Clouds}, 
year={2009}, 
pages={66-71}, 
abstract={As cloud computing becomes increasingly pervasive, the data center energy consumption attributable to cloud computing is climbing, despite the clarion call of action to reduce consumption and reverse environmental effects. At the same time, the rising cost of energy - due to regulatory measures enforcing a "true cost" of energy coupled with finite natural resources rapidly diminishing, resulting in scarcity - is refocusing IT leaders on efficiency and total cost of ownership (TCO), particularly in the context of the world-wide financial crisis. We propose a "smart metering" approach that encompasses all the stakeholders in the cloud computing ecosystem to achieve these twin goals of "energy conservation" and "demand response". As such, this paper introduces our initial thoughts on "smart metering" and various implications and implementation ideas related to it.}, 
keywords={computer centres;energy conservation;environmental factors;power aware computing;cloud computing ecosystem;data center energy consumption;demand response;energy conservation;pervasive computing;smart metering;Cloud computing;Conferences;Cooling;Costs;Distributed computing;Ecosystems;Energy consumption;Energy efficiency;Global warming;Grid computing}, 
doi={10.1109/WETICE.2009.49}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{5358166, 
author={H. Lu and B. Feng}, 
booktitle={2009 IEEE International Conference on Intelligent Computing and Intelligent Systems}, 
title={Intelligent topic map: A new approach to multi-resource knowledge service}, 
year={2009}, 
volume={3}, 
pages={373-377}, 
abstract={Along with the up-rising of knowledge economy, effective organizing multiple, distributed, heterogeneous knowledge resource and providing high-quality knowledge services for users have been becoming increasingly important. This paper proposes a novel concept of intelligent topic map for knowledge organization and knowledge services, which embodies the multi-level, multi-granularity and inherent relevant characteristics of knowledge and realizes knowledge reasoning. And then we define the architecture of multi-resource knowledge services based on intelligent topic map. Additionally, with the cloud computing as platform, a knowledge service system for multi-resource is designed and implemented. Finally, a demonstration is given to display the knowledge navigation based on intelligent topic map.}, 
keywords={grid computing;knowledge based systems;cloud computing;intelligent topic map;knowledge economy;knowledge navigation;knowledge organization;knowledge reasoning;knowledge resource;multiresource knowledge services;Cloud computing;Computer architecture;Information resources;Knowledge engineering;Knowledge management;Navigation;Ontologies;Portals;Research and development;Semantic Web;Cloud computing;Intelligent topic map;Knowledge navigation;Knowledge service}, 
doi={10.1109/ICICISYS.2009.5358166}, 
month={Nov},}
@INPROCEEDINGS{5395118, 
author={M. Randles and E. Odat and D. Lamb and O. Abu-Rahmeh and A. Taleb-Bendiab}, 
booktitle={2009 Second International Conference on Developments in eSystems Engineering}, 
title={A Comparative Experiment in Distributed Load Balancing}, 
year={2009}, 
pages={258-265}, 
abstract={The anticipated uptake of Cloud computing, built on the well-established research fields of Web services, networks, utility computing, distributed computing and virtualisation, will bring many advantages in cost, flexibility and availability for service users. These benefits are expected to further drive the demand for cloud services, increasing both the cloud customer base and the scale of cloud installations. This has implications for many technical issues in such Service Oriented Architectures and Internet of Services (IoS) type applications; fault tolerance, high availability and scalability for examples. Central to these issues is the establishment of effective load balancing techniques. It is clear that the scale and complexity of these systems makes centralized individual assignment of jobs to specific servers infeasible; leading to the need for an effective distributed solution. This paper investigates three possible distributed solutions, which have been proposed for load balancing: an approach inspired by the foraging behaviour of the Honeybee, Biased Random Sampling and Active Clustering.}, 
keywords={distributed processing;fault tolerant computing;resource allocation;software architecture;Internet of services;cloud computing;distributed load balancing;fault tolerance;service oriented architecture;Availability;Cloud computing;Computer networks;Costs;Distributed computing;Fault tolerance;Load management;Service oriented architecture;Web and internet services;Web services}, 
doi={10.1109/DeSE.2009.20}, 
month={Dec},}
@INPROCEEDINGS{5301850, 
author={C. Zhao and S. Zhang and Q. Liu and J. Xie and J. Hu}, 
booktitle={2009 5th International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={Independent Tasks Scheduling Based on Genetic Algorithm in Cloud Computing}, 
year={2009}, 
pages={1-4}, 
abstract={Task scheduling algorithm, which is an NP-completeness problem, plays a key role in cloud computing systems. In this paper, we propose an optimized algorithm based on genetic algorithm to schedule independent and divisible tasks adapting to different computation and memory requirements. We prompt the algorithm in heterogeneous systems, where resources (including CPUs) are of computational and communication heterogeneity. Dynamic scheduling is also in consideration. Though GA is designed to solve combinatorial optimization problem, it's inefficient for global optimization. So we conclude with further researches in optimized genetic algorithm.}, 
keywords={Internet;combinatorial mathematics;genetic algorithms;scheduling;NP-complete problem;cloud computing;combinatorial optimization problem;dynamic scheduling;genetic algorithm;global optimization;heterogeneous systems;independent tasks scheduling;Application software;Cloud computing;Design optimization;Dynamic scheduling;Genetic algorithms;Job shop scheduling;Laboratories;Processor scheduling;Scheduling algorithm;Service oriented architecture}, 
doi={10.1109/WICOM.2009.5301850}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{5228188, 
author={Dong Huailin and Zheng Yuhui and Gao Xin and Chen Fan and Guo Xin-hua}, 
booktitle={2009 4th International Conference on Computer Science Education}, 
title={The mobile search platform base on base station}, 
year={2009}, 
pages={960-964}, 
abstract={Start with cloud computing, SOA and Web 2.0, the three current emerging technologies, through composite applying, propose the mutational practice of user interactive question and answering system, which bases on mobile platform, research and probe the composes of system, flow work and its distinct property, and preview its commercial and technical significance.}, 
keywords={mobile computing;search engines;software architecture;workstation clusters;SOA;Web 2.0;base station;cloud computing;mobile search platform;Application software;Base stations;Cloud computing;Computer science;Connectors;Distributed computing;Internet;Mobile computing;Search engines;Service oriented architecture;Cloud Computing;Emulation;Interactive Question and Answering;SOA (Service Oriented Architecture);Web 2.0}, 
doi={10.1109/ICCSE.2009.5228188}, 
month={July},}
@INPROCEEDINGS{5375900, 
author={K. Mukherjee and G. Sahoo}, 
booktitle={2009 International Conference on Advances in Computing, Control, and Telecommunication Technologies}, 
title={Mathematical Model of Cloud Computing Framework Using Fuzzy Bee Colony Optimization Technique}, 
year={2009}, 
pages={664-668}, 
abstract={The existing infrastructure of modern civilization is based on some utility services, which are on pay per user basis. As for example, the utility services like water, gas, electricity etc are chargeable per user. Similarly, the agenda of cloud computing is to provide on demand IT resources on pay per user basis. These IT resources consist of different Web services. Accessing and scheduling of these Web services is always a challenging job. This paper proposes a new paradigm to provide these Web services to the end users. In this paper, we have simulated the nature of honey bee colony with the use of fuzziness to capture all the possible run time entities.}, 
keywords={Web services;fuzzy set theory;optimisation;Web services;cloud computing framework;fuzzy bee colony optimization technique;mathematical model;utility services;Cloud computing;Computer applications;Fuzzy control;Mathematical model;Telecommunication computing;Telecommunication control;Water resources;Web and internet services;Web server;Web services;Bee Colony;Cloud Computing;Fuzzy;Web services}, 
doi={10.1109/ACT.2009.168}, 
month={Dec},}
@INPROCEEDINGS{4736803, 
author={Y. Yang and K. Liu and J. Chen and X. Liu and D. Yuan and H. Jin}, 
booktitle={2008 IEEE Fourth International Conference on eScience}, 
title={An Algorithm in SwinDeW-C for Scheduling Transaction-Intensive Cost-Constrained Cloud Workflows}, 
year={2008}, 
pages={374-375}, 
abstract={The concept of cloud computing has been wide spreading very recently. Cloud computing has many unique advantages which can be utilised to facilitate (cloud) workflow execution. Transaction-intensive cost-constrained cloud workflows are workflows with a large number of workflow instances (i.e. transaction intensive) bounded by a certain budget for execution (i.e. cost constrained) in a cloud computing environment (i.e. cloud workflows). However, there are not any specific scheduling algorithms so far for transaction-intensive cost-constrained cloud workflows. This paper presents a novel scheduling algorithm which considers the characteristics of cloud computing to accommodate transaction-intensive cost-constrained workflows by compromising execution time and cost with user input enabled on the fly. The simulation performed demonstrates that the algorithm can reduce the mean execution cost while meeting the user-requested deadline.}, 
keywords={Internet;grid computing;scheduling;transaction processing;SwinDeW-C;Swinburne Decentralised for Cloud workflow system;cloud computing;scheduling algorithm;transaction-intensive cost-constrained cloud workflow;Australia;Cloud computing;Computer science;Cost function;Monitoring;Processor scheduling;Resource management;Scheduling algorithm;Throughput;User interfaces;Cloud Computing;Cloud Workflows;Cost-constrained workflows;Transaction-intensive workflows;Workflow Scheduling Algorithms}, 
doi={10.1109/eScience.2008.93}, 
month={Dec},}
@INPROCEEDINGS{5298710, 
author={P. C. Y. Sheu and S. Wang and Q. Wang and K. Hao and R. Paul}, 
booktitle={2009 IEEE International Conference on Semantic Computing}, 
title={Semantic Computing, Cloud Computing, and Semantic Search Engine}, 
year={2009}, 
pages={654-657}, 
abstract={Semantic Computing extends Semantic Web both in breadth and depth. It bridges, and integrates, technologies such as software engineering, user interface, natural language processing, artificial intelligence, programming language, grid computing and pervasive computing, among others, into a complete and unified theme. Cloud Computing, the dream of computing as a utility, shifts user programs and data from personal computers to the clouds, providing all kinds of resources over the Internet as services to customers and letting customers pay for them in a way much like they pay for traditional utilities such as electricity. This paper analyzes both Semantic Computing and Cloud Computing, and introduces the Semantic Search Engine, an infrastructure and implementation of Semantic Computing, that demonstrates how Semantic Computing can benefit Cloud Computing.}, 
keywords={search engines;semantic Web;Internet;cloud computing;semantic Web;semantic computing;semantic search engine;Artificial intelligence;Bridges;Cloud computing;Computer languages;Grid computing;Natural language processing;Search engines;Semantic Web;Software engineering;User interfaces;cloud computing;semantic computing;semantic search engine}, 
doi={10.1109/ICSC.2009.51}, 
month={Sept},}
@INPROCEEDINGS{5355050, 
author={A. Leon-Garcia}, 
booktitle={2009 IEEE 34th Conference on Local Computer Networks}, 
title={ICT as enabler of smart infrastructures}, 
year={2009}, 
pages={12-12}, 
abstract={Summary form only given. Together, the proliferation of sensors and communicating devices and the emergence of cloud computing represents a major opportunity to develop applications for connected environments in general, and especially management systems that address urgent challenges facing society. These challenges include the deployment of large-scale cloud computing, smart power grids, intelligent transportation systems, and next-generation communications and collaborations that will provide the foundation for a post-carbon society. In this talk we discuss the socio-economic context that gives these challenges urgency as well as the technical challenges that need to be addressed by the ICT community.}, 
keywords={information technology;social aspects of automation;socio-economic effects;ICT community;cloud computing;intelligent transportation systems;management systems;next-generation communications;smart infrastructures;smart power grids;socio-economic context;Cloud computing;Collaboration;Disaster management;Environmental management;Intelligent Transportation Systems Society;Intelligent sensors;Large-scale systems;Power system management;Sensor systems and applications;Smart grids}, 
doi={10.1109/LCN.2009.5355050}, 
ISSN={0742-1303}, 
month={Oct},}
@INPROCEEDINGS{5328581, 
author={D. Bernstein}, 
booktitle={2009 Sixth IFIP International Conference on Network and Parallel Computing}, 
title={Keynote 2: The Intercloud: Cloud Interoperability at Internet Scale}, 
year={2009}, 
pages={xiii-xiii}, 
abstract={Today, cloud computing is seen largely as isolated providers or enterprise instances of a special kind of hosting or application container. Virtual machines, or managed code executing against cloud API's, are limited to that provider or that enterprise in terms of direct context or reach. This reminds us very much of the state of networking before the Internet where LANs of various domains and protocols did not interconnect. It will either be history repeating, or our collective manifest destiny, to evolve cloud computing to a worldwide, interoperable, transparent platform. In other words, cloud will become to computing just what the Internet is for data. Unfortunately, there are many aspects of the platform on which cloud computing depends which are preventing this. For example, for the Internet to work, someone had to invent IP addressing, domain name service, peering and routing protocols such as AS numbering, OSPF and BGP, and certificates to enable SSL. In cloud, for the broader vision of cloud interoperability to work, ranging from VM mobility to storage federation to multicast and media streaming interoperability to identity and presence and everything in between, analogous technologies need to be invented. This talk overviews the "grand challenges" in making such changes on the scale of the Internet, and then speaks to specific work completed to-date and in-progress in standards bodies. The attendee will leave the talk with a new understanding of how following the blueprints of the Internet itself (exchange and peering, geographical dispersion, etc) are enabling cloud interoperability at a fundamental level. This is what is being called the "intercloud".}, 
keywords={Internet;application program interfaces;open systems;virtual machines;Internet;application programming interface;cloud API;cloud computing;cloud interoperability;collective manifest destiny;intercloud paradigm;media streaming interoperability;virtual machine;Cloud computing;Containers;History;IP networks;LAN interconnection;Routing protocols;Streaming media;Virtual machining;Virtual manufacturing;Web and internet services}, 
doi={10.1109/NPC.2009.7}, 
month={Oct},}
@INPROCEEDINGS{5222625, 
author={A. Singh and M. Korupolu and D. Mohapatra}, 
booktitle={2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis}, 
title={Server-storage virtualization: Integration and load balancing in data centers}, 
year={2008}, 
pages={1-12}, 
abstract={We describe the design of an agile data center with integrated server and storage virtualization technologies. Such data centers form a key building block for new cloud computing architectures.We also show how to leverage this integrated agility for non-disruptive load balancing in data centers across multiple resource layers - servers, switches, and storage. We propose a novel load balancing algorithm called VectorDot for handling the hierarchical and multi-dimensional resource constraints in such systems. The algorithm, inspired by the successful Toyoda method for multi-dimensional knapsacks, is the first of its kind. We evaluate our system on a range of synthetic and real data center testbeds comprising of VMware ESX servers, IBM SAN Volume Controller, Cisco and Brocade switches. Experiments under varied conditions demonstrate the end-to-end validity of our system and the ability of VectorDot to efficiently remove overloads on server, switch and storage nodes.}, 
keywords={computer centres;file servers;resource allocation;storage area networks;Brocade switches;Cisco;IBM SAN Volume Controller;VMware ESX servers;VectorDot;agile data center;cloud computing architectures;load balancing algorithm;multidimensional knapsacks;multidimensional resource constraints;server-storage virtualization;storage virtualization technologies;Application virtualization;Computer applications;Load management;Network servers;Resource management;Resource virtualization;Storage area networks;Switches;Virtual machining;Voice mail}, 
doi={10.1109/SC.2008.5222625}, 
ISSN={2167-4329}, 
month={Nov},}
@INPROCEEDINGS{5381739, 
author={J. Abawajy}, 
booktitle={2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks}, 
title={Determining Service Trustworthiness in Intercloud Computing Environments}, 
year={2009}, 
pages={784-788}, 
abstract={Deployment of applications and scientific workflows that require resources from multiple distributed platforms are fuelling the federation of autonomous clouds to create cyber infrastructure environments. As the scope of federated cloud computing enlarges to ubiquitous and pervasive computing, there will be a need to assess and maintain the trustworthiness of the cloud computing entities. In this paper, we present a fully distributed framework that enable interested parties determine the trustworthiness of federated cloud computing entities.}, 
keywords={grid computing;security of data;ubiquitous computing;cyber infrastructure environments;distributed platforms;federated cloud computing;grid computing;intercloud computing environments;pervasive computing;scientific workflows;service trustworthiness;ubiquitous computing;Cloud computing;Computer networks;Distributed computing;Grid computing;IP networks;Pervasive computing;Protocols;Resource management;Virtual machining;Web and internet services;Cloud computing;Grid computing;interCloud;interGrid;reputation;trust}, 
doi={10.1109/I-SPAN.2009.155}, 
ISSN={1087-4089}, 
month={Dec},}
@INPROCEEDINGS{5329075, 
booktitle={2009 Fourth ChinaGrid Annual Conference}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics were dealt with: grid resource management; grid job scheduling; data grid; grid security; grid applications; semantic grid and semantic Web; cluster computing; virtual machine; peer-to-peer computing; and cloud computing.}, 
keywords={grid computing;peer-to-peer computing;semantic Web;virtual machines;workstation clusters;cloud computing;cluster computing;data grid;grid applications;grid job scheduling;grid resource management;grid security;peer-to-peer computing;semantic Web;semantic grid;virtual machine}, 
doi={10.1109/ChinaGrid.2009.1}, 
ISSN={1949-131X}, 
month={Aug},}
@INPROCEEDINGS{5405416, 
author={Zhen Li and Dahai Han and Jie Zhang and Xiuzhong Chen and Wanyi Gu and Yuefeng Ji}, 
booktitle={2009 Asia Communications and Photonics conference and Exhibition (ACP)}, 
title={The research of Cloud Computing based on service plane over optical networks}, 
year={2009}, 
volume={2009-Supplement}, 
pages={1-8}, 
abstract={The implementation of Cloud Computing over optical networks faces many challenges and opportunities. A cloud computing architecture over optical networks is proposed based on the service plane. And the validity of the architecture we proposed was experimentally demonstrated in our Adaptive Multi-Service Optical Network testbed.}, 
keywords={Adaptive systems;Cloud computing;Computer architecture;Costs;Distributed computing;Grid computing;Internet;Optical fiber networks;Photonics;Testing;AMSON;Cloud Computing;optical network;service plane}, 
ISSN={2162-108X}, 
month={Nov},}
@INPROCEEDINGS{5342052, 
author={F. C. Lin and Y. S. Lee and C. H. Hsu and K. Y. Chen and T. C. Weng}, 
booktitle={2009 IEEE International Conference on e-Business Engineering}, 
title={Service Component Architecture for Vending Machine System in Cloud Computing Infrastructure}, 
year={2009}, 
pages={591-595}, 
abstract={This paper proposes a software integration model of service component architecture in the vending industry. We use this architecture to rapidly integrate related services, substantially reduce development costs, establish innovative services, and provide consumers with a brand new experiential shopping environment in retail domain. Meanwhile, we apply a cloud computing technology to solve the following problem: service over loading in a distributed environment. We also discover many issues that will happen with system scaling up in smart store, such as virtual integration, location-based shopping service, personal services, and product optimization. Therefore we use cloud computing to solve these discussed issues. Finally, this paper gives two services as an example to be implemented in the vending industry. The research provides a cloud-based integration system that composes other services easily. The results of this research can increase development speed, and decrease poorly-done work over again and time consumption. It also makes allowance for system stability and scalability.}, 
keywords={Web services;object-oriented programming;resource allocation;retail data processing;vending machines;cloud computing infrastructure;development cost reduction;distributed environment;experiential shopping environment;innovative service establishment;location-based shopping service;personal service;product optimization;retail domain;service component architecture;service over loading;smart store;system scalability;system stability;vending industry;vending machine system;virtual software integration model;Application software;Cloud computing;Component architectures;Computer architecture;Computer industry;Costs;Distributed computing;IP networks;Machinery production industries;Service oriented architecture;cloud computing;service component architecture;vending industry}, 
doi={10.1109/ICEBE.2009.93}, 
month={Oct},}
@INPROCEEDINGS{5276725, 
author={G. Briscoe and A. Marinos}, 
booktitle={2009 3rd IEEE International Conference on Digital Ecosystems and Technologies}, 
title={Digital ecosystems in the clouds: Towards community cloud computing}, 
year={2009}, 
pages={103-108}, 
abstract={Cloud Computing is rising fast, with its data centres growing at an unprecedented rate. However, this has come with concerns of privacy, efficiency at the expense of resilience, and environmental sustainability, because of the dependence on Cloud vendors such as Google, Amazon, and Microsoft. Community Cloud Computing makes use of the principles of Digital Ecosystems to provide a paradigm for Clouds in the community, offering an alternative architecture for the use cases of Cloud Computing. It is more technically challenging to deal with issues of distributed computing, such as latency, differential resource management, and additional security requirements. However, these are not insurmountable challenges, and with the need to retain control over our digital lives and the potential environmental consequences, it is a challenge we must pursue.}, 
keywords={Internet;computer centres;Amazon;Google;Microsoft;cloud vendors;community cloud computing;data centres;differential resource management;digital ecosystems;distributed computing;environmental sustainability;latency;potential environmental consequences;security requirements;Cloud computing;Computer architecture;Delay;Distributed computing;Ecosystems;Green products;Privacy;Resilience;Resource management;Security;Cloud Computing;Community Cloud Computing;Community Clouds;Digital Ecosystems;Sustainability}, 
doi={10.1109/DEST.2009.5276725}, 
ISSN={2150-4938}, 
month={June},}
@ARTICLE{5429055, 
author={M. Naghshineh and R. Ratnaparkhi and D. Dillenberger and J. R. Doran and C. Dorai and L. Anderson and G. Pacifici and J. L. Snowdon and A. Azagury and M. VanderWiele and Y. Wolfsthal}, 
journal={IBM Journal of Research and Development}, 
title={IBM Research Division cloud computing initiative}, 
year={2009}, 
volume={53}, 
number={4}, 
pages={1:1-1:10}, 
abstract={Cloud computing represents the latest phase in the evolution of Internet-based computing. In this paper, we describe the fundamental building blocks of cloud computing and the initiative undertaken by the IBM Research Division in this area, which includes work on Internet-scale data centers, virtualization, scalable storage, and cloud computing services. The focus of this project has been the Research Compute Cloud, an environment for cloud computing research that is also used as a computing resource by various groups in the IBM Research Division.}, 
doi={10.1147/JRD.2009.5429055}, 
ISSN={0018-8646}, 
month={July},}
@INPROCEEDINGS{5394133, 
author={H. Ma and K. D. Schewe and Q. Wang}, 
booktitle={2009 IEEE Asia-Pacific Services Computing Conference (APSCC)}, 
title={An abstract model for service provision, search and composition}, 
year={2009}, 
pages={95-102}, 
abstract={Service-oriented computing, cloud computing, and web services composition mark cornerstones of a paradigm shift in software systems engineering. The general new idea is to use as much as possible services that are made available by others, mostly disseminated via the web. In this paper, we present an abstract model for clouds as federations of services together with a specification of semantics and quality characteristics. For the services as such we adopt the abstract model of abstract state services, which is based on views on some hidden database layer that are equipped with service operations. For the semantics we adopt types for in- and output, pre- and post-conditions, and a description of functionality within an operations ontology. In addition, quality characteristics capture performance, costs, availability, etc. On the basis of this model of clouds, users may conduct a (web) search for usable services, extract service components, and recompose these components. The quality characteristics can be used to optimise the selection of usable services.}, 
keywords={Web services;software engineering;Web search;Web services composition;abstract model;abstract state services;cloud computing;hidden database layer;paradigm shift;service oriented computing;service provision;software systems engineering;usable services;Cloud computing;Computer architecture;Computer science;Databases;Information science;Information systems;Ontologies;Service oriented architecture;Software systems;Web services}, 
doi={10.1109/APSCC.2009.5394133}, 
month={Dec},}
@INPROCEEDINGS{5368588, 
author={B. C. Ooi}, 
booktitle={2009 Fifth International Conference on Semantics, Knowledge and Grid}, 
title={Cloud Data Management Systems: Opportunities and Challenges}, 
year={2009}, 
pages={2-2}, 
abstract={Cloud computing, an infrastructure of providing computing utility as a service, is changing a large part of the IT industry. By delivering to users "infinite" computing resources in a pay-as-you-go manner, cloud computing is turning into reality a dream that has long been cherished by the IT industry. For years, people have been hoping to achieve the abilities of continuously scaling up and of elastic resource utilizing, which now are within grasp. However, building a scalable data management system on existing commercial cloud platforms, such as Amazon EC2, poses a grand challenge. Indeed, new application requirements and the underlying hardware environment affect every aspect of the data management system, from individual components to system architecture. In this talk, we will present the opportunities and challenges of developing a scalable cloud data management system. First, we examine the anatomy of a cloud data intensive system. Then, we present three main challenges posed by a scalable cloud data processing system, i.e., multitenancy architecture, high throughout low latency transactions, and high performance reliable query processing. We will discuss why existing large-scale distributed systems such as peer-to-peer systems, distributed data management systems and massive parallel processing systems may not be able to deliver sufficient scalability, fault tolerance and satisfactory performance at cloud scale. Finally, we discuss possible solutions, consider current practices, and speculate the future of cloud computing.}, 
keywords={Internet;parallel processing;peer-to-peer computing;ubiquitous computing;cloud computing;cloud data intensive system;distributed data management;distributed system;multitenancy architecture;parallel processing system;peer-to-peer system;query processing;scalable cloud data management system;Anatomy;Buildings;Cloud computing;Computer industry;Data processing;Delay;Environmental management;Hardware;Query processing;Turning}, 
doi={10.1109/SKG.2009.110}, 
month={Oct},}
@INPROCEEDINGS{5159215, 
author={W. Ji and J. Ma and X. Ji}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={A Reference Model of Cloud Operating and Open Source Software Implementation Mapping}, 
year={2009}, 
pages={63-65}, 
abstract={In this article, a reference model is proposed. The model divides the cloud computing system with various components in a 3-layer hierarchy called infrastructure, platform and application. The details of the components are presented for its functionality assumed. Also the open source software implementation for the components in the model is addressed.}, 
keywords={operating systems (computers);public domain software;workstation clusters;cloud computing system;cloud operating;open source software implementation mapping;Clouds;Open source software;Cloud Computing;FCAPS;Open Source Software;Reference Model}, 
doi={10.1109/WETICE.2009.28}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{5279613, 
author={C. Hu and Z. Liu}, 
booktitle={2009 Eighth International Conference on Grid and Cooperative Computing}, 
title={MatDC: Data Cloud Model For Management and Sharing of Material Science Data}, 
year={2009}, 
pages={225-231}, 
abstract={Cloud computing allows to access large amounts of scientific data and scientific computational resources efficiently through a variety of service interfaces. This paper presents a data cloud model called MatDC, which is designed for material scientists to conveniently integrate and analyze material science data. MatDC is a domain scientific data platform with the cloud computing. It not only provides an easy interface for user to access large amounts distributed resources through web browser, but also creates a flexible mechanism for cloud provider to deploy and replace the data-intensive application. In addition, highly modularity is the characteristic of MatDC, well-defined service API with module improves reusing and sharing service components. We describe the architecture of MatDC and illustrate the core data cloud services in detail. Finally, an experiment is prepared to show how MatDC is used to support material scientific activity.}, 
keywords={Internet;application program interfaces;data analysis;materials science computing;online front-ends;API;MatDC;cloud computing;data cloud model;data-intensive application;distributed resources;material science data management;material science data sharing;modularity;scientific computational resources;scientific data;service component reusing;service component sharing;web browser;Cloud computing;Computer interfaces;Data analysis;Data engineering;Distributed computing;Failure analysis;Grid computing;Materials science and technology;Power engineering computing;Resource management;MatDC;cloud computing;data cloud service;material science data}, 
doi={10.1109/GCC.2009.31}, 
ISSN={2160-4908}, 
month={Aug},}
@ARTICLE{5305906, 
author={P. Hunter}, 
journal={Engineering Technology}, 
title={Cloud aloud [IT Applications]}, 
year={2009}, 
volume={4}, 
number={16}, 
pages={54-56}, 
abstract={The concept of cloud computing is going to reorganise the tenets of enterprise IT. Cloud computing sounds like traditional IT outsourcing, but the difference is that this is not just about ownership of IT staff and resources, but a new way of organising, acquiring, and paying for IT infrastructures and services, with outsourcing being just part of the mix. Characterised this way, the move towards cloud computing seems certain, even if enterprises are reluctant to move forward too rapidly right now. Only a few enterprises are actually adopting cloud services at the moment, but the fact that any are is notable. This paper discusses cloud computing's progress within the enterprises.}, 
keywords={Internet;electronic commerce;IT outsourcing;cloud computing;cloud service;enterprise IT}, 
ISSN={1750-9637}, 
month={Sept},}
@INPROCEEDINGS{5236386, 
author={K. Xu and M. Song and X. Zhang and J. Song}, 
booktitle={2009 IEEE International Symposium on IT in Medicine Education}, 
title={A Cloud Computing Platform Based on P2P}, 
year={2009}, 
volume={1}, 
pages={427-432}, 
abstract={In recent years, the technology of cloud computing has been widely applied in e-business, e-education and etc.. Cloud computing platform is a set of scalable large-scale data server clusters, it provide computing and storage services to customers. The cloud storage is a relatively basic and widely applied service which can provide users with stable, massive data storage space. Our research shows that the architecture of current cloud computing system is central structured one, all the data nodes must be indexed by a master server which may become bottle neck of the system. In this paper, we propose a new cloud storage architecture based on P2P and design a prototype system. The system based on the new architecture has better scalability and fault tolerance.}, 
keywords={Web services;peer-to-peer computing;storage management;P2P;cloud computing platform;data storage service;e-business;e-education;master server;scalable large-scale data server cluster;Cloud computing;Computer architecture;File systems;Large-scale systems;Memory;Neck;Network servers;Prototypes;Scalability;Telecommunication computing;P2P;cloud computing;storage}, 
doi={10.1109/ITIME.2009.5236386}, 
month={Aug},}
@INPROCEEDINGS{5279590, 
author={E. Elmroth and L. Larsson}, 
booktitle={2009 Eighth International Conference on Grid and Cooperative Computing}, 
title={Interfaces for Placement, Migration, and Monitoring of Virtual Machines in Federated Clouds}, 
year={2009}, 
pages={253-260}, 
abstract={Current cloud computing infrastructure offerings are lacking in interoperability, which is a hindrance to the advancement and adoption of the cloud computing paradigm. As clouds are made interoperable, federations of clouds may be formed. Such federations are from the point of view of the user not burdened by vendor lock-in, and opens for business possibilities where a market place of cloud computing infrastructure can be formed. Federated clouds require unified management interfaces regarding the virtual machines (VMs) that comprise the services running in the cloud federation. Standardization efforts for the required management interfaces have so far focused on definition of description formats regarding VMs, and the control of already deployed VMs. We propose technology neutral interfaces and architectural additions for handling placement, migration, and monitoring of VMs in federated cloud environments, the latter as an extension of current monitoring architectures used in grid computing. The interfaces presented adhere to the general requirements of scalability, efficiency, and security in addition to specific requirements related to the particular issues of interoperability and business relationships between competing cloud computing infrastructure providers. In addition, they may be used equally well locally and remotely, creating a layer of abstraction that simplifies management of virtualized service components.}, 
keywords={grid computing;open systems;security of data;software architecture;software management;system monitoring;virtual machines;business relationships;cloud computing infrastructure;federated clouds;grid computing;monitoring architectures;security;technology neutral interfaces;virtual machines;virtualized service component management;Cloud computing;Computer architecture;Condition monitoring;Grid computing;Remote monitoring;Scalability;Standardization;Virtual machine monitors;Virtual machining;Voice mail;cloud computing;federated cloud;migration;monitoring}, 
doi={10.1109/GCC.2009.36}, 
ISSN={2160-4908}, 
month={Aug},}
@ARTICLE{4907382, 
author={R. W. Lucky}, 
journal={IEEE Spectrum}, 
title={Cloud computing [Reflections]}, 
year={2009}, 
volume={46}, 
number={5}, 
pages={27-27}, 
abstract={Is cloud computing an idea whose time has come?}, 
keywords={Cloud computing}, 
doi={10.1109/MSPEC.2009.4907382}, 
ISSN={0018-9235}, 
month={May},}
@INPROCEEDINGS{5381749, 
author={J. Y. Lee and J. W. Lee and D. W. Cheun and S. D. Kim}, 
booktitle={2009 Seventh ACIS International Conference on Software Engineering Research, Management and Applications}, 
title={A Quality Model for Evaluating Software-as-a-Service in Cloud Computing}, 
year={2009}, 
pages={261-266}, 
abstract={Cloud computing is a style of computing in which dynamically scalable and often virtualized resources are provided as a service over the Internet. One type of cloud service, SaaS is commonly utilized and it provides several benefits to service consumers. To realize these benefits, it is essential to evaluate the quality of SaaS and manage relatively higher level of its quality based on the evaluation result. Hence, there is a high demand for devising a quality model to evaluate SaaS cloud services. Conventional frameworks do not effectively support SaaS-specific quality aspects such as reusability and accessibility. In this paper, we propose a comprehensive model for evaluating quality of SaaS. We first define key features of SaaS. And then, we derive quality attributes from the key features, and define metrics for the quality attributes. To validate our quality model for SaaS, we conduct assessment based on IEEE 1061. By using the proposed SaaS quality model, SaaS can be evaluated by both service providers. Furthermore, the evaluation results are utilized as an indicator for SaaS quality management.}, 
keywords={Internet;software performance evaluation;software quality;software reusability;software standards;IEEE 1061;Internet;SaaS cloud services;SaaS quality management;SaaS quality model;cloud computing;quality attributes;service consumers;software-as-a-service;Cloud computing;Conference management;ISO standards;Q factor;Quality management;Resource management;Software engineering;Software maintenance;Web and internet services;Web services}, 
doi={10.1109/SERA.2009.43}, 
month={Dec},}
@INPROCEEDINGS{4637675, 
author={R. Buyya and C. S. Yeo and S. Venugopal}, 
booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
title={Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities}, 
year={2008}, 
pages={5-13}, 
abstract={This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision.}, 
keywords={Web services;customer services;grid computing;marketing data processing;resource allocation;risk management;3rd generation Aneka enterprise grid technology;IT service delivery;SLA-oriented resource allocation;Web service;computational risk management;computing utility;customer-driven service management;market-oriented cloud computing;resource management strategy;Cloud computing;Computer architecture;Computer vision;Environmental management;Grid computing;Paper technology;Resource management;Risk management;Technology management;Voice mail;Cloud Computing;Market Oriented Resource Management;Service Level Agreements;Utility Computing;Virtual Machines}, 
doi={10.1109/HPCC.2008.172}, 
month={Sept},}
@INPROCEEDINGS{5072540, 
author={D. Bernstein and E. Ludvigson and K. Sankar and S. Diamond and M. Morrow}, 
booktitle={2009 Fourth International Conference on Internet and Web Applications and Services}, 
title={Blueprint for the Intercloud - Protocols and Formats for Cloud Computing Interoperability}, 
year={2009}, 
pages={328-336}, 
abstract={Cloud computing is a term applied to large, hosted datacenters, usually geographically distributed, which offer various computational services on a ldquoutilityrdquo basis. Most typically the configuration and provisioning of these datacenters, as far as the services for the subscribers go, is highly automated, to the point of the service being delivered within seconds of the subscriber request. Additionally, the datacenters typically use hypervisor based virtualization as a technique to deliver these services. The concept of a cloud operated by one service provider or enterprise interoperating with a clouds operated by another is a powerful idea. So far that is limited to use cases where code running on one cloud explicitly references a service on another cloud. There is no implicit and transparent interoperability. Use cases for interoperability, as well as work-in-progress around inter-cloud protocols and formats for enabling those use cases, are discussed in this paper.}, 
keywords={open systems;protocols;cloud computing interoperability;computational services;datacenters;hypervisor based virtualization;inter-cloud protocols;transparent interoperability;Cloud computing;Protocols;Cloud Computing;Intercloud}, 
doi={10.1109/ICIW.2009.55}, 
month={May},}
@INPROCEEDINGS{5454495, 
author={G. Wei and A. V. Vasilakos and N. Xiong}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Scheduling Parallel Cloud Computing Services: An Evolutional Game}, 
year={2009}, 
pages={376-379}, 
abstract={Cloud computing is a natural evolution for data and compute centers with automated systems management, workload balancing, and virtualization technologies. Cloud-based services integrate globally distributed resources into seamless computing platforms. In an open cloud computing framework, scheduling tasks with guaranteeing QoS constrains presents a challenging technical problem. This paper presents a game theoretic method to schedule dependent computational cloud computing services with time and cost constrained. An evolutionary mechanism is designed to fairly and approximately solve the NP-hard scheduling problem.}, 
keywords={Internet;computer centres;game theory;parallel architectures;quality of service;resource allocation;scheduling;NP hard scheduling problem;QoS constrains;automated systems management;computer centers;evolutional game;game theoretic method;parallel cloud computing services;seamless computing platforms;virtualization technologies;workload balancing;Cloud computing;Concurrent computing;Data engineering;Distributed computing;Educational institutions;Processor scheduling;Quality of service;Resource management;Technology management;Telecommunication computing}, 
doi={10.1109/ICISE.2009.1046}, 
ISSN={2160-1283}, 
month={Dec},}
@ARTICLE{5076318, 
author={T. Sterling and D. Stark}, 
journal={Computing in Science Engineering}, 
title={A High-Performance Computing Forecast: Partly Cloudy}, 
year={2009}, 
volume={11}, 
number={4}, 
pages={42-49}, 
abstract={Cloud computing is emerging as an important computational resource allocation trend in commercial, academic, and industrial sectors. Yet, because the business model doesn't currently meet all the needs of high-performance computing (HPC)-the demands of capability computing, for example-the relationship between clouds and HPC suggests a partly cloudy forecast.}, 
keywords={Web services;parallel processing;resource allocation;HPC forecast;cloud computing;computational resource allocation;high-performance computing forecast;industrial sector;Availability;Business;Cloud computing;Computer industry;Computer networks;Costs;Delay;Distributed computing;Economies of scale;Resource management;computer system implementation;computer systems;computer systems organization;emerging technologies}, 
doi={10.1109/MCSE.2009.111}, 
ISSN={1521-9615}, 
month={July},}
@INPROCEEDINGS{5270298, 
author={A. Kangarlou and P. Eugster and D. Xu}, 
booktitle={2009 IEEE/IFIP International Conference on Dependable Systems Networks}, 
title={VNsnap: Taking snapshots of virtual networked environments with minimal downtime}, 
year={2009}, 
pages={524-533}, 
abstract={A virtual networked environment (VNE) consists of virtual machines (VMs) connected by a virtual network. It has been adopted to create ldquovirtual infrastructuresrdquo for individual users on a shared cloud computing infrastructure. The ability to take snapshots of an entire VNE - including images of the VMs with their execution, communication and storage states - yields a unique approach to reliability as a snapshot can restore the operation of an entire virtual infrastructure. We present VNsnap, a system that takes distributed snapshots of VNEs. Unlike existing distributed snapshot/checkpointing solutions, VNsnap does not require any modifications to the applications, libraries, or (guest) operating systems running in the VMs. Furthermore, VNsnap incurs only seconds of downtime as much of the snapshot operation takes place concurrently with the VNE's normal operation. We have implemented VNsnap on top of Xen. Our experiments with real-world parallel and distributed applications demonstrate VNsnap's effectiveness and efficiency.}, 
keywords={checkpointing;distributed algorithms;virtual machines;VNsnap-snapshot technique;checkpointing solution;distributed snapshot;distributed snapshot algorithm;real-world parallel-distributed application;shared cloud computing infrastructure;system downtime minimization;virtual infrastructure;virtual machine;virtual networked environment;Application software;Checkpointing;Cloud computing;Image restoration;Image storage;Operating systems;TCPIP;Virtual machining;Virtual manufacturing;Voice mail}, 
doi={10.1109/DSN.2009.5270298}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{4666551, 
author={J. Wang and Z. Liu}, 
booktitle={2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery}, 
title={Parallel Data Mining Optimal Algorithm of Virtual Cluster}, 
year={2008}, 
volume={5}, 
pages={358-362}, 
abstract={Based on the problem of TB level mass data lacking of parallel patterns which is distributed on Earth and accessed by Internet, we focus on the research of parallel computing architecture structure--virtual cluster based on cloud computing. Meanwhile, the parallel data mining algorithm is studied, and the effectiveness of parallel data mining algorithm based on this platform is proved.}, 
keywords={Internet;data mining;parallel algorithms;virtual machines;workstation clusters;Internet;cloud computing;data mining algorithm;parallel data mining optimal algorithm;virtual cluster;Application software;Cloud computing;Clustering algorithms;Concurrent computing;Data mining;Internet;Parallel algorithms;Parallel processing;Virtual machining;Web server;Data Mining;Parallel Algorithms;Virtual Cluster}, 
doi={10.1109/FSKD.2008.452}, 
month={Oct},}
@INPROCEEDINGS{5353075, 
author={S. Ostermann and R. Prodan and T. Fahringer}, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={Extending Grids with cloud resource management for scientific computing}, 
year={2009}, 
pages={42-49}, 
abstract={From its start using supercomputers, scientific computing constantly evolved to the next levels such as cluster computing, meta-computing, or computational Grids. Today, Cloud Computing is emerging as the paradigm for the next generation of large-scale scientific computing, eliminating the need of hosting expensive computing hardware. Scientists still have their Grid environments in place and can benefit from extending them by leased Cloud resources whenever needed. This paradigm shift opens new problems that need to be analyzed, such as integration of this new resource class into existing environments, applications on the resources and security. The virtualization overheads for deployment and starting of a virtual machine image are new factors which will need to be considered when choosing scheduling mechanisms. In this paper we investigate the usability of compute Clouds to extend a Grid workflow middleware and show on a real implementation that this can speed up executions of scientific workflows.}, 
keywords={grid computing;information management;middleware;virtual machines;cloud computing;cloud resource management;grid extension;grid workflow middleware;large-scale scientific computing;scheduling mechanisms;virtual machine image;Cloud computing;Grid computing;Hardware;Large-scale systems;Processor scheduling;Resource management;Scientific computing;Security;Supercomputers;Virtual machining}, 
doi={10.1109/GRID.2009.5353075}, 
ISSN={2152-1085}, 
month={Oct},}
@INPROCEEDINGS{5359623, 
author={H. S. Abdelsalam and K. Maly and R. Mukkamala and M. Zubair and D. Kaminsky}, 
booktitle={2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns}, 
title={Analysis of Energy Efficiency in Clouds}, 
year={2009}, 
pages={416-421}, 
abstract={A cloud can be defined as a pool of computer resources that can host a variety of different workloads, ranging from long-running scientific jobs (e.g., modeling and simulation) to transactional work (e.g., web applications). A cloud computing platform dynamically provisions, configures, reconfigures, and de-provisions servers as needed. Servers in the cloud can be physical machines or virtual machines. Cloud-hosting facilities, including many large businesses that run clouds in-house, became more common as businesses tend to out-source their computing needs more and more. For large-scale clouds power consumption is a major cost factor. Modern computing devices have the ability to run at various frequencies each one with a different power consumption level. Hence, the possibility exists to choose frequencies at which applications run to optimize total power consumption while staying within the constraints of the Service Level Agreements (SLA) that govern the applications. In this paper, we analyze the mathematical relationship of these SLAs and the number of servers that should be used and at what frequencies they should be running. We discuss a proactive provisioning model that includes hardware failures, devices available for services, and devices available for change management, all as a function of time and within constraints of SLAs. We provide scenarios that illustrate the mathematical relationships for a sample cloud and that provides a range of possible power consumption savings for different environments.}, 
keywords={Internet;virtual machines;change management;cloud computing;hardware failures;long-running scientific jobs;physical machines;power consumption;proactive provisioning model;service level agreements;transactional work;virtual machines;Application software;Cloud computing;Computational modeling;Computer simulation;Costs;Energy consumption;Energy efficiency;Frequency;Large-scale systems;Virtual machining;Autonomic Manager;Change Management;Cloud Computing;Energy Efficient.;Policy Languages}, 
doi={10.1109/ComputationWorld.2009.38}, 
month={Nov},}
@ARTICLE{4712495, 
author={L. D. Paulson and L. D. Paulson and L. D. Paulson and L. D. Paulson}, 
journal={Computer}, 
title={News Briefs}, 
year={2008}, 
volume={41}, 
number={12}, 
pages={21-23}, 
abstract={An academic team has developed a prototype system for providing antivirus protection via the Internet. This security-as-a-service approach is an example of cloud computing, an increasingly popular technique in which applications and services are offered via the Internet, rather than via programs loaded onto in-house PCs or servers. The University of Michigan team's CloudAV system would let users avoid having to keep and update complex antivirus software on their own computers. Instead, security providers would handle this on their systems.}, 
keywords={Internet;educational institutions;invasive software;Internet;academic team;antivirus protection;cloud computing;prototype system;security-as-a-service approach;Batteries;Current;Fires;Mesh networks;Power generation;Radiofrequency identification;Satellite broadcasting;Sensor systems;Temperature sensors;Wireless sensor networks;Ambient Systems;CloudAV;RFID;Voltree Power;antivirus;holography;wireless-sensor-networks}, 
doi={10.1109/MC.2008.501}, 
ISSN={0018-9162}, 
month={Dec},}
@INPROCEEDINGS{5284078, 
author={B. Li and J. Li and J. Huai and T. Wo and Q. Li and L. Zhong}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={EnaCloud: An Energy-Saving Application Live Placement Approach for Cloud Computing Environments}, 
year={2009}, 
pages={17-24}, 
abstract={With the increasing prevalence of large scale cloud computing environments, how to place requested applications into available computing servers regarding to energy consumption has become an essential research problem, but existing application placement approaches are still not effective for live applications with dynamic characters. In this paper, we proposed a novel approach named EnaCloud, which enables application live placement dynamically with consideration of energy efficiency in a cloud platform. In EnaCloud, we use a Virtual Machine to encapsulate the application, which supports applications scheduling and live migration to minimize the number of running machines, so as to save energy. Specially, the application placement is abstracted as a bin packing problem, and an energy-aware heuristic algorithm is proposed to get an appropriate solution. In addition, an over-provision approach is presented to deal with the varying resource demands of applications. Our approach has been successfully implemented as useful components and fundamental services in the iVIC platform. Finally, we evaluate our approach by comprehensive experiments based on virtual machine monitor Xen and the results show that it is feasible.}, 
keywords={Internet;power aware computing;scheduling;virtual machines;EnaCloud;Internet;bin packing problem;cloud computing;energy consumption;energy-aware heuristic algorithm;energy-saving application live placement approach;over-provision approach;scheduling;virtual machine;Application software;Cloud computing;Energy consumption;Energy efficiency;Heuristic algorithms;Large-scale systems;Processor scheduling;Virtual machining;Virtual manufacturing;Voltage;Application Placement;Cloud Computing;Energy Saving;Live Migration;Virtual Machine}, 
doi={10.1109/CLOUD.2009.72}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5439441, 
author={A. K. Talukder and H. A. Prahalad}, 
booktitle={2009 IEEE International Conference on Internet Multimedia Services Architecture and Applications (IMSAA)}, 
title={Security #x00026; scalability architecture for next generation internet services}, 
year={2009}, 
pages={1-4}, 
abstract={Next Generation Internet Applications will experience many paradigm shifts from what we have seen so far. Through various technologies like applications mash-up, content aggregations, grid computing, cloud computing, Web 2.0, Web 3.0, applications will have to adopt novel software engineering techniques for development and deployment. Scalability, Interoperability, Availability (tolerance to failure), Accounting (journaling, billing), and Security (confidentiality, integrity, authentication, authorization), and Anonymity are some of the important quality and usability features that will determine the success of new Internet applications. This position paper proposes how these complex challenges can be managed.}, 
keywords={Internet;grid computing;innovation management;open systems;security of data;software engineering;Web 2.0;Web 3.0;accounting;anonymity;applications mash up;availability;cloud computing;content aggregations;grid computing;interoperability;next generation Internet services;scalability architecture;security architecture;software engineering techniques;Application software;Authentication;Authorization;Cloud computing;Computer architecture;Grid computing;Scalability;Security;Software engineering;Web and internet services;Cloud Computing;Next Generation Internet;Scalability and Security aware Software Development Life Cycle, SaSDLC;Security-aware}, 
doi={10.1109/IMSAA.2009.5439441}, 
month={Dec},}
@INPROCEEDINGS{5314089, 
author={L. Hu and M. Xiao}, 
booktitle={2009 IEEE AUTOTESTCON}, 
title={The future of automatic test system (ATS) brought by Cloud Computing}, 
year={2009}, 
pages={412-414}, 
abstract={Cloud Computing becomes important computing technology, such as Google, Micro Soft, IBM and Amazon. Cloud Computing is a kind of parallel computing spreading into Internet. The "Cloud" mainly represents the Web based on the TCP/IP protocol or protocols compatible with that. Cloud Computing expands the range of parallel computing into all of the computing devices connecting into the "Cloud". In "Cloud Computing" era, almost all of the data and operation capability will be distracted from the Automatic Test System (ATS), and run in the Web. The decreased demand for hardware could cut the budget and cost of ATS. At the same time, the cloud service will reform the measurement mode of test system, as well the modes of development and fault diagnostics.}, 
keywords={Web services;automatic testing;parallel processing;program diagnostics;transport protocols;Internet;TCP-IP protocol;automatic test system;cloud computing;cloud service;fault diagnostics;parallel computing;Automatic testing;Cloud computing;Computers;Concurrent computing;Internet;Joining processes;Parallel processing;Protocols;System testing;TCPIP;ATS;Cloud Computing;Diagnostics}, 
doi={10.1109/AUTEST.2009.5314089}, 
ISSN={1088-7725}, 
month={Sept},}
@INPROCEEDINGS{5350690, 
author={Y. S. Chen and J. W. Rau}, 
booktitle={2009 39th IEEE Frontiers in Education Conference}, 
title={Work in progress - digital school desk}, 
year={2009}, 
pages={1-2}, 
abstract={Combining embedded computer, touch panel, and cloud computing capability, a newly designed digital school desk (DSD) is presented to further build an advanced classroom or meeting room considering not only e-service but also interpersonal interaction. Based on a highlighted digital ink, the frontier work of our DSD designed is to make a paper-free but paper-like desk which is used close to human nature and can greatly improve educational quality, teachers-students-students interactions, as well as resource preservation and reusing. The core system of our DSD is a web-based portable virtual desk, which can be accessed anywhere and thus like a student's digital backpack. Our present work contributes a significant education unit, the DSD, to move a simply classroom presenter to a comprehensively future digital classroom.}, 
keywords={Internet;computer aided instruction;embedded systems;microcomputers;Web-based portable virtual desk;advanced classroom;cloud computing;digital backpack;digital school desk;e-service;educational quality;embedded computer;highlighted digital ink;interpersonal interaction;meeting room;resource preservation;teachers-students-students interaction;touch panel;Cloud computing;Education;Educational institutions;Embedded computing;Humans;Ink;Internet;Monitoring;Web server;Writing;Digital ink;Digital school desk;Traditional classroom;Web-based system}, 
doi={10.1109/FIE.2009.5350690}, 
ISSN={0190-5848}, 
month={Oct},}
@INPROCEEDINGS{4736878, 
author={C. Hoffa and G. Mehta and T. Freeman and E. Deelman and K. Keahey and B. Berriman and J. Good}, 
booktitle={2008 IEEE Fourth International Conference on eScience}, 
title={On the Use of Cloud Computing for Scientific Workflows}, 
year={2008}, 
pages={640-645}, 
abstract={This paper explores the use of cloud computing for scientific workflows, focusing on a widely used astronomy application-Montage. The approach is to evaluate from the point of view of a scientific workflow the tradeoffs between running in a local environment, if such is available, and running in a virtual environment via remote, wide-area network resource access. Our results show that for Montage, a workflow with short job runtimes, the virtual environment can provide good compute time performance but it can suffer from resource scheduling delays and widearea communications.}, 
keywords={astronomy computing;scheduling;scientific information systems;virtual reality;wide area networks;workflow management software;astronomy application-Montage;cloud computing;resource scheduling delays;scientific workflows;virtual environment;wide-area network resource access;widearea communications;Astronomy;Cloud computing;Costs;Grid computing;Internet;Laboratories;Power grids;Resource management;Runtime;Virtual environment;cloud computing;virtual machine;workflow}, 
doi={10.1109/eScience.2008.167}, 
month={Dec},}
@ARTICLE{4804041, 
author={G. Lin and D. Fu and J. Zhu and G. Dasmalchi}, 
journal={IT Professional}, 
title={Cloud Computing: IT as a Service}, 
year={2009}, 
volume={11}, 
number={2}, 
pages={10-13}, 
abstract={Industry panelists at an IEEE Computer Society conference in Beijing look at the opportunities and challenges emerging from cloud computing and how their companies are addressing them.}, 
keywords={grid computing;Beijing;IEEE Computer Society conference;cloud computing;Application software;Cloud computing;Computer industry;Costs;IP networks;Investments;Runtime environment;Software maintenance;Web and internet services;Web services;IT professional;cloud computing;data center;trends}, 
doi={10.1109/MITP.2009.22}, 
ISSN={1520-9202}, 
month={March},}
@INPROCEEDINGS{5289182, 
author={G. von Laszewski and L. Wang and A. J. Younge and X. He}, 
booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
title={Power-aware scheduling of virtual machines in DVFS-enabled clusters}, 
year={2009}, 
pages={1-10}, 
abstract={With the advent of Cloud computing, large-scale virtualized compute and data centers are becoming common in the computing industry. These distributed systems leverage commodity server hardware in mass quantity, similar in theory to many of the fastest Supercomputers in existence today. However these systems can consume a cities worth of power just to run idle, and require equally massive cooling systems to keep the servers within normal operating temperatures. This produces CO2 emissions and significantly contributes to the growing environmental issue of Global Warming. Green computing, a new trend for high-end computing, attempts to alleviate this problem by delivering both high performance and reduced power consumption, effectively maximizing total system efficiency. This paper focuses on scheduling virtual machines in a compute cluster to reduce power consumption via the technique of Dynamic Voltage Frequency Scaling (DVFS). Specifically, we present the design and implementation of an efficient scheduling algorithm to allocate virtual machines in a DVFS-enabled cluster by dynamically scaling the supplied voltages. The algorithm is studied via simulation and implementation in a multi-core cluster. Test results and performance discussion justify the design and implementation of the scheduling algorithm.}, 
keywords={microprocessor chips;power aware computing;processor scheduling;supervisory programs;virtual machines;workstation clusters;cloud computing;computer cluster;dynamic voltage frequency scaling;global warming;green computing;high-end computing;multicore cluster;power-aware scheduling;virtual machine;Algorithm design and analysis;Cloud computing;Dynamic voltage scaling;Energy consumption;High performance computing;Job shop scheduling;Large-scale systems;Processor scheduling;Scheduling algorithm;Virtual machining;Cluster Computing;Dynamic Voltage and Frequency Scaling;Scheduling;Virtual machine}, 
doi={10.1109/CLUSTR.2009.5289182}, 
ISSN={1552-5244}, 
month={Aug},}
@INPROCEEDINGS{5159203, 
author={S. Tai}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={Cloud Service Engineering}, 
year={2009}, 
pages={3-4}, 
abstract={Cloud computing is widely perceived as a disruptive technology that has the potential to fundamentally change the way services are built and delivered, and hence the way businesses operate. In this keynote, we argue for cloud service engineering as a discipline that takes a focused perspective on cloud computing and an integrative approach of technology and economics. We describe three aspects as open research challenges that require particular attention.}, 
keywords={Internet;cloud computing;cloud service engineering;integrative approach;Application software;Business;Cloud computing;Collaborative work;Computer architecture;Computer industry;Conferences;Costs;International collaboration;Middleware}, 
doi={10.1109/WETICE.2009.72}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{5318900, 
author={L. Li}, 
booktitle={2009 Third International Conference on Multimedia and Ubiquitous Engineering}, 
title={An Optimistic Differentiated Service Job Scheduling System for Cloud Computing Service Users and Providers}, 
year={2009}, 
pages={295-299}, 
abstract={Job scheduling system problem is a core and challenging issue in cloud computing. How to use cloud computing resources efficiently and gain the maximum profits with job scheduling system is one of the cloud computing service providers' ultimate goals. In this paper, firstly, by analysis the differentiated QoS requirements of cloud computing resources users' jobs, we build the corresponding non-preemptive priority M/G/1 queuing model for the jobs. Then, considering cloud computing service providers' destination which is to gain the maximum profits by offering cloud computing resources, we built the system cost function for this queuing model. After that, based on the queuing model and system cost function, considering the goals of both the cloud computing service users and providers, we gave the corresponding strategy and algorithm to get the approximate optimistic value of service for each job in the corresponding no-preemptive priority M/G/1 queuing model. Finally, we also provide corresponding simulations and numerical results. Analysis and number results show that our approach for job scheduling system can not only guarantee the QoS requirements of the users' jobs, but also can make the maximum profits for the cloud computing service providers.}, 
keywords={Web services;quality of service;queueing theory;scheduling;QoS requirement;cloud computing resource user job;cloud computing service provider;job scheduling system problem;maximum profit;no-preemptive priority M/G/1 queuing model;numerical result;optimistic differentiated service value;system cost function;Cloud computing;Computational modeling;Cost function;Dynamic scheduling;Environmental economics;Grid computing;Multimedia computing;Multimedia systems;Processor scheduling;Scheduling algorithm;Cloud Computing;Job scheduling system;Little's Law;QoS;queuing system}, 
doi={10.1109/MUE.2009.58}, 
month={June},}
@INPROCEEDINGS{5289187, 
author={J. Wilkening and A. Wilke and N. Desai and F. Meyer}, 
booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
title={Using clouds for metagenomics: A case study}, 
year={2009}, 
pages={1-6}, 
abstract={Cutting-edge sequencing systems produce data at a prodigious rate; and the analysis of these datasets requires significant computing resources. Cloud computing provides a tantalizing possibility for on-demand access to computing resources. However, many open questions remain. We present here a performance assessment of BLAST on real metagenomics data in a cloud setting in order to determine the viability of this approach. BLAST is one of the premier applications in bioinformatics and computational biology and is assumed to consume the vast majority of resources in that area.}, 
keywords={bioinformatics;genomics;information networks;BLAST performance assessment;approach viability;bioinformatics application;cloud computing;computational biology;computing resource;metagenomics data;on-demand access;sequencing system;Bioinformatics;Biology computing;Cloud computing;Costs;DNA;Data analysis;Genomics;Laboratories;Organisms;Sequences}, 
doi={10.1109/CLUSTR.2009.5289187}, 
ISSN={1552-5244}, 
month={Aug},}
@INPROCEEDINGS{5283862, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics dealt in the 2009 IEEE International Conference on Cloud Computing are related to: service cloud and other cloud applications; DSP re-encryption; deployment of service in a cloud subject to memory and license constraints; application performance isolation in virtualization; optimistic synchronisation of parallel simulation in cloud computing environments; customer centric cloud service model and a case study on commerce as a service; intelligent management of remote facilities through a ubiquitous cloud middleware; resource management system for online virtual cluster provision; SOA's last mile-connecting smartphones to the service cloud; and satellite data processing on high end compute clusters. On the application and industry track, topics are dealt with; the method and tool of cost analysis for cloud computing; an end-to-end methodology and toolkit for fine granularity SaaS-ization; on technical security issue in cloud computing; etc; etc. On work in progress track, topic are dealt with; policy based event driven services-oriented architecture for cloud services operation and management; a RESTful approach to the management of cloud infrastructure; service oriented architecture for cloud based travel reservation software as a service; etc; etc. The paper also includes the discussion in CS&BI workshop and SQAM workshop.}, 
keywords={Web services;CS&BI workshop;DSP re-encryption;SQAM workshop;application performance isolation;cloud based travel reservation software;cloud computing environment;cloud service management;cloud service operation;cost analysis;customer centric cloud service model;end-to-end methodology;granularity SaaS-ization;industry track;intelligent management;license constraint;memory constraint;online virtual cluster provision;optimistic synchronisation;parallel simulation;policy based event driven services-oriented architecture;remote facility;resource management system;satellite data processing;service cloud application;service oriented architecture;technical security issue;ubiquitous cloud middleware;virtualization}, 
doi={10.1109/CLOUD.2009.44}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5380440, 
author={W. Tian}, 
booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
title={Adaptive Dimensioning of Cloud Data Centers}, 
year={2009}, 
pages={5-10}, 
abstract={Cloud data centers (CDCs) provide key infrastructure for cloud computing. Allocating computing resources is very important for the CDCs to function efficiently. Current allocation of resources in CDCs is mostly dedicated and static. However, workloads for cloud applications are highly variable which cause poor application performance, poor resource utilization or both. In this paper, adaptive dimensioning methods for CDCs are developed so that right amount of computing resources are allocated for variable workloads to meet quality of service requirements.}, 
keywords={Internet;computer centres;quality of service;resource allocation;adaptive dimensioning method;cloud computing;cloud data centers;computing resource allocation;quality of service requirements;Cloud computing;Computer architecture;Computer science;Europe;Hardware;Network servers;North America;Resource management;Switches;Web server;Adaptive Dimensioning Methods;Cloud Data Centers (CDCs);Cloud computing}, 
doi={10.1109/DASC.2009.58}, 
month={Dec},}
@INPROCEEDINGS{5071977, 
author={A. F. Mohammad}, 
booktitle={2009 Third Asia International Conference on Modelling Simulation}, 
title={An Achievable Service-Oriented Architecture ASOA}, 
year={2009}, 
pages={164-169}, 
abstract={This paper presents a new novel approach as achievable service-oriented architecture (ldquoASOArdquo). This approach introduces strategic steps to implementation of information systems and technology, which are flexible and robust. There is a scarcity of research substantiation of Quality of Service of SOA and acceptance and implementation of SOA across our current industrial landscape. The adoption of ASOA bridges this research gap in cloud computing and enhances performance of legacy systems, by combining both available and newly designed consumer interfaces using the latest technologies. The best use of available legacy applications in ASOA methodology can generate much better performance of electronics as well as improving the physical supply chain of products to consumers and sales partners. This paper also discusses how business and information systems managers can take advantage of ASOA.}, 
keywords={business data processing;information management;information systems;quality of service;software architecture;software maintenance;QoS;achievable service-oriented architecture;business manager;cloud computing;consumer interface;information system manager;legacy system;Bridges;Cloud computing;Information management;Information systems;Management information systems;Marketing and sales;Quality of service;Robustness;Service oriented architecture;Supply chains;Documentation Process;Legacy System;SOA;Software Reengineering}, 
doi={10.1109/AMS.2009.35}, 
ISSN={2376-1164}, 
month={May},}
@INPROCEEDINGS{5446227, 
author={V. Nae and R. Prodan and T. Fahringer and A. Iosup}, 
booktitle={2009 8th Annual Workshop on Network and Systems Support for Games (NetGames)}, 
title={The impact of virtualization on the performance of Massively Multiplayer Online Games}, 
year={2009}, 
pages={1-6}, 
abstract={Today's highly successful Massively Multiplayer Online Games (MMOGs) have millions of registered users and hundreds of thousands of active concurrent users. As a result of the highly dynamic MMOG usage patterns, the MMOG operators pre-provision and then maintain throughout the lifetime of the game tens of thousands of compute resources in data centers located across the world. Until recently, the difficulty of porting the MMOG software services to different platforms made it impractical to dynamically provision resources external to the MMOG operators' data centers. However, virtualization is a new technology that promises to alleviate this problem by providing a uniform computing platform with minimal overhead. To investigate the potential of this new technology, in this paper we propose a new hybrid resource provisioning model that uses a smaller and less expensive set of self-owned data centers, complemented by virtualized cloud computing resources during peak hours. Using real traces from RuneScape, one of the most successful contemporary MMOGs, we evaluate with simulations the effectiveness of the on-demand cloud resource provisioning strategy for MMOGs. We assess the impact of provisioning of virtualized cloud resources, analyze the components of virtualization overhead, and compare provisioning of virtualized resources with direct provisioning of data center resources.}, 
keywords={computer games;virtual reality;MMOG software services;RuneScape;data center resources;massively multiplayer online games;resource provisioning model;uniform computing platform;virtualization impact;virtualized cloud resources;Cloud computing;Computational modeling;Computer science;Ecosystems;Large-scale systems;Physics computing;Platform virtualization;Quality of service;Resource management;Resource virtualization}, 
doi={10.1109/NETGAMES.2009.5446227}, 
ISSN={2156-8138}, 
month={Nov},}
@INPROCEEDINGS{4756640, 
author={Y. Xiao and Y. Tao and Q. Li}, 
booktitle={2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application}, 
title={A New Wireless Web Access Mode Based on Cloud Computing}, 
year={2008}, 
volume={1}, 
pages={645-649}, 
abstract={As most Websites are designed for desktop PCs, it is extremely uncomfortable to browse these large pages on a wireless handheld device with small screen and limited user interface. So it is necessary to adapt these web pages to small screen devices. Besides, as the limited computing ability and capacity of storage of wireless handheld devices, it is also extremely challenging to deploy existing Web page adaptation engine. By referring to huge computing ability and storage resource of cloud computing infrastructure, a new wireless web access mode is proposed. Firstly, the system framework is present. Subsequently, the two key components of system are described in detail: the one is distributed Web page adaptation engine, which is designed for the purpose that the engine can be carried by computing cloud distributed and parallel; the other is distributed Web page blocks management based on cloud computing, which is proposed so that the Web page adaptation engine can be deployed reasonably. Moreover, a prototype system and a set of evaluation experiments have been implemented.}, 
keywords={Web sites;distributed processing;peer-to-peer computing;Web page adaptation engine;Web sites;cloud computing;distributed Web page blocks management;wireless Web access mode;Cloud computing;Concurrent computing;Distributed computing;Engines;Handheld computers;Personal communication networks;Prototypes;User interfaces;Web page design;Web pages}, 
doi={10.1109/PACIIA.2008.18}, 
month={Dec},}
@INPROCEEDINGS{4641466, 
author={N. Ilyadis}, 
booktitle={2008 IEEE International SOC Conference}, 
title={ #x201C;SOC challenges in the terabit networks era #x201D;}, 
year={2008}, 
pages={3-3}, 
abstract={The worldwide appetite for Internet connectivity and bandwidth continues to grow as the delivery of data, voice and video expands to every corner of the globe. This demand, combined with transformations in computing models centered on cloud computing and thin clients, is driving the need for greater bandwidth and low latency in next-generation networks. Broadband connectivity serves as the ubiquitous mode of network access for an ever expanding number of both consumer and business users and, as such, the aggregate capacity of the underlying network now demands terabit-based infrastructure equipment. This talk will focus on the significant bandwidth drivers in today’s networks, along with the challenges inherent in creating SoC designs that enable network infrastructure equipment.}, 
keywords={Bandwidth;Cloud computing;Computer networks;Data engineering;Data security;Ethernet networks;Internet;Physical layer;Portfolios;Wireless LAN}, 
doi={10.1109/SOCC.2008.4641466}, 
ISSN={2164-1676}, 
month={Sept},}
@ARTICLE{5280645, 
author={D. Geer}, 
journal={Computer}, 
title={The OS Faces a Brave New World}, 
year={2009}, 
volume={42}, 
number={10}, 
pages={15-17}, 
abstract={Increasingly popular approaches such as virtualization, cloud computing, and application development frameworks are changing the importance of the traditional operating system. Virtualization lets a single server host slices of multiple operating systems, each of which can run different applications within virtual machines. This makes the installation of any single full-featured OS instance a choice rather than a necessity. Cloud computing features applications that run on servers spread across the Internet. Cloud providers push these applications to users' browsers. Users of cloud based software thus don't need an OS to do more than run the browser. Developers are increasingly using frameworks that enable the faster building of applications that work with multiple OSs, again making the use of a specific operating system less important. The just enough operating system (JeOS, pronounced "juice") movement focuses on packaging an application with only the parts of an OS necessary for it to work. Over time, these developments could affect what constitutes an operating system, what its roles and responsibilities will be, and how it will be installed and used.}, 
keywords={Internet;operating systems (computers);virtual machines;Internet browser;JeOS term;application development framework;cloud based software;cloud computing;just enough operating system;operating system;server host;virtual machine;virtualization;Application software;Application virtualization;Cloud computing;Internet;Operating systems;Packaging;Virtual machining;Web server;Application development framework;Cloud computing;JeOS;Operating systems;Virtualization}, 
doi={10.1109/MC.2009.333}, 
ISSN={0018-9162}, 
month={Oct},}
@INPROCEEDINGS{5136797, 
author={S. W. Neville and K. F. Li}, 
booktitle={2009 International Conference on Advanced Information Networking and Applications Workshops}, 
title={The Rational for Developing Larger-scale 1000+ Machine Emulation-Based Research Test Beds}, 
year={2009}, 
pages={1092-1099}, 
abstract={This position paper outlines the need and rational for developing large-scale emulation facilities structured to allow the scientific method tenets to be met on a per experiment basis. The work specifically focuses on the need to develop emulation-based test beds on the 1000+ machine scale, as expressed within the U.S. Defense Advanced Research Program Agency's (DARPA) BAA-08-43 Broad Agency Announcement of May 2008 for a National Cyber Range, the University of Victoria's Fall 2008 application to the Canadian Foundation for Innovation for a Canadian at-scale Emulation Laboratory (CASElab), and the recent HP-Intel-Yahoo global cloud computing test bed initiative. The work places these proposed large-scale facilities both within the general context of the standard research tools (i.e., analytical analysis, simulation studies, ad hoc testing, and smaller-scale emulation), as their placement against other available test beds, most notably Emulab, DETERlab, and PlanetLab.}, 
keywords={Internet;large-scale systems;program testing;test facilities;BAA-08-43 Broad Agency;Canadian Foundation for Innovation;Canadian at-scale Emulation Laboratory;HP-Intel-Yahoo global cloud computing test bed initiative;National Cyber Range;U.S. Defense Advanced Research Program Agency;University of Victoria;ad hoc testing;analytical analysis;larger-scale 1000+ machine emulation;simulation studies;smaller-scale emulation;Analytical models;Cloud computing;Computational modeling;Context modeling;Emulation;IEEE news;Laboratories;Large-scale systems;Technological innovation;Testing;at-scale emulation;distributed test bed;large-scale computing systems;real-world applications}, 
doi={10.1109/WAINA.2009.183}, 
month={May},}
@INPROCEEDINGS{5408002, 
author={G. Juve and E. Deelman and K. Vahi and G. Mehta and B. Berriman and B. P. Berman and P. Maechling}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Scientific workflow applications on Amazon EC2}, 
year={2009}, 
pages={59-66}, 
abstract={The proliferation of commercial cloud computing providers has generated significant interest in the scientific computing community. Much recent research has attempted to determine the benefits and drawbacks of cloud computing for scientific applications. Although clouds have many attractive features, such as virtualization, on-demand provisioning, and Â¿pay as you goÂ¿ usage-based pricing, it is not clear whether they are able to deliver the performance required for scientific applications at a reasonable price. In this paper we examine the performance and cost of clouds from the perspective of scientific workflow applications. We use three characteristic workflows to compare the performance of a commercial cloud with that of a typical HPC system, and we analyze the various costs associated with running those workflows in the cloud. We find that the performance of clouds is not unreasonable given the hardware resources provided, and that performance comparable to HPC systems can be achieved given similar resources. We also find that the cost of running workflows on a commercial cloud can be reduced by storing data in the cloud rather than transferring it from outside.}, 
keywords={Internet;ubiquitous computing;Amazon EC2;HPC system;commercial cloud computing;scientific workflow application;Application software;Application virtualization;Cloud computing;Costs;Grid computing;Open source software;Performance analysis;Processor scheduling;Resource management;Scientific computing}, 
doi={10.1109/ESCIW.2009.5408002}, 
month={Dec},}
@INPROCEEDINGS{5405670, 
author={C. Hur and H. Yoo and S. Kim and Y. Kim}, 
booktitle={Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications}, 
title={Resource Management Using Virtual Ontologies for Scientific Applications}, 
year={2009}, 
pages={1-4}, 
abstract={Cloud computing has recently paid attention as a way to share the resources to provide scalable and on-demand services. Across various authorities, cloud resources should be configured to a virtual organization (VO) according to user's requirements. Ontology-based representation of cloud computing environment would be able to conceptualize common attributes among cloud resources and to represent semantic relations among them. However, mutual compatibility among different VOs is limited because a method applying ontology to cloud is in progress. We propose to introduce a resource virtualization method using virtual ontology. A new virtual ontology (VOn) is configured dynamically based on requirement of users, and the VOn is mapped to actual cloud resources. Our service uses a map/reduce model for rapid and efficient merging a number of ontology. The execution environment is orchestrated with selected resources mapped to the VOn, which is generated by ontology merge engine.}, 
keywords={Internet;ontologies (artificial intelligence);virtual reality;cloud computing;map-reduce model;on-demand services;ontology merge engine;ontology-based representation;resource management;resource virtualization method;virtual ontologies;virtual organization;Application software;Cloud computing;Computer science;Engines;Environmental management;Merging;Ontologies;Processor scheduling;Resource management;Resource virtualization}, 
doi={10.1109/ICUT.2009.5405670}, 
ISSN={1976-0035}, 
month={Dec},}
@INPROCEEDINGS{4780656, 
author={G. Giunta and G. Laccetti and R. Montella}, 
booktitle={2008 IEEE Asia-Pacific Services Computing Conference}, 
title={Five Dimension Environmental Data Resource Brokering on Computational Grids and Scientific Clouds}, 
year={2008}, 
pages={81-88}, 
abstract={In this paper we describe how the grid computing resource brokering approach, classically divided into matchmaking discovery and optimize selection, is applied to five dimensional environmental data distribution. This result is achieved thanks to the integration of a resource broker service we developed from scratch. This service implements the key feature of autonomic mapping of Globus toolkit index service resources on the Condor ClassAd resource description. Our five dimensional distribution data service relays on this software infrastructure to advertise metadata and it provides the requested data leveraging on the Web service resource framework. We provide an example based on a grid aware application component, showing the application of resource brokering to environmental problems. We focused our interests mainly about high resolution weather forecast data management and results quality assessment. Our approach would be both modular and distributed computing technology aware in order to provide the e-science community of grid based cloud computing enabled tools fully benefiting of this technology.}, 
keywords={Web services;environmental science computing;grid computing;resource allocation;Condor ClassAd resource description;Globus toolkit index service resource;Web service resource framework;autonomic mapping;computational grid;distributed computing technology;e-science community;environmental data resource brokering;five-dimensional distribution data service;grid aware application component;grid based cloud computing;grid computing resource brokering approach;high-resolution weather forecast data management;matchmaking discovery;quality assessment;scientific cloud computing;service selection optimization;software infrastructure;Application software;Cloud computing;Distributed computing;Environmental factors;Frame relay;Grid computing;Quality assessment;Quality management;Weather forecasting;Web services;Cloud Computing;Environmental Data Distribution;Grid Computing;Resource Broking;Weather Model Evaluation}, 
doi={10.1109/APSCC.2008.201}, 
month={Dec},}
@INPROCEEDINGS{5071865, 
author={T. Dörnemann and E. Juhnke and B. Freisleben}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={On-Demand Resource Provisioning for BPEL Workflows Using Amazon's Elastic Compute Cloud}, 
year={2009}, 
pages={140-147}, 
abstract={BPEL is the de facto standard for business process modeling in today's enterprises and is a promising candidate for the integration of business and Grid applications. Current BPEL implementations do not provide mechanisms to schedule service calls with respect to the load of the target hosts. In this paper, a solution that automatically schedules workflow steps to underutilized hosts and provides new hosts using Cloud computing infrastructures in peak-load situations is presented. The proposed approach does not require any changes to the BPEL standard. An implementation based on the ActiveBPEL engine and Amazon's Elastic Compute Cloud is presented.}, 
keywords={Web services;business data processing;grid computing;scheduling;workflow management software;Amazon elastic compute cloud;BPEL workflow scheduling;Web service;business process modeling;cloud computing;enterprises business integration;grid application;on-demand resource provisioning;service-oriented architectures;Cloud computing;Computer science;Engines;Grid computing;Mathematics;Paramagnetic resonance;Processor scheduling;Runtime;Service oriented architecture;Web services;BPEL;Cloud Computing;Load Balancing;Provisioning;Reliability;Scheduling;Workflow}, 
doi={10.1109/CCGRID.2009.30}, 
month={May},}
@ARTICLE{5280121, 
author={B. Michael}, 
journal={IEEE Security Privacy}, 
title={In Clouds Shall We Trust?}, 
year={2009}, 
volume={7}, 
number={5}, 
pages={3-3}, 
abstract={Cloud computing will become ubiquitous, but what we can do to improve our ability to provide users and providers of cloud computing with trust in the software services and infrastructure that make up the cloud. In this article we touch on issues of the transparency, changing expectations and uses, architecture, and amorphous nature of cloud computing.}, 
keywords={Amorphous materials;Cloud computing;Computer architecture;Cloud computing;privacy;security;trust}, 
doi={10.1109/MSP.2009.124}, 
ISSN={1540-7993}, 
month={Sept},}
@INPROCEEDINGS{5279502, 
booktitle={2009 Eighth International Conference on Grid and Cooperative Computing}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: grid computing; QoS; service computing; resource management; computer-supported cooperative work; cloud computing; middleware and disaster recovery.}, 
keywords={grid computing;groupware;middleware;resource allocation;QoS;cloud computing;computer-supported cooperative work;disaster recovery;grid computing;middleware;resource management;service computing}, 
doi={10.1109/GCC.2009.1}, 
ISSN={2160-4908}, 
month={Aug},}
@INPROCEEDINGS{5306780, 
author={Shu Xu and Bo Huang and Junyong Ding and Jinquan Dai}, 
booktitle={2009 IEEE International Symposium on Workload Characterization (IISWC)}, 
title={Browser workload characterization for an Ajax-based commercial online service}, 
year={2009}, 
pages={208-216}, 
abstract={The transition to cloud computing and SaaS is a disruptive trend where users can conveniently access the services through browsers at any clients. In addition, with the prevalence of Web 2.0 and AJAX techniques, a browser-based client can have complex application logic and fancy user interface that are comparable to traditional desktop applications. This paper reports the study of workload construction and characterization for browser-based clients, using the Ajax-based Web client of Zimbra (a commercial online messaging and collaboration suite). By comparing the various workload behaviors across different Zimbra server datasets, different browsers and different client platforms, it presents the characteristics of a real-life Web application, which has significant differences from existing browser benchmarks in the literature. In addition, the platform-independent and browser-independent design of our workload makes it portable across various clients. Finally, this paper also provides valuable insights to the browser internals by analyzing the workload execution, the browser memory footprint and the breakdown of browser sub-modules.}, 
keywords={Web services;XML;online front-ends;user interfaces;AJAX technique;Web 2.0;Zimbra;application logic;browser memory footprint;browser submodule breakdown;browser workload characterization;browser-based client;browser-independent design;cloud computing;commercial online service;disruptive trend;fancy user interface;platform-independent design;Application software;Cloud computing;Collaborative work;Internet;Java;Logic;Network servers;Search engines;User interfaces;Zero current switching}, 
doi={10.1109/IISWC.2009.5306780}, 
month={Oct},}
@INPROCEEDINGS{5166969, 
author={D. K. Hwang}, 
booktitle={2009 11th IEEE International Conference on High Performance Computing and Communications}, 
title={Keynote: Virtual Clusters for Grid, Cloud, and High-performance Computing}, 
year={2009}, 
pages={xxxvi-xxxvi}, 
abstract={In this talk, the impact of cloud computing and emerging Internet applications will be accessed. A virtual-machine approach to cluster partitioning and mechanisms for replicated data protection will be presented. These techniques enable dynamic cloud resource provisioning and secure data management in web-scale distributed computing and business applications. The talk covers the impact of virtualization on grid, cloud, and high-performance computing platforms. He will discuss research frontiers in building virtualized grid/cloud infrastructures and assessing some grid/cloud projects at USA, France, Japan, and China, that explore distributed server clusters and globally deployed data-centers.}, 
keywords={Internet;grid computing;security of data;virtual machines;Internet applications;Web-scale distributed computing;cloud computing;cloud resource provisioning;cluster partitioning;high-performance computing;replicated data protection;secure data management;virtual clusters;virtual machine;web-scale distributed computing;Application software;Cloud computing;Computer science;Distributed computing;Grid computing;Internet;Laboratories;Platform virtualization;Protection;Resource management}, 
doi={10.1109/HPCC.2009.106}, 
month={June},}
@INPROCEEDINGS{5332012, 
author={H. y. Paik and K. M. Goschka and A. Van Moorsel and R. Wong and I. Warren}, 
booktitle={2009 13th Enterprise Distributed Object Computing Conference Workshops}, 
title={Introduction to the proceedings of the EDOC 2009 workshop Middleware for Web Services (MWS) 2009}, 
year={2009}, 
pages={72-73}, 
abstract={The fifth Middleware for Web Services (MWS) workshop in 2009 is being held at the EDOC 2009 conference in Auckland, New Zealand. The workshop aims to bring together practitioners and academic researchers interested in the advancement of Web services and middleware technologies. This year, the five selected papers represent the new role and challenges middleware and Web services are faced with in light of a rapidly evolving environment which now includes cloud computing, virtualisation and mobile sensors.}, 
keywords={cloud computing;middleware;service architecture;service-oriented computing;web services}, 
doi={10.1109/EDOCW.2009.5332012}, 
ISSN={2325-6583}, 
month={Sept},}
@INPROCEEDINGS{5071533, 
author={C. Ragusa and F. Longo and A. Puliafito}, 
booktitle={2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing}, 
title={Experiencing with the Cloud over gLite}, 
year={2009}, 
pages={53-60}, 
abstract={Market competitiveness puts enormous pressures over companies to be agile in providing their offers and adapt to fast changes. In such context, resource dimensioning is an hard and risky task which may lead companies to underprovision their data-center, and therefore be unable to cope with peak loads, or to overprovision it, and not fullfill their ROI. Cloud computing ought to provide such ability. In a previous work, we presented our solution for multi-tier Web-based application hosting over a gLite based infrastructure. In this paper, we present a further development of our system towards the Cloud model. A scenario describing our system in action is also discussed.}, 
keywords={Internet;business data processing;computer centres;Cloud model;cloud computing;data center;gLite;market competitiveness;resource dimensioning;Business;Cloud computing;Companies;Costs;Investments;Resource management;Resource virtualization;Service oriented architecture;Virtual machining;Virtual manufacturing}, 
doi={10.1109/CLOUD.2009.5071533}, 
month={May},}
@INPROCEEDINGS{5159214, 
author={R. Mikkilineni and V. Sarathy}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={Cloud Computing and the Lessons from the Past}, 
year={2009}, 
pages={57-62}, 
abstract={The skyrocketing demand for a new generation of cloud-based consumer and business applications is driving the need for next generation of data centers that must be massively scalable, efficient, agile, reliable and secure. The authors see a parallel between the state of the data centers today and the evolution of the Intelligent Network (IN) infrastructure in telecommunication. The telecommunications networks have for many years, demonstrated their ability to reliably enable network (voice) services creation, assurance and delivery on a massive scale. Based on an analysis of the Intelligent Networks in telecommunications to identify proven concepts and key lessons that can be applied to enable next generation IT datacenters experience this paper asserts that: (1) In order to scale cloud services reliably to millions of service developers and billions of end users the next generation cloud computing and datacenter infrastructure will have to follow an evolution similar to the one that led to the creation of scalable telecommunication networks. (2) In the future network-based cloud service providers will leverage virtualization technologies to be able to allocate just the right levels of virtualized compute, network and storage resources to individual applications based on real-time business demand while also providing full service level assurance of availability, performance and security at a reasonable cost. (3) A key component - identified in this paper as the Virtual Resource Mediation Layer (VRML), must be developed through industry collaboration to enable interoperability of various public and private clouds. This layer will form the basis for ensuring massive scalability of cloud infrastructure by enabling distributed service creation, service delivery and service assurance without any single vendor domination. (4) The next generation virtualization technologies must allow applications to dynamically access CPU, memory, bandwidth and storage (capacity, I/O and - throughput) in a manner similar to that of the telecommunications 800 Service Call Model with one level of indirection and mediation. The authors believe that the next generation cloud evolution is a fundamental transformation - and not just an evolutionary stack of XaaS implementations, which will enable global service collaboration networks utilizing optimally distributed and managed computing, network and storage resources driven in real-time by business priorities.}, 
keywords={Internet;computer centres;electronic commerce;intelligent networks;open systems;business applications;cloud computing;cloud-based consumer;data centers;distributed service creation;intelligent network infrastructure;interoperability;private clouds;public clouds;service assurance;service delivery;virtual resource mediation layer;virtualization;Application virtualization;Cloud computing;Computer networks;Intelligent networks;Mediation;Next generation networking;Resource management;Resource virtualization;Telecommunication computing;Telecommunication network reliability;Cloud Computing;Service Collaboration Network;xAAS}, 
doi={10.1109/WETICE.2009.14}, 
ISSN={1524-4547}, 
month={June},}
@ARTICLE{5076315, 
author={F. Sullivan}, 
journal={Computing in Science Engineering}, 
title={Guest Editor's Introduction: Cloud Computing for the Sciences}, 
year={2009}, 
volume={11}, 
number={4}, 
pages={10-11}, 
abstract={The guest editor of this special issue on cloud computing defines the term and describes the articles highlighted.}, 
keywords={Application software;Bandwidth;Centralized control;Cloud computing;Costs;Data security;Distributed computing;Scientific computing;Web and internet services;Wikipedia;Cloud computing;computer science;scientific computing}, 
doi={10.1109/MCSE.2009.121}, 
ISSN={1521-9615}, 
month={July},}
@ARTICLE{5268002, 
author={S. Cherry}, 
journal={IEEE Spectrum}, 
title={Forecast for Cloud Computing: Up, Up, and Away}, 
year={2009}, 
volume={46}, 
number={10}, 
pages={68-68}, 
abstract={The forecast for cloud computing is sky-high.}, 
keywords={Application software;Cellular phones;Cloud computing;Collaborative tools;Internet;Lead;Marketing and sales;Mobile computing;Streaming media;Utility programs}, 
doi={10.1109/MSPEC.2009.5268002}, 
ISSN={0018-9235}, 
month={Oct},}
@INPROCEEDINGS{4777906, 
author={Yunhong Gu and R. Grossman}, 
booktitle={2008 Workshop on Many-Task Computing on Grids and Supercomputers}, 
title={Exploring data parallelism and locality in wide area networks}, 
year={2008}, 
pages={1-10}, 
abstract={Cloud computing has demonstrated that processing very large datasets over commodity clusters can be done simply given the right programming structure. Work to date, for example MapReduce and Hadoop, has focused on systems within a data center. In this paper, we present Sphere, a cloud computing system that targets distributed data-intensive applications over wide area networks. Sphere uses a data-parallel computing model that views the processing of distributed datasets as applying a group of operators to each element in the datasets. As a cloud computing system, application developers can use the Sphere API to write very simple code to process distributed datasets in parallel, while the details, including but not limited to, data locations, server heterogeneity, load balancing, and fault tolerance, are transparent to developers. Unlike MapReduce or Hadoop, Sphere supports distributed data processing on a global scale by exploiting data parallelism and locality in systems over wide area networks.}, 
keywords={application program interfaces;data handling;distributed processing;software fault tolerance;wide area networks;Hadoop;MapReduce;Sphere API;cloud computing system;data center;data locality;data locations;data-parallel computing model;distributed data-intensive applications;fault tolerance;load balancing;server heterogeneity;very large datasets;wide area networks;Astronomy;Cloud computing;Computer interfaces;Concurrent computing;Data processing;Distributed computing;Load management;Parallel processing;Pervasive computing;Wide area networks}, 
doi={10.1109/MTAGS.2008.4777906}, 
ISSN={2151-1683}, 
month={Nov},}
@INPROCEEDINGS{5413073, 
author={Jian Wang and Yan Zhao and Shuo Jiang and Jiajin Le}, 
booktitle={2009 International Conference on Test and Measurement}, 
title={Providing privacy preserving in cloud computing}, 
year={2009}, 
volume={2}, 
pages={213-216}, 
abstract={People can only enjoy the full benefits of Cloud computing if we can address the very real privacy and security concerns that come along with storing sensitive personal information in databases and software scattered around the Internet. There are many service provider in the internet, we can call each service as a cloud, each cloud service will exchange data with other cloud, so when the data is exchanged between the clouds, there exist the problem of disclosure of privacy. So the privacy disclosure problem about individual or company is inevitably exposed when releasing or sharing data in the cloud service. Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. Our paper provides some privacy preserving technologies used in cloud computing services.}, 
keywords={Internet;data privacy;Internet;cloud computing;cloud service;privacy disclosure problem;privacy preserving technologies;Cloud computing;Data privacy;Data security;Databases;Information security;Law;Legal factors;Paper technology;Scattering;Web and internet services;cloud computing;network;privacy preserving}, 
doi={10.1109/ICTM.2009.5413073}, 
ISSN={2157-5592}, 
month={Dec},}
@INPROCEEDINGS{5284132, 
author={C. H. Yun and H. Han and H. S. Jung and H. Y. Yeom and Y. W. Lee}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={Intelligent Management of Remote Facilities through a Ubiquitous Cloud Middleware}, 
year={2009}, 
pages={65-71}, 
abstract={This paper introduces a tele-management system as a part of SmartUM which is a ubiquitous cloud middleware for ubiquitous city (u-city). The cloud computing platform allows users to control remote devices. The users get data from a various kinds of remote sensors and scene images about the place of sensors from remote video cameras and control remote devices seeing the scene images of the remote place. Our cloud computing platform has context-awareness and can intelligently control the remote devices according to the circumstance scenario. We used ontology for the context aware intelligence processing.}, 
keywords={Internet;image sensors;middleware;ontologies (artificial intelligence);ubiquitous computing;cloud computing platform;context aware intelligence processing;image sensor;intelligent remote facility management;ontology;remote video camera;tele-management system;u-city;ubiquitous city;ubiquitous cloud middleware;Cameras;Cities and towns;Cloud computing;Image sensors;Intelligent control;Intelligent sensors;Layout;Middleware;Ontologies;Remote sensing}, 
doi={10.1109/CLOUD.2009.88}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5454600, 
author={Q. Li and Q. Hao and L. Xiao and Z. Li}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Adaptive Management of Virtualized Resources in Cloud Computing Using Feedback Control}, 
year={2009}, 
pages={99-102}, 
abstract={Cloud computing as newly emergent computing environment offers dynamic flexible infrastructures and QoS guaranteed services in pay-as-you-go manner to the public. System virtualization technology which renders flexible and scalable system services is the base of the cloud computing. How to provide a self-managing and autonomic infrastructure for cloud computing through virtualization becomes an important challenge. In this paper, using feedback control theory, we present VM-based architecture for adaptive management of virtualized resources in cloud computing and model an adaptive controller that dynamically adjusts multiple virtualized resources utilization to achieve application Service Level Objective (SLO) in cloud computing. Compared with Xen, KVM is chosen as a virtual machine monitor (VMM) to implement the architecture. Evaluation of the proposed controller model showed that the model could allocate resources reasonably in response to the dynamically changing resource requirements of different applications which execute on different VMs in the virtual resource pool to achieve applications SLOs.}, 
keywords={Internet;feedback;resource allocation;software architecture;virtual machines;QoS guaranteed service;VM-based architecture;adaptive controller;adaptive management;autonomic infrastructure;cloud computing;controller model;dynamic flexible infrastructure;feedback control;pay-as-you-go manner;resource allocation;self-managing infrastructure;service level objective;system virtualization;virtual machine monitor;virtual resource pool;virtualized resources;Adaptive control;Application virtualization;Cloud computing;Computer architecture;Feedback control;Programmable control;Resource management;Resource virtualization;Virtual machine monitors;Voice mail}, 
doi={10.1109/ICISE.2009.211}, 
ISSN={2160-1283}, 
month={Dec},}
@ARTICLE{4620087, 
author={D. Milojicic}, 
journal={IEEE Internet Computing}, 
title={Cloud Computing: Interview with Russ Daniels and Franco Travostino}, 
year={2008}, 
volume={12}, 
number={5}, 
pages={7-9}, 
abstract={Milojicić discusses cloud computing with Russ Daniels, Vice President and Chief Technology Officer of Hewlett-Packard’s cloud services strategy, and Franco Travostino, a distinguished architect at eBay.}, 
keywords={Access protocols;Cloud computing;Context-aware services;Credit cards;Distributed computing;Explosives;Grid computing;Internet;Interviews;Portals;Franco Travostino;Russ Daniels;SaaS;Software as a Service;cloud computing;distributed computing}, 
doi={10.1109/MIC.2008.97}, 
ISSN={1089-7801}, 
month={Sept},}
@ARTICLE{5233607, 
author={M. D. Dikaiakos and D. Katsaros and P. Mehra and G. Pallis and A. Vakali}, 
journal={IEEE Internet Computing}, 
title={Cloud Computing: Distributed Internet Computing for IT and Scientific Research}, 
year={2009}, 
volume={13}, 
number={5}, 
pages={10-13}, 
abstract={Cloud computing is a disruptive technology with profound implications not only for Internet services but also for the IT sector as a whole. Its emergence promises to streamline the on-demand provisioning of software, hardware, and data as a service, achieving economies of scale in IT solutions' deployment and operation. This issue's articles tackle topics including architecture and management of cloud computing infrastructures, SaaS and IaaS applications, discovery of services and data in cloud computing infrastructures, and cross-platform interoperability. Still, several outstanding issues exist, particularly related to SLAs, security and privacy, and power efficiency. Other open issues include ownership, data transfer bottlenecks, performance unpredictability, reliability, and software licensing issues. Finally, hosted applications' business models must show a clear pathway to monetizing cloud computing. Several companies have already built Internet consumer services such as search, social networking, Web email, and online commerce that use cloud computing infrastructure. Above all, cloud computing's still unknown "killer application" will determine many of the challenges and the solutions we must develop to make this technology work in practice.}, 
keywords={Internet;electronic commerce;open systems;IT sector;Web email;business model;cloud computing;consumer services;cross-platform interoperability;data transfer;distributed Internet computing;online commerce;social networking;software licensing;software reliability;Application software;Business;Cloud computing;Computer architecture;Data security;Disaster management;Distributed computing;Economies of scale;Hardware;Web and internet services;Internet data centers;cloud computing;distributed systems;utility computing}, 
doi={10.1109/MIC.2009.103}, 
ISSN={1089-7801}, 
month={Sept},}
@INPROCEEDINGS{5088911, 
author={Wei-Ying Ma}, 
booktitle={2009 Tenth International Conference on Mobile Data Management: Systems, Services and Middleware}, 
title={Keynote 2}, 
year={2009}, 
pages={xxxii-xxxii}, 
abstract={A principal aspiration of cloud computing is to create an Internet-based platform that facilitates the development of Web-scale services. By presenting this platform and infrastructure (including datacenters) as a service for developers, together with cloud-based software and data as a service for users, cloud computing promises to "level the playing field" such that small start-up ventures can directly compete with more established Internet companies. In this talk, I will share my thoughts on how this emerging trend could change the landscape of the Internet as we know it, and discuss the opportunities and technical challenges it raises from the perspective of Web data management.}, 
keywords={Web services;Internet services;Web data management;Web-scale services;cloud computing;cloud-based software;Asia;Biographies;Cloud computing;Data mining;Information retrieval;Natural languages;Research and development management;Web and internet services;Web search;World Wide Web}, 
doi={10.1109/MDM.2009.128}, 
ISSN={1551-6245}, 
month={May},}
@INPROCEEDINGS{5159242, 
author={E. P. Mancini and M. Rak and U. Villano}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={PerfCloud: GRID Services for Performance-Oriented Development of Cloud Computing Applications}, 
year={2009}, 
pages={201-206}, 
abstract={Cloud computing, born in the e-business context, and grid computing, originated in the e-science context, are two different but similar paradigms for managing large sets of distributed computing resources. In the last few years there have been many efforts that aim at integrating them. One of the main problems linked to the use of the virtualization techniques adopted in clouds in the grid and high performance computing context derives from the overheads in the virtualization layer. This paper introduces "PerfCloud", a cloud environment built on the top of a GRID system, which lets the user to instantiate virtual clusters (VCs) that become part of the starting GRID. The architecture proposed integrates a set of services able to predict the performance (response time) of user applications on the newly generated VC taking into account the actual amount of computing and communication resources allocated to the VC, as well as the presence of the virtualization layer. The obtained predictions let the user to evaluate on-the-fly if the created VC is compatible with his performance expectations or not.}, 
keywords={distributed processing;grid computing;resource allocation;software architecture;software performance evaluation;cloud computing;distributed computing resources;e-business context;e-science context;grid services;performance-oriented development;resource allocation;virtual cluster;virtualization techniques;Application virtualization;Cloud computing;Computer architecture;Delay;Distributed computing;Grid computing;High performance computing;Resource management;Resource virtualization;Virtual colonoscopy;Cloud Computing;GRID;Performance Evaluation}, 
doi={10.1109/WETICE.2009.47}, 
ISSN={1524-4547}, 
month={June},}
@ARTICLE{5429057, 
author={G. Breiter and M. Behrendt}, 
journal={IBM Journal of Research and Development}, 
title={Life cycle and characteristics of services in the world of cloud computing}, 
year={2009}, 
volume={53}, 
number={4}, 
pages={3:1-3:8}, 
abstract={The emerging style of cloud computing provides applications, data, and information technology resources as services of a network. The cloud services approach focuses on a positive user experience while shielding the user from the complexity of the underlying technology. Each cloud service progresses through a well-defined life cycle: The cloud service provider defines the cloud services to be offered and exposes them via a service catalog; service requesters instantiate the services, which are managed against a set of service-level agreements; and finally the cloud service is destroyed when it is no longer needed. This paper describes this life cycle and explains the relationship of managing the life cycle of cloud services to traditional ITIL® (Information Technology Infrastructure Library) processes as they are present in many data centers today. Furthermore, this paper elaborates on ensembles that provide the hardware infrastructure required to optimally support such flexible and massively scalable cloud services. An ensemble is an autonomically managed pool of like resources that exposes only virtualized resources while hiding the physical infrastructure. This approach allows growing the physical infrastructure with very little or no incremental administration costs.}, 
doi={10.1147/JRD.2009.5429057}, 
ISSN={0018-8646}, 
month={July},}
@ARTICLE{4917459, 
author={J. P. Conti}, 
journal={Engineering Technology}, 
title={Hidden dragon}, 
year={2009}, 
volume={4}, 
number={2}, 
pages={64-66}, 
abstract={The 2010 Winter Olympics are upon us, and organisers are hoping that heavy investment in technology will pave the way to gold and green. The faint sound of Alpine bells must mean the Winter Olympic Games are set to begin this year nestling between the city of Vancouver and Whistler mountain in the Canadian West. The whisper is, Canada may just have a surprise up its sleeve with a top secret programme funding a small army of scientists and engineers aiming for the 'greenest' ever Olympics. As soon as it was awarded the games, the Vancouver Organizing Committee (VANOC) swung into action developing infrastructure and investing in sports. Bell Canada official sponsor and telecommunications provider lay 285 km of fibre optic cable between the 135 venues, offering 15,000 simultaneous connections to the network. "An all-IP system allows us to converge data, voice, video and broadcast over one network to improve reliability. reduce costs, and easily build in redundancy." says Ward Chapin. chief information officer of VANOC. "It's so such simpler because there is 3s cabling, fewer switches, id no need for a PBX for voice". Bell has also built and is hosting the vancouver2010.com portal, on a custom made cloud computing infrastructure comprised of 30,000 servers jildwide.}, 
keywords={Internet;computer games;Canada;Vancouver Organizing Committee;Whistler mountain;Winter Olympic Games;all-IP system;cloud computing infrastructure;distance 285 km;fibre optic cable;green games;telecommunications provider}, 
doi={10.1049/et.2009.2116}, 
ISSN={1750-9637}, 
month={Jan},}
@INPROCEEDINGS{5208703, 
author={R. Maggiani}, 
booktitle={2009 IEEE International Professional Communication Conference}, 
title={Cloud computing is changing how we communicate}, 
year={2009}, 
pages={1-4}, 
abstract={Cloud computing refers to a network that distributes processing power, applications, and large systems among many computers. Social media channels and many other applications use cloud computing as their platform. But cloud computing goes beyond that, offering a way for people to expand their local computing power onto the (seemingly) infinite processing power of the Internet. One of the results is a changing method of communication. Cloud computing can be a single-function application, an infrastructure on which these applications (and many others) can run, a set of services that offer the advantages of huge amounts of computing resources, and the ability to store large amounts of data remotely. Many companies and educational institutions are just beginning to realize the benefits of cloud-based applications that have traditionally required site licensing, installation, and maintenance. Cloud computing, SaaS, software as a service, social media.}, 
keywords={Internet;Internet;SaaS;cloud computing;single-function application;social media channel;software-as-a-service;Application software;Cloud computing;Collaboration;Computer networks;Distributed computing;Educational institutions;Internet;Microcomputers;Supercomputers;Web server}, 
doi={10.1109/IPCC.2009.5208703}, 
ISSN={2158-091X}, 
month={July},}
@ARTICLE{5281248, 
author={B. Bing and J. Kruys}, 
journal={IEEE Wireless Communications}, 
title={Untethered clouds}, 
year={2009}, 
volume={16}, 
number={4}, 
pages={8-10}, 
abstract={Welcome to this first issue on Industry Perspectives, a section dedicated to broad impact articles that aim to bridge the gap between academic research and emerging industry applications. In this issue, we showcase two articles. The usefulness of cloud computing as a virtualized Internet resource has been well documented. The first article by Jan Kruys describes how wireless technologies such as WiFi, WiMax/LTE, and Wi-Fibre can expand the reach of this resource, and enable pervasive on demand computing. The second article by Nada Golmie focuses on the key functionalities for achieving seamless mobility in wireless networks, and explains why deployment challenges remain even though standards and solutions are available. I hope these articles help shed some light on real-world problems that may, in turn, spawn new research topics. I take this opportunity to thank the authors for their fine efforts and to invite potential contributors for future sections.}, 
keywords={mobile computing;wireless LAN;cloud computing;pervasive on demand computing;seamless mobility;virtualized Internet resource;wireless networks;Bandwidth;Channel capacity;Cloud computing;Degradation;MIMO;Marketing and sales;Radio frequency;Signal to noise ratio;Transmitters;WiMAX}, 
doi={10.1109/MWC.2009.5281248}, 
ISSN={1536-1284}, 
month={Aug},}
@INPROCEEDINGS{5359493, 
author={V. Stantchev}, 
booktitle={2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences}, 
title={Performance Evaluation of Cloud Computing Offerings}, 
year={2009}, 
pages={187-192}, 
abstract={Advanced computing on cloud computing infrastructures can only become viable alternative for the enterprise if these infrastructures can provide proper levels of nonfunctional properties (NPFs). A company that focuses on service-oriented architectures (SOA) needs to know what configuration would provide the proper levels for individual services if they are deployed in the cloud. In this paper we present an approach for performance evaluation of cloud computing configurations. While cloud computing providers assure certain service levels, this it typically done for the platform and not for a particular service instance. Our approach focuses on NFPs of individual services and thereby provides a more relevant and granular information. An experimental evaluation in Amazon Elastic Compute Cloud (EC2) verified our approach.}, 
keywords={Internet;software architecture;software performance evaluation;Amazon Elastic Compute Cloud;cloud computing offerings;nonfunctional properties;performance evaluation;service-oriented architectures;Cloud computing;Companies;Computer applications;Conference management;Delay;Engineering management;Runtime;Service oriented architecture;Web server;Web services;cloud computing;performance evaluation;service-oriented computing}, 
doi={10.1109/ADVCOMP.2009.36}, 
month={Oct},}
@INPROCEEDINGS{5402989, 
author={S. K. Seo and S. J. Baek and C. W. Lee and S. W. Kim and S. M. Park and Y. S. Jeong}, 
booktitle={2009 Fourth International Conference on Embedded and Multimedia Computing}, 
title={TMS: Visual Monitoring of Trusted Platform Board for Trust Computing Based on Web}, 
year={2009}, 
pages={1-6}, 
abstract={The TPB (trusted platform board) is an expansion of the TPM (trust platform module) chip for the elevation of the efficiency and usability of the TPM chip that has been developed from the TCG (trusted computing group) for the trust computing. In addition to the TPB function supporting environments for the high-standard trust within the hardware standard of the system, the present paper develops the TMS (trust monitoring system) that provides the visualization of the real-time monitoring for the system resources (process, memory, network, users, etc.). Moreover, TMS is not only the Internet-based computing environment for the system resources but also the real-time monitoring system for the cloud computing environment.}, 
keywords={Internet;real-time systems;system monitoring;Internet;TMS;World Wide Web;cloud computing;hardware standard;real-time monitoring system;system resources;trust computing;trust monitoring system;trust platform module;trusted computing group;trusted platform board;visual monitoring;Cloud computing;Computer peripherals;Hardware;Military computing;Monitoring;Pervasive computing;Real time systems;Security;Standards development;Usability}, 
doi={10.1109/EM-COM.2009.5402989}, 
ISSN={2159-1520}, 
month={Dec},}
@INPROCEEDINGS{5392830, 
booktitle={2009 Fourth International Conference on Frontier of Computer Science and Technology}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: parallel computing; distributed computing; pervasive computing; grid computing; P2P computing; cloud computing; embedded computing; database management; data management; network computing; Internet computing; computer vision; image processing; wireless sensor networks; mobile computing; reliability; fault tolerance; distributed transaction processing; trustworthy computing; artificial intelligence; theoretical computer science; system software; software engineering; machine learning; pattern recognition; and human-computer interaction.}, 
keywords={Internet;computer vision;database management systems;fault tolerance;grid computing;human computer interaction;learning (artificial intelligence);mobile computing;parallel processing;peer-to-peer computing;security of data;software engineering;wireless sensor networks;Internet computing;P2P computing;artificial intelligence;cloud computing;computer vision;data management;database management;distributed computing;distributed transaction processing;embedded computing;fault tolerance;grid computing;human-computer interaction;image processing;machine learning;mobile computing;network computing;parallel computing;pattern recognition;pervasive computing;software engineering;system software;theoretical computer science;trustworthy computing;wireless sensor networks}, 
doi={10.1109/FCST.2009.1}, 
ISSN={2159-6301}, 
month={Dec},}
@INPROCEEDINGS{5161639, 
booktitle={2009 International Conference on Network and Service Security}, 
title={N2S 2009 - Title page}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: cloud computing trust; distributed deniai-of-service attack; Web application security; pervasive computing; ubiquitous computing; mobile computing; communication security; cryptography; cryptanalysis; distributed intrusion detection systems; mobile ad hoc networks security and peer-to-peer network security.}, 
keywords={Internet;ad hoc networks;computer network security;cryptography;mobile computing;peer-to-peer computing;Web application security;cloud computing;communication security;cryptography;distributed deniai-of-service attack;distributed intrusion detection system;mobile ad hoc networks security;mobile computing;peer-to-peer network security;pervasive computing;ubiquitous computing}, 
month={June},}
@INPROCEEDINGS{5175875, 
author={L. J. Zhang and Q. Zhou}, 
booktitle={2009 IEEE International Conference on Web Services}, 
title={CCOA: Cloud Computing Open Architecture}, 
year={2009}, 
pages={607-616}, 
abstract={Cloud computing is evolving as a key computing platform for sharing resources that include infrastructures, software, applications, and business processes. Virtualization is a core technology for enabling cloud resource sharing. However, most existing cloud computing platforms have not formally adopted the service-oriented architecture (SOA) that would make them more flexible, extensible, and reusable. By bridging the power of SOA and virtualization in the context of cloud computing ecosystem, this paper presents seven architectural principles and derives ten interconnected architectural modules to form a reusable and customizable cloud computing open architecture (CCOA). Two case studies on infrastructure and business cloud are used to deliver business and practical value of infrastructure and business process provisioning services over the Internet. We also present some potential value-added services of the proposed CCOA to guide strategic planning and other consulting practices of cloud computing.}, 
keywords={Web services;business data processing;resource allocation;strategic planning;CCOA;Internet;business process;cloud computing ecosystem;cloud resource sharing;customizable cloud computing open architecture;guide strategic planning;service-oriented architecture;virtualization technology;Application software;Cloud computing;Computer architecture;Concurrent computing;Grid computing;Internet;Middleware;Open source software;Service oriented architecture;Web services;Business Cloud;Cloud Computing;Cloud Computing Open Architecture (CCOA);Infrastructure Cloud;SOA;architectural principles;ecosystem;virtualization}, 
doi={10.1109/ICWS.2009.144}, 
month={July},}
@ARTICLE{5076317, 
author={J. Cohen}, 
journal={Computing in Science Engineering}, 
title={Graph Twiddling in a MapReduce World}, 
year={2009}, 
volume={11}, 
number={4}, 
pages={29-41}, 
abstract={As the size of graphs for analysis continues to grow, methods of graph processing that scale well have become increasingly important. One way to handle large datasets is to disperse them across an array of networked computers, each of which implements simple sorting and accumulating, or MapReduce, operations. This cloud computing approach offers many attractive features. If decomposing useful graph operations in terms of MapReduce cycles is possible, it provides incentive for seriously considering cloud computing. Moreover, it offers a way to handle a large graph on a single machine that can't hold the entire graph as well as enables streaming graph processing. This article examines this possibility.}, 
keywords={distributed processing;graph theory;MapReduce cycles;cloud computing approach;distributed processing;graph processing;graph twiddling;Cloud computing;Computer networks;Distributed computing;Distributed processing;Hardware;Humans;National security;Packaging;Robustness;Sorting;Hadoop;MapReduce;cloud computing;clustering;cycles;graphs;networks;social network analysis;trusses}, 
doi={10.1109/MCSE.2009.120}, 
ISSN={1521-9615}, 
month={July},}
@INPROCEEDINGS{5066449, 
author={M. Descher and P. Masser and T. Feilhauer and A. M. Tjoa and D. Huemer}, 
booktitle={2009 International Conference on Availability, Reliability and Security}, 
title={Retaining Data Control to the Client in Infrastructure Clouds}, 
year={2009}, 
pages={9-16}, 
abstract={Cloud computing allows delivering information technology power on demand. Be it either the hosting of a certain Web application or the outsourcing of an entire server or data center by means of virtualization. Applying these techniques however goes along with handing over the ultimate control of data to a third party. This paper investigates the application of Nimbus as a cloud resource and shows an example implementation for retaining data control to the user based on virtual machine images encrypted on the client side. This means that the procedures involved for verifying validity and accessing the virtual machine have to be entirely provided by the user. We provide a sample implementation of a secure virtual machine consisting of an encrypted partition, containing the data to be hosted, and a boot system, containing the logic to verify and access the encrypted partition. Further details of the implementation are described and applied on a cloud resource available within the AustrianGrid project. The methods presented in this paper form the basis for subsequent research on single point of access grid resp. cloud resources. The results will be applied in the AustrianGrid Phase 2 research project "Grid-supported Breath Gas Analysis of Molecular Oriented Diseases".}, 
keywords={Internet;grid computing;virtual machines;AustrianGrid project;Nimbus;Web application;access grid;boot system;cloud computing;cloud resource;data center;data control;encrypted partition verification;information technology;infrastructure clouds;secure virtual machine;virtual machine images;virtualization;Ambient intelligence;Application software;Application virtualization;Cloud computing;Cryptography;Grid computing;Resource management;Resource virtualization;Virtual machining;Web services}, 
doi={10.1109/ARES.2009.78}, 
month={March},}
@INPROCEEDINGS{5353074, 
author={R. Prodan and S. Ostermann}, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={A survey and taxonomy of infrastructure as a service and web hosting cloud providers}, 
year={2009}, 
pages={17-25}, 
abstract={With an increasing number of providers claiming to offer Cloud infrastructures, there is a lack in the community for a common terminology, accompanied by a clear definition and classification of Cloud features. We conduct in this paper a survey on a selection of Cloud providers, and propose a taxonomy of eight important Cloud computing elements covering service type, resource deployment, hardware, runtime tuning, business model, middleware, and performance. We conclude that the provisioning of Service Level Agreements as utilities, of open and interoperable middleware solutions, as well as of sustained performance metrics for high-performance computing applications are three elements with the highest need of further community research.}, 
keywords={Internet;middleware;open systems;Web hosting cloud providers;business model;cloud computing elements;cloud infrastructure;infrastructure as a service;interoperable middleware solution;resource deployment;runtime tuning;service level agreements;service type;Cloud computing;Companies;Computer science;Hardware;Middleware;Runtime;Software maintenance;Taxonomy;Terminology;Web and internet services}, 
doi={10.1109/GRID.2009.5353074}, 
ISSN={2152-1085}, 
month={Oct},}
@INPROCEEDINGS{5342096, 
author={J. Yan and W. S. Li}, 
booktitle={2009 IEEE International Conference on e-Business Engineering}, 
title={Calibrating Resource Allocation for Parallel Processing of Analytic Tasks}, 
year={2009}, 
pages={327-332}, 
abstract={Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. In this environment, any application needs a model of to achieve elasticity and the illusion of infinite capacity requires each of these resources to be virtualized to hide the implementation of how they are multiplexed and shared. Given the nature of parallel processing dynamic, how to assign numbers of servers, CPUs, cores to the tasks have great impacts to the resource utilization of a PaaS (Platform as a Service) provider. In this paper, we face the challenge in automated calibration of resource allocation for parallel processing of analytic tasks. The proposed framework does not assume availability of data statistics and application semantics but probeable tradeoff between parallelism benefits and overheads. To implement it, a Sampling-then-Calibrating algorithm is presented to sample the runtime statistic information and calibrate the resource allocation accordingly. The experiments validate effectiveness of our approach.}, 
keywords={parallel processing;resource allocation;CPU;IT industry;PaaS provider;analytic task;automated resource allocation calibration;cloud computing;data statistics;parallel processing;platform-as-a-service;server assignment;Application software;Application virtualization;Cloud computing;Computer industry;Elasticity;Hardware;Parallel processing;Resource management;Resource virtualization;Statistics}, 
doi={10.1109/ICEBE.2009.51}, 
month={Oct},}
@INPROCEEDINGS{5380866, 
author={X. Gao and M. Lowe and Y. Ma and M. Pierce}, 
booktitle={2009 Fifth IEEE International Conference on e-Science}, 
title={Supporting Cloud Computing with the Virtual Block Store System}, 
year={2009}, 
pages={208-215}, 
abstract={The fast development of cloud computing systems stimulates the needs for a standalone block storage system to provide persistent block storage services to virtual machines maintained by clouds. This paper presents the Virtual Block Store (VBS) System, a standalone block storage system built on the basis of LVM, iSCSI, and Xen hypervisor, which can provide basic block storage services such as volume creation and attachment. The concept and functional interface of VBS are based on Amazon Elastic Block Store (EBS) service; moreover, VBS works independently with an existing LVM volume server and Xen nodes, and thus can be easily extended to support other types of volume servers and virtual machine managers, or integrated with various cloud computing systems. Preliminary I/O benchmark results are presented and analyzed, indicating that a VBS volume can provide throughput that is similar to an ATA over Ethernet virtual device.}, 
keywords={Internet;virtual machines;virtual storage;Amazon elastic block store service;Ethernet virtual device;LVM volume server;Xen hypervisor;cloud computing;functional interface;iSCSI;standalone block storage system;virtual block store system;virtual machines;Cloud computing;Ethernet networks;File systems;Image storage;Memory;Resource management;Virtual machine monitors;Virtual machining;Virtual manufacturing;Voice mail;Cloud computing;Virtual Block Store}, 
doi={10.1109/e-Science.2009.37}, 
month={Dec},}
@INPROCEEDINGS{5273833, 
author={H. Al Shargi and S. Berkovich}, 
booktitle={2009 Second International Conference on the Applications of Digital Information and Web Technologies}, 
title={Biological information processing as cloud computing}, 
year={2009}, 
pages={417-422}, 
abstract={What distinguishes biological complexity is that it is an information based complexity. Bioinformatics deals with genetic configurations of limited information content. It seems problematical that separate directives of several thousand symbols could be responsible for the whole richness of living systems. It is unrealistic to exempt biological systems from the requirements of information processing and expect them to function with inadequate amount of instructions. Recent findings of epigenetic effects bring the problem of information deficiency of the genetic configurations to the forefront. Analyzing the results of our Information theoretic analysis performed on biological sequences, and a survey of recent developments in the epigenetic research, we propose a novel approach to explain how biological systems function and achieve complexity where we consider the possibility that biological information processing can be organized in analogy with the emerging cloud computing paradigm. Such organization depicts great prospects to solving biology's most enigmatic puzzles.}, 
keywords={Internet;bioinformatics;genetics;Information theoretic analysis;Internet;bioinformatics;biological complexity;biological information processing;biological sequence;biological system;cloud computing;epigenetic research;genetic configuration;information content;information deficiency;living system;Bioinformatics;Biological information theory;Cloud computing;Entropy;Genomics;Humans;Information analysis;Information processing;Organisms;Sequences}, 
doi={10.1109/ICADIWT.2009.5273833}, 
month={Aug},}
@INPROCEEDINGS{5158835, 
author={J. Liu and F. Zhao and X. Liu and W. He}, 
booktitle={2009 29th IEEE International Conference on Distributed Computing Systems Workshops}, 
title={Challenges Towards Elastic Power Management in Internet Data Centers}, 
year={2009}, 
pages={65-72}, 
abstract={Data Centers are energy consuming facilities that host Internet services such as cloud computing platforms. Their complex cyber and physical systems bring unprecedented challenges in resource managements. In this paper, we give an overview of the resource provisioning and utilization patterns in data centers and propose a macro-resource management layer to coordinate among cyber-and-physical resources. We review some existing work and solutions in the field and explain their limitations. We give some future research directions and the potential solutions to jointly optimize computing and environmental resources in data centers.}, 
keywords={Internet;information retrieval systems;power aware computing;Internet data centers;Internet services;cloud computing platforms;elastic power management;energy consuming facilities;resource managements;Cloud computing;Cooling;Costs;Energy consumption;Energy efficiency;Energy management;Internet;Network servers;Power system management;Resource management}, 
doi={10.1109/ICDCSW.2009.44}, 
ISSN={1545-0678}, 
month={June},}
@INPROCEEDINGS{4755688, 
author={T. Meinl and D. Neumann}, 
booktitle={2009 42nd Hawaii International Conference on System Sciences}, 
title={A Real Options Model for Risk Hedging in Grid Computing Scenarios}, 
year={2009}, 
pages={1-10}, 
abstract={The acquisition of remote IT resources via grid or cloud computing for a certain amount of time, instead of setting up a proprietary IT infrastructure, has attracted much attention during the last years, as technical obstacles are overcome. In order to reduce their maintenance cost of internal IT clusters, many hard- and software providers reconsider to offer these resources in grid and cloud markets. However, participants in these markets bear some uncertainties and risks which can be hedged against by resource reservation. In this work we analyze the use of real options traded at an additional contract market, to efficiently manage economical issues arising from the realization of a flexible resource reservation scheme. We derive the necessary conditions that even risk neutral agents have incentives to participate in such a market, as it increases their expected utility.}, 
keywords={contracts;grid computing;pricing;risk analysis;cloud computing;contract market;flexible resource reservation scheme;grid computing;real options;remote IT resources;risk hedging;Conference management;Contracts;Costs;Environmental economics;Grid computing;Management information systems;Mathematical model;Power generation economics;Resource management;Risk management}, 
doi={10.1109/HICSS.2009.33}, 
ISSN={1530-1605}, 
month={Jan},}
@INPROCEEDINGS{5190710, 
author={M. Vukovic}, 
booktitle={2009 Congress on Services - I}, 
title={Crowdsourcing for Enterprises}, 
year={2009}, 
pages={686-692}, 
abstract={Crowdsourcing is emerging as the new on-line distributed problem solving and production model in which networked people collaborate to complete a task. Enterprises are increasingly employing crowdsourcing to access scalable workforce on-line. In parallel, cloud computing has emerged as a new paradigm for delivering computational services, which seamlessly interweave physical and digital worlds through a common infrastructure.This paper presents a sample crowdsourcing scenario in software development domain to derive the requirements for delivering a general-purpose crowdsourcing service in the Cloud. It proposes taxonomy for categorization of crowdsourcing platforms, and evaluates a number of existing systems against the set of identified features. Finally, the paper outlines a research agenda for enhancing crowdsourcing capabilities, with focus on virtual team building and task-based service provisioning, whose lack has been a barrier to the realization of a peer-production model that engages providers from around the world.}, 
keywords={Web services;groupware;social networking (online);software engineering;cloud computing;computational services;crowdsourcing service;peer-production model;software development;task-based service provisioning;virtual team building;Cloud computing;Collaborative work;Concurrent computing;Physics computing;Problem-solving;Production;Programming;Taxonomy;Testing;Virtual groups;cloud;crowdsourcing;people services}, 
doi={10.1109/SERVICES-I.2009.56}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{4808890, 
author={Yun Hou and M. Zafer and Kang-won Lee and D. Verma and K. K. Leung}, 
booktitle={2009 First International Communication Systems and Networks and Workshops}, 
title={On the mapping between logical and physical topologies}, 
year={2009}, 
pages={1-10}, 
abstract={Network graphs, in general, successfully model a wide variety of interactions and relationships among entities, including both physical and logical connections. In this work, we study the problem of mapping a logical network on to a physical network; such a problem arises in various scenarios, for example, assignment of virtual machines on to physical servers in cloud computing, assignment of services on to physical devices in wireless/wire-line environments and physical resource assignment based on social networks. Specifically, in this paper, a logical network is a set of nodes with edges that denote the communication/bandwidth requirement between them, while a physical network denotes a set of physical nodes with edges that represent the available physical resources. The goal is to map the logical nodes on to the physical nodes and find physical resource allocation to meet the logical network demands, subject to physical network constraints. Towards this end, we propose a two-step approach to the problem, provide a set of novel feasibility checks for node assignment which are proved to be necessary and sufficient, and finally present a simple and fast algorithm that achieves a feasible logical to physical mapping with high probability. Illustrative simulation results are also presented to highlight the efficiency of the proposed algorithms.}, 
keywords={computer networks;telecommunication network topology;communication/bandwidth requirement;fast algorithm;logical connections;logical network demands;logical topology;network constraints;network graphs;node assignment;physical mapping;physical topology;resource allocation;Bandwidth;Channel allocation;Cloud computing;Educational institutions;Network servers;Network topology;Resource management;Routing;Social network services;Virtual machining;Overlay Networks;Topology Mapping;Vitualization}, 
doi={10.1109/COMSNETS.2009.4808890}, 
ISSN={2155-2487}, 
month={Jan},}
@INPROCEEDINGS{5368503, 
author={K. Takayama and H. Yokota}, 
booktitle={2009 15th IEEE Pacific Rim International Symposium on Dependable Computing}, 
title={Performance and Reliability of a Revocation Method Utilizing Encrypted Backup Data}, 
year={2009}, 
pages={151-158}, 
abstract={When multiple users access a network storage system for cloud computing, security becomes a key factor in the service, as well as performance and reliability. The "encrypt-on-disk'' scheme effectively protects transmitted and stored data in network storage. However, this scheme has the problem of revocation for shared files. Active revocation is safe but has denial periods to allow immediate reencryption, while lazy revocation has no denial period but is unsafe during the delay. We propose intelligent storage nodes capable of handling active revocation in storage without the denial period by adopting a primary-backup configuration. This approach provides a good combination of security and availability by replication. However, the reencryption process negatively affects the update performance. Delaying the reencryption process and disk write on the backup node improves performance with no ill effect on security and a small decrease of MTTDL for the simple primary-backup configuration. We evaluate the performance of the proposed approaches by experiments, and the reliability by estimation.}, 
keywords={cryptography;disc storage;peer-to-peer computing;reliability;MTTDL;availability;cloud computing;disk write delay;encrypted backup data;intelligent storage nodes;network storage system;primary-backup configuration;reencryption;reliability;replication;revocation method;security;shared files;Availability;Cloud computing;Computer network reliability;Computer networks;Cryptography;Data security;Delay;Protection;Scalability;Secure storage;encrypt-on-disk;parallel storage;primary-backup structure;revocation;secure storage}, 
doi={10.1109/PRDC.2009.32}, 
month={Nov},}
@ARTICLE{4621885, 
author={K. Sangani}, 
journal={Engineering Technology}, 
title={gadget speak}, 
year={2008}, 
volume={3}, 
number={11}, 
pages={30-31}, 
abstract={Microsoft has decided to take on Google Docs with the launch of its very own 'cloud computing' package. Kris Sangani compares both application suites. It used to be the case that the reason to buy a PC or Mac was to run a spreadsheet and word processing application. These apps were instant successes when Microsoft chose to bundle these programs and add other options, such as a presentation and database software.}, 
ISSN={1750-9637}, 
month={June},}
@INPROCEEDINGS{4976555, 
author={D. Bernstein and E. Ludvigson}, 
booktitle={2009 Workshops at the Grid and Pervasive Computing Conference}, 
title={Networking Challenges and Resultant Approaches for Large Scale Cloud Construction}, 
year={2009}, 
pages={136-142}, 
abstract={Cloud Computing is a term applied to large, hosted data centers, usually geographically distributed, which offer various computational services on a ldquoutilityrdquo basis. Most typically the configuration and provisioning of these data centers, as far as the services for the subscribers go, is highly automated, to the point of the service being delivered within seconds of the subscriber request. Additionally, the data centers typically use hypervisor based virtualization as a technique to deliver these services. Providers who construct these data centers run into a variety of challenges which are not common in ordinary-scale data centers. Of specific interest is the unique demand placed on the underlying network. Many unique approaches are utilized to address these networking challenges, several of which are discussed in this paper.}, 
keywords={Internet;computer centres;cloud computing;large hosted datacenters;large scale cloud construction;networking challenges;ordinary-scale datacenters;virtualization;Cloud computing;Construction industry;Ethernet networks;IP networks;Large-scale systems;Microcomputers;Network servers;Pervasive computing;Voice mail;Web server;Cloud Computing;Dynamic Datacenter;Internet Computing}, 
doi={10.1109/GPC.2009.10}, 
month={May},}
@INPROCEEDINGS{5368477, 
author={L. Xiong and H. Tong}, 
booktitle={2009 Second International Symposium on Computational Intelligence and Design}, 
title={Customer Satisfaction Index Assessment Based on Cloud Computing}, 
year={2009}, 
volume={2}, 
pages={330-333}, 
abstract={Customer satisfaction index (CSI) containing economic quality information has become a heated topic in new economic era. How to assess CSI is very important to a country as well as an enterprise. Structure equation model (SEM) is a popular method to analyze CSI. In this paper, we first analyze the observation equations in SEM and find the least square relationship between each structural variable and its observation variables. Then we obtain the modular constraint least square (MCLS) solution of SEM by adding a constraint with modular length to the structural variable. The algorithm is definite without convergence problem and the solution is unique. Furthermore, combining cloud computing technology, we construct a CSI assessment system based on cloud computing.}, 
keywords={customer satisfaction;economics;least mean squares methods;cloud computing;customer satisfaction index assessment;economic quality information;enterprise;modular constraint least square solution;structure equation model;Cloud computing;Computational intelligence;Computer science;Covariance matrix;Customer satisfaction;Equations;Globalization;Least squares methods;Mathematics;Numerical analysis;CSI;SEM;SaaS;cloud computing}, 
doi={10.1109/ISCID.2009.228}, 
month={Dec},}
@INPROCEEDINGS{5395288, 
author={Y. Xia and C. Yang and X. Cheng}, 
booktitle={2009 15th International Conference on Parallel and Distributed Systems}, 
title={PaS: A Preemption-aware Scheduling Interface for Improving Interactive Performance in Consolidated Virtual Machine Environment}, 
year={2009}, 
pages={340-347}, 
abstract={As virtualization technology is used widely in cloud computing, there are more and more interactive workloads being deployed on virtual machine (VM) environment. Although improving interactive performance has been heavily studied in operating system area, in consolidated VM environment, the improvements of guest OS are usually offset by the more coarse-grained VM scheduler, which may cause poor interactive performance. The guest OS scheduler and VM scheduler are totally independent with each other, which leads to the so called 'semantic gap'. To reduce this semantic gap, this paper presents PaS (Preemption-aware Scheduling) as an extension of VM scheduling interface. PaS introduces only two interfaces: one to register VM preemption conditions, the other to check if a VM is preempting. Thanks to the sophisticated techniques of interactive-process identification and optimization in traditional OS, it is trivial for guest OS to use the new interfaces: only 10 lines of code are added into Linux 2.6.18.8. The evaluation results show that PaS can significantly improve the interactive performance of consolidated VMs while keeping the fairness and performance isolation.}, 
keywords={Linux;operating system kernels;resource allocation;scheduling;virtual machines;cloud computing;consolidated virtual machine environment;interactive performance improvement;interactive workload;interactive-process identification;operating system scheduler;performance isolation;preemption-aware scheduling interface;resource allocation;semantic gap;virtualization technology;Cloud computing;Delay;Kernel;Linux;Microprocessors;Processor scheduling;Registers;Virtual machining;Virtual manufacturing;Voice mail;interactive performance;scheduling;virtual machine}, 
doi={10.1109/ICPADS.2009.51}, 
ISSN={1521-9097}, 
month={Dec},}
@ARTICLE{5226615, 
author={K. Keahey and M. Tsugawa and A. Matsunaga and J. Fortes}, 
journal={IEEE Internet Computing}, 
title={Sky Computing}, 
year={2009}, 
volume={13}, 
number={5}, 
pages={43-51}, 
abstract={Infrastructure-as-a-service (IaaS) cloud computing is revolutionizing how we approach computing. Compute resource consumers can eliminate the expense inherent in acquiring, managing, and operating IT infrastructure and instead lease resources on a pay-as-you-go basis. IT infrastructure providers can exploit economies of scale to mitigate the cost of buying and operating resources and avoid the complexity required to manage multiple customer-specific environments and applications. The authors describe the context in which cloud computing arose, discuss its current strengths and shortcomings, and point to an emerging computing pattern it enables that they call sky computing.}, 
keywords={Internet;economies of scale;socio-economic effects;IT infrastructure provider;economies of scale;infrastructure-as-a-service cloud computing;sky computing;Cloud computing;Costs;Economies of scale;Environmental management;Resource management;cloud computing;infrastructure-as-a-service;sky computing}, 
doi={10.1109/MIC.2009.94}, 
ISSN={1089-7801}, 
month={Sept},}
@INPROCEEDINGS{5394127, 
author={D. Niyato and S. Chaisiri and B. S. Lee}, 
booktitle={2009 IEEE Asia-Pacific Services Computing Conference (APSCC)}, 
title={Economic analysis of resource market in cloud computing environment}, 
year={2009}, 
pages={156-162}, 
abstract={Cloud computing has been emerged as the flexible, efficient, and economical distributed computing platform to meet the dynamic and random demand from the users. In this paper, we consider cloud computing environment with resource market between private clouds (i.e., buyers) and service providers (i.e., sellers) in public cloud. Economic analysis is proposed for different types of resource markets, i.e., monopoly (single service provider), competitive and cooperative oligopolies (few service providers). We study the optimal strategy for service provider in monopoly market, the Nash equilibria in competitive oligopoly market, and bargaining solution in cooperative oligopoly market. In addition, the decision and condition for service providers to to establish collusion in the oligopoly market are also investigated.}, 
keywords={distributed processing;game theory;oligopoly;Nash equilibria;bargaining solution;cloud computing environment;competitive oligopoly market;cooperative oligopoly market;distributed computing platform;economic analysis;monopoly market;private clouds;public cloud;resource market;service providers;Cloud computing;Computer architecture;Distributed computing;Economic forecasting;Environmental economics;Mathematical model;Monopoly;Oligopoly;Virtual machining;Virtual manufacturing}, 
doi={10.1109/APSCC.2009.5394127}, 
month={Dec},}
@INPROCEEDINGS{5289160, 
author={S. Pallickara and J. Ekanayake and G. Fox}, 
booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
title={Granules: A lightweight, streaming runtime for cloud computing with support, for Map-Reduce}, 
year={2009}, 
pages={1-10}, 
abstract={Cloud computing has gained significant traction in recent years. The Map-Reduce framework is currently the most dominant programming model in cloud computing settings. In this paper, we describe Granules, a lightweight, streaming-based runtime for cloud computing which incorporates support for the Map-Reduce framework. Granules provides rich lifecycle support for developing scientific applications with support for iterative, periodic and data driven semantics for individual computations and pipelines. We describe our support for variants of the Map-Reduce framework. The paper presents a survey of related work in this area. Finally, this paper describes our performance evaluation of various aspects of the system, including (where possible) comparisons with other comparable systems.}, 
keywords={graph theory;pipeline processing;program diagnostics;Granules;Map-Reduce;cloud computing;data driven semantics;Application software;Cloud computing;Computer science;Concurrent computing;Hardware;Machine learning algorithms;Parallel processing;Parallel programming;Pipelines;Runtime;cloud computing;cloud runtimes;content distribution networks;map-reduce;streaming}, 
doi={10.1109/CLUSTR.2009.5289160}, 
ISSN={1552-5244}, 
month={Aug},}
@INPROCEEDINGS{5357099, 
author={G. Caryer and T. Rings and J. Gallop and S. Schulz and J. Grabowski and I. Stokes-Rees and T. Kovacikova}, 
booktitle={2009 13th International Conference on Intelligence in Next Generation Networks}, 
title={Grid/cloud computing interoperability, standardization and the Next Generation Network (NGN)}, 
year={2009}, 
pages={1-6}, 
abstract={For telecom operators, the future lies in converging fixed, mobile and data services onto the next generation network (NGN). This paper discusses the relationship between grid and cloud computing, identifies gaps and overlaps in existing standards and identifies how grid and cloud technology could be exploited to improve the efficiency of NGN resources and to offer new ¿¿data¿¿ services to consumers. This will enable telecom operators to manage their resources in a dynamic and optimal way by a single platform. This paper describes the approach taken by the European Telecommunications Standards Institute (ETSI) Technical Committee for Grid Computing (TC GRID) to identify gaps and overlaps in grid/cloud computing standards and to support the integration of grid/cloud computing with the NGN architecture.}, 
keywords={Internet;grid computing;open systems;telecommunication standards;ETSI;European Telecommunications Standards Institute;NGN architecture;TC GRID;Technical Committee for Grid Computing;cloud computing interoperability;cloud technology;data services;grid computing interoperability;next generation network;telecom operators;Cloud computing;Computer interfaces;Computer networks;Grid computing;Large-scale systems;Next generation networking;Resource management;Resource virtualization;Standardization;Telecommunication standards;NGN;Next Gerneration Network;cloud;grid;interoperability}, 
doi={10.1109/ICIN.2009.5357099}, 
month={Oct},}
@ARTICLE{4804046, 
author={C. Weinhardt and A. Anandasivam and B. Blau and J. Stößer}, 
journal={IT Professional}, 
title={Business Models in the Service World}, 
year={2009}, 
volume={11}, 
number={2}, 
pages={28-33}, 
abstract={The authors provide a criteria catalogue to characterize cloud computing and their own Cloud Business Ontology Model to classify current product offerings and pricing models.}, 
keywords={Web services;cataloguing;classification;electronic commerce;grid computing;ontologies (artificial intelligence);IT resource sharing;cloud business ontology model;cloud computing;electronic commerce;grid computing;product catalogue;product classification;service world;voluntary computing;Application software;Application specific processors;Assembly;Business communication;Cloud computing;Grid computing;Pricing;Software libraries;Sun;Technological innovation;IT professional;business models;cloud computing;grid computing;pricing}, 
doi={10.1109/MITP.2009.21}, 
ISSN={1520-9202}, 
month={March},}
@INPROCEEDINGS{4732159, 
author={W. Guoqin and X. Meihua}, 
booktitle={2008 International Symposium on Information Science and Engineering}, 
title={Research on Tightly Coupled Multi-Robot Architecture Using Microkernel-Based, Real-Time, Distributed Operating System}, 
year={2008}, 
volume={1}, 
pages={8-13}, 
abstract={This paper presents a method to build a real-time distributed operating system. We first discuss the theory of microkernels and their operating system implementations, to find a way to build a real-time distributed operating system that meet the requirements in constructing tightly coupled multi-robot architecture.We choose DROPS as the basis, and do many modifications on real time and distributivity on it, to make it hard real-time, and make both real-time and time-sharing components run distributed on it. We then use this operating system to implement a multi-robot architecture to show reasonableness and practicability. Besides in multi-robot architecture, we introduce the idea that, using this operating system, the clusters may allow any computer or computing device of the users to participate in, to build much bigger distributed systems, hence named advanced cloud computing.}, 
keywords={control engineering computing;multi-robot systems;operating systems (computers);real-time systems;robot programming;DROPS;multirobot architecture;real-time distributed operating system;Distributed;Microkernel;Multi-Robot Architecture;Operating System}, 
doi={10.1109/ISISE.2008.80}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5207834, 
booktitle={2009 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
title={[Front cover]}, 
year={2009}, 
pages={C1-C1}, 
abstract={The following topics are dealt with: distributed systems and applications; virtual machines; multi-core architecture, visualization and GPU; security systems, fault-tolerance and reliability ; mobile, wireless and sensor networks; network routing; security in e-Science and e-Research; cyberspace safety and security; architecture support on virtualization techniques; workflow management in service and cloud computing.}, 
keywords={computer architecture;computer graphics;distributed processing;fault tolerance;multi-agent systems;network routing;security of data;virtual machines;virtual reality;wireless sensor networks;workflow management software;GPU;cyberspace safety;distributed processing;fault-tolerance;graphics processing unit;multi-agent system;multi-core architecture;network routing;security systems;virtual machines;virtualization;wireless sensor networks;workflow management}, 
doi={10.1109/ISPA.2009.129}, 
ISSN={2158-9178}, 
month={Aug},}
@INPROCEEDINGS{5238672, 
author={J. E. Berthold}, 
booktitle={2009 17th IEEE Symposium on High Performance Interconnects}, 
title={Optical Networking for Data Center Interconnects Across Wide Area Networks}, 
year={2009}, 
pages={149-153}, 
abstract={This paper explores the application of wide area optical networking to enhance the interconnection of data centers, supporting a more capable and efficient cloud computing environment. It examines cost and performance metrics for optical transmission and switching relevant to this application.}, 
keywords={Internet;optical fibre networks;telecommunication traffic;wide area networks;cloud computing environment;data center;optical switching;optical transmission;performance metrics;wide area networks;wide area optical networking;Bandwidth;Business continuity;Clouds;Costs;Optical fiber networks;Optical interconnections;Optical network units;Telecommunication traffic;Wavelength division multiplexing;Wide area networks;optical networking;optical switching;optical transmission}, 
doi={10.1109/HOTI.2009.25}, 
ISSN={1550-4794}, 
month={Aug},}
@INPROCEEDINGS{5410452, 
author={K. Y. Cheng and C. H. Wu}, 
booktitle={2009 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)}, 
title={Peeraid: A resilient path-aware storage system for open clouds}, 
year={2009}, 
pages={1-8}, 
abstract={Data management is one of the key issues in Cloud Computing. This paper proposes a peer-to-peer storage system, called Peeraid, for the clouds that are structured as a collection of peer nodes which are supplied by different participants around the world. Peeraid is highly scalable because data object and node lookups are accomplished by distributed hash table (DHT). User files are stored as erasure-coded shares to achieve high data availability with less storage cost. Peeraid also supports distributed group management in a fully decentralized manner, and utilizes group locality and network proximity to improve access performance. Besides, write operations are efficiently logged to support fast update.}, 
keywords={Internet;database management systems;peer-to-peer computing;storage management;Peeraid;cloud computing;data management;distributed group management;distributed hash table;erasure-coded;network proximity;node lookups;open clouds;peer-to-peer storage system;resilient path-aware storage system;scalable data object;user files;write operations;Availability;Cloud computing;Computational modeling;Computer science;Costs;Cryptography;Engineering management;Hardware;Peer to peer computing;Scalability;Cloud Computing;component;distributed group;distributed hash table;erasure coding;group locality;network locality;peer-to-peer file system}, 
doi={10.1109/SOCA.2009.5410452}, 
ISSN={2163-2871}, 
month={Jan},}
@INPROCEEDINGS{4736170, 
author={D. W. Bauer and M. Mohtashemi}, 
booktitle={2008 Winter Simulation Conference}, 
title={An application of parallel Monte Carlo modeling for real-time disease surveillance}, 
year={2008}, 
pages={1029-1037}, 
abstract={The global health, threatened by emerging infectious diseases, pandemic influenza, and biological warfare, is becoming increasingly dependent on the rapid acquisition, processing, integration and interpretation of massive amounts of data. In response to these pressing needs, new information infrastructures are needed to support active, real time surveillance. Detection algorithms may have a high computational cost in both the time and space domains. High performance computing platforms may be the best approach for efficiently computing these algorithms. Unfortunately, these platforms are unavailable to many health care agencies. Our work focuses on efficient parallelization of outbreak detection algorithms within the context of cloud computing as a high throughput computing platform. Cloud computing is investigated as an approach to meet real time constraints and reduce or eliminate costs associated with real time disease surveillance systems.}, 
keywords={Internet;Monte Carlo methods;biohazards;diseases;health care;medical computing;parallel processing;surveillance;terrorism;biological warfare;cloud computing;detection algorithm;health care agency;pandemic influenza;parallel Monte Carlo modeling;real-time disease surveillance;Biological system modeling;Cloud computing;Detection algorithms;Diseases;High performance computing;Influenza;Monte Carlo methods;Pressing;Real time systems;Surveillance}, 
doi={10.1109/WSC.2008.4736170}, 
ISSN={0891-7736}, 
month={Dec},}
@INPROCEEDINGS{5190364, 
author={V. D. Cunsolo and S. Distefano and A. Puliafito and M. Scarpa}, 
booktitle={2009 Eighth IEEE International Symposium on Network Computing and Applications}, 
title={Volunteer Computing and Desktop Cloud: The Cloud@Home Paradigm}, 
year={2009}, 
pages={134-139}, 
abstract={Only commercial cloud solutions have been implemented so far, offering computing resources and services for renting. Some interesting projects, such as Nimbus, OpenNEbula, Reservoir, work on cloud. One of their aims is to provide a cloud infrastructure able to provide and share resources and services for scientific purposes. The encouraging results of volunteer computing projects in this context and the flexibility of the cloud, suggested to address our research efforts towards a combined new computing paradigm we named Cloud@Home.On one hand it can be considered as a generalization of the @homephilosophy, knocking down the barriers of volunteer computing, and also allowing to share more general services. On the other hand, Cloud@Home can be considered as the enhancement of the grid-utility vision of cloud computing. In this new paradigm, userspsila hosts are not passive interface to cloud services anymore, but they can interact (free or by charge) with other clouds. In this paper we present the Cloud@Home paradigm, highlighting its contribution to the actual state of the art on the topic of distributed and cloud computing. We detail the functional architecture and the core structure implementing such paradigm, demonstrating how it is really possible to build up a Cloud@Home infrastructure.}, 
keywords={distributed processing;grid computing;resource allocation;software architecture;@homephilosophy;Cloud@Home;Nimbus project;OpenNEbula project;Reservoir project;core structure;desktop cloud;distributed computing;functional architecture;grid-utility vision;resource sharing;scientific purposes;volunteer computing projects;work on cloud project;Cloud computing;Computer applications;Computer networks;Distributed computing;Grid computing;Hardware;Mashups;Reservoirs;Scientific computing;Service oriented architecture}, 
doi={10.1109/NCA.2009.41}, 
month={July},}
@INPROCEEDINGS{5336521, 
author={V. Vinge}, 
booktitle={2009 8th IEEE International Symposium on Mixed and Augmented Reality}, 
title={Mixed and augmented reality: #x201C;Scary and wondrous #x201D;}, 
year={2009}, 
pages={vii-vii}, 
abstract={Summary form only given. Mixed and augmented reality is the nature of the supporting infrastructure.Its current incarnation is cloud computing versus microcontrollers distributed throughout the environment.Ubiquity has always been a catchword of the distributed processing enthusiasts, and each new generation has pushed the idea beyond the horizons of the previous generation. Imagine an environment where most physical objects know where they are, what they are, and can (in principle) network with any other object. With this infrastructure, reality becomes its own database.Multiple consensual virtual environments are possible, each oriented to the needs of its constituency. If we also have open standards, then bottom-up social networks and even bottom-up advertising become possible.Then the physical world becomes much more like a software construct. The possibilities are both scary and wondrous.}, 
keywords={Web services;augmented reality;distributed processing;microcontrollers;social networking (online);augmented reality;bottom-up social network;cloud computing;distributed processing;microcontroller;mixed reality;multiple consensual virtual environment;open standard;physical object;software construct;Advertising;Augmented reality;Cloud computing;Distributed processing;Image databases;Microcontrollers;Object oriented databases;Social network services;Software standards;Virtual environment}, 
doi={10.1109/ISMAR.2009.5336521}, 
month={Oct},}
@INPROCEEDINGS{5207924, 
author={X. Kong and J. Huang and C. Lin and P. D. Ungsunan}, 
booktitle={2009 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
title={Performance, Fault-Tolerance and Scalability Analysis of Virtual Infrastructure Management System}, 
year={2009}, 
pages={282-289}, 
abstract={The virtual infrastructure has become more and more popular in the grid and cloud computing. With the aggrandizement scale, the management of the resources in virtual infrastructure faces a great technical challenge. To support the upper services effectively, it raises higher requirements for the performance, fault-tolerance and scalability of virtual infrastructure management systems. In this paper, we study the performance, fault-tolerance and scalability of virtual infrastructure management systems with the three typical structures, including centralized, hierarchical and peer-to-peer structures. We give the mathematical definition of the evaluation metrics and give detailed quantitative analysis, and then get several useful conclusions for enhancing the performance, fault-tolerance and scalability, based on the quantitative analysis. We believe that the results of this work will help system architects make informed choices for building virtual infrastructure.}, 
keywords={grid computing;peer-to-peer computing;software fault tolerance;software performance evaluation;virtual reality;aggrandizement scale;cloud computing;evaluation metrics;fault-tolerance analysis;grid computing;peer-to-peer structures;performance analysis;quantitative analysis;scalability analysis;virtual infrastructure management system;Cloud computing;Fault tolerance;Fault tolerant systems;Grid computing;Large-scale systems;Peer to peer computing;Performance analysis;Resource management;Scalability;Voice mail;fault-tolerance;performance;scalability;virtual infrastructure management system}, 
doi={10.1109/ISPA.2009.24}, 
ISSN={2158-9178}, 
month={Aug},}
@INPROCEEDINGS{5284143, 
author={Q. Wang and R. Deters}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={SOA's Last Mile-Connecting Smartphones to the Service Cloud}, 
year={2009}, 
pages={80-87}, 
abstract={Modern Smartphones are the fastest growing computing platforms capable of consuming Web services. However, due to their form factor these mobile computing devices face many challenges and constrains when engaging service providers. How to overcome these challenges and how to link smartphones to the service cloud is one of the key issues that will have a major impact on the further growth of the software-as-a-service (SaaS) and software-plus-service (S+S) deployments. This paper focuses on the use of a cloud hosted middleware layer that acts as a personal service bus (PSB). Similar to an ESB the PSB offers a user and device customized view on services of the cloud by enabling protocol transformation, request/response augmentation, message optimization, caching and pre-fetching. The paper also reports on an evaluation of the PSB called Mobile Cloud Computing Middleware (MCCM) with the G1 (HTC).}, 
keywords={Internet;mobile computing;mobile handsets;Web services;caching;cloud hosted middleware layer;computing platform;message optimization;mobile cloud computing middleware;mobile computing device;personal service bus;protocol transformation;service cloud;smartphones;software-as-a-service;software-plus-service;Cloud computing;Costs;Middleware;Mobile computing;Personal digital assistants;Simple object access protocol;Smart phones;Uniform resource locators;Web services;XML;Cloud;Middleware;Mobile}, 
doi={10.1109/CLOUD.2009.73}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5188871, 
author={Jin Heo and X. Zhu and P. Padala and Z. Wang}, 
booktitle={2009 IFIP/IEEE International Symposium on Integrated Network Management}, 
title={Memory overbooking and dynamic control of Xen virtual machines in consolidated environments}, 
year={2009}, 
pages={630-637}, 
abstract={The newly emergent cloud computing environments host hundreds to thousands of services on a shared resource pool. The sharing is enhanced by virtualization technologies allowing multiple services to run in different virtual machines (VMs) on a single physical node. Resource over-booking allows more services with time-varying demands to be consolidated reducing operational costs. In the past, researchers have studied dynamic control mechanisms for allocating CPU to virtual machines, when CPU is over-booked with respect to the sum of the peak demands from all the VMs. However, runtime re-allocation of memory among multiple VMs has not been widely studied, except on VMware platforms. In this paper, we present a case study where feedback control is used for dynamic memory allocation to Xen virtual machines in a consolidated environment. We illustrate how memory behaves differently from CPU in terms of its relationship to application-level performance, such as response times. We have built a prototype of a joint resource control system for allocating both CPU and memory resources to co-located VMs in real time. Experimental results show that our solution allows all the hosted applications to achieve the desired performance in spite of their time-varying CPU and memory demands, whereas a solution without memory control incurs significant service level violations.}, 
keywords={resource allocation;storage allocation;virtual machines;workstation clusters;VMware platforms;Xen virtual machines;cloud computing environments;dynamic control mechanisms;dynamic memory allocation;dynamic resource allocation;joint resource control system;memory over-booking;operational costs reduction;resource over-booking;shared resource pool;virtualization technologies;Cloud computing;Control systems;Costs;Delay;Feedback control;Prototypes;Resource management;Runtime;Virtual machining;Voice mail;application performance;consolidation;dynamic control;resource overbooking;virtualization}, 
doi={10.1109/INM.2009.5188871}, 
ISSN={1573-0077}, 
month={June},}
@INPROCEEDINGS{5360419, 
author={W. Gao and R. Grossman and P. S. Yu and Y. Gu}, 
booktitle={2009 IEEE International Conference on Data Mining Workshops}, 
title={Why Naive Ensembles Do Not Work in Cloud Computing}, 
year={2009}, 
pages={282-289}, 
abstract={One of the greatest challenges of data mining is dealing with very large datasets. Cloud computing has demonstrated great advantages in processing very large datasets. When considering taking advantage of the high performance data cloud to do data mining, there are different approaches to make an existing data mining algorithm parallelizable in a cloud computing environment. One concern is how to achieve better performance by making use of the data in a more intelligent way. In this paper, we describe two different approaches to parallelize the existing random decision tree mining algorithm, which we have built on the sector/sphere cloud computing environment. We compare the cost and accuracy between those two different implementations and analyze the result of this experimental study.}, 
keywords={data mining;decision trees;random processes;cloud computing;data mining;random decision tree mining algorithm;Cloud computing;Clustering algorithms;Computer networks;Conferences;Costs;Data mining;Data processing;Decision trees;Machine learning algorithms;Training data}, 
doi={10.1109/ICDMW.2009.85}, 
ISSN={2375-9232}, 
month={Dec},}
@INPROCEEDINGS{5407223, 
author={K. Hazra}, 
booktitle={2009 4th International Conference on Computers and Devices for Communication (CODEC)}, 
title={Cloud computing - the next chasm}, 
year={2009}, 
pages={1-1}, 
abstract={Summary form only given. The word "cloud computing" is creating a buzz in the IT Industry today and is being looked upon as the foundation of the "fourth wave" of technology termed as "IT everywhere". While the different companies are gearing up to be a part of the "cloud" the significant drivers of this new paradigm are lowering of cost and increasing efficiencies. We read about Google, Salesforce and Amazon moving up the value chain in their offerings and providing services in the generic domain of "Xaas" These includes terms like Infrastructure as a service, platform as a service, software as a service etc etc. There are key customer issues around cloud and as a principle there is no one single solution that fits all, every situation is unique and brings along its own set of challenges and therefore solutions. Further, there are implications associated with every organization in terms of identifying the core issues and finding the "right" solution at the "right" price. If we talk to any CIO in the audience today and ask him what keeps him awake at night, one of the points will be the relentless pressure on cost. The question is is the cloud the all pervasive answer to all his woes? The objective of this session is to unravel the myth, provide a background of what are the real scenarios being unraveled and explore some of the challenges associated with the current state of affairs where the cloud is positioned to deliver business outcomes rather than being just a hyped up term. It will provide insights of the different level of maturity the entire ecosystem is going through and finally will provide some key tenets of what Hewlett Packard is doing in this area to help customers and the IT ecosystem.}, 
keywords={Internet;Web sites;Amazon;Google;Hewlett Packard;IT Industry;IT ecosystem;Salesforce;cloud computing;software as a service;Cloud computing;Codecs;Communication industry;Computer industry;Costs;Ecosystems;Paper technology;Tag clouds}, 
month={Dec},}
@ARTICLE{5271524, 
author={H. E. Schaffer}, 
journal={IT Professional}, 
title={X as a Service, Cloud Computing, and the Need for Good Judgment}, 
year={2009}, 
volume={11}, 
number={5}, 
pages={4-5}, 
abstract={The paper talks about the spreading "X as a service" phenomenon in the IT arena, cloud computing, and SLA. In the article, the author mentioned that "X as a Service" has entered the vocabulary in many forms, mostly in computing aspect. Also, cloud computing can lead to significant savings as well as significant service improvements. Cloud computing vendors would like to reap most of those benefits.It can change this by bringing past experiences and good judgment into play and adapt them to new situation. That is the mark of being a "professional" in IT field. Experience, understanding, and thoughtfulness can help the contract people write an effective service level agreement (SLA) that puts its needs in good legal form. Ideally the SLA will include all needed services and none that aren't needed.}, 
keywords={Internet;industrial property;information services;social aspects of automation;X as a service phenomenon;cloud computing;cloud computing vendor;Cloud computing;Computer aided analysis;Contracts;Data security;Databases;Law;Legal factors;Outsourcing;Time sharing computer systems;Vocabulary;IT Professional;data management;from the editors;information technology;networking and communications;services}, 
doi={10.1109/MITP.2009.112}, 
ISSN={1520-9202}, 
month={Sept},}
@INPROCEEDINGS{5284146, 
author={Y. Chen and T. Wo and J. Li}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={An Efficient Resource Management System for On-Line Virtual Cluster Provision}, 
year={2009}, 
pages={72-79}, 
abstract={As a prevalent paradigm for flexible, scalable and on-demand provisions of computing services, Cloud computing can be an alternative platform for scientific computing. In this paper, we propose an efficient resource management system for on-line virtual clusters provision, aiming to provide immediately-available virtual clusters for academic users. Particularly, we investigated two crucial problems: efficient VM image management and intelligent resource mapping, either of them has remarkable impact on the performance of the system. VM image management includes image preparation and local image management on physical resources. A resource mapping refers to a mapping from userpsilas resource constraints to specific physical resources. We explore how to simplify VM image management and reduce image preparation overhead by the multicast file transferring and image caching/reusing. Additionally, the Load-Aware Mapping, a novel resource mapping strategy, is proposed in order to further reduce deploying overhead and make efficient use of resources. The strategy takes account of both image cache and VM load distribution information. System evaluation is conducted through various real stress workloads, and results show that our approaches are effective comparing to other common solutions.}, 
keywords={resource allocation;ubiquitous computing;cloud computing;image caching;intelligent resource mapping;load-aware mapping;multicast file transferring method;online virtual cluster;resource management;virtual machine image management;Resource management;Cloud computing;On-line Provision;Resource Management;Resource Mapping;VM Image Management;Virtual Cluster}, 
doi={10.1109/CLOUD.2009.64}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{4637787, 
author={L. Wang and J. Tao and M. Kunze and A. C. Castellanos and D. Kramer and W. Karl}, 
booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
title={Scientific Cloud Computing: Early Definition and Experience}, 
year={2008}, 
pages={825-830}, 
abstract={Cloud computing emerges as a new computing paradigm which aims to provide reliable, customized and QoS guaranteed computing dynamic environments for end-users. This paper reviews recent advances of Cloud computing, identifies the concepts and characters of scientific Clouds, and finally presents an example of scientific Cloud for data centers}, 
keywords={Web services;natural sciences computing;quality of service;QoS guaranteed computing;Web service;customized computing environment;reliable computing environment;scientific cloud computing;Ambient intelligence;Cloud computing;Computer industry;Grid computing;High performance computing;Image storage;Resource management;Scientific computing;Virtual machining;Web services}, 
doi={10.1109/HPCC.2008.38}, 
month={Sept},}
@INPROCEEDINGS{5158440, 
author={W. Wang and C. Amza}, 
booktitle={2009 29th IEEE International Conference on Distributed Computing Systems}, 
title={On Optimal Concurrency Control for Optimistic Replication}, 
year={2009}, 
pages={317-326}, 
abstract={Concurrency control is a core component in optimistic replication systems. To detect concurrent updates, the system associates each replicated object with metadata, such as, version vectors or causal graphs exchanged on synchronization opportunities. However, the size of such metadata increases at least linearly with the number of active sites. With trends in cloud computing, multi-regional collaboration, and mobile networks, the number of sites within a single replication system becomes very large. This imposes substantial overhead in communication and computation on every site. In this paper, we first present three version vector implementations that significantly reduce the cost of vector exchange by incrementally transferring vector elements. Basic rotating vectors (BRV) support systems providing no conflict reconciliation, whereas conflict rotating vectors (CRV) extend BRV to overcome this limitation. Skip rotating vectors (SRV) based on CRV further reduce data transmission. We show that both BRV and SRV are optimal implementations of version vectors, which, in turn, have minimal storage complexity among all known concurrency control schemes for state-transfer systems. We then present a causal graph exchange algorithm for operation-transfer systems with optimal communication overhead. All these algorithms adopt network pipelining to reduce running time.}, 
keywords={concurrency control;graph theory;meta data;basic rotating vectors support systems;causal graph exchange algorithm;cloud computing;concurrent update detection;conflict rotating vectors;metadata;mobile networks;multiregional collaboration;network pipelining;operation-transfer systems;optimal communication overhead;optimal concurrency control;optimistic replication systems;single replication system;skip rotating vectors;state-transfer systems;version vectors;Availability;Cloud computing;Collaboration;Concurrency control;Control systems;Costs;Distributed computing;Mobile computing;Object detection;Scalability}, 
doi={10.1109/ICDCS.2009.71}, 
ISSN={1063-6927}, 
month={June},}
@INPROCEEDINGS{4738445, 
author={I. Foster and Y. Zhao and I. Raicu and S. Lu}, 
booktitle={2008 Grid Computing Environments Workshop}, 
title={Cloud Computing and Grid Computing 360-Degree Compared}, 
year={2008}, 
pages={1-10}, 
abstract={Cloud computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for cloud computing and there seems to be no consensus on what a cloud is. On the other hand, cloud computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established grid computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast cloud computing with grid computing from various angles and give insights into the essential characteristics of both.}, 
keywords={grid computing;cloud computing;cluster computing;distributed system;grid computing;utility computing;Cloud computing;Computer science;Computer vision;Costs;Distributed computing;Economies of scale;Grid computing;Laboratories;Large-scale systems;Standards organizations}, 
doi={10.1109/GCE.2008.4738445}, 
ISSN={2152-1085}, 
month={Nov},}
@INPROCEEDINGS{5342101, 
author={T. C. Chieu and A. Mohindra and A. A. Karve and A. Segal}, 
booktitle={2009 IEEE International Conference on e-Business Engineering}, 
title={Dynamic Scaling of Web Applications in a Virtualized Cloud Computing Environment}, 
year={2009}, 
pages={281-286}, 
abstract={Scalability is critical to the success of many enterprises currently involved in doing business on the Web and in providing information that may vary drastically from one time to another. Maintaining sufficient resources just to meet peak requirements can be costly. Cloud computing provides a powerful computing model that allows users to access resources on-demand. In this paper, we will describe a novel architecture for the dynamic scaling of Web applications based on thresholds in a virtualized cloud computing environment. We will illustrate our scaling approach with a front-end load-balancer for routing and balancing user requests to Web applications deployed on Web servers installed in virtual machine instances. A dynamic scaling algorithm for automated provisioning of virtual machine resources based on threshold number of active sessions will be introduced. The on-demand capability of the cloud to rapidly provision and dynamically allocate resources to users will be discussed. Our work has demonstrated the compelling benefits of the cloud which is capable of handling sudden load surges, delivering IT resources on-demands to users, and maintaining higher resource utilization, thus reducing infrastructure and management costs.}, 
keywords={Internet;resource allocation;virtual machines;Web application;dynamic scaling algorithm;resource allocation;resource on-demand;virtual machine;virtualized cloud computing environment;Application virtualization;Cloud computing;Computer architecture;Heuristic algorithms;Resource management;Routing;Scalability;Service oriented architecture;Virtual machining;Web server;Cloud computing;Scalability;Virtual machine;Virtualization}, 
doi={10.1109/ICEBE.2009.45}, 
month={Oct},}
@INPROCEEDINGS{4670143, 
author={W. Chou}, 
booktitle={2008 IEEE International Conference on Web Services}, 
title={Web Services: Software-as-a-Service (SaaS), Communication}, 
year={2008}, 
pages={1-1}, 
abstract={Web services is a fast moving research field with a profound impact to many critical research areas, ranging from software to communication, from server platforms to mobile endpoints. It emerges as a disruptive technology to various enterprises to deliver services, computing, communication and information to their customers and partners. This talk intends to capture some recent advances of Web services and new Web services applications in software-as-a-services, cloud computing, communication, message centric SOAP engine design, and mobile services computing endpoints. In addition to present the technical perspectives and extension potentials in these new developments, I would like to fill the gap between academic research and industry applications through real examples and use cases, with a goal to demonstrate how these technical advances of Web services are applied to industry products and applications, Standards, servers, clients, and new paradigms in software design and testing.}, 
keywords={Web services;program testing;Web services;cloud computing;message centric SOAP engine design;software design;software testing;software-as-a-services;Application software;Cloud computing;Computer industry;Engines;Industry applications;Mobile communication;Mobile computing;Simple object access protocol;Software standards;Web services}, 
doi={10.1109/ICWS.2008.140}, 
month={Sept},}
@INPROCEEDINGS{5071469, 
author={A. Agarwal}, 
booktitle={2009 3rd ACM/IEEE International Symposium on Networks-on-Chip}, 
title={Keynote 3 (Banquet Talk) Digital space}, 
year={2009}, 
pages={213-213}, 
abstract={The multicore trend is universal. Spanning embedded processors, desktop CPUs and DSPs, supercomputers and cloud computing, multicore processors offer a game-changing opportunity for improvements in power efficiency and processing performance. More than anything else, multicores have put on-chip interconnect front and center in terms of design attention, since it has a first order impact on multicore performance, power efficiency, and even ease of programming. This talk will provide the inside scoop on our experiences with onchip interconnect in university research with the 16-core Raw multicore processor, in a commercial environment with Tilera's 64-core Tile processor, and conclude with some startling predictions for future 1000 core processors.}, 
keywords={embedded systems;microprocessor chips;multiprocessor interconnection networks;16-core Raw multicore processor;DSPs;cloud computing;desktop CPUs;digital space;multicore trend;on-chip interconnect front;power efficiency;spanning embedded processors;supercomputers;Computer architecture;Computer science;Digital signal processing;Education;Integrated circuit interconnections;Laboratories;Microphone arrays;Microprocessors;Multicore processing;Supercomputers}, 
doi={10.1109/NOCS.2009.5071469}, 
month={May},}
@INPROCEEDINGS{5071907, 
author={N. Yigitbasi and A. Iosup and D. Epema and S. Ostermann}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={C-Meter: A Framework for Performance Analysis of Computing Clouds}, 
year={2009}, 
pages={472-477}, 
abstract={Cloud computing has emerged as a new technology that provides large amounts of computing and data storage capacity to its users with a promise of increased scalability, high availability, and reduced administration and maintenance costs. As the use of cloud computing environments increases, it becomes crucial to understand the performance of these environments. So, it is of great importance to assess the performance of computing clouds in terms of various metrics, such as the overhead of acquiring and releasing the virtual computing resources, and other virtualization and network communications overheads. To address these issues, we have designed and implemented C-Meter, which is a portable, extensible, and easy-to-use framework for generating and submitting test workloads to computing clouds. In this paper, first we state the requirements for frameworks to assess the performance of computing clouds. Then, we present the architecture of the C-Meter framework and discuss several cloud resource management alternatives. Finally, we present our early experiences with C-Meter in Amazon EC2. We show how C-Meter can be used for assessing the overhead of acquiring and releasing the virtual computing resources, for comparing different configurations, and for evaluating different scheduling algorithms.}, 
keywords={Web services;file organisation;cloud computing;cloud resource management alternatives;data storage capacity;network communications overheads;performance analysis;virtual computing resources;Availability;Cloud computing;Computer networks;Costs;Memory;Performance analysis;Portable computers;Resource virtualization;Scalability;Testing;cloud;performance;resource management}, 
doi={10.1109/CCGRID.2009.40}, 
month={May},}
@INPROCEEDINGS{5342047, 
author={H. H. Chang and P. B. Chou and S. Ramakrishnan}, 
booktitle={2009 IEEE International Conference on e-Business Engineering}, 
title={An Ecosystem Approach for Healthcare Services Cloud}, 
year={2009}, 
pages={608-612}, 
abstract={Patient-centric healthcare and evidence-based medicine with the emphasis on prevention and wellness promise to deliver better and more affordable healthcare. At minimal, they require health related information to be shared among a community including patients, providers, payers, and regulators. It is important for IT systems to facilitate information sharing within such communities. Furthermore, we argue that it is highly valuable to develop IT technologies that can foster sustainable healthcare ecosystems for collaborative, coordinated healthcare delivery. The emerging cloud computing appears well-suited to meet the demand of a broad set of health service scenarios. In particular, the concept of shared infrastructure and services provides the foundation for supporting healthcare service ecosystems. This paper proposes an ecosystem approach to identify high-level requirements for cloud computing technologies to provide hosting environments for sustainable healthcare ecosystems. We draw the lessons and principles from the sustainable ecological ecosystems, review some of the existing IT-enabled healthcare ecosystems, and provide our view on the imperatives for cloud computing research to support future healthcare IT needs.}, 
keywords={health care;medical information systems;IT system;cloud computing;;evidence-based medicine;healthcare service cloud;information system;patient-centric healthcare;sustainable healthcare ecosystem;Cloud computing;Collaboration;Costs;Couplings;Diseases;Ecosystems;Information management;Medical services;Medical treatment;Technological innovation;cloud computing;ecosystems;evidence-based medicine;healthcare;patient-centric}, 
doi={10.1109/ICEBE.2009.98}, 
month={Oct},}
@INPROCEEDINGS{5195324, 
booktitle={2009 International Conference on High Performance Computing Simulation}, 
title={[Copyright notice]}, 
year={2009}, 
pages={lviii-lviii}, 
abstract={The following topics are dealt with: cloud computing; graphical processing unit; scientific computing; data structure; software fault tolerant; reliable system design; microprocessor chips; cache coherent protocol; Web server; service-oriented architecture; parallel remote sensing; transaction processing; medical image segmentation; Matlab; large data sets; video steganalysis; image compression; mobile robot; IEEE 802.16 QPSK radio link; and biometric authentication.}, 
keywords={Internet;biometrics (access control);computer graphic equipment;data compression;data structures;file servers;image segmentation;medical image processing;message authentication;microprocessor chips;mobile robots;protocols;radio links;remote sensing;software architecture;software fault tolerance;steganography;very large databases;IEEE 802.16 QPSK radio link;Matlab;Web server;biometric authentication;cache coherent protocol;cloud computing;data structure;face recognition;graphical processing unit;image compression;large data sets;medical image segmentation;microprocessor chips;mobile robot;parallel remote sensing;reliable system design;scientific computing;service-oriented architecture;software fault tolerant;transaction processing;video steganalysis}, 
doi={10.1109/HPCSIM.2009.5195324}, 
month={June},}
@INPROCEEDINGS{5160911, 
author={D. Kondo and B. Javadi and P. Malecot and F. Cappello and D. P. Anderson}, 
booktitle={2009 IEEE International Symposium on Parallel Distributed Processing}, 
title={Cost-benefit analysis of Cloud Computing versus desktop grids}, 
year={2009}, 
pages={1-12}, 
abstract={Cloud Computing has taken commercial computing by storm. However, adoption of cloud computing platforms and services by the scientific community is in its infancy as the performance and monetary cost-benefits for scientific applications are not perfectly clear. This is especially true for desktop grids (aka volunteer computing) applications. We compare and contrast the performance and monetary cost-benefits of clouds for desktop grid applications, ranging in computational size and storage. We address the following questions: (i) What are the performance tradeoffs in using one platform over the other? (ii) What are the specific resource requirements and monetary costs of creating and deploying applications on each platform? (iii) In light of those monetary and performance cost-benefits, how do these platforms compare? (iv) Can cloud computing platforms be used in combination with desktop grids to improve cost-effectiveness even further? We examine those questions using performance measurements and monetary expenses of real desktop grids and the Amazon elastic compute cloud.}, 
keywords={Web services;cost-benefit analysis;grid computing;Web service;cloud computing;cost-benefit analysis;desktop grid application;volunteer computing application;Cloud computing;Computer applications;Cost benefit analysis;Distributed computing;Grid computing;Internet;Java;Measurement;Storms;Virtual colonoscopy}, 
doi={10.1109/IPDPS.2009.5160911}, 
ISSN={1530-2075}, 
month={May},}
@ARTICLE{4476216, 
author={G. Lawton}, 
journal={Computer}, 
title={Moving the OS to the Web}, 
year={2008}, 
volume={41}, 
number={3}, 
pages={16-19}, 
abstract={With the increasing use of high-speed Internet technologies, the concept of cloud computing has become more popular. In cloud computing, users work with Web-based, rather than local, storage and software. These applications are accessible via a browser and look and act like desktop programs.}, 
keywords={Internet;operating systems (computers);Internet technology;Web operating system;World Wide Web;cloud computing;Application software;Cloud computing;Collaborative work;Computer applications;File systems;Internet;Operating systems;Productivity;Scattering;Sun;Web-based operating systems;cloud computing}, 
doi={10.1109/MC.2008.94}, 
ISSN={0018-9162}, 
month={March},}
@INPROCEEDINGS{5071864, 
author={M. Dalheimer and F. J. Pfreundt}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={GenLM: License Management for Grid and Cloud Computing Environments}, 
year={2009}, 
pages={132-139}, 
abstract={Software license management allows independent software vendors (ISVs) to control the access of their products. It is a fundamental part of the ISVs' business strategy. A wide range of products has been developed in order to address license management. There are, however, only few ongoing works with regard to license management in grid and cloud computing environments. This paper presents our work on GenLM, a license management solution suitable for these environments. It has been built in order to provide a secure and robust solution for ISVs that want to extend their software usage to these systems. We provide ISVs a toolchain to implement arbitrary software licensing models. At the same time we ensure that licenses are mobile, i.e. they can be used on any resource the user has access to.}, 
keywords={DP industry;grid computing;middleware;software development management;GenLM;cloud computing;grid computing;independent software vendors;software license management;Cloud computing;Environmental management;Licenses;cloud computing;cryptography;grid computing;license management;protocol engineering}, 
doi={10.1109/CCGRID.2009.31}, 
month={May},}
@INPROCEEDINGS{5284223, 
author={J. Namjoshi and A. Gupte}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={Service Oriented Architecture for Cloud Based Travel Reservation Software as a Service}, 
year={2009}, 
pages={147-150}, 
abstract={Cloud is gaining popularity as means for saving cost of IT ownership and accelerating time to market due to ready-to-use, dynamically scalable computing infrastructure and software services offered on cloud on pay-per-use basis. Design of software solution for delivery as a shared service over cloud requires specific considerations. In this paper we describe an approach for design of travel reservations solution for use by corporate business travelers based on service oriented architecture, software-as-a-service, and cloud computing paradigms.}, 
keywords={Web services;reservation computer systems;software architecture;travel industry;IT ownership;cloud computing paradigm;cloud-based travel reservation software-as-a-service design;corporate business travel;cost saving;dynamically-scalable computing infrastructure;pay-per-use service;service oriented architecture;shared software service delivery;Acceleration;Availability;Cloud computing;Costs;Distributed computing;Service oriented architecture;Software design;Software reusability;Time to market;Travel services;Architecture;Cloud;IaaS;Infrastructure-as-a-Service;Multi-tenancy;SOA;SaaS;Software-as-a-Service;Travel Reservation as a Service}, 
doi={10.1109/CLOUD.2009.77}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{4534231, 
author={H. Liu and D. Orban}, 
booktitle={2008 Eighth IEEE International Symposium on Cluster Computing and the Grid (CCGRID)}, 
title={GridBatch: Cloud Computing for Large-Scale Data-Intensive Batch Applications}, 
year={2008}, 
pages={295-305}, 
abstract={To be competitive, enterprises are collecting and analyzing increasingly large amount of data in order to derive business insights. However, there are at least two challenges to meet the increasing demand. First, the growth in the amount of data far outpaces the computation power growth of a uniprocessor. The growing gap between the supply and demand of computation power forces Enterprises to parallelize their application code. Unfortunately, parallel programming is both time-consuming and error-prone. Second, the emerging Cloud Computing paradigm imposes constraints on the underlying infrastructure, which forces enterprises to rethink their application architecture. We propose the GridBatch system, which aims at solving large-scale data-intensive batch problems under the Cloud infrastructure constraints. GridBatch is a programming model and associated library that hides the complexity of parallel programming, yet it gives the users complete control on how data are partitioned and how computation is distributed so that applications can have the highest performance possible. Through a real client example, we show that GridBatch achieves high performance in Amazon's EC2 computing Cloud.}, 
keywords={batch processing (computers);grid computing;parallel programming;Cloud Computing;EC2 computing Cloud;GridBatch system;large-scale data-intensive batch applications;large-scale data-intensive batch problems;parallel programming;Cloud computing;Computer architecture;Concurrent computing;Distributed computing;Grid computing;High performance computing;Large-scale systems;Libraries;Parallel programming;Supply and demand;Amazon;Cloud Computing;EC2;GridBatch;MapReduce;S3}, 
doi={10.1109/CCGRID.2008.30}, 
month={May},}
@INPROCEEDINGS{5350011, 
author={R. Schwarzkopf and M. Schmidt and N. Fallenbeck and B. Freisleben}, 
booktitle={2009 35th Euromicro Conference on Software Engineering and Advanced Applications}, 
title={Multi-layered Virtual Machines for Security Updates in Grid Environments}, 
year={2009}, 
pages={563-570}, 
abstract={The use of user specific virtual machines (VMs) in Grid and Cloud computing reduces the administration overhead associated with manually installing required software for every user on every computational resource. However, a large number of user specific VMs increases the risk of security attacks. In particular, Cloud computing providers like Amazon suffer from these problems, since they offer different operating systems within VMs and delegate the security update problem for VMs to the users. In this paper, a solution that solves the problem by separating a VM into several layers is presented. The approach creates the possibility of installing security updates into a base layer centrally, affecting all VMs without affecting the users' own installed software stack by merging package databases. The proposal permits resource providers to keep a large number of VMs patched with the latest security fixes without bothering the users. Furthermore, the proposal avoids the overhead for transferring possible large VM images over the network between the nodes of a Grid or Cloud by allowing to hold locally cached VM images with a basic operating system installation while only the user-specific software stack stored in a separate layer needs to be transferred.}, 
keywords={grid computing;security of data;virtual machines;cloud computing;grid computing;grid environments;multilayered virtual machines;security attack risk;security updates;software stack;user specific virtual machines;Cloud computing;Data security;Grid computing;Merging;Operating systems;Proposals;Software packages;Virtual machining;Virtual manufacturing;Voice mail;Cloud Computing;Grid Computing;Layered Virtual Machines;Security Updates;Virtualization}, 
doi={10.1109/SEAA.2009.74}, 
ISSN={1089-6503}, 
month={Aug},}
@INPROCEEDINGS{5358085, 
author={Zehua Zhang and Xuejie Zhang}, 
booktitle={2009 IEEE International Conference on Intelligent Computing and Intelligent Systems}, 
title={Realization of open cloud computing federation based on mobile agent}, 
year={2009}, 
volume={3}, 
pages={642-646}, 
abstract={Although cloud computing is generally recognized as a technology which will has a significant impact on IT in the future. However, Cloud computing is still in its infancy, currently, there is not a standard available for it, portability and interoperability is also impossible between different Cloud Computing Service Providers, therefore, handicaps the widely deploy and quick development of cloud computing, there is still a long distance to the fine scenery which theoretically depicted by cloud computing. We analyze the problems in the current state of the art, put forward that Open Cloud Computing Federation is an inevitable approach for the widely use of cloud computing and to realize the greatest value of it. Accordingly, we proposal the MABOCCF (Mobile Agent Based Open Cloud Computing Federation) mechanism in this paper, it combines the advantages of Mobile Agent and cloud computing to provide a realization for the Open Cloud Computing Federation, MABOCCF can span over multiple heterogeneous Cloud Computing platforms and realizes portability and interoperability, it can be a beginning of open cloud computing federation and a future part of cloud computing. We also present in this paper the rationalities and the motivations for the combination of Mobile Agent and Cloud Computing, finally, a prototype is given with a performance analysis.}, 
keywords={Internet;mobile agents;cloud computing service providers;mobile agent;open cloud computing federation;Availability;Cloud computing;Computer industry;Computer networks;Distributed computing;Electric breakdown;Information science;Mobile agents;Scalability;Standards development;cloud computing;federation;interoperablility;mobile agent;portability}, 
doi={10.1109/ICICISYS.2009.5358085}, 
month={Nov},}
@INPROCEEDINGS{5359468, 
booktitle={2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: advances on computing mechanisms; computing applications in science; grid networks, services and applications; computational geometry; complex computing in application domains; and cloud computing.}, 
keywords={Internet;computational geometry;engineering computing;grid computing;advanced engineering computing;application domains;cloud computing;complex computing;computational geometry;computing application;grid networks}, 
doi={10.1109/ADVCOMP.2009.1}, 
month={Oct},}
@INPROCEEDINGS{4782564, 
author={K. A. Delic and J. A. Riley}, 
booktitle={2009 International Conference on Information, Process, and Knowledge Management}, 
title={Enterprise Knowledge Clouds: Next Generation KM Systems?}, 
year={2009}, 
pages={49-53}, 
abstract={We are witnessing the emergence of the global, dependable and efficient infrastructure of cloud computing. We assess the current state of the enterprise knowledge management field and project the possible emergence of enterprise knowledge clouds. We give some architectural views, discuss briefly the underlying technologies and describe roughly related applications. We conclude with possible developments in the next five to fifteen years.}, 
keywords={knowledge management;cloud computing;enterprise knowledge clouds;enterprise knowledge management;Blogs;Cloud computing;Collaboration;Computer architecture;Computer industry;Computer networks;Education;Knowledge management;Social network services;Web and internet services;Cloud computing;Enterprise Knowledge Management;Knowledge Clouds}, 
doi={10.1109/eKNOW.2009.28}, 
month={Feb},}
@INPROCEEDINGS{5255089, 
author={K. W. Lin and Y. C. Luo}, 
booktitle={2009 IEEE International Conference on Granular Computing}, 
title={A fast parallel algorithm for discovering frequent patterns}, 
year={2009}, 
pages={398-403}, 
abstract={Fast discovery of frequent patterns is the most extensively discussed problem in data mining fields due to its wide applications. As the size of database increases, the computation time and the required memory increase severely. The difficulty of mining large database launched the research of designing parallel and distributed algorithms to solve the problem. Most of the past studies tried to parallelize the computation by dividing the database and distribute the divided database to other nodes for mining. This approach might leak data out and evidently is not suitable to be applied to sensitive domains like health-care. In this paper, we propose a novel data mining algorithm named FD-Mine that is able to efficiently utilize the nodes to discover frequent patterns in cloud computing environments with data privacy preserved. Through empirical evaluations on various simulation conditions, the proposed FD-Mine delivers excellent performance in terms of scalability and execution time.}, 
keywords={data mining;data privacy;parallel algorithms;association rule mining;data mining algorithm;data privacy;database mining;distributed algorithm;fast parallel algorithm;frequent pattern discovery;Algorithm design and analysis;Cloud computing;Computational modeling;Concurrent computing;Data mining;Data privacy;Distributed algorithms;Distributed computing;Distributed databases;Parallel algorithms;Data mining;association rule mining;cloud computing;frequent pattern mining;privacy preserved}, 
doi={10.1109/GRC.2009.5255089}, 
month={Aug},}
@INPROCEEDINGS{5071532, 
author={S. Pearson}, 
booktitle={2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing}, 
title={Taking account of privacy when designing cloud computing services}, 
year={2009}, 
pages={44-52}, 
abstract={Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. In this paper the privacy challenges that software engineers face when targeting the cloud as their production environment to offer services are assessed, and key design principles to address these are suggested.}, 
keywords={data privacy;cloud computing services;software engineers;software privacy;Cloud computing;Data privacy;Databases;Design engineering;Humans;Law;Legal factors;Maintenance engineering;Production;Protection}, 
doi={10.1109/CLOUD.2009.5071532}, 
month={May},}
@ARTICLE{5233514, 
author={V. S. Pendyala and S. S. Y. Shim}, 
journal={Computer}, 
title={The Web as the Ubiquitous Computer}, 
year={2009}, 
volume={42}, 
number={9}, 
pages={90-92}, 
abstract={With the convergence of mobile smart devices, cloud computing, and software as a service, the Web is enabling anywhere, anytime computing.}, 
keywords={Internet;mobile computing;cloud computing;mobile smart device;ubiquitous computer;Cloud computing;Convergence;Mobile computing;Pervasive computing;Ubiquitous computing;Internet/Web;Ubiquitous Computer;Web technologies}, 
doi={10.1109/MC.2009.302}, 
ISSN={0018-9162}, 
month={Sept},}
@INPROCEEDINGS{5159213, 
author={M. Sato}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={Creating Next Generation Cloud Computing Based Network Services and the Contributions of Social Cloud Operation Support System (OSS) to Society}, 
year={2009}, 
pages={52-56}, 
abstract={Emerging virtualization technologies are making ubiquitous access to on-demand computing, network and storage resources to deliver various applications over public Internet. In this paper we present how the telecom operation support systems (OSS) that provide enterprise to enterprise (E2E) transactions, switching management, on-demand service management and scalability have evolved to provide next generation cloud management. Fujitsupsilas Social Cloud OSS provides multi-vendor, multi-network management, multi-layer Service Level Agreement (SLA) assurance, on-demand service management and impact analysis to businesses. The social cloud OSS service management solution for cloud computing will be the next killer application that will facilitate easy access to cloud services with appropriate SLAs and enable the society to use social networking applications that are currently being delivered using clouds.}, 
keywords={Internet;social networking (online);enterprise to enterprise transaction;network services;next generation cloud computing;on-demand service management;public Internet;social cloud operation support system;social networking;switching management;ubiquitous access;virtualization technologies;Application virtualization;Cloud computing;Computer networks;IP networks;Next generation networking;Pervasive computing;Resource virtualization;Scalability;Telecommunication computing;Telecommunication switching;Cloud Computing;Data Center Management;Operation Support System;Social OSS}, 
doi={10.1109/WETICE.2009.18}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{4780718, 
author={L. Mei and W. K. Chan and T. H. Tse}, 
booktitle={2008 IEEE Asia-Pacific Services Computing Conference}, 
title={A Tale of Clouds: Paradigm Comparisons and Some Thoughts on Research Issues}, 
year={2008}, 
pages={464-469}, 
abstract={Cloud computing is an emerging computing paradigm. It aims to share data, calculations, and services transparently among users of a massive grid. Although the industry has started selling cloud-computing products, research challenges in various areas, such as UI design, task decomposition, task distribution, and task coordination, are still unclear. Therefore, we study the methods to reason and model cloud computing as a step toward identifying fundamental research questions in this paradigm. In this paper, we compare cloud computing with service computing and pervasive computing. Both the industry and research community have actively examined these three computing paradigms. We draw a qualitative comparison among them based on the classic model of computer architecture. We finally evaluate the comparison results and draw up a series of research questions in cloud computing for future exploration.}, 
keywords={Web services;ubiquitous computing;cloud computing;cloud-computing products;computing paradigm;massive grid;pervasive computing;service computing;task coordination;task decomposition;task distribution;Application software;Cloud computing;Computer architecture;Computer industry;Computer networks;Distributed computing;History;Pervasive computing;Software engineering;Web services;cloud computing;paradigm comparison}, 
doi={10.1109/APSCC.2008.168}, 
month={Dec},}
@INPROCEEDINGS{5067515, 
author={G. C. Fox and A. Ho and E. Chan and W. Wang}, 
booktitle={2009 International Symposium on Collaborative Technologies and Systems}, 
title={Measured characteristics of distributed cloud computing infrastructure for message-based collaboration applications}, 
year={2009}, 
pages={465-467}, 
abstract={While the emerging cloud computing systems promise infrastructure resources to support application scalability, there are publications of systematic evaluation of this emerging information technology infrastructure in general, and no obvious publications for some representative collaboration applications in particular. We describe a methodology to study the characteristics of distributed cloud computing infrastructure for message-based collaboration applications.}, 
keywords={Web services;groupware;message passing;Web services;application scalability;distributed cloud computing system;information technology infrastructure;message-based collaboration application;Application software;Cloud computing;Collaboration;Collaborative tools;Image storage;Information technology;Linux;Quality of service;Scalability;Throughput}, 
doi={10.1109/CTS.2009.5067515}, 
month={May},}
@ARTICLE{5172883, 
author={M. Ingebretsen}, 
journal={IEEE Intelligent Systems}, 
title={In the News}, 
year={2009}, 
volume={24}, 
number={4}, 
pages={5-9}, 
abstract={GPU-enabled AI is a subset of so- called general-purpose GPU computing (GPGPU). But it promises to be one of the fastest-growing subsets. The rise of cloud computing, recent high-powered graphics-chip releases by AMD's competitor Nvidia, and the growing acceptance of the OpenCL programming platform have all converged to allow GPU-enabled AI to take off in the months ahead. AMD continues to work with partners such as OTOY, a developer of high-speed rendering technologies, on cloud computing initiatives such as its so-called Fusion Render Cloud.}, 
keywords={artificial intelligence;computer graphic equipment;rendering (computer graphics);AMD;Fusion Render Cloud;GPU computing;GPU-enabled AI;Nvidia;OTOY;OpenCL programming platform;cloud computing;rendering;Artificial intelligence;Bandwidth;Cloud computing;Graphics;High definition video;Intelligent systems;Rendering (computer graphics);Space technology;Streaming media;User interfaces;AI;AMD;Dennis Hong;GPU;HyDRAS;Hyper-Redundant Discrete Robotic Articulated Serpentine;Virginia Tech;artificial intelligence;froblins;graphics processing units;nvidia}, 
doi={10.1109/MIS.2009.77}, 
ISSN={1541-1672}, 
month={July},}
@ARTICLE{4755149, 
author={N. Leavitt}, 
journal={Computer}, 
title={Is Cloud Computing Really Ready for Prime Time?}, 
year={2009}, 
volume={42}, 
number={1}, 
pages={15-20}, 
abstract={Even though the technology faces several significant challenges, many vendors and industry observers predict a bright future for cloud computing.}, 
keywords={Internet;cloud computing;industry observers;vendor observers;Cloud computing;Computer networks;Costs;Internet;Operating systems;Personal communication networks;Portable computers;Scalability;Smart phones;Web server;IaaS;PaaS;SaaS;blades;cloud computing;data centers;grids;virtualization}, 
doi={10.1109/MC.2009.20}, 
ISSN={0018-9162}, 
month={Jan},}
@INPROCEEDINGS{5284131, 
author={H. Cai and K. Zhang and M. Wang and J. Li and L. Sun and X. Mao}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={Customer Centric Cloud Service Model and a Case Study on Commerce as a Service}, 
year={2009}, 
pages={57-64}, 
abstract={This paper proposes a cloud service model that centers around customer business requirements. The model covers the customers' subscribed services and the service providers' offered cloud services. It covers the relationship among offering versus subscription, cloud infrastructure service versus cloud application service, configuration versus customization of cloud services, etc. It then depicts a customer centric cloud service model which models the artifacts of enterprises owned by public serving cloud services. It's an extension of enterprise services to open service ecosystem leveraging the latest technical innovation of cloud computing. Later, this paper carries out a case study on an IBM software group ongoing project, commerce as a service, which aims to provide e-commerce functions as services over a cloud infrastructure.}, 
keywords={customer services;electronic commerce;IBM software group;cloud application service;cloud computing;cloud infrastructure service;commerce as a service;customer business requirements;customer centric cloud service model;e-commerce functions;enterprise services;open service ecosystem;service subscription;Business;Cloud computing}, 
doi={10.1109/CLOUD.2009.67}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5395121, 
author={G. Hughes and D. Al-Jumeily and A. Hussain}, 
booktitle={2009 Second International Conference on Developments in eSystems Engineering}, 
title={A Declarative Language Framework for Cloud Computing Management}, 
year={2009}, 
pages={279-284}, 
abstract={Cloud computing solutions have quickly become a hot topic in information technology circles. The proliferation of high performance, reliable and secure internet infrastructure, along with new, rich web development tools and technologies has meant that for the first time software can be hosted in a purely web based context. Many of the traditional software packages (especially business packages) that have historically been installed and used on local computers for decades are slowly but surely appearing online. The trend is undeniable and it is now not unreasonable to speculate that most business software packages will be purely web based in the not too distant future. With this centralisation of software, comes considerable management problems. These problems stem from the astronomical scale of the data centres that operate Cloud Computing solutions. This paper suggests a new declarative language framework that might address these management problems by automating the deployment and day to day operation of cloud computing solutions.}, 
keywords={Internet;information technology;security;software packages;software tools;Internet;Web based context;Web development tools;cloud computing;declarative language framework;information technology;reliable infrastructure;secure infrastructure;software packages;Application software;Cloud computing;Computer architecture;Costs;Information technology;Packaging;Software packages;Telecommunication computing;Web and internet services;Web server}, 
doi={10.1109/DeSE.2009.16}, 
month={Dec},}
@INPROCEEDINGS{5362864, 
author={P. Rodríguez and D. Gallego and J. Cerviño and F. Escribano and J. Quemada and J. Salvachúa}, 
booktitle={2009 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing}, 
title={VaaS: Videoconference as a service}, 
year={2009}, 
pages={1-11}, 
abstract={Internet is a place nowadays where interoperating services are offered which can be integrated or mashed up in order to fulfill user demands. This paper proposes a way to offer videoconference as a Web service over an interface which can be used by third parties to enrich their applications. This interface includes a security mechanism supporting delegated authorization to allow integration into third party's environments. Via this interface virtual rooms are provided where users can collaborate with audio, video, shared applications, IM, etc. An implementation of these concepts is described, including performance figures and validation results. We would finally like to stress that this architecture has been defined to support a scalable cloud computing service over the Internet.}, 
keywords={Web services;multimedia communication;security of data;software architecture;telecommunication computing;teleconferencing;Internet;Web service;cloud computing;security mechanism support;videoconference;virtual rooms;Authorization;Cloud computing;Collaboration;Computer architecture;Security;Stress;Video sharing;Videoconference;Web and internet services;Web services;Cloud computing;ROA;Real-Time Collaboration;SOA;Videoconferencing;Web}, 
doi={10.4108/ICST.COLLABORATECOM2009.8285}, 
month={Nov},}
@INPROCEEDINGS{5329110, 
author={R. Buyya}, 
booktitle={2009 Fourth ChinaGrid Annual Conference}, 
title={Market-oriented cloud computing: vision, hype, and reality of delivering computing as the 5th utility}, 
year={2009}, 
pages={xii-xv}, 
abstract={Computing is being transformed to a model consisting of services that are commoditised and delivered in a manner similar to utilities such as water, electricity, gas, and telephony. In such a model, users access services based on their requirements without regard to where the services are hosted. Several computing paradigms have promised to deliver this utility computing vision and they include Grid computing, P2P computing, and more recently Cloud computing. The latter term denotes the infrastructure as a "Cloud" in which businesses and users are able to access applications from anywhere in the world on demand. Cloud computing delivers infrastructure, platform, and software (application) as services, which are made available as subscription-based services in a pay-as-you-go model to consumers. These services in industry are respectively referred to as Infrastructure as a Service (Iaas), Platform as a Service (PaaS), and Software as a Service (SaaS). To realize Cloud computing, vendors such as Amazon, HP, IBM, and Sun are starting to create and deploy Clouds in various locations around the world. In addition, companies with global operations require faster response time, and thus save time by distributing workload requests to multiple Clouds in various locations at the same time. This creates the need for establishing a computing atmosphere for dynamically interconnecting and provisioning Clouds from multiple domains within and across enterprises. There are many challenges involved in creating such Clouds and Cloud interconnections. This keynote talk (1) presents the 21st century vision of computing and identifies various IT paradigms promising to deliver the vision of computing utilities; (2) defines the architecture for creating market-oriented Clouds and computing atmosphere by leveraging technologies such as VMs; (3) provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk man- gement to sustain SLA-oriented resource allocation; (4) presents the work carried out as part of our recent initiative in cloud computing, called as Megha: (i) Aneka, a software system for providing PaaS within private or public Clouds and supporting market-oriented resource management, (ii) internetworking of Clouds for dynamic creation of federated computing environments for scaling of elastic applications, (iii) creation of 3rd party Cloud brokering services for content delivery network and e-Science applications and their deployment on capabilities of IaaS providers such as Amazon and Nirvanix along with Grid mashups, and (iv) CloudSim supporting modelling and simulation of Clouds for performance studies; and (5) concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision along with pathways for future research.}, 
keywords={Web services;commerce;customer satisfaction;customer services;grid computing;peer-to-peer computing;resource allocation;risk management;Amazon;Aneka;CloudSim;Grid computing;Megha;Nirvanix;P2P computing;SLA-oriented resource allocation;cloud interconnections;computational risk management;content delivery network;customer-driven service management;e-Science application;infrastructure as a service;market-based resource management;market-oriented cloud computing;pay-as-you-go model;platform as a service;software as a service;subscription-based services;utility computing vision}, 
doi={10.1109/ChinaGrid.2009.6}, 
ISSN={1949-131X}, 
month={Aug},}
@ARTICLE{5189563, 
author={L. M. Kaufman}, 
journal={IEEE Security Privacy}, 
title={Data Security in the World of Cloud Computing}, 
year={2009}, 
volume={7}, 
number={4}, 
pages={61-64}, 
abstract={Today, we have the ability to utilize scalable, distributed computing environments within the confines of the Internet, a practice known as cloud computing. In this new world of computing, users are universally required to accept the underlying premise of trust. Within the cloud computing world, the virtual environment lets users access computing power that exceeds that contained within their own physical worlds. Typically, users will know neither the exact location of their data nor the other sources of the data collectively stored with theirs. The data you can find in a cloud ranges from public source, which has minimal security concerns, to private data containing highly sensitive information (such as social security numbers, medical records, or shipping manifests for hazardous material). Does using a cloud environment alleviate the business entities of their responsibility to ensure that proper security measures are in place for both their data and applications, or do they share joint responsibility with service providers? The answers to this and other questions lie within the realm of yet-to-be-written law. As with most technological advances, regulators are typically in a "catch-up" mode to identify policy, governance, and law. Cloud computing presents an extension of problems heretofore experienced with the Internet. To ensure that such decisions are informed and appropriate for the cloud computing environment, the industry itself should establish coherent and effective policy and governance to identify and implement proper security methods.}, 
keywords={Internet;law;security of data;Internet;cloud computing;data security;distributed computing;service providers;virtual environment;Cloud computing;Computer industry;Data security;Distributed computing;Hazardous materials;Information security;Internet;Physics computing;Regulators;Virtual environment;cloud computing;governance;it all depends;security}, 
doi={10.1109/MSP.2009.87}, 
ISSN={1540-7993}, 
month={July},}
@INPROCEEDINGS{5339583, 
author={Xin Huang and Tingting Zhang and Yifan Hou}, 
booktitle={2009 First International Conference on Future Information Networks}, 
title={ID management among clouds}, 
year={2009}, 
pages={237-241}, 
abstract={In the following years, the desktop-based applications will be changed to cloud computing gradually. Since all users' profile and context data will be stored on the service supplier side based on their ID. ID is becoming a security bottleneck: attackers can trace all other information via user ID. Increasingly, a simple service may be involved in a chain of service clouds; each cloud is able to access data in its cloud without the control of any technology. With ID and password cross utilization in clear text, leakage of ID profile and password in one cloud may propagate to the whole cloud chain. Without proper protection, the success of cloud computing will be threatened by ID privacy leakage. In this paper, privacy preserved ID profile utilizing protocol (PPID) is proposed to prevent this privacy flaw. PPID together with its extension ID anonymity protocol (IDA) separate ID and services. With these two protocols, threaten from crash of whole cloud chain caused by ID privacy leakage is minimized.}, 
keywords={data privacy;protocols;security of data;ID anonymity protocol;ID management;ID privacy leakage;ID profile utilizing protocol;cloud computing;password;security;Cloud computing;Computer crashes;Conference management;Context-aware services;Engineering management;Identity management systems;Information management;Privacy;Protection;Protocols}, 
doi={10.1109/ICFIN.2009.5339583}, 
month={Oct},}
@INPROCEEDINGS{5363824, 
author={P. Z. Yeh and C. A. Puri and A. Kass}, 
booktitle={2009 21st IEEE International Conference on Tools with Artificial Intelligence}, 
title={Towards a Technology Platform for Building Corporate Radar Applications that Mine the Web for Business Insight}, 
year={2009}, 
pages={477-484}, 
abstract={In this paper, we give a progress report on an ongoing effort at Accenture to develop a technology platform for building a wide range of corporate radar applications,which can turn the Web into a systematic source of business insight. Our goal is to share the platform we have developed and the lessons we have learned, so others can leverage this knowledge when building similar applications. We give an overview of this platform, which integrates a combination of established AI technologies - i.e. semantic models, natural language processing, and inference engines - in a novel way. We then illustrate the kinds of corporate radars that can be built with our platform through two applications we developed at Accenture: the technology lifecycle tracker, which assesses the maturity of technologies from the wireless industry, and the technology trend tracker, which measures hype versus reality for emerging technology trends such as cloud computing, software-as-a-service, and more. Finally, we discuss our experiences in using this platform to build these applications and the lessons learned.}, 
keywords={artificial intelligence;corporate modelling;data mining;electronic commerce;inference mechanisms;natural language processing;radar computing;AI technologies;Accenture;Web mining;building corporate radar applications;cloud computing;inference engines;natural language processing;semantic models;software-as-a-service;technology lifecycle tracker;wireless industry;Application software;Artificial intelligence;Bismuth;Companies;Event detection;Monitoring;Natural language processing;Radar applications;Radar tracking;Recruitment;Knowledge-Based Systems;NL;Ontology;Web Mining}, 
doi={10.1109/ICTAI.2009.106}, 
ISSN={1082-3409}, 
month={Nov},}
@ARTICLE{4804044, 
author={C. Hutchinson and J. Ward and K. Castilon}, 
journal={IT Professional}, 
title={Navigating the Next-Generation Application Architecture}, 
year={2009}, 
volume={11}, 
number={2}, 
pages={18-22}, 
abstract={In today's Internet environment, hyperconnectivity and new and complex technologies require a shift from individualized proprietary enterprise applications to a more open and dependent world of cloud computing. This article identifies changes IT professionals must understand to make the necessary adjustments to practices in today's evolving development space.}, 
keywords={Internet;software architecture;Internet;cloud computing;individualized proprietary enterprise applications;next-generation application architecture;service-oriented architecture;Application software;Cloud computing;Computer architecture;Feeds;Internet;Mashups;Navigation;Portals;Service oriented architecture;User interfaces;IT Professional;cloud computing;cutting edge;enterprise data}, 
doi={10.1109/MITP.2009.33}, 
ISSN={1520-9202}, 
month={March},}
@INPROCEEDINGS{7074401, 
author={C. A. Yfoulis and A. Gounaris}, 
booktitle={2009 European Control Conference (ECC)}, 
title={Honoring SLAs on cloud computing services: A control perspective}, 
year={2009}, 
pages={184-189}, 
abstract={This work contains a short survey of recent results in the literature with a view to opening up new research directions for the problem of honoring SLAs on cloud computing services. This is a new problem that has attracted significant interest recently, due to the urgent need for providers to provide reliable, customized and QoS guaranteed computing dynamic environments for end-users as agreed in contracts on the basis of certain Service Level Agreements (SLAs). Honoring SLAs is a multi-faceted problem that may involve optimal use of the available resources, optimization of the system's performance and availability or maximization of the provider's revenue and it poses a significant challenge for researchers and system administrators due to the volatile, huge and unpredictable Web environments where these computing systems reside. The use of algorithms possessing run-time adaptation features, such as dynamic resource allocation, admission control and optimization becomes an absolute must. As a continuation of the recent successful application of control theory concepts and methods to the computing systems area, our survey indicates that the problem of honoring SLAs on cloud computing services is a new interesting application for control theory and that researchers can benefit significantly from a number of well-known modern control methodologies, such as hybrid, supervisory, hierarchical and model predictive control.}, 
keywords={Internet;cloud computing;contracts;control engineering computing;quality of service;QoS guaranteed computing dynamic environments;SLAs;Web environments;cloud computing services;control theory concepts;run-time adaptation features;service level agreements;Cloud computing;Decision support systems;Europe;Handheld computers}, 
month={Aug},}
@INPROCEEDINGS{5284157, 
author={X. Li and Y. Li and T. Liu and J. Qiu and F. Wang}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={The Method and Tool of Cost Analysis for Cloud Computing}, 
year={2009}, 
pages={93-100}, 
abstract={Proposal of cloud computing is tightly coupled with low cost. Reduction of cost is considered as an important advantage of cloud. However, there are no available tools proper for cost calculation and analysis in Cloudenvironment. This paper presents our efforts towards filling in the gap. We format suits of metrics and formulas for the calculation of Cloud Total Cost of Ownership(TCO) and Utilization Cost, considering the elastic feature of Cloud infrastructure and widely adopted virtualization technology in Cloud. This provides afoundation for evaluating economic efficiency of Cloud and provides indications for cost optimization of Cloud.We have developed our calculation and analysis approach into a web tool which is used in the internal Cloud environment and demonstrate initially its analysis capability on the cost distribution and utilization imbalance factor.}, 
keywords={Internet;Cloud Total Cost of Ownership;Web tool;cloud computing;cost analysis;utilization cost;virtualization technology;Application software;Cloud computing;Computer industry;Cost function;Economies of scale;Environmental economics;Filling;Proposals;Resource management;Web server;Cloud computing;Ecnomic Scale;TCO}, 
doi={10.1109/CLOUD.2009.84}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5460878, 
author={H. Veith}, 
booktitle={2009 11th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
title={Embedding Formal Methods into Systems Engineering}, 
year={2009}, 
pages={11-11}, 
abstract={'Summary form only given.' Industrial computing is rapidly moving towards systems that exhibit vast amounts of internal concurrency and communication, most visibly in many-core architectures, but equally important in the MilliWatt scale of embedded systems and the GigaWatt scale of cloud computing. The shift of focus from stand-alone systems connected through a network to collaborative computation in a network is going to shape the development of computer science for many decades to come, and constitutes a major methodological challenge for systems engineering. Practical solutions for these questions need to account not only for the inherent logical complexity of the systems, but also for the human engineers' natural inclination to apply sequential models in their informal reasoning, and industry's need to build reliable systems from reusable components. This setting strongly motivates the development of powerful tools which facilitate mathematically precise modeling on the one hand as well as computer-aided design and validation on the other.}, 
keywords={CAD;Internet;embedded systems;groupware;systems engineering;GigaWatt scale;MilliWatt scale;cloud computing;collaborative computation;computer science development;computer-aided design;embedded systems;formal methods;industrial computing;informal reasoning;logical complexity;reliable systems;sequential models;stand-alone systems;systems engineering;Cloud computing;Communication industry;Computer architecture;Computer industry;Concurrent computing;Embedded computing;Embedded system;Power system modeling;Reliability engineering;Systems engineering and theory;automotive software;avionic software;concurrent cloud computing;embedded systems;formal methods;model checking;testing}, 
doi={10.1109/SYNASC.2009.71}, 
month={Sept},}
@INPROCEEDINGS{4575109, 
booktitle={NOMS 2008 - 2008 IEEE Network Operations and Management Symposium}, 
title={Table of contents}, 
year={2008}, 
pages={xxxiv-xlviii}, 
abstract={The following topics are dealt with: teaching network management; cloud computing; Internet traffic; IT management; session-based services linkage control; session-based services linkage management; and NGN-IMS.}, 
keywords={Internet;computer network management;telecommunication engineering education;telecommunication traffic;ubiquitous computing;IMS;IT management;Internet traffic;NGN;cloud computing;pervasive management;session-based services linkage control;session-based services linkage management;teaching network management;ubiquitous networks;ubiquitous services}, 
doi={10.1109/NOMS.2008.4575109}, 
ISSN={1542-1201}, 
month={April},}
@INPROCEEDINGS{5374726, 
author={M. Pokharel and Y. Yoon and J. S. Park}, 
booktitle={2009 International Symposium on Computer Network and Multimedia Technology}, 
title={Cloud Computing in System Architecture}, 
year={2009}, 
pages={1-5}, 
abstract={Cloud computing is new paradigm for computing in which all required resources are available as a service. With the help of rich set of features, it is getting more and more popular and well accepted by many computing communities. It is utility based system which has two parts one service provider and other service consumer. In this paper, we use cloud computing in System Architecture. We use the basic concept of Service Oriented Architecture in System Architecture and try to put it into cloud system.}, 
keywords={Internet;software architecture;cloud computing;service consumer;service oriented architecture;service provider;system architecture;utility based system;Cloud computing;Computer architecture;Computer networks;Computer security;Concurrent computing;Connectors;Government;Grid computing;Service oriented architecture;Telecommunication computing}, 
doi={10.1109/CNMT.2009.5374726}, 
month={Jan},}
@INPROCEEDINGS{5066660, 
author={X. You and X. Xu and J. Wan and C. Jiang}, 
booktitle={2009 International Conference on Embedded Software and Systems}, 
title={Analysis and Evaluation of the Scheduling Algorithms in Virtual Environment}, 
year={2009}, 
pages={291-296}, 
abstract={Virtual machine technologies currently receive great interest both in industry and research communities. And it is one of the most important technologies for the coming Cloud Computing. We surveyed the CPU scheduling algorithms in Xen and VMWare systems, and found that both of them use a distinctive VCPUs running queue for each physical CPU, which is referred to Partition Queue Model (PQM) in this paper. As a contrast, a Sharing Queue Model (SQM) of CPU scheduling algorithm is proposed. The simulation experiments results show that the sharing queue model of CPU scheduling achieves better performance than the partition queue model and the deduction from Queue Theory also confirms the results. Moreover, with the CPU utilization increased, the advantage of Sharing Queue Model over Partition Queue Mode is more evident in response time.}, 
keywords={processor scheduling;queueing theory;virtual machines;CPU scheduling algorithm analysis;CPU scheduling algorithm evaluation;VMWare system;Xen system;cloud computing;multicore processor;partition queue model;queue theory;sharing queue model;virtual machine technology;Algorithm design and analysis;Embedded software;Job shop scheduling;Queueing analysis;Scheduling algorithm;Virtual environment;Virtual machine monitors;Virtual machining;Virtual manufacturing;Voice mail;Scheduling algorithms;Virtual machine;queue theory}, 
doi={10.1109/ICESS.2009.22}, 
month={May},}
@INPROCEEDINGS{5345440, 
author={G. Minutoli and M. Fazio and M. Paone and A. Puliafito}, 
booktitle={2009 International Conference on Ultra Modern Telecommunications Workshops}, 
title={Virtual business networks with Cloud Computing and virtual machines}, 
year={2009}, 
pages={1-6}, 
abstract={To be competitive and to react faster to the market demands, Enterprises need new information processing techniques, able to analyse the increasing amount of produced data, and innovative solutions in order to manage the computational resources with better flexibility, scalability, efficiency and smaller costs. The traditional monolithic high performance computing paradigm is not suitable to achieve these requisites. The emerging Cloud Computing represents a valuable answer to these requirements. In fact, in this model the business buy computing time from commercial providers, allowing to dramatically decrease the investments in own data centers. Nevertheless, this paradigm often imposes constraints related to underlying infrastructure, forcing Enterprises to rethink their application architectures. Inspired by Amazon's EC2 model, we propose a system which allows Enterprises to extend their business networks within any Cloud infrastructure, creating custom virtual environments able to run the applications without any change, but responding always to the business companies typical requirements: Quality of Service, High- Availability and Security.}, 
keywords={computer centres;corporate modelling;service industries;virtual enterprises;virtual machines;business networks extension;cloud computing;computational resources management;custom virtual environment;data center;efficiency;flexibility;information processing technique;scalability;virtual business network;virtual machine;Business;Cloud computing;Costs;High performance computing;Information analysis;Information processing;Innovation management;Resource management;Scalability;Virtual machining;Cloud computing;business;enterprises;virtual machines}, 
doi={10.1109/ICUMT.2009.5345440}, 
ISSN={2157-0221}, 
month={Oct},}
@INPROCEEDINGS{5380584, 
author={W. Itani and A. Kayssi and A. Chehab}, 
booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
title={Privacy as a Service: Privacy-Aware Data Storage and Processing in Cloud Computing Architectures}, 
year={2009}, 
pages={711-716}, 
abstract={In this paper we present PasS (privacy as a service); a set of security protocols for ensuring the privacy and legal compliance of customer data in cloud computing architectures. PasS allows for the secure storage and processing of users' confidential data by leveraging the tamper-proof capabilities of cryptographic coprocessors. Using tamper-proof facilities provides a secure execution domain in the computing cloud that is physically and logically protected from unauthorized access. PasS central design goal is to maximize users' control in managing the various aspects related to the privacy of sensitive data. This is achieved by implementing user-configurable software protection and data privacy mechanisms. Moreover, PasS provides a privacy feedback process which informs users of the different privacy operations applied on their data and makes them aware of any potential risks that may jeopardize the confidentiality of their sensitive information. To the best of our knowledge, PasS is the first practical cloud computing privacy solution that utilizes previous research on cryptographic coprocessors to solve the problem of securely processing sensitive data in cloud computing infrastructures.}, 
keywords={Internet;coprocessors;cryptography;data privacy;protocols;PasS central design;cloud computing architectures;cryptographic coprocessors;customer data;privacy as a service;privacy feedback process;privacy-aware data storage;security protocol;sensitive data privacy;tamper-proof facilities;user confidential data processing;user-configurable software protection;Cloud computing;Computer architecture;Coprocessors;Cryptographic protocols;Cryptography;Data privacy;Data security;Law;Legal factors;Memory;cloud computing;cryptographic coprocessors;privacy;security}, 
doi={10.1109/DASC.2009.139}, 
month={Dec},}
@INPROCEEDINGS{5348483, 
author={S. Kewei and L. Ying and L. Jing and X. Xiang and Q. Quan}, 
booktitle={2009 2nd IEEE International Conference on Broadband Network Multimedia Technology}, 
title={Network traffic-based automatic optimized migration from physical to virtualized cloud environment with UCM tool}, 
year={2009}, 
pages={281-285}, 
abstract={Cloud computing provides virtualized resources as a service over the Internet. Migrating workload to virtualized cloud environment will benefit their owners on low cost, as well as dynamic scalability and performance. In this paper, we address the solutions on the migration challenge. An extensible and automatic migration framework is presented and implemented by the tool UCM which has been proved to reduce 90% cost in term of time. Workload migration to cloud environment is also a good timing for optimization. Despite the traditional capacity planning method, this paper proposes network traffic is critical dimension to be considered for migration optimization. The experiments illustrate the effective of the proposed method and tool.}, 
keywords={Unix;Web services;optimisation;virtual machines;Internet;UCM tool;capacity planning method;cloud computing;dynamic scalability;network traffic-based automatic optimized workload migration;unix configuration migration;virtualized cloud environment;Application software;Capacity planning;Cloud computing;Costs;Hardware;Optimization methods;Resource virtualization;Sun;Telecommunication traffic;Web and internet services}, 
doi={10.1109/ICBNMT.2009.5348483}, 
month={Oct},}
@INPROCEEDINGS{5408004, 
author={L. Gillam and N. Cooke and J. Skinner}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Towards Executable Acceptable Use Policies (execAUPs) for email clouds}, 
year={2009}, 
pages={48-51}, 
abstract={In this paper, we discuss the potential use of cloud computing for hosting and analysis of email. In particular, we are working towards the development of executable acceptable use policies (execAUPs) that assist organizations in preventing certain kinds of detrimental employee activities. We consider requirements for execAUPs, and outline initial efforts in using Microsoft's Azure as an environment for providing hosted storage for such research.}, 
keywords={electronic mail;organisational aspects;personnel;Microsoft Azure;cloud computing;detrimental employee activities;email clouds;execAUPs;executable acceptable use policies;Application software;Business communication;Cloud computing;Control systems;Hardware;Protection;Resilience;Scalability;Software maintenance;Temperature control}, 
doi={10.1109/ESCIW.2009.5408004}, 
month={Dec},}
@INPROCEEDINGS{5194182, 
author={B. Dong and Q. Zheng and J. Yang and H. Li and M. Qiao}, 
booktitle={2009 Ninth IEEE International Conference on Advanced Learning Technologies}, 
title={An E-learning Ecosystem Based on Cloud Computing Infrastructure}, 
year={2009}, 
pages={125-127}, 
abstract={Recently the research community has believed that an e-learning ecosystem is the next generation e-learning. However, the current models of e-learning ecosystems lack the support of underlying infrastructures, which can dynamically allocate the required computation and storage resources for e-learning ecosystems. Cloud computing is a promising infrastructure which provides computation and storage resources as services. Hence, this paper introduces Cloud computing into an e-learning ecosystem as its infrastructure. In this paper, an e-learning ecosystem based on Cloud computing infrastructure is presented. Cloud computing infrastructure and related mechanisms allow for the stability, equilibrium, efficient resource use, and sustainability of an e-learning ecosystem.}, 
keywords={computer aided instruction;cloud computing;e-learning ecosystem;Cloud computing;Computer science;Costs;Ecosystems;Electronic learning;Hardware;Isolation technology;Resource management;Scalability;USA Councils}, 
doi={10.1109/ICALT.2009.21}, 
ISSN={2161-3761}, 
month={July},}
@INPROCEEDINGS{5425403, 
author={F. Liu and L. Li and W. Chou}, 
booktitle={GLOBECOM 2009 - 2009 IEEE Global Telecommunications Conference}, 
title={Communications Enablement of Software-as-a-Service (SaaS) Applications}, 
year={2009}, 
pages={1-8}, 
abstract={Software-as-a-Service (SaaS) is an emerging software application delivery model. It has gained an increasing momentum, and it is being adopted at a very fast pace. However, the integration of SaaS applications with enterprise on-premise applications has become a major factor for the success of its adoption. There is a critical need for methods and communication infrastructures that can enable distributed SaaS applications over the data network. This paper presents an approach and a realization of communications enablement of SaaS applications. It focuses on three areas: 1) an approach to enabling communications as a service; 2) a SaaS adaptor framework for integrating SaaS applications with on-premise communications services; and 3) methods and communication middleware for two-way web services crossing enterprise domains. A communication enabled sales opportunity management SaaS application is implemented to verify the proposed approach. Experimental results indicated that the proposed approach is feasible and effective to communication enable SaaS applications in distributed environment that connects both cloud computing and enterprise on-premises systems.}, 
keywords={Web services;middleware;SaaS adaptor framework;SaaS application;Web services;cloud computing;communications enablement;enterprise on-premises systems;middleware;sales opportunity management;software application delivery model;software-as-a-service;Application software;Data security;Databases;Enterprise resource planning;Law;Legal factors;Marketing and sales;Telephony;Web and internet services;Web services}, 
doi={10.1109/GLOCOM.2009.5425403}, 
ISSN={1930-529X}, 
month={Nov},}
@INPROCEEDINGS{5279594, 
author={E. Elmroth and F. G. Marquez and D. Henriksson and D. P. Ferrera}, 
booktitle={2009 Eighth International Conference on Grid and Cooperative Computing}, 
title={Accounting and Billing for Federated Cloud Infrastructures}, 
year={2009}, 
pages={268-275}, 
abstract={Emerging Cloud computing infrastructures provide computing resources on demand based on postpaid principles. For example, the RESERVOIR project develops an infrastructure capable of delivering elastic capacity that can automatically be increased or decreased in order to cost-efficiently fulfill established Service Level Agreements. This infrastructure also makes it possible for a data center to extend its total capacity by subcontracting additional resources from collaborating data centers, making the infrastructure a federation of Clouds. For accounting and billing, such infrastructures call for novel approaches to perform accounting for capacity that varies over time and for services (or more precisely virtual machines) that migrate between physical machines or even between data centers. For billing, needs arise for new approaches to simultaneously manage postpaid and prepaid payment schemes for capacity that varies over time in response to user needs. In this paper, we outline usage scenarios and a set of requirements for such infrastructures, and propose an accounting and billing architecture to be used within RESERVOIR. Even though the primary focus for this architecture is accounting and billing between resource consumers and infrastructure provides, future support for inter-site billing is also taken into account.},
keywords={resource allocation;virtual machines;RESERVOIR project;data center;federated cloud computing infrastructure;postpaid payment scheme;prepaid payment scheme;resources-services virtualization;service level agreement;usage scenario;Cloud computing;Collaboration;Computer architecture;Grid computing;Reservoirs;Resource virtualization;Subcontracting;Technology management;Time factors;Virtual machining;RESERVOIR;SGAS;accounting;billing;cloud computing;grid computing}, 
doi={10.1109/GCC.2009.37}, 
ISSN={2160-4908}, 
month={Aug},}
@INPROCEEDINGS{5190680, 
author={H. Wada and J. Suzuki and K. Oba}, 
booktitle={2009 Congress on Services - I}, 
title={Queuing Theoretic and Evolutionary Deployment Optimization with Probabilistic SLAs for Service Oriented Clouds}, 
year={2009}, 
pages={661-669}, 
abstract={This paper focuses on service deployment optimization in cloud computing environments. In a cloud, each service in an application is deployed as one or more service instances. Different service instances operate at different quality of service (QoS) levels. In order to satisfy given service level agreements (SLAs) as end-to-end QoS requirements of an application, the application is required to optimize its deployment configuration of service instances. E3/Q is a multiobjective genetic algorithm to solve this problem. By leveraging queuing theory, E3/Q estimates the performance of an application and allows for defining SLAs in a probabilistic manner. Simulation results demonstrate that E3/Q efficiently obtains deployment configurations that satisfy given SLAs.}, 
keywords={Web services;probability;quality of service;queueing theory;E3/Q;cloud computing environments;evolutionary deployment optimization;multiobjective genetic algorithm;probabilistic service level agreements;quality of service;queuing theoretic optimization;service deployment optimization;service oriented clouds;Application software;Cloud computing;Computer science;Costs;Delay;Genetic algorithms;Quality of service;Queueing analysis;Resource management;Throughput}, 
doi={10.1109/SERVICES-I.2009.59}, 
ISSN={2378-3818}, 
month={July},}
@ARTICLE{5165541, 
author={H. E. Schaffer and S. F. Averitt and M. I. Hoit and A. Peeler and E. D. Sills and M. A. Vouk}, 
journal={Computer}, 
title={NCSU's Virtual Computing Lab: A Cloud Computing Solution}, 
year={2009}, 
volume={42}, 
number={7}, 
pages={94-97}, 
abstract={The delivery of many diverse computing services over the Internet, with flexible provisioning, has led to much greater efficiency, substantial cost savings, and many ways to enable and empower end users. NCSU's own experience with cloud computing, through its Virtual Computing Lab, indicates that this approach would be beneficial to a much wider audience.ays to enable and empower end users. NCSU's own experience with cloud computing, through its Virtual Computing Lab, indicates that this approach would be beneficial to a much wider audience.}, 
keywords={Internet;computer aided instruction;cost accounting;educational institutions;laboratories;Internet;NCSU;Virtual Computing Lab;cloud computing solution;cost savings;diverse computing services;Application software;Blades;Cloud computing;Computer applications;Costs;Educational institutions;Internet;Licenses;Linux;Portable computers;Education;IT systems;Information technology;Networking and communications;Systems engineering}, 
doi={10.1109/MC.2009.230}, 
ISSN={0018-9162}, 
month={July},}
@INPROCEEDINGS{5254216, 
author={L. Mei and Z. Zhang and W. K. Chan}, 
booktitle={2009 33rd Annual IEEE International Computer Software and Applications Conference}, 
title={More Tales of Clouds: Software Engineering Research Issues from the Cloud Application Perspective}, 
year={2009}, 
volume={1}, 
pages={525-530}, 
abstract={Cloud computing is an emerging computing paradigm. It aims to share data, calculations, and services transparently among users of a massive grid. Although the industry has started selling cloud-computing products, the software engineering infrastructure and application model are still unclear. In this paper, we compare cloud computing with service-oriented computing and pervasive computing. Both the industry and research community have actively examined these three computing paradigms. In this paper, we draw a qualitative comparison among their application characteristics based on the classic model of computer architecture from the cloud application perspective. We contrast the difference and pinpoint areas that researchers may examine in the future.}, 
keywords={Web services;computer architecture;grid computing;software architecture;ubiquitous computing;SOA;application perspective;cloud computing;computer architecture;computing paradigm;pervasive computing;service-oriented computing;software engineering infrastructure;Application software;Cloud computing;Computer applications;Computer architecture;Computer industry;Computer networks;Pervasive computing;Service oriented architecture;Software engineering;Web services;applications;cloud computing;software engineering}, 
doi={10.1109/COMPSAC.2009.76}, 
ISSN={0730-3157}, 
month={July},}
@INPROCEEDINGS{5359505, 
author={A. V. Dastjerdi and K. A. Bakar and S. G. H. Tabatabaei}, 
booktitle={2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences}, 
title={Distributed Intrusion Detection in Clouds Using Mobile Agents}, 
year={2009}, 
pages={175-180}, 
abstract={Cloud computing extends an enterprise ability to meet the computing demands of its everyday operations, while offering flexibility, mobility and scalability. However, the reason that chief information officers (CIOs) and their colleagues hesitate to let their business workloads to move from private cloud into public cloud is security. This work tries to offer a line of defense by applying mobile agents technology to provide intrusion detection for cloud applications regardless of their locations. Therefore, CIOs feel safer to use cloud to extend their on-premise infrastructure by adding capacity on demand.}, 
keywords={distributed processing;mobile agents;security of data;ubiquitous computing;cloud computing;distributed intrusion detection;mobile agent;Cloud computing;Costs;Distributed computing;Economies of scale;Grid computing;Hardware;Intrusion detection;Mobile agents;Scalability;Turing machines;Cloud Computing;Intrusion Detection System;Mobile Agent}, 
doi={10.1109/ADVCOMP.2009.34}, 
month={Oct},}
@INPROCEEDINGS{5071524, 
booktitle={2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing}, 
title={[Title page]}, 
year={2009}, 
pages={xvii-xvii}, 
abstract={The following topics are dealt with: cloud service management; software modules; cloud service engineering; cloud computing services; and software deployment.}, 
keywords={Internet;software engineering;cloud computing services;cloud service engineering;cloud service management;software deployment;software modules}, 
doi={10.1109/CLOUD.2009.5071524}, 
month={May},}
@INPROCEEDINGS{5329054, 
author={X. You and X. Xu and J. Wan and D. Yu}, 
booktitle={2009 Fourth ChinaGrid Annual Conference}, 
title={RAS-M: Resource Allocation Strategy Based on Market Mechanism in Cloud Computing}, 
year={2009}, 
pages={256-263}, 
abstract={Resource management is one of the main issues in cloud computing. in order to improve resource utilization of large data centers while delivering services with higher QoS to cloud clients, a resource allocation strategy based on market (RAS-M) is proposed. Firstly, the architecture and the market model of RAS-M are constructed, in which a QoS-refection utility function is designed according to different resource requirements of the cloud client, the equilibrium state of RAS-M is defined and the proof of its optimality is given. Secondly, GA-based price adjusted algorithm is introduced to deal with the problem of achieving the equilibrium state of RAS-M. Finally, RAS-M is implemented upon Xen to reallocate the VM's weight. Experiments results obtained by setting different parameters show that RAS-M can achieve the equilibrium state approximately, that is, demand and supply is balanced nearly, which validates RAS-M is effective and practicable, and is capable of achieving its goal.}, 
keywords={genetic algorithms;grid computing;quality of service;resource allocation;virtual machines;GA-based price adjusted algorithm;QoS-refection utility function;RAS-M;Xen;cloud computing;market mechanism;resource allocation;resource management;resource requirements;virtual machine;Cloud computing;Computational modeling;Computer science;Concurrent computing;Conference management;Distributed computing;Grid computing;Resource management;Technology management;Virtual manufacturing;Cloud Computing;Genetic Algorithm;Market Mechanisml;Resource Allocation}, 
doi={10.1109/ChinaGrid.2009.41}, 
ISSN={1949-131X}, 
month={Aug},}
@INPROCEEDINGS{5447227, 
author={J. Peng and X. Zhang and Z. Lei and B. Zhang and W. Zhang and Q. Li}, 
booktitle={2009 Second International Symposium on Information Science and Engineering}, 
title={Comparison of Several Cloud Computing Platforms}, 
year={2009}, 
pages={23-27}, 
abstract={Cloud computing is the development of parallel computing, distributed computing and grid computing. It has been one of the most hot research topics. Now many corporations have involved in the cloud computing related techniques and many cloud computing platforms have been put forward. This is a favorable situation to study and application of cloud computing related techniques. Though interesting, there are also some problems for so many flatforms. For to a novice or user with little knowledge about cloud computing, it is still very hard to make a reasonable choice. What differences are there for different cloud computing platforms and what characteristics and advantages each has? To answer these problems, the characteristics, architectures and applications of several popular cloud computing platforms are analyzed and discussed in detail. From the comparison of these platforms, users can better understand the different cloud platforms and more reasonablely choose what they want.}, 
keywords={grid computing;cloud computing platforms;distributed computing;grid computing;parallel computing;Cloud computing;Computer industry;Computer science;Concurrent computing;Distributed computing;Grid computing;High performance computing;Network servers;Parallel processing;Platform virtualization;IaaS;PaaS;SaaS;cloud computing;utility computing;virtualization}, 
doi={10.1109/ISISE.2009.94}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5454756, 
author={G. Li and H. Lu and W. Ren}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Service-Oriented Knowledge Modeling on Intelligent Topic Map}, 
year={2009}, 
pages={2394-2397}, 
abstract={Providing high-quality knowledge services for users has become increasingly important with the rapid growth of information resources, and using Service-Oriented Architecture to build knowledge services is mentioned by many researchers. In this paper, we firstly proposed a new concept of intelligent topic map for knowledge organization and knowledge reasoning, it embodies the multi-level, multi-granularity and inherent relevant characteristics of knowledge. And then we established multi-layer Service-Oriented knowledge architecture with the intelligent topic map as infrastructure. Additionally, a system framework of the knowledge service is designed and implemented based on cloud computing. Finally, a demonstration is given to display the knowledge navigation.}, 
keywords={Web services;software architecture;cloud computing;high-quality knowledge services;information resources;intelligent topic map;knowledge navigation;knowledge organization;knowledge reasoning;knowledge services;multilayer service-oriented knowledge architecture;service-oriented knowledge modeling;Cloud computing;Educational institutions;ISO standards;Information resources;Intelligent structures;Knowledge engineering;Navigation;Portals;Semantic Web;Service oriented architecture}, 
doi={10.1109/ICISE.2009.1058}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5347793, 
author={X. Lei and X. Zhe and M. Shaowu and T. Xiongyan}, 
booktitle={2009 2nd IEEE International Conference on Broadband Network Multimedia Technology}, 
title={Cloud computing and services platform construction of telecom operator}, 
year={2009}, 
pages={864-867}, 
abstract={Based on the analysis of the basic concepts, characteristics and type of service of cloud computing and through the study of IT industrial chain, the construction of cloud computing services platform for the telecom operators is put forward. The layers of the platform and various services in different layers are also detailed analyzed from the point of view of telecom operators.}, 
keywords={IP networks;Web services;telecommunication services;IT industrial chain;cloud computing;services platform construction;telecom operator;Cloud computing;Communication industry;Computer industry;Construction industry;Costs;Data security;Distributed computing;Internet;Scalability;Telecommunication computing;cloud computing;industrial chain;services platform;telecom operator}, 
doi={10.1109/ICBNMT.2009.5347793}, 
month={Oct},}
@INPROCEEDINGS{4683075, 
author={B. Kaliski}, 
booktitle={2008 Third Asia-Pacific Trusted Infrastructure Technologies Conference}, 
title={Multi-tenant Cloud Computing: From Cruise Liners to Container Ships}, 
year={2008}, 
pages={4-4}, 
abstract={As a multi-tenant service, cloud computing may be compared to container ships and cruise lines, which also provide services to large numbers of independent customers. To be cost-effective, cloud computing needs to be more like container shipping, with standardized containers, optimized costs, and automated assurances of non-interference from other cargo. Trusted infrastructures offer key technology elements that deliver these assurances.}, 
keywords={Internet;automated assurances;container ships;cruise liners;multi-tenant cloud computing;optimized costs;standardized containers;trusted infrastructure;Cloud computing;Containers;Cost function;Electromagnetic compatibility;Marine vehicles;Oceans;Technology management;Wikipedia;assurance;cloud computing;multi-tenancy;trusted infrastructure}, 
doi={10.1109/APTC.2008.16}, 
month={Oct},}
@INPROCEEDINGS{5190736, 
booktitle={2009 Congress on Services - I}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={This following topics are dealt with: regular sessions and workshops; SOA solutioning; service oriented architecture; services cup; Web services testing; self healing Web services; scientific workflows; Web services performance; Web service composition and adaptation; cloud computing services; service-oriented community coordinated multimedia; software engineering for adaptive service-oriented systems; Web services security management; service intelligence and computing; software and services maintenance and management.}, 
keywords={Web services;software engineering;SOA solutioning;Web services security management;Web services testing;cloud computing service;scientific workflow;service oriented architecture;service-oriented community coordinated multimedia;software engineering;software maintenance;software management}, 
doi={10.1109/SERVICES-I.2009.1}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5284272, 
author={S. Hosono and A. Kuno and M. Hasegawa and T. Hara and Y. Shimomura and T. Arai}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={A Framework of Co-creating Business Values for IT Services}, 
year={2009}, 
pages={167-174}, 
abstract={The IT industry traditionally offers system services to user companies. The services which integrate software and hardware products are geared toward product-based business models. However, with the emergence of cloud computing, users' in-house systems and applications are virtualized on the net, and are replaced with ones provided through outsourcing services. The alternative systems will be combinations of service functions of their companies' and of outsourcers'. This will relieve user companies from their legacy systems, allowing them to concentrate on their competence and to develop new business models effectively. In order to meet this trend, IT vendors should focus not only on the values of platform development but also on those of creating business opportunities. They need to share users' business goals and collaborate with them to enhance their business values. This paper proposes a framework and supporting tools to co-create business values between IT vendors and clients through the business lifecycle, showing the results from partly applying them to the early stages of development of e-learning services.}, 
keywords={Internet;commerce;economic cycles;information technology;outsourcing;IT industry;IT service;business goal;business lifecycle;business opportunity;cloud computing;co-creating business values;e-learning service;information technology;legacy system;offer system service;outsourcing service;product-based business model;user company;Application software;Cloud computing;Collaboration;Companies;Computer industry;Hardware;Laboratories;Manufacturing industries;National electric code;Precision engineering}, 
doi={10.1109/CLOUD.2009.57}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5071834, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={[Front cover]}, 
year={2009}, 
pages={C1-C1}, 
abstract={The following topics are dealt with: grid scheduling; peer-to-peer computing; power management; cloud computing; file systems; software resources management; data management; software fault tolerance; and E-science workflow systems virtualization.}, 
keywords={grid computing;scheduling;software fault tolerance;E-science workflow systems virtaulization;cloud computing;data management;file systems;grid scheduling;peer-to-peer computing;power management;software fault tolerance;software resources management}, 
doi={10.1109/CCGRID.2009.100}, 
month={May},}
@INPROCEEDINGS{5380611, 
author={S. Roschke and F. Cheng and C. Meinel}, 
booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
title={Intrusion Detection in the Cloud}, 
year={2009}, 
pages={729-734}, 
abstract={Intrusion detection systems (IDS) have been used widely to detect malicious behaviors in network communication and hosts. IDS management is an important capability for distributed IDS solutions, which makes it possible to integrate and handle different types of sensors or collect and synthesize alerts generated from multiple hosts located in the distributed environment. Facing new application scenarios in cloud computing, the IDS approaches yield several problems since the operator of the IDS should be the user, not the administrator of the cloud infrastructure. Extensibility, efficient management, and compatibility to virtualization-based context need to be introduced into many existing IDS implementations.Additionally, the cloud providers need to enable possibilities to deploy and configure IDS for the user. Within this paper, we summarize several requirements for deploying IDS in the cloud and propose an extensible IDS architecture for being easily used in a distributed cloud infrastructure.}, 
keywords={Internet;security of data;IDS management;cloud computing;cloud providers;distributed IDS solutions;distributed cloud infrastructure;distributed environment;intrusion detection system;network communication;virtualization-based context compatibility;Application software;Cloud computing;Computer architecture;Computer networks;Intrusion detection;Monitoring;Network servers;Protection;Robustness;Virtual machining;Cloud Computing;IDS;IDS Management;Virtual Machine;Virtualization}, 
doi={10.1109/DASC.2009.94}, 
month={Dec},}
@INPROCEEDINGS{5284194, 
author={L. J. Zhang and J. Zhang}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={Architecture-Driven Variation Analysis for Designing Cloud Applications}, 
year={2009}, 
pages={125-134}, 
abstract={Service oriented architecture (SOA) is one central technical foundation supporting the rapidly emerging cloud computing paradigm. To date, however, its application practice is not always successful. One major reason is the lack of a systematic engineering process and tool supported by reusable architectural artifacts. Toward this ultimate goal, this paper proposes a variation oriented analysis method of performing architectural building blocks (ABB)-based SOA solution design for enabling cloud application design. We present the modeling of solution-level architectural artifacts and their relationships, whose formalization enables event-based variation notification and propagation analysis. We report a prototype tool and describe how we extend the Unified Modeling Language (UML) mechanism to implement the system and enable solution-level variation analysis and enforcement in business cloud as an example.}, 
keywords={Unified Modeling Language;Web services;software architecture;software reusability;UML;Unified Modeling Language;architectural building block-based SOA;business cloud;cloud application design;cloud computing paradigm;event-based variation notification;event-based variation propagation analysis;service oriented architecture;software reusability;systematic engineering process;Application software;Cloud computing;Computer science;Libraries;Power system modeling;Semiconductor optical amplifiers;Service oriented architecture;Systems engineering and theory;USA Councils;Unified modeling language}, 
doi={10.1109/CLOUD.2009.86}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5254144, 
author={G. Wishnie and H. Saiedian}, 
booktitle={2009 33rd Annual IEEE International Computer Software and Applications Conference}, 
title={A Complex Event Routing Infrastructure for Distributed Systems}, 
year={2009}, 
volume={2}, 
pages={92-95}, 
abstract={With the growing number of mega services and cloud computing platforms, many industrial organizations are building distributed data centers and are populating them at increasing rates. At the same time, the field of complex event processing(CEP) is gaining popularity as its value is realized for real-time monitoring of these large distributed systems. Traditionally, the CEP system and core event passing infrastructure are created independent of one another. In this paper we propose that including an event based communication system with integrated support for CEP will provide certain benefits at many levels.}, 
keywords={Internet;message passing;middleware;peer-to-peer computing;telecommunication network routing;CEP system;Internet;cloud computing platform;complex event processing system;complex event routing infrastructure;distributed data center;distributed system;event based-communication system;mega service;peer-to-peer network;publish/subscribe architecture;real-time monitoring;Application software;Cloud computing;Computer applications;Computer industry;Computer science;Distributed computing;Monitoring;Peer to peer computing;Routing;Subscriptions;Cloud;Mega services}, 
doi={10.1109/COMPSAC.2009.120}, 
ISSN={0730-3157}, 
month={July},}
@ARTICLE{5076316, 
author={J. L. Johnson}, 
journal={Computing in Science Engineering}, 
title={SQL in the Clouds}, 
year={2009}, 
volume={11}, 
number={4}, 
pages={12-28}, 
abstract={In a cloud computing context, the MapReduce algorithm comprises two massively parallel operations linked by a generic sorting and data-distribution process. Although this algorithm is the workhorse in most cloud computing strategies, it's a special case of a more general dataflow. In place of the two cloud operations, the proposed method substitutes longer sequences and then lets the user direct outputs to any subsequent downstream operation. However, the method retains the job-supervisor infrastructure, which performs the necessary sorting, collating, and distributing of these outputs prior to initiating operations. To evaluate SQL database queries, particularly those with correlated subqueries, a computation identifies and aligns data elements from widely separated storage locations, suggesting cloud algorithms that exploit the supervisory sorting process to achieve the desired alignments. Exploring such algorithms reveals that a few customizable templates, assembled recursively as necessary, can handle a wide class of SQL data-mining queries.}, 
keywords={SQL;Web services;data mining;parallel algorithms;query processing;relational databases;sorting;MapReduce algorithm;SQL database query;cloud computing environment;data mining;data-distribution process;job-supervisor infrastructure;parallel algorithm;supervisory sorting process;Automobiles;Cloud computing;Computer networks;Data mining;Databases;Maintenance;Multiprocessor interconnection networks;Parallel processing;Search engines;Surveillance;SQL cloud algorithms;cloud computing;database query evaluation;database structures;dataflow architectures;distributed computing}, 
doi={10.1109/MCSE.2009.127}, 
ISSN={1521-9615}, 
month={July},}
@INPROCEEDINGS{5208724, 
booktitle={2009 IEEE International Professional Communication Conference}, 
title={[Front cover]}, 
year={2009}, 
pages={c1-c1}, 
abstract={The following topics are dealt with: music video; Internet; mobile radio; XML; cloud computing; World Wide Web; multimedia; educational courses; information management; software application program interfaces; project knowledge management; information quality; visual design; engineering communication teaching; Web sites; and manufacturing industry.}, 
keywords={Internet;Web sites;XML;application program interfaces;educational courses;information management;knowledge management;manufacturing industries;mobile radio;multimedia computing;teaching;Internet;Web sites;World Wide Web;XML;cloud computing;educational courses;engineering communication teaching;information management;information quality;manufacturing industry;mobile radio;music video;project knowledge management;software application program interfaces;visual design}, 
doi={10.1109/IPCC.2009.5208724}, 
ISSN={2158-091X}, 
month={July},}
@INPROCEEDINGS{5088912, 
author={C. S. Jensen}, 
booktitle={2009 Tenth International Conference on Mobile Data Management: Systems, Services and Middleware}, 
title={Keynote 3}, 
year={2009}, 
pages={xxxiii-xxxiii}, 
abstract={The Internet is going mobile, and indications are that on a global scale, the mobile Internet will soon be "bigger" than the conventional Internet. Due to aspects such as user mobility, much more varied use situations, and the form factor of mobile devices, context awareness is important on the mobile Internet. Focusing on aspects of geo-spatial context awareness, this talk covers research that aims to build cloud computing infrastructure for mobile data management. A key research goal is to enable sites that allow users to easily create, deploy, and share geo-spatial services.}, 
keywords={Internet;mobile computing;cloud computing infrastructure;geo-spatial context awareness;mobile Internet;mobile data management;mobile devices;Biographies;Board of Directors;Cloud computing;Computer science;Context awareness;Data engineering;Indexing;Internet;Mobile computing;Query processing},
doi={10.1109/MDM.2009.129}, 
ISSN={1551-6245}, 
month={May},}
@INPROCEEDINGS{5254135, 
author={W. Hao and I. L. Yen and B. Thuraisingham}, 
booktitle={2009 33rd Annual IEEE International Computer Software and Applications Conference}, 
title={Dynamic Service and Data Migration in the Clouds}, 
year={2009}, 
volume={2}, 
pages={134-139}, 
abstract={Cloud computing is an emerging computation paradigm. To support successful cloud computing, service oriented architecture (SOA) should play a major role. Due to the nature of widely distributed service providers in clouds, the service performance could be impacted when the network traffic is congested. This can be a major barrier for tasks with real-time requirements. In clouds, this problem can be solved by migrating services to different platforms such that the communication cost can be minimized. In this paper, we consider the problem of service selection and migration in clouds. We develop a framework to facilitate service migration and design a cost model and the decision algorithm to determine the tradeoffs on service selection and migration.}, 
keywords={Web services;decision theory;SOA;cloud computing;communication cost minimisation;data migration;decision algorithm;distributed service;dynamic service;network traffic congestion;service oriented architecture;service selection;Application software;Cloud computing;Computer science;Costs;Delay;Distributed computing;Hardware;Resource management;Service oriented architecture;Web services;cloud computing;genetic algorithm;real-time services;service composition;service migration}, 
doi={10.1109/COMPSAC.2009.127}, 
ISSN={0730-3157}, 
month={July},}
@ARTICLE{5429058, 
author={B. Rochwerger and D. Breitgand and E. Levy and A. Galis and K. Nagin and I. M. Llorente and R. Montero and Y. Wolfsthal and E. Elmroth and J. Caceres and M. Ben-Yehuda and W. Emmerich and F. Galan}, 
journal={IBM Journal of Research and Development}, 
title={The Reservoir model and architecture for open federated cloud computing}, 
year={2009}, 
volume={53}, 
number={4}, 
pages={4:1-4:11}, 
abstract={The emerging cloud-computing paradigm is rapidly gaining momentum as an alternative to traditional IT (information technology). However, contemporary cloud-computing offerings are primarily targeted for Web 2.0-style applications. Only recently have they begun to address the requirements of enterprise solutions, such as support for infrastructure service-level agreements. To address the challenges and deficiencies in the current state of the art, we propose a modular, extensible cloud architecture with intrinsic support for business service management and the federation of clouds. The goal is to facilitate an open, service-based online economy in which resources and services are transparently provisioned and managed across clouds on an on-demand basis at competitive costs with high-quality service. The Reservoir project is motivated by the vision of implementing an architecture that would enable providers of cloud infrastructure to dynamically partner with each other to create a seemingly infinite pool of IT resources while fully preserving their individual autonomy in making technological and business management decisions. To this end, Reservoir could leverage and extend the advantages of virtualization and embed autonomous management in the infrastructure. At the same time, the Reservoir approach aims to achieve a very ambitious goal: creating a foundation for next-generation enterprise-grade cloud computing.}, 
doi={10.1147/JRD.2009.5429058}, 
ISSN={0018-8646}, 
month={July},}
@INPROCEEDINGS{5369469, 
author={L. Chuling and Z. Xie and P. Peng}, 
booktitle={2009 Third International Symposium on Intelligent Information Technology Application}, 
title={A Discussion on the Framework of Smarter Campus}, 
year={2009}, 
volume={2}, 
pages={479-482}, 
abstract={Intelligence will be a new trend with the proposed of the concept smarter earth. With the application of new technologies such as cloud computing and RFID, the theoretical foundation and technical support of smarter campus is analyzed in intelligent and digital aspects in this paper. The framework of the smarter campus is discussed and the architecture is expressed in detail, based on the digital campus and the characteristics of the intelligence. From campus card to the intelligence of the teaching, management and service, smarter campus will provide a new idea for the construction of the campus, based on the digital campus.}, 
keywords={educational administrative data processing;educational institutions;RFID;campus card;cloud computing;digital campus;smarter campus;smarter earth;teaching;Artificial intelligence;Cloud computing;Computer science;Educational institutions;Grid computing;Internet;Planets;Radiofrequency identification;Resource management;Web server;cloud computing;smarter campus system;smarter planet;virtualization}, 
doi={10.1109/IITA.2009.208}, 
month={Nov},}
@ARTICLE{5054870, 
author={E. Walker}, 
journal={Computer}, 
title={The Real Cost of a CPU Hour}, 
year={2009}, 
volume={42}, 
number={4}, 
pages={35-41}, 
abstract={IT organizations can now outsource computer hardware by leasing CPU time through cloud computing services. A proposed modeling tool can quantitatively compare the cost of leasing CPU time from these online services to that of purchasing and using a server cluster of equivalent capability.}, 
keywords={DP industry;information technology;outsourcing;pattern clustering;CPU;IT organizations;cloud computing services;computer hardware outsourcing;equivalent capability;modeling tool;server cluster;Books;Business;Clouds;Costs;Investments;Retirement;Sliding mode control;Sustainable development;cloud computing;computers and society;e-commerce;economics;management of computing and information systems}, 
doi={10.1109/MC.2009.135}, 
ISSN={0018-9162}, 
month={April},}
@INPROCEEDINGS{5270287, 
author={C. Fetzer and R. Rodrigues}, 
booktitle={2009 IEEE/IFIP International Conference on Dependable Systems Networks}, 
title={Fifth Workshop on Hot Topics in System Dependability (HotDep 2009)}, 
year={2009}, 
pages={594-595}, 
abstract={The FifthWorkshop on Hot Topics in System Dependability (HotDep'09) brings forth cutting-edge research ideas in fault tolerance, reliability and systems. This year's edition of the workshop will feature a total of 10 presentations of original research on wide array of topics, including cloud computing, storage, program analysis, operating systems, replication protocols, or failure prediction.}, 
doi={10.1109/DSN.2009.5270287}, 
ISSN={1530-0889}, 
month={June},}
@ARTICLE{5054903, 
author={G. McGraw and M. Chow}, 
journal={IEEE Security Privacy}, 
title={Guest Editors' Introduction: Securing Online Games: Safeguarding the Future of Software Security}, 
year={2009}, 
volume={7}, 
number={3}, 
pages={11-12}, 
abstract={Massively distributed online role-playing games are a bellwether for problems to come in software security. As cloud computing, service-oriented architecture, and Web 2.0 take off, we can expect to grapple with very similar technical issues to those currently facing online games. The guest editors of this special issue on securing online games tackle this problem from three angles, describing the articles they've lined up to address money and virtual economies, the nascent state of the law, and thorny technical issues.}, 
keywords={Collision mitigation;Computer crime;Computer hacking;Economic indicators;Law;Legal factors;Security;Software safety;Software systems;MMORPGs;massively multiplayer online role-playing games;privacy;security;software security}, 
doi={10.1109/MSP.2009.65}, 
ISSN={1540-7993}, 
month={May},}
@INPROCEEDINGS{5158402, 
author={K. Birman}, 
booktitle={2009 29th IEEE International Conference on Distributed Computing Systems}, 
title={Rethinking Multicast for Massive-Scale Platforms}, 
year={2009}, 
pages={1-1}, 
abstract={A dramatic scale-up of distributed computing platforms is underway. Internet routers can contain hundreds or thousands of line cards. Cloud computing platforms may contain tens or even hundreds of thousands of machines. What is gluing all of this together? Multicast to support data replication, event streams, and coordination. Yet yesterday??s multicast protocols are poorly matched to this new generation of uses; so much so that many cloud platforms refuse to deploy multicast as such, and have instead resorted to clumsy alternatives, mapping multicast to TCP or even web services method invocations. This talk will explore inadequacies of existing protocols, early progress towards better ones, and the longer term research agenda.}, 
keywords={Biographies;Cloud computing;Computer science;Distributed computing;Internet;Magnetic heads;Mashups;Multicast protocols;Waste materials;Web services},
doi={10.1109/ICDCS.2009.84}, 
ISSN={1063-6927}, 
month={June},}
@INPROCEEDINGS{5331755, 
author={B. P. Rimal and E. Choi and I. Lumb}, 
booktitle={2009 Fifth International Joint Conference on INC, IMS and IDC}, 
title={A Taxonomy and Survey of Cloud Computing Systems}, 
year={2009}, 
pages={44-51}, 
abstract={The computational world is becoming very large and complex. Cloud Computing has emerged as a popular computing model to support processing large volumetric data using clusters of commodity computers. According to J.Dean and S. Ghemawat [1], Google currently processes over 20 terabytes of raw Web data. It's some fascinating, large-scale processing of data that makes your head spin and appreciate the years of distributed computing fine-tuning applied to today's large problems. The evolution of cloud computing can handle such massive data as per on demand service. Nowadays the computational world is opting for pay-for-use models and Hype and discussion aside, there remains no concrete definition of cloud computing. In this paper, we first develop a comprehensive taxonomy for describing cloud computing architecture. Then we use this taxonomy to survey several existing cloud computing services developed by various projects world-wide such as Google, force.com, Amazon. We use the taxonomy and survey results not only to identify similarities and differences of the architectural approaches of cloud computing, but also to identify areas requiring further research.}, 
keywords={Web services;software architecture;cloud computing system survey;computational world;computer cluster;distributed computing fine tuning;large volumetric data processing support;memory size 20 TByte;pay-for-use model;raw Web data;taxonomy result;Cloud computing;Taxonomy;Cloud Computing;Distributed Computing;Evolution;Large Scale Processors;Massive Data;Taxonomy}, 
doi={10.1109/NCM.2009.218}, 
month={Aug},}
@INPROCEEDINGS{5188828, 
author={B. Rochwerger and A. Galis and E. Levy and J. A. Caceres and D. Breitgand and Y. Wolfsthal and I. M. Llorente and M. Wusthoff and R. S. Montero and E. Elmroth}, 
booktitle={2009 IFIP/IEEE International Symposium on Integrated Network Management}, 
title={RESERVOIR: Management technologies and requirements for next generation Service Oriented Infrastructures}, 
year={2009}, 
pages={307-310}, 
abstract={RESERVOIR project is developing an advanced system and service management approach that will serve as the infrastructure for cloud computing and communications and future Internet of services by creative coupling of service virtualization, grid computing, networking and service management techniques. This paper presents work in progress for the integration and management of such systems into a new generation of managed service infrastructure.}, 
keywords={Web services;grid computing;virtual machines;RESERVOIR project;cloud computing;future Internet;grid computing;networking technique;next generation service oriented infrastructure;service management technology;service virtualization;Cloud computing;Grid computing;Java;Platform virtualization;Project management;Reservoirs;Resource management;Resource virtualization;Technology management;Virtual machining;Cloud Computing;Service Infrastructure;Service Management;Service Virtualization}, 
doi={10.1109/INM.2009.5188828}, 
ISSN={1573-0077}, 
month={June},}
@INPROCEEDINGS{4634779, 
author={R. Curry and C. Kiddle and N. Markatchev and R. Simmonds and T. Tan and M. Arlitt and B. Walker}, 
booktitle={2008 12th International IEEE Enterprise Distributed Object Computing Conference}, 
title={Facebook Meets the Virtualized Enterprise}, 
year={2008}, 
pages={286-292}, 
abstract={ldquoWeb 2.0rdquo and ldquocloud computingrdquo are revolutionizing the way IT infrastructure is accessed and managed. Web 2.0 technologies such as blogs, wikis and social networking platforms provide Internet users with easier mechanisms to produce Web content and to interact with each other. Cloud computing technologies are aimed at running applications as services over the Internet on a scalable infrastructure. In this paper we explore the advantages of using Web 2.0 and cloud computing technologies in an enterprise setting to provide employees with a comprehensive and transparent environment for utilizing applications. To demonstrate the effectiveness of this approach we have developed an environment that uses a social networking platform to provide access to a legacy application. The application is hosted on an internal cloud computing infrastructure that adapts dynamically to user demands. Initial feedback suggests this approach provides an improved user experience while simplifying management and increasing effective utilization of the underlying IT resources.}, 
keywords={Internet;social networking (online);software maintenance;virtual enterprises;Facebook;Internet;Web 2.0;Web content;blogs;cloud computing;social networking;virtual enterprise;wikis;Blogs;Cloud computing;Conference management;Distributed computing;Employment;Facebook;Grid computing;IP networks;MySpace;Social network services;Web 2.0;cloud computing;social networking}, 
doi={10.1109/EDOC.2008.19}, 
ISSN={1541-7719}, 
month={Sept},}
@INPROCEEDINGS{5328452, 
author={J. R. and V. R. R. and S. Sadhasivam and N. N.}, 
booktitle={2009 International Conference on Advances in Recent Technologies in Communication and Computing}, 
title={Design and Implementation of an Efficient Two-level Scheduler for Cloud Computing Environment}, 
year={2009}, 
pages={884-886}, 
abstract={Cloud computing focuses on delivery of reliable, fault-tolerant and scalable infrastructure for hosting Internet based application services. This paper presents the implementation of an efficient Quality of Service (QoS) based Meta-Scheduler and Backfill strategy based light weight Virtual Machine Scheduler for dispatching jobs. The user centric meta-scheduler deals with selection of proper resources to execute high level jobs. The system centric Virtual Machine (VM) scheduler optimally dispatches the jobs to processors for better resource utilization. We also present our thoughts on scheduling heuristics that can be incorporated at data center level for selecting ideal host for VM creation. The implementation can be further extended at the host level, using Inter VM scheduler for adaptive load balancing in cloud environment.}, 
keywords={Internet;scheduling;Internet based application service;adaptive load balancing;backfill strategy;cloud computing;fault-tolerant infrastructure;meta-scheduler;quality of service;resource utilization;scalable infrastructure;two-level scheduler;virtual machine scheduler;Adaptive scheduling;Cloud computing;Dispatching;Fault tolerance;Processor scheduling;Quality of service;Resource management;Virtual machining;Virtual manufacturing;Web and internet services;Cloud Computing;Conservative Backfilling;Distributed Computing;Inter Virtual Machine Scheduler;Local Scheduler;Meta-Scheduler}, 
doi={10.1109/ARTCom.2009.148}, 
month={Oct},}
@INPROCEEDINGS{5370935, 
author={M. Paletta and P. Herrero}, 
booktitle={2009 International Conference on Intelligent Networking and Collaborative Systems}, 
title={A MAS-Based Negotiation Mechanism to Deal with Service Collaboration in Cloud Computing}, 
year={2009}, 
pages={147-153}, 
abstract={Cloud computing focuses on the use of scalable and often virtualized resources. It is based on service-level agreements made to provide external users with services under request. Cloud computing is still evolving so that new specific negotiation mechanisms among service providers are needed for enabling effective collaboration, allowing the process of serving consumers to be more efficient. This paper presents a negotiation mechanism (mean algorithm and protocol) that allows nodes in a Â¿cloudÂ¿ to achieve an effective collaboration among service providers by means of a multi-agent architecture. In this multi-agent system, agents are aware of its surroundings by means of a parametrical and flexible use of the information related with this awareness situation. This approach makes use of heuristic strategies in order to improve the effectiveness of agents' communication, improving therefore collaboration in these environments.}, 
keywords={Web services;multi-agent systems;negotiation support systems;service industries;MAS based negotiation mechanism;cloud computing;multi-agent architecture;service collaboration;service level agreement;service provider;Cloud computing;Connectors;Data communication;Fuzzy logic;Fuzzy systems;Intelligent networks;International collaboration;Joining processes;Web and internet services;Web services;Cloud computing;artificial neural network;awareness;multi-agent system;negotiation}, 
doi={10.1109/INCOS.2009.21}, 
month={Nov},}
@INPROCEEDINGS{5190711, 
author={K. Xiong and H. Perros}, 
booktitle={2009 Congress on Services - I}, 
title={Service Performance and Analysis in Cloud Computing}, 
year={2009}, 
pages={693-700}, 
abstract={Cloud computing is a new cost-efficient computing paradigm in which information and computer power can be accessed from a Web browser by customers. Understanding the characteristics of computer service performance has become critical for service applications in cloud computing. For the commercial success of this new computing paradigm, the ability to deliver Quality of Services (QoS) guaranteed services is crucial. In this paper, we present an approach for studying computer service performance in cloud computing. Specifically, in an effort to deliver QoS guaranteed services in such a computing environment, we find the relationship among the maximal number of customers, the minimal service resources and the highest level of services. The obtained results provide the guidelines of computer service performance in cloud computing that would be greatly useful in the design of this new computing paradigm.}, 
keywords={Internet;online front-ends;quality of service;Web browser;cloud computing;computer service performance;quality of service;service applications;service resources;Application software;Business;Cloud computing;Computer science;Grid computing;Information analysis;Performance analysis;Quality of service;Web and internet services;Web server}, 
doi={10.1109/SERVICES-I.2009.121}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5357108, 
author={A. Manzalini and R. Minerva and C. Moiso}, 
booktitle={2009 13th International Conference on Intelligence in Next Generation Networks}, 
title={If the Web is the platform, then what is the SDP?}, 
year={2009}, 
pages={1-6}, 
abstract={The richness of functions and the availability of data make the Web the real service platform. Telecomm operators are using an old approach to a new All-IP infrastructure. This enables the WebCos to become the major Service Providers of next generation networks. TelCos should instead use the Web APIs and the cloud computing infrastructure to build services. They should also provide interworking functions between NGN and the old infrastructure as Enablers in order to leverage their assets. Finally TelCos should open up data interfaces and by starting immediately data mining their data bases.}, 
keywords={Web services;application program interfaces;data mining;database management systems;All-IP infrastructure;Web API;cloud computing infrastructure;data bases;data interfaces;data mining;service delivery platform;telecomm operators;Availability;Cloud computing;Computer architecture;Ecosystems;IP networks;Network servers;Next generation networking;Telecommunications;Web and internet services;Web server;Architecture;Combining Web 2.0/Mashup and Telco Technologies;Service Delivery Platform}, 
doi={10.1109/ICIN.2009.5357108}, 
month={Oct},}
@INPROCEEDINGS{5380520, 
author={W. Wei and J. Du and T. Yu and X. Gu}, 
booktitle={2009 Annual Computer Security Applications Conference}, 
title={SecureMR: A Service Integrity Assurance Framework for MapReduce}, 
year={2009}, 
pages={73-82}, 
abstract={MapReduce has become increasingly popular as a powerful parallel data processing model. To deploy MapReduce as a data processing service over open systems such as service oriented architecture, cloud computing, and volunteer computing, we must provide necessary security mechanisms to protect the integrity of MapReduce data processing services. In this paper, we present SecureMR, a practical service integrity assurance framework for MapReduce. SecureMR consists of five security components, which provide a set of practical security mechanisms that not only ensure MapReduce service integrity as well as to prevent replay and denial of service (DoS) attacks, but also preserve the simplicity, applicability and scalability of MapReduce. We have implemented a prototype of SecureMR based on Hadoop, an open source MapReduce implementation. Our analytical study and experimental results show that SecureMR can ensure data processing service integrity while imposing low performance overhead.}, 
keywords={Web services;data integrity;security of data;software architecture;DoS;MapReduce;SecureMR;denial of service;service integrity;service integrity assurance framework;Cloud computing;Computer crime;Data processing;Data security;Open systems;Power system modeling;Power system protection;Power system security;Scalability;Service oriented architecture;Cloud Computing Security;Decentralized Verification;MapReduce;Service Integrity}, 
doi={10.1109/ACSAC.2009.17}, 
ISSN={1063-9527}, 
month={Dec},}
@INPROCEEDINGS{5305993, 
author={M. M. Hassan and B. Song and C. Yoon and H. W. Lee and E. N. Huh}, 
booktitle={2009 World Conference on Services - II}, 
title={A Novel Market Oriented Dynamic Collaborative Cloud Service Infrastructure}, 
year={2009}, 
pages={9-16}, 
abstract={In this paper, we present a novel combinatorial auction (CA) based cloud market model that facilitates dynamic collaboration (DC) among cloud providers (CPs) for providing composite/collaborative cloud services to consumers and hence can address the interoperability and scalability issues for cloud computing. Also to minimize the conflicts that may happen when negotiating among providers in a DC platform, we propose a new auction policy in CA that allows a CP to dynamically collaborate with suitable partner CPs to form a group before joining the auction and to publish their group bids as a single bid to fulfill the service requirements completely. But to find a good combination of CP partners is a NP-hard problem. So we propose a promising multi-objective (MO) optimization model for CP partner selection that not only uses their individual information (INI) but also their past collaborative relationship information (PRI) which is seldom considered in existing approaches. A multi-objective genetic algorithm (MOGA) called MOGA-IC is also developed to solve the model. We implemented our proposed CACM model and the MOGA-IC in a simulated environment and study their economic efficiency and performance with existing model and algorithm. The experimental results show that the proposed MOGA-IC can support satisfactory and high quality partner selection in CACM model.}, 
keywords={commerce;genetic algorithms;open systems;NP-hard problem;cloud computing;cloud market model;collaborative cloud services;combinatorial auction;dynamic collaboration;market oriented dynamic collaborative cloud service infrastructure;multiobjective genetic algorithm;past collaborative relationship information;Cloud computing;Computational modeling;Consumer electronics;Electronic mail;Genetic algorithms;International collaboration;NP-hard problem;Power generation economics;Scalability;Telecommunication computing;Cloud market;MOGA.;combinatorial auction;dynamic collaboration;partner selection}, 
doi={10.1109/SERVICES-2.2009.20}, 
month={Sept},}
@ARTICLE{4620101, 
author={C. Hewitt}, 
journal={IEEE Internet Computing}, 
title={ORGs for Scalable, Robust, Privacy-Friendly Client Cloud Computing}, 
year={2008}, 
volume={12}, 
number={5}, 
pages={96-99}, 
abstract={The advent of multicore architecture stands to transform cloud computing in terms of scalability, robustness, and privacy. Social systems offer promising metaphors to address these issues. This column presents an approach based on organizations of restricted generality (ORGs), which are analogous to human organizations.}, 
keywords={data privacy;multicore architecture;privacy-friendly client cloud computing;restricted generality organization;robust client cloud computing;scalable client cloud computing;social systems;Cloud computing;Computer architecture;Humans;Information processing;Internet;Multicore processing;Packaging;Privacy;Robustness;Scalability;ORGs;Peering;client cloud computing;multicore;organizations of restricted generality;privacy;robustness;scalability}, 
doi={10.1109/MIC.2008.107}, 
ISSN={1089-7801}, 
month={Sept},}
@INPROCEEDINGS{5422331, 
author={M. Meisinger and C. Farcas and E. Farcas and C. Alexander and M. Arrott and J. de La Beaujardiere and P. Hubbard and R. Mendelssohn and R. Signell}, 
booktitle={OCEANS 2009}, 
title={Serving ocean model data on the cloud}, 
year={2009}, 
pages={1-10}, 
abstract={The NOAA-led Integrated Ocean Observing System (IOOS) and the NSF-funded Ocean Observatories Initiative Cyberinfrastructure Project (OOI-CI) are collaborating on a prototype data delivery system for numerical model output and other gridded data using cloud computing. The strategy is to take an existing distributed system for delivering gridded data and redeploy on the cloud, making modifications to the system that allow it to harness the scalability of the cloud as well as adding functionality that the scalability affords.}, 
keywords={geophysics computing;grid computing;oceanographic techniques;NOAA-led Integrated Ocean Observing System;NSF;OOI-CI;Ocean Observatories Initiative Cyberinfrastructure Project;cloud computing;distributed system;gridded data;numerical model output;prototype data delivery system;serving ocean model data;Clouds;Oceans}, 
doi={10.23919/OCEANS.2009.5422331}, 
ISSN={0197-7385}, 
month={Oct},}
@INPROCEEDINGS{5284165, 
author={M. Jensen and J. Schwenk and N. Gruschka and L. L. Iacono}, 
booktitle={2009 IEEE International Conference on Cloud Computing}, 
title={On Technical Security Issues in Cloud Computing}, 
year={2009}, 
pages={109-116}, 
abstract={The Cloud Computing concept offers dynamically scalable resources provisioned as a service over the Internet. Economic benefits are the main driver for the Cloud, since it promises the reduction of capital expenditure (CapEx) and operational expenditure (OpEx). In order for this to become reality, however, there are still some challenges to be solved. Amongst these are security and trust issues, since the user's data has to be released to the Cloud and thus leaves the protection-sphere of the data owner. Most of the discussions on this topics are mainly driven by arguments related to organizational means. This paper focuses on technical security issues arising from the usage of Cloud services and especially by the underlying technologies used to build these cross-domain Internet-connected collaborations.}, 
keywords={Internet;security of data;Internet;capital expenditure reduction;cloud computing;operational expenditure reduction;technical security issue;Application software;Cloud computing;Costs;Data security;Environmental economics;Europe;Hardware;Licenses;National electric code;Web and internet services;Cloud Computing security;Cloud Malware Injection;TLS;WS-Security;attacks}, 
doi={10.1109/CLOUD.2009.60}, 
ISSN={2159-6182}, 
month={Sept},}
@INPROCEEDINGS{5190356, 
author={M. Atighetchi and P. Pal}, 
booktitle={2009 Eighth IEEE International Symposium on Network Computing and Applications}, 
title={From Auto-adaptive to Survivable and Self-Regenerative Systems Successes, Challenges, and Future}, 
year={2009}, 
pages={98-101}, 
abstract={This paper charts the course of adaptive behavior in intrusion tolerance, starting from pre-programmed and user-controlled reactive adaptation to highly sophisticated autonomic and cognitively driven adaptation. The goal of intrusion-tolerance is to provide mission continuity even under conditions of sustained cyber attacks. We describe key themes of our previous work in adaptive cyber defense and introduction of autonomic response capabilities and discuss challenges that warrant further research. We also discuss the potential impact of new trends in distributed systems, e.g., service-oriented architecture and cloud computing, on future survivable systems, and point out new opportunities for developing sophisticated auto-adaptive capabilities for increased survivability .}, 
keywords={distributed processing;fault tolerant computing;security of data;adaptive cyber defense;auto-adaptive system;autonomic computing;autonomic driven adaptation;autonomic response capabilities;cloud computing;cognitively driven adaptation;cyber attacks;distributed systems;intrusion tolerance;selfregenerative system;service-oriented architecture;survivable system;user-controlled reactive adaptation;Application software;Cloud computing;Costs;Fault tolerance;Information security;Information systems;Middleware;Resource management;Service oriented architecture;Uncertainty;Autonomous Computing;Cognitive Algorithms;Information Assurance;Intrusion Tolerance;Survivability}, 
doi={10.1109/NCA.2009.12}, 
month={July},}
@INPROCEEDINGS{4683078, 
author={F. Zhang and Y. Huang and H. Wang and H. Chen and B. Zang}, 
booktitle={2008 Third Asia-Pacific Trusted Infrastructure Technologies Conference}, 
title={PALM: Security Preserving VM Live Migration for Systems with VMM-enforced Protection}, 
year={2008}, 
pages={9-18}, 
abstract={Live migration of virtual machine (VM) is a desirable feature for distributed computing such as grid computing and recent cloud computing by facilitating fault tolerance, load balance, and hardware maintenance. Virtual machine monitor (VMM) enforced process protection is a newly advocated approach to provide a trustworthy execution environment for processes running on commodity operating systems.While VMM-enforced protection systems extend protection to the processes in the virtual machine (VM), it also breaks the mobility of VMs since a VM is more closely bound to the VMM. Furthermore, several security vulnerabilities exists in migration, especially live migration of such systems that may degrade the protection strength or even break the protection.In this paper, we propose a secure migration system that provides live migration capability to VMs in VMM-enforced process protection systems, while not degrading the protection level. We implemented a prototype system base on Xen and GNU Linux to evaluate the design. The results shows that no serious performance degradation is incurred comparing to Xen live migration system.}, 
keywords={Linux;grid computing;security of data;virtual machines;GNU Linux;PALM;VMM-enforced protection;Xen;cloud computing;commodity operating systems;distributed computing;fault tolerance;grid computing;hardware maintenance;load balance;process protection;security preserving VM live migration;trustworthy execution environment;virtual machine;virtual machine monitor;Cloud computing;Degradation;Distributed computing;Fault tolerance;Grid computing;Protection;Security;Virtual machining;Virtual manufacturing;Voice mail;Live Migration;Privacy;Security;VMM-enforced Process Protection;Virtual Machine},
doi={10.1109/APTC.2008.15}, 
month={Oct},}
@INPROCEEDINGS{5353040, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={[Front cover]}, 
year={2009}, 
pages={c1-c1}, 
abstract={The following topics are dealt with: grid computing; cloud computing; resource management; and clusters workshop.}, 
keywords={grid computing;resource allocation;workstation clusters;cloud computing;clusters workshop;grid computing;resource management}, 
doi={10.1109/GRID.2009.5353040}, 
ISSN={2152-1085}, 
month={Oct},}
@INPROCEEDINGS{5381133, 
author={A. Khalid and H. Mujtaba}, 
booktitle={2009 Second International Conference on Machine Vision}, 
title={Data Processing Issues in Cloud Computing}, 
year={2009}, 
pages={301-304}, 
abstract={Cloud computing is a catchphrase that is flipped around a lot these days to describe the direction in which information road and rail network seems to be stirring. The concept, is that immense computing data will reside someplace out there in the anonymous place (in spite of the computer space) and we'll bond to them and utilize them as needed. This research paper presents basic issues regarding data usage and processing in cloud computing and their limitations. An attempt to propose appropriate solutions for these underlying issues has also been made.}, 
keywords={Internet;cloud computing;data processing;distributed processing;Cloud computing;Data processing;Government;Machine vision;Protection}, 
doi={10.1109/ICMV.2009.31}, 
month={Dec},}
@INPROCEEDINGS{5032516, 
author={M. Jinno and Y. Tsukishima}, 
booktitle={2009 Conference on Optical Fiber Communication - incudes post deadline papers}, 
title={Virtualized optical network (VON) for agile cloud computing environment}, 
year={2009}, 
pages={1-3}, 
abstract={A virtualized optical network is proposed as a key to implementing increased agility and flexibility into a cloud computing environment by providing any-to-any connectivity with the appropriate optical bandwidth at the appropriate time.}, 
keywords={Internet;bandwidth allocation;optical fibre networks;telecommunication network management;agile cloud computing environment;network resource management;optical bandwidth;virtualized optical network;Bandwidth;Cloud computing;Computer architecture;Distributed computing;Grid computing;Optical fiber networks;Optical switches;Repeaters;Resource management;Resource virtualization;(060.1155) All-optical networks;(060.4265) Networks, wavelength routing}, 
doi={10.1364/OFC.2009.OMG1}, 
month={March},}
@INPROCEEDINGS{5367965, 
author={W. Zeng and Y. Zhao and W. Song and K. Ou}, 
booktitle={2009 Fourth International Conference on Computer Sciences and Convergence Information Technology}, 
title={Research on Wireless Storage System Key Technologies}, 
year={2009}, 
pages={191-195}, 
abstract={In the environment of wireless and pervasive computing, wireless storage can provide flexible data access function, data transfer, data collection, and information services, etc. The paper proposes the architecture of wireless storage system, discusses wireless storage system key technologies, and gives performance analysis of it. Later, the paper illustrates related question and some algorithms, and makes a conclusion at last. It is expected that the wireless storage system will be developed and applied more popularly with the cloud computing and cloud storage technology.}, 
keywords={Internet;mobile computing;radio networks;ubiquitous computing;cloud computing;cloud storage technology;data access function;data collection;data transfer;information services;pervasive computing;wireless network;wireless storage system key technologies;Cloud computing;Communication system security;Computer architecture;Computer science;Electronic mail;Ground penetrating radar;Performance analysis;Wireless LAN;Wireless networks;Wireless sensor networks;architecture;data access;key technologies;performance analysis;wireless storage system}, 
doi={10.1109/ICCIT.2009.243}, 
month={Nov},}
@INPROCEEDINGS{5380880, 
author={N. Markatchev and R. Curry and C. Kiddle and A. Mirtchovski and R. Simmonds and T. Tan}, 
booktitle={2009 Fifth IEEE International Conference on e-Science}, 
title={A Cloud-Based Interactive Application Service}, 
year={2009}, 
pages={102-109}, 
abstract={Accessing, running and sharing applications and data presents researchers with many challenges. Cloud computing and social networking technologies have the potential to simplify or eliminate many of these challenges. Cloud computing technologies can provide scientists with transparent and on-demand access to applications served over the Internet in a dynamic and scalable manner. Social networking technologies provide a means for easily sharing applications and data. In this paper we present an on-line/on-demand interactive application service. The service is built on a cloud computing infrastructure that dynamically provisions virtualized application servers based on user demand. An open source social networking platform is leveraged to establish a portal front end that enables applications and results to be easily shared between researchers. Furthermore, the service works with existing/legacy applications without requiring any modifications.}, 
keywords={Web services;social networking (online);Internet;cloud based interactive application service;cloud computing;on-demand interactive application service;on-line interactive application service;open source social networking platform;virtualized application server;Application software;Application virtualization;Cloud computing;Collaborative work;Internet;Network servers;Operating systems;Portals;Social network services;Web server}, 
doi={10.1109/e-Science.2009.23}, 
month={Dec},}
@INPROCEEDINGS{5270350, 
author={K. R. Joshi and G. Bunker and F. Jahanian and A. van Moorsel and J. Weinman}, 
booktitle={2009 IEEE/IFIP International Conference on Dependable Systems Networks}, 
title={Dependability in the cloud: Challenges and opportunities}, 
year={2009}, 
pages={103-104}, 
abstract={Cloud based infrastructures are rapidly becoming a destination of choice to host a variety of applications ranging from high availability enterprise services and online TV stations, to batch oriented scientific computations. With investments of billions of dollars, the fortunes of dozens of companies, and major research initiatives staked on its success, it is clear that cloud computing is here to stay. However, it is not yet clear whether cloud services can be a dependable alternative to dedicated infrastructure. On one hand, availability and privacy are serious challenges for applications hosted on cloud infrastructure. On the other hand, a cloud provider's economies of scale allow levels of investment in redundancy and dependability that are difficult to match for smaller operators. Furthermore, the ability to monitor large numbers of applications can enable ldquowisdom of crowdsrdquo approaches to provide enhanced security much in the same way that network providers have been able to do with worms and DDoS attacks. The panel will discuss new dependability related challenges and opportunities that arise in the context of cloud computing, some examples of which are as follows.}, 
keywords={Internet;security of data;DDoS attacks;cloud based infrastructures;cloud computing;wisdom of crowds;Availability;Cloud computing;Companies;Economies of scale;Investments;Monitoring;Privacy;Redundancy;Research initiatives;TV}, 
doi={10.1109/DSN.2009.5270350}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{5201381, 
booktitle={2009 17th International Workshop on Quality of Service}, 
title={[Copyright notice]}, 
year={2009}, 
pages={1-1}, 
abstract={The following topics are dealt with: cloud computing; resource management; P2P networks; distributed storage; delay assurance; data security; wireless networks; QoS routing; TCP; and service management.}, 
keywords={Internet;peer-to-peer computing;protocols;quality of service;radio networks;security of data;telecommunication network management;telecommunication network routing;P2P networks;QoS routing;TCP;cloud computing;data security;delay assurance;distributed storage;resource management;service management;wireless networks}, 
doi={10.1109/IWQoS.2009.5201381}, 
ISSN={1548-615X}, 
month={July},}
@INPROCEEDINGS{4812386, 
author={R. Ramakrishnan}, 
booktitle={2009 IEEE 25th International Conference on Data Engineering}, 
title={Data Management in the Cloud}, 
year={2009}, 
pages={5-5}, 
abstract={We are in the midst of a computing revolution. As the cost of provisioning hardware and software stacks grows, and the cost of securing and administering these complex systems grows even faster, we're seeing a shift towards computing clouds. Clouds are essentially services accessed over a network, and offer developers scalable, robust computing infrastructure on a "pay as you go" basis, with the ability to dynamically adjust the amount of "rented" resources, and thereby, the bill. For cloud service providers, there is efficiency from amortizing costs and averaging usage peaks. Internet portals like Yahoo! have long offered application services, such as email for individuals and organizations. Companies are now offering services such as storage and compute cycles, enabling higher-level services to be built on top. In this talk, I will discuss Yahoo!'s vision of cloud computing, and describe some of the key initiatives, highlighting the technical challenges involved in designing hosted, multi-tenanted data management systems.}, 
keywords={Internet;computer networks;cloud computing;computing revolution;hosted data management system;multi-tenanted data management system;Cloud computing;Computer networks;Conference management;Costs;Data engineering;Educational institutions;Engineering management;Hardware;Robustness;USA Councils;cloud computing;data storage;multi-tenancy;yahoo}, 
doi={10.1109/ICDE.2009.175}, 
ISSN={1063-6382}, 
month={March},}
@INPROCEEDINGS{5071813, 
author={K. Sergey and K. Yury}, 
booktitle={2009 First International Confernce on Advances in Databases, Knowledge, and Data Applications}, 
title={Applying Map-Reduce Paradigm for Parallel Closed Cube Computation}, 
year={2009}, 
pages={62-67}, 
abstract={After many years of studies, efficient data cube computation remains an open field of research due to ever-growing amounts of data. One of the most efficient algorithms (quotient cubes) is based on the notion of cube cells closure, condensing groups of cells into equivalence classes, which allows to loss lessly decrease amount of data to be stored. Recently developed parallel computation framework Map-Reduce lead to a new wave of interest to large-scale algorithms for data analysis (and to so called cloud-computing paradigm). This paper is devoted to applying such approaches to data and computation intensive task of OLAP-cube computation. We show that there are two scales of Map-Reduce applicability (for local multicore or multiprocessor server and multi-server clusters), present cube construction and query processing algorithms used at the both levels. Experimental results demonstrate that algorithms are scalable.}, 
keywords={data analysis;data mining;data reduction;Map-Reduce paradigm;OLAP-cube computation;cloud-computing;data analysis;data cube computation;parallel closed cube computation;parallel computation;Aggregates;Clustering algorithms;Concurrent computing;Databases;Large-scale systems;Lattices;Mathematical programming;Multicore processing;Parallel programming;Partitioning algorithms;closed cubes;map reduce;olap}, 
doi={10.1109/DBKDA.2009.32}, 
month={March},}
@INPROCEEDINGS{4812593, 
author={D. Dash and V. Kantere and A. Ailamaki}, 
booktitle={2009 IEEE 25th International Conference on Data Engineering}, 
title={An Economic Model for Self-Tuned Cloud Caching}, 
year={2009}, 
pages={1687-1693}, 
abstract={Cloud computing, the new trend for service infrastructures requires user multi-tenancy as well as minimal capital expenditure. In a cloud that services large amounts of data that are massively collected and queried, such as scientific data, users typically pay for query services. The cloud supports caching of data in order to provide quality query services. User payments cover query execution costs and maintenance of cloud infrastructure, and incur cloud profit. The challenge resides in providing efficient and resource-economic query services while maintaining a profitable cloud. In this work we propose an economic model for self-tuned cloud caching targeting the service of scientific data. The proposed economy is adapted to policies that encourage high-quality individual and overall query services but also brace the profit of the cloud. We propose a cost model that takes into account all possible query and infrastructure expenditure. The experimental study proves that the proposed solution is viable for a variety of workloads and data.}, 
keywords={Internet;cache storage;costing;economics;information services;profitability;query processing;cloud computing;cloud infrastructure;cloud profit;data caching;economic model;minimal capital expenditure;profitable cloud;quality query service;query execution cost;query execution maintenance;resource-economic query service;self-tuned cloud caching;service infrastructure;user multitenancy;user payment;Bandwidth;Cloud computing;Computer network management;Costs;Data engineering;Databases;Environmental economics;Space technology;Web and internet services;Web server;cache;cloud economy;self-tuning}, 
doi={10.1109/ICDE.2009.143}, 
ISSN={1063-6382}, 
month={March},}
@INPROCEEDINGS{5190707, 
author={M. Brock and A. Goscinski}, 
booktitle={2009 Congress on Services - I}, 
title={Attributed Publication and Selection for Web Service-Based Distributed Systems}, 
year={2009}, 
pages={732-739}, 
abstract={With the emergence of cloud computing, the need for flexible and detailed publication and selection of services that expose cloud resources is greatly stressed. While dynamic attributes have improved the publication and selection of resources in distributed systems, the use of dynamic attributes is yet to be tried in Web services: a key element that makes cloud computing possible. We propose a new approach to Web service publication and selection using dynamic attributes shown in Web service WSDL documents, the most commonly accessed and used elements of Web services.}, 
keywords={Web services;XML;publishing;WSDL documents;Web service-based distributed systems;attributed publication;attributed selection;cloud computing;cloud resources;Australia;Cloud computing;Communication standards;Data models;Information technology;Publishing;Service oriented architecture;Standards publication;Testing;Web services;Discovery;Dynamic Attributes;State Aware WSDL;Web services}, 
doi={10.1109/SERVICES-I.2009.82}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5439456, 
author={A. Gupta and L. K. Awasthi}, 
booktitle={2009 IEEE International Conference on Internet Multimedia Services Architecture and Applications (IMSAA)}, 
title={Peer enterprises: A viable alternative to Cloud computing?}, 
year={2009}, 
pages={1-6}, 
abstract={Cloud computing has emerged as an exciting new computing paradigm offering organizations and businesses the flexibility of scaling their compute resource usage, without having to worry about under or over-provisioning. It also enables services to be deployed and utilized in a seamless manner facilitating new developments in the pay-per-use domain by incorporating elements of utility computing and software-as-a-service. While organizations, researchers and application developers vigorously espouse the virtues of the Â¿CloudÂ¿ amidst much fanfare, there is an urgent need to examine the environmental impact of the Cloud. As large organizations race to create their million-server warehouses and necessary compute infrastructure to become to early dominators in the cloud market, their high energy consumption and overall environmental impact cannot be neglected. This research paper presents the concept of Peer Enterprises - organizations which share their under-utilized resources by participating in a mammoth Peer-to-Peer network, potentially offering the same computing power as the Cloud, but without requiring additional investment or adversely impacting the environment. We present the case that if the already provisioned yet under-utilized compute resources across the world can be leveraged, a computing infrastructure comparable to the envisaged Cloud can be created, minus the negative impact on the environment.}, 
keywords={Web services;business communication;enterprise resource planning;peer-to-peer computing;utility programs;cloud computing;compute resource scaling;pay-per-use domain;peer enterprises;peer to peer network;software-as-a-service;utility computing;Application software;Cloud computing;Computer networks;Computer science;Energy consumption;Investments;Jamming;Peer to peer computing;Programming profession;Virtual machining;Alternative to Cloud Computing;Cloud Computing;Peer Enterprises;Peer-to-Peer Networks/Computing}, 
doi={10.1109/IMSAA.2009.5439456}, 
month={Dec},}
@INPROCEEDINGS{7478382, 
author={W. J. Starke}, 
booktitle={2009 IEEE Hot Chips 21 Symposium (HCS)}, 
title={POWER7: IBM's next generation, balanced POWER server chip}, 
year={2009}, 
pages={1-32}, 
abstract={Presents a collection of slides covering the following topics: Extreme multicore throughput; SMP scaling; 8-core high performance server chip; virtual machine; cloud computing; server evolution; cache hierarchy technology; memory subsystem; and off-chip signaling technology.}, 
keywords={cache storage;cloud computing;file servers;multiprocessing systems;virtual machines;8-core high performance server chip;IBM;POWER7;SMP scaling;balanced POWER server chip;cache hierarchy technology;cloud computing;extreme multicore throughput;memory subsystem;off-chip signaling technology;server evolution;virtual machine;Market research;Multicore processing;Servers;Throughput}, 
doi={10.1109/HOTCHIPS.2009.7478382}, 
month={Aug},}
@INPROCEEDINGS{5372585, 
author={A. Adamov and M. Erguvan}, 
booktitle={2009 International Conference on Application of Information and Communication Technologies}, 
title={The truth about cloud computing as new paradigm in IT}, 
year={2009}, 
pages={1-3}, 
abstract={The boom around cloud computing has reached to crown. Some professionals believe it's an absolutely new trend representing the next level of the Internet evolution. Others believe it's hype, as it uses long established computing technologies. This paper analyze cloud computing technology from different points of view and presents the findings in order to figure out the benefits and risks of cloud computing and the best way to use this technology.}, 
keywords={Internet;socio-economic effects;Internet evolution;cloud computing benefit;cloud computing risk;Cloud computing;Computers;Hardware;Internet;Open source software;Personnel;Risk analysis;Scalability;Software maintenance;Software standards}, 
doi={10.1109/ICAICT.2009.5372585}, 
month={Oct},}
@INPROCEEDINGS{5162336, 
author={Q. Cao and Z. B. Wei and W. M. Gong}, 
booktitle={2009 3rd International Conference on Bioinformatics and Biomedical Engineering}, 
title={An Optimized Algorithm for Task Scheduling Based on Activity Based Costing in Cloud Computing}, 
year={2009}, 
pages={1-3}, 
abstract={In cloud computing, traditional way for task scheduling cannot measure the cost of cloud resources accurately by reason that each of the tasks on cloud systems is totally different between each other. There may be no relationship between the overhead application base and the way that different tasks cause overhead costs of resources in cloud systems. The traditional way for task scheduling cannot meet the cloud market well enough. This paper introduces an optimized algorithm for task scheduling based on ABC (activity based costing) in cloud computing and its implementation. Compared with the traditional methods of task scheduling, a new method with an optimized algorithm based on ABC algorithm was proposed in this paper.}, 
keywords={Internet;optimisation;scheduling;task analysis;ABC algorithm;activity based costing;cloud computing;optimized algorithm;task scheduling;Application software;Cloud computing;Computer architecture;Computer networks;Costing;Costs;Internet;Network servers;Processor scheduling;Scheduling algorithm}, 
doi={10.1109/ICBBE.2009.5162336}, 
ISSN={2151-7614}, 
month={June},}
@INPROCEEDINGS{5362080, 
author={M. Nagappan and K. Wu and M. A. Vouk}, 
booktitle={2009 20th International Symposium on Software Reliability Engineering}, 
title={Efficiently Extracting Operational Profiles from Execution Logs Using Suffix Arrays}, 
year={2009}, 
pages={41-50}, 
abstract={An important software reliability engineering tool is operational profiles. In this paper we propose a cost effective automated approach for creating second generation operational profiles using execution logs of a software product. Our algorithm parses the execution logs into sequences of events and produces an ordered list of all possible subsequences by constructing a suffix-array of the events. The difficulty in using execution logs is that the amount of data that needs to be analyzed is often extremely large (more than a million records per day in many applications). Our approach is very efficient. We show that our approach requires O(N) in space and time to discover all possible patterns in N events. We discuss a practical implementation of the algorithm in the context of the logs from a large cloud computing system.}, 
keywords={computational complexity;data mining;software reliability;software tools;O(N);cost effective automated approach;execution logs;large cloud computing system;operational profiles extraction;second generation operational profiles;software product;software reliability engineering tool;suffix arrays;Application software;Cloud computing;Computer science;Costs;Frequency;Humans;Laboratories;Reliability engineering;Software reliability;Software systems;Execution logs;O(N);Operational profile;Software reliability;Suffix arrays}, 
doi={10.1109/ISSRE.2009.23}, 
ISSN={1071-9458}, 
month={Nov},}
@INPROCEEDINGS{5380466, 
author={R. Dhand}, 
booktitle={2009 Second International Conference on Computer and Electrical Engineering}, 
title={Web Services: A Trend Shift from Conventional Distributed Computing Model}, 
year={2009}, 
volume={1}, 
pages={313-317}, 
abstract={Recent shift to the Software as Service popularly known as SaS and Cloud Computing, importance of conventional PC Software has reduced and is making drift towards the cloud with the help of Web 2.0. Software is being used as a Service in the Web that can be accessed from any part of the world. Web Services are one integral part of the cloud computing that are making noises and proposing a lot in depth benefits to the area of distributed computing. Conventional well established methods like RMI, DCOM, CORBA are replaced by superior techniques like Web Services. Web Services are providing a fusion of the conventional distributed computing model and the Web 2.0 architecture. This paper presents the benefits of the Web services to be deployed in a Web Server for providing a higher performance distributed object style implementation than the conventional methods.}, 
keywords={Web services;distributed processing;Web 2.0;Web 2.0 architecture;Web server;Web services;cloud computing;distributed computing model;distributed object style;software as service;Cloud computing;Computer architecture;Distributed computing;Java;Middleware;Service oriented architecture;Skeleton;Sockets;Web server;Web services;Distributed Computing;Invocation;Remote Object;WSDL;Web service}, 
doi={10.1109/ICCEE.2009.26}, 
month={Dec},}
@ARTICLE{4786942, 
author={H. Erdogmus}, 
journal={IEEE Software}, 
title={Cloud Computing: Does Nirvana Hide behind the Nebula?}, 
year={2009}, 
volume={26}, 
number={2}, 
pages={4-6}, 
abstract={At the core of cloud computing is a simple concept: software as a service, or SaaS. Whether the underlying software is an application, application component, platform, framework, environment, or some other soft infrastructure for composing applications to be delivered as a service on the Web, it's all software in the end. But the simplicity ends there. Just a step away from that core, a complex concoction of paradigms, concepts, and technologies envelop cloud computing.}, 
keywords={Application software;Chemical technology;Chemistry;Cloud computing;Hardware;Insulation;Network servers;Programming;Web and internet services;Web server;SaaS;application infrastructure;cloud computing;framework;software as a service}, 
doi={10.1109/MS.2009.31}, 
ISSN={0740-7459}, 
month={March},}
@INPROCEEDINGS{5283742, 
author={Q. Liu and G. Wang and J. Wu}, 
booktitle={2009 International Conference on Computational Science and Engineering}, 
title={An Efficient Privacy Preserving Keyword Search Scheme in Cloud Computing}, 
year={2009}, 
volume={2}, 
pages={715-720}, 
abstract={A user stores his personal files in a cloud, and retrieves them wherever and whenever he wants. For the sake of protecting the user data privacy and the user queries privacy, a user should store his personal files in an encrypted form in a cloud, and then sends queries in the form of encrypted keywords. However, a simple encryption scheme may not work well when a user wants to retrieve only files containing certain keywords using a thin client. First, the user needs to encrypt and decrypt files frequently, which depletes too much CPU capability and memory power of the client. Second, the service provider couldn't determine which files contain keywords specified by a user if the encryption is not searchable. Therefore, it can only return back all the encrypted files. A thin client generally has limited bandwidth, CPU and memory, and this may not be a feasible solution under the circumstances. In this paper, we investigate the characteristics of cloud computing and propose an efficient privacy preserving keyword search scheme in cloud computing. It allows a service provider to participate in partial decipherment to reduce a client's computational overhead, and enables the service provider to search the keywords on encrypted files to protect the user data privacy and the user queries privacy efficiently. By proof, our scheme is semantically secure.}, 
keywords={Internet;client-server systems;cryptography;data privacy;information retrieval;Internet;client computational overhead;cloud computing;encrypted keywords;file encryption;partial decipherment;personal file retrieval;personal file storage;privacy preserving keyword search;thin client;user data privacy;user query privacy;Bandwidth;Cloud computing;Computer science;Cryptography;Data privacy;Information retrieval;Information science;Keyword search;Personal digital assistants;Protection;cloud computing;partial decipherment;privacy preserving;searchable encryption}, 
doi={10.1109/CSE.2009.66}, 
month={Aug},}
@INPROCEEDINGS{5161236, 
author={K. Beaty and A. Kochut and H. Shaikh}, 
booktitle={2009 IEEE International Symposium on Parallel Distributed Processing}, 
title={Desktop to cloud transformation planning}, 
year={2009}, 
pages={1-8}, 
abstract={Traditional desktop delivery model is based on a large number of distributed PCs executing operating system and desktop applications. Managing traditional desktop environments is incredibly challenging and costly. Tasks like installations, configuration changes, security measures require time-consuming procedures and dedicated deskside support. Also these distributed desktops are typically underutilized, resulting in low ROI for these assets. Further, this distributed computing model for desktops also creates a security concern as sensitive information could be compromised with stolen laptops or PCs. Desktop virtualization, which moves computation to the data center, allows users to access their applications and data using stateless ldquothin-clientldquo devices and therefore alleviates some of the problems of traditional desktop computing. Enterprises can now leverage the flexibility and cost-benefits of running users' desktops on virtual machines hosted at the data center to enhance business agility and reduce business risks, while lowering TCO. Recent research and development of cloud computing paradigm opens new possibilities of mass hosting of desktops and providing them as a service. However, transformation of legacy systems to desktop clouds as well as proper capacity provisioning is a challenging problem. Desktop cloud needs to be appropriately designed and provisioned to offer low response time and good working experience to desktop users while optimizing back-end resource usage and therefore minimizing provider's costs. This paper presents tools and approaches we have developed to facilitate fast and accurate planning for desktop clouds. We present desktop workload profiling and benchmarking tools as well as desktop to cloud transformation process enabling fast and accurate transition of legacy systems to new cloud-based model.}, 
keywords={network computers;operating systems (computers);virtual machines;workstation clusters;cloud transformation planning;cloud-based model;deskside support;desktop clouds;desktop computing;desktop delivery model;desktop virtualization;desktop workload profiling;distributed PC;distributed desktops;operating system;security measures;thin-client devices;virtual machines;Application virtualization;Clouds;Data security;Distributed computing;Environmental management;Information security;Operating systems;Personal communication networks;Portable computers;Virtual machining}, 
doi={10.1109/IPDPS.2009.5161236}, 
ISSN={1530-2075}, 
month={May},}
@ARTICLE{5339332, 
author={H. G. Miller and J. Veiga}, 
journal={IT Professional}, 
title={Cloud Computing: Will Commodity Services Benefit Users Long Term?}, 
year={2009}, 
volume={11}, 
number={6}, 
pages={57-59}, 
abstract={The attention the IT community has given cloud computing recently rivals that given to American Idol judges by the public. This magazine alone dedicated its March/April 2009 issue and significant other space throughout the year to the topic. Cloud computing's potential lies not only in the evolution of technology but also in a sourcing strategy that uses resources shared by increasingly larger volumes of users. Further potential lies in the commoditization of cloud computing services - that is, a market in which price primarily differentiates cloud computing services. Although the entire IT community will need to address significant challenges, the result will be decreased prices, increased numbers of services, and improved performance not only in the near term but also the longer term. The result should be a decade or more in which cloud computing providers and users all benefit from future technology advancements, cloud efficiencies, and market competition. In response to the as to whether cloud computing is just the same old IT packaged in a new bottle, or is it really new wine?The authors believe that not only is it new wine, but one of a vintage that will improve with maturity.}, 
keywords={Internet;cloud computing;commodity services;sourcing strategy;Application software;Cloud computing;Data security;IP networks;Middleware;Packaging;Phase measurement;Resource management;Runtime environment;Twitter;IT Professional;Smart IT;cloud computing;services computing}, 
doi={10.1109/MITP.2009.117}, 
ISSN={1520-9202}, 
month={Nov},}
@INPROCEEDINGS{5325391, 
author={P. Varma and V. K. Naik}, 
booktitle={2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement}, 
title={Scheduling and Controlling Semantics for Distributed Resource Based Computing Engines}, 
year={2009}, 
pages={47-56}, 
abstract={With the advent of autonomic and cloud computing, computation engines are getting redefined as dynamic configurations of heterogeneous, distributed resources. In this paper, we describe the operational semantics of scheduling and controlling of computation engines configured from component resources subject to dependency and capacity constraints and in accordance with policies and objectives such as priorities and load balancing. The operational semantics provides a novel formal model in denotational style, for establishing properties like computability and dependability in the presence of faults and reported and unreported events. It supports dynamic features such as resource up and down events, synchronized startup, synchronized shutdown, and resource groups/virtual servers. An efficient, interpreter-based implementation using the specified semantics is suggested.}, 
keywords={dynamic scheduling;fault tolerant computing;programming language semantics;resource allocation;autonomic computing;cloud computing;computability;computation engines;controlling semantics;denotational semantics;dependability;distributed resource-based computing engines;heterogeneous distributed resources;load balancing;operational semantics;priorities;resource groups;resource up-and-down events;scheduling;synchronized shutdown;synchronized startup;virtual servers;Availability;Cloud computing;Control systems;Distributed computing;Distributed control;Engines;File servers;Network servers;Processor scheduling;Resource management;autonomic and cloud computing;denotational semantics;formal model;operational semantics;resource configuration;scheduling and controlling}, 
doi={10.1109/SSIRI.2009.29}, 
month={July},}
@INPROCEEDINGS{5406408, 
author={Hao Shi and Zhiqiang Zhan}, 
booktitle={2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)}, 
title={An optimal infrastructure design method of cloud computing services from the BDIM perspective}, 
year={2009}, 
volume={1}, 
pages={393-396}, 
abstract={For IT service providers, infrastructure construction plays a significant role in the maximization of business profits. Infrastructure design is becoming more and more crucial as IT service environments evolve from deployment on site to software as a service (SaaS), and, most recently, to cloud computing. In this paper, a cloud computing architecture is proposed from the viewpoint of business-driven IT management (BDIM); then an optimal cloud infrastructure design methodology is devised, whereby numbers of servers, routers and communication bandwidth can be calculated through considering both infrastructure costs and business losses incurred by service level agreement (SLA) violations. Finally, a complete numerical example is discussed to testify the proposed method.}, 
keywords={business data processing;information technology;software architecture;BDIM perspective;SaaS;business losses;business profits;business-driven IT management;cloud computing services;communication bandwidth;optimal infrastructure design;routers;servers;service level agreement;software-as-a-service;Application software;Cloud computing;Computer architecture;Design methodology;Internet;Laboratories;Quality of service;Service oriented architecture;Telecommunication switching;Testing;BDIM;SLA;SaaS;cloud computing;infrastructure design}, 
doi={10.1109/PACIIA.2009.5406408}, 
month={Nov},}
@ARTICLE{4629730, 
author={P. Mika and G. Tummarello}, 
journal={IEEE Intelligent Systems}, 
title={Web Semantics in the Clouds}, 
year={2008}, 
volume={23}, 
number={5}, 
pages={82-87}, 
abstract={Cloud computing refers to the use of large-scale computer clusters often built from low-cost hardware and network equipment, where resources are allocated dynamically among users of the cluster. While the paradigm is not entirely novel, recent developments in software frameworks for cloud computing are making it increasingly easy for programmers to parallelize and thereby scale-up complex data-processing tasks. This article investigates how this trend is impacting the semantic Web field and shows how cloud computing can be used to analyze, query, and reason with the massive amounts of metadata handled by semantic search engines.}, 
keywords={meta data;query processing;resource allocation;search engines;semantic Web;cloud computing;dynamic resource allocation;meta data;query processing;search engine;semantic Web;cloud computing;distributed systems;scalability;semantic search;semantic web}, 
doi={10.1109/MIS.2008.94}, 
ISSN={1541-1672}, 
month={Sept},}
@INPROCEEDINGS{5353079, 
author={G. Cheng and H. Jin and D. Zou and X. Zhang and M. Li and C. Yu and G. Xiang}, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={Building dynamic integrity protection for multiple independent authorities in virtualization-based infrastructure}, 
year={2009}, 
pages={113-119}, 
abstract={In grid and cloud computing infrastructures, the integrity of a computing platform is a critical security requirement in order to provide secure and honest computing environments to service providers and resource consumers. However, due to the fact that software components running on a single platform are usually provided and maintained by different authorities which are potentially untrusted to each other, the problem to monitor and protect runtime system integrity become very challenging and has not been well addressed yet. In this paper, we present a virtualization based dynamic integrity protection method which ensures that only appropriate authorities can control over their components without interfering with other component providers or authorities. In our solution, integrity requirements defined by the authorities of upper components (e.g., service middleware and applications) are respected by preventing the underlying components (e.g., operating system) from exposing their sensitive data, which can be caused by update of the underlying components or other malicious actions. We implement our solution on Xen-based platform, and our evaluation results show that the solution is effective for integrity protection with acceptable performance overhead.}, 
keywords={data integrity;grid computing;object-oriented programming;security of data;Xen-based platform;cloud computing;computing environments;critical security requirement;dynamic integrity protection;grid computing;multiple independent authority;resource consumers;runtime system integrity;service providers;software components;virtualization-based infrastructure;Application software;Cloud computing;Computer science;Grid computing;Hardware;Middleware;Operating systems;Physics computing;Portable computers;Protection}, 
doi={10.1109/GRID.2009.5353079}, 
ISSN={2152-1085}, 
month={Oct},}
@ARTICLE{4804045, 
author={R. L. Grossman}, 
journal={IT Professional}, 
title={The Case for Cloud Computing}, 
year={2009}, 
volume={11}, 
number={2}, 
pages={23-27}, 
abstract={To understand clouds and cloud computing, we must first understand the two different types of clouds. The author distinguishes between clouds that provide on-demand computing instances and those that provide on-demand computing capacity. Cloud computing doesn't yet have a standard definition, but a good working description of it is to say that clouds, or clusters of distributed computers, provide on-demand resources and services over a network, usually the Internet, with the scale and reliability of a data center.}, 
keywords={Internet;Internet;cloud computing;data center;distributed computer cluster;on-demand resource;on-demand service;Cloud computing;Costs;Data security;Distributed computing;File systems;Grid computing;Pricing;Resource management;Web and internet services;Writing;IT Professional;cloud computing;on-demand computing capacity;on-demand computing instances;utility computing}, 
doi={10.1109/MITP.2009.40}, 
ISSN={1520-9202}, 
month={March},}
@ARTICLE{4907679, 
author={F. Douglis}, 
journal={IEEE Internet Computing}, 
title={Staring at Clouds}, 
year={2009}, 
volume={13}, 
number={3}, 
pages={4-6}, 
abstract={Cloud computing's premise is to lower computing costs by providing computational resources in a shared infrastructure. This could be a godsend to smaller organizations, but interoperability and security challenges still exist for this emerging technology.}, 
keywords={cost reduction;open systems;security of data;cloud computing;computational resources;cost reduction;interoperability;security;Application software;Cloud computing;Ecosystems;Hardware;Licenses;Monitoring;Open source software;Sun;Videos;Cloud Computing Expo;cloud computing;virtualization}, 
doi={10.1109/MIC.2009.70}, 
ISSN={1089-7801}, 
month={May},}
@INPROCEEDINGS{5331732, 
author={Y. Zhao and W. Huang}, 
booktitle={2009 Fifth International Joint Conference on INC, IMS and IDC}, 
title={Adaptive Distributed Load Balancing Algorithm Based on Live Migration of Virtual Machines in Cloud}, 
year={2009}, 
pages={170-175}, 
abstract={EUCALYPTUS, an open source cloud-computing framework, is still lack of load balancing. In the paper, we provide a kind of implementation by adaptive live migration of virtual machines. We design and implement a simple model which decreases the migration time of virtual machines by shared storage and fulfills the zero-downtime relocation of virtual machines by transforming them as Red Hat cluster services. During the migration process, we also keep the inclusion relationship between VLAN and virtual machines. We propose a distributed load balancing algorithm COMPARE_AND_BALANCE based on sampling to reach an equilibrium solution. The experimental results show that it converges quickly.}, 
keywords={distributed processing;public domain software;resource allocation;virtual machines;COMPARE_AND_BALANCE;EUCALYPTUS;Red Hat cluster services;VLAN;adaptive distributed load balancing;adaptive live migration;migration process;open source cloud-computing framework;virtual machines;zero-downtime relocation;Application software;Application virtualization;Cloud computing;Clustering algorithms;Computers;Load management;Network servers;Operating systems;Sampling methods;Virtual machining;Adaptive;Cloud Computing;Live Migration;Load Balancing;Virtual Machine}, 
doi={10.1109/NCM.2009.350}, 
month={Aug},}
@INPROCEEDINGS{5232041, 
booktitle={2009 IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing}, 
title={[Front cover]}, 
year={2009}, 
pages={C1-C1}, 
abstract={The following topics are dealt with: service-oriented real-time distributed computing; operating system; model driven design; embedded software crisis; scheduling and resource management; software architecture; ambient intelligence; cyber-physical system; cloud computing; middleware; software development support; software modeling and analysis.}, 
keywords={embedded systems;middleware;object-oriented programming;operating systems (computers);program diagnostics;resource allocation;scheduling;software architecture;ambient intelligence;cloud computing;cyber-physical system;embedded software crisis;middleware;model driven design;operating system;resource management;scheduling;service-oriented real-time distributed computing;software analysis;software architecture;software development support;software modeling}, 
doi={10.1109/ISORC.2009.57}, 
ISSN={1555-0885}, 
month={March},}
@INPROCEEDINGS{4591338, 
author={M. E. Frîncu and D. Petcu}, 
booktitle={2008 The Third International Multi-Conference on Computing in the Global Information Technology (iccgi 2008)}, 
title={On Designing an Asynchronous and Dynamic Platform for Solving Single Task Requests of Remote Applications}, 
year={2008}, 
pages={12-18}, 
abstract={Using remotely located software or hardware resources for solving various technical problems is presently the main subject of the current emerging technologies such as utility computing, cloud computing, Grid computing and so on. This paper discusses a possible architectural solution and describes a platform built bearing in mind the requirements for solving mathematical-described problems, but potentially useful also for other kinds of technical problems.}, 
keywords={distributed processing;cloud computing;grid computing;remotely located hardware resources;remotely located software;single task requests;utility computing;Application software;Automatic control;Cloud computing;Communication system control;Computerized monitoring;Grid computing;Hardware;Information technology;Remote monitoring;Simple object access protocol;Distributed Computing;Grid;Remote Control}, 
doi={10.1109/ICCGI.2008.14}, 
month={July},}
@INPROCEEDINGS{5190363, 
author={T. Miyamoto and M. Hayashi and H. Tanaka}, 
booktitle={2009 Eighth IEEE International Symposium on Network Computing and Applications}, 
title={Customizing Network Functions for High Performance Cloud Computing}, 
year={2009}, 
pages={130-133}, 
abstract={A new cloud computing architecture introducing customization of network functions based on active network is studied. To flexibly reconfigure the network functions depending on the requirement of each cloud computing environment, network functions are deployed on a virtual machine. Customizable sequences of network functions are essential for cloud computing environments. The content-based packet marking mechanism is introduced to transfer packets to the next network function. The architecture for customizing network functions is experimentally demonstrated for high performance cloud computing with data caching and compression.}, 
keywords={cache storage;data compression;distributed processing;virtual machines;active network;cloud computing architecture;content-based packet marking;data caching;data compression;high performance cloud computing;network function customization;packet transfer;virtual machine;Cloud computing;Computer architecture;Computer networks;Laboratories;Network servers;Switches;Transfer functions;Virtual machining;Virtual manufacturing;Voice mail;Active Network;Cloud Computing;Network Function}, 
doi={10.1109/NCA.2009.59}, 
month={July},}
@INPROCEEDINGS{5353179, 
author={I. ul Haq and E. Schikuta and K. Kofler}, 
booktitle={2009 International Conference on Emerging Technologies}, 
title={Using blackboard system to automate and optimize workflow orchestrations}, 
year={2009}, 
pages={173-178}, 
abstract={Automated composition and optimization of workflows in Service Oriented Computing (SOC) is a challenging research area. However, there are numerous problems yet to be completely resolved, such as: How to automate the solution in a service oriented environment with redundant services competing with each other? How to formally quantify the performance metrics based on user requirements both at the task level and at the overall workflow level? How to select the optimal set of services in order to maximize the user happiness? How to cope with the dynamic behaviors such as user changing his requirements and failing resources? We present a smart approach based on the Blackboard Systems for the generation of workflows in service enriched environments such as the Grid and the Cloud Computing. We devise a mathematical model to automate the blackboard based workflow generation. Our model defines a Â¿happiness measureÂ¿, that, on the basis of user specified requirements and priorities for various activities in the abstract workflow, identifies optimal possibilities of service orchestrations. Then we discuss an example scenario to demonstrate these formal techniques and show a speedup analysis of our parallelized Branch and Bound algorithm based implementation. We also discuss possibilities of other more efficient algorithms.}, 
keywords={distributed processing;software architecture;automated composition;blackboard based workflow generation;blackboard system;cloud computing;grid computing;happiness measure;mathematical model;service oriented computing;service oriented environment;workflow optimization;workflow orchestration;Algorithm design and analysis;Artificial intelligence;Cloud computing;Concrete;Knowledge engineering;Measurement;Mesh generation;Quality of service;Service oriented architecture;Web and internet services;Artificial Intelligence;Blackboard Systems;Formal Model;Multidimensional Multi-choice Knapsack Problem;Parallel Branch and Bound Algorithm;Service Composition;Service Selection;Workflow Management}, 
doi={10.1109/ICET.2009.5353179}, 
month={Oct},}
@INPROCEEDINGS{4736741, 
author={M. S. Avila-Garcia and A. E. Trefethen and M. Brady and F. Gleeson and D. Goodman}, 
booktitle={2008 IEEE Fourth International Conference on eScience}, 
title={Lowering the Barriers to Cancer Imaging}, 
year={2008}, 
pages={63-70}, 
abstract={There are various issues that limit the development and deployment of new software solutions in cancer image analysis research. In this paper we discuss some of these and propose a framework design based on cloud computing concepts, Microsoft technologies, existing middleware and imaging toolkits. Furthermore, we address some of these issues by introducing collaborative visual tools for visual input data and multi-user interactions.}, 
keywords={cancer;groupware;human computer interaction;medical image processing;middleware;Microsoft technology;cancer image analysis;cloud computing;collaborative visual tool;middleware;multiuser interaction;software solution;Biomedical imaging;Cancer;Computed tomography;Computer languages;Image analysis;Image color analysis;Image segmentation;Liver neoplasms;Medical diagnostic imaging;Visualization;Cloud computing;Medical image analysis;Multi-touch technology;Virtual research environment}, 
doi={10.1109/eScience.2008.33}, 
month={Dec},}
@INPROCEEDINGS{5328097, 
booktitle={2009 Ninth IEEE International Conference on Computer and Information Technology}, 
title={[Title page i - Volume 1]}, 
year={2009}, 
volume={1}, 
pages={i-i}, 
abstract={The following topics are dealt with: artificial intelligence; computer architecture; computer graphics; information visualisation; image processing; high-performance computing; information security; biomedicine; database management systems; data management; IT; utility computing; and cloud computing.}, 
keywords={Internet;artificial intelligence;bioinformatics;computer architecture;computer graphics;data visualisation;database management systems;image processing;security of data;IT;artificial intelligence;biomedicine;cloud computing;computer architecture;computer graphics;data management;database management systems;high-performance computing;image processing;information security;information visualisation;utility computing}, 
doi={10.1109/CIT.2009.144}, 
month={Oct},}
@INPROCEEDINGS{4738443, 
author={L. Youseff and M. Butrico and D. Da Silva}, 
booktitle={2008 Grid Computing Environments Workshop}, 
title={Toward a Unified Ontology of Cloud Computing}, 
year={2008}, 
pages={1-10}, 
abstract={Progress of research efforts in a novel technology is contingent on having a rigorous organization of its knowledge domain and a comprehensive understanding of all the relevant components of this technology and their relationships. Cloud computing is one contemporary technology in which the research community has recently embarked. Manifesting itself as the descendant of several other computing research areas such as service-oriented architecture, distributed and grid computing, and virtualization, cloud computing inherits their advancements and limitations. Towards the end-goal of a thorough comprehension of the field of cloud computing, and a more rapid adoption from the scientific community, we propose in this paper an ontology of this area which demonstrates a dissection of the cloud into five main layers, and illustrates their interrelations as well as their inter-dependency on preceding technologies. The contribution of this paper lies in being one of the first attempts to establish a detailed ontology of the cloud. Better comprehension of the technology would enable the community to design more efficient portals and gateways for the cloud, and facilitate the adoption of this novel computing approach in scientific environments. In turn, this will assist the scientific community to expedite its contributions and insights into this evolving computing field.}, 
keywords={Web services;ontologies (artificial intelligence);cloud computing technology;distributed computing;gateway design;grid computing;portal design;scientific community;scientific environment;service-oriented architecture;unified ontology;virtualization technology;Application software;Cloud computing;Computer networks;Distributed computing;Grid computing;Ontologies;Portals;Semiconductor optical amplifiers;Service oriented architecture;User interfaces}, 
doi={10.1109/GCE.2008.4738443}, 
ISSN={2152-1085}, 
month={Nov},}
@INPROCEEDINGS{5190681, 
author={S. Krishnan and L. Clementi and J. Ren and P. Papadopoulos and W. Li}, 
booktitle={2009 Congress on Services - I}, 
title={Design and Evaluation of Opal2: A Toolkit for Scientific Software as a Service}, 
year={2009}, 
pages={709-716}, 
abstract={Grid computing provides mechanisms for making large-scale computing environments available to the masses. In recent times, with the advent of Cloud computing, the concepts of Software as a Service (SaaS), where vendors provide key software products as services over the internet that can be accessed by users to perform complex tasks, and Service as Software (SaS), where customizable and repeatable services are packaged as software products that dynamically meet the demands of individual users, have become increasingly popular. Both SaaS and SaS models are highly applicable to scientific software and users alike. Opal2 is a toolkit for wrapping scientific applications as Web services on Grid and cloud computing resources. It provides a mechanism for scientific application developers to expose the functionality of their codes via simple Web service APIs, abstracting out the details of the back-end infrastructure. Services may be combined via customized workflows for specific research areas and distributed as virtual machine images. In this paper, we describe the overall philosophy and architecture of the Opal2 framework, including its new plug-in architecture and data handling capabilities. We analyze its performance in typical cluster and Grid settings, and in a cloud computing environment within virtual machines, using Amazon's Elastic Computing Cloud (EC2).}, 
keywords={Web services;grid computing;software engineering;software packages;virtual machines;Opal2;Web services;cloud computing;cloud computing resources;data handling;elastic computing cloud;grid computing;scientific software;software as a service;software products;virtual machine images;Application software;Cloud computing;Computer architecture;Grid computing;Large-scale systems;Software performance;Software tools;Virtual machining;Web and internet services;Web services;Clouds;Grid Computing;Service Oriented Architectures}, 
doi={10.1109/SERVICES-I.2009.52}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5158873, 
author={Z. Chen and Y. Zhao and X. Miao and Y. Chen and Q. Wang}, 
booktitle={2009 29th IEEE International Conference on Distributed Computing Systems Workshops}, 
title={Rapid Provisioning of Cloud Infrastructure Leveraging Peer-to-Peer Networks}, 
year={2009}, 
pages={324-329}, 
abstract={As an emerging model for new enterprise data centers, the cloud paradigm provides a disruptive market opportunity to better utilize computing resources and reduce IT complexity. To provide the cloud computing service, the provisioning of the cloud infrastructure in data centers is a pre-request. However, the provisioning for systems and applications on large number of physical machines is traditionally a time consuming process, with low assurance on deployment time and cost. This paper thus leverages peer-to-peer (P2P) networks to speedup the provisioning for cloud infrastructure. In the proposed P2P-assisted cloud provisioning system, BitTorrent-like P2P protocol is utilized to accelerate image delivery to large-scale target machines, by sharing their upload capacity to overcome the traditional bandwidth bottleneck of provisioning server. Further, the BitTorrent component is integrated with file system in user space (FUSE) through a message-driven piece selection scheme, to enable virtual machines and requested services in required time. Based on our prototype system, experiments demonstrate the effectiveness of our system in saving deployment time, increasing service availability and reducing traffic cost, leading to high quality of service of end users.}, 
keywords={computer centres;peer-to-peer computing;quality of service;workstation clusters;BitTorrent-like P2P protocol;P2P-assisted cloud provisioning system;cloud infrastructure;cloud paradigm;disruptive market opportunity;enterprise data centers;peer-to-peer networks;quality of service;Acceleration;Bandwidth;Cloud computing;Costs;File systems;Large-scale systems;Market opportunities;Network servers;Peer to peer computing;Protocols;BitTorrent;Cloud Computing;Peer-to-Peer;Provision}, 
doi={10.1109/ICDCSW.2009.35}, 
ISSN={1545-0678}, 
month={June},}
@ARTICLE{4937182, 
author={P. Hunter}, 
journal={Engineering Technology}, 
title={Keeping IP in trim - [IT network speed]}, 
year={2009}, 
volume={4}, 
number={5}, 
pages={58-60}, 
abstract={IP management is no longer just a lubricant for the machinery of enterprise networks. It has become a core part of the platform for delivering applications and enabling new business models to emerge: consider the huge impact that unified communications is starting to make, bringing key components such as presence along with IP-based voice and video into sharp focus. At the same time the growth of virtualisation and cloud computing will need more sophisticated IP management to maintain the separation between applications and the underlying infrastructure. These developments all rely on the ability to manage both IP traffic and end devices including IP addresses on the basis of application and user level information. Unified communications (UC) depends on identifying users and locating devices to select the correct message type and destination, which ultimately determine how the underlying IP traffic should be routed and what quality of service (QOS) be allocated to it.}, 
keywords={IP networks;Internet;business communication;telecommunication network management;telecommunication traffic;IP addresses;IP management;IP traffic;IP-based video;IP-based voice;business models;cloud computing;enterprise network;location services;quality of service;unified communication}, 
doi={10.1049/et.2009.0525}, 
ISSN={1750-9637}, 
month={March},}
@INPROCEEDINGS{5455133, 
author={T. Jia and X. Wang}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Notice of Retraction
The Construction and Realization of the Intelligent NIPS Based on the Cloud Security}, 
year={2009}, 
pages={1885-1888}, 
abstract={Notice of Retraction

After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.

We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.

The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.

The cloud security is a safe mode applied super Internet based on the cloud computing, also a new technology and the trend of development on network security. On the basis of outlining the cloud security's superiority, key technologies and the IPS technology, this paper proposes a new cloud security-based intelligent NIPS structure, function, characteristic and difference from general NIPS, finally discusses the way of realizing cloud security-based intelligent NIPS.}, 
keywords={Internet;security of data;cloud computing;cloud security;intelligent network invasion prevention systems;network security;super Internet;Cloud computing;Data security;Distributed computing;Electronic mail;Grid computing;IP networks;Information security;Intelligent networks;Intelligent structures;Parallel processing}, 
doi={10.1109/ICISE.2009.1192}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5302240, 
author={Q. Liu and X. Jian and J. Hu and H. Zhao and S. Zhang}, 
booktitle={2009 5th International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={An Optimized Solution for Mobile Environment Using Mobile Cloud Computing}, 
year={2009}, 
pages={1-5}, 
abstract={Cloud computing has been the most prevalent technology in the past few years and many prominent enterprises have prompted their cloud systems, preparing for the coming age of cloud computing. We can predict that the mobile area will take on a boom with the advent of this new concept. While due to the inherent characteristics of mobile environment, challenges like mobility, heterogeneity and low band-width will hinder the advancement of this incorporation. In this paper we will introduce a new concept and an abstraction derived from mobile agent-Universal Mobile Service Cell to shield the unequivalence of heterogeneous distributed systems between mobile devices and the cloud. Then scheduling the cell plays a key role in the mobile cloud computing. Here we adopt the Genetic Algorithm to meet this challenge. This paper is aimed at proposing a whole solution from the architecture to the algorithm.}, 
keywords={Web services;genetic algorithms;mobile agents;mobile computing;cloud systems;genetic algorithm;heterogeneous distributed systems;mobile agent;mobile cloud computing;mobile devices;universal mobile service cell;Cloud computing;Computer architecture;Distributed computing;Genetic algorithms;Mobile agents;Mobile communication;Mobile computing;Processor scheduling;Software engineering;Wireless networks}, 
doi={10.1109/WICOM.2009.5302240}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{4663749, 
author={D. A. Reed}, 
booktitle={2008 IEEE International Conference on Cluster Computing}, 
title={Clouds, clusters and ManyCore: The revolution ahead}, 
year={2008}, 
pages={1-1}, 
abstract={Without doubt, scientific discovery, business practice and social interactions are moving rapidly from a world of homogeneous and local systems to a world of distributed software, virtual organizations and cloud computing infrastructure, all powered by multicore processors and large-scale infrastructure. In science, a tsunami of new experimental and computational data and a suite of increasingly ubiquitous sensors pose vexing problems in data analysis, transport, visualization and collaboration. In society and business, software as a service and cloud computing are empowering distributed groups. Letpsilas step back and think about the longer term future. Where is the technology going and what are the implications? What architectures are appropriate? How to we manage power and scale? What are the right size building blocks? How do we come to grips with the fact that our clusters and data centers are now bigger than the Internet was just a few years ago? How do we develop and support malleable software? What is the ecosystem of components in which distributed, data rich applications will operate? How do we optimize performance and reliability? How do we program these systems?}, 
keywords={distributed processing;multiprocessing systems;ubiquitous computing;cloud computing;clusters;distributed software;homogeneous systems;large-scale infrastructure;local systems;multicore processors;ubiquitous sensors;virtual organizations;Cloud computing;Collaboration;Computer architecture;Data analysis;Data visualization;Energy management;Large-scale systems;Multicore processing;Pervasive computing;Tsunami}, 
doi={10.1109/CLUSTR.2008.4663749}, 
ISSN={1552-5244}, 
month={Sept},}
@INPROCEEDINGS{5207942, 
author={W. Qu and M. Li and C. Weng}, 
booktitle={2009 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
title={An Active Trusted Model for Virtual Machine Systems}, 
year={2009}, 
pages={145-152}, 
abstract={Virtualization is a new area for research in recent years, and virtualization technology can bring convenience to the management of computing resources. Together with the development of the network and the network computing, it gives the virtualization technology more scenarios. The cloud computing technology uses the virtualization technology as while. With the development of the technology, it meets some security problems, such as rootkit attacks and malignant tampers. Malicious programs can plug into the system, and be booted at the any time of the virtualized system. There is little theoretical research on booting a trusted virtualized system. We propose an active trusted model in order to give a theoretical model for not only analyzing the state of a virtualized system, but also helping to design trusted virtual machine application. TBoot is a project to boot a trusted virtual machine. We use our model to illustrate that TBoot can boot a trusted virtual machine theoretically.}, 
keywords={Internet;information resources;security of data;virtual machines;active trusted model;cloud computing technology;computing resources management;malicious programs;network computing;network development;trusted virtual machine;trusted virtualized system;virtual machine systems;virtualization technology;Application software;Application virtualization;Cloud computing;Computer interfaces;Computer networks;Hardware;Protection;Resource management;Standards development;Virtual machining;active model;measure;trusted virtual machine;verify}, 
doi={10.1109/ISPA.2009.68}, 
ISSN={2158-9178}, 
month={Aug},}
@INPROCEEDINGS{5380612, 
author={J. Hu and A. Klein}, 
booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
title={A Benchmark of Transparent Data Encryption for Migration of Web Applications in the Cloud}, 
year={2009}, 
pages={735-740}, 
abstract={Cloud computing is a new computing style which provides IT infrastructure and software as dynamic, scalable, and pay-per-use services. One of its characteristics is that enterprise data are hosted by storage service providers in the cloud. Hence strong data security must be taken into account for planning migration of business applications into the cloud. In this paper we analyze privacy requirements for the cloud applications and discuss data encryption approaches for securing e-commerce applications in the cloud. To provide quantitative estimation of performance penalties caused by data encryption, we made a benchmark for an online marketplace application as a case study. Lessons learned from the benchmark are also discussed in the paper to provide some recommendations for avoiding unnecessary encryption costs.}, 
keywords={Internet;cryptography;data privacy;electronic commerce;IT infrastructure;Web application;cloud computing;data security;e-commerce security;enterprise data;storage service providers;transparent data encryption approach;Application software;Cloud computing;Costs;Cryptography;Data privacy;Data security;Electronic commerce;Intrusion detection;Protection;Web services;Benchmark;Cloud Computing;Encryption}, 
doi={10.1109/DASC.2009.85}, 
month={Dec},}
@INPROCEEDINGS{5236390, 
author={E. Hai-Hong and M. N. Song and J. D. Song and X. x. Luo and X. Q. Zhang}, 
booktitle={2009 IEEE International Symposium on IT in Medicine Education}, 
title={A new service delivery open platform (SDOP) architecture}, 
year={2009}, 
volume={1}, 
pages={404-409}, 
abstract={Grid computing, utility computing, P2P computing, service computing and cloud computing, such as technological development is leading the future of networks resources, services resources, data resources toward shared, on-demand, and the tendency of promoting utility. To develop an internationally advanced course of study on service sciences has enormous opportunities, especially in service composing, service providing and the quality of service. However, there is not a complete framework for service delivery platform enables the open sharing of service resources, on-demand services delivery, service capabilities together combination, and service capacity delivery. In this paper, we introduce the layered architecture of service delivery open platform (SDOP), and particularly describe the components and the functions of SDOP. In conclusion, we present our recommended SDOP architecture and point out that the horizontal, layered SDOP architecture will help service operators to build a new service management and operation platform, such as B2B electronic commerce, digital education and digital medical, that provides security credible integrated services and open access to heterogeneous data, massive resources network capabilities and services capabilities.}, 
keywords={grid computing;peer-to-peer computing;software architecture;B2B electronic commerce;P2P computing;cloud computing;data resources;digital education;digital medical;grid computing;networks resources;on-demand services delivery;service capacity delivery;service computing;service delivery open platform architecture;services resources;utility computing;Cloud computing;Computer networks;Design engineering;Electronic commerce;Engineering management;Grid computing;Industrial economics;Refining;Resource management;Time sharing computer systems;SDOP;service capabilities;service delivery open platform;service science}, 
doi={10.1109/ITIME.2009.5236390}, 
month={Aug},}
@INPROCEEDINGS{5336745, 
author={V. Vinge}, 
booktitle={2009 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media and Humanities}, 
title={Mixed and augmented reality: #x201C;Scary and wondrous #x201D;}, 
year={2009}, 
pages={v-v}, 
abstract={Perhaps the most interesting question about the future of Mixed and Augmented Reality is the nature of the supporting infrastructure. The battle between big iron and minicomputers dates almost to the earliest days of computers. The debate has morphed again and again through the years. Its current incarnation is cloud computing versus microcontrollers distributed throughout the environment. Clouds have the mindshare right now, but I think the tension between centralized and distributed computing will continue long into the future, each approach complementing the other and each becoming more and more awesomely useful. A straightforward way to provide the latency and specifcity that AR needs is to use a huge number of itsy-bitsy computers distributed throughout the physical environment, each one with sensors, self-location knowledge, and near-neighbor wireless access. Ubiquity has always been a catchword of the distributed processing enthusiasts, and each new generation has pushed the idea beyond the horizons of the previous generation. Imagine an environment where most physical objects know where they are, what they are, and can (in principle) network with any other object. With this infrastructure, reality becomes its own database. Multiple consensual virtual environments are possible, each oriented to the needs of its constituency. If we also have open standards, then bottom-up social networks and even bottom-up advertising become possible. Now imagine that in addition to sensors, many of these itsy-bitsy processors are equipped with effectors. Then the physical world becomes much more like a software construct. The possibilities are both scary and wondrous.}, 
keywords={Augmented reality;Cloud computing;Delay;Distributed computing;Iron;Microcomputers;Microcontrollers;Military computing;Physics computing;Wireless sensor networks}, 
doi={10.1109/ISMAR-AMH.2009.5336745}, 
ISSN={2381-8360}, 
month={Oct},}
@INPROCEEDINGS{5380576, 
booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
title={[Title page i]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: secure computing; autonomic computing; pervasive intelligence; pervasive computing; Ubisafe computing; network evolution; routing innovation; social computing; social networking; ambient computing; ambient intelligence; cloud computing; software engineering; reality intelligence; ad hoc networks; sensor networks; smart homes; tele-health; intellectual information systems; trust management and pervasive systems.}, 
keywords={Internet;artificial intelligence;home automation;medical computing;mobile radio;security of data;social networking (online);telecommunication network routing;ubiquitous computing;wireless sensor networks;Ubisafe computing;ad hoc networks;ambient computing;ambient intelligence;autonomic computing;cloud computing;intellectual information systems;network evolution;pervasive computing;pervasive intelligence;pervasive systems;reality intelligence;routing innovation;secure computing;sensor networks;smart homes;social computing;social networking;software engineering;tele-health;trust management}, 
doi={10.1109/DASC.2009.1}, 
month={Dec},}
@INPROCEEDINGS{5455073, 
author={C. d. Gu and Y. Zhang and J. p. Wu}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Image Knowledge Management and Rapid Precise Image-Mining Technology Investigation in Internal Cloud Computing}, 
year={2009}, 
pages={2940-2942}, 
abstract={Internal cloud computing system can be built via constructing intra-enterprise server clusters, distributed database system, and parallel computing systems. We can define original semantic tags for digital images stored in the system or uploaded by users and store these tags in a distributed way. Then the corresponding search algorithms can be designed to help system to find the needed information promptly and accurately. And it can provide a fast image browsing interface based on the order of the degree of matching and worth to let users to choose and download the images they need. Particularly, we can build the industry-oriented, more specialized picture information base that enterprises can take advantage of. In the meantime, it can provide general-purpose users and specialized users with digital-image-related service suite. The innovation parts of this research include building intra-enterprise cloud computing system, the definition of index tags of the images based on the weight factors of various semantics and images to serve the purpose of accurately search images, and distributed storage of every copy of retrieved data in multiple databases installed on different servers to facilitate fast image-mining.}, 
keywords={Internet;data mining;distributed databases;image matching;indexing;information retrieval;knowledge management;workstation clusters;data retrieval;digital image semantic tags;distributed database system;fast image browsing interface;image knowledge management;internal cloud computing system;intraenterprise server cluster;parallel computing systems;rapid precise image mining technology;search algorithms;Algorithm design and analysis;Cloud computing;Clustering algorithms;Database systems;Digital images;Image storage;Indexes;Knowledge management;Parallel processing;Technological innovation}, 
doi={10.1109/ICISE.2009.649}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5071905, 
author={T. Hirofuchi and H. Ogawa and H. Nakada and S. Itoh and S. Sekiguchi}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={A Live Storage Migration Mechanism over WAN for Relocatable Virtual Machine Services on Clouds}, 
year={2009}, 
pages={460-465}, 
abstract={IaaS (Infrastructure-as-a-Service) is an emerging concept of cloud computing, which allows users to obtain hardware resources from virtualized data centers. Although many commercial IaaS clouds have recently been launched, dynamic virtual machine (VM) migration is not possible among service providers; users are locked into a particular provider, and cannot transparently relocate their VMs to another one for the best cost-effectiveness. In this paper, we propose an advanced storage access mechanism that strongly supports live VM migration over WAN. It rapidly relocates VM disks between source and destination sites with the minimum impact on I/O performance. The proposed mechanism addresses I/O consistency of virtual disks before/after migration, which is the major issue regarding wide-area live migration. The proposed mechanism works as a storage server of a block-level storage I/O protocol (e.g.,iSCSI and NBD). Two key techniques (on-demand fetching and background copying) move on-line virtual disks among remote sites, transparently and efficiently. Our prototype system works perfectly for Xen and KVM without any modification to them. Experiments showed the prototype system also worked successfully for an emulated WAN environment.}, 
keywords={Web services;computer centres;storage management;user interfaces;virtual machines;wide area networks;WAN environment;advanced storage access mechanism;background copying;cloud computing;dynamic virtual machine migration;infrastructure-as-a-service;live storage migration mechanism;on-demand fetching;virtualized data centers;Cloud computing;File servers;Hardware;Load management;Prototypes;Switches;Virtual machining;Virtual manufacturing;Voice mail;Wide area networks;Cloud Computing;IaaS;Live Migration;Storage;Virtual Machine;iSCSI}, 
doi={10.1109/CCGRID.2009.44}, 
month={May},}
@INPROCEEDINGS{5254138, 
author={I. Brandic}, 
booktitle={2009 33rd Annual IEEE International Computer Software and Applications Conference}, 
title={Towards Self-Manageable Cloud Services}, 
year={2009}, 
volume={2}, 
pages={128-133}, 
abstract={Cloud computing represents a promising computing paradigm, where computational power is provided as a utility. An important characteristic of Cloud computing, other than in similar paradigms like Grid or HPC computing, is the provision of non-functional guarantees to users. Thereby, applications can be executed considering predefined execution time, price, security or privacy standards, which are guaranteed in real time in form of Service Level Agreements (SLAs). However, due to changing components, workload, external conditions, hardware, and software failures, established SLAs may be violated. Thus, frequent user interactions with the system, which are usually necessary in case of failures, might turn out to be an obstacle for the success of Cloud computing. In this paper we discuss self-manageable Cloud services. In case of failures, environmental changes, and similar, services manage themselves automatically following the principles of autonomic computing. Based on the life cycle of a self-manageable Cloud service we derive a resource submission taxonomy. Furthermore, we present an architecture for the implementation of self-manageable Cloud services. Finally, we discuss the application of autonomic computing to Cloud services based on service mediation and negotiation bootstrapping case study.}, 
keywords={Web services;fault tolerant computing;system recovery;autonomic computing;cloud computing;external condition;hardware failure;negotiation bootstrapping;resource submission taxonomy;self-manageable cloud service;service level agreement;software failure;user interaction;Application software;Cloud computing;Computer applications;Computer architecture;Environmental management;Grid computing;Hardware;Power system security;Privacy;Taxonomy;Autonomic Computing;Cloud Computing;Service Self-management;Web Services}, 
doi={10.1109/COMPSAC.2009.126}, 
ISSN={0730-3157}, 
month={July},}
@INPROCEEDINGS{5402561, 
author={S. Biggs and S. Vidalis}, 
booktitle={2009 International Conference for Internet Technology and Secured Transactions, (ICITST)}, 
title={Cloud Computing: The impact on digital forensic investigations}, 
year={2009}, 
pages={1-6}, 
abstract={Cloud Computing (CC) as a concept and business opportunity is likely to see many organisations experiencing the 'credit crunch', embrace the relatively low cost option of CC to ensure continued business viability and sustainability. The pay-as-you-go structure of the CC business model is typically suited to SME's who do not have the resources to completely fulfil their IT requirements. Private end users will also look to utilise the colossal pool of resources that CC offers in an attempt to provide mobile freedom of information. However, as with many opportunities that offer legitimate users enormous benefits, unscrupulous and criminal users will also look to use CC to exploit the loopholes that may exist within this new concept, design and business model. This paper will outline the tasks that the authors undertook for the CLOIDIFIN project and highlight where the impact of CC will diversely effect digital forensic investigations.}, 
keywords={commerce;computer forensics;CC business model;CLOIDIFIN project;SME;business sustainability;business viability;cloud computing;digital forensic investigations;Capacitive sensors;Cloud computing;Companies;Computer crime;Costs;Digital forensics;Frequency;Guidelines;Law enforcement;Operations research}, 
doi={10.1109/ICITST.2009.5402561}, 
month={Nov},}
@INPROCEEDINGS{5381699, 
author={C. Rathbone and L. Wang and G. von Laszewski and F. Wang}, 
booktitle={2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks}, 
title={Cyberaide Creative: On-Demand Cyberinfrastructure Provision in Clouds}, 
year={2009}, 
pages={684-690}, 
abstract={As demand for grid and cloud computing solutions increases, the need for user oriented software to provide access to theses resources also increases. Until recently the use of computing resources was limited to those with exceptional knowledge of the system design and configuration. With the advent of grid middleware projects this started to change allowing for new users not familiar with the complex grid infrastructure and client software to use the systems for their own research. The Cyberaide Gridshell demonstrated this by developing a user friendly interface to submit jobs to a grid. Following this theme it is our objective to create a tool that will take another step further by abstracting the creation and configuration of the infrastructure and system software away from the end-user. This will be achieved through the use of cloud resources provided by VMware virtualization and deployment via a web interface. We will show the benefits of deploying cyber infrastructures, like clusters and grids, on a cloud design by demonstrating the ease of cyber infrastructure deployment and the versatility of the systems that can be spawned on demand.}, 
keywords={grid computing;middleware;user interfaces;Cyberaide Gridshell;VMware virtualization;Web interface;client software;cloud computing;cloud resources;computing resources;grid computing;grid infrastructure;grid middleware;on-demand cyberinfrastructure provision;user friendly interface;user oriented software;Cloud computing;Computer interfaces;Computer networks;Grid computing;Hardware;Middleware;Pervasive computing;Resource virtualization;Software algorithms;System software}, 
doi={10.1109/I-SPAN.2009.23}, 
ISSN={1087-4089}, 
month={Dec},}
@INPROCEEDINGS{5190712, 
author={T. Anstett and F. Leymann and R. Mietzner and S. Strauch}, 
booktitle={2009 Congress on Services - I}, 
title={Towards BPEL in the Cloud: Exploiting Different Delivery Models for the Execution of Business Processes}, 
year={2009}, 
pages={670-677}, 
abstract={More and more companies are outsourcing parts of their business processes to third party providers to exploit the expertise and economies of scale of these third party providers. In the IT field, emerging delivery models for software such as Software as a Service and cloud computing offer the possibility to outsource applications and computing infrastructure and thus enable enterprises to focus on their core competences. In this paper we investigate how the new delivery models affect the outsourcing of business processes modeled in WS-BPEL. WS-BPEL is the standard to model and execute business processes in Web service-based IT landscapes. We describe how security and trust issues affect the execution of BPEL processes in the cloud and show the requirements on the middleware supporting the execution of BPEL processes.}, 
keywords={Web services;business data processing;middleware;outsourcing;WS-BPEL;Web service-based IT landscape;business process execution;cloud computing;delivery model;middleware;outsourcing;third party provider;Application software;Cloud computing;Companies;Computer architecture;Economies of scale;Engines;Middleware;Outsourcing;Service oriented architecture;Web services;BPEL;Cloud Computing;IaaS;PaaS;SaaS;Security;Trust}, 
doi={10.1109/SERVICES-I.2009.32}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5353059, 
author={M. Gómez and D. Perales and E. J. Torres}, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={An energy-aware design and reporting tool for on-demand service infrastructures}, 
year={2009}, 
pages={209-216}, 
abstract={During last years, great progress has been made in exposing the energy consumption of computing equipment and providing infrastructure users with mechanisms to adequate power expenditures to the performance levels required from hardware elements. However, mapping such hardware-level capabilities to service-level energy monitoring and control mechanisms is not straightforward in advanced service delivery scenarios, where the implementation of virtualization technologies and the adoption of the cloud computing paradigm abstract infrastructure users from the physical details of the platform where their services are running. In this context, this paper presents the energy-aware design and reporting capabilities introduced in the management system of an Infrastructure as a Service (IaaS) platform in order to assist users in defining energy-efficient infrastructure architectures and provide infrastructure users and providers with service-level energy chargeback information. The energy estimation mechanisms employed to assess architecture designs and the energy apportionment procedures used to attribute service energy consumption are detailed, providing also practical usage examples to clarify their utilization within the management system.}, 
keywords={energy consumption;power engineering computing;software architecture;virtual reality;architecture designs;cloud computing;computing equipment;energy consumption;energy-aware design;energy-aware reporting tool;infrastructure as a service;on-demand service infrastructures;virtualization technologies;Cloud computing;Computer architecture;Context-aware services;Energy consumption;Energy efficiency;Energy management;Hardware;Monitoring;Platform virtualization;Resource management}, 
doi={10.1109/GRID.2009.5353059}, 
ISSN={2152-1085}, 
month={Oct},}
@INPROCEEDINGS{5380521, 
author={J. Schiffman and T. Moyer and C. Shal and T. Jaeger and P. McDaniel}, 
booktitle={2009 Annual Computer Security Applications Conference}, 
title={Justifying Integrity Using a Virtual Machine Verifier}, 
year={2009}, 
pages={83-92}, 
abstract={Emerging distributed computing architectures, such as grid and cloud computing, depend on the high integrity execution of each system in the computation. While integrity measurement enables systems to generate proofs of their integrity to remote parties, we find that current integrity measurement approaches are insufficient to prove runtime integrity for systems in these architectures. Integrity measurement approaches that are flexible enough have an incomplete view of runtime integrity, possibly leading to false integrity claims, and approaches that provide comprehensive integrity do so only for computing environments that are too restrictive. In this paper, we propose an architecture for building comprehensive runtime integrity proofs for general purpose systems in distributed computing architectures. In this architecture, we strive for classical integrity, using an approximation of the Clark-Wilson integrity model as our target. Key to building such integrity proofs is a carefully crafted host system whose long-term integrity can be justified easily using current techniques and a new component, called a VM verifier, which comprehensively enforces our integrity target on VMs. We have built a prototype based on the Xen virtual machine system for SELinux VMs, and find that distributed compilation can be implemented, providing accurate proofs of our integrity target with less than 4% overhead.}, 
keywords={Linux;distributed programming;virtual machines;Clark-Wilson integrity model;SELinux;VM verifier;Xen virtual machine system;cloud computing;distributed computing architectures;false integrity;grid computing;integrity measurement;virtual machine verifier;Buildings;Cloud computing;Computer architecture;Current measurement;Distributed computing;Grid computing;Runtime environment;Virtual machining;Virtual manufacturing;Voice mail;cloud computing;integrity measurement;virtual machines}, 
doi={10.1109/ACSAC.2009.18}, 
ISSN={1063-9527}, 
month={Dec},}
@INPROCEEDINGS{5377446, 
author={Z. Li and J. Zhang and X. Chen and D. Han and W. Gu and Y. Ji}, 
booktitle={2009 Asia Communications and Photonics conference and Exhibition (ACP)}, 
title={The research of cloud computing based on service plane over optical networks}, 
year={2009}, 
pages={1-2}, 
abstract={A novel cloud computing architecture over optical networks is proposed based on the service plane. An experiment of resources dynamic co-schedule is deployed on our AMSON testbed and the result of it demonstrates the validity of the architecture we proposed.}, 
keywords={Cloud computing;Computer architecture;Computer network management;Distributed computing;Network servers;Optical fiber networks;Resource management;Resource virtualization;Service oriented architecture;Testing}, 
doi={10.1364/ACP.2009.FO4}, 
ISSN={2162-108X}, 
month={Nov},}
@INPROCEEDINGS{4663752, 
author={M. Kesavan and A. Ranadive and A. Gavrilovska and K. Schwan}, 
booktitle={2008 IEEE International Conference on Cluster Computing}, 
title={Active CoordinaTion (ACT) - toward effectively managing virtualized multicore clouds}, 
year={2008}, 
pages={23-32}, 
abstract={A key benefit of utility data centers and cloud computing infrastructure is the level of consolidation they can offer to arbitrary guest applications, and the substantial saving in operational costs and resources that can be derived in the process. However, significant challenges remain before it becomes possible to effectively and at low cost manage virtualized systems, particularly in the face of increasing complexity of individual many-core platforms, and given the dynamic behaviors and resource requirements exhibited by cloud guest VMs. This paper describes the active coordination (ACT) approach, aimed to address a specific issue in the management domain, which is the fact that management actions must (1) typically touch upon multiple resources in order to be effective, and (2) must be continuously refined in order to deal with the dynamism in the platform resource loads. ACT relies on the notion of class-of-service, associated with (sets of) guest VMs, based on which it maps VMs onto platform units, the latter encapsulating sets of platform resources of different types. Using these abstractions, ACT can perform active management in multiple ways, including a VM-specific approach and a black box approach that relies on continuous monitoring of the guest VMs' runtime behavior and on an adaptive resource allocation algorithm, termed Multiplicative Increase, Subtractive Decrease Algorithm with Wiggle Room. In addition, ACT permits explicit external events to trigger VM or application-specific resource allocations, e.g., leveraging emerging standards such as WSDM. The experimental analysis of the ACT prototype, built for Xen-based platforms, use industry-standard benchmarks, including RUBiS, Hadoop, and SPEC. They demonstrate ACT's ability to efficiently manage the aggregate platform resources according to the guest VMs' relative importance (class-of-service), for both the black-box and the VM-specific approach.}, 
keywords={computer centres;resource allocation;system monitoring;virtual machines;Hadoop;RUBiS;SPEC;WSDM;Xen-based platform;active coordination approach;adaptive resource allocation algorithm;black box approach;class-of-service notion;cloud computing infrastructure;continuous runtime behavior monitoring;multiplicative increase subtractive decrease algorithm;utility data center;virtual machine-specific approach;virtualized multicore cloud management;Cloud computing;Costs;Multicore processing;Platform virtualization;Prototypes;Resource management;Resource virtualization;Runtime;Virtual manufacturing;Voice mail}, 
doi={10.1109/CLUSTR.2008.4663752}, 
ISSN={1552-5244}, 
month={Sept},}
@INPROCEEDINGS{4812605, 
author={K. S. Candan and W. S. Li and T. Phan and M. Zhou}, 
booktitle={2009 IEEE 25th International Conference on Data Engineering}, 
title={Frontiers in Information and Software as Services}, 
year={2009}, 
pages={1761-1768}, 
abstract={The high cost of creating and maintaining software and hardware infrastructures for delivering services to businesses has led to a notable trend toward the use of third-party service providers, which rent out network presence, computation power, and data storage space to clients with infrastructural needs. These third party service providers can act as data stores as well as entire software suites for improved availability and system scalability, reducing small and medium businesses' burden of managing complex infrastructures. This is called information/application outsourcing or software as a service (SaaS). Emergence of enabling technologies, such as service oriented architectures (SOA), virtual machines, and cloud computing, contribute to this trend. Scientific grid computing, on-line software services, and business service networks are typical examples leveraging database and software as service paradigm. In this paper, we survey the technologies used to enable SaaS paradigm as well as the current offerings on the market. We also outline research directions in the field.}, 
keywords={grid computing;software engineering;cloud computing;hardware infrastructures;scientific grid computing;service oriented architectures;software maintenance;third-party service providers;virtual machines;Availability;Computer networks;Costs;Disaster management;Hardware;Memory;Power system management;Scalability;Service oriented architecture;Software maintenance}, 
doi={10.1109/ICDE.2009.168}, 
ISSN={1063-6382}, 
month={March},}
@INPROCEEDINGS{5402569, 
author={S. Boldyrev and I. Oliver and R. Brown and J. M. Tuupola and A. Palin and A. Lappetelainen}, 
booktitle={2009 International Conference for Internet Technology and Secured Transactions, (ICITST)}, 
title={Network and content aware information management}, 
year={2009}, 
pages={1-7}, 
abstract={The presented approach addresses the problem of query and persistent query (subscription) resolution, taking into consideration distribution across multi-domains, network infrastructure and content management. This approach is particularly suitable for information-centric and cloud computing applications based around a mobile-device infrastructure.}, 
keywords={content management;information management;persistent objects;query processing;ubiquitous computing;cloud computing applications;content aware information management;information-centric applications;mobile-device infrastructure;network infrastructure;persistent query resolution;Cameras;Cloud computing;Computer architecture;Content management;Delay;Displays;Information management;Information retrieval;Microphones;Subscriptions}, 
doi={10.1109/ICITST.2009.5402569}, 
month={Nov},}
@INPROCEEDINGS{5224231, 
author={S. F. A. Razak}, 
booktitle={2009 Innovative Technologies in Intelligent Systems and Industrial Applications}, 
title={Cloud computing in Malaysia Universities}, 
year={2009}, 
pages={101-106}, 
abstract={Students in the 21st century can no longer be confined to traditional teaching-learning methods, i.e. lecturing and tutoring which is commonly used in universities. Universities from around the global have recognized needs to adapt new teaching learning approach to meet students' diverse need. This paper will briefly discuss cloud computing and the possible benefits or offerings cloud computing have for universities especially in Malaysia. We will also look into a few challenges that need to be recognized by universities in adapting cloud computing into the teaching learning environment.}, 
keywords={computer aided instruction;educational institutions;teaching;Malaysia university;cloud computing;lecturing method;teaching learning method;tutoring method;Application software;Appraisal;Cloud computing;Communications technology;Continuing education;Continuing professional development;Educational institutions;Intelligent systems;Knowledge transfer;Problem-solving}, 
doi={10.1109/CITISIA.2009.5224231}, 
month={July},}
@INPROCEEDINGS{5408000, 
author={X. Gao and M. Lowe and Y. Ma and M. Pierce}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Supporting cloud computing with the virtual block store system}, 
year={2009}, 
pages={71-78}, 
abstract={The fast development of cloud computing systems stimulates the needs for a standalone block storage system to provide persistent block storage services to virtual machines maintained by clouds. This paper presents the Virtual Block Store (VBS) System, a standalone block storage system built on the basis of LVM, iSCSI, and Xen hypervisor, which can provide basic block storage services such as volume creation and attachment. The concept and functional interface of VBS are based on Amazon Elastic Block Store (EBS) service; moreover, VBS works independently with an existing LVM volume server and Xen nodes, and thus can be easily extended to support other types of volume servers and virtual machine managers, or integrated with various cloud computing systems. Preliminary I/O benchmark results are presented and analyzed, indicating that a VBS volume can provide throughput that is similar to an ATA over Ethernet virtual device.}, 
keywords={Cloud computing;Ethernet networks;File systems;Image storage;Memory;Resource management;Virtual machine monitors;Virtual machining;Virtual manufacturing;Voice mail}, 
doi={10.1109/ESCIW.2009.5408000}, 
month={Dec},}
@INPROCEEDINGS{5070949, 
booktitle={2009 31st International Conference on Software Engineering - Companion Volume}, 
title={[Title page]}, 
year={2009}, 
pages={i-i}, 
abstract={The following topics are dealt with: software engineering; software estimation; complex system; model checking; software refactoring; software tool; software testing; software defect prediction; software component; software development; software requirement analysis; software product line; software comprehension; software quality and cloud computing.}, 
keywords={software engineering;cloud computing;complex system;model checking;software component;software comprehension;software defect prediction;software development;software engineering;software estimation;software product line;software quality;software refactoring;software requirement analysis;software testing;software tool}, 
doi={10.1109/ICSE-COMPANION.2009.5070949}, 
month={May},}
@INPROCEEDINGS{5439474, 
author={M. K. Nair and V. Gopalakrishna}, 
booktitle={2009 IEEE International Conference on Internet Multimedia Services Architecture and Applications (IMSAA)}, 
title={ #x2018;CloudCop #x2019;: Putting network-admin on cloud nine towards Cloud Computing for Network Monitoring}, 
year={2009}, 
pages={1-6}, 
abstract={Computer Network Monitoring is an evergreen field of challenges. The recent advent of Cloud Computing, in the realm of `New Generation Networks', opens a whole new field of envisaging and implementing at least two of its aspects, namely `Software as a Service(SaaS)'and `Platform as a Service(PaaS)' in the field of Network Management(NM). In this paper, we present the design and implementation of a Network Monitoring Framework oriented towards Cloud Computing which we call `CloudCop'. The NM framework uses Web Services (WS) and Service Oriented Computing (SOC) to implement SaaS, while PaaS is provided by providing some of the features such as WS marshalling, integration, storage and persistence. Its data storage schema is made very generic to be applicable for other applications thus being in tune with the vision of SOC. It also employs a whole gamut of technologies such as WS, SOC, Mobile Agents(MA), Simple Network Management Protocol(SNMP) and is made scalable and robust enough to absorb new pieces such as Rule Engines and Ontology based Service Discovery which are planned in the next implementation phase. Therefore, this paper attempts to provide directions on the applicability of Cloud Computing for NM with a case study and implementation results paving the way for the users of such applications, network system administrators (network-admin)truly elated and therefore on `cloud nine'!}, 
keywords={Internet;Web services;telecommunication network management;CloudCop;PaaS;SNMP;SOC;SaaS;Web services;cloud computing;cloud nine;computer network monitoring;data storage;mobile agents;network admin;network management;network monitoring framework;network system administrators;platform as a service;rule engines;service oriented computing;simple network management protocol;software as a service;Cloud computing;Computer network management;Computer networks;Computerized monitoring;Engines;Memory;Ontologies;Robustness;Technology management;Web services;Agent Based Web Services;Cloud Computing;Enterprise Agent;Network Monitoring and Management;Service Oriented Computing;Web Services}, 
doi={10.1109/IMSAA.2009.5439474}, 
month={Dec},}
@INPROCEEDINGS{5408006, 
author={C. Baun and M. Kunze}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Building a private cloud with Eucalyptus}, 
year={2009}, 
pages={33-38}, 
abstract={Scientists very often have specific requirements regarding the IT services to support their research and very often standardized offerings of their service providers do not fit. At KIT we aim to build a private cloud to offer flexible infrastructure services that can easily be utilized and managed by end users according to their needs. With Eucalyptus, an open source solution exists that is fully compatible with Amazon EC2, S3 and EBS. This paper compares the performance of a cloud computing infrastructure implemented with Eucalyptus to Amazon EC2/S3/EBS and includes the lessons learned while building up a private cloud with Eucalyptus.}, 
keywords={Internet;public domain software;Amazon EC2/S3/EBS;Eucalyptus;IT services;cloud computing infrastructure;flexible infrastructure services;open source solution;private cloud;service providers;Application software;Application virtualization;Centralized control;Cloud computing;Computer networks;Open source software;Platform virtualization;Protocols;Virtual machining;Web services}, 
doi={10.1109/ESCIW.2009.5408006}, 
month={Dec},}
@INPROCEEDINGS{5175852, 
author={Y. Wu and Z. Zou and Y. Chen and Y. Zhao and Q. Wang}, 
booktitle={2009 IEEE International Conference on Web Services}, 
title={SPA: A Comprehensive Framework for Hybrid Solution Provisioning}, 
year={2009}, 
pages={421-428}, 
abstract={With the emerging technologies like cloud computing and Internet scale data centers, radically simplified deployment approaches are critical for the success of the even more complicated solutions. Although there have been many traditional solution deployment approaches, each of them mainly focuses on particular software type or product. In this paper, we propose the next generation solution deployment paradigm as hybrid solution deployment, which enables fast solution deployment from bare metal mode to production mode based on todaypsilas state-of-the-art provisioning tools. Solution provisioning automation (SPA) framework is our practice of such deployment paradigm. In SPA, we use solution template to capture the solution components and their dependencies, which exposes only the necessary parameters for users to customize. Provisioning Requests are placed through reservations and scheduled globally for execution. The SPA engine receives provisioning requests from scheduler, interprets the solution template, manages provisioning tasks and performs runtime logging. We also present a real world case to demonstrate the effectiveness of our approach.}, 
keywords={Web services;ubiquitous computing;cloud computing;hybrid solution provisioning;solution provisioning automation;Application software;Assembly;Automation;Costs;Home appliances;Java;Middleware;Operating systems;Packaging machines;Production}, 
doi={10.1109/ICWS.2009.15}, 
month={July},}
@INPROCEEDINGS{5071529, 
author={A. Lenk and M. Klems and J. Nimis and S. Tai and T. Sandholm}, 
booktitle={2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing}, 
title={What's inside the Cloud? An architectural map of the Cloud landscape}, 
year={2009}, 
pages={23-31}, 
abstract={We propose an integrated Cloud computing stack architecture to serve as a reference point for future mash-ups and comparative studies. We also show how the existing Cloud landscape maps into this architecture and identify an infrastructure gap that we plan to address in future work.}, 
keywords={Internet;software architecture;architectural map;cloud landscape;integrated cloud computing stack architecture;mash-ups;Application virtualization;Business;Cloud computing;Computer architecture;Distributed computing;Laboratories;Platform virtualization;Resource virtualization;Service oriented architecture;Software systems}, 
doi={10.1109/CLOUD.2009.5071529}, 
month={May},}
@INPROCEEDINGS{5342089, 
author={H. J. La and S. W. Choi and S. D. Kim}, 
booktitle={2009 IEEE International Conference on e-Business Engineering}, 
title={Technical Challenges and Solution Space for Developing SaaS and Mash-Up Cloud Services}, 
year={2009}, 
pages={359-364}, 
abstract={As an effective reuse paradigm, Cloud Computing (CC) provide many benefits. Among different types of cloud services, SaaS and Mash-up services are delivering the conventional software functionality as a service. Hence, both types of services become alternatives to acquisition of conventional software applications. However, there are some critical technical problems/risks in trying to reuse SaaS and Mash-up services, such as providing pre-specified scalability even at peak and engineering services with high commonality and applicability. In this paper, we first define meta-models of two types of cloud services; SaaS and Mash-up Service. For each type of cloud service, we raise two technical issues and provide their effective solution space. By applying the provided solutions, much of the technical problems and risks can be remedied in advance, making cloud services more reusable and reliable.}, 
keywords={Web services;cloud computing;mash-up cloud service reuse;meta model;software application;software functionality;Application software;Availability;Cloud computing;Computer interfaces;Computer science;Hardware;Scalability;Service oriented architecture;Web and internet services;Web server;Cloud Computing;Mash-up Service;Software-as-a-Service (SaaS);Technical Challenges and Solutions}, 
doi={10.1109/ICEBE.2009.56}, 
month={Oct},}
@INPROCEEDINGS{4839205, 
author={D. Lamb and M. Randles and A. Taleb-Bendiab}, 
booktitle={2009 Sixth IEEE Conference and Workshops on Engineering of Autonomic and Autonomous Systems}, 
title={Monitoring Autonomic Networks through Signatures of Emergence}, 
year={2009}, 
pages={56-65}, 
abstract={This paper addresses the problems of delivering autonomic management of large-scale networks. It encompasses both the governance of networks of autonomic components and the autonomic governance of networks and indeed the provision of the latter by the former. For this it is necessary to consider the complexity of the systems involved and the mastering of this complexity by distributed self-* functions. The complexity arises as a natural result of the engineered robustness; as with all autonomic systems the components added to provide self-*operations also add to the complexity. In addition the feedback control loops within larger scale systems will interact causing emergent outcome to the system as a whole and to individual self-* functions. This often means that the system is robust to large environmental perturbations yet remains vulnerable to cascading failures initiated by small perturbations. This is investigated through a formally specified observer system where novel outcome can be grounded to a series of actions and likely outcome reasoned upon. This further demands a range of metrics over which reasoning needs to take place: In this paper the algebraic connectivity of the (autonomic) network (of networks) is considered and a implementation presented based on autonomic monitoring selection by self-organisation characterisation. This addresses many current in establishing models of future computation such as the Internet of Services or Cloud Computing.}, 
keywords={computational complexity;digital signatures;feedback;software fault tolerance;algebraic connectivity;autonomic networks;distributed self-functions;feedback control loops;large-scale networks;observer system;signatures of emergence;Cloud computing;Computational modeling;Disaster management;Feedback control;Large-scale systems;Monitoring;Power system faults;Power system protection;Robustness;Web and internet services}, 
doi={10.1109/EASe.2009.18}, 
ISSN={2168-1864}, 
month={April},}
@INPROCEEDINGS{5394149, 
booktitle={2009 IEEE Asia-Pacific Services Computing Conference (APSCC)}, 
title={[Title page]}, 
year={2009}, 
pages={i-xxv}, 
abstract={The following topics are dealt with: business process integration and management; cloud computing; Web computing; utility computing; foundations of services computing; mobile computing; ubiquitous computing; pervasive computing; and service-centric computing models.}, 
keywords={Internet;business process re-engineering;mobile computing;business process integration;business process management;cloud computing;mobile computing;service-centric computing;services computing}, 
doi={10.1109/APSCC.2009.5394149}, 
month={Dec},}
@INPROCEEDINGS{5138050, 
author={X. Chen}, 
booktitle={2009 International Conference on E-Business and Information System Security}, 
title={Research on Grid-Service Based Virtual Products Experience Environment Supporting Architecture in E-commerce Applications}, 
year={2009}, 
pages={1-5}, 
abstract={Internet-based virtual product experience enables online electronic commerce (e-commerce) websites to present and promote their products more efficiently and is essential to the success of e-commerce especially for those providing complex products websites. Despite the advantages of virtual product experience, integrating and constructing multidisciplinary virtual product model data for e-commerce websites and improving interactivity and validity of virtual product design and presentation in web environment are the key technical problems in virtual complex products supporting system. After long time research on Grid services and multi-agent systems, a Grid-service based virtual product experience supporting system was proposed, system architecture, communication style and system workflow were illustrated. Further more it discussed virtual complex product design and development process, decision arithmetic and gave the structure of intelligent agent group for communities or enterprises involved in virtual complex product design, realized a service-oriented multi-field collaborative virtual product experience supporting platform for e-commerce websites. Further researches of the system and in cloud computing environment operation were prospected.}, 
keywords={Internet;Web sites;electronic commerce;grid computing;multi-agent systems;product design;virtual reality;Internet;Web sites;collaborative virtual product experience supporting platform;e-commerce application;grid service;intelligent agent group;multiagent system;multidisciplinary virtual product model data;online electronic commerce;system workflow;virtual complex product design;Arithmetic;Cloud computing;Collaborative work;Costs;Electronic commerce;Environmental management;Intelligent agent;Multiagent systems;Multimedia systems;Product design}, 
doi={10.1109/EBISS.2009.5138050}, 
ISSN={2161-5942}, 
month={May},}
@INPROCEEDINGS{5381731, 
author={M. Yildiz and J. Abawajy and T. Ercan and A. Bernoth}, 
booktitle={2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks}, 
title={A Layered Security Approach for Cloud Computing Infrastructure}, 
year={2009}, 
pages={763-767}, 
abstract={This paper introduces a practical security model based on key security considerations by looking at a number of infrastructure aspects of Cloud Computing such as SaaS, Utility, Web, Platform and Managed Services, Service commerce platforms and Internet Integration which was introduced with a concise literature review. The purpose of this paper is to offer a macro level solution for identified common infrastructure security requirements. This model with a number of emerged patterns can be applied to infrastructure aspect of Cloud Computing as a proposed shared security approach in system development life cycle focusing on the plan-built-run scope.}, 
keywords={Internet;security of data;cloud computing infrastructure;key security consideration;security model;security requirement;system development life cycle;Business;Cloud computing;Computer networks;Computer security;Data security;Grid computing;Information security;Pervasive computing;Web and internet services;Web services;Cloud computing;Dynamic infrastructure;Grid computing;Security;Service Oriented Architectures;Utility computing;Virtualization}, 
doi={10.1109/I-SPAN.2009.157}, 
ISSN={1087-4089}, 
month={Dec},}
@INPROCEEDINGS{5071845, 
author={R. Buyya}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={Market-Oriented Cloud Computing: Vision, Hype, and Reality of Delivering Computing as the 5th Utility}, 
year={2009}, 
pages={1-1}, 
abstract={Computing is being transformed to a model consisting of services that are commoditised and delivered in a manner similar to utilities such as water, electricity, gas, and telephony. In such a model, users access services based on their requirements without regard to where the services are hosted. Several computing paradigms have promised to deliver this utility computing vision and they include Grid computing, P2P computing, and more recently Cloud computing. The latter term denotes the infrastructure as a ldquoCloudrdquo in which businesses and users are able to access applications from anywhere in the world on demand. Hence, Cloud computing can be classed as a new paradigm for the dynamic creation of next-generation Data Centers by assembling services of networked Virtual Machines (VMs). Thus, the computing world is rapidly transforming towards developing software for millions to consume as a service rather than creating software for millions to run on their PCs.}, 
keywords={Internet;computer centres;customer services;resource allocation;virtual machines;SLA-oriented resource allocation;computational risk management;customer-driven service management;market-oriented cloud computing;market-oriented resource management;networked virtual machines;next-generation data centers;pay-as-you-go model;subscription-based services;utility computing vision;Application software;Assembly;Cloud computing;Computer vision;Grid computing;Next generation networking;Personal communication networks;Telephony;Virtual machining;Voice mail}, 
doi={10.1109/CCGRID.2009.97}, 
month={May},}
@INPROCEEDINGS{5283911, 
author={B. R. Kandukuri and R. P. V. and A. Rakshit}, 
booktitle={2009 IEEE International Conference on Services Computing}, 
title={Cloud Security Issues}, 
year={2009}, 
pages={517-520}, 
abstract={In past three decades, the world of computation has changed from centralized (client-server not web-based) to distributed systems and now we are getting back to the virtual centralization (Cloud Computing). Location of data and processes makes the difference in the realm of computation. On one hand, an individual has full control on data and processes in his/her computer. On the other hand, we have the cloud computing wherein, the service and data maintenance is provided by some vendor which leaves the client/customer unaware of where the processes are running or where the data is stored. So, logically speaking, the client has no control over it. The cloud computing uses the internet as the communication media. When we look at the security of data in the cloud computing, the vendor has to provide some assurance in service level agreements (SLA) to convince the customer on security issues. Organizations use cloud computing as a service infrastructure, critically like to examine the security and confidentiality issues for their business critical insensitive applications. Yet, guaranteeing the security of corporate data in the "cloud" is difficult, if not impossible, as they provide different services like Software as a service (SaaS), Platform as a service (PaaS), and Infrastructure as a service (IaaS). Each service has their own security issues. So the SLA has to describe different levels of security and their complexity based on the services to make the customer understand the security policies that are being implemented. There has to be a standardized way to prepare the SLA irrespective to the providers. This can help some of the enterprises to look forward in using the cloud services. In this paper, we put forward some security issues that have to be included in SLA.}, 
keywords={Internet;contracts;security of data;Internet;business critical insensitive applications;cloud computing;cloud security issues;communication media;distributed systems;infrastructure as a service;platform as a service;security policies;service infrastructure;service level agreements;software as a service;virtual centralization;Application software;Automation;Cloud computing;Computer architecture;Conference management;Costs;Data security;Marketing and sales;Subscriptions;Usability;Cloud Computing;Cloud computing Security;Service Level Agreement (SLA);Software as a Service (SaaS)}, 
doi={10.1109/SCC.2009.84}, 
month={Sept},}
@INPROCEEDINGS{5370108, 
author={F. Liu and X. Luo and J. Yu and G. Liang}, 
booktitle={2009 Fifth International Conference on Semantics, Knowledge and Grid}, 
title={Semantic Cloud Based on SLN and ALN}, 
year={2009}, 
pages={314-317}, 
abstract={Clouding computing is considered as one of the most promising computing paradigms. Most already existing systems, which provide cloud computing, only pay attention to aggregating resources with the same computing capability and provide user with local optimized and discontinuous results. To satisfy users' complex requirements it's necessary to orchestrate resources with different functions together and produce the personalized resource flow to users. In this paper, we offer an approach for the issues. We build a semantic layer for cloud computing to connect resources from different domains. Our approach relies on the semantic representation and relationship of resources. The Similarity Link Network (SLN) and Association Link Network (ALN) based on the similarity and association relation respectively, form SLN-cloud and ALN-cloud which makes the clouds with rich abilities possible. Accurate and continuous results can be provided to users depending on the global view of resources.}, 
keywords={grid computing;association link network;association relation;semantic cloud computing;similarity link network;similarity relation;Application software;Cloud computing;Cognitive informatics;Computer architecture;Computer networks;Concurrent computing;Distributed computing;Grid computing;Knowledge engineering;Next generation networking;cloud computing;semantic link network}, 
doi={10.1109/SKG.2009.87}, 
month={Oct},}
@INPROCEEDINGS{4634959, 
author={S. Gaisbauer and J. Kirschnick and N. Edwards and J. Rolia}, 
booktitle={2008 Fifth International Conference on Quantitative Evaluation of Systems}, 
title={VATS: Virtualized-Aware Automated Test Service}, 
year={2008}, 
pages={93-102}, 
abstract={It is anticipated that by 2015 more than 75% of Information Technology infrastructure will be purchased as a service from service providers. Services will be hosted in virtualized shared resource pools referred to as Clouds. Service providers will need to ensure that customer performance requirements are satisfied while consuming an acceptable quantity of resources. This paper describes a Virtualization-aware Automated Testing Service (VATS). VATS is a framework for automated test execution in Cloud computing environments. It executes tests, manipulates virtualized infrastructure, and collects performance information. VATS uses HP LoadRunner as a load generator and provides the foundation for an automatic performance evaluator for Cloud environments. A case study describes our use of VATS with an SAP R/3 system running in a Xen-based virtualized resource pool. The results from VATS are used to determine the impact of virtual machine configuration parameters on a SAP system.}, 
keywords={automatic testing;customer satisfaction;resource allocation;virtual machines;VATS;automated test execution;cloud computing;customer performance requirements;service providers;virtual machine;virtualized shared resource pools;virtualized-aware automated test service;Application virtualization;Automatic testing;Cloud computing;Delay;Feedback;Humans;Information technology;Resource management;Resource virtualization;Virtual machining;Autonomic Management;Cloud Computing;Performance Testing;Virtualization}, 
doi={10.1109/QEST.2008.24}, 
month={Sept},}
@INPROCEEDINGS{5071073, 
author={K. Bhattacharya and M. Bichler and S. Tai}, 
booktitle={2009 31st International Conference on Software Engineering - Companion Volume}, 
title={ICSE Cloud 09: First international workshop on software engineering challenges for Cloud Computing}, 
year={2009}, 
pages={482-483}, 
abstract={Cloud Computing has emerged as a new paradigm for deploying, managing and offering services through a shared infrastructure. The projected benefits of cloud computing are very compelling both from a cloud consumer as well as a cloud services provider perspective: ease of deployment of services; low capital expenses and constant operational expenses leading to variable pricing schemes and reduced opportunity costs; leveraging the economies of scale for both services providers and users of the cloud. However, the actual realization of these perceived benefits are far from being well-achieved and pose a broad range of interesting questions.}, 
doi={10.1109/ICSE-COMPANION.2009.5071073}, 
month={May},}
@INPROCEEDINGS{5370395, 
author={Z. Huang and Y. Xiang}, 
booktitle={2009 Second International Symposium on Computational Intelligence and Design}, 
title={Improve the Usefulness of Skyline Analysis in Cloud Computing Environments}, 
year={2009}, 
volume={1}, 
pages={325-328}, 
abstract={Skyline query processing has recently received a lot of attention in cloud computing community. However, in most real applications, the skyline result can not satisfy the needs of users. This paper proposes a novel type of SkyRank query to more efficiently analyze the data. The SkyRank query on the subspace V divides the input data AD into m separate subsets SKR(1, AD, V),..., SKR(m, AD, V) such that an object p belongs to SKR(i, AD, V) if it is not dominated by any other objects on V except for those in SKR(1, AD, V),..., SKR(i-1, AD, V) where iÂ¿[1, m]. In order to fast implement the proposed query, an effective algorithm ZHYX which utilizes the regular grid structure is presented. The detailed theoretical analyses and extensive experiments demonstrate that our proposed algorithm is both efficient and effective.}, 
keywords={grid computing;query processing;SkyRank query;ZHYX algorithm;cloud computing environment;regular grid structure;skyline query processing;Algorithm design and analysis;Application software;Cloud computing;Computational efficiency;Computational intelligence;Computer science;Data analysis;Data mining;Decision making;Query processing;SkyRank query;query optimization;regular grid;skyline analysis}, 
doi={10.1109/ISCID.2009.89}, 
month={Dec},}
@INPROCEEDINGS{5362456, 
author={K. Kofler and I. u. Haq and E. Schikuta}, 
booktitle={2009 International Conference on Parallel Processing}, 
title={A Parallel Branch and Bound Algorithm for Workflow QoS Optimization}, 
year={2009}, 
pages={478-485}, 
abstract={Automated composition and optimization of workflows in service-enriched environments is a challenging research area with strong implications in globally distributed systems such as Grid Computing and Cloud Computing. A workflow is composed of web services selected in accordance with user requirements. A strong formal realization of the problem is inevitable to ensure efficiency based on various interdependent parameters. We devise a mathematical model in order to map abstract workflows into concrete workflows satisfying user requirements represented by QoS parameters. Our model, which is based on the Multidimensional Multi-choice Knapsack Problem (MMKP), defines a happiness measure, that takes into account these requirements as well as the weights given to each requirement by the user. Then we develop a parallelizable branch and bound algorithm to maximize this happiness measure. We incorporate the Kepler Workflow tool, CORBA and C++ based optimization components to simulate two versions of the algorithm: a sequential version and a parallel version. We also indicate how to use heuristics to reuse the results of the parallel optimization under dynamic changes in requirements or service availability. Finally, we show a speedup analysis of our implementation.}, 
keywords={Web services;distributed object management;grid computing;knapsack problems;quality of service;tree searching;workflow management software;C++;CORBA;Kepler workflow tool;Web services;bound algorithm;cloud computing;globally distributed systems;grid computing;happiness measure;multidimensional multi-choice knapsack problem;parallel branch algorithm;parallel optimization;speedup analysis;workflow QoS optimization;Algorithm design and analysis;Cloud computing;Computational modeling;Concrete;Costs;Design optimization;Distributed computing;Grid computing;Multidimensional systems;Runtime;CORBA Implementation;Formal Model;Grid Computing;Multi-choice Knapsack Problem;Multidimensional;Parallel Branch and Bound Algorithm;Service Composition;Workflow Management}, 
doi={10.1109/ICPP.2009.34}, 
ISSN={0190-3918}, 
month={Sept},}
@INPROCEEDINGS{5353060, 
author={C. Y. Tu and W. C. Kuo and Y. T. Wang and S. Shiau}, 
booktitle={2009 10th IEEE/ACM International Conference on Grid Computing}, 
title={E2CC: Building energy efficient ClassCloud using DRBL}, 
year={2009}, 
pages={189-195}, 
abstract={Green computing is a growing research topic. Its goal is to increase energy efficiency and reduced resource consumption. Building infrastructure for cloud computing is one of the methods to achieve these goals. The key concept of cloud computing is to provide a resource sharing model based on virtualization, distributed filesystem and Web services. In this paper, we propose an energy efficient architecture for cloud computing using Diskless Remote Boot in Linux (DRBL) and Xen. We call this architecture ClassCloud because it is suitable to build an experimental cloud infrastructure in PC classrooms. According to our power consumption experiments, the diskless design of DRBL provides a way to implement a power economization computing platform. Computers booting from network without hard disk installed will reduce power consumption from 7% to 33% compared to computers with hard disk installed.}, 
keywords={Linux;Web services;file organisation;power aware computing;resource allocation;virtual machines;Diskless Remote Boot in Linux;E2CC;PC classrooms;Web services;Xen;cloud computing;distributed filesystem;energy efficient ClassCloud;energy efficient architecture;green computing;power consumption experiments;power economization computing platform;resource consumption reduction;resource sharing model;virtualization;Buildings;Cloud computing;Computer architecture;Computer networks;Energy consumption;Energy efficiency;Hard disks;Resource management;Resource virtualization;Web services;Cloud Computing;Diskless Remote Boot in Linux (DRBL);Green Computing;Xen}, 
doi={10.1109/GRID.2009.5353060}, 
ISSN={2152-1085}, 
month={Oct},}
@INPROCEEDINGS{4736763, 
author={X. Llorà and B. Ács and L. S. Auvil and B. Capitanu and M. E. Welge and D. E. Goldberg}, 
booktitle={2008 IEEE Fourth International Conference on eScience}, 
title={Meandre: Semantic-Driven Data-Intensive Flows in the Clouds}, 
year={2008}, 
pages={238-245}, 
abstract={Data-intensive flow computing allows efficient processing of large volumes of data otherwise unapproachable. This paper introduces a new semantic-driven data-intensive flow infrastructure which: (1) provides a robust and transparent scalable solution from a laptop to large-scale clusters,(2) creates an unified solution for batch and interactive tasks in high-performance computing environments, and (3) encourages reusing and sharing components. Banking on virtualization and cloud computing techniques the Meandre infrastructure is able to create and dispose Meandre clusters on demand, being transparent to the final user. This paper also presents a prototype of such clustered infrastructure and some results obtained using it.}, 
keywords={data flow computing;object-oriented programming;semantic Web;software reusability;virtual machines;Meandre infrastructure;batch task;cloud computing;component reuse;component sharing;high-performance computing environment;interactive task;large-scale cluster;semantic Web-driven data-intensive flow computing;virtualization;Cloud computing;Computer industry;Data engineering;Data flow computing;Genetic algorithms;Genetic engineering;Laboratories;Large-scale systems;Portable computers;Robustness}, 
doi={10.1109/eScience.2008.172}, 
month={Dec},}
@INPROCEEDINGS{5358101, 
author={Z. Yang and S. i. Kamata and A. Ahrary}, 
booktitle={2009 IEEE International Conference on Intelligent Computing and Intelligent Systems}, 
title={NIR: Content based image retrieval on cloud computing}, 
year={2009}, 
volume={3}, 
pages={556-559}, 
abstract={NIR is an open source cloud computing enabled content based image retrieval system. With the development and popularization of cloud computing, more and more researchers from different research areas do research with the help of cloud computing. Nowadays content based image retrieval as one of the challenging and emerging technologies is high computation task because of the algorithm computation complexity and big amount of data. As based on cloud computing infrastructure, NIR is easy to extent and flexible for deployment. As an open source project, NIR can be improved on demand and integrated to other existing systems. This paper presents our ideas, findings, design and the system from our work of NIR.}, 
keywords={Internet;algorithm theory;image retrieval;NIR;algorithm computation complexity;cloud computing;cloud computing infrastructure;content based image retrieval;emerging technologies;extent deployment;flexible deployment;high computation task;open source project;Cloud computing;Computer architecture;Computer vision;Content based retrieval;Histograms;Image retrieval;Information retrieval;Research and development;Search engines;Time sharing computer systems;cloud computing;component;content based image retrieval;open source}, 
doi={10.1109/ICICISYS.2009.5358101}, 
month={Nov},}
@INPROCEEDINGS{5368745, 
author={R. Kaewpuang and P. Uthayopas and G. Srimool and J. Pichitlamkhen}, 
booktitle={2009 Fourth International Conference on Computer Sciences and Convergence Information Technology}, 
title={Building a Service Oriented Cloud Computing Infrastructure Using Microsoft CCR/DSS System}, 
year={2009}, 
pages={812-817}, 
abstract={Cloud computing is new paradigm for provision of a computing infrastructure and services the over network using a pool of abstracted, virtualized, and scalable, computing resources. One of the challenges is the lack of standard in configuration, management, and programming. Thus, we propose that a service oriented cloud can be built and program using Microsoft Windows server and program using Microsoft CCR/DSS. The architecture of this service oriented cloud is presented in this paper. In addition, a practical logistic application called pickup and delivery problem with time window (PDPTW) is developed to demonstrate the concept. The experiments show that a very high speed up of more than 50 times on 16 quad core node and 80-90% efficiency can be obtained using a cloud computing system based on our concept.}, 
keywords={Web services;Microsoft CCR-DSS system;Microsoft Windows server;logistic application;pickup and delivery problem with time window;service oriented cloud;service oriented cloud computing infrastructure;Application software;Cloud computing;Computer architecture;Computer networks;Costs;Decision support systems;Hardware;Logistics;Multicore processing;Resource virtualization;cloud computing;microsoft CCR/DSS;pickup and delivery problem with time window;service oriented cloud}, 
doi={10.1109/ICCIT.2009.121}, 
month={Nov},}
@INPROCEEDINGS{5407995, 
author={M. Baker and M. Kunze}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Cloud-based services and applications}, 
year={2009}, 
pages={31-32}, 
abstract={Cloud computing is increasingly being used for what was known as “on-demand” and “utility computing”. The services provided, the APIs and the applications that can be hosted by these Cloud providers have superseded the use of the grid, and are increasingly becoming popular with users. There are obviously two sides to the services that are provided by Cloud providers: those that are supplied by commercial entities, such as Amazon and Google, as well as those that are open-source systems, such as provided by Open Cirrus and Eucalyptus. In this workshop we wish to examine and explore the services, interfaces and types of applications that can be executed on Cloud systems. In addition, we are interested in the interfaces used to access the underlying services, the pros/cons of using virtualisation, the range and scope of applications that can be executed, the security used by these services, and aspects such a service level agreements and quality of service provided. This workshop intends to provide a forum for researchers, developers and users working on security issues associated with e-Science and e-Research to exchange ideas and share experiences. The workshop will be a blend of invited talks, presentations of research papers, and discussions about the current status, emergent areas, and trends on security-related issues in e-Science and e-Research.}, 
keywords={Application software;Cloud computing;Data security;Fault tolerant systems;File systems;Open source software;Protocols;Quality of service;Scalability;Secure storage}, 
doi={10.1109/ESCIW.2009.5407995}, 
month={Dec},}
@INPROCEEDINGS{5071863, 
author={D. Nurmi and R. Wolski and C. Grzegorczyk and G. Obertelli and S. Soman and L. Youseff and D. Zagorodnov}, 
booktitle={2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
title={The Eucalyptus Open-Source Cloud-Computing System}, 
year={2009}, 
pages={124-131}, 
abstract={Cloud computing systems fundamentally provide access to large pools of data and computational resources through a variety of interfaces similar in spirit to existing grid and HPC resource management and programming systems. These types of systems offer a new programming target for scalable application developers and have gained popularity over the past few years. However, most cloud computing systems in operation today are proprietary, rely upon infrastructure that is invisible to the research community, or are not explicitly designed to be instrumented and modified by systems researchers. In this work, we present Eucalyptus - an open-source software framework for cloud computing that implements what is commonly referred to as infrastructure as a service (IaaS); systems that give users the ability to run and control entire virtual machine instances deployed across a variety physical resources. We outline the basic principles of the Eucalyptus design, detail important operational aspects of the system, and discuss architectural trade-offs that we have made in order to allow EUCALYPTUS to be portable, modular and simple to use on infrastructure commonly found within academic settings. Finally, we provide evidence that EUCALYPTUS enables users familiar with existing grid and HPC systems to explore new cloud computing functionality while maintaining access to existing, familiar application development software and grid middleware.}, 
keywords={Web services;grid computing;middleware;parallel processing;programming;public domain software;resource allocation;software architecture;virtual machines;Eucalyptus open-source cloud-computing system design;HPC system resource management;application development software;architectural principle;grid computing;grid middleware;infrastructure-as-a-service system;programming system;virtual machine instance;Application software;Cloud computing;Computer interfaces;Control systems;Grid computing;Instruments;Open source software;Resource management;Software maintenance;Virtual machining;cloud computing;virtualization}, 
doi={10.1109/CCGRID.2009.93}, 
month={May},}
@INPROCEEDINGS{5369983, 
author={P. H. Deussen and M. Baumgarten and M. Mulvenna and A. Manzalini and C. Moiso}, 
booktitle={2009 First International Conference on Emerging Network Intelligence}, 
title={Autonomic Re-configuration of Pervasive Supervision Services}, 
year={2009}, 
pages={33-38}, 
abstract={This paper describes a supervision system for autonomic distributed systems (e.g., a cloud computing environment). It is designed as a supplementary service and is structured as an ensemble of components that implement an autonomic control loop, which does not require any a priori knowledge on the structure of the supervised system. The architecture devised is highly modular and can be configured towards individual needs. In particular, the supervision system is able to re-configure itself according to the changes of the supervised system and the environment it is operating in.}, 
keywords={fault tolerant computing;ubiquitous computing;CASCADAS;autonomic control loop;autonomic distributed systems;autonomic re-configuration;pervasive supervision services;supervision system;supplementary service;Cloud computing;Computer architecture;Control systems;autonomic communication;autonomic computing;fault management;pervasive supervision;self-reconfiguration}, 
doi={10.1109/EMERGING.2009.18}, 
month={Oct},}
@INPROCEEDINGS{5190373, 
author={Y. Koh and C. Pu and Y. Shinjo and H. Eiraku and G. Saito and D. Nobori}, 
booktitle={2009 Eighth IEEE International Symposium on Network Computing and Applications}, 
title={Improving Virtualized Windows Network Performance by Delegating Network Processing}, 
year={2009}, 
pages={203-210}, 
abstract={Virtualized environments are important building blocks in consolidated data centers and cloud computing. Full virtualization (FV) allows unmodified guest OSes to run on virtualization-aware microprocessors. However, the significant overhead of device emulation in FV has caused high I/O overhead. Current implementations based on paravirtualization can only reduce such overhead partially. This paper describes the Linsock approach that applies the outsourcing method to speed up I/O in FV environments by combining different guest OS and host OS. Concretely, Linsock replaces the guest Windowspsila network processing with the host Linux kernel on the same machine. Linsock has been implemented on Linux Kernel-based Virtual Machine (KVM) as the host virtual machine (VM) environment. Our measurement results with Linsock show significant performance increase of more than 300% compared with device paravirtualization in a 10 Gbps Ethernet networking environment. In addition, Linsock also yields a fourfold increase in inter-VM communication performance.}, 
keywords={Linux;computer centres;local area networks;microcomputers;network operating systems;operating system kernels;operating systems (computers);virtual machines;virtual reality;Ethernet networking environment;Linsock approach;Linux kernel;cloud computing;consolidated data center;full virtualization;guest OS;host OS;inter VM communication performance;network processing;operating system;paravirtualization;virtual machine;virtualization aware microprocessor;virtualized Windows network;virtualized environment;Cloud computing;Emulation;Ethernet networks;Kernel;Linux;Microprocessors;Outsourcing;Virtual machining;Virtual manufacturing;Windows}, 
doi={10.1109/NCA.2009.49}, 
month={July},}
@INPROCEEDINGS{5373228, 
author={K. M. Sim}, 
booktitle={2009 IEEE International Conference on Industrial Engineering and Engineering Management}, 
title={Agent-based Cloud commerce}, 
year={2009}, 
pages={717-721}, 
abstract={In a business model for cloud computing, users pay providers for consumption of their computing capabilities. This work proposes an agent-based testbed for bolstering the discovery of cloud resources and SLA negotiation. In the testbed, provider and consumer agents act as intermediaries between providers and consumers. Through a 4-stage resource discovery process (selection, evaluation, filtering, and recommendation), a set of broker agents match consumers' requests to advertisements from providers. Following the matching of requests to resources, consumer and provider agents negotiate for mutually acceptable resource time slots. Empirical results show that broker agents are successful in matching requests to resources, and consumer and provider agents are successful in negotiating for mutually acceptable time slots.}, 
keywords={Internet;electronic commerce;multi-agent systems;ubiquitous computing;4-stage resource discovery process;SLA negotiation;agent-based cloud commerce;business model;cloud computing;cloud resources;consumer agents;e-commerce;electronic commerce;grid computing;service level agreement;Business communication;Cloud computing;Costs;Electronic mail;Matched filters;Pervasive computing;Physics computing;Resource management;Resource virtualization;Testing;Cloud/Grid computing;e-Commerce;multiagent systems;negotiation;resource management}, 
doi={10.1109/IEEM.2009.5373228}, 
ISSN={2157-3611}, 
month={Dec},}
@INPROCEEDINGS{5350010, 
author={M. Schmidt and N. Fallenbeck and M. Smith and B. Freisleben}, 
booktitle={2009 35th Euromicro Conference on Software Engineering and Advanced Applications}, 
title={Secure Service-Oriented Grid Computing with Public Virtual Worker Nodes}, 
year={2009}, 
pages={555-562}, 
abstract={Cloud computing uses virtualization technologies to offer a non-shared use rental of computer resources with publicly accessible worker nodes. However, unlike grid computing, cloud computing as implemented by Amazon, IBM, Google and Microsoft only offers compute and storage resources from a single organization. Many of the cross-site and cross-organizational advantages offered by grid computing are lost. In this paper, we present a novel infrastructure that combines the benefits of grid and cloud computing: Cheap multi-organizational resources and private compute nodes with root access reachable from the Internet. Our previously introduced virtualization of grid resources is extended by an approach to offer the same freedom of network access cloud computing offers, but in a multi-organizational and shared use environment without endangering existing users or resources. An approach is presented for the dynamic network isolation of grid users from each other as well as a mechanism for shielding the grid infrastructure from malicious users and attacks from the Internet. This solution overcomes the traditional limitation that grid worker nodes are kept in private networks and enables new multi-site service-oriented applications to be deployed securely.}, 
keywords={Internet;grid computing;security of data;Internet;cloud computing;grid resources virtualization;malicious attacks;malicious users;network isolation;public virtual worker nodes;secure service-oriented grid computing;Application software;Application virtualization;Business;Cloud computing;Grid computing;Internet;Processor scheduling;Protection;Resource virtualization;Voice mail;Cloud Computing;Grid Computing;Security;Virtualization}, 
doi={10.1109/SEAA.2009.73}, 
ISSN={1089-6503}, 
month={Aug},}
@INPROCEEDINGS{4976702, 
author={G. Fenu and S. Surcis}, 
booktitle={2009 Eighth International Conference on Networks}, 
title={A Cloud Computing Based Real Time Financial System}, 
year={2009}, 
pages={374-379}, 
abstract={The ldquoCloud Computingrdquo is becoming an increasingly popular term. The new ldquoXaaSrdquo category of services introduced will slowly replace many types of computational resources currently used. In this perspective, grid computing, the basic element for the large scale supply of cloud services, will play a fundamental role in defining how those services will be provided. This paper is concerned with the study and preliminary design of a real time financial system based on cloud computing technologies that enable macroeconomic analysis and forecasts of the financial markets and their instruments. Cloud and grid paradigms can generate different added values which are examined in detail in the paper. This work utilises the results obtained during the Cybersar Project managed by the COSMOLAB Consortium (Italy). The system analyzed and described herein will be implemented in the Cybersar Computational Grid by autumn 2009.}, 
keywords={economic forecasting;financial data processing;grid computing;macroeconomics;real-time systems;XaaS service category;cloud computing;financial market forecasting;grid computing;macroeconomic analysis;real time financial system;Cloud computing;Economic forecasting;Grid computing;Instruments;Large-scale systems;Macroeconomics;Mesh generation;Project management;Real time systems;Technology forecasting}, 
doi={10.1109/ICN.2009.71}, 
month={March},}
@INPROCEEDINGS{5365722, 
author={Y. Zhao and S. Liu}, 
booktitle={2009 International Conference on Computational Intelligence and Software Engineering}, 
title={Cloud Computing in Port Industry}, 
year={2009}, 
pages={1-4}, 
abstract={As promoted by the vision of "everything as a service", all products provided by cloud computing can recognized as a service. The concept "IT as a service" is an effective solution to the IT difficulties of the port industry. This paper has done a study on cloud computing application in port industry. Combining the architecture of cloud computing with the actual needs of the port business, this paper proposes the cloud computing platform architecture of port industry. This paper holds that SOA infrastructure and cloud computing architecture can meet the IT demand of port industry. Moreover, this paper also provides steps for port enterprises to adopt cloud computing.}, 
keywords={Internet;logistics;software architecture;SOA infrastructure;cloud computing architecture;logistics supply chain;port industry;service oriented architecture;Business;Cloud computing;Computer architecture;Computer industry;Government;Industrial economics;Information management;Semiconductor optical amplifiers;Service oriented architecture;Supply chains}, 
doi={10.1109/CISE.2009.5365722}, 
month={Dec},}
@INPROCEEDINGS{5407985, 
author={J. Wiebelitz and S. Piger and C. Kunz and C. Grimm}, 
booktitle={2009 5th IEEE International Conference on E-Science Workshops}, 
title={Transparent identity-based firewall transition for eScience}, 
year={2009}, 
pages={3-10}, 
abstract={As new concepts for eSciene like grid computing and cloud computing tend to leave the research phase and develop towards production quality, the security eventually moves into focus. Up to now research in the security area concentrates on authentication and authorization on the resources themselves, but to enhance network security more generally, access control must be pushed back to the entry point of the resource providers' network. In this paper TCP-AuthN is presented, an approach for dynamic firewall operation, which uses the TCP three-way handshake to transport users' authentication information for dynamic firewall operation. The authentication information enables firewalls to authorize each connection establishment individually, based on the user's proven identity. To prevent man-in-the-middle attacks and replay attacks, a challenge-response procedure must be accomplished before the connection is finally allowed. To distinguish the authentication information from application level data, a new TCP option tcpauthn was designed. The presented approach is intended to withdraw the initial authorization decision from the resources and therefore from the internal network and move this decision to firewalls, which are employed to protect networks and services.}, 
keywords={Internet;authorisation;transport protocols;TCP-AuthN;authentication information;cloud computing;eScience;grid computing;man-in-the-middle attacks;network security;security area;transparent identity-based firewall transition;Access control;Authentication;Authorization;Cloud computing;Employment;Grid computing;Information security;Production;Protection;Virtual private networks}, 
doi={10.1109/ESCIW.2009.5407985}, 
month={Dec},}
@INPROCEEDINGS{4664329, 
author={F. M. Aymerich and G. Fenu and S. Surcis}, 
booktitle={2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)}, 
title={An approach to a Cloud Computing network}, 
year={2008}, 
pages={113-118}, 
abstract={ldquoCloud Computingrdquo is becoming increasingly relevant, as it will enable companies involved in spreading this technology to open the doors to Web 3.0. In this work the basic features of cloud computing are presented and compared with those of the original technology: Grid Computing. The new categories of services introduced will slowly replace many types of computational resources currently used. In this perspective, grid computing, the basic element for the large scale supply of cloud services, will play a fundamental role in defining how those services will be provided. The paper describes the concept of computational resources outsourcing, referred to computational grids and a real application. This work utilises the results by the Cybersar Project managed by the COSMOLAB Consortium (Italy).}, 
keywords={cosmology;grid computing;Cybersar Project;cloud computing network;computational resources;grid computing;large scale supply;Cloud computing;Distributed computing;Grid computing;Hardware;Image storage;Internet;Project management;Search engines;Storage automation;Technology management}, 
doi={10.1109/ICADIWT.2008.4664329}, 
month={Aug},}
@INPROCEEDINGS{5071530, 
author={J. S. Rellermeyer and M. Duller and G. Alonso}, 
booktitle={2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing}, 
title={Engineering the cloud from software modules}, 
year={2009}, 
pages={32-37}, 
abstract={Cloud computing faces many of the challenges and difficulties of distributed and parallel software. While the service interface hides the actual application from the remote user, the application developer still needs to come to terms with distributed software that needs to run on dynamic clusters and operate under a wide range of configurations. In this paper, we outline our vision of a model and runtime platform for the development, deployment, and management of software applications on the cloud. Our basic idea is to turn the notion of software module into a first class entity used for management and distribution that can be autonomously managed by the underlying software fabric of the cloud. In the paper we present our model, outline an initial implementation, and describe a first application developed using the ideas presented in the paper.}, 
keywords={parallel processing;software engineering;cloud computing;distributed software;parallel software;software applications;software fabric;software modules;Application software;Cloud computing;Computer science;Fabrics;Information processing;Outsourcing;Platform virtualization;Runtime;Software development management;Software testing}, 
doi={10.1109/CLOUD.2009.5071530}, 
month={May},}
@INPROCEEDINGS{5405687, 
author={B. P. Rimal and E. Choi}, 
booktitle={Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications}, 
title={A Conceptual Approach for Taxonomical Spectrum of Cloud Computing}, 
year={2009}, 
pages={1-6}, 
abstract={Cloud computing has emerged as a popular computing model to support processing volumetric data using clusters of commodity computers. Nowadays computational world is opting for pay-for-use models and hype and discussion aside, there remains no canonical definition of cloud computing. In this paper we proposed a wide spectrum of taxonomy for cloud computing, aiming at a better understanding of the categories of applications that could benefit from cloudification and that will address the landscape of enterprise IT, management services, and data governance etc.}, 
keywords={distributed processing;workstation clusters;cloud computing;computer clusters;data governance;enterprise IT;management services;taxonomical spectrum;volumetric data processing;Application software;Cloud computing;Computational efficiency;Distributed computing;Grid computing;Hardware;Image processing;Large-scale systems;Taxonomy;Throughput}, 
doi={10.1109/ICUT.2009.5405687}, 
ISSN={1976-0035}, 
month={Dec},}
@INPROCEEDINGS{4760415, 
author={R. Buyya}, 
booktitle={2008 16th International Conference on Advanced Computing and Communications}, 
title={Market-Oriented Grid Computing and the Gridbus Middleware}, 
year={2008}, 
pages={1-1}, 
abstract={Grid computing, one of the latest buzzwords in the ICT industry, is emerging as a new paradigm for Internet-based parallel and distributing computing. Despite a number of advances in grid computing, resource management and application scheduling in such environments continues to be a challenging and complex undertaking. This is due to geographic distribution of grid resources owned by different organizations with different usage policies, cost models and varying load and availability patterns with time. This tutorial introduces fundamental principles of grid computing and computational economy and discusses how they impact on emerging computational and data grid technologies. It identifies resource management challenges and introduces new challenges and requirements introduced by the grid economy on grid service providers (GSPs) and grid service consumers. The tutorial presents a service-oriented grid architecture inspired by computational economies and demonstrates how it can be realized by leveraging the existing grid technologies and building new economic-oriented capabilities and components. We present solutions to these challenges based on our experience in designing and developing market-oriented Gridbus technologies such as Grid Market Directory, Grid Bank, Grid Service Broker, Workflow Engine, and SLA-based enterprise Grid Resource Allocation system. Case studies on the use of Gridbus middleware in the creation of various e-science and e-business applications and their deployment on national/international utility-oriented grids along with its impact on emerging cloud computing paradigm will also be highlighted.}, 
keywords={grid computing;middleware;resource allocation;software architecture;Gridbus middleware;computational economy;computational grid;data grid;e-business;e-science;grid computing;grid economy;grid service consumer;grid service provider;resource management;service-oriented grid architecture;Computer industry;Concurrent computing;Costs;Distributed computing;Grid computing;Internet;Job shop scheduling;Middleware;Processor scheduling;Resource management}, 
doi={10.1109/ADCOM.2008.4760415}, 
month={Dec},}
@INPROCEEDINGS{5381983, 
author={C. Vecchiola and S. Pandey and R. Buyya}, 
booktitle={2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks}, 
title={High-Performance Cloud Computing: A View of Scientific Applications}, 
year={2009}, 
pages={4-16}, 
abstract={Scientific computing often requires the availability of a massive number of computers for performing large scale experiments. Traditionally, these needs have been addressed by using high-performance computing solutions and installed facilities such as clusters and super computers, which are difficult to setup, maintain, and operate. Cloud computing provides scientists with a completely new model of utilizing the computing infrastructure. Compute resources, storage resources, as well as applications, can be dynamically provisioned (and integrated within the existing infrastructure) on a pay per use basis. These resources can be released when they are no more needed. Such services are often offered within the context of a service level agreement (SLA), which ensure the desired quality of service (QoS). Aneka, an enterprise cloud computing solution, harnesses the power of compute resources by relying on private and public clouds and delivers to users the desired QoS. Its flexible and service based infrastructure supports multiple programming paradigms that make Aneka address a variety of different scenarios: from finance applications to computational science. As examples of scientific computing in the cloud, we present a preliminary case study on using Aneka for the classification of gene expression data and the execution of fMRI brain imaging workflow.}, 
keywords={Internet;quality of service;ubiquitous computing;QoS;high-performance cloud computing;quality of service;scientific computing;service level agreement;Application software;Availability;Cloud computing;Computer applications;Context-aware services;Finance;Gene expression;Large-scale systems;Quality of service;Scientific computing;Cloud computing;Scientific computing;computational science;high-performance computing}, 
doi={10.1109/I-SPAN.2009.150}, 
ISSN={1087-4089}, 
month={Dec},}
@INPROCEEDINGS{4670147, 
author={G. Lin and G. Dasmalchi and J. Zhu}, 
booktitle={2008 IEEE International Conference on Web Services}, 
title={Cloud Computing and IT as a Service: Opportunities and Challenges}, 
year={2008}, 
pages={5-5}, 
abstract={This panel brings together technology experts and business leaders and provide first hand insight to the evolution of cloud computing and IT as a service (ITaaS), from both technology and business model perspectives. The panel will discuss the disruptive nature of cloud computing and its business model, including the impact to the current enterprise IT industry, to the service provider industry, to the enterprise software industry, to the networking industry, and to the service industry. The panel will also discuss the confluence of SOA paradigm and SaaS paradigm and examine its implication to the enterprise IT architecture. The panel will also help audience understand the limitation and challenges for cloud computing and ITaaS. The audience of this panel is targeted at the technology leaders and business decision makers in enterprise IT, software industry, and networking industry.}, 
keywords={DP industry;commerce;IT as a service;business model;cloud computing;enterprise IT architecture;networking industry;software industry;Asia;Cloud computing;Computer architecture;Computer industry;Engineering management;Service oriented architecture;Silicon;Technological innovation;USA Councils;Web services}, 
doi={10.1109/ICWS.2008.144}, 
month={Sept},}
@INPROCEEDINGS{5210812, 
author={A. Anandasivam and S. Buschek and R. Buyya}, 
booktitle={2009 IEEE Conference on Commerce and Enterprise Computing}, 
title={A Heuristic Approach for Capacity Control in Clouds}, 
year={2009}, 
pages={90-97}, 
abstract={Cloud resource providers in a market face dynamic and unpredictable consumer behavior. The way, how prices are set in a dynamic environment, can influence the demand behavior of price sensitive customers. A cloud resource provider has to decide on how to allocate his scarce resources in order to maximize his profit. The application of bid price control for evaluating incoming service requests is a common approach for capacity control in network revenue management. In this paper we introduce a customized version of the concept of self-adjusting bid prices and apply it to the area of cloud computing. Furthermore, we perform a simulation in order to test the efficiency of the proposed model.}, 
keywords={Internet;linear programming;pricing;profitability;resource allocation;bid price control;capacity control;cloud computing;cloud resource providers;demand behavior;dynamic environment;heuristic approach;incoming service requests evaluation;network revenue management;price sensitive customers;profit maximisation;randomized linear programming;scarce resource allocation;selfadjusting bid prices;unpredictable consumer behavior;Business;Cloud computing;Computational modeling;Conference management;Consumer behavior;Control systems;Distributed computing;Grid computing;Management information systems;Resource management;bid price control;cloud services;genetic algorithm;revenue management}, 
doi={10.1109/CEC.2009.20}, 
ISSN={2378-1963}, 
month={July},}
@INPROCEEDINGS{5364720, 
author={Z. Sun and P. Ma and X. Su}, 
booktitle={2009 International Conference on Computational Intelligence and Software Engineering}, 
title={A Perspective on Trusted Hardware and Operating System of Cloud Terminal}, 
year={2009}, 
pages={1-4}, 
abstract={The rise of cloud computing leads to a possibility that nearly all applications can be ported to Web and only browser is needed in client computer. This kind of computer is called network computer or thin client. PC and laptops are fat clients and too luxurious to run browsers only. Netbooks and nettops are cheap and designed to match cloud computing. But they are still using the same operating systems with PCs and laptops. This paper first introduces the concept of cloud terminal, a computer system dedicated to Web browsing. Then discuss the research challenges and design proposals of its hardware and operating systems in detail.}, 
keywords={Internet;network operating systems;online front-ends;security of data;PC;Web browsing;cloud terminal;laptops;netbooks;nettops;network computer;operating system;thin client;trusted hardware;Application software;Cloud computing;Collaborative software;Computer network reliability;Computer networks;Hardware;Operating systems;Personal communication networks;Portable computers;Proposals}, 
doi={10.1109/CISE.2009.5364720}, 
month={Dec},}
@INPROCEEDINGS{5166884, 
author={S. AjayKumar and C. Nachiappan and K. Periyakaruppan and P. Boominathan}, 
booktitle={2009 International Conference on Signal Processing Systems}, 
title={Enhancing Portable Environment Using Cloud and Grid}, 
year={2009}, 
pages={728-732}, 
abstract={This paper ldquoenhancing portable environment using cloud and gridrdquo aims at providing the users with the most easy and the efficient way of using an OS, which is stored in a server and accessing it from anywhere (at Office or home). The only thing you need to do is that you should have a system with minimum configuration with an Internet connection and having a browser for accessing the OS present in the Server. In this paper we are going to introduce the Web OS - Moving OS to the Web concept using cloud computing and grid computing. This can be done by storing the OS in a server and accessing the OS via browsers in the other systems that are connected to the Internet. cloud computing is the latest buzz in the IT world, which provides the use of software as a service, example Google docs, where in we have an in-built Word processor, Power point ,etc. In the same way in our Web OS we will be using the same concept of software as a service which has a fabulous advantage, which is, we can install a new software in one server and can access the software from other systems. Other examples of applications which use cloud computing are Yahoo calendar, YouTube, Blogger, etc. In order to make the concept of cloud computing more efficient and reliable, we are going to include grid computing for providing much more performance for the systems which access the WebOS. This is done since more users login at the same time and the server might not be able to provide the equal performance to all the systems, so when we add grid computing by combining other systems to the server we can achieve the performance by getting the performance from the systems that are connected to the server and providing them to the systems that are accessing the Web OS. The Advantages of Web OS are it runs on any Internet enabled computer or device. This is important for mobile workers or people who donpsilat have their own computers and must work out of Internet cafes, libraries, or schools. Also, W- eb OS users can work, log out, and then log in later from a different computer.}, 
keywords={Internet;grid computing;mobile computing;online front-ends;operating systems (computers);Internet connection;Web OS;Web browser;cloud computing;grid computing;mobile worker;portable environment;Application software;Calendars;Cloud computing;Grid computing;Mobile computing;Operating systems;Software systems;Web and internet services;Web server;YouTube;Cloud Computing;Grid Computing;Web PC}, 
doi={10.1109/ICSPS.2009.106}, 
month={May},}
@INPROCEEDINGS{5345327, 
author={B. J. d'Auriol and X. H. Le and S. Lee and Y. K. Lee}, 
booktitle={2009 International Conference on Ultra Modern Telecommunications Workshops}, 
title={Visualizations of human activities in sensor-enabled ubiquitous environments}, 
year={2009}, 
pages={1-6}, 
abstract={Sensor network ubiquitous environments may generate a lot of data including heterogeneous `raw' sensor data, low-level feature and/or trend data and higher-level context and inferenced information. This paper considers the visualization of such large, heterogeneous and complex integrated information, especially for real-time deployments facilitating rapid understanding leading to decision making. Visualizations are contextually structured according to the newly proposed serviceable visualizations paradigm for service-based and cloud-enabled visualizations. Specific visualizations of human activities are subsequently developed. These visualizations are based on the data provided via a secured WSN-integrated cloud computing for u-Health Care (SC3) architecture that is under development.}, 
keywords={Internet;data visualisation;inference mechanisms;wireless sensor networks;WSN-integrated cloud computing;cloud-enabled visualizations;decision making;human activities visualizations;inferenced information;sensor-enabled ubiquitous environments;service-based visualizations;u-Health Care;Computer networks;Context-aware services;Data engineering;Data visualization;Decision making;Humans;Information analysis;Information filtering;Pervasive computing;Sensor systems}, 
doi={10.1109/ICUMT.2009.5345327}, 
ISSN={2157-0221}, 
month={Oct},}
@INPROCEEDINGS{5357114, 
booktitle={2009 13th International Conference on Intelligence in Next Generation Networks}, 
title={[Title page]}, 
year={2009}, 
pages={1-1}, 
abstract={The following topics are discussed: next generation networks, Web 2.0, software as a service, software architecture, cloud computing, IMS, mobile computing, telecommunication applications, artificial intelligence techniques, social networks, grid computing, etc.}, 
keywords={Internet;grid computing;social networking (online);software architecture;telecommunication computing;telecommunication services;IMS;Web 2.0;artificial intelligence techniques;cloud computing;grid computing;mobile computing;next generation networks;social networks;software architecture;software as a service;telecommunication service applications}, 
doi={10.1109/ICIN.2009.5357114}, 
month={Oct},}
@INPROCEEDINGS{5235697, 
author={Y. Guan}, 
booktitle={2009 ETP International Conference on Future Computer and Communication}, 
title={A Statistical CPID Algorithm on Cloud Computing}, 
year={2009}, 
pages={101-104}, 
abstract={In this paper, we propose a framework for the construction of a statistical CPID security system in e-government on cloud computing. The idea can help people construct a flexible security system based on a well organized strategy and statistical model. Cloud computing is a general concept of the computing service which is reliance on the Internet for satisfying the computing needs of the users. The providers and the users of the service will be benefit for the new organization pattern.}, 
keywords={Internet;government data processing;security of data;Internet;cloud computing;statistical CPID security system;Cloud computing;Databases;Electronic government;Grid computing;Hardware;Intrusion detection;Investments;Local government;Privacy;Security;Change-point Theory;Cloud Computing;E-Government;Intrusion Detection}, 
doi={10.1109/FCC.2009.27}, 
month={June},}
@INPROCEEDINGS{5201413, 
author={Zhenhuan Gong and P. Ramaswamy and Xiaohui Gu and Xiaosong Ma}, 
booktitle={2009 17th International Workshop on Quality of Service}, 
title={SigLM: Signature-driven load management for cloud computing infrastructures}, 
year={2009}, 
pages={1-9}, 
abstract={Cloud computing has emerged as a promising platform that grants users with direct yet shared access to computing resources and services without worrying about the internal complex infrastructure. Unlike traditional batch service model, cloud service model adopts a pay-as-you-go form, which demands explicit and precise resource control. In this paper, we present SigLM, a novel Signature-driven Load Management system to achieve quality-aware service delivery in shared cloud computing infrastructures. SigLM dynamically captures fine-grained signatures of different application tasks and cloud nodes using time series patterns, and performs precise resource metering and allocation based on the extracted signatures. SigLM employs dynamic time warping algorithm and multi-dimensional time series indexing to achieve efficient signature pattern matching. Our experiments using real load traces collected on the PlanetLab show that SigLM can improve resource provisioning performance by 30-80% compared to existing approaches. SigLM is scalable and efficient, which imposes less than 1 % overhead to the system and can perform signature matching within tens of milliseconds.}, 
keywords={Internet;pattern matching;resource allocation;time series;SigLM;cloud computing infrastructure;cloud service model;dynamic time warping;multidimensional time series indexing;quality-aware service delivery;resource allocation;resource control;resource metering;signature pattern matching;signature-driven load management system;time series patterns;Cloud computing;Control systems;Distributed computing;Indexing;Large-scale systems;Load management;Pattern matching;Peer to peer computing;Resource management;Web and internet services}, 
doi={10.1109/IWQoS.2009.5201413}, 
ISSN={1548-615X}, 
month={July},}
@ARTICLE{4977572, 
author={J. Hayes}, 
journal={Engineering Technology}, 
title={Clout of the cloud}, 
year={2009}, 
volume={4}, 
number={6}, 
pages={60-61}, 
abstract={Among the emerging technologies in enterprise IT, cloud computing enjoys the most commendation, and its proponents seem to have a positive reply for every critical reservation. 'Cloud computing' has become a buzz phrase, but there's plenty of evidence that it also represents a tangible platform for future applications, and offers the prospect of real operational and financial advantages.}, 
keywords={electronic commerce;cloud computing;enterprise IT;financial advantages;operational advantages}, 
doi={10.1049/et.2009.0611}, 
ISSN={1750-9637}, 
month={April},}
@INPROCEEDINGS{5192685, 
author={R. Buyya and R. Ranjan and R. N. Calheiros}, 
booktitle={2009 International Conference on High Performance Computing Simulation}, 
title={Modeling and simulation of scalable Cloud computing environments and the CloudSim toolkit: Challenges and opportunities}, 
year={2009}, 
pages={1-11}, 
abstract={Cloud computing aims to power the next generation data centers and enables application service providers to lease data center capabilities for deploying applications depending on user QoS (Quality of Service) requirements. Cloud applications have different composition, configuration, and deployment requirements. Quantifying the performance of resource allocation policies and application scheduling algorithms at finer details in Cloud computing environments for different application and service models under varying load, energy performance (power consumption, heat dissipation), and system size is a challenging problem to tackle. To simplify this process, in this paper we propose CloudSim: an extensible simulation toolkit that enables modelling and simulation of Cloud computing environments. The CloudSim toolkit supports modelling and creation of one or more virtual machines (VMs) on a simulated node of a Data Center, jobs, and their mapping to suitable VMs. It also allows simulation of multiple Data Centers to enable a study on federation and associated policies for migration of VMs for reliability and automatic scaling of applications.}, 
keywords={computer centres;quality of service;resource allocation;scheduling;software engineering;utility programs;virtual machines;CloudSim toolkit;Quality of Service;application scheduling algorithms;automatic scaling;cloud computing environments;data center;resource allocation policies;user QoS requirements;virtual machines;Cloud computing;Computational modeling;Energy consumption;Load modeling;Power system modeling;Quality of service;Resource management;Scheduling algorithm;Virtual machining;Voice mail}, 
doi={10.1109/HPCSIM.2009.5192685}, 
month={June},}
@INPROCEEDINGS{5382441, 
author={Zhou Naibao and Peng Jin and Wei Bing}, 
booktitle={2009 IEEE Youth Conference on Information, Computing and Telecommunication}, 
title={NGCN: A P2P-based distributed next generation core network towards 4G}, 
year={2009}, 
pages={530-533}, 
abstract={With the development of mobile Internet and distributed technologies, the traditional telecommunications network is subject to many challenges. Skype, a popular peer-to-peer VoIP (Voice over IP) application, shows the gigantic advantage of distributed communication. Therefore, we are trying to design a Next Generation Core Network (NGCN), which utilizes distributed technologies such as P2P, cloud computing, virtualization, etc. It can not only provide traditional telecom services, but also better support the high-bandwidth consumption services in 4G, such as Streaming, file-sharing and so on. This paper first introduces the NGCN architecture, layered architecture model and the P2P overlay design, and then analyzes the future network capabilities demands. The NGCN we provide is distributed, self-organization and scalable.}, 
keywords={Internet telephony;peer-to-peer computing;Skype;file sharing;layered architecture model;mobile Internet;next generation core network;peer-to-peer voice over IP;Application software;Computerized monitoring;Control systems;Irrigation;Large-scale systems;Network topology;Next generation networking;Wireless application protocol;Wireless sensor networks;ZigBee;NGCN;Overlay;P2P;Relay}, 
doi={10.1109/YCICT.2009.5382441}, 
month={Sept},}