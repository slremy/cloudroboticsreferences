@article{Wang2017116,
title = "Ubiquitous manufacturing system based on Cloud: A robotics application ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "116 - 125",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300345",
author = "Xi Vincent Wang and Lihui Wang and Abdullah Mohammed and Mohammad Givehchi",
keywords = "Ubiquitous manufacturing",
keywords = "Cloud manufacturing",
keywords = "Interoperability",
keywords = "Cloud robotics ",
abstract = "Abstract Modern manufacturing industry calls for a new generation of production system with better interoperability and new business models. As a novel information technology, Cloud provides new service models and business opportunities for manufacturing industry. In this research, recent Cloud manufacturing and Cloud robotics approaches are reviewed. Function block-based integration mechanisms are developed to integrate various types of manufacturing facilities. A Cloud-based manufacturing system is developed to support ubiquitous manufacturing, which provides a service pool maintaining physical facilities in terms of manufacturing services. The proposed framework and mechanisms are evaluated by both machining and robotics applications. In practice, it is possible to establish an integrated manufacturing environment across multiple levels with the support of manufacturing Cloud and function blocks. It provides a flexible architecture as well as ubiquitous and integrated methodologies for the Cloud manufacturing system. "
}
@article{Xu2017370,
title = "Energy Condition Perception and Big Data Analysis for Industrial Cloud Robotics ",
journal = "Procedia \{CIRP\} ",
volume = "61",
number = "",
pages = "370 - 375",
year = "2017",
note = "The 24th \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.164",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116313245",
author = "Wei Xu and Quan Liu and Wenjun Xu and Zude Zhou and Duc Truong Pham and Ping Lou and Qingsong Ai and Xiaomei Zhang and Jiwei Hu",
keywords = "Industrial cloud robotics",
keywords = "energy-efficient manufacturing",
keywords = "distributed perception",
keywords = "big data analysis ",
abstract = "Abstract Industrial cloud robotics (ICRs), which is proposed to integrate the distributed industrial robots (IRs) resources to provide \{ICRs\} services at any place, has been attracted great attention due to the characteristics of convenient access, cheaper computing cost, more convenient network resources, etc. Meanwhile, in manufacturing industry, the energy-efficient issue, which means minimize the amount of energy resources to achieve a given output level in manufacturing process, is also gradually paid great attention by academia, industry and government. Currently, \{ICRs\} plays a crucial role in production. The implementation of energy-efficient manufacturing for \{ICRs\} will significantly decrease the energy consumption on the premise of normal production process, and also have remarkable effect on energy-saving and emission-reduction in manufacturing industry. In this context, the energy condition perception and big data analysis of \{ICRs\} are the essential procedure to achieve the aforementioned goals. A novel system architecture which mainly focuses on distributed energy condition perception and big data analysis for \{ICRs\} is built. Based on the perceptive data of \{ICRs\} related to energy consumption, a big data analysis model combined with the manufacturing status of \{ICRs\} is proposed, and the relationship between the big data and the analysis model is presented. Through the data analysis model, we can analyze the energy consumption fluctuation characteristic of \{ICRs\} operating state, count the energy consumption of the product related to different production phases, predict the health status of ICRs, as well as the trend of energy consumption associated with their operations. A case study is implemented to demonstrate the effectiveness of the proposed system and approaches. "
}
@article{Tsardoulias2017157,
title = "Towards an integrated robotics architecture for social inclusion – The \{RAPP\} paradigm ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "157 - 173",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716300535",
author = "Emmanouil G. Tsardoulias and Athanassios M. Kintsakis and Konstantinos Panayiotou and Aristeidis G. Thallas and Sofia E. Reppou and George G. Karagiannis and Miren Iturburu and Stratos Arampatzis and Cezary Zielinski and Vincent Prunet and Fotis E. Psomopoulos and Andreas L. Symeonidis and Pericles A. Mitkas",
keywords = "Robotic applications",
keywords = "Cloud robotics",
keywords = "Robotic architectures",
keywords = "Assistance robotics",
keywords = "Social robotics ",
abstract = "Abstract Scientific breakthroughs have led to an increase in life expectancy, to the point where senior citizens comprise an ever increasing percentage of the general population. In this direction, the \{EU\} funded \{RAPP\} project “Robotic Applications for Delivering Smart User Empowering Applications” introduces socially interactive robots that will not only physically assist, but also serve as a companion to senior citizens. The proposed \{RAPP\} framework has been designed aiming towards a cloud-based integrated approach that enables robotic devices to seamlessly deploy robotic applications, relieving the actual robots from computational burdens. The Robotic Applications (RApps) developed according to the \{RAPP\} paradigm will empower consumer social robots, allowing them to adapt to versatile situations and materialize complex behaviors and scenarios. The \{RAPP\} pilot cases involve the development of \{RApps\} for the \{NAO\} humanoid robot and the ANG-MED rollator targeting senior citizens that (a) are technology illiterate, (b) have been diagnosed with mild cognitive impairment or (c) are in the process of hip fracture rehabilitation. Initial results establish the robustness of \{RAPP\} in addressing the needs of end users and developers, as well as its contribution in significantly increasing the quality of life of senior citizens. "
}
@article{doNascimento201648,
title = "A Platform for Cloud Robotics* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "48 - 53",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.124",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325629",
author = "Amadeu do Nascimento and Eleri Cardozo and Ricardo S. Souza and Eliane G. Guimaraes",
keywords = "Telerobotics",
keywords = "robot programming",
keywords = "mobile robots",
keywords = "telematics",
keywords = "cloud robotics ",
abstract = "Abstract: This paper presents the evolution of a software platform for supporting experimentation in mobile robotics as part of teaching and researching activities. Starting with Web-based laboratories (WebLabs) in the early 2000s the platform kept evolving according to the networking and distributed computing trends since then. In addition to the physical resources managed by the platform, the platform now is able to manage a pool of virtual machines as resources for experimentation. This new class of resources brings the processing power as required by many modern mobile robotics applications. Virtual machines can be widespread on a cluster of processors, on a private cloud computing infrastructure, or on a public cloud computing service. Like any other resource managed by the platform the access to the virtual machines is subjected to user authentication and authorization. A mechanism of user authentication and authorization based on federated identities (single-sign-on) allows the sharing resources maintained by different administrative domains. The paper emphasizes the current stage of the platform and a case study in mobile robotics localization. Localization, as many other mobile robotics algorithms, can employ parallelism at the cluster and cloud levels in order to improve speed, reliability, and scaling. "
}
@article{Du2016,
title = "Robot Cloud: Bridging the power of robotics and cloud computing ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16000042",
author = "Zhihui Du and Ligang He and Yinong Chen and Yu Xiao and Peng Gao and Tongzhou Wang",
keywords = "Service-oriented architecture (SOA)",
keywords = "Cloud computing",
keywords = "Robotics",
keywords = "Robot Cloud",
keywords = "Robot as a Service (RaaS) ",
abstract = "Abstract Cloud computing is shaping the cyber world and evolves as a key computing and service platform for sharing resources including platforms, software applications and everything in the form of services. This is known “X as a Service”. Although it brings our age unparalleled computing ability and economic benefits, the application of cloud computing is still limited currently in the cyberspace due to the cloud services can only reside in cloud instead of our daily life environment. In fact, there are still a plethora of physical position based on-site service demands that cloud computing could help little due to the “cyber limitation”. In this paper, we aim to integrate the cyber world and the physical world by bringing up the idea of “Robot Cloud” to bridge the power of robotics and cloud computing. To make it possible, we design a novel Robot Cloud stack to support our idea and adopt the service-oriented architecture (SOA) to make the functional modules in the Robot Cloud more flexible, extensible and reusable. Then we develop a prototype of Robot Cloud using the popular Google App Engine to demonstrate our design method. Finally, we conduct the simulation experiments with a “robot show” application scenario to evaluate our scheduling policy and identify the effect of different request distributions and robot center solutions. "
}
@article{Dogmus2015100,
title = "RehabRobo-Onto: Design, development and maintenance of a rehabilitation robotics ontology on the cloud ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "100 - 109",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000714",
author = "Zeynep Dogmus and Esra Erdem and Volkan Patoglu",
keywords = "Rehabilitation robotics",
keywords = "Ontologies",
keywords = "Knowledge representation ",
abstract = "Abstract Representing the available information about rehabilitation robots in a structured form, as an ontology, facilitates access to various kinds of information about the existing robots, and thus it is important both from the point of view of rehabilitation robotics and from the point of view of physical medicine. Rehabilitation robotics researchers can learn various properties of the existing robots and access to the related publications to further improve the state-of-the-art. Physical medicine experts can find information about rehabilitation robots and related publications (possibly including results of clinical studies) to better identify the right robot for a particular therapy or patient population. Therefore, considering also the advantages of ontologies and ontological reasoning, such as interoperability of various heterogeneous knowledge resources (e.g., patient databases or disease ontologies), such an ontology provides the underlying mechanisms for translational physical medicine, from bench-to-bed and back, and personalized rehabilitation robotics. With these motivations, the first formal rehabilitation robotics ontology, called RehabRobo-Onto, is designed and developed, collaborating with experts in robotics and in physical medicine. A web based software (called RehabRobo-Query) with an easy-to-use intelligent user-interface is also built. RehabRobo-Query allows robot designers to add/modify information about their rehabilitation robots to/from RehabRobo-Onto. The ontology system consisting of RehabRobo-Onto and RehabRobo-Query is made available on the cloud, utilizing Amazon Web services, to provide a reliable environment for access, development and maintenance of RehabRobo-Onto by rehabilitation robot designers and physical medicine experts around the world. "
}
@article{Qureshi2014220,
title = "Five Traits of Performance Enhancement Using Cloud Robotics: A Survey ",
journal = "Procedia Computer Science ",
volume = "37",
number = "",
pages = "220 - 227",
year = "2014",
note = "The 5th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2014)/ The 4th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2014)/ Affiliated Workshops ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.08.033",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914009983",
author = "Basit Qureshi and Anis Koubaa",
keywords = "Cloud Computing",
keywords = "Cloud Robotics",
keywords = "Big Data",
keywords = "Networked Robots",
keywords = "Autonomous Systems. ",
abstract = "Abstract Recently, robots and automation systems have been at the front of research with the majority of systems still operating indepen- dently using onboard computation, memory manipulation and communication. With improvements in communication technology and the increasing availability of network, new approaches where robot and automation processing is performed remotely with access to large scale datasets, support a range of functions. Cloud Robotics supplements performance enhancement of robotics and autonomous systems by providing a global infrastructure in innovative ways. This paper summarizes recent research into five traits of Cloud Robotics for performance enhancement in robotics and autonomous systems: 1) Remote Brain, 2) Big Data and Shared Knowledge-base, 3) Collective Learning, 4) Intelligence and Behavior, and 5) Cloud architectures. Towards the end, in this survey, we present future directions for research in cloud robotics. "
}
@article{Merrick201738,
title = "Value systems for developmental cognitive robotics: A survey ",
journal = "Cognitive Systems Research ",
volume = "41",
number = "",
pages = "38 - 55",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716301280",
author = "Kathryn Merrick",
keywords = "Robotics",
keywords = "Cognition",
keywords = "Developmental systems",
keywords = "Value systems",
keywords = "Intrinsic motivation ",
abstract = "Abstract This paper surveys value systems for developmental cognitive robotics. A value system permits a biological brain to increase the likelihood of neural responses to selected external phenomena. Many machine learning algorithms capture the essence of this learning process. However, computational value systems aim not only to support learning, but also autonomous attention focus to direct learning. This combination of unsupervised attention focus and learning aims to address the grand challenge of autonomous mental development for machines. This survey examines existing value systems for developmental cognitive robotics in this context. We examine the definitions of value used—including recent pioneering work in intrinsic motivation as value—as well as initialisation strategies for innate values, update strategies for acquired value and the data structures used for storing value. We examine the extent to which existing value systems support attention focus, learning and prediction in an unsupervised setting. The types of robots and applications in which these value systems are used are also examined, as well as the ways that these applications are evaluated. Finally, we study the strengths and limitations of current value systems for developmental cognitive robots and conclude with a set of research challenges for this field. "
}
@article{Holder2016383,
title = "Robotics and law: Key legal and regulatory implications of the robotics age (Part I of II) ",
journal = "Computer Law & Security Review ",
volume = "32",
number = "3",
pages = "383 - 402",
year = "2016",
note = "",
issn = "0267-3649",
doi = "https://doi.org/10.1016/j.clsr.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0267364916300358",
author = "Chris Holder and Vikram Khurana and Faye Harrison and Louisa Jacobs",
keywords = "Robots and law",
keywords = "Autonomous vehicles and law",
keywords = "Healthcare robots and law",
keywords = "Data protection issues in robotics",
keywords = "Intellectual property issues in robotics",
keywords = "Consumer protection issues in robotics",
keywords = "Robotics and commercial contracting ",
abstract = "Abstract In this edition, we explore some of the legal, regulatory and ethical implications of robots and robotic systems and applications. We begin by giving our view of why this emerging technology will become increasingly prevalent and why it is important that lawyers and regulators play an important role in its development. We go on to address the key legal, regulatory and ethical issues in respect of specific types of robotics, including automated vehicles and healthcare robots. We also focus on the impact that robotics will have on core legal practice areas, including data protection, intellectual property, consumer protection and commercial contracting. Our objective is to identify the key legal and regulatory implications of robotics, and to start a dialogue about how our existing legal framework might need to adapt and change to meet the demands of the robotics age. In the next edition, we will continue our focus on key legal issues in respect of different types of robotics and core legal practice areas relevant to the discussion. "
}
@article{Aly2017313,
title = "Metrics and benchmarks in human-robot interaction: Recent advances in cognitive robotics ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "313 - 323",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716300912",
author = "Amir Aly and Sascha Griffiths and Francesca Stramandinoli",
keywords = "Metrics",
keywords = "Benchmarks",
keywords = "System evaluation",
keywords = "Intelligent robot technologies ",
abstract = "Abstract Robots are having an important growing role in human social life, which requires them to be able to behave appropriately to the context of interaction so as to create a successful long-term human-robot relationship. A major challenge in developing intelligent systems, which could enhance the interactive abilities of robots, is defining clear metrics and benchmarks for the different aspects of human-robot interaction, like human and robot skills and performances, which could facilitate comparing between systems and avoid application-biased evaluations based on particular measures. The point of evaluating robotic systems through metrics and benchmarks, in addition to some recent frameworks and technologies that could endow robots with advanced cognitive and communicative abilities, are discussed in this technical report that covers the outcome of our recent workshop on current advances in cognitive robotics: Towards Intelligent Social Robots - Current Advances in Cognitive Robotics, in conjunction with the 15th IEEE-RAS Humanoids Conference - Seoul - South Korea - 2015 (https://intelligent-robots-ws.ensta-paristech.fr/). Additionally, a summary of an interactive discussion session between the workshop participants and the invited speakers about different issues related to cognitive robotics research is reported. "
}
@article{Qureshi201690,
title = "Performance of a Low Cost Hadoop Cluster for Image Analysis in Cloud Robotics Environment ",
journal = "Procedia Computer Science ",
volume = "82",
number = "",
pages = "90 - 98",
year = "2016",
note = "4th Symposium on Data Mining Applications, SDMA2016, 30 March 2016, Riyadh, Saudi Arabia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916300278",
author = "Basit Qureshi and Yasir Javed and Anis Koubaa and Mohamed-Foued Sriti and Maram Alajlan",
keywords = "UAVs",
keywords = "HIPI",
keywords = "Hadoop cluster",
keywords = "Image analysis",
keywords = "Distributed processing",
keywords = "Embedded systems ",
abstract = "Abstract With the emergence of cloud robotics, the cloud computing paradigm becomes increasingly attractive to robotics, where the cloud acts as the remote brain of low-cost robots, such as commodity drones. The idea is to offload heavy computations, like image processing, from the robot to the cloud; process it in short time (near real-time) and send back commands to the robot. This paper investigates the performance of a back-end cloud computing framework in deploying robotics-like applications (i.e. image analysis and processing) using low-cost Hadoop clusters. The design of a low-cost mini-data center built with readily available commodity 32-bit \{ARM\} boards, i.e. Raspberry Pi 2 Model B, is presented. Furthermore, the performance of RPi-based clusters is extensively tested with different types of data including text, text/image and image, and a comparative analysis against Hadoop cluster running on virtual machines is presented. The Hadoop Image Processing Interface (HIPI) Library was used and also configured to optimally utilize the Pi Cluster resources for improved performance. Results show that the \{RPi\} Hadoop cluster lags in performance when compared to Hadoop cluster running on virtual machines, the low cost and small form factor makes it ideal for remote Image analysis in surveillance / disaster recovery scenarios where \{UAVs\} can transmit image streams to the Cluster for remote processing. "
}
@article{Jelinek2015193,
title = "Practical Aspects of Total Least Squares Vectorization of Point Clouds in Mobile Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "4",
pages = "193 - 198",
year = "2015",
note = "13th \{IFAC\} and \{IEEE\} Conference on Programmable Devices and Embedded SystemsPDES 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.07.031",
url = "http://www.sciencedirect.com/science/article/pii/S240589631500806X",
author = "Ales Jelinek",
keywords = "Robot",
keywords = "point cloud",
keywords = "vectorization",
keywords = "least squares",
keywords = "localization and mapping ",
abstract = "Abstract Fast and reliable point cloud processing is a challenging task, especially when online running of the implementation on a mobile robot is required. This paper summarizes generally usable optimization techniques (hardware dependent implementation details are not covered) for vectorization of the point cloud using the least squares approach. Formulas for efficient implementation, methodology of tuning of the control variables, posprocessing for result reliability, as well as illustrative examples are all covered in the text. The discussed suggestions were experimentally proofed to give increased performance (in terms of speed and quality of approximation) with respect to basic implementation. "
}
@article{Aly2017153,
title = "Towards intelligent social robots: Current advances in cognitive robotics ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "153 - 156",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716302224",
abstract = "",
author = "Amir Aly and Sascha Griffiths and Francesca Stramandinoli"
}
@article{Tochacek2016377,
title = "Developing Technological Knowledge and Programming Skills of Secondary Schools Students through the Educational Robotics Projects ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "217",
number = "",
pages = "377 - 381",
year = "2016",
note = "Future Academy Multidisciplinary Conference “ICEEPSY &amp; \{CPSYC\} &amp; icPSIRS &amp; BE-ci” 13–17 October 2015 Istanbul ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2016.02.107",
url = "http://www.sciencedirect.com/science/article/pii/S1877042816001324",
author = "Daniel Tochacek and Jakub Lapes and Viktor Fuglik",
keywords = "educational robotics",
keywords = "education",
keywords = "ICT ",
abstract = "Abstract Many pedagogical approaches that are mainly used in order to develop technological knowledge and programming skills of students at schools are mostly theoretically-oriented. They are based on the traditional model of transfer of finished knowledge between a teacher and a student. Exploitation of educational robotics project into the education at schools has the potential to change the students’ access to the knowledge and skills through their own work and experiments under the supervision of teachers and tutors. The paper describes study that was aimed at identify the potential and aspects of exploitation of educational robotics project in education at secondary schools and training teachers in order to develop technological knowledge and programming skills of secondary school students in practically-oriented ways of education. "
}
@article{Shukla2016490,
title = "Application of robotics in onshore oil and gas industry—A review Part I ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "490 - 507",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.012",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002006",
author = "Amit Shukla and Hamad Karki",
keywords = "Robotics",
keywords = "Automation",
keywords = "In-pipe inspection robots",
keywords = "Tank inspection robots",
keywords = "NDT",
keywords = "UAV",
keywords = "Wireless sensor networks (WSN)",
keywords = "Oil and gas exploration ",
abstract = "Abstract With ever increasing global demand and depleting resources for fossil fuels, oil and gas industry is now positively looking for advanced robotic solutions to increase their productivity and safety. With time easy resources of the fossil fuels are shrinking and newly searched reservoirs, to feed supply demands of global consumption, are mostly located in extreme environmental conditions such as hot deserts, deep water and arctic zone etc. Production of the fossil fuels, in such inhospitable environmental conditions, poses difficult challenges to health, safety and environment (HSE). Tragic incidents like Exxon Valdez and Deepwater Horizon oil spills are examples of such challenges. Therefore, oil and gas industry has lot to learn from successful implementation of robotics and automation for dull, dirty and dangerous (3D) tasks of manufacturing industry. Most of the robotics technologies, currently used in the oil and gas industry, are mainly focused on inspection, maintenance and repair (IMR) of plant facilities with higher frequency and accuracy. Fundamental idea, involved in the automatization of these processes, is based on the principle of teleoperation with skilled operator. Automation of 3D tasks not only improves \{HSE\} standards but also lead to much needed economic efficiency by reducing production cycle, floor space and number of staff members required for continuous inspection and manipulation of plant facilities. Considering the risks involved in this industry usage of completely autonomous robots, first without achieving very high reliability, is still a far fetch choice. Therefore, semi-autonomous robots, where actions are performed by robots but cognitive decisions are still taken by skilled operator, is an excellent choice for this industry as a near future solution. In the onshore oil and gas industry robotic solutions are used both in upstream and downstream processes, such as site survey, drilling, production and transportation, mainly focused in the form of in-pipe inspection robots (IPIRs), tank inspection robots (TIRs), unmanned aerial vehicles (UAVs) and wireless sensor networks (WSNs) etc. This paper presents the state of art robotic solutions currently used in onshore oil and gas facilities. "
}
@article{Shukla2016508,
title = "Application of robotics in offshore oil and gas industry— A review Part \{II\} ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "508 - 524",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002018",
author = "Amit Shukla and Hamad Karki",
keywords = "Robotics",
keywords = "Automation",
keywords = "Underwater manipulator",
keywords = "Underwater welding",
keywords = "Production structure",
keywords = "NDT",
keywords = "ROV",
keywords = "AUV",
keywords = "WSN",
keywords = "Oil spill ",
abstract = "Abstract Demands for oil and gas are increasing with urbanization and industrialization of the world’s increasing population. Giant oil fields are declining in their production worldwide and this situation is creating need for search of new conventional and non-conventional fossil reserves. With steep depletion of major onshore and shallow-water-offshore oil fields new search of fossil fuel is moving towards deep-water and ultra-deep water offshore fields. Obviously new reserves are located in extreme, hostile and hard-to-reach environmental conditions. Exploration, development and production of oil from such difficult offshore fields have many serious challenges to health, safety and environment (HSE) therefore, require sophisticated technological innovations to support increasing energy demand. Biggest oil spill accidents in explosion of Deepwater Horizon offshore oil platform are burning example of such challenges which human society cannot risk to repeat. Therefore, development of advance drilling system, more accurate and intelligent inspection mechanism, faster responsive system in cases of unfortunate incidence and efficient damage control system is need of the safer future. Successful implementation of robotics, in space and manufacturing industry, is an critical example of how robotic assistance and automation is the only option for safe and cost-effective production of oil in foreseeable future. Teleoperation of unmanned drilling and production platforms, remote operated vehicles (ROVs), autonomous underwater vehicles (AUVs), under-water welding, welding robots for double hulled ships and under-water manipulator are such key robotic technologies which have facilitated smooth transition of offshore rigs from shallow waters to ultra-deep waters in modern time. Considering the sensitivity of product and difficulty of environment, most of these technologies fall under semi-autonomous category, where human operator is in loop for providing cognitive assistance to the overall operation for safe execution. This paper summarizes the key robotic technologies currently used in offshore oil and gas facilities. "
}
@article{Ayari201617,
title = "A semantic approach for enhancing assistive services in ubiquitous robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "17 - 27",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.10.022",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003121",
author = "Naouel Ayari and Abdelghani Chibani and Yacine Amirat and Eric Matson",
keywords = "Intelligent assistive services",
keywords = "Ubiquitous robotics",
keywords = "Multi-agents",
keywords = "Ontologies",
keywords = "Symbolic modeling and reasoning ",
abstract = "Abstract The Ambient Intelligence (AmI) technologies have the potential to create intelligent environments with new generation of assistive services, enhanced with ubiquitous robots. These environments have the ability to be anticipatory, responsive and intelligent providers of assistive services anytime and anywhere. These services can assist frail persons effectively in their daily tasks. One of the main challenging research problems in assistive robotics is to endow ubiquitous robots with ability to pro-actively taking on some tasks to help humans in performing complex activities, by participating with them just as other humans do, in normal societies or organizations. In this paper, we propose a collective intelligence framework based on narrative reasoning and natural language processing. In the proposed approach, we propose a hybrid model that bridges together the Narrative Knowledge Representation Language (NKRL), from natural language processing field, and the \{HARMS\} (Humans, software Agents, Robots, Machines and Sensors) model, from multi-agent systems engineering field. This model is able to (i) drive the dialogues between humans, robots and smart devices, (ii) understand a complex situation, and (iii) trigger reactive actions, in the ubiquitous environment, according to given contexts. Two scenarios dedicated to the assistance of a frail person in a smart home equipped with a companion robot and smart objects are implemented and discussed for validation purposes of the proposed framework. "
}
@article{Manfredi2016120,
title = "Autonomous Apartment Exploration, Modelling and Segmentation for Service Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "120 - 125",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.719",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316309958",
author = "Guido Manfredi and Sandra Devin and Michel Devy and Daniel Sidobre",
keywords = "Autonomous",
keywords = "Exploration",
keywords = "Modeling",
keywords = "Segmentation",
keywords = "Service Robotics ",
abstract = "Abstract This work proposes a full pipeline for a robot to explore, model and segment an apartment from a 2-D map. Viewpoints are found offline and then visited by the robot to create a 3-D model of the environment. This model is segmented in order to find the various rooms and how they are linked (windows, doors, walls) yielding a topological map. Moreover areas of interest are also segmented, in this case furniture’s planar surfaces. The method is validated on a realistic three rooms apartment. Results show that, despite occlusion, autonomous exploration and modeling covers 95% of the apartment. For the segmentation part, 1 link out of 14 is wrongly classified while all the existing areas of interest are found. "
}
@article{Bock2015113,
title = "The future of construction automation: Technological disruption and the upcoming ubiquity of robotics ",
journal = "Automation in Construction ",
volume = "59",
number = "",
pages = "113 - 121",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.07.022",
url = "http://www.sciencedirect.com/science/article/pii/S092658051500165X",
author = "Thomas Bock",
keywords = "Construction automation",
keywords = "Robotics in construction",
keywords = "Ambient integrated robotics",
keywords = "S-curves ",
abstract = "Abstract The following article reviews past and current tendencies and derives and describes opportunities for future construction automation that go beyond the current notion of construction automation. Various indicators suggest that conventional construction methodology has reached its limits. An overlay of S-curves can be used to describe the relationship between the stagnation and technical limits of conventional construction and the initiation, development, and growth of new strategies and technologies of construction automation. Although approaches of construction automation are still in an innovation or seed phase, it can be expected that with continued effort put into research and development these approaches may soon enter into the growth phase and encounter adoption on a larger scale. Furthermore, the article shows that over time, the ability of robot systems has grown, allowing them to work more and more in comparably unstructured environments as well as to be deployed in numerous and diverse fields. Currently, it can already be observed that construction automation technology, \{STCR\} approaches, service robot systems, and other microsystems technology are merging with the built environment, becoming inherent elements of buildings, building components, and building furniture. "
}
@article{Dirican2015564,
title = "The Impacts of Robotics, Artificial Intelligence On Business and Economics ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "195",
number = "",
pages = "564 - 573",
year = "2015",
note = "World Conference on Technology, Innovation and Entrepreneurship ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2015.06.134",
url = "http://www.sciencedirect.com/science/article/pii/S1877042815036137",
author = "Cuneyt Dirican",
keywords = "Robots",
keywords = "Robotics",
keywords = "Artificial Intelligence",
keywords = "Hologram",
keywords = "Mecatronics",
keywords = "Business",
keywords = "Economics ",
abstract = "Abstract In the Industrial Age that humanity has entered long time ago with steam series has caused to primitive mechanization in production. With the development of internet and mobile technologies, electronics, nano technology, advances in medicine, health and digital applications and so on speed up mechatronics studies nowadays. Last World Economic Forum holds an important place on the agenda of Robotics and Artificial Intelligence and the economists like Roubini, Stiglitz also entered in the discussion of robotics and artificial in intelligence impacts on economics and business. Although Stephen Hawking criticized on the risks in this regard, every day we are witnessing tremendous news and articles in business pages, regarding on these topics and obviously corporate life and professionals can no longer resist to these changes. Changing form of the business terms and work forces, the way of doing business by using new technologies will have serious impacts on the daily business life and deriving from these on countries and on world economics. Many items and headlines such as jobless ratio, Philips Curve, performance, management, \{CRM\} Analytics, customer relationship management, sales, strategic planning, mass production, Purchasing Power Parity, GDP, inflation, money, Central Banks, Banking System, coaching, training, accounting, taxes etc. regarding to business and economics will face serious dangers, hits, change, exposures as well as opportunities and gains with the improvements in Artificial Intelligence and Robotics. One simple example can explain the degree of these impacts: Should we continue to make provisions for severance pay of the company's staff or should we calculate reserve for depreciation / amortization of robots in the company, which side of the balance sheet will be managed by human resources managers or shall we still name human resources ? This conceptual and hypothetical paper is aiming to address and discusses the future of robots, mechatronics and artificial intelligence in different perspectives. "
}
@article{Chibani20131162,
title = "Ubiquitous robotics: Recent challenges and future trends ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1162 - 1172",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000572",
author = "Abdelghani Chibani and Yacine Amirat and Samer Mohammed and Eric Matson and Norihiro Hagita and Marcos Barreto",
keywords = "Ubiquitous robots",
keywords = "Networked robots",
keywords = "Ambient intelligence",
keywords = "Cloud robotics ",
abstract = "Abstract Ambient intelligence, ubiquitous and networked robots, and cloud robotics are new research hot topics that have started to gain popularity among the robotics community. They enable robots to acquire richer functionalities and open the way for the composition of a variety of robotic services with three functions: semantic perception, reasoning and actuation. Ubiquitous robots (ubirobots) overcome the limitations of stand-alone robots by integrating them with web services and ambient intelligence technologies. The overlap that exists now between ubirobots and ambient intelligence makes their integration worthwhile. It targets to create a hybrid physical–digital space rich with a myriad of proactive intelligent services that enhance the quality and the way of our living and working. Furthermore, the emergence of cloud computing initiates the massive use of a new generation of ubirobots that enrich their cognitive capabilities and share their knowledge by connecting themselves to cloud infrastructures. The future of ubirobots will certainly be open to an unlimited space of applications such as physical and virtual companions assisting people in their daily living, ubirobots that are able to co-work alongside people and cooperate with them in the same environment, and physical and virtual autonomic guards that are able to protect people, monitor their security and safety, and rescue them in indoor and outdoor spaces. This paper introduces the recent challenges and future trends on these topics. "
}
@article{Grieco201432,
title = "IoT-aided robotics applications: Technological implications, target domains and open issues ",
journal = "Computer Communications ",
volume = "54",
number = "",
pages = "32 - 47",
year = "2014",
note = "",
issn = "0140-3664",
doi = "https://doi.org/10.1016/j.comcom.2014.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0140366414002783",
author = "L.A. Grieco and A. Rizzo and S. Colucci and S. Sicari and G. Piro and D. Di Paola and G. Boggia",
keywords = "IoT",
keywords = "Robots",
keywords = "Robotics Applications",
keywords = "IoT security",
keywords = "Semantic consensus ",
abstract = "Abstract The ongoing revolution of Internet of Things (IoT), together with the growing diffusion of robots in many activities of every day life, makes IoT-aided robotics applications a tangible reality of our upcoming future. Accordingly, new advanced services, based on the interplay between robots and “things”, are being conceived in assisting humans. Nevertheless, the path to a mature development of IoT-aided robotics applications requires several pivotal issues to be solved, design methodologies to be consolidated, and strong architectural choices to be discussed. This paper discusses technological implications, open issues, and target applications in the IoT-aided robotics domain. In particular, the present contribution is four-folded. First, it provides a solid state of the art on the main topics related to IoT-aided robotics services: communication networks, robotics applications in distributed and pervasive environments, semantic-oriented approaches to consensus, and network security. Second, it highlights the most important research challenges to be faced. Third, it describes the technological tools available nowadays. Fourth, it summarizes lessons learned to foster a joint scientific investigation among research teams with complementary skills. "
}
@article{MattaGomez2014305,
title = "Multi-robot data mapping simulation by using microsoft robotics developer studio ",
journal = "Simulation Modelling Practice and Theory ",
volume = "49",
number = "",
pages = "305 - 319",
year = "2014",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2014.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X14001543",
author = "Antonio Matta-Gomez and Jaime Del Cerro and Antonio Barrientos",
keywords = "Service Oriented Computing (SOC)",
keywords = "Multi-robot systems",
keywords = "Data mapping",
keywords = "Robotics frameworks",
keywords = "Microsoft robotics developer studio ",
abstract = "Abstract This document summarizes the goals achieved in the development of a data mapping application, for a multi-robot system, implemented as a service with the guidelines found in the Service Oriented Computing paradigm (SOC). The obtained service generates both local and global maps in the reconstruction of a virtual scenario: the local maps represent the surrounding area around each one of the mobile robots, and the global one the totality of the scenario where the robots move. The information of the global map is continuously updated by merging the data coming from the local maps by using a novel approach: each one of the maps manages a confidence level value that defines which of the data coming from the maps is worthy of being updated into the global one. This technique is not present in related work. The Microsoft Robotics Developer Studio framework was chosen for its implementation because of the advantages that this tool offers in the management of concurrent and distributed processes, typically found in both a robotics platform and in a multi-robot system. "
}
@article{Prestes20131193,
title = "Towards a core ontology for robotics and automation ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1193 - 1204",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000596",
author = "Edson Prestes and Joel Luis Carbonera and Sandro Rama Fiorini and Vitor A. M. Jorge and Mara Abel and Raj Madhavan and Angela Locoro and Paulo Goncalves and Marcos E. Barreto and Maki Habib and Abdelghani Chibani and Sebastien Gerard and Yacine Amirat and Craig Schlenoff",
keywords = "Ontologies for robotics and automation",
keywords = "Ontology-based standards",
keywords = "Core ontology",
keywords = "Ontology engineering",
keywords = "Semantic interoperability",
keywords = "Knowledge representation ",
abstract = "Abstract In this paper, we present the current results of the newly formed IEEE-RAS Working Group, named Ontologies for Robotics and Automation. In particular, we introduce a core ontology that encompasses a set of terms commonly used in Robotics and Automation along with the methodology we have adopted. Our work uses ISO/FDIS 8373 standard developed by the ISO/TC184/SC2 Working Group as a reference. This standard defines, in natural language, some generic terms which are common in Robotics and Automation such as robot, robotic device, etc. Furthermore, we discuss the ontology development process employed along with the problems and decisions taken. "
}
@article{Sheffer2014653,
title = "Viability of Decisional \{DNA\} in Robotics ",
journal = "Procedia Computer Science ",
volume = "35",
number = "",
pages = "653 - 661",
year = "2014",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.08.147",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914011120",
author = "Carl Sheffer and Cesar Sanin and Edward Szczerbicki",
keywords = "SOEKS",
keywords = "Decisional DNA",
keywords = "Mapping",
keywords = "Knowledge Representation",
keywords = "Robotics ; ",
abstract = "Abstract The Decisional \{DNA\} is an artificial intelligence system that uses prior experiences to shape future decisions. Decisional \{DNA\} is written in the Set Of Experience Knowledge Structure (SOEKS) and is capable of capturing and reusing a broad range of data. Decisional \{DNA\} has been implemented in several fields including Alzheimer's diagnosis, geothermal energy and smart TV. Decisional \{DNA\} is well suited to use in robotics due to the large amount of data available and the generally repetitive nature of the tasks robots perform. However, there is very little evidence about the system's performance in this application. This project aims to assess the viability of \{SOEKS\} in robotics. Several knowledge representation approaches were explored then coded in the Java programming language. A hardware platform was constructed from readily available electronics and set up to be compatible with the Java language. Codes were installed on the hardware platform and tested by conducting a series of feature mapping tasks. Success of this project could lead to the future use of \{SOEKS\} in robot control. "
}
@article{Kirill2014216,
title = "The Architecture of Robotics Control Software for Heterogeneous Mobile Robots Network ",
journal = "Procedia Engineering ",
volume = "69",
number = "",
pages = "216 - 221",
year = "2014",
note = "24th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.02.224",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814002264",
author = "Kirsanov Kirill",
keywords = "robtics software",
keywords = "robotics control systems",
keywords = "turing-complite protocol",
keywords = "python",
keywords = "dynamic language ",
abstract = "Abstract This paper dwells on the control software architecture of mobile robots from a programmer's perspective. Several approaches to the construction of such systems were considered in the case of popular systems and the author's own designs. The need for such systems has even become increasingly obvious due to the heterogeneous nature of robotics network. The authors had to work with different types of robots, namely Sensorika \{AMUR\} 1-7, Brokk-400 and Festo Robotino XT. Here, heterogeneity refers not only to the network architecture but also to the robots themselves. Particular attention was given to programming theory, organization of a two-level control instruction pipeline, using Turing-complete protocols, and virtualization of input/output ports. "
}
@incollection{Chang2014213,
title = "Chapter 13 - Medical Robotics for Cellular and Molecular Imaging ",
editor = "Chen, Xiaoyuan and ,  and Wong, Stephen ",
booktitle = "Cancer Theranostics ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2014",
pages = "213 - 225",
isbn = "978-0-12-407722-5",
doi = "https://doi.org/10.1016/B978-0-12-407722-5.00013-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012407722500013X",
author = "Tou Pin Chang and Guang-Zhong Yang",
keywords = "Cellular",
keywords = "Molecular",
keywords = "Robotics",
keywords = "Imaging",
keywords = "Minimally invasive surgery",
keywords = "MIS",
keywords = "Endoscopy",
keywords = "Cancer therapy",
keywords = "Deformation",
keywords = "Robotic assistance",
keywords = "Clinical applications",
keywords = "Confocal",
keywords = "Endomicroscopy",
keywords = "Neoplasia",
keywords = "Endoluminal",
keywords = "Intra-abdominal ",
abstract = "The quest for providing real-time cellular and molecular characterization during endoscopy and minimally invasive surgery (MIS) has motivated the development of new in vivo, in-situ high-resolution microscopic imaging tools. These techniques have shown promise for cancer therapies with the potential for accurate margin definition during \{MIS\} procedures. However, the practical use of these imaging tools is faced with a number of technical difficulties. These include the handling of in vivo tissue deformation and maintenance of consistent tissue contact and probe movement to ensure large area surveillance. Existing results have shown problems associated with manual handling of these imaging probes during intervention and called for the development of smart surgical instruments or the use of robotic assistance. It is increasingly evident that robotics has now an established foothold in medicine as an enabling technology for MIS. This chapter outlines some of the promising clinical applications of confocal endomicroscopy in neoplasia detection and how robotic technologies can be used in the near future to overcome some of the challenges in endoluminal and intra-abdominal imaging. "
}
@article{vanHenten2013170,
title = "Robotics in protected cultivation ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "18",
pages = "170 - 177",
year = "2013",
note = "4th \{IFAC\} Conference on Modelling and Control in Agriculture, Horticulture and Post Harvest Industry ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130828-2-SF-3019.00070",
url = "http://www.sciencedirect.com/science/article/pii/S147466701534979X",
author = "E.J. van Henten and C.W. Bac and J. Hemming and Y. Edan",
keywords = "protected cultivation",
keywords = "robotics",
keywords = "sensor",
keywords = "sensor fusion",
keywords = "motion planning",
keywords = "artificial intelligence",
keywords = "optimal design",
keywords = "human-robot collaboration ",
abstract = "Abstract This paper reviews robotics for protected cultivation systems. Based on a short description of the greenhouse crop production process, the current state in greenhouse mechanization and the challenges for robotics in protected cultivation are identified. Examples of current greenhouse robotics research are presented. Since the complex working environment constitutes a considerable challenge to robotics, opportunities will be identified to deal with this complexity. Solutions can be found in developing more advanced technology, including multiple sensor approaches, sensor fusion and artificial intelligence concepts and in human-robot collaboration. Alternatively, solutions can be found in modifying the working environment. The paper also pleas for the development of more generic solutions to deal with the small and very scattered markets of robots in protected cultivation. "
}
@article{Ma20151279,
title = "LTE-based humanoid robotics system ",
journal = "Microprocessors and Microsystems ",
volume = "39",
number = "8",
pages = "1279 - 1284",
year = "2015",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001179",
author = "Yujun Ma and Chi Harold Liu and Musaed Alhussein and Yin Zhang and Min Chen",
keywords = "LTE",
keywords = "Robot",
keywords = "Cloud computing ",
abstract = "Abstract Although the robots integrated with communication module can provide various functions, there is intrinsic limitation because of the instable wireless connection, restricted bandwidth and limited coverage of network. Fortunately, assisted by \{LTE\} (Long Term Evolution) techniques, the robots can be deployed more widely to support bandwidth-intensive applications. Hence, this paper proposes a LTE-based robotics system integrated with cloud computing to enhance the capability of data transmissions and intelligence for providing higher quality and more friendly services. Furthermore, we develop a robot with emotional recognition and feedback for improving Quality of Service (QoS) and Quality of Experience (QoE), and design a testbed for verifying system’s feasibility and performance. "
}
@article{Sgorbissa20131665,
title = "Structure-based object representation and classification in mobile robotics through a Microsoft Kinect ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1665 - 1679",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001139",
author = "Antonio Sgorbissa and Damiano Verda",
keywords = "Object classification",
keywords = "Structure-based modelling and recognition",
keywords = "Microsoft Kinect",
keywords = "Mobile robotics ",
abstract = "Abstract A new approach enabling a mobile robot to recognize and classify furniture-like objects composed of assembled parts using a Microsoft Kinect is presented. Starting from considerations about the structure of furniture-like objects, i.e., objects which can play a role in the course of a mobile robot mission, the 3D point cloud returned by the Kinect is first segmented into a set of “almost convex” clusters. Objects are then represented by means of a graph expressing mutual relationships between such clusters. Off-line, snapshots of the same object taken from different positions are processed and merged, in order to produce multiple-view models that are used to populate a database. On-line, as soon as a new object is observed, a run-time window of subsequent snapshots is used to search for a correspondence in the database. Experiments validating the approach with a set of objects (i.e., chairs, tables, but also other robots) are reported and discussed in detail. "
}
@article{Malaska20161,
title = "Editorial to 'The best papers from the 32nd International Symposium on Automation and Robotics in Construction and Mining (ISARC 2015)' ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "1 - ",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.08.045",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516301996",
abstract = "",
author = "Mikko Malaska and Rauno Heikkila"
}
@article{InigoBlasco2012803,
title = "Robotics software frameworks for multi-agent robotic systems development ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "6",
pages = "803 - 821",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012000322",
author = "Pablo Inigo-Blasco and Fernando Diaz-del-Rio and M Carmen Romero-Ternero and Daniel Cagigas-Muniz and Saturnino Vicente-Diaz",
keywords = "Robotics",
keywords = "MAS",
keywords = "Agents",
keywords = "Software frameworks",
keywords = "Middleware",
keywords = "Architecture ",
abstract = "Robotics is an area of research in which the paradigm of Multi-Agent Systems (MAS) can prove to be highly useful. Multi-Agent Systems come in the form of cooperative robots in a team, sensor networks based on mobile robots, and robots in Intelligent Environments, to name but a few. However, the development of Multi-Agent Robotic Systems (MARS) still presents major challenges. Over the past decade, a high number of Robotics Software Frameworks (RSFs) have appeared which propose some solutions to the most recurrent problems in robotics. Some of these frameworks, such as ROS, YARP, OROCOS, ORCA, Open-RTM, and Open-RDK, possess certain characteristics and provide the basic infrastructure necessary for the development of MARS. The contribution of this work is the identification of such characteristics as well as the analysis of these frameworks in comparison with the general-purpose Multi-Agent System Frameworks (MASFs), such as \{JADE\} and Mobile-C. "
}
@article{PuigPey2017162,
title = "Public entities driven robotic innovation in urban areas ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "162 - 172",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016302792",
author = "Ana Puig-Pey and Yolanda Bolea and Antoni Grau and Josep Casanovas",
keywords = "Robotics",
keywords = "Urban challenges",
keywords = "Smart City",
keywords = "Innovative Public Procurement",
keywords = "Public end Users Driven Technological Innovation ",
abstract = "Abstract Cities present new challenges and needs to satisfy and improve lifestyle for their citizens under the concept “Smart City”. In order to achieve this goal in a global manner, new technologies are required as the robotic one. But Public entities unknown the possibilities offered by this technology to get solutions to their needs. In this paper the development of the Innovative Public Procurement instruments is explained, specifically the process \{PDTI\} (Public end Users Driven Technological Innovation) as a driving force of robotic research and development and offering a list of robotic urban challenges proposed by European cities that have participated in such a process. In the next phases of the procedure, this fact will provide novel robotic solutions addressed to public demand that are an example to be followed by other Smart Cities. "
}
@article{Kerr201723,
title = "Accurate 3D reconstruction of bony surfaces using ultrasonic synthetic aperture techniques for robotic knee arthroplasty ",
journal = "Computerized Medical Imaging and Graphics ",
volume = "58",
number = "",
pages = "23 - 32",
year = "2017",
note = "",
issn = "0895-6111",
doi = "https://doi.org/10.1016/j.compmedimag.2017.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0895611117300204",
author = "William Kerr and Philip Rowe and Stephen Gareth Pierce",
keywords = "Ultrasound",
keywords = "Total focussing method",
keywords = "Synthetic aperture focussing technique",
keywords = "Robotics",
keywords = "3D surface reconstruction",
keywords = "Computer-aided surgery ",
abstract = "Abstract Robotically guided knee arthroplasty systems generally require an individualized, preoperative 3D model of the knee joint. This is typically measured using Computed Tomography (CT) which provides the required accuracy for preoperative surgical intervention planning. Ultrasound imaging presents an attractive alternative to CT, allowing for reductions in cost and the elimination of doses of ionizing radiation, whilst maintaining the accuracy of the 3D model reconstruction of the joint. Traditional phased array ultrasound imaging methods, however, are susceptible to poor resolution and signal to noise ratios (SNR). Alleviating these weaknesses by offering superior focusing power, synthetic aperture methods have been investigated extensively within ultrasonic non-destructive testing. Despite this, they have yet to be fully exploited in medical imaging. In this paper, the ability of a robotic deployed ultrasound imaging system based on synthetic aperture methods to accurately reconstruct bony surfaces is investigated. Employing the Total Focussing Method (TFM) and the Synthetic Aperture Focussing Technique (SAFT), two samples were imaged which were representative of the bones of the knee joint: a human-shaped, composite distal femur and a bovine distal femur. Data were captured using a 5 MHz, 128 element 1D phased array, which was manipulated around the samples using a robotic positioning system. Three dimensional surface reconstructions were then produced and compared with reference models measured using a precision laser scanner. Mean errors of 0.82 mm and 0.88 mm were obtained for the composite and bovine samples, respectively, thus demonstrating the feasibility of the approach to deliver the sub-millimetre accuracy required for the application. "
}
@article{Bidot2017229,
title = "Geometric backtracking for combined task and motion planning in robotic systems ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "229 - 265",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S000437021500051X",
author = "Julien Bidot and Lars Karlsson and Fabien Lagriffoul and Alessandro Saffiotti",
keywords = "Combined task and motion planning",
keywords = "Task planning",
keywords = "Action planning",
keywords = "Path planning",
keywords = "Robotics",
keywords = "Geometric reasoning",
keywords = "Hybrid reasoning",
keywords = "Robot manipulation ",
abstract = "Abstract Planners for real robotic systems should not only reason about abstract actions, but also about aspects related to physical execution such as kinematics and geometry. We present an approach to hybrid task and motion planning, in which state-based forward-chaining task planning is tightly coupled with motion planning and other forms of geometric reasoning. Our approach is centered around the problem of geometric backtracking that arises in hybrid task and motion planning: in order to satisfy the geometric preconditions of the current action, a planner may need to reconsider geometric choices, such as grasps and poses, that were made for previous actions. Geometric backtracking is a necessary condition for completeness, but it may lead to a dramatic computational explosion due to the large size of the space of geometric states. We explore two avenues to deal with this issue: the use of heuristics based on different geometric conditions to guide the search, and the use of geometric constraints to prune the search space. We empirically evaluate these different approaches, and demonstrate that they improve the performance of hybrid task and motion planning. We demonstrate our hybrid planning approach in two domains: a real, humanoid robotic platform, the \{DLR\} Justin robot, performing object manipulation tasks; and a simulated autonomous forklift operating in a warehouse. "
}
@article{Giuseppe2012104,
title = "Educational Robotics Between Narration and Simulation ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "51",
number = "",
pages = "104 - 109",
year = "2012",
note = "The World Conference on Design, Arts and Education (DAE-2012), May 1-3 2012, Antalya, Turkey ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2012.08.126",
url = "http://www.sciencedirect.com/science/article/pii/S1877042812032648",
author = "Alessandri Giuseppe and Paciaroni Martina",
keywords = "Technology learning",
keywords = "Educational robotics: Storytelling",
keywords = "Simulation",
keywords = "Narration. ",
abstract = "This contribution wants to show two of the different approaches to Educational Robotics: narration and simulation. One can be independent from another, but they can be put in a sequence made of two steps: first, the creation and organization of a story, then its realization on a stage, where the robot represents a character in the story itself and acts in the real world. You move from a flexible phase (narration) to a rigorous one (simulation).Robotic experiences in educational contexts are particularly important, not only as mediators for activities in disciplinary fields, but also as tools for activating abilities through a didactic approach based on action. According to Varela, Thompson and Rosch (1991), objects are not seen by extracting characteristics from the visual system, but through the visual guide of action. Robotics allows recognizing the world by living, not by observing or listening to stories. Robotic, thus, becomes Educational: you can move from the observation of a device to the immersion in the device itself; through the device, moreover, knowledge can be developed from the awareness of the real world's segment you are exploring. "
}
@article{Mirolli2011298,
title = "Towards a Vygotskyan cognitive robotics: The role of language as a cognitive tool ",
journal = "New Ideas in Psychology ",
volume = "29",
number = "3",
pages = "298 - 311",
year = "2011",
note = "Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism ",
issn = "0732-118X",
doi = "https://doi.org/10.1016/j.newideapsych.2009.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0732118X09000348",
author = "Marco Mirolli and Domenico Parisi",
keywords = "Robotics",
keywords = "Cognition",
keywords = "Language",
keywords = "Vygotsky",
keywords = "Categorization",
keywords = "Learning ",
abstract = "Cognitive Robotics can be defined as the study of cognitive phenomena by their modeling in physical artifacts such as robots. This is a very lively and fascinating field which has already given fundamental contributions to our understanding of natural cognition. Nonetheless, robotics has to date addressed mainly very basic, low-level cognitive phenomena like sensory-motor coordination, perception, and navigation, and it is not clear how the current approach might scale up to explain high-level human cognition. In this paper we argue that a promising way to do that is to merge current ideas and methods of ‘embodied cognition’ with the Russian tradition of theoretical psychology which views language not only as a communication system but also as a cognitive tool, that is by developing a Vygotskyan cognitive robotics. We substantiate this idea by discussing several domains in which language can improve basic cognitive abilities and permit the development of high-level cognition: learning, categorization, abstraction, memory, voluntary control, and mental life. "
}
@article{Chaari2016260,
title = "Cyber-physical systems clouds: A survey ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "260 - 278",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S1389128616302699",
author = "Rihab Chaari and Fatma Ellouze and Anis Koubaa and Basit Qureshi and Nuno Pereira and Habib Youssef and Eduardo Tovar",
keywords = "Cloud computing",
keywords = "Cloud robotics",
keywords = "Cloud sensors",
keywords = "Vehicular cloud networks ",
abstract = "Abstract Cyber-Physical Systems (CPSs) represent systems where computations are tightly coupled with the physical world, meaning that physical data is the core component that drives computation. Industrial automation systems, wireless sensor networks, mobile robots and vehicular networks are just a sample of cyber-physical systems. Typically, \{CPSs\} have limited computation and storage capabilities due to their tiny size and being embedded into larger systems. With the emergence of cloud computing and the Internet-of-Things (IoT), there are several new opportunities for these \{CPSs\} to extend their capabilities by taking advantage of the cloud resources in different ways. In this survey paper, we present an overview of research efforts on the integration of cyber-physical systems with cloud computing and categorize them into three areas: (1) remote brain, (2) big data manipulation, (3) and virtualization. In particular, we focus on three major \{CPSs\} namely mobile robots, wireless sensor networks and vehicular networks. "
}
@article{Vonasek2012210,
title = "Techniques for Modeling Simulation Environments for Modular Robotics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "2",
pages = "210 - 215",
year = "2012",
note = "7th Vienna International Conference on Mathematical Modelling ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120215-3-AT-3016.00037",
url = "http://www.sciencedirect.com/science/article/pii/S147466701630670X",
author = "Vojtěch Vonasek and Miroslav Kulich and Tomas Krajnik and Martin Saska and Daniel Fiser and Vladimir Petrik and Libor Přeucil",
keywords = "modular robotics",
keywords = "simulation",
keywords = "3D model reconstruction ",
abstract = "Abstract In modular robotics, complex structures can be formed from basic modules to solve tasks which would be difficult for a single robot. The development of techniques for adaptation and evolution of multi-robot organisms is the subject of Symbrion project Levi and Kernbach (2010). In the project, the bio-inspired evolutionary algorithms are massively simulated prior to run them on a real hardware. It is crucial to evolve behaviors of the robots in a simulation, that is close to a real world. Hence, accurate and efficient representation of an environment in the simulation is needed. The robots learn simple motion primitives or complex movement patterns during many runs of the evolution. The learned skills are then used during experiments with a real hardware. In this paper, we present methods for building 3D model of a real arena using a laser rangefinder. The resulting 3D models consist of triangles. They can be constructed in various level of details using state-of-the-art methods for 3D reconstruction. We will show, how the size of the models influences the speed of the simulation. "
}
@article{MateoFerrus201699,
title = "Design in robotics based in the voice of the customer of household robots ",
journal = "Robotics and Autonomous Systems ",
volume = "79",
number = "",
pages = "99 - 107",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016000178",
author = "Rafael Mateo Ferrus and Manuel Dominguez Somonte",
keywords = "Tele-assistance",
keywords = "Dementia",
keywords = "Tele-care",
keywords = "Housekeeping",
keywords = "Voice of the customer",
keywords = "Robot ",
abstract = "Abstract The aim of this study is the analysis of the state of the art in consumer robotics dedicated to personal care and housekeeping, for further critical analysis of it. After interviewing different users we will follow a methodology to find the voice of the customer. From these interviews we get the customer’s needs which will be structured and ordered in a hierarchy that will help us to set the priorities, concluding with the design requirements and the basic features that the robot must have. "
}
@article{Kopacek201636,
title = "Development Trends in Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "29",
pages = "36 - 41",
year = "2016",
note = "17th \{IFAC\} Conference on International Stability, Technology and Culture \{TECIS\} 2016Durrës, Albania, 26—28 October 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.070",
url = "http://www.sciencedirect.com/science/article/pii/S240589631632506X",
author = "P. Kopacek",
keywords = "Robots",
keywords = "Control",
keywords = "Roboethics",
keywords = "Social aspects ",
abstract = "Abstract: Current developing trends are humanoid robots and robots supporting people in everyday life. Other intensive research areas are cooperative robots, bio inspired robots, ubiquitous robots, cloud robots, modular robots,...... Micro-, Nano-and Femtorobots are in development and Atorobots are knocking on the door. This paper is an “upgrade” from Kopacek (2015) because the field of robotics is dramatically changing. Therefore an overview as well as an outlook on future developments will be given with special emphasis to the demands and relations to TECIS. "
}
@article{Gustin2016470,
title = "Hand gesture recognition from multibeam sonar imagery* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "23",
pages = "470 - 475",
year = "2016",
note = "10th \{IFAC\} Conference on Control Applications in Marine SystemsCAMS 2016Trondheim, Norway, 13—16 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.450",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316320389",
author = "Franka Gustin and Ivor Rendulic and Nikola Miskovic and Zoran Vukic",
keywords = "Multibeam sonar",
keywords = "gesture recognition ",
abstract = "Abstract: Divers perform demanding tasks in a complex and hazardous underwater environment, which prevents them from carrying special devices that may allow them to communicate with their robotic diving buddies. In this world of natural human-robot interaction in the underwater environment, envisioned by the \{FP7\} Cognitive Robotics project CADDY, hand detection and gesture interpretation is a prerequisite. While hand gesture recognition is most often performed with cameras (mono and stereo), their use in the underwater environment is compromised due to water turbidity and lack of sunlight at greater depths. This paper deals with this lack of performance by introducing the concept of using high resolution multibeam sonars (often referred to as acoustic cameras) for diver hand gesture recognition. In order to ensure reliable communication between the diver and the robot, it is of great importance that the classification precision is as high as possible. This paper presents results of hand gesture recognition which is performed by using two approaches: convex hull method and the support vector machine (SVM). A novel approach that fuses the two methods is introduced as a way of increasing the precision of classification. The results obtained on more than 1000 real sonar samples show that the precision using the convex hull method is around 92%, and using the \{SVM\} around 94%, while fusing the two approaches provides around 99% classification precision. "
}
@article{Carlone20118150,
title = "On Registration of Uncertain Three-dimensional Vectors with Application to Robotics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "8150 - 8158",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.01163",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016449190",
author = "Luca Carlone and Basilio Bona",
keywords = "Registration",
keywords = "Optimization",
keywords = "3D Vectors",
keywords = "Robotics",
keywords = "Robot Navigation ",
abstract = "Abstract In this paper we investigate the problem of finding a suitable roto-translation achieving the optimal matching between two uncertain three-dimensional vector sets. State-of-the-art approaches for vector registration are based on strict assumptions on the covariance matrices describing the uncertainty on the vectors, hence they can be too conservative or inaccurate when the actual uncertainty differs from the employed model. After discussing the problem we propose two iterative solutions for matching the 3D vectors, showing that a suitable uncertainty model allows reducing the estimation error while preserving the real-time nature of the computation. We further derive the covariance matrices for such estimates, evaluating their consistency through extensive numerical experiments. The results appear particularly suitable for robotic applications, since the vector sets constitute a natural representation of three-dimensional perception of a robot, interacting with complex non-planar environments. "
}
@incollection{Nomdedeu2011125,
title = "6 - Sensing capabilities for mobile robotics ",
editor = "Baudoin, Y. and ,  and Habib, Maki K. ",
booktitle = "Using Robots in Hazardous Environments ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2011",
pages = "125 - 146",
isbn = "978-1-84569-786-0",
doi = "https://doi.org/10.1533/9780857090201.2.125",
url = "http://www.sciencedirect.com/science/article/pii/B978184569786050006X",
author = "L. Nomdedeu and J. Sales and R. Marin and E. Cervera and J.S. Aez",
keywords = "\{GUARDIANS\} project",
keywords = "sensing capabilities",
keywords = "localization",
keywords = "mobile robotics",
keywords = "ego-motion",
keywords = "environment perception ",
abstract = "Abstract: This chapter provides an overview of sensing capabilities for the estimation of distances and localization in a team of mobile robot platforms. This work, similar to others in this book, has been carried out in the context of the \{EU\} \{GUARDIANS\} project (Group of Unmanned Assistant Robots Deployed In Aggregative Navigation supported by Scent detection). There is a need for a localization method not only for robot platforms but also for fire fighters. This chapter will present an overview of the current sensing capabilities available, both commercial, and those not yet commercialized. "
}
@article{Amirat20161,
title = "Assistance and Service Robotics in a Human Environment ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "1 - 3",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.002",
url = "http://www.sciencedirect.com/science/article/pii/S092188901500247X",
abstract="",
author = "Yacine Amirat and David Daney and Samer Mohammed and Anne Spalanzani and Abdelghani Chibani and Olivier Simonin"
}
@article{Gedicke2016114,
title = "\{FLAP\} for CAOS: Forward-Looking Active Perception for Clutter-Aware Object Search1 ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "114 - 119",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.718",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316309946",
author = "Thorsten Gedicke and Martin Gunther and Joachim Hertzberg",
keywords = "autonomous mobile robots",
keywords = "heuristic searches",
keywords = "knowledge acquisition",
keywords = "path planning",
keywords = "probabilistic models",
keywords = "robot vision",
keywords = "sampling actions",
keywords = "searching systems ",
abstract = "Abstract In this paper, we present a system for autonomous object search and exploration in cluttered environments. The system shortens the average time needed to complete search tasks by continually planning multiple perception actions ahead of time using probabilistic prior knowledge. Useful sensing actions are found using a frontier-based view sampling technique in a continuously built 3D map. We demonstrate the system on real hardware, investigate the planner’s performance in three experiments in simulation, and show that our approach achieves shorter overall run times of search tasks compared to a greedy strategy. "
}
@article{Bertacchini2017,
title = "Shopping with a robotic companion ",
journal = "Computers in Human Behavior ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2017.02.064",
url = "http://www.sciencedirect.com/science/article/pii/S0747563217301450",
author = "Francesca Bertacchini and Eleonora Bilotta and Pietro Pantano",
keywords = "Social robotics",
keywords = "Human Robot Interaction (HRI)",
keywords = "Emotion and Gesture Recognition",
keywords = "Machine learning",
keywords = "Smart retail settings ",
abstract = "Abstract In this paper, we present a robotic shopping assistant, designed with a cognitive architecture, grounded in machine learning systems, in order to study how the human-robot interaction (HRI) is changing the shopping behavior in smart technological stores. In the software environment of the \{NAO\} robot, connected to the Internet with cloud services, we designed a social-like interaction where the robot carries out actions with the customer. In particular, we focused our design on two main skills the robot has to learn: the first is the ability to acquire social input communicated by relevant clues that humans provide about their emotional state (emotions, emotional speech), or collected in the Social Media (such as, information on the customer's tastes, cultural background, etc.). The second is the skill to express in turn its own emotional state, so that it can affect the customer buying decision, refining in the user the sense of interacting with a human-like companion. By combining social robotics and machine learning systems the potential of robotics to assist people in real life situations will increase, providing a gentle customers' acceptance of advanced technologies. "
}
@article{Indelman201563,
title = "Incremental light bundle adjustment for structure from motion and robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "70",
number = "",
pages = "63 - 82",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015000810",
author = "Vadim Indelman and Richard Roberts and Frank Dellaert",
keywords = "Bundle adjustment",
keywords = "SLAM",
keywords = "Vision-aided navigation ",
abstract = "Abstract Bundle adjustment (BA) is essential in many robotics and structure-from-motion applications. In robotics, often a bundle adjustment solution is desired to be available incrementally as new poses and 3D points are observed. Similarly in batch structure from motion, cameras are typically added incrementally to allow good initializations. Current incremental \{BA\} methods quickly become computationally expensive as more camera poses and 3D points are added into the optimization. In this paper we introduce incremental light bundle adjustment (iLBA), an efficient optimization framework that substantially reduces computational complexity compared to incremental bundle adjustment. First, the number of variables in the optimization is reduced by algebraic elimination of observed 3D points, leading to a structureless BA. The resulting cost function is formulated in terms of three-view constraints instead of re-projection errors and only the camera poses are optimized. Second, the optimization problem is represented using graphical models and incremental inference is applied, updating the solution using adaptive partial calculations each time a new camera is incorporated into the optimization. Typically, only a small fraction of the camera poses are recalculated in each optimization step. The 3D points, although not explicitly optimized, can be reconstructed based on the optimized camera poses at any time. We study probabilistic and computational aspects of iLBA and compare its accuracy against incremental \{BA\} and another recent structureless method using real–imagery and synthetic datasets. Results indicate iLBA is 2–10 times faster than incremental BA, depending on number of image observations per frame. "
}
@article{Rausch201733,
title = "Kinematics chain based dimensional variation analysis of construction assemblies using building information models and 3D point clouds ",
journal = "Automation in Construction ",
volume = "75",
number = "",
pages = "33 - 44",
year = "2017",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516304733",
author = "Christopher Rausch and Mohammad Nahangi and Carl Haas and Jeffrey West",
keywords = "Dimensional variability",
keywords = "Kinematics chains",
keywords = "Robotics",
keywords = "Laser scanning",
keywords = "Building information model",
keywords = "Tolerance",
keywords = "Discrepancy and deviation ",
abstract = "Abstract As modern methods of construction progressively incorporate more facets of manufacturing, design optimization tools used in manufacturing can be adopted into construction to solve complex challenges. The specification and control of dimensions and geometry of construction assemblies is one such challenge that can be solved using tools from manufacturing. Even with building information models (BIM) to assist with clash detection for identifying potential dimensional problems, or the use of tolerances to control critical features in an assembly, dimensional variability is still a complex challenge to address in construction. This paper explores the use of a dimensional variation analysis (DVA), which is a design optimization tool from the manufacturing industry. This paper presents a \{DVA\} approach which is based on kinematics theory in robotics to define the assembly equation (how components are dimensionally related to each other). A case study is used to validate the proposed framework through two distinct approaches: (1) an as-designed (model-based) \{DVA\} and (2) an as-built (laser-based) DVA. Comparison of these two methods resulted in a percent difference less than 1% which demonstrates the reliability of using the model-based method for designing critical construction components. "
}
@article{Lee2012376,
title = "Liability Exposure for Surgical Robotics Instructors ",
journal = "Journal of Minimally Invasive Gynecology ",
volume = "19",
number = "3",
pages = "376 - 379",
year = "2012",
note = "",
issn = "1553-4650",
doi = "https://doi.org/10.1016/j.jmig.2012.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S1553465012000209",
author = "Yu L. Lee and Gokhan Kilic and John Y. Phelps",
keywords = "Instructors",
keywords = "Liability",
keywords = "Proctors",
keywords = "Robotic surgery ",
abstract = "Surgical robotics instructors provide an essential service in improving the competency of novice gynecologic surgeons learning robotic surgery and advancing surgical skills on behalf of patients. However, despite best intentions, robotics instructors and the gynecologists who use their services expose themselves to liability. The fear of litigation in the event of a surgical complication may reduce the availability and utility of robotics instructors. A better understanding of the principles of duty of care and the physician-patient relationship, and their potential applicability in a court of law likely will help to dismantle some concerns and uncertainties about liability. This commentary is not meant to discourage current and future surgical instructors but to raise awareness of liability issues among robotics instructors and their students and to recommend certain preventive measures to curb potential liability risks. "
}
@article{Kostavelis201586,
title = "Semantic mapping for mobile robotics tasks: A survey ",
journal = "Robotics and Autonomous Systems ",
volume = "66",
number = "",
pages = "86 - 103",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003030",
author = "Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Mobile robots",
keywords = "Semantic map",
keywords = "Topological map",
keywords = "Temporal coherence",
keywords = "Object recognition",
keywords = "Place recognition",
keywords = "Human–robot interaction",
keywords = "Knowledge representation",
keywords = "Planning ",
abstract = "Abstract The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human–robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also made. "
}
@article{Tsai20081392,
title = "An ontology-based collaborative service-oriented simulation framework with Microsoft Robotics Studio® ",
journal = "Simulation Modelling Practice and Theory ",
volume = "16",
number = "9",
pages = "1392 - 1414",
year = "2008",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2008.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X08001421",
author = "W.T. Tsai and Xin Sun and Qian Huang and Helen Karatza",
keywords = "Service-oriented computing",
keywords = "Simulation framework",
keywords = "Ontology",
keywords = "Robotics Studio",
keywords = "Model-driven development ",
abstract = "In Service-Oriented Architecture (SOA), the concepts that services can be discovered and application can be composed via service discovery bring great flexibility to application development [Y. Chen, W.T. Tsai, Distributed Service-Oriented Software Development, Kendall/Hunt, 2008, [4]]. Microsoft Robotics Studio (MSRS) is a recent initiative in applying \{SOA\} to embedded systems and one of its key features is its 3-D simulation tool that allows applications to be simulated before deployment. This paper proposes an ontology-based service-oriented simulation framework with \{MSRS\} by adding a set of ontology systems, i.e., service ontology, workflow ontology, entity ontology, and environment ontology. These ontology systems store relevant information useful to compose simulation applications, and items stored also cross reference to each other to facilitate reusability and rapid application composition, This paper then provides a detailed case study on a popular robotic game Sumobot using \{MSRS\} to illustrate the key concepts and how they can support rapid simulation development.1The contents of this paper were developed under a grant from \{US\} Department of Defense and the Fund for the Improvement of Postsecondary Education (FIPSE), \{US\} Department of Education. However, these contents do not necessarily represent the policy of the Department of Education, and you should not assume endorsement by the Federal Government. 1 "
}
@article{Schlenoff20151,
title = "Preface: Special issue on knowledge driven robotics and manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "1 - 2",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000763",
abstract="",
author = "Craig Schlenoff and Stephen Balakirsky and Edson Prestes"
}
@article{Carstensen2016560,
title = "Condition Monitoring and Cloud-based Energy Analysis for Autonomous Mobile Manipulation - Smart Factory Concept with \{LUHbots\} ",
journal = "Procedia Technology ",
volume = "26",
number = "",
pages = "560 - 569",
year = "2016",
note = "3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2016.08.070",
url = "http://www.sciencedirect.com/science/article/pii/S2212017316304170",
author = "Jan Carstensen and Torben Carstensen and Malte Pabst and Fabian Schulz and Jan Friederichs and Simon Aden and Daniel Kaczor and Jens Kotlarski and Tobias Ortmaier",
keywords = "Mobile Robotics",
keywords = "Condition Monitoring",
keywords = "Cloud-based Energy Analysis",
keywords = "Logistic Handling ",
abstract = "Abstract In this paper, a smart factory concept for autonomous mobile robots is presented. The main purpose is to increase productivity of the transport in machine-floor. It is based on advanced methods for failure handling and prevention, leading to increased robustness, less downtime and less effort in maintenance [1], [2]. Therefore, condition data and states of the robot are collected by Robot Operation System (ROS) and transferred to a factory hub (server). The collected data, e.g. voltages, currents, set points, velocities and accelerations are used to identify important system parameters, e.g. moving masses and friction parameters to enable the proposed smart factory concept. Further aim is to let the factory hub control a group of mobile robots using a self-organizing algorithm for different tasks. Due to the increasing customization of products causing smaller lot sizes [3], manufacturers of mobile robotic production systems have developed a diversity of flexible robots [4], [5], [6], [7], [8]. Mobile robots inside the production line allow for collecting and evaluation of system-inherent data e.g. handling and transportation time, wheel friction, workpieces mass, center of gravity and energy consumption during trajectory execution. In general, mobile robots are electrically driven. Hence, an estimation of the battery state is essential in order to automatically plan charging cycles and to organize and optimize the cooperation behavior of a group of mobile robots. In this proposed approach, mobile robots are equipped with a measurement system and connected via Bluetooth to a factory hub, providing monitoring, analyzing and planning tools. The battery states of all robots are considered in the process planning. The robots are based on the \{KUKA\} youBot, equipped with a soft gripper and a RealSense camera. A condition monitoring system measures the energy consumption of all components and transfers the information to the factory hub. The state of charge limits the number of executable operations. Therefore, in a first step the power consumption of all individual consumers is captured, e.g. EC-Maxxon base motors, PC, gripper, camera and five-axis arm. Experimental results show, that the youBot requires 46 W in standstill plus the drive power depending on the movement. Here, the results for mobile manipulation in industrial scenarios during preparation for the RoboCup@Work 2016 will be presented. The transfer of raw measurement data to the hub is shown, as well as the proposed algorithms allowing for range prediction and optimized set point generation. The concept provides excellent capability in data collection, analysis of existing production and production planning. "
}
@article{WANG2015490,
title = "Obstacle Avoidance for Kinematically Redundant Robot*** ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "28",
pages = "490 - 495",
year = "2015",
note = "17th \{IFAC\} Symposium on System Identification \{SYSID\} 2015Beijing, China, 19–21 October 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.12.176",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315028001",
author = "Xinyu WANG and Chenguang YANG and Junshen CHEN and Hongbin MA and Feng LIU",
keywords = "Kinematically Redundant",
keywords = "Obstacle Avoidance ",
abstract = "Abstract Manipulator's obstacle avoidance is always a challenging topic in robotics. With the concern of the safety problems in human working environment, an improved obstacle avoidance method is proposed based on the general solution of the inverse kinematic problem of a redundant manipulator. A new obstacle detection method using Kinect R sensor is designed to give a robust obstacle information. By designing a parallel system of the manipulator, the proposed control method is not only to achieve the goal of moving away from the obstacle, but also able to guarantee the robot move back to its original pose. The stability of the closed-loop system is established using Lyapunov direct method to ensure the asymptotic stability of the system. The performance of the simulation results verifies the effectiveness of the proposed obstacle detection algorithm and the obstacle avoidance method. "
}
@article{Taylor20081089,
title = "Faux frogs: multimodal signalling and the value of robotics in animal behaviour ",
journal = "Animal Behaviour ",
volume = "76",
number = "3",
pages = "1089 - 1097",
year = "2008",
note = "",
issn = "0003-3472",
doi = "https://doi.org/10.1016/j.anbehav.2008.01.031",
url = "http://www.sciencedirect.com/science/article/pii/S0003347208002327",
abstract="",
author = "Ryan C. Taylor and Barrett A. Klein and Joey Stein and Michael J. Ryan",
keywords = "female choice",
keywords = "multimodal signalling",
keywords = "Physalaemus pustulosus",
keywords = "robotics",
keywords = "sexual selection",
keywords = "tungara frog",
keywords = "visual cue "
}
@article{Ahmad201616,
title = "Software architectures for robotic systems: A systematic mapping study ",
journal = "Journal of Systems and Software ",
volume = "122",
number = "",
pages = "16 - 39",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.08.039",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216301479",
author = "Aakash Ahmad and Muhammad Ali Babar",
keywords = "Software architecture",
keywords = "Robotic systems",
keywords = "Evidence-based software engineering",
keywords = "Software architecture for robotics",
keywords = "Systematic mapping study ",
abstract = "AbstractContext Several research efforts have been targeted to support architecture centric development and evolution of software for robotic systems for the last two decades. Objective We aimed to systematically identify and classify the existing solutions, research progress and directions that influence architecture-driven modeling, development and evolution of robotic software. Research Method We have used Systematic Mapping Study (SMS) method for identifying and analyzing 56 peer-reviewed papers. Our review has (i) taxonomically classified the existing research and (ii) systematically mapped the solutions, frameworks, notations and evaluation methods to highlight the role of software architecture in robotic systems. Results and Conclusions We have identified eight themes that support architectural solutions to enable (i) operations, (ii) evolution and (iii) development specific activities of robotic software. The research in this area has progressed from object-oriented to component-based and now to service-driven robotics representing different architectural models that emerged overtime. An emerging solution is cloud robotics that exploits the foundations of service-driven architectures to support an interconnected web of robots. The results of this \{SMS\} facilitate knowledge transfer – benefiting researchers and practitioners – focused on exploiting software architecture to model, develop and evolve robotic systems. "
}
@article{Mineo2017,
title = "Introducing a novel mesh following technique for approximation-free robotic tool path trajectories ",
journal = "Journal of Computational Design and Engineering ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "2288-4300",
doi = "https://doi.org/10.1016/j.jcde.2017.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S228843001630135X",
author = "Carmelo Mineo and Stephen Gareth Pierce and Pascual Ian Nicholson and Ian Cooper",
keywords = "Tool path generation",
keywords = "Mesh following technique",
keywords = "Triangular meshes",
keywords = "Robotics",
keywords = "NDT ",
abstract = "Abstract Modern tools for designing and manufacturing of large components with complex geometries allow more flexible production with reduced cycle times. This is achieved through a combination of traditional subtractive approaches and new additive manufacturing processes. The problem of generating optimum tool-paths to perform specific actions (e.g. part manufacturing or inspection) on curved surface samples, through numerical control machinery or robotic manipulators, will be increasingly encountered. Part variability often precludes using original design \{CAD\} data directly for toolpath generation (especially for composite materials), instead surface mapping software is often used to generate tessellated models. However, such models differ from precise analytical models and are often not suitable to be used in current commercially available path-planning software, since they require formats where the geometrical entities are mathematically represented thus introducing approximation errors which propagate into the generated toolpath. This work adopts a fundamentally different approach to such surface mapping and presents a novel Mesh Following Technique (MFT) for the generation of tool-paths directly from tessellated models. The technique does not introduce any approximation and allows smoother and more accurate surface following tool-paths to be generated. The background mathematics to the new \{MFT\} algorithm are introduced and the algorithm is validated by testing through an application example. Comparative metrology experiments were undertaken to assess the tracking performance of the \{MFT\} algorithms, compared to tool-paths generated through commercial software. It is shown that the \{MFT\} tool-paths produced 40% smaller errors and up to 66% lower dispersion around the mean values. "
}
@article{Alenya201410,
title = "ToF cameras for active vision in robotics ",
journal = "Sensors and Actuators A: Physical ",
volume = "218",
number = "",
pages = "10 - 22",
year = "2014",
note = "",
issn = "0924-4247",
doi = "https://doi.org/10.1016/j.sna.2014.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0924424714003458",
author = "G. Alenya and S. Foix and C. Torras",
keywords = "Time-of-Flight cameras",
keywords = "3D perception for manipulation",
keywords = "Depth calibration",
keywords = "Outdoor imaging",
keywords = "Complex-shape objects ",
abstract = "Abstract ToF cameras are now a mature technology that is widely being adopted to provide sensory input to robotic applications. Depending on the nature of the objects to be perceived and the viewing distance, we distinguish two groups of applications: those requiring to capture the whole scene and those centered on an object. It will be demonstrated that it is in this last group of applications, in which the robot has to locate and possibly manipulate an object, where the distinctive characteristics of ToF cameras can be better exploited. After presenting the physical sensor features and the calibration requirements of such cameras, we review some representative works highlighting for each one which of the distinctive ToF characteristics have been more essential. Even if at low resolution, the acquisition of 3D images at frame-rate is one of the most important features, as it enables quick background/foreground segmentation. A common use is in combination with classical color cameras. We present three developed applications, using a mobile robot and a robotic arm, to exemplify with real images some of the stated advantages. "
}
@article{Williams2017313,
title = "Learned Action SLAM: Sharing \{SLAM\} through learned path planning information between heterogeneous robotic platforms ",
journal = "Applied Soft Computing ",
volume = "50",
number = "",
pages = "313 - 326",
year = "2017",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2016.11.036",
url = "http://www.sciencedirect.com/science/article/pii/S1568494616306056",
author = "Henry Williams and Will N. Browne and Dale A. Carnegie",
keywords = "Cognitive robotics",
keywords = "Learning Classifier Systems",
keywords = "Simultaneous localisation and mapping",
keywords = "Navigation ",
abstract = "Abstract Currently when path planning is used in \{SLAM\} it is to benefit \{SLAM\} only, with no mutual benefit for path planning. Furthermore, \{SLAM\} algorithms are generally implemented and modified for individual heterogeneous robotic platforms without autonomous means of sharing navigation information. This limits the ability for robot platforms to share navigation information and can require heterogeneous robot platforms to generate individual maps within the same environment. This paper introduces Learned Action SLAM, which for the first time autonomously combines path-planning with \{SLAM\} such that heterogeneous robots can share learnt knowledge through Learning Classifier Systems (LCS). This is in contrast to Active SLAM, where path-planning is used to benefit \{SLAM\} only. Results from testing LA-SLAM on robots in the real world have shown; promise for use on teams of robots with various sensor morphologies, implications for scaling to associated domains, and ability to share maps taken from less capable to more advanced robots. "
}
@article{Barnfather2016561,
title = "Development and testing of an error compensation algorithm for photogrammetry assisted robotic machining ",
journal = "Measurement ",
volume = "94",
number = "",
pages = "561 - 577",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2016.08.032",
url = "http://www.sciencedirect.com/science/article/pii/S0263224116304936",
author = "J.D. Barnfather and M.J. Goodfellow and T. Abram",
keywords = "Machining",
keywords = "Robotics",
keywords = "Photogrammetry",
keywords = "Compensation",
keywords = "Error ",
abstract = "Abstract Robotic machining of relatively small features on large components potentially offers an opportunity to reduce capital expenditure in various industries. A barrier to this is the inability of robotic machine tools to machine to the tolerances of conventional equipment. This paper proposes and tests a photogrammetry-based metrology assistance algorithm to compensate for robotic machining inaccuracy, as measured in the part, and investigates the associated measurement challenges. The algorithm is executed in a two stage process, whereby the closest point to nominal cutting coordinates on an aligned inspection surface is used for compensation, created a penultimate measured cut. Finally, the finishing program coordinates are compensated to correct under-cuts during the measured cut stage. Conceptual tests using simulated measurement data give confidence that the proposed approach works well. In experiments, a key area for further R&amp;D effort is found to be uneven inspect point coverage, which results in alignment issues and a poor surface finish. Ultimately, direction is given to improve measurement system performance to enable the metrology assistance approach proposed to be implemented and therefore the benefits of “process-to-part” robotic machining to be realised. "
}
@article{Hayati2007180,
title = "\{ADVANCED\} \{ROBOTICS\} \{TECHNOLOGY\} \{INFUSION\} \{TO\} \{THE\} \{NASA\} \{MARS\} \{EXPLORATION\} \{ROVER\} (MER) \{PROJECT\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "180 - 185",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00033",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346584",
author = "Samad Hayati and Arturo Rankin and Won Kim and Patrick Leger and Rebecca Castano and Khaled Ali",
keywords = "Rover",
keywords = "Autonomy",
keywords = "Autonomous Science",
keywords = "Mars",
keywords = "Space Robotics",
keywords = "Instrument placement",
keywords = "Planetary Rovers ",
abstract = "Abstract This paper presents four new technology developments and their infusion into the Mars Exploration Rover (MER) mission. These technologies were not ready for infusion prior to the launch of this mission. Three of these new capabilities are designed to increase the level of autonomy for the operations, i.e., fewer ground-in-the-loop steps for executing commands. One of the new capabilities is designed to intelligently filter rover obtained images and return only those that are very likely to contain useful information. These new capabilities will be used for this and future \{NASA\} planetary missions. "
}
@article{Choe20141130,
title = "Online urban object recognition in point clouds using consecutive point information for urban robotic missions ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1130 - 1152",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000815",
author = "Yungeun Choe and Seunguk Ahn and Myung Jin Chung",
keywords = "Urban object recognition",
keywords = "Online",
keywords = "Generative model",
keywords = "LIDAR",
keywords = "Point cloud",
keywords = "Urban environment ",
abstract = "Abstract Urban object recognition is the ability to categorize ambient objects into several classes and it plays an important role in various urban robotic missions, such as surveillance, rescue, and SLAM. However, there were several difficulties when previous studies on urban object recognition in point clouds were adopted for robotic missions: offline-batch processing, deterministic results in classification, and necessity of many training examples. The aim of this paper is to propose an urban object recognition algorithm for urban robotic missions with useful properties: online processing, classification results with probabilistic outputs, and training with a few examples based on a generative model. To achieve this, the proposed algorithm utilizes the consecutive point information (CPI) of a 2D \{LIDAR\} sensor. This additional information was useful for designing an online algorithm consisting of segmentation and classification. Experimental results show that the proposed algorithm using \{CPI\} enhances the applicability of urban object recognition for various urban robotic missions. "
}
@article{Stoyanov20131094,
title = "Comparative evaluation of range sensor accuracy for indoor mobile robotics and automated logistics applications ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1094 - 1105",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001431",
author = "Todor Stoyanov and Rasoul Mojtahedzadeh and Henrik Andreasson and Achim J. Lilienthal",
keywords = "Range sensing",
keywords = "Comparative evaluation",
keywords = "Automated logistics ",
abstract = "3D range sensing is an important topic in robotics, as it is a component in vital autonomous subsystems such as for collision avoidance, mapping and perception. The development of affordable, high frame rate and precise 3D range sensors is thus of considerable interest. Recent advances in sensing technology have produced several novel sensors that attempt to meet these requirements. This work is concerned with the development of a holistic method for accuracy evaluation of the measurements produced by such devices. A method for comparison of range sensor output to a set of reference distance measurements, without using a precise ground truth environment model, is proposed. This article presents an extensive evaluation of three novel depth sensors — the Swiss Ranger SR-4000, Fotonic \{B70\} and Microsoft Kinect. Tests are concentrated on the automated logistics scenario of container unloading. Six different setups of box-, cylinder-, and sack-shaped goods inside a mock-up container are used to collect range measurements. Comparisons are performed against hand-crafted ground truth data, as well as against a reference actuated Laser Range Finder (aLRF) system. Additional test cases in an uncontrolled indoor environment are performed in order to evaluate the sensors’ performance in a challenging, realistic application scenario. "
}
@article{Chen2017133,
title = "Development of a cloud-based factory simulation system for enabling ubiquitous factory simulation ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "133 - 143",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300084",
author = "Toly Chen and Min-Chi Chiu",
keywords = "Cloud manufacturing",
keywords = "Factory simulation",
keywords = "Cloud-based simulation",
keywords = "Ubiquitous manufacturing ",
abstract = "Abstract This study investigated several problems related to the implementation of cloud-based factory simulation. First, the differences between cloud-based factory simulation and parallel and distributed factory simulation were discussed. Individually managed, resource heterogeneity, uneven load partitioning, and potential business opportunities were found to be the novel characteristics that discriminate cloud-based factory simulation from parallel and distributed factory simulation. The problems in existing cloud-based factory simulation systems are discussed. An experimental cloud-based factory simulation system was developed and used for simulating a mobile lift table factory. "
}
@article{Jiang201621,
title = "Enhanced control of a wheelchair-mounted robotic manipulator using 3-D vision and multimodal interaction ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "21 - 31",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - 'Assistive Solutions for Mobility, Communication and HMI' ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.015",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300066",
author = "Hairong Jiang and Ting Zhang and Juan P. Wachs and Bradley S. Duerstock",
keywords = "3D vision",
keywords = "Multi-modal interface",
keywords = "Wheelchair mounted robotic manipulator",
keywords = "Assistive robotics ",
abstract = "Abstract This paper presents a multiple-sensors, 3D vision-based, autonomous wheelchair-mounted robotic manipulator (WMRM). Two 3D sensors were employed: one for object recognition, and the other for recognizing body parts (face and hands). The goal is to recognize everyday items and automatically interact with them in an assistive fashion. For example, when a cereal box is recognized, it is grasped, poured in a bowl, and brought to the user. Daily objects (i.e. bowl and hat) were automatically detected and classified using a three-steps procedure: (1) remove background based on 3D information and find the point cloud of each object; (2) extract feature vectors for each segmented object from its 3D point cloud and its color image; and (3) classify feature vectors as objects after applying a nonlinear support vector machine (SVM). To retrieve specific objects, three user interface methods were adopted: voice-based, gesture-based, and hybrid commands. The presented system was tested using two common activities of daily living -- feeding and dressing. The results revealed that an accuracy of 98.96% is achieved for a dataset with twelve daily objects. The experimental results indicated that hybrid (gesture and speech) interaction outperforms any single modal interaction. "
}
@article{Cocias2013960,
title = "Generic fitted shapes (GFS): Volumetric object segmentation in service robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "9",
pages = "960 - 972",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.020",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000845",
author = "Tiberiu T. Cocias and Florin Moldoveanu and Sorin M. Grigorescu",
keywords = "Active contours",
keywords = "3D segmentation",
keywords = "3D reconstruction",
keywords = "Robot vision systems",
keywords = "RGB-D sensors ",
abstract = "Abstract In this paper, a simultaneous 3D volumetric segmentation and reconstruction method, based on the so-called Generic Fitted Shapes (GFS) is proposed. The aim of this work is to cope with the lack of volumetric information encountered in visually controlled mobile manipulation systems equipped with stereo or RGB-D cameras. Instead of using primitive volumes, such as cuboids or cylinders, for approximating objects in point clouds, their volumetric structure has been estimated based on fitted generic shapes. The proposed \{GFSs\} can capture the shapes of a broad range of object classes without the need of large a-priori shape databases. The fitting algorithm, which aims at determining the particular geometry of each object of interest, is based on a modified version of the active contours approach extended to the 3D Cartesian space. The proposed volumetric segmentation system produces comprehensive closed object surfaces which can be further used in mobile manipulation scenarios. Within the experimental setup, the proposed technique has been evaluated against two state-of-the-art methods, namely superquadrics and 3D Object Retrieval (3DOR) engines. "
}
@article{Toffetti2017165,
title = "Self-managing cloud-native applications: Design, implementation, and experience ",
journal = "Future Generation Computer Systems ",
volume = "72",
number = "",
pages = "165 - 179",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302977",
author = "Giovanni Toffetti and Sandro Brunner and Martin Blochlinger and Josef Spillner and Thomas Michael Bohnert",
keywords = "Micro services",
keywords = "Cloud-native applications",
keywords = "Container-based applications",
keywords = "Distributed systems",
keywords = "Auto-scaling",
keywords = "Health-management ",
abstract = "Abstract Running applications in the cloud efficiently requires much more than deploying software in virtual machines. Cloud applications have to be continuously managed: (1) to adjust their resources to the incoming load and (2) to face transient failures replicating and restarting components to provide resiliency on unreliable infrastructure. Continuous management monitors application and infrastructural metrics to provide automated and responsive reactions to failures (health management) and changing environmental conditions (auto-scaling) minimizing human intervention. In the current practice, management functionalities are provided as infrastructural or third party services. In both cases they are external to the application deployment. We claim that this approach has intrinsic limits, namely that separating management functionalities from the application prevents them from naturally scaling with the application and requires additional management code and human intervention. Moreover, using infrastructure provider services for management functionalities results in vendor lock-in effectively preventing cloud applications to adapt and run on the most effective cloud for the job. In this paper we discuss the main characteristics of cloud native applications, propose a novel architecture that enables scalable and resilient self-managing applications in the cloud, and relate on our experience in porting a legacy application to the cloud applying cloud-native principles. "
}
@article{Serafin201791,
title = "Using extended measurements and scene merging for efficient and robust point cloud registration ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "91 - 106",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302712",
author = "Jacopo Serafin and Giorgio Grisetti",
keywords = "Pose tracking",
keywords = "Point cloud registration",
keywords = "Iterative closest point (ICP) ",
abstract = "Abstract Point cloud registration is a fundamental building block of many robotic applications. In this paper we describe a system to solve the registration problem, that builds on top of our previous work (Serafin and Grisetti (2015)), and that represents an extension to the well known Iterative Closest Point (ICP) algorithm. Our approach combines recent achievements on optimization by using an extended point representation (Serafin and Grisetti (2014)) that captures the surface characteristics around the points. Thanks to an effective strategy to search for correspondences, our method can operate on-line and cope with measurements gathered with an heterogeneous set of range and depth sensors. By using an efficient map-merging procedure our approach can quickly update the tracked scene and handle dynamic aspects. We also introduce an approximated variant of our method that runs at twice the speed of our full implementation. Experiments performed on a large publicly available benchmarking dataset show that our approach performs better with respect to other state-of-the art methods. In most of the tests considered, our algorithm has been able to obtain a translational and rotational relative error of respectively ∼ 1 cm and ∼ 1 ° . "
}
@article{Liu20173,
title = "Workload-based multi-task scheduling in cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "3 - 20",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516303210",
author = "Yongkui Liu and Xun Xu and Lin Zhang and Long Wang and Ray Y. Zhong",
keywords = "Cloud manufacturing",
keywords = "Multi-task scheduling",
keywords = "Task workload ",
abstract = "Abstract Cloud manufacturing is an emerging service-oriented business model that integrates distributed manufacturing resources, transforms them into manufacturing services, and manages the services centrally. Cloud manufacturing allows multiple users to request services at the same time by submitting their requirement tasks to a cloud manufacturing platform. The centralized management and operation of manufacturing services enable cloud manufacturing to deal with multiple manufacturing tasks in parallel. An important issue with cloud manufacturing is therefore how to optimally schedule multiple manufacturing tasks to achieve better performance of a cloud manufacturing system. Task workload provides an important basis for task scheduling in cloud manufacturing. Based on this idea, we present a cloud manufacturing multi-task scheduling model that incorporates task workload modelling and a number of other essential ingredients regarding services such as service efficiency coefficient and service quantity. Then we investigate the effects of different workload-based task scheduling methods on system performance such as total completion time and service utilization. Scenarios with or without time constraints are separately investigated in detail. Results from simulation experiments indicate that scheduling larger workload tasks with a higher priority can shorten the makespan and increase service utilization without decreasing task fulfilment quality when there is no time constraint. When time constraint is involved, the above strategy enables more tasks to be successfully fulfilled within the time constraint, and task fulfilment quality also does not deteriorate. "
}
@article{Hao2017168,
title = "The role of wearable devices in meeting the needs of cloud manufacturing: A case study ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "168 - 179",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515001131",
author = "Yuqiuge Hao and Petri Helo",
keywords = "Cloud manufacturing",
keywords = "Internet of users",
keywords = "Value co-creation",
keywords = "Wearable technology",
keywords = "Augmented reality ",
abstract = "Abstract Cloud manufacturing is a service-oriented, customer-centric and demand-driven process with well-established industrial automation. Even though, it does not necessarily mean the absence of human beings. Due to products and their corresponding manufacturing processes becoming increasingly complex, operators' daily working lives are also becoming more difficult. Enhanced human–machine interaction is one of the core areas for the success of the next generation of manufacturing. However, the current research only focuses on the automation and flexibility features of cloud manufacturing, the interaction between human and machine and the value co-creation among operators is missing. Therefore, a new method is needed for operators to support their work, with the objective of reducing the time and cost of machine control and maintenance. This paper describes a practical demonstration that uses the technologies of the Internet of things (IoT), wearable technologies, augmented reality, and cloud storage to support operators' activities and communication in discrete factories. This case study exhibits the capabilities and user experience of smart glasses in a cloud manufacturing environment, and shows that smart glasses help users stay productive and engaged. "
}
@article{Remetean2016161,
title = "Philae locating and science support by robotic vision techniques ",
journal = "Acta Astronautica ",
volume = "125",
number = "",
pages = "161 - 173",
year = "2016",
note = "Rosetta and Philae at comet 67P/Churyumov-Gerasimenko ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515004397",
author = "E. Remetean and B. Dolives and F. Souvannavong and T. Germa and JB. Ginestet and A. Torres and T. Mousset",
keywords = "Philae;",
keywords = "Robotics;",
keywords = "Vision ",
abstract = "Abstract The ROLIS, CIVA-P and \{OSIRIS\} instruments on-board the Philae lander and the Rosetta orbiter acquired high-resolution images during the lander׳s descent towards the targeted landing site Agilkia, during its unexpected rebounds and at the final landing site Abydos on comet 67P/Churyumov–Gerasimenko. We, exploited these images, using robotic vision techniques, to locate the first touchdown on the surface of the comet nucleus, to reconstruct the lander׳s 3D trajectory during the descent and at the beginning of the first rebound, and to create local digital terrain models and depth maps of Agilkia and Abydos sites. Using the \{ROLIS\} close-up images we could also determine the actual movements of the lander between the beginning and the end of the First Science Sequence and we propose a new lander׳s bubble movement command meant to increase the probability for a successful drilling during a hypothetical future Long Term Science phase. "
}
@article{Jimenez2017107,
title = "Visual grasp point localization, classification and state recognition in robotic manipulation of cloth: An overview ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "107 - 125",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016303517",
author = "P. Jimenez",
keywords = "Deformable object manipulation",
keywords = "Robotic vision",
keywords = "Clothing",
keywords = "Cloth state recognition",
keywords = "Garment classification",
keywords = "Grasp point localization ",
abstract = "Abstract Cloth manipulation by robots is gaining popularity among researchers because of its relevance, mainly (but not only) in domestic and assistive robotics. The required science and technologies begin to be ripe for the challenges posed by the manipulation of soft materials, and many contributions have appeared in the last years. This survey provides a systematic review of existing techniques for the basic perceptual tasks of grasp point localization, state estimation and classification of cloth items, from the perspective of their manipulation by robots. This choice is grounded on the fact that any manipulative action requires to instruct the robot where to grasp, and most garment handling activities depend on the correct recognition of the type to which the particular cloth item belongs and its state. The high inter- and intraclass variability of garments, the continuous nature of the possible deformations of cloth and the evident difficulties in predicting their localization and extension on the garment piece are challenges that have encouraged the researchers to provide a plethora of methods to confront such problems, with some promising results. The present review constitutes for the first time an effort in furnishing a structured framework of these works, with the aim of helping future contributors to gain both insight and perspective on the subject. "
}
@article{Zheng201773,
title = "A system framework for \{OKP\} product planning in a cloud-based design environment ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "73 - 85",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301132",
author = "Pai Zheng and Yuqian Lu and Xun Xu and Sheng Quan Xie",
keywords = "One-of-a-kind production",
keywords = "Product planning",
keywords = "Cloud-based design",
keywords = "Cloud manufacturing",
keywords = "Mass customisation ",
abstract = "Abstract Nowadays, one-of-a-kind (OKP) companies, which generally operate in an 'engineer-to-order' business mode, strive to deliver individualized products with quality to achieve customer satisfaction. Thus, an accurate and prompt analysis of customer requirements (CRs) in the early design stage is critical to its success. However, most \{OKP\} companies are small or medium-sized enterprises (SMEs). Due to the limited resources and low product planning budget, they often cannot obtain abundant \{CR\} information nor can they afford the expense of complicated planning process. To address these issues, a system framework is proposed in support of \{OKP\} product planning process in a cloud-based design (CBD) environment. The challenges and future market niches of \{OKP\} companies are presented. The comparison of typical distributed systems shows that CBD, which utilizes advanced information technologies and business model, has advantages in providing sufficient resources, decreasing product development time span for \{OKP\} companies in a cost-efficient way. This article describes the proposed system architecture, the business interaction process and the information communication among customers, designers and marketing analysts at the product planning stage. To validate the proposed framework, a prototype system module MyProduct is under development in the \{CBD\} environment with an illustrative example. "
}
@article{Riazuelo2014401,
title = "C2TAM: A Cloud framework for cooperative tracking and mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "4",
pages = "401 - 413",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013002248",
author = "L. Riazuelo and Javier Civera and J.M.M. Montiel",
keywords = "SLAM",
keywords = "Visual SLAM",
keywords = "Cloud SLAM",
keywords = "Cloud Robotics",
keywords = "Cloud Computing ",
abstract = "Abstract The Simultaneous Localization And Mapping by an autonomous mobile robot–known by its acronym SLAM–is a computationally demanding process for medium and large-scale scenarios, in spite of the progress both in the algorithmic and hardware sides. As a consequence, a robot with \{SLAM\} capabilities has to be equipped with the latest computers whose weight and power consumption might limit its autonomy. This paper describes a visual \{SLAM\} system based on a distributed framework where the expensive map optimization and storage is allocated as a service in the Cloud, while a light camera tracking client runs on a local computer. The robot onboard computers are freed from most of the computation, the only extra requirement being an internet connection. The data flow from and to the Cloud is low enough to be supported by a standard wireless connection. The experimental section is focused on showing real-time performance for single-robot and cooperative \{SLAM\} using an \{RGBD\} camera. The system provides the interface to a map database where: (1) a map can be built and stored, (2) stored maps can be reused by other robots, (3) a robot can fuse its map online with a map already in the database, and (4) several robots can estimate individual maps and fuse them together if an overlap is detected. "
}
@article{Tao201734,
title = "SDMSim: A manufacturing service supply–demand matching simulator under cloud environment ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "34 - 46",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516302605",
author = "Fei Tao and Jiangfeng Cheng and Ying Cheng and Shixin Gu and Tianyu Zheng and Hao Yang",
keywords = "Manufacturing service",
keywords = "Supply–demand matching (SDM)",
keywords = "Service-oriented manufacturing (SoM)",
keywords = "Simulator",
keywords = "Hypernetwork",
keywords = "Cloud manufacturing ",
abstract = "Abstract Nowadays, with the introduction and application of new information technologies in manufacturing, various advanced manufacturing modes and national strategies have been put forward and paid more and more attention, such as Industry 4.0, Industrial Internet, Cyber-Physical System or Cyber Manufacturing, Made in China 2025, Internet Plus Manufacturing, Cloud Manufacturing, etc. For these modes and strategies, how to realize the effective and intelligent supply–demand matching (SDM) of various manufacturing resources and capabilities (MR&amp;C) in the form of service is one of the common issues and aims. In order to provide a uniformed research platform for related researchers both in academic and industry, the concept of manufacturing service \{SDM\} simulator (SDMSim) is proposed in this paper. A hypernetwork based architecture for the simulator is designed, as well as its seven key functions and subsystems, including manufacturing service management, manufacturing task management, manufacturing service \{SDM\} hypernetwork, manufacturing service \{SDM\} problem formulation and configuration, matching and scheduling algorithms/strategies selection and design, statistical analysis, and visualization. It illustrates that \{SDMSim\} has the potential to serve the users of manufacturing service provider, manufacturing service consumer, manufacturing service operator in the field of SoM, as well as the related researchers. "
}
@article{Smara201774,
title = "Acceptance Test for Fault Detection in Component-based Cloud Computing and Systems ",
journal = "Future Generation Computer Systems ",
volume = "70",
number = "",
pages = "74 - 93",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302151",
author = "Mounya Smara and Makhlouf Aliouat and Al-Sakib Khan Pathan and Zibouda Aliouat",
keywords = "Fault detection",
keywords = "Component-based Cloud Computing",
keywords = "Recovery blocks",
keywords = "Acceptance Test",
keywords = "BIP framework ",
abstract = "Abstract Fault Detection is considered as one of the main challenges in large-scale dynamic environments and thus, for maintaining the reliability requirements of Cloud and Mobile Cloud systems. Most of the popular existing techniques for fault detection applied on the Cloud Computing environment in general, are based on system-monitoring despite the extreme difficulty of keeping track of all machines with their huge number in Cloud systems. In this paper, we propose a Fault Detection framework for the Component-based Cloud Computing by using Recovery Blocks’ Acceptance Test. This framework aims to construct Fail-Silent Cloud modules which have the ability of Self-Fault detection. In this, the detection process of transient hardware faults, software faults, and response-time failures is performed locally on each computing machine in the Cloud system. Background of the research issue, our mechanism, thorough analysis, and appropriate case study are presented. The efficiency and practicality of the proposed framework are proved by Safety verification using the model-checker. "
}
@article{Li2017349,
title = "A \{GMM\} based uncertainty model for point clouds registration ",
journal = "Robotics and Autonomous Systems ",
volume = "91",
number = "",
pages = "349 - 362",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.021",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015303109",
author = "Qianshan Li and Rong Xiong and Teresa Vidal-Calleja",
keywords = "Point cloud registration",
keywords = "Point cloud uncertainty modeling ",
abstract = "Abstract The existing methods for the registration of point clouds acquired by laser scanners have some limitations. Firstly, as some samples of surface, a point cloud acquired by the laser scanner, which normally works in a spherical fashion, has very limited density when the surface is far away from the laser scanner and the density varies a lot at different ranges. Current registration methods cannot accurately model the surface uncertainty for such kind of point clouds of limited and large varying density. Secondly, when the point cloud is acquired while the platform is simultaneously moving, the estimation error of the platform motion makes the acquired point cloud distorted. To deal with these problems, in this paper, we propose an uncertainty model based on the Gaussian Mixture Model (GMM) to represent the point cloud. Specifically, we construct the \{GMM\} piece-wisely on the underlying surface of point cloud, which will accurately model the surface uncertainty. Also a hierarchical structure is employed to increase the robustness of the registration. Furthermore, by assigning each Gaussian component with a pose, a probabilistic graph can be constructed to tackle the problem of registration when the platform is moving while scanning. In this way the distorted point cloud, caused by the estimation error of the platform’s motion, can be corrected by performing graph optimization. Simulation and real world experimental results show that our method leads to better convergence than the state-of-the-art methods due to the accurate modeling of the surface uncertainty and the hierarchical structure, and it also enables us to correct the distorted point clouds. "
}
@article{Reina2016114,
title = "Ambient awareness for agricultural robotic vehicles ",
journal = "Biosystems Engineering ",
volume = "146",
number = "",
pages = "114 - 132",
year = "2016",
note = "Special Issue: Advances in Robotic Agriculture for Crops ",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2015.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015001889",
author = "Giulio Reina and Annalisa Milella and Raphaël Rouveure and Michael Nielsen and Rainer Worst and Morten R. Blas",
keywords = "Agricultural robotics",
keywords = "Intelligent vehicles",
keywords = "Safe driving in crop fields",
keywords = "Advanced perception systems",
keywords = "Ambient awareness ",
abstract = "In the last few years, robotic technology has been increasingly employed in agriculture to develop intelligent vehicles that can improve productivity and competitiveness. Accurate and robust environmental perception is a critical requirement to address unsolved issues including safe interaction with field workers and animals, obstacle detection in controlled traffic applications, crop row guidance, surveying for variable rate applications, and situation awareness, in general, towards increased process automation. Given the variety of conditions that may be encountered in the field, no single sensor exists that can guarantee reliable results in every scenario. The development of a multi-sensory perception system to increase the ambient awareness of an agricultural vehicle operating in crop fields is the objective of the Ambient Awareness for Autonomous Agricultural Vehicles (QUAD-AV) project. Different onboard sensor technologies, namely stereovision, LIDAR, radar, and thermography, are considered. Novel methods for their combination are proposed to automatically detect obstacles and discern traversable from non-traversable areas. Experimental results, obtained in agricultural contexts, are presented showing the effectiveness of the proposed methods. "
}
@article{Spinnewyn201714,
title = "Resilient application placement for geo-distributed cloud networks ",
journal = "Journal of Network and Computer Applications ",
volume = "85",
number = "",
pages = "14 - 31",
year = "2017",
note = "Intelligent Systems for Heterogeneous Networks ",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2016.12.015",
url = "http://www.sciencedirect.com/science/article/pii/S1084804516303149",
author = "Bart Spinnewyn and Ruben Mennes and Juan Felipe Botero and Steven Latre",
keywords = "Cloud computing",
keywords = "Quality of service",
keywords = "Application placement",
keywords = "Reliability ",
abstract = "Abstract The strong uptake of cloud computing has led to an important increase of mission-critical applications being placed on cloud environments. Those applications often require high levels of availability coupled with guarantees on a minimum level of throughput and a maximum level of response time. To achieve the lowest response time possible, clouds are more and more decentralized, leading to a heterogeneous network of micro clouds positioned on the edge of the network and possibly interconnected by best-effort links. This heterogeneous environment introduces important challenges for the management of these clouds as the heterogeneity results in an increased failure probability. In this paper, we address these challenges by providing a resilient placement of mission-critical applications on geo-distributed clouds. We present an exact solution to the problem, which is complemented by two heuristics: a near-optimal distributed genetic meta-heuristic and a scalable centralized heuristic based on subgraph isomorphism detection. A detailed performance evaluation shows that, with the newly proposed heuristic based on subgraph isomorphism detection, we can double the amount of applications satisfying availability requirements, in cloud environments comprising over 100 nodes, while keeping the time required to calculate the solution under 20 s. "
}
@article{Cura201739,
title = "A scalable and multi-purpose point cloud server (PCS) for easier and faster point cloud data management and processing ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "127",
number = "",
pages = "39 - 56",
year = "2017",
note = "Geospatial Week 2015 ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.06.012",
url = "http://www.sciencedirect.com/science/article/pii/S092427161630123X",
author = "Remi Cura and Julien Perret and Nicolas Paparoditis",
keywords = "RDBMS",
keywords = "Point cloud management",
keywords = "Point cloud generalisation",
keywords = "Patch",
keywords = "Meta-data",
keywords = "Point cloud server ",
abstract = "Abstract In addition to more traditional geographical data such as images (rasters) and vectors, point cloud data are becoming increasingly available. Such data are appreciated for their precision and true three-Dimensional (3D) nature. However, managing point clouds can be difficult due to scaling problems and specificities of this data type. Several methods exist but are usually fairly specialised and solve only one aspect of the management problem. In this work, we propose a comprehensive and efficient point cloud management system based on a database server that works on groups of points (patches) rather than individual points. This system is specifically designed to cover the basic needs of point cloud users: fast loading, compressed storage, powerful patch and point filtering, easy data access and exporting, and integrated processing. Moreover, the proposed system fully integrates metadata (like sensor position) and can conjointly use point clouds with other geospatial data, such as images, vectors, topology and other point clouds. Point cloud (parallel) processing can be done in-base with fast prototyping capabilities. Lastly, the system is built on open source technologies; therefore it can be easily extended and customised. We test the proposed system with several billion points obtained from Lidar (aerial and terrestrial) and stereo-vision. We demonstrate loading speeds in the ∼50 million pts/h per process range, transparent-for-user and greater than 2 to 4:1 compression ratio, patch filtering in the 0.1 to 1 s range, and output in the 0.1 million pts/s per process range, along with classical processing methods, such as object detection. "
}
@article{Liu2017,
title = "Cyber-physical manufacturing cloud: Architecture, virtualization, communication, and testbed ",
journal = "Journal of Manufacturing Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0278612517300432",
author = "Xiaoqing F. Liu and Md Rakib Shahriar and S.M. Nahian Al Sunny and Ming C. Leu and Liwen Hu",
keywords = "Cloud manufacturing",
keywords = "Cyber-physical systems",
keywords = "Service-oriented architecture",
keywords = "MTConnect ",
abstract = "Abstract Cyber-physical systems are integrations of computation, networking, and physical processes and they are increasingly finding applications in manufacturing. Cloud manufacturing integrates cloud computing and service-oriented technologies with manufacturing processes and provides manufacturing services in manufacturing clouds. A cyber physical system for manufacturing is not a manufacturing cloud if it does not use virtualization technique in cloud computing and service oriented architecture in service computing. On the other hand, a manufacturing cloud is not cyber physical system if it does not have components for direct interactions with machine tools and other physical devices. In this paper, a new paradigm of Cyber-Physical Manufacturing Cloud (CPMC) is introduced to bridge gaps among cloud computing, cyber physical systems, and manufacturing. A \{CPMC\} allows direct operations and monitoring of machine tools in a manufacturing cloud over the Internet. A scalable and service-oriented layered architecture of \{CPMC\} is developed. It allows publication and subscription of manufacturing web services and cross-platform applications in CPMC. A virtualization method of manufacturing resources in \{CPMC\} is presented. In addition, communication mechanisms between the layers of the \{CPMC\} using communication protocols such as MTConnect, TCP/IP, and \{REST\} are discussed. A \{CPMC\} testbed is developed and implemented based on the proposed architecture. The testbed is fully operational in two geographically distributed sites. The developed testbed is evaluated using several manufacturing scenarios. Its testing results demonstrate that it can monitor and execute manufacturing operations remotely over the Internet efficiently in a manufacturing cloud. "
}
@article{Jankovic20161715,
title = "\{GNC\} architecture for autonomous robotic capture of a non-cooperative target: Preliminary concept design ",
journal = "Advances in Space Research ",
volume = "57",
number = "8",
pages = "1715 - 1736",
year = "2016",
note = "Advances in Asteroid and Space Debris Science and Technology - Part 2 ",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2015.05.018",
url = "http://www.sciencedirect.com/science/article/pii/S0273117715003439",
author = "Marko Jankovic and Jan Paul and Frank Kirchner",
keywords = "GNC",
keywords = "Active debris removal",
keywords = "Space debris",
keywords = "Proximity operations",
keywords = "Space robotics ",
abstract = "Abstract Recent studies of the space debris population in low Earth orbit (LEO) have concluded that certain regions have already reached a critical density of objects. This will eventually lead to a cascading process called the Kessler syndrome. The time may have come to seriously consider active debris removal (ADR) missions as the only viable way of preserving the space environment for future generations. Among all objects in the current environment, the SL-8 (Kosmos 3M second stages) rocket bodies (R/Bs) are some of the most suitable targets for future robotic \{ADR\} missions. However, to date, an autonomous relative navigation to and capture of an non-cooperative target has never been performed. Therefore, there is a need for more advanced, autonomous and modular systems that can cope with uncontrolled, tumbling objects. The guidance, navigation and control (GNC) system is one of the most critical ones. The main objective of this paper is to present a preliminary concept of a modular \{GNC\} architecture that should enable a safe and fuel-efficient capture of a known but uncooperative target, such as Kosmos 3M R/B. In particular, the concept was developed having in mind the most critical part of an \{ADR\} mission, i.e. close range proximity operations, and state of the art algorithms in the field of autonomous rendezvous and docking. In the end, a brief description of the hardware in the loop (HIL) testing facility is made, foreseen for the practical evaluation of the developed architecture. "
}
@article{Razzaghzadeh201712,
title = "Probabilistic modeling to achieve load balancing in Expert Clouds ",
journal = "Ad Hoc Networks ",
volume = "59",
number = "",
pages = "12 - 23",
year = "2017",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S157087051730001X",
author = "Shiva Razzaghzadeh and Ahmad Habibizad Navin and Amir Masoud Rahmani and Mehdi Hosseinzadeh",
keywords = "Expert Cloud",
keywords = "Human resource",
keywords = "Cloud computing",
keywords = "Load balancing",
keywords = "Poisson distribution",
keywords = "Quality of service ",
abstract = "Abstract Expert Cloud as a new class of Cloud computing systems enables its users to request the skill, knowledge and expertise of people without any information of their location by employing Internet infrastructures and Cloud computing concepts. Effective load balancing in a heterogeneous distributed environment such as Cloud is important. Since the differences in the human resource (HRs) capabilities and the variety of users' requests causes that some \{HRs\} are overloaded and some others are idle. The task allocation to the \{HR\} based on the announced requirements by the user may cause the imbalanced load distribution among \{HRs\} as well. Hence resource management and scheduling are among the important cases to achieve load balancing. Using static and dynamic algorithms, the ant colony, and the method based on searching tree all are among the methods to achieve load balancing. This paper presents a new method in order to distribute the dynamic load based on distributed queues aware of service quality in the Cloud environment. In this method, we utilize the colorful ants as a ranking for making distinction among the \{HRs\} capabilities. In this paper, we perform the mapping among the tasks and \{HRs\} using allocating a label to each HR. We model the load balancing and mapping process based on Poisson and exponential distribution. This model allows us to allocate each task to the \{HR\} which is able to execute it with maximum power using the distributed queues aware of the service quality. Simulation results show that the expert Cloud can reduce the execution and tardiness time and improve \{HR\} utilization. The cost of using resources as an effective factor in load balancing is also observed. "
}
@article{Feng2015128,
title = "Vision guided autonomous robotic assembly and as-built scanning on unstructured construction sites ",
journal = "Automation in Construction ",
volume = "59",
number = "",
pages = "128 - 138",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S092658051500120X",
author = "Chen Feng and Yong Xiao and Aaron Willette and Wes McGee and Vineet R. Kamat",
keywords = "On-site construction robotics",
keywords = "Autonomous assembly",
keywords = "Pose estimation",
keywords = "As-built 3D modeling ",
abstract = "Abstract Unlike robotics in the manufacturing industry, on-site construction robotics has to consider and address two unique challenges: 1) the rugged, evolving, and unstructured environment of typical work sites; and 2) the reversed spatial relationship between the product and the manipulator, i.e., the manipulator has to travel to and localize itself at the work face, rather than a partially complete product arriving at an anchored manipulator. The presented research designed and implemented algorithms that address these challenges and enable autonomous robotic assembly of freeform modular structures on construction sites. Building on the authors' previous work in computer-vision-based pose estimation, the designed algorithms enable a mobile robotic manipulator to: 1) autonomously identify and grasp prismatic building components (e.g., bricks, blocks) that are typically non-unique and arbitrarily stored on-site; and 2) assemble these components into pre-designed modular structures. The algorithms use a single camera and a visual marker-based metrology to rapidly establish local reference frames and to detect staged building components. Based on the design of the structure being assembled, the algorithms automatically determine the assembly sequence. Furthermore, if a 3D camera is mounted on the manipulator, 3D point clouds can be readily captured and registered into a same reference frame through our marker-based metrology and the manipulator's internal encoders, either after construction to facilitate as-built Building Information Model (BIM) generation, or during construction to document details of the progress. Implemented using a 7-axis \{KUKA\} \{KR100\} robotic manipulator, the presented robotic system has successfully assembled various structures and created as-built 3D point cloud models autonomously, demonstrating the designed algorithms' effectiveness in autonomous on-site construction robotics applications. "
}
@article{Namitha2016209,
title = "Point Cloud Mapping Measurements Using Kinect RGB-D Sensor and Kinect Fusion for Visual Odometry ",
journal = "Procedia Computer Science ",
volume = "89",
number = "",
pages = "209 - 212",
year = "2016",
note = "Twelfth International Conference on Communication Networks, \{ICCN\} 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, \{ICDMW\} 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, \{ICISP\} 2016, August 19-21, 2016, Bangalore, India ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.06.044",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916311097",
author = "N. Namitha and S.M. Vaitheeswaran and V.K. Jayasree and M.K. Bharat",
keywords = "Kinect",
keywords = "Kinect Fusion",
keywords = "Odometry",
keywords = "Robotics",
keywords = "Vision. ",
abstract = "Abstract RGB-D camera like Kinect make available \{RGB\} Images along with per-pixel depth information in real time. This paper uses the Kinect Fusion developed by Microsoft Research for the 3D reconstruction of the scene in real time using the MicroKinect Camera and applies it as an aid for Visual Odometry of a Robotic Vehicle where no external reference like \{GPS\} is available. "
}
@article{Liu2017a,
title = "Comparison of 2D image models in segmentation performance for 3D laser point clouds ",
journal = "Neurocomputing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.04.030",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217307002",
author = "Yisha Liu and Fei Wang and Abdullah M. Dobaie and Guojian He and Yan Zhuang",
keywords = "3D scene segmentation",
keywords = "2D image model",
keywords = "Laser scanning",
keywords = "3D point clouds ",
abstract = "Abstract The selection of a suitable representing model for 3D laser point clouds plays a significant role in 3D outdoor scene understanding. In this paper, we compare the segmentation performance of four types of models which can transform 3D laser point clouds into 2D images. In these models, fast optimal bearing-angle (FOBA) image is a novel 2D image model, which provides a general way to project 3D laser point clouds into 2D images. A series of segmentation performance tests and data analysis for these models are conducted in four datasets, which are acquired with different laser scanning modes. According to the experimental results, we argue that 2D image models greatly reduce the time cost of scene segmentation with a little loss of accuracy. Moreover, the usage of 2D image models is not limited in scene segmentation since robust features can be extracted from 2D image models to accomplish laser point classification and scene understanding. "
}
@article{Mineo20161,
title = "Robotic path planning for non-destructive testing – A custom \{MATLAB\} toolbox approach ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "37",
number = "",
pages = "1 - 12",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.05.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000666",
author = "Carmelo Mineo and Stephen Gareth Pierce and Pascual Ian Nicholson and Ian Cooper",
keywords = "Robotics",
keywords = "Path-planning",
keywords = "Automated non-destructive inspections ",
abstract = "Abstract The requirement to increase inspection speeds for non-destructive testing (NDT) of composite aerospace parts is common to many manufacturers. The prevalence of complex curved surfaces in the industry provides motivation for the use of 6 axis robots in these inspections. The purpose of this paper is to present work undertaken for the development of a \{KUKA\} robot manipulator based automated \{NDT\} system. A new software solution is presented that enables flexible trajectory planning to be accomplished for the inspection of complex curved surfaces often encountered in engineering production. The techniques and issues associated with conventional manual inspection techniques and automated systems for the inspection of large complex surfaces were reviewed. This approach has directly influenced the development of a \{MATLAB\} toolbox targeted to \{NDT\} automation, capable of complex path planning, obstacle avoidance, and external synchronization between robots and associated external \{NDT\} systems. This paper highlights the advantages of this software over conventional off-line-programming approaches when applied to \{NDT\} measurements. An experimental validation of path trajectory generation, on a large and curved composite aerofoil component, is presented. Comparative metrology experiments were undertaken to evaluate the real path accuracy of the toolbox when inspecting a curved 0.5 m2 and a 1.6 m2 surface using a \{KUKA\} \{KR16\} L6-2 robot. The results have shown that the deviation of the distance between the commanded \{TCPs\} and the feedback positions were within 2.7 mm. The variance of the standoff between the probe and the scanned surfaces was smaller than the variance obtainable via commercial path-planning software. Tool paths were generated directly on the triangular mesh imported from the \{CAD\} models of the inspected components without need for an approximating analytical surface. By implementing full external control of the robotic hardware, it has been possible to synchronise the \{NDT\} data collection with positions at all points along the path, and our approach allows for the future development of additional functionality that is specific to \{NDT\} inspection problems. For the current \{NDT\} application, the deviations from \{CAD\} design and the requirements for both coarse and fine inspections, dependent on measured \{NDT\} data, demand flexibility in path planning beyond what is currently available from existing off-line robot programming software. "
}
@article{Mateo20131239,
title = "Scalable Adaptive Group Communication for Collaboration Framework of Cloud-enabled Robots ",
journal = "Procedia Computer Science ",
volume = "22",
number = "",
pages = "1239 - 1248",
year = "2013",
note = "17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - \{KES2013\} ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2013.09.211",
url = "http://www.sciencedirect.com/science/article/pii/S1877050913010041",
author = "Romeo Mark A. Mateo",
keywords = "Cloud computing",
keywords = "Cloud robotics",
keywords = "Group communications ",
abstract = "Abstract Recently, researchers have been exploring the idea of robots that rely on cloud-computing infrastructure to take advantage of processing power and access vast amounts of data. This approach allows a robot to delegate compute-intensive tasks like image recognition, graphical mapping systems and etc. However, the efficient information sharing of cloud-enabled robots is not addressed which is necessary in disseminating real time information. In this paper, a collaboration framework is presented which is designed for information sharing of cloud-enabled robots. Based on attributes, cloud-enabled robots form logical groups to perform information sharing through the Internet. To provide a faster way of disseminating messages, a scalable adaptive group communication (SAGC) is proposed. The logical groups are processed using fuzzy system to employ scalable grouping, and then, the logical links are adjusted by a node link weight function based on Brownian agent to direct the queries to robots with relevant information. The performance evaluation showed that the \{SAGC\} had the fastest response to queries compared to other group communication methods. "
}
@article{Montero201599,
title = "Past, present and future of robotic tunnel inspection ",
journal = "Automation in Construction ",
volume = "59",
number = "",
pages = "99 - 112",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515000229",
author = "R. Montero and J.G. Victores and S. Martinez and A. Jardon and C. Balaguer",
keywords = "Robotics",
keywords = "Automation",
keywords = "Inspection",
keywords = "Maintenance",
keywords = "Tunnels",
keywords = "IAARC ",
abstract = "Abstract Nowadays, the vast majority of the tunnel inspection processes are performed manually by qualified operators. The process is subjective and the operators need to face very uncomfortable and even dangerous conditions such as dust environments, absence of light, or toxic substance exposition. Robotic technology can overcome many of these disadvantages and provide quality inspections collecting different types of data. This paper presents the key aspects of tunnel inspection and a survey of the developed robotic tunnel inspection systems up to date. Additionally, two projects regarding automation of the processes involved and future trends will be discussed. "
}
@article{Dittrich2017195,
title = "Analytical and numerical investigations on the accuracy and robustness of geometric features extracted from 3D point cloud data ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "126",
number = "",
pages = "195 - 208",
year = "2017",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2017.02.012",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616305755",
author = "Andre Dittrich and Martin Weinmann and Stefan Hinz",
keywords = "3D",
keywords = "Point cloud",
keywords = "Feature extraction",
keywords = "Eigenvalues",
keywords = "Covariance features",
keywords = "Shape primitives",
keywords = "Variance propagation ",
abstract = "Abstract In photogrammetry, remote sensing, computer vision and robotics, a topic of major interest is represented by the automatic analysis of 3D point cloud data. This task often relies on the use of geometric features amongst which particularly the ones derived from the eigenvalues of the 3D structure tensor (e.g. the three dimensionality features of linearity, planarity and sphericity) have proven to be descriptive and are therefore commonly involved for classification tasks. Although these geometric features are meanwhile considered as standard, very little attention has been paid to their accuracy and robustness. In this paper, we hence focus on the influence of discretization and noise on the most commonly used geometric features. More specifically, we investigate the accuracy and robustness of the eigenvalues of the 3D structure tensor and also of the features derived from these eigenvalues. Thereby, we provide both analytical and numerical considerations which clearly reveal that certain features are more susceptible to discretization and noise whereas others are more robust. "
}
@article{Paraforos2017166,
title = "Total station data assessment using an industrial robotic arm for dynamic 3D in-field positioning with sub-centimetre accuracy ",
journal = "Computers and Electronics in Agriculture ",
volume = "136",
number = "",
pages = "166 - 175",
year = "2017",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2017.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916308468",
author = "Dimitris S. Paraforos and Marcus Reutemann and Galibjon Sharipov and Roland Werner and Hans W. Griepentrog",
keywords = "Total station",
keywords = "Robotic arm",
keywords = "3D positioning",
keywords = "Cross-track error",
keywords = "In-field accuracy ",
abstract = "Abstract For agricultural tasks related to precision farming, accurate in-field positioning is a necessity. The accuracy of some centimetres that the real time kinematic-global navigation satellite system (RTK-GNSS) can provide is adequate for many applications, such as auto-steering navigation and section control for spraying or fertiliser applications. Nevertheless, the demand for higher in-field accuracy at a mm level is increasing. A device that is gaining a lot of attention in the agricultural sector for its increased accuracy is a robotic total station (TS) that can track a prism mounted on a vehicle. With the aim to be able to use this device under realistic conditions for dynamic 3D in-field positioning at a sub-centimetre level, the accuracy of the \{TS\} was assessed utilising an industrial robotic arm. The robotic arm had a repeatability factor of ±0.1 mm and was placed outdoors under normal environmental conditions for agriculture practice. Straight \{AB\} lines but also U-turn and Pattern-8 experiments were performed. The absolute error of the robotic arm had a maximum mean value of 0.33 mm for the Pattern-8 experiment, while the highest error, equal to 1.30 mm, was detected in the 95th percentile of the same experiment. The horizontal and vertical relative cross-track error (XTE) between the \{TS\} and the robotic arm data was calculated for various speeds and for two different positions of the TS. From the results, it was evident that as the speed increased so did the horizontal relative XTE. Furthermore, changing the position of the \{TS\} from in line to perpendicular, in respect to the direction of motion, proved to result in a higher accuracy. The maximum mean horizontal relative \{XTE\} value of all experiments was 4.01 mm for Pattern-8, which also had the maximum value for the 95th percentile, i.e. 12.86 mm. The vertical relative \{XTE\} for all experiments did not exceed 10 mm including the outliers. "
}
@article{Dragone2015269,
title = "A cognitive robotic ecology approach to self-configuring and evolving \{AAL\} systems ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "45",
number = "",
pages = "269 - 280",
year = "2015",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2015.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0952197615001517",
author = "Mauro Dragone and Giuseppe Amato and Davide Bacciu and Stefano Chessa and Sonya Coleman and Maurizio Di Rocco and Claudio Gallicchio and Claudio Gennaro and Hector Lozano and Liam Maguire and Martin McGinnity and Alessio Micheli and Gregory M.P. O׳Hare and Arantxa Renteria and Alessandro Saffiotti and Claudio Vairo and Philip Vance",
keywords = "Robotic ecology",
keywords = "Ambient assisted living",
keywords = "Cognitive robotics",
keywords = "Machine learning",
keywords = "Planning ",
abstract = "Abstract Robotic ecologies are systems made out of several robotic devices, including mobile robots, wireless sensors and effectors embedded in everyday environments, where they cooperate to achieve complex tasks. This paper demonstrates how endowing robotic ecologies with information processing algorithms such as perception, learning, planning, and novelty detection can make these systems able to deliver modular, flexible, manageable and dependable Ambient Assisted Living (AAL) solutions. Specifically, we show how the integrated and self-organising cognitive solutions implemented within the \{EU\} project \{RUBICON\} (Robotic \{UBIquitous\} Cognitive Network) can reduce the need of costly pre-programming and maintenance of robotic ecologies. We illustrate how these solutions can be harnessed to (i) deliver a range of assistive services by coordinating the sensing &amp; acting capabilities of heterogeneous devices, (ii) adapt and tune the overall behaviour of the ecology to the preferences and behaviour of its inhabitants, and also (iii) deal with novel events, due to the occurrence of new user׳s activities and changing user׳s habits. "
}
@article{Srinivasan2011535,
title = "Visual control of navigation in insects and its relevance for robotics ",
journal = "Current Opinion in Neurobiology ",
volume = "21",
number = "4",
pages = "535 - 543",
year = "2011",
note = "Sensory and motor systems ",
issn = "0959-4388",
doi = "https://doi.org/10.1016/j.conb.2011.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0959438811000882",
author = "Mandyam V Srinivasan",
abstract = "Flying insects display remarkable agility, despite their diminutive eyes and brains. This review describes our growing understanding of how these creatures use visual information to stabilize flight, avoid collisions with objects, regulate flight speed, detect and intercept other flying insects such as mates or prey, navigate to a distant food source, and orchestrate flawless landings. It also outlines the ways in which these insights are now being used to develop novel, biologically inspired strategies for the guidance of autonomous, airborne vehicles. "
}
@article{JafarnejadGhomi2017,
title = "Load-balancing Algorithms in Cloud Computing: A Survey ",
journal = "Journal of Network and Computer Applications ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2017.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S1084804517301480",
author = "Einollah Jafarnejad Ghomi and Amir Masoud Rahmani and Nooruldeen Nasih Qader",
keywords = "Cloud Computing",
keywords = "Load Balancing",
keywords = "Task Scheduling",
keywords = "Hadoop MapReduce ",
abstract = "Abstract Cloud computing is a modern paradigm to provide services through the Internet. Load balancing is a key aspect of cloud computing and avoids the situation in which some nodes become overloaded while the others are idle or have little work to do. Load balancing can improve the Quality of Service (QoS) metrics, including response time, cost, throughput, performance and resource utilization. In this paper, we study the literature on the task scheduling and load-balancing algorithms and present a new classification of such algorithms, for example, Hadoop MapReduce load balancing category, Natural Phenomena-based load balancing category, Agent-based load balancing category, General load balancing category, application-oriented category, network-aware category, and workflow specific category. Furthermore, we provide a review in each of these seven categories. Also. We provide insights into the identification of open issues and guidelines for future research. "
}
@article{Hallawi20171,
title = "Multi-Capacity Combinatorial Ordering \{GA\} in Application to Cloud resources allocation and efficient virtual machines consolidation ",
journal = "Future Generation Computer Systems ",
volume = "69",
number = "",
pages = "1 - 10",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16304630",
author = "Huda Hallawi and Jorn Mehnen and Hongmei He",
keywords = "Cloud resources allocation",
keywords = "Cloud resources provisioning",
keywords = "Virtual machines consolidation",
keywords = "Vector bin packing",
keywords = "Genetic algorithm ",
abstract = "Abstract This paper describes a novel approach making use of genetic algorithms to find optimal solutions for multi-dimensional vector bin packing problems with the goal to improve cloud resource allocation and Virtual Machines (VMs) consolidation. Two algorithms, namely Combinatorial Ordering First-Fit Genetic Algorithm (COFFGA) and Combinatorial Ordering Next Fit Genetic Algorithm (CONFGA) have been developed for that and combined. The proposed hybrid algorithm targets to minimise the total number of running servers and resources wastage per server. The solutions obtained by the new algorithms are compared with latest solutions from literature. The results show that the proposed algorithm \{COFFGA\} outperforms other previous multi-dimension vector bin packing heuristics such as Permutation Pack (PP), First Fit (FF) and First Fit Decreasing (FFD) by 4%, 34%, and 39%, respectively. It also achieved better performance than the existing genetic algorithm for multi-capacity resources virtual machine consolidation (RGGA) in terms of performance and robustness. A thorough explanation for the improved performance of the newly proposed algorithm is given. "
}
@article{Hung2017174,
title = "Development of a novel cloud-based multi-tenant model creation service for automatic virtual metrology ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "44",
number = "",
pages = "174 - 189",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301077",
author = "Min-Hsiung Hung and Yu-Yung Li and Yu-Chuan Lin and Chun-Fan Wei and Haw-Ching Yang and Fan-Tien Cheng",
keywords = "Automatic virtual metrology (AVM)",
keywords = "Multi-tenant",
keywords = "Cloud-based model creation service",
keywords = "VM model",
keywords = "CNC machine tool",
keywords = "Machining of wheel rim ",
abstract = "Abstract \{AVM\} (Automatic Virtual Metrology) is the highest-level technology for \{VM\} (Virtual Metrology) applications from the perspective of automation. Its various automatic capabilities could facilitate fast factory-wide deployment and operations of \{VM\} systems. \{AVM\} systems have been successfully applied to the semiconductor, TFT-LCD, solar-cell, and machining industries for on-line monitoring the production quality of workpieces. However, in its past industrial applications, the model creation (MC) functionality of the existing \{AVM\} system encountered several limitations, such as being a standalone application and confined to be used in situ in a factory, no support for multiuser model creation, wasting computing resources, etc., which could diminish the applicability of the existing \{AVM\} system in current global and distributed manufacturing environments. Thus, this paper is dedicated to tackling the problem of how to systematically and effectively overcome MC-related limitations of the existing \{AVM\} system so that it can robustly support multiple users across factories to create their \{VM\} models simultaneously in distributed manufacturing settings. By leveraging the advantages of cloud computing and several \{IT\} technologies (including virtualization software, XML, Web Service, Multi-tenancy technique, and HTML5), this paper proposes a novel cloud-based multi-tenant model creation service (i.e., CMMCS) for AVM. The proposed \{CMMCS\} contains a cloud-based system architecture, functional frameworks of its key components, several functional mechanisms, and HTML5-based Web GUIs. Testing results in an industrial case study that creates \{VM\} models using the \{CMMCS\} for \{CNC\} machine tools in machining wheel rims of automobiles in a factory in Taiwan demonstrate that the \{CMMCS\} can allow multiple users from different tenants to simultaneously create their \{VM\} models, while enabling the \{MC\} cloud services to be more robust for processing \{MC\} requests, having higher CPU-usage rates in the underlying virtual machines, and achieving better cross-platform usage, compared to the original \{MC\} functionality. This paper has provided a feasible solution to systematically and effectively remedying the MC-related limitations of the existing \{AVM\} system. The existing VM-related literature mainly focused on the development of \{VM\} models. To our knowledge, no papers have coped with issues addressed in this paper by leveraging cloud computing. The results of this paper can be a useful reference for industrial practitioners to construct \{AVM\} systems which support multi-tenant or multiuser model creation. "
}
@article{Goncalves201590,
title = "Knowledge representation applied to robotic orthopedic surgery ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "90 - 99",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.014",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000751",
author = "Paulo J.S. Goncalves and Pedro M.B. Torres",
keywords = "Knowledge representation",
keywords = "Ontologies",
keywords = "Robotics",
keywords = "Orthopedic surgery ",
abstract = "Abstract In this paper the efforts and methods used in the past years are presented to represent knowledge in the biomedical field and to obtain a conceptual model of the Ontology for Robotic Orthopedic Surgery (OROSU). This model is proposed in this paper to represent the knowledge to be used, in a machine readable format, during surgeries. Since ontologies in the biomedical filed are relatively mature and have been widely used, this is a perfect field to show the interest of using ontologies to represent robotic knowledge and its use, directly with humans (surgeons, nurses, technicians, and so on). From the biomedical ontologies that already exist, the conceptual model of \{OROSU\} is defined. The base ontologies were merged by the authors to obtain the \{OROSU\} ontology, and applied to Hip Surgery surgical procedures. It was then implemented using the KnowRob framework. Results on tasks definitions and reasoning using the presented ontology showed its usability, for Hip Surgery surgical procedures. "
}
@article{Bore2017139,
title = "Efficient retrieval of arbitrary objects from long-term robot observations ",
journal = "Robotics and Autonomous Systems ",
volume = "91",
number = "",
pages = "139 - 150",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016308466",
author = "Nils Bore and Rares Ambrus and Patric Jensfelt and John Folkesson",
keywords = "Mapping",
keywords = "Mobile robotics",
keywords = "Point cloud",
keywords = "Segmentation",
keywords = "Retrieval ",
abstract = "Abstract We present a novel method for efficient querying and retrieval of arbitrarily shaped objects from large amounts of unstructured 3D point cloud data. Our approach first performs a convex segmentation of the data after which local features are extracted and stored in a feature dictionary. We show that the representation allows efficient and reliable querying of the data. To handle arbitrarily shaped objects, we propose a scheme which allows incremental matching of segments based on similarity to the query object. Further, we adjust the feature metric based on the quality of the query results to improve results in a second round of querying. We perform extensive qualitative and quantitative experiments on two datasets for both segmentation and retrieval, validating the results using ground truth data. Comparison with other state of the art methods further enforces the validity of the proposed method. Finally, we also investigate how the density and distribution of the local features within the point clouds influence the quality of the results. "
}
@article{Weiss2009982,
title = "Adaptive supervision of moving objects for mobile robotics applications ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "10",
pages = "982 - 995",
year = "2009",
note = "5th International Conference on Computational Intelligence, Robotics and Autonomous Systems (5th CIRAS) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001043",
author = "Norman Weiss",
keywords = "Adaptive computer vision",
keywords = "Image understanding",
keywords = "Autonomous mobile robots",
keywords = "Robot soccer ",
abstract = "One of the main tasks of mobile robotics is vision. Lighting independence, adaptivity and automated learning are still the main issues when it comes to applications. In this article, we present an image understanding system and its methods targeting automatic, lighting-independent and reliable color-based object recognition under real time conditions. Its application test bed is global vision robot soccer (i.e. FIRA MiroSot und RoboCup Small Size leagues) but it has many other applications in color-based supervision of moving objects. Under typical conditions, it learns the objects of recognition automatically, has zero setup time and tolerates environmental changes during run-time. "
}
@article{Smith201710,
title = "Cloud cover effect of clear-sky index distributions and differences between human and automatic cloud observations ",
journal = "Solar Energy ",
volume = "144",
number = "",
pages = "10 - 21",
year = "2017",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2016.12.055",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X16306624",
author = "Christopher J. Smith and Jamie M. Bright and Rolf Crook",
keywords = "Clouds",
keywords = "Clear-sky index",
keywords = "Statistics",
keywords = "Ceilometer ",
abstract = "Abstract The statistics of clear-sky index can be used to determine solar irradiance when the theoretical clear sky irradiance and the cloud cover are known. In this paper, observations of hourly clear-sky index for the years of 2010–2013 at 63 locations in the \{UK\} are analysed for over 1 million data hours. The aggregated distribution of clear-sky index is bimodal, with strong contributions from mostly-cloudy and mostly-clear hours, as well as a lower number of intermediate hours. The clear-sky index exhibits a distribution of values for each cloud cover bin, measured in eighths of the sky covered (oktas), and also depends on solar elevation angle. Cloud cover is measured either by a human observer or automatically with a cloud ceilometer. Irradiation (time-integrated irradiance) values corresponding to human observations of “cloudless” skies (0 oktas) tend to agree better with theoretical clear-sky values, which are calculated with a radiative transfer model, than irradiation values corresponding to automated observations of 0 oktas. It is apparent that the cloud ceilometers incorrectly categorise more non-cloudless hours as cloudless than human observers do. This leads to notable differences in the distributions of clear-sky index for each okta class, and between human and automated observations. Two probability density functions—the Burr (type III) for mostly-clear situations, and generalised gamma for mostly-cloudy situations—are suggested as analytical fits for each cloud coverage, observation type, and solar elevation angle bin. For human observations of overcast skies (8 oktas) where solar elevation angle exceeds 10°, there is no significant difference between the observed clear-sky indices and the generalised gamma distribution fits. "
}
@article{GhobaeiArani2017,
title = "An autonomic resource provisioning approach for service-based cloud applications: A hybrid approach ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.022",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302327",
author = "Mostafa Ghobaei-Arani and Sam Jabbehdari and Mohammad Ali Pourmina",
keywords = "Cloud computing",
keywords = "Cloud services",
keywords = "Resource provisioning",
keywords = "Autonomic computing",
keywords = "Reinforcement learning ",
abstract = "Abstract In cloud computing environment, resources can be dynamically provisioned on deman for cloud services The amount of the resources to be provisioned is determined during runtime according to the workload changes. Deciding the right amount of resources required to run the cloud services is not trivial, and it depends on the current workload of the cloud services. Therefore, it is necessary to predict the future demands to automatically provision resources in order to deal with fluctuating demands of the cloud services. In this paper, we propose a hybrid resource provisioning approach for cloud services that is based on a combination of the concept of the autonomic computing and the reinforcement learning (RL). Also, we present a framework for autonomic resource provisioning which is inspired by the cloud layer model. Finally, we evaluate the effectiveness of our approach under two real world workload traces. The experimental results show that the proposed approach reduces the total cost by up to 50%, and increases the resource utilization by up to 12% compared with the other approaches. "
}
@article{Fylaktopoulos2017,
title = "A distributed modular platform for the development of cloud based applications ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.035",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302716",
author = "G. Fylaktopoulos and M. Skolarikis and I. Papadopoulos and G. Goumas and A. Sotiropoulos and I. Maglogiannis",
keywords = "Cloud based development",
keywords = "Model Driven Development",
keywords = "Cloud Integrated Development Environment ",
abstract = "Abstract In this paper we describe the \{CIRANO\} platform, a modular Integrated Development Environment (IDE) for cloud based applications. The proposed platform is built to support Model Driven Development (MDD) and team collaboration, facilitating the rapid development of advanced applications in the cloud. The paper presents at a first stage the state of the art in the field of cloud \{IDEs\} and describes the design, implementation and technical details of the \{CIRANO\} platform. The main features of the proposed platform are presented in two case studies concerning the development of an application from scratch and porting of an existing application. The paper discusses the findings in comparison with existing tools and proposes extensions of the platform as future work. "
}
@article{Li2017192,
title = "Multi-year ground-based observations of aerosol-cloud interactions in the Mid-Atlantic of the United States ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "188",
number = "",
pages = "192 - 199",
year = "2017",
note = "Advances in Atmospheric Light Scattering: Theory and Remote Sensing Techniques ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315303198",
author = "Siwei Li and Everette Joseph and Qilong Min and Bangsheng Yin",
keywords = "Aerosols",
keywords = "Aerosol-cloud interaction",
keywords = "Cloud droplet effective radius",
keywords = "Cloud optical depth",
keywords = "Fine particles ",
abstract = "Abstract The U.S. Mid-Atlantic region experiences a wide variability of aerosol loading and frequent episodes of elevated anthropogenic aerosol loading associated with urban pollution conditions during summer months. In this study, multi-year ground-based observations (2006 to 2010) of aerosol and cloud properties from passive, active and in situ measurements at an atmospheric measurement field station in the Baltimore–Washington corridor operated by Howard University were analyzed to examine aerosol indirect effect on single-layer warm clouds including cloud optical depth (COD), liquid water path (LWP), cloud droplet effective radius (Re) and cloud droplet number concentration (Nd) in this region. A greater occurrence of polluted episodes and cloud cases with smaller Re (&lt;7 µm) were found during the polluted year summers (2006, 2007 and 2008) than the clean year summers (2009 and 2010). The measurements of aerosol particulate matter with aerodynamic diameter≤2.5 µm (PM2.5) were used to represent the aerosol loading under cloudy conditions. Significant negative relationships between cloud droplet Re and PM2.5 were observed. Cloud cases were separated into clean and polluted groups based on the value of PM2.5. The cloud droplet Re was found proportional to \{LWP\} under clean conditions but weakly dependent on \{LWP\} under polluted conditions. The Nd was proportional to \{LWP\} under polluted condition but weakly dependent on \{LWP\} under clean conditions. Moreover, the effects of increasing fine aerosol particles on modifying cloud microphysical properties were found more significant under large \{LWP\} than small \{LWP\} in this region. "
}
@article{Yang201756,
title = "Cognitive-affective regulation process for micro-expressions based on Gaussian cloud distribution ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "2",
number = "1",
pages = "56 - 61",
year = "2017",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2016.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S246823221630107X",
author = "Xiujun Yang and Lun Xie and Jing Han and Zhiliang Wang",
keywords = "Micro-expression",
keywords = "Cognitive-affective regulation",
keywords = "Gaussian cloud distribution",
keywords = "Transferring probability",
keywords = "Emotional intensity ",
abstract = "Abstract In this paper, we explore the process of emotional state transition. And the process is impacted by emotional state of interaction objects. First of all, the cognitive reasoning process and the micro-expressions recognition is the basis of affective computing adjustment process. Secondly, the threshold function and attenuation function are proposed to quantify the emotional changes. In the actual environment, the emotional state of the robot and external stimulus are also quantified as the transferring probability. Finally, the Gaussian cloud distribution is introduced to the Gross model to calculate the emotional transitional probabilities. The experimental results show that the model in human–computer interaction can effectively regulate the emotional states, and can significantly improve the humanoid and intelligent ability of the robot. This model is consistent with experimental and emulational significance of the psychology, and allows the robot to get rid of the mechanical emotional transfer process. "
}
@article{MarcondosSantos2016192,
title = "Fast algorithm for real-time ground extraction from unorganized stereo point clouds ",
journal = "Pattern Recognition Letters ",
volume = "84",
number = "",
pages = "192 - 198",
year = "2016",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2016.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167865516302677",
author = "Gilberto Antonio Marcon dos Santos and Victor Terra Ferrao and Cassio Dener Noronha Vinhal and Gelson da Cruz Junior",
keywords = "Ground extraction",
keywords = "Stereo point clouds",
keywords = "Multilayer perceptron ",
abstract = "Abstract This paper presents a fast, robust algorithm for ground extraction from unstructured point clouds obtained from stereo reconstruction. Unlike most point cloud segmentation approaches, our algorithm does not rely on 2.5D range image structures nor on any sensor information. All processes involved consider geometry only and do not depend on any reflectivity or color information. We propose applying a top-down 4-ary segmentation followed by a segment-wise classification. This adaptive approach allows accurate differentiation between ground and obstacles in noisy point clouds of cluttered scenes. Real-time performance is achieved on a low cost embedded platform. "
}
@article{Lee2009968,
title = "Visibility-based modelling and control for network-based robotics ",
journal = "Pattern Recognition Letters ",
volume = "30",
number = "11",
pages = "968 - 976",
year = "2009",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2009.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167865509000750",
author = "Sang Il Lee and Byoung In Cho and Jae-Kyu Lee and Seongjin Ahn and Jin Wook Chung",
keywords = "Line-based recognition",
keywords = "Plane sweep",
keywords = "Real plane",
keywords = "Visibility test ",
abstract = "We present an algorithm to model 3D workspace and to understand test scene for navigation or human computer interaction in network-based mobile robot. This was done by line-based modelling and recognition algorithm. Line-based recognition using 3D lines has been tried by many researchers however its reliability still needs improvement due to ambiguity of 3D line feature information from original images. To improve the outcome, we approach firstly to find real planes using the given 3D lines and then to implement recognition process. The methods we use are principle component analysis (PCA), plane sweep, visibility test, and iterative closest point (ICP). During the implementation, we also use 3D map information for localization. We apply this algorithm to real test scene images and to find out our result can be useful to identify doors or walls in indoor environment with better efficiency. "
}
@article{Rubino2015288,
title = "Wireless Image Compression and Transmission for Underwater Robotic Applications? ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "288 - 293",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.047",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002864",
author = "Eduardo M. Rubino and Diego Centelles and Jorge Sales and Jose Vte. Marti and Raul Marin and Pedro J. Sanz",
keywords = "Wireless Communications",
keywords = "RF signal",
keywords = "Image Compression",
keywords = "Image Transmission",
keywords = "Underwater Robotics Intervention",
keywords = "Autonomy ",
abstract = "Abstract Nowadays, there is an increasing demand for underwater robotic intervention systems around the world in several application domains. Examples of applications include search and recovery (i.e. aviation or naval accidents), archaeology, offshore industry, environment protection and monitoring, etc. The commercially available systems are expensive and far from what it is demanded in many aspects, justifying the need of more autonomous, cheap and easy-to- use solutions for underwater intervention missions. Most of them consist of remote operated vehicles, relying on an umbilical cable for its remote operation. This umbilical provides high bandwidth and reliable communications between the vehicle and the operator, but also presents some drawbacks: high cost, movement and depth constraints, lack of autonomy, etc. The current trend is to advance towards less expensive and more autonomous systems, where the umbilical is not present, and the transmission of wireless information is necessary. This work analyses the use of an underwater \{RF\} link to provide affordable communications. Moreover, different data compression techniques that can be used to optimize underwater wireless communications are analysed. Image transmission performance results in pool conditions are presented and discussed. "
}
@article{Schlechtendahl201789,
title = "Extended study of network capability for cloud based control systems ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "43",
number = "",
pages = "89 - 95",
year = "2017",
note = "Special Issue: Extended Papers Selected from \{FAIM\} 2014 ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515001246",
author = "Jan Schlechtendahl and Felix Kretschmer and Zhiqian Sang and Armin Lechler and Xun Xu",
keywords = "Cloud based manufacturing",
keywords = "Cyber physical system",
keywords = "Realtime communication ",
abstract = "Abstract Current control systems are limited from a technical viewpoint in areas such as scalability, start-up and reconfiguration time and computational complexity for algorithms. These limitations call for a new concept for control systems to address current and future requirements. It has been suggested that the physical location of the control system be moved from that of the machine to a cloud, i.e. control system as a service (CSaaS). In this way, the control system becomes scalable and can handle highly complex computational tasks while keeping the process know-hows. Utilizing capabilities of modern Wide Area Network (WAN) and Local Area Network (LAN) the control system can be connected with the rest of the machine, e.g. drives, sensors, devices and HMI. This approach, however, presents new challenges, i.e. the requirement for integration of network, cloud computing and control system expertize. This paper will focus on the requirements of the communication for a cloud based control system. "
}
@article{Stathopoulos2017191,
title = "Space-borne observations of aerosol - cloud relations for cloud systems of different heights ",
journal = "Atmospheric Research ",
volume = "183",
number = "",
pages = "191 - 201",
year = "2017",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.09.005",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516303192",
author = "S. Stathopoulos and A.K. Georgoulias and K. Kourtidis",
keywords = "Aerosols",
keywords = "Cloud",
keywords = "Water vapor",
keywords = "China",
keywords = "Cloud height ",
abstract = "Abstract Here, we examine the aerosol - cloud relations over three major urban clusters of China, representative of three different climatic regimes, under different water vapor conditions and cloud heights, using Aerosol Optical Depth at 550 nm (AOD), Cloud Fraction (CC), Cloud Optical Depth (COD), Water Vapor (WV) and Cloud Top Pressure (CTP) data from the \{MODIS\} instrument. Over all regions and for all seasons, \{CC\} is found to increase with increasing AOD, \{WV\} and cloud height. Aerosols, at low \{WV\} environments and under constant CTP, have less impact on \{CC\} than at high \{WV\} environments. Furthermore, \{AOD\} has a varying influence on \{COD\} depending on CTP. Finally, \{COD\} is found to increase with height for low and middle height clouds, and with increasing AOD, especially at low AOD. Our results demonstrate that the role of \{WV\} in the observed satellite-based aerosol - cloud relations is significant for all cloud heights. "
}
@article{Cao2017,
title = "A novel relocation method for simultaneous localization and mapping based on deep learning algorithm ",
journal = "Computers & Electrical Engineering ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2017.03.015",
url = "http://www.sciencedirect.com/science/article/pii/S0045790617305943",
author = "Jun Cao and Bi Zeng and Jianqi Liu and Zhenting Zhao and Yongfeng Su",
keywords = "SLAM",
keywords = "Relocation",
keywords = "Deep learning",
keywords = "Cloud robotics",
keywords = "Classification ",
abstract = "Abstract Relocation is one of the most common problems in Simultaneous Localization and Mapping (SLAM). This paper presents a novel relocation method, using unsupervised deep learning algorithm to extract the feature of Light Detection and Ranging (LiDAR) data, and narrows the scope of relocation by classifying these features to reduce the randomness of the relocation. Compared with the other methods which is based on matching the manual feature points, this method avoids some limitations of manual features. We modify the Particle Filter \{SLAM\} (PF-SLAM), and use our relocation method to replace the original method for experimentation. The experimental results demonstrate that this method can be relocation whit high success rate only use a small amount of computational resource in a short time. Training neural network will consume a lot of computing resources, we also propose a cloud computing framework to the implementation of this method for the mobile robot which computational resources are limited. "
}
@article{Donoso2017147,
title = "How do \{ICP\} variants perform when used for scan matching terrain point clouds? ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "147 - 161",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016301282",
author = "F.A. Donoso and K.J. Austin and P.R. McAree",
keywords = "Iterative closest point",
keywords = "Terrain mapping",
keywords = "Point cloud registration algorithms ",
abstract = "Abstract Many variants of the Iterative Closest Point (ICP) algorithm have been proposed for registering point clouds. This paper explores the performance of 20,736 \{ICP\} variants applied to the registration of point clouds for the purpose of terrain mapping, using data obtained from a mobile platform. The methodology of the study has involved taking sequences of 100 consecutive scans at three distinct scenes along the route of a mining haul truck operating in a typical surface mining environment. The scan sequences were obtained at 20 Hz from a Velodyne HDL-64E mounted on the truck. The aim is to understand how well the \{ICP\} variants perform in consolidating these scans into sub-maps. Variants are compared against three metrics: accuracy, precision, and relative computational cost. The main finding of the paper is that none of the variants is simultaneously accurate, precise, and fast to compute, across all three scenes. The best performing variants employed strategies that filtered the data sets, used local surface geometry in the form normals, and used the distance between points in one point cloud to a corresponding surface from a reference point cloud as a measure of the fit between two point clouds. The significance of this work is that it: (i) provides guidance in the construction of \{ICP\} variants for terrain mapping; and (ii) identifies the significant limitations of existing \{ICP\} variants for this application. "
}
@article{Li2017209,
title = "Novel availability and integrity verification protocol for \{ISMAC\} system under cloud environment ",
journal = "Computers & Electrical Engineering ",
volume = "57",
number = "",
pages = "209 - 219",
year = "2017",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2016.11.002",
url = "http://www.sciencedirect.com/science/article/pii/S0045790616307017",
author = "Jun Li",
keywords = "Cloud computing",
keywords = "Protocol verification",
keywords = "Data center",
keywords = "Security and storage",
keywords = "Numerical simulation ",
abstract = "Abstract The Novel Availability and Integrity Verification Protocol (NAIVP) is a novel technique for indicating the global availability and general integrity that is supported by data that has been stored in the cloud. There are several schemes that have been designed which rely on the Vandermonde-based Reed-Solomon Code. This is necessary to ensure that the data has good availability. Researchers have proposed the homomorphic distributed verification protocol for guaranteeing the security of data storage in the cloud and pseudorandom data is used by the token pre-computation to determine whether the stored data is correct. However, there is very little integrity in the security provided for the data. The proposed \{NAIVP\} overcomes the difficulties faced by this previously published protocol. It can offer robust assurance of the availability and integrity of information stored in the cloud using fractional dynamic data sustenance through verifiability. The experimental result proves effectiveness and robustness of the proposed methodology. "
}
@article{Wiedemann200813689,
title = "Analysis and characterization of the \{PMD\} camera for application in mobile robotics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "41",
number = "2",
pages = "13689 - 13694",
year = "2008",
note = "17th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20080706-5-KR-1001.02318",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016411845",
author = "Matthias Wiedemann and Markus Sauer and Frauke Driewer and Klaus Schilling",
abstract = "Abstract Three-dimensional perception of the environment offers significant potential to improve navigation solutions for mobile systems. The Pixel-Mixed-Device Technology (PMD) offers here a small, light-weight camera generating 3-D images, based on time-of-flight measurements. This contribution analyzes the sensor characteristics and application potential for mobile robots. Specific aspects related to parameter optimization and limitations in measurements are discussed on basis of performance tests. In particular, range images in unstructured and changing scenes are of interest. Specific properties of mobile systems are taken into account to generate appropriate range images for navigation and mapping tasks in robotic applications. Related adaptations of integration time and methods to percept consistent distances are derived and characterized by tests. "
}
@article{Kurkin2017459,
title = "Autonomous Mobile Robotic System for Environment Monitoring in a Coastal Zone ",
journal = "Procedia Computer Science ",
volume = "103",
number = "",
pages = "459 - 465",
year = "2017",
note = "\{XII\} International Symposium Intelligent Systems 2016, \{INTELS\} 2016, 5-7 October 2016, Moscow, Russia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.01.022",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917300236",
author = "A.A. Kurkin and D.Yu. Tyugin and V.D. Kuzin and A.G. Chernov and V.S. Makarov and P.O. Beresnev and V.I. Filatov and D.V. Zeziulin",
keywords = "autonomous mobile robotic system",
keywords = "coastal zone monitoring ",
abstract = "Abstract Definition of optimum conditions for monitoring coastal zones, especially for the places which are poorly provided with supervision, belongs to one of important tasks of the forecast of marine natural disasters. The project includes the development of technology for monitoring and forecasting the state of environment of a coastal zone by autonomous mobile robotic system (AMRS). The structural composition of the robotic complex for coastal zone monitoring is presented. The special modular design of the \{AMRS\} chassis for functioning in various climatic and landscape conditions is described. Information of monitoring system, positioning system, meteorological system, vehicle control and obstacles detection system is also given within the paper. The results of the first field tests of the \{AMRS\} on the coast of the Okhotsk Sea are presented. "
}
@article{Hassan201748,
title = "A multimedia healthcare data sharing approach through cloud-based body area network ",
journal = "Future Generation Computer Systems ",
volume = "66",
number = "",
pages = "48 - 58",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15004070",
author = "Mohammad Mehedi Hassan and Kai Lin and Xuejun Yue and Jiafu Wan",
keywords = "Wireless body area network",
keywords = "Media healthcare",
keywords = "Data sharing",
keywords = "Cloud computing",
keywords = "Network architecture ",
abstract = "Abstract Wireless Body Area Network (WBAN), as a dramatic platform for pervasive computing and communication, has been widely applied in healthcare domains. Since the patient-related data in the form of text, image, voice, etc. is significant in the process of healthcare services, efficiently managing these media data from various \{WBAN\} is vital for various applications. Recently, Cloud-assisted \{WBAN\} has become popular that can supply massive computing, flexible storage and various software services to WBAN. Still, there are some challenging issues exist in this platform to deliver and share the huge media healthcare data to remote terminals timely with guaranteed QoS support. In the paper, we propose an efficient network model that combines \{WBAN\} and Cloud for valid data sharing. The proposed network architecture is designed as four layers: perception layer, network layer, cloud computing layer, and application layer. In the network, the integration of TCP/IP and Zigbee in the coordinator devices is utilized. Consequently, \{WBAN\} coordinators can compatibility inter-operate with various local networks such as WiFi and \{LTE\} network to support high mobility of users. Besides, we integrate Content Centric Networking (CCN) with our proposed architecture to improve the ability of the \{WBAN\} coordinator. Thus, it can support uninterrupted media healthcare content delivery. In addition, adaptive streaming technique was also utilized to reduce packet loss. Various simulations were conducted using \{OPNET\} simulator to show the feasibility of the proposed architecture in terms of transmitting a huge amount of media healthcare data in real-time under traditional IP-based network. "
}
@article{Chen2017347,
title = "Operation Mode Study in Cloud Manufacturing Ecosystem ",
journal = "Procedia \{CIRP\} ",
volume = "61",
number = "",
pages = "347 - 352",
year = "2017",
note = "The 24th \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.154",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116313142",
author = "Shengkai Chen and Shuiliang Fang and Tao Peng and Renzhong Tang",
keywords = "Cloud manufacturing ecosystem",
keywords = "decision-making",
keywords = "operation mode",
keywords = "ecosystem evolution",
keywords = "agent-based simulation ",
abstract = "Abstract With cloud manufacturing and its shared big-data, the life-cycle management of the massive distributed manufacturing resources can be considered as an ecosystem, in which every entity makes their own decisions depend on the enriched information, which will affect the life cycle of the resources and the overall industry states. In this paper, an original operation mode with three extensions are proposed to describe the life cycle vicissitude of each resource. An agent-based model was designed to simulate the ecosystem modes from the very beginning, and the results show that the ecosystem has: 1) shorter job queue length and lower resource idle rate with incubation mode; 2) a little shorter job queue length and fewer amount of registered resource with outsourcing mode; 3) the fewest amount of registered resource but a little higher resource idle rate with metabolism mode. "
}
@article{Badawi201759,
title = "Mobile cloud-based physical activity advisory system using biofeedback sensors ",
journal = "Future Generation Computer Systems ",
volume = "66",
number = "",
pages = "59 - 70",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15003428",
author = "Hawazin Faiz Badawi and Haiwei Dong and Abdulmotaleb El Saddik",
keywords = "Physical activity",
keywords = "Advisory system",
keywords = "Cloud computing",
keywords = "Wellbeing",
keywords = "Biofeedback",
keywords = "Environmental context ",
abstract = "Abstract Physical inactivity has gained a wide attention due to its negative influence on human wellness. Physical activity advisory systems consider a promising solution for this phenomenon. In this paper, we propose a mobile cloud-based physical activity advisory system utilizing biofeedback sensors and environmental context data based on calories expenditure from performing various activities by tracking user’s physical movements. To evaluate the proposed system, we conducted in total a three-month experiment on six users. For each user, we tracked the amount of burnt calories from the physical movements for a two-week period. During the first week, the system did not send any advice, while during the second week, the system was advising the user on activities to perform. The compared results of the two weeks collected data (without and with advice) reflect the positive effect of the proposed system on participants’ physical activity level. The system motivates them to reach or exceed the recommended number of calories to be burned daily. "
}
@article{Muliukha2017505,
title = "Network-centric Supervisory Control System for Mobile Robotic Groups ",
journal = "Procedia Computer Science ",
volume = "103",
number = "",
pages = "505 - 510",
year = "2017",
note = "\{XII\} International Symposium Intelligent Systems 2016, \{INTELS\} 2016, 5-7 October 2016, Moscow, Russia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.01.036",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917300376",
author = "Vladimir Muliukha and Alexander Ilyashenko and Leonid Laboshin",
keywords = "network-centric control system",
keywords = "cyber-physical approach",
keywords = "mobile robots",
keywords = "high-performance cloud system. ",
abstract = "Abstract The paper analyzes network-centric control methods for mobile robotic groups. We consider the task of controlling a group of mobile robots, performing reconnaissance for space and terrestrial applications. In the paper each robot is a cyber-physical object consisting of mechatronic part and computer module, which analyzes data from sensors and generates commands. The use of network-centric approach allows separating these two parts, transferring resource-intensive computing tasks in a high-performance hybrid cloud environment. A cloud environment as a single point for processing of all sensory data allows us to use the advantages of centralized control method and to manage the resources of mobile robots more effectively. In this case, each robot keeps the autonomy if there is no communication with the control center. So a key element of such control systems is reliable communication links. In our work we use redundancy and duplication of various communication channels to provide a continuous connection between a mobile robot and control center. "
}
@article{Dodds1988179,
title = "Fuzziness in knowledge-based robotics systems ",
journal = "Fuzzy Sets and Systems ",
volume = "26",
number = "2",
pages = "179 - 193",
year = "1988",
note = "Fuzzy Control ",
issn = "0165-0114",
doi = "https://doi.org/10.1016/0165-0114(88)90207-2",
url = "http://www.sciencedirect.com/science/article/pii/0165011488902072",
author = "David R. Dodds",
keywords = "Knowledge representation",
keywords = "approximate and commonsense reasoning",
keywords = "Robotics ",
abstract = "This paper addresses how fuzziness is employed in a robotics system, for the purposes of object representation, object or feature location and as a means of representing actions performed on objects. Many, perhaps most, robotics systems do not take advantage of either regular data bases nor Solid Geometry data bases. This paper describes a robotic system which would use a multi-modal representation knowledge base (KB). The focus of the present paper is on the use of fuzziness in this robotic system. Keyboard entered natural language phrases would be used by a human user of the robot. The robot system would, in practice, translate these phrases into executable commands and coordinates. There are several points of departure that would be employed and the first of these is the use of ‘fuzzy descriptions’ rather than the conventional binary distinctive feature matrix (such as SHRDLU) or a point cluster approach. A fuzzy descriptor is a generalization of a geometric description of an object from the system's geometric data base. How the fuzzy descriptor works is described. Object or (geometric) feature location is handled by means of extrapolating the object description method. Named concrete or specific coordinate locations, or named abstract locations which involve a range of coordinates, are used to do this; by means of the familiar ‘linguistic variable’ which we all use in everyday speech. Some means whereby this is done is explained. The user of this robotic system may semantically attach linguistic variables to a fuzzy mapping of knowledge base object descriptions. The paper provides some details as to how a robotic system might be operated in an ‘action abstraction’ mode. "
}
@article{Abd2016,
title = "An effective approach for managing power consumption in cloud computing infrastructure ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316303830",
author = "Sura Khalil Abd and S.A.R Al-Haddad and Fazirulhisyam Hashim and Azizol B.H.J. Abdullah and Salman Yussof",
keywords = "Cloud computing",
keywords = "DNA-based fuzzy genetic",
keywords = "DFGA",
keywords = "Energy consumption",
keywords = "Resource utilization",
keywords = "VM consolidation",
keywords = "VM migration ",
abstract = "Abstract Cloud computing offers a dynamic provisioning of server capabilities as a scalable virtualized service. Big datacenters which deliver cloud computing services consume a lot of power. This results in high operational cost and large carbon emission. One way to lower power consumption without affecting the cloud services quality is to consolidate resources for reducing power. In this paper, we introduce a DNA-based Fuzzy Genetic Algorithm (DFGA) that employs DNA-based scheduling strategies to reduce power consumption in cloud datacenters. It is a power-aware architecture for managing power consumption in the cloud computing infrastructure. We also identify the performances metrics that are needed to evaluate the proposed work performance. The experimental results show that \{DFGA\} reduced power consumption when comparing with other algorithms. Our proposed work deals with real time task which is not static, and concentrates on the dynamic users since they are involved in cloud. "
}
@article{Vaha2013168,
title = "Extending automation of building construction — Survey on potential sensor technologies and robotic applications ",
journal = "Automation in Construction ",
volume = "36",
number = "",
pages = "168 - 178",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001167",
author = "Pentti Vaha and Tapio Heikkila and Pekka Kilpelainen and Markku Jarviluoma and Ernesto Gambao",
keywords = "Sensor technologies",
keywords = "Building construction automation",
keywords = "Automated data acquisition",
keywords = "Construction robotics",
keywords = "Prefabrication ",
abstract = "Abstract Today, many construction operations have incorporated automated equipment, means, and methods into their regular practises. Although adaption of automation in the building construction sector has been slow, principles of industrial automation are applicable to this domain, both to building construction, civil engineering, and to prefabrication of construction components. Improved sensor technologies and the widening use of the Building Information Modeling (BIM) will offer new possibilities to cover various needs and operations taking place throughout the building life cycle. These can play a key role in future construction automation. This paper provides a survey for potential sensor technologies for building construction automation, highlighting their potential also with contributions from robotics. The paper carries out the survey from the viewpoints of building construction phases. "
}
@article{Caci20131493,
title = "Robotic and virtual World Programming labs to Stimulate Reasoning and visual-spatial Abilities ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "93",
number = "",
pages = "1493 - 1497",
year = "2013",
note = "3rd World Conference on Learning, Teaching and Educational Leadership ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2013.10.070",
url = "http://www.sciencedirect.com/science/article/pii/S1877042813035155",
author = "Barbara Caci and Giuseppe Chiazzese and Antonella D’Amico",
keywords = "Robotics",
keywords = "virtual worlds",
keywords = "visual-spatial working memory",
keywords = "programming learning",
keywords = "playful learning environment. ",
abstract = "Abstract The individuals’ cognitive skills, academic performance and their relationship with programming of robots or virtual learning environment is a topic of particular interest in the area of human-robot interaction. This paper presents a pilot study performed on a group of 36 lower secondary school students involved in a 32-hours laboratory based on the combination of \{LEGO\} Mindstorm \{NXT\} and Microsoft Kodu Game Lab (KGL) and aimed at programming first a robot and further a more complete virtual world based on a narrative-designed scenario. The findings of the research will be discussed in the light of the effectiveness of using robotics and virtual world programming as a meaningful and playful learning environment for improving cognition in children. "
}
@article{Srinivasan201357,
title = "Design and Development of a Robotic Teleoperation System using Duplex WebSockets suitable for Variable Bandwidth Networks ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "29",
pages = "57 - 61",
year = "2013",
note = "3rd \{IFAC\} Symposium on Telematics Applications ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20131111-3-KR-2043.00029",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015343639",
author = "Lakshminarasimhan Srinivasan and Julian Scharnagl and Zhihao Xu and Nicolas Faerber and Dinesh K. Babu and Klaus Schilling",
keywords = "Tele-operation",
keywords = "WebSockets",
keywords = "Low-bandwidth robotics",
keywords = "Remote robotics",
keywords = "Technology management ",
abstract = "Abstract This paper addresses the development of a new teleoperation framework for remote robotics. The status of existing robotic teleoperation systems is introduced, with emphasis on several technological drawbacks and is followed by a description of the design, development and implementation of a new framework based on bleeding edge technologies in internet protocols and software engineering related to robotics. As a first implementation, an update of an existing tele-robotics laboratory is in progress aiming round-the-clock networked access, suited for even the most demanding online learning platforms. A comparison between the current and previous teleoperation system is also published verifying the implemented framework. "
}
@article{AbuSharkh201678,
title = "Building a cloud on earth: A study of cloud computing data center simulators ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "78 - 96",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.06.037",
url = "http://www.sciencedirect.com/science/article/pii/S138912861630216X",
author = "Mohamed Abu Sharkh and Ali Kanso and Abdallah Shami and Peter ohlen",
keywords = "Cloud computing",
keywords = "Cloud simulators",
keywords = "Scalability",
keywords = "Data centers",
keywords = "Virtualization",
keywords = "Network and systems monitoring and measurements ",
abstract = "Abstract As cloud computing technologies finalize their transformation into the standard technologies for businesses of all sizes, they face more scrutiny than ever. Clients are expecting the benefits of turning infrastructure, platform and network into services payable per use without tolerating any service hiccups caused by performance bottlenecks or overprovision. This puts cloud providers under pressure to deliver data center management solutions and deployment plans in minimal time and with failure allowance close to none. Any comprehensive solution evaluation could gain much from the use of cloud simulators. Cloud simulators have the advantage of practicality over both mathematical proofs and real testbeds. They support any amount of heterogeneous use cases demanded by the cloud provider. Despite being a relatively new concept, multiple cloud simulators were developed. However, they are still in the phase of adapting to the scenarios, objectives and characteristics of the cloud. This paper examines a selected set of the current cloud simulators in terms of vision, features, and architecture. Strong points and limitations are discussed. Moreover, this paper presents a framework for cloud simulator design that can serve as an elaborate design checklist. A discussion of the open research challenges concludes the paper. "
}
@article{Tchernykh2016,
title = "Towards understanding uncertainty in cloud computing with risks of confidentiality, integrity, and availability ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.11.011",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316303878",
author = "Andrei Tchernykh and Uwe Schwiegelsohn and El-ghazali Talbi and Mikhail Babenko",
keywords = "Cloud computing",
keywords = "Uncertainty",
keywords = "Resource provisioning",
keywords = "Optimization",
keywords = "Scheduling",
keywords = "Reliability",
keywords = "Privacy ",
abstract = "Abstract An extensive research has led to a general understanding of uncertainty issues in different fields ranging from computational biology to decision making in economics. However, a study of uncertainty on large scale computing systems and cloud computing systems is limited. Most of works examine uncertainty phenomena in users’ perceptions of the qualities, intentions and actions of cloud providers. In this paper, we discuss the role of uncertainty in the resource and service provisioning, privacy, etc. especially, in the presence of the risks of confidentiality, integrity, and availability. We review sources of uncertainty, and fundamental approaches for scheduling under uncertainty. We also discuss potentials of these approaches, and address methods for mitigating the risks of confidentiality, integrity, and availability associated with the loss of information, denial of access for a long time, and information leakage. "
}
@article{Fink2009226,
title = "CYCLOPS: A mobile robotic platform for testing and validating image processing and autonomous navigation algorithms in support of artificial vision prostheses ",
journal = "Computer Methods and Programs in Biomedicine ",
volume = "96",
number = "3",
pages = "226 - 233",
year = "2009",
note = "",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2009.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S0169260709002053",
author = "Wolfgang Fink and Mark A. Tarbell",
keywords = "Artificial vision prostheses",
keywords = "Retinal implants",
keywords = "Image processing",
keywords = "Autonomous navigation",
keywords = "Robotics",
keywords = "Tele-commanding",
keywords = "Self-commanding",
keywords = "Cloud computing",
keywords = "Worldwide accessibility ",
abstract = "While artificial vision prostheses are quickly becoming a reality, actual testing time with visual prosthesis carriers is at a premium. Moreover, it is helpful to have a more realistic functional approximation of a blind subject. Instead of a normal subject with a healthy retina looking at a low-resolution (pixelated) image on a computer monitor or head-mounted display, a more realistic approximation is achieved by employing a subject-independent mobile robotic platform that uses a pixelated view as its sole visual input for navigation purposes. We introduce CYCLOPS: an AWD, remote controllable, mobile robotic platform that serves as a testbed for real-time image processing and autonomous navigation systems for the purpose of enhancing the visual experience afforded by visual prosthesis carriers. Complete with wireless Internet connectivity and a fully articulated digital camera with wireless video link, \{CYCLOPS\} supports both interactive tele-commanding via joystick, and autonomous self-commanding. Due to its onboard computing capabilities and extended battery life, \{CYCLOPS\} can perform complex and numerically intensive calculations, such as image processing and autonomous navigation algorithms, in addition to interfacing to additional sensors. Its Internet connectivity renders \{CYCLOPS\} a worldwide accessible testbed for researchers in the field of artificial vision systems. \{CYCLOPS\} enables subject-independent evaluation and validation of image processing and autonomous navigation systems with respect to the utility and efficiency of supporting and enhancing visual prostheses, while potentially reducing to a necessary minimum the need for valuable testing time with actual visual prosthesis carriers. "
}
@incollection{Hong201477,
title = "6.04 - Robotic Welding Technology ",
editor = "Hashmi, Saleem and Batalha, Gilmar Ferreira and Tyne, Chester J. Van  and Yilbas, Bekir ",
booktitle = "Comprehensive Materials Processing ",
publisher = "Elsevier",
edition = "",
address = "Oxford",
year = "2014",
pages = "77 - 99",
isbn = "978-0-08-096533-8",
doi = "https://doi.org/10.1016/B978-0-08-096532-1.00604-X",
url = "http://www.sciencedirect.com/science/article/pii/B978008096532100604X",
author = "T.S. Hong and M. Ghobakhloo and W. Khaksar",
keywords = "Arc welding",
keywords = "Automatic welding",
keywords = "Friction stir welding",
keywords = "Robotics",
keywords = "Robot welding",
keywords = "Spot welding",
keywords = "Welding ",
abstract = "Abstract Since the first industrial robots were introduced in the early 1960s, the development of robotized welding has been truly remarkable and is today one of the major application areas for industrial robots. Robot welding is mainly concerned with the use of mechanized programmable tools, known as robots, which completely automate a welding process by both performing the weld and handling the part. Robots are quite versatile and hence have been used for a variety of welding types such as resistance welding and arc welding. This chapter describes the development and progress of robotization in welding over the years and also discusses many advantages and disadvantages of different robotic welding technologies. "
}
@article{Vallecillos2016198,
title = "A cloud service for \{COTS\} component-based architectures ",
journal = "Computer Standards & Interfaces ",
volume = "48",
number = "",
pages = "198 - 216",
year = "2016",
note = "Special Issue on Information System in Distributed Environment ",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2015.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0920548915001415",
author = "Jesus Vallecillos and Javier Criado and Nicolas Padilla and Luis Iribarne",
keywords = "Cloud service",
keywords = "Software architectures",
keywords = "Component-based systems",
keywords = "COTS ",
abstract = "Abstract Software architecture management, especially in component-based web user interfaces is important to enhance their run-time accessibility, dynamics and management. The cloud offers some excellent mechanisms for this kind of systems, since software can be managed remotely, easy availability of the resources is ensured and mass storage is possible. This article presents an infrastructure solution, based on the use of web services and cloud computing, for managing COTS-based architectures. "
}
@article{Pagallo2013501,
title = "Robots in the cloud with privacy: A new threat to data protection? ",
journal = "Computer Law & Security Review ",
volume = "29",
number = "5",
pages = "501 - 508",
year = "2013",
note = "",
issn = "0267-3649",
doi = "https://doi.org/10.1016/j.clsr.2013.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S0267364913001398",
author = "Ugo Pagallo",
keywords = "Data protection",
keywords = "Human-robot interaction",
keywords = "Katz's test",
keywords = "Network-centric applications",
keywords = "Privacy",
keywords = "Privacy by design",
keywords = "Robotics technology ",
abstract = "Abstract The focus of this paper is on the class of robots for personal or domestic use, which are connected to a networked repository on the internet that allows such machines to share the information required for object recognition, navigation and task completion in the real world. The aim is to shed light on how these robots will challenge current rules on data protection and privacy. On one hand, a new generation of network-centric applications could in fact collect data incessantly and in ways that are “out of control,” because such machines are increasingly “autonomous.” On the other hand, it is likely that individual interaction with personal machines, domestic robots, and so forth, will also affect what U.S. common lawyers sum up with the Katz's test as a reasonable “expectation of privacy.” Whilst lawyers continue to liken people's responsibility for the behaviour of robots to the traditional liability for harm provoked by animals, children, or employees, attention should be drawn to the different ways in which humans will treat, train, or manage their robots-in-the-cloud, and how the human–robot interaction may affect the multiple types of information that are appropriate to reveal, share, or transfer, in a given context. "
}
@article{Tzoumanikas2016314,
title = "The effect of clouds on surface solar irradiance, based on data from an all-sky imaging system ",
journal = "Renewable Energy ",
volume = "95",
number = "",
pages = "314 - 322",
year = "2016",
note = "",
issn = "0960-1481",
doi = "https://doi.org/10.1016/j.renene.2016.04.026",
url = "http://www.sciencedirect.com/science/article/pii/S0960148116303305",
author = "P. Tzoumanikas and E. Nikitidou and A.F. Bais and A. Kazantzidis",
keywords = "Cloud radiative effect",
keywords = "All-sky camera",
keywords = "Cloud enhancement ",
abstract = "Abstract An all-sky imaging system is deployed to estimate the effect of clouds on incident solar irradiance, for a 2-year period over the city of Thessaloniki, Greece. The minutely cloud radiative effect (CRE) is examined in relevance to the cloud cover and type as well as the percentage of the solar disk covered by clouds and the relative position of Sun and clouds in the sky. \{CRE\} increases with the cloud cover and decreases with the solar zenith angle (SZA). The minimum instantaneous values can reach −900 W m−2 while enhancement events are found to reach up to +200 W m−2. The greatest cooling effects are caused by thick cumulus clouds, in cases where obstruction of the solar disk is visible and by stratocumulus, stratus-altostratus and cumulonimbus-nimbostratus when accompanied by high values of cloud cover. The enhancement events are mostly found when the clouds are in the vicinity of the Sun and when the clouds are accumulated at the upper part of the sky but the Sun is in a lower position. "
}
@article{Bueno2016264,
title = "Evaluation of point cloud registration using Monte Carlo method ",
journal = "Measurement ",
volume = "92",
number = "",
pages = "264 - 270",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2016.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S0263224116303116",
author = "M. Bueno and H. Gonzalez-Jorge and J. Martinez-Sanchez and L. Diaz-Vilarino and P. Arias",
keywords = "Point cloud registration",
keywords = "ICP",
keywords = "Monte Carlo",
keywords = "SLAM ",
abstract = "Abstract Supervision and control are one of the most important steps while executing a construction project and their automation remains an area of growing interest. LiDAR systems provide accurate point clouds with geometric information that can help to improve the automation of survey control. Alignment of the point clouds acquired from a number of scan positions is a fundamental issue regarding surveying accuracy and is frequently carried out in two steps: coarse and fine registration. Fine registration can be achieved automatically by means of an Iterative Closest Point (ICP) procedure. This work presents a Monte Carlo based method to quantify the reliability of a coarse registration step that would enable the automation of the alignment. The method consists of verifying the tolerance of a particular \{ICP\} implementation to coarse registration errors. Results show that the \{ICP\} alignment used works fine when coarse registration errors are lower than 18° for rotations and 1 m for translations. These values were similar for four case studies analysed. Quantifying these limits is crucial for operations such as robotic stop &amp; go surveying, where coarse alignment is based on Simultaneous Location and Mapping (SLAM) and fine alignment is achieved through ICP. "
}
@article{Chen201634,
title = "A cloud-based system framework for performing online viewing, storage, and analysis on big data of massive \{BIMs\} ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "34 - 48",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516300413",
author = "Hung-Ming Chen and Kai-Chuan Chang and Tsung-Hsi Lin",
keywords = "Cloud computing",
keywords = "Building information model",
keywords = "Big data analysis",
keywords = "Web3D",
keywords = "Bigtable",
keywords = "MapReduce ",
abstract = "Abstract This paper presents a cloud-based system framework based on Bigtable and MapReduce as the data storage and processing paradigms for providing a web-based service for viewing, storing, and analyzing massive building information models (BIMs). Cloud and Web 3D technologies were utilized to develop a \{BIM\} data center that can handle the big data of massive \{BIMs\} using multiple servers in a distributed manner and can be accessed by multiple users to concurrently submit and view \{BIMs\} online in 3D. Traditional \{BIM\} include only static information such as the geometric parameters, physical properties, and spatial relations for modeling a physical space. In this study, \{BIM\} was extended to dynamic BIM, which includes dynamic data such as historical records from the monitoring of the facility environment and usage. Owing to this extension, a dynamic \{BIM\} became a parametric model, which can be used to simulate user behaviors. On the client side, this study applied WebGL in the web interface development to achieve the display of \{BIMs\} in 3D on browsers. Users can access the services via various online devices anytime and anywhere to view the 3D model online. On the server side, this study used Apache Hadoop, which can utilize multiple servers to provide mass storage spaces in a distributed manner with Bigtable-like structured storage, to establish the \{BIM\} data center. A schema for storing the big data of massive dynamic \{BIMs\} in Bigtables was proposed. MapReduce, a Hadoop component for the parallel processing of large data sets, was utilized to process big data from dynamic BIMs. A big data analysis framework to effectively retrieve and calculate required information from dynamic \{BIMs\} in the data center for various applications by MapReduce distributed computing was proposed this study. We provide principle and architecture of the proposed framework along with its experimental assessment. The results confirmed that scalable and reliable management of massive \{BIMs\} can be achieved using the proposed framework. "
}
@article{Gharbaoui2016279,
title = "Cloud and network orchestration in \{SDN\} data centers: Design principles and performance evaluation ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "279 - 295",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.08.029",
url = "http://www.sciencedirect.com/science/article/pii/S1389128616302821",
author = "M. Gharbaoui and B. Martini and D. Adami and S. Giordano and P. Castoldi",
keywords = "Cloud",
keywords = "SDN",
keywords = "Orchestration",
keywords = "OpenFlow",
keywords = "Data Center network ",
abstract = "Abstract The oversubscription of Data Center network links and the high volatility of Virtual Machine (VM) deployments call for a flexible and agile control of Data Center networks, coordinated with computing resource control (i.e., cloud resource management). The Software-Defined Network (SDN) paradigm opens up new opportunities to design convergent resource management systems able to address the provisioning of cloud services while meeting dynamically changing traffic demands of running VMs. This paper presents the architectural design of an SDN-based orchestration system which is able to coordinate the provision of composite cloud and network services while assuring computational requirements as well as a better than best effort \{VM\} data delivery. The proposed orchestration system is able to perform \{VM\} allocations also based on estimations of switch/link and server loads as result of the synergistic interwork of the following functions: (i) resource selection and composition functions, (ii) coordinated resource configuration and management functions, (iii) monitoring and registration functions of resource status. A set of resource selection and composition strategies and estimation schemes have been also specified. The orchestration process has been thoroughly evaluated through a comprehensive set of simulations that clearly show an increasing acceptance rate of service requests, an improved utilization of network capabilities while effectively preventing significant degradations of the user experience despite the oversubscription of data center network links. "
}
@article{Golightly201612,
title = "Manufacturing in the cloud: A human factors perspective ",
journal = "International Journal of Industrial Ergonomics ",
volume = "55",
number = "",
pages = "12 - 21",
year = "2016",
note = "",
issn = "0169-8141",
doi = "https://doi.org/10.1016/j.ergon.2016.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0169814116300464",
author = "David Golightly and Sarah Sharples and Harshada Patel and Svetan Ratchev",
keywords = "Cloud manufacturing",
keywords = "Assembly",
keywords = "Production",
keywords = "Collaboration ",
abstract = "Abstract Cloud manufacturing adopts a cloud computing paradigm as the basis for delivering shared, on-demand manufacturing services. The result is customer-centric supply chains that can be configured for cost, quality, speed and customisation. While the technical capabilities required for cloud manufacturing are a current focus, there are many emerging questions relating to the impact, both positive and negative, on the people consuming or supporting cloud manufacturing services. Human factors can have a pivotal role in enabling the success and adoption of cloud manufacturing, while ensuring the safety, well-being and optimum user experience of those involved in a cloud manufacturing environment. This paper presents these issues, structured around groups of users (service providers, application providers and consumers). We also consider the issues of collaboration that are likely to arise from the manufacturing cloud. From this analysis we discuss the central role of human factors as an enabler of cloud manufacturing, and the opportunities that emerge. "
}
@article{Lauri201615,
title = "Planning for robotic exploration based on forward simulation ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "15 - 31",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015301779",
author = "Mikko Lauri and Risto Ritala",
keywords = "Partially observable Markov decision process",
keywords = "Active sensing",
keywords = "Robotic exploration",
keywords = "Mutual information",
keywords = "Sensor management ",
abstract = "Abstract We address the problem of controlling a mobile robot to explore a partially known environment. The robot’s objective is the maximization of the amount of information collected about the environment. We formulate the problem as a partially observable Markov decision process (POMDP) with an information-theoretic objective function, and solve it applying forward simulation algorithms with an open-loop approximation. We present a new sample-based approximation for mutual information useful in mobile robotics. The approximation can be seamlessly integrated with forward simulation planning algorithms. We investigate the usefulness of \{POMDP\} based planning for exploration, and to alleviate some of its weaknesses propose a combination with frontier based exploration. Experimental results in simulated and real environments show that, depending on the environment, applying \{POMDP\} based planning for exploration can improve performance over frontier exploration. "
}
@article{Salgueiro201695,
title = "Effects of clouds on the surface shortwave radiation at a rural inland mid-latitude site ",
journal = "Atmospheric Research ",
volume = "178–179",
number = "",
pages = "95 - 101",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.03.020",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516300709",
author = "Vanda Salgueiro and Maria Joao Costa and Ana Maria Silva and Daniele Bortoli",
keywords = "Effective cloud optical thickness",
keywords = "Shortwave cloud radiative effect",
keywords = "Cloud radiative effect efficiency ",
abstract = "Abstract Seven years (2003–2010) of measured shortwave (SW) irradiances were used to obtain estimates of the 10 min averaged effective cloud optical thickness (ECOT) and of the shortwave cloud radiative effect (CRESW) at the surface in a mid-latitude site (evora — south of Portugal), and its seasonal variability is presented. The ECOT, obtained using transmittance measurements at 415 nm, was compared with the correspondent \{MODIS\} cloud optical thickness (MODIS COT) for non-precipitating water clouds and cloud fractions higher than 0.25. This comparison showed that the \{ECOT\} represents well the cloud optical thickness over the study area. The CRESW, determined for two \{SW\} broadband ranges (300–1100 nm; 285–2800 nm), was normalized (NCRESW) and related with the obtained ECOT. A logarithmic relation between \{NCRESW\} and \{ECOT\} was found for both \{SW\} ranges, presenting lower dispersion for overcast-sky situations than for partially cloudy-sky situations. The \{NCRESW\} efficiency (NCRESW per unit of ECOT) was also related with the \{ECOT\} for overcast-sky conditions. The relation found is parameterized by a power law function showing that \{NCRESW\} efficiency decreases as the \{ECOT\} increases, approaching one for \{ECOT\} values higher than about 50. "
}
@article{Aube201611,
title = "The spectral amplification effect of clouds to the night sky radiance in Madrid ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "181",
number = "",
pages = "11 - 23",
year = "2016",
note = "Using remote sensing to better understand light pollution (Light Pollution Theory Modelling and Measurements 2015) ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.01.032",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315301849",
author = "M. Aube and M. Kocifaj and J. Zamorano and H.A. Solano Lamphar and A. Sanchez de Miguel",
keywords = "Sky brightness measurements",
keywords = "Cloud amplification factor",
keywords = "Spectrum",
keywords = "Artificial light at night ",
abstract = "Abstract Artificial Light at Night (ALAN) may have various environmental impacts ranging from compromising the visibility of astronomical objects to the perturbation of circadian cycles in animals and humans. In the past much research has been carried out to study the impact of \{ALAN\} on the radiance of the night sky during clear sky conditions. This was mainly justified by the need for a better understanding of the behavior of \{ALAN\} propagation into the environment in order to protect world-class astronomical facilities. More recently, alongside to the threat to the natural starry sky, many issues have emerged from the biological science community. It has been shown that, nearby or inside cities, the presence of cloud cover generally acts as an amplifier for artificial sky radiance while clouds behave as attenuators for remote observers. In this paper we show the spectral behavior of the zenith sky radiance amplification factor exerted by clouds inside a city. We compare in-situ measurements made with the spectrometer SAND-4 with a numerical model applied to the specific geographical context of the Universidad Complutense de Madrid in Spain. "
}
@article{Gravina2016,
title = "Cloud-based Activity-aaService cyber–physical framework for human activity monitoring in mobility ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16303016",
author = "Raffaele Gravina and Congcong Ma and Pasquale Pace and Gianluca Aloi and Wilma Russo and Wenfeng Li and Giancarlo Fortino",
keywords = "Cloud computing",
keywords = "Activity monitoring",
keywords = "Wearable sensors",
keywords = "Programming framework",
keywords = "Software as a service ",
abstract = "Abstract This paper proposes Activity as a Service (Activity-aaService), a full-fledged cyber–physical framework to support community, on-line and off-line human activity recognition and monitoring in mobility. Activity-aaService is able to address the current lack of Cloud-Assisted Body Area Networks platforms and applications supporting monitoring and analysis of human activity for single individuals and communities. Activity-aaService is built atop the BodyCloud platform so enabling efficient BSN-based sensor data collection and local processing (Body-side), high performance computing of collected sensor data and data storing on the Cloud (Cloud-side), workflow-based programming of data analysis (Analyst-side), and advanced visualization of results (Viewer-side). Specifically, it provides specific, powerful and flexible programming abstractions for the rapid prototyping of efficient human activity-oriented applications. The effectiveness of the proposed framework has been demonstrated through the development of several prototypes related to physical activity monitoring, step counting, physical energy estimation, automatic fall detection, and smart wheelchair support. Finally, performance evaluation of the proposed framework at the Body-side of the activity classification has been carried out by analyzing processing load, data transmission time, \{CPU\} usage, memory footprint, and battery consumption using four heterogeneous mobile devices representing low, medium and high performance mobile platforms. "
}
@article{CommitteeonArmyRoboticsandArtificialIntelligence|ManufacturingStudiesBoard|CommissiononEngineeringandTechnicalSystems|NationalResearchCouncil1984191,
title = "Applications of robotics and artificial intelligence to reduce risk and improve effectiveness: A study for the United States Army ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "1",
number = "2",
pages = "191 - 222",
year = "1984",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/0736-5845(84)90007-3",
url = "http://www.sciencedirect.com/science/article/pii/0736584584900073",
abstract="",
author = "Committee on Army Robotics and Artificial Intelligence and Manufacturing Studies Board and Commission on Engineering and Technical Systems and National Research Council"
}
@article{Casas2016,
title = "GA-ETI: An enhanced genetic algorithm for the scheduling of scientific workflows in cloud environments ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316301399",
author = "Israel Casas and Javid Taheri and Rajiv Ranjan and Lizhe Wang and Albert Y. Zomaya",
keywords = "Cloud computing",
keywords = "Scientific workflow",
keywords = "Scheduling algorithms",
keywords = "Genetic algorithm",
keywords = "Virtual machine ",
abstract = "Abstract Over recent years, cloud computing has become one of the main sources of computer power to run scientific experiments. To cope with these demands, cloud providers need to efficiently match applications with computing resources to maintain an acceptable level of customer satisfaction. A correct match or scheduling of scientific workflows relies on the ability to fully analyze applications prior to execution, analyze characteristics of available computing resources, provide users with several scheduling configurations, and guide users to select the optimal configuration to execute workflows. To date, different schedulers have been proposed to execute complex applications on cloud environments; nevertheless, none exists, to the best of our knowledge, to provide all the aforementioned features. GA-ETI, the scheduler proposed in this work, is designed to address all aforementioned concerns by providing several efficient solutions (in a Pareto Front fashion) to run scientific workflows on cloud resources. Flexibility of optimization procedure of GA-ETI allows it to easily adapt to different types of scientific workflows and produce schedules that effectively exploit/consider the relationship between jobs and their required data. GA-ETI acts as an interface between cloud user and cloud provider in receiving an application, analyzing it, and distributing its tasks among selected resources. GA-ETI differs from the majority of proposed schedulers because it can adapt to the size of both jobs and virtual machines, it includes a monetary cost model (from a public cloud), and it considers complex interdependencies among tasks. We test GA-ETI with five well-known benchmarks with different computing and data transfer demands in our VMware-vSphere private cloud. Through experimentation, GA-ETI has been proved to reduce makespan of executing workflows between 11% and 85% when compared to three up-do-date scheduling algorithms without increasing the monetary cost. GA-ETI opens the way to develop a top-layer-scheduler for a workflow manager system to provide a complex analysis and include different optimizing objectives. "
}
@article{Tong2013146,
title = "Evaluation of heterogeneous measurement outlier rejection schemes for robotic planetary surface mapping ",
journal = "Acta Astronautica ",
volume = "88",
number = "",
pages = "146 - 162",
year = "2013",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2012.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094576512003189",
author = "Chi Hay Tong and Timothy D. Barfoot",
keywords = "Surface mapping",
keywords = "Outlier rejection",
keywords = "SLAM",
keywords = "Mobile robotics ",
abstract = "In this paper, we describe the development and evaluation of a core algorithmic component for robust robotic planetary surface mapping. In particular, we consider the issue of outlier measurements when utilizing both odometry and sparse features for laser scan alignment. Due to the heterogeneity of the measurements and the relative scarcity of distinct geometric features in the planetary environment, we have found that the conventional outlier rejection methods in the current literature do not produce satisfactory classifications for accurate mapping performance. In light of these limitations, we develop a new approach capable of addressing these concerns. This includes a family of four outlier classification algorithms, which are incorporated through iterative reclassification into the batch alignment framework to provide robust surface mapping performance. Characterization of these outlier rejection schemes is presented using a combination of simulated data and real-world testing with an indoor rover. "
}
@article{Badescu2016254,
title = "Reconstruction of effective cloud field geometry from series of sunshine number ",
journal = "Atmospheric Research ",
volume = "176–177",
number = "",
pages = "254 - 266",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516300540",
author = "Viorel Badescu and Marius Paulescu and Marek Brabec",
keywords = "Cloud field geometry",
keywords = "Sunshine number",
keywords = "Point cloudiness ",
abstract = "Abstract A new method is proposed for extracting the parameters of effective cloud field models from time series of sunshine number (SSN). Data of \{SSN\} number and point cloudiness during 2009 and 2010 at Timisoara (Romania, South Eastern Europe; temperate continental climate) are used to illustrate the method. Two procedures of fitting the estimated point cloudiness to the observed point cloudiness data are proposed and tested. Seven simple effective cloud field models are analyzed. All models underestimate the point cloudiness. The \{MBE\} ranges between − 0.06 and − 0.23 while \{RMSE\} between 0.15 and 0.38, depending on the month and the duration of the \{SSN\} data averaging interval. The best model is based on a field of clouds of semicircle form. This agrees with previous results obtained in the semi-arid climate of Great South Plains in US. The dynamics of the effective cloud field is reconstructed during all months of 2010 at Timisoara. The time series of effective cloud fields are dominated by semicircle clouds but short episodes of semielliptic clouds, ellipsoid clouds, truncated cone clouds and cuboidal clouds are included in the series. "
}
@article{Mollaret201678,
title = "A multi-modal perception based assistive robotic system for the elderly ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "78 - 97",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - 'Assistive Solutions for Mobility, Communication and HMI' ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216000758",
author = "C. Mollaret and A.A. Mekonnen and F. Lerasle and I. Ferrane and J. Pinquier and B. Boudet and P. Rumeau",
keywords = "Assistive technology",
keywords = "Elderly care",
keywords = "Intention detection",
keywords = "Multi-modal data fusion",
keywords = "Human–robot interaction",
keywords = "Robotic perception ",
abstract = "Abstract In this paper, we present a multi-modal perception based framework to realize a non-intrusive domestic assistive robotic system. It is non-intrusive in that it only starts interaction with a user when it detects the user’s intention to do so. All the robot’s actions are based on multi-modal perceptions which include user detection based on RGB-D data, user’s intention-for-interaction detection with RGB-D and audio data, and communication via user distance mediated speech recognition. The utilization of multi-modal cues in different parts of the robotic activity paves the way to successful robotic runs (94% success rate). Each presented perceptual component is systematically evaluated using appropriate dataset and evaluation metrics. Finally the complete system is fully integrated on the \{PR2\} robotic platform and validated through system sanity check runs and user studies with the help of 17 volunteer elderly participants. "
}
@article{Gates2005100,
title = "Our molecular future: how nanotechnology, robotics, genetics and artificial intelligence will transform our world ",
journal = "Futures ",
volume = "37",
number = "1",
pages = "100 - ",
year = "2005",
note = "",
issn = "0016-3287",
doi = "https://doi.org/10.1016/j.futures.2004.03.017",
url = "http://www.sciencedirect.com/science/article/pii/S0016328704000680",
abstract="",
author = "Phil Gates"
}
@article{Sharma201663,
title = "Expanded cloud plumes hiding Big Data ecosystem ",
journal = "Future Generation Computer Systems ",
volume = "59",
number = "",
pages = "63 - 92",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16000054",
author = "Sugam Sharma",
keywords = "Cloud",
keywords = "Big Data",
keywords = "Smart Data and Lakes",
keywords = "IoT",
keywords = "XCLOUDX",
keywords = "as-a-Service ",
abstract = "Abstract Today, a paradigm shift is being observed in science, where the focus is gradually shifting away from operation to data, which is greatly influencing the decision making also. The data is being inundated proactively from several sources in various forms; especially social media and in modern data science vocabulary is being recognized as Big Data. Today, Big Data is permeating through the bigger aspect of human life for scientific and commercial dependencies, especially for massive scale data analytics of beyond the exabyte magnitude. As the footprint of Big Data applications is continuously expanding, the reliability on cloud environments is also increasing to obtain appropriate, robust and affordable services to deal with Big Data challenges. Cloud computing avoids any need to locally maintain the overly scaled computing infrastructure that include not only dedicated space, but the expensive hardware and software also. Several data models to process Big Data are already developed and a number of such models are still emerging, potentially relying on heterogeneous underlying storage technologies, including cloud computing. In this paper, we investigate the growing role of cloud computing in Big Data ecosystem. Also, we propose a novel \{XCLOUDX\} {XCloudX, X…X}classification to zoom in to gauge the intuitiveness of the scientific name of the cloud-assisted NoSQL Big Data models and analyze whether \{XCloudX\} always uses cloud computing underneath or vice versa. \{XCloudX\} symbolizes those NoSQL Big Data models that embody the term “cloud” in their name, where X is any alphanumeric variable. The discussion is strengthen by a set of important case studies. Furthermore, we study the emergence of as-a-Service era, motivated by cloud computing drive and explore the new members beyond traditional cloud computing stack, developed in the past couple of years. "
}
@article{McKee2012455,
title = "Robotic Ecologies for Deep Space Outposts ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "455 - 460",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00183",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336527",
author = "Gerard McKee and Blesson Varghese",
keywords = "robotic ecologies",
keywords = "space robotics",
keywords = "human outposts",
keywords = "networked robotics",
keywords = "self-adaptation",
keywords = "ambient intelligence",
keywords = "multi-agent systems ",
abstract = "Abstract Robotics systems are a recognised part of the human exploration and colonisation of space. Advances in sensor and robotic networks, ambient intelligence and multi-agent systems offer approaches to modelling, implementing and operating robotic ecologies, comprising heterogeneous sets of mobile and embedded robotic devices and sensors, to support space applications, particularly in constructing and maintaining human habitats prior and subsequent to human arrival. This paper proposes a framework for integrating these technologies and techniques. The framework comprises application-level and infrastructure-level components, the former emphasising a model-driven approach supporting cognitive awareness and the latter an autonomic computing approach to self management. The paper provides a first draft of the framework, motivated by a deep space human outpost mission scenario. "
}
@article{Brabec2016136,
title = "A new perspective on the relationship between cloud shade and point cloudiness ",
journal = "Atmospheric Research ",
volume = "172–173",
number = "",
pages = "136 - 146",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S016980951600017X",
author = "Marek Brabec and Viorel Badescu and Marius Paulescu and Alexandru Dumitrescu",
keywords = "Point cloudiness",
keywords = "Cloud shade",
keywords = "Statistical analysis",
keywords = "Semi-parametric modeling ",
abstract = "Abstract Several simple relationships between cloud shade and point cloudiness have been proposed in the last few decades. The present approach is fundamentally different in that it captures some of the hard restrictions dictated by the bounded range (0, 1)of the cloud shade. Three different models are proposed. The main aim is to produce estimates of the whole conditional distribution of the cloud shade for a given point cloudiness value. The beta-inflated model, which takes into account natural physical constraints of the cloud shade, provides the best results. "
}
@article{Alves2012417,
title = "Mobile Robot Control Using a Cloud of Particles ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "417 - 422",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00096",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336461",
author = "Jorge Augusto Vasconcelos Alves and Walter Fetter Lages",
keywords = "Mobile robotics",
keywords = "particle filter",
keywords = "nonlinear control",
keywords = "stochastic control",
keywords = "stochastic estimation ",
abstract = "Abstract Common control systems for mobile robots include the use of deterministic control laws together with state estimation approaches and the consideration of the certainty equivalence principle. Recent approaches consider the use of partially observable Markov decision process strategies together with Bayesian estimators. In order to reduce the required processing power and yet allow for multimodal or non-Gaussian distributions, a scheme based on a particle filter and a corresponding cloud of input signals is proposed in this paper. Results are presented and compared to a scheme with extended Kalman filter and the assumption that the certainty equivalence holds. "
}
@article{Kambezidis2017616,
title = "Meteorological Radiation Model (MRM v6.1): Improvements in diffuse radiation estimates and a new approach for implementation of cloud products ",
journal = "Renewable and Sustainable Energy Reviews ",
volume = "74",
number = "",
pages = "616 - 637",
year = "2017",
note = "",
issn = "1364-0321",
doi = "https://doi.org/10.1016/j.rser.2017.02.058",
url = "http://www.sciencedirect.com/science/article/pii/S1364032117302770",
author = "H.D. Kambezidis and B.E. Psiloglou and D. Karagiannis and U.C. Dumka and D.G. Kaskaoutis",
keywords = "Solar radiation",
keywords = "Models and techniques",
keywords = "Meteorological Radiation Model",
keywords = "Diffuse radiation",
keywords = "MERRA",
keywords = "Model comparison ",
abstract = "Abstract This work reviews techniques and models for solar radiation simulations and communicates further improvements performed in the Meteorological Radiation Model (MRM) developed at the National Observatory of Athens. The new version (MRM v6.1) considers a forward to-the-ground scattering as a function of solar altitude for the diffuse radiation estimates, while concurrently uses two running codes i.e., with sunshine duration as input (MRM v6.1a) and with cloud products (MRM v6.1b). The new scattering function leads to increase in diffuse radiation, especially for low zenith angles, and to better simulations with the measured diffuse (RMSE=36.3% and MBE=6.5%, against RMSE=42.0% and MBE=22.3% for the latest \{MRM\} v6). These changes lead also to better simulations of global radiation (RMSE=8.7% against RMSE=9.5% for \{MRM\} v6), while the direct radiation is not affected. The accuracy in the simulations increases significantly for clear-sky conditions, while it shows a small dependence on aerosol amount and solar altitude. Furthermore, in the sub-version \{MRM\} v6.1b the calculations for the cloud transmittance have been modified to allow for the inclusion of cloud products as inputs in case of non-availability of sunshine duration data. In this study, \{MRM\} v6.1b uses \{MERRA\} retrievals of cloud optical depth and cloud fraction for calculations of the cloud transmittance; these parameters usually lead to significant uncertainties in the simulations of the hourly direct and global radiations, especially for large cloud fractions. This indicates the need for high spatial and temporal resolution satellite data of cloudiness for accurate estimations of solar radiation under cloudy conditions and highlights the incapability of radiative transfer models on such simulations. However, on monthly basis both \{MRM\} v6.1a and v6.1b provide high accuracy in solar radiation estimates, thus rendering \{MRM\} v6.1 as a powerful tool for solar energy applications. "
}
@article{Sreekanth20162104,
title = "Discussion on linear long-term trends in aerosol and cloud properties over India and its surrounding waters ",
journal = "Advances in Space Research ",
volume = "57",
number = "10",
pages = "2104 - 2114",
year = "2016",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2016.02.015",
url = "http://www.sciencedirect.com/science/article/pii/S0273117716001149",
author = "V. Sreekanth",
keywords = "MODIS",
keywords = "Linear trend",
keywords = "Aerosol Optical Depth",
keywords = "Cloud fraction ",
abstract = "Abstract Spatial and seasonal variations in the linear long-term trend estimates of aerosol and cloud properties over Indian subcontinent and the surrounding oceanic regions of Bay of Bengal (BoB) and Arabian Sea (AS) are studied and discussed utilizing 12 complete years (2003–2014) of Moderate Resolution Imaging Spectroradiometer (MODIS) derived Aerosol and cloud products. Annual Aerosol Optical Depth (AOD) trends (in terms of AOD/year) are found to be positive (upward) over most of the study region with a spatial mean (median) value of ∼0.0065 (0.0064) and exhibited significant spatial and seasonal heterogeneity. Over Indian landmass \{AOD\} trends and their statistical significance decreased towards north along the Indo-Gangetic plains (IGP), for which the probable causes are discussed. Same kind of pattern in \{AOD\} trends has been observed as we move deeper into the oceanic regions of BoB and AS, away from Indian subcontinent. Observed trend patterns are discussed in light of the possible increase in emissions (over Indian landmass) and transported aerosol component, co-variation with trends in meteorological parameters and their possible feedbacks. Trend maps in seasonal \{AOD\} are shown to understand the aerosol build up over the study region under varying meteorological conditions. Seasonal \{AOD\} trend patterns resembled the synoptic scale wind circulation over the study region revealing that the upward trend in aerosol abundance over the adjoining oceanic regions of India is a result of effective transport of increasing emissions over India on to them. No significant trends in cloud properties (over the whole study region) are depicted in concert with that of aerosols, except over few pockets. The study also highlighted the role of large scale atmospheric processes in modulating the shape of the \{AOD\} time series over the regions with significant abundance of natural aerosol component (dust). "
}
@article{Xia20165,
title = "Closed-loop design evolution of engineering system using condition monitoring through internet of things and cloud computing ",
journal = "Computer Networks ",
volume = "101",
number = "",
pages = "5 - 18",
year = "2016",
note = "Industrial Technologies and Applications for the Internet of Things ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615005034",
author = "Min Xia and Teng Li and Yunfei Zhang and Clarence W. de Silva",
keywords = "Engineering system design",
keywords = "Design evolution",
keywords = "Multi-domain modeling",
keywords = "Machine condition monitoring",
keywords = "Internet of things",
keywords = "Cloud computing ",
abstract = "Abstract Flexibility of a manufacturing system is quite important and advantageous in modern industry, which function in a competitive environment where market diversity and the need for customized product are growing. Key machinery in a manufacturing system should be reliable, flexible, intelligent, less complex, and cost effective. To achieve these goals, the design methodologies for engineering systems should be revisited and improved. In particular, continuous or on-demand design improvements have to be incorporated rapidly and effectively in order to address new design requirements or resolve potential weaknesses of the original design. Design of an engineering system, which is typically a multi-domain system, can become complicated due to its complex structure and possible dynamic coupling between domains. An integrated and concurrent approach should be considered in the design process, in particular in the conceptual and detailed design phases. In the context of multi-domain design, attention has been given recently to such subjects as multi-criteria decision making, multi-domain modeling, evolutionary computing, and genetic programing. More recently, machine condition monitoring has been considered for integration into a scheme of design evolution even though many challenges exist for this to become a reality such as lack of systematic approaches and the existence of technical barriers in massive condition data acquisition, transmission, storage and mining. Recently, the internet of things (IoT) and cloud computing (CC) are being developed quickly and they offer new opportunities for evolutionary design for such tasks as data acquisition, storage and processing. In this paper, a framework for the closed-loop design evolution of engineering systems is proposed in order to achieve continuous design improvement for an engineering system through the use of a machine condition monitoring system assisted by IoT and CC. New design requirements or the detection of design weaknesses of an existing engineering system can be addressed through the proposed framework. A design knowledge base that is constructed by integrating design expertise from domain experts, on-line process information from condition monitoring and other design information from various sources is proposed to realize and supervise the design process so as to achieve increased efficiency, design speed, and effectiveness. The framework developed in this paper is illustrated by using a case study of design evolution of an industrial manufacturing system. "
}
@article{Chen2017144,
title = "A nonlinearly normalized back propagation network and cloud computing approach for determining cycle time allowance during wafer fabrication ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "144 - 156",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S073658451500143X",
author = "Toly Chen and Yi-Chi Wang",
keywords = "Internal due date assignment",
keywords = "Allowance determination",
keywords = "Upper bound",
keywords = "Wafer fabrication",
keywords = "Back propagation network ",
abstract = "Abstract This study investigated the determination of the allowance that must be added to the cycle time estimate, which is a critical concern when assigning internal due dates. Because no method for estimating cycle times is completely accurate, producing such estimates remains problematic but has rarely been addressed in the literature. A large allowance postpones the internal due date, diminishing company appeal when a factory manager negotiates with a customer. Therefore, in this study, a nonlinear approach was proposed to normalize the cycle times. After estimating the cycle time of a job by using a back propagation network, the allowance added to the cycle time can be effectively reduced through the collaboration of several computing clouds. Theoretical properties of the proposed method were validated, and a case from a wafer fabrication factory was used to evaluate the effectiveness of the proposed method in comparison with various existing methods. According to the experimental results, the proposed method facilitated establishing tight upper bounds on the cycle times. The proposed method was proven to be very effective. "
}
@article{Xiao201538,
title = "Street environment change detection from mobile laser scanning point clouds ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "107",
number = "",
pages = "38 - 49",
year = "2015",
note = "Multitemporal remote sensing data analysis ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001215",
author = "Wen Xiao and Bruno Vallet and Mathieu Bredif and Nicolas Paparoditis",
keywords = "Change detection",
keywords = "Lidar",
keywords = "K-d tree",
keywords = "Occupancy grids",
keywords = "Point-to-triangle distance",
keywords = "Dempster–Shafer theory ",
abstract = "Abstract Mobile laser scanning (MLS) has become a popular technique for road inventory, building modelling, infrastructure management, mobility assessment, etc. Meanwhile, due to the high mobility of \{MLS\} systems, it is easy to revisit interested areas. However, change detection using \{MLS\} data of street environment has seldom been studied. In this paper, an approach that combines occupancy grids and a distance-based method for change detection from \{MLS\} point clouds is proposed. Unlike conventional occupancy grids, our occupancy-based method models space based on scanning rays and local point distributions in 3D without voxelization. A local cylindrical reference frame is presented for the interpolation of occupancy between rays according to the scanning geometry. The Dempster–Shafer theory (DST) is utilized for both intra-data evidence fusion and inter-data consistency assessment. Occupancy of reference point cloud is fused at the location of target points and then the consistency is evaluated directly on the points. A point-to-triangle (PTT) distance-based method is combined to improve the occupancy-based method. Because it is robust to penetrable objects, e.g. vegetation, which cause self-conflicts when modelling occupancy. The combined method tackles irregular point density and occlusion problems, also eliminates false detections on penetrable objects. "
}
@article{Chen201642,
title = "Estimating simulation workload in cloud manufacturing using a classifying artificial neural network ensemble approach ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "38",
number = "",
pages = "42 - 51",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000964",
author = "Toly Chen and Yu-Cheng Wang",
keywords = "Cloud manufacturing",
keywords = "Simulation",
keywords = "k-means",
keywords = "Artificial neural network",
keywords = "Ensemble",
keywords = "Workload estimation ",
abstract = "Abstract Cloud manufacturing (CMfg) is an extension of cloud computing in the manufacturing sector. The \{CMfg\} concept of simulating a factory online by using Web services is a topic of interest. To distribute a simulation workload evenly among simulation clouds, a simulation task is typically decomposed into small parts that are simultaneously processed. Therefore, the time required to complete a simulation task must be estimated in advance. However, this topic is seldom discussed. In this paper, a classifying artificial neural network (ANN) ensemble approach is proposed for estimating the required time for a simulation task. In the proposed methodology, simulation tasks are classified using k-means before their simulation times are estimated. Subsequently, for each task category, an \{ANN\} is constructed to estimate the required task time in the category. However, to reduce the impact of \{ANN\} overfitting, the required time for each simulation task is estimated using the \{ANNs\} of all categories, and the estimation results are then weighted and summed. Thus, the \{ANNs\} form an ensemble. In addition to the proposed methodology, six statistical and soft computing methods were applied in real tasks. According to the experimental results, compared with the six existing methods, the proposed methodology reduced the estimation time considerably. In addition, this advantage was statistically significant according to the results of the paired t test. "
}
@article{GarciaLuna2016365,
title = "Towards an artificial vision-robotic system for tomato identification ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "365 - 370",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.067",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316305",
author = "F. Garcia-Luna and A. Morales-Diaz",
keywords = "Artificial vision",
keywords = "fruit detection",
keywords = "fruit localization",
keywords = "robotic system ",
abstract = "Abstract: In the present paper we developed a simple and affordable vision-based robotic system for the identification of the Euclidean position of red spheres that emulate ripe tomatoes. This is done by using a RGB-D sensor in a fixed position, together with a 5 \{DOF\} manipulator. To detect the tomato the sensor considers it as a red blob and then it calculates its center using a point cloud map. The position of the red blob is mapped to the manipulator reference frame using the homogeneous transformation matrix from the camera to the manipulator. The position of the sphere is sent through a micro-controller to drive the manipulator, with the purpose of reaching the sphere’s position. Experimental results of the vision-based robotic system are provided, and the system accuracy obtained in localizing and touching the interest object demonstrate to be highly effective, reaching an accuracy of 10/10 in identification and touching the object in ideal environment. "
}
@article{Mourad201630,
title = "Interoperability as a Key Enabler for Manufacturing in the Cloud ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "30 - 34",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.051",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116308010",
author = "M. Mourad and A. Nassehi and D. Schaefer",
keywords = "Cloud manufacturing",
keywords = "Interoperability",
keywords = "Manufacturing as a service (MaaS) ",
abstract = "Abstract The emerging cloud paradigm has a prominent effect on manufacturing. The move from hardware bound systems to requirements based service provision is enabling the transition to cloud manufacturing. A networked manufacturing service provision system requires vast amounts of information to be exchanged in a non-ambiguous and timely manner to meet production requirements. In this paper, interoperability is identified as a key enabler for cloud manufacturing and a framework for realisation of interoperability across heterogeneous computer aided manufacturing systems is proposed. Using this framework, manufacturing resources can be shared by a large number of clients based on requirements and priorities. "
}
@article{Fehr201680,
title = "Covariance based point cloud descriptors for object detection and recognition ",
journal = "Computer Vision and Image Understanding ",
volume = "142",
number = "",
pages = "80 - 93",
year = "2016",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215001368",
author = "Duc Fehr and William J. Beksi and Dimitris Zermas and Nikolaos Papanikolopoulos",
keywords = "RGB-D data",
keywords = "Colored point clouds",
keywords = "Classification",
keywords = "Object recognition ",
abstract = "Abstract Processing 3D point cloud data is of primary interest in many areas of computer vision, including object grasping, robot navigation, and object recognition. The introduction of affordable RGB-D sensors has created a great interest in the computer vision community towards developing efficient algorithms for point cloud processing. Previously, capturing a point cloud required expensive specialized sensors such as lasers or dedicated range imaging devices; now, range data is readily available from low-cost sensors that provide easily extractable point clouds from a depth map. From here, an interesting challenge is to find different objects in the point cloud. Various descriptors have been introduced to match features in a point cloud. Cheap sensors are not necessarily designed to produce precise measurements, which means that the data is not as accurate as a point cloud provided from a laser or a dedicated range finder. Although some feature descriptors have been shown to be successful in recognizing objects from point clouds, there still exists opportunities for improvement. The aim of this paper is to introduce techniques from other fields, such as image processing, into 3D point cloud processing in order to improve rendering, classification, and recognition. Covariances have proven to be a success not only in image processing, but in other domains as well. This work develops the application of covariances in conjunction with 3D point cloud data. "
}
@article{Arrouk2016302,
title = "CAD-based unified graphical methodology for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "37",
number = "",
pages = "302 - 321",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000447",
author = "Khaled Assad Arrouk and Belhassen Chedli Bouzgarrou and Grigore Gogu",
keywords = "Planar parallel robotic manipulator (PPRM)",
keywords = "Computer-Aided Design techniques",
keywords = "3D total workspace",
keywords = "Forward kinematic problem (FKP)",
keywords = "Singularity-free trajectory planning ",
abstract = "Abstract \{CAD\} environments provide powerful tools for graphical programming and geometric feature handling. This paper explores this potential for robotics applications by presenting a set of several original approaches for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators (PPRMs). These approaches rely on the use of CAD-based graphical programming enabling rapid resolution and geometric interpretation of the 3D total workspace characteristics. The novelty of the proposed approach resides in the association of an original, unique and natural 3D graphical representation of the end-effector poses and the use of geometric feature handling and graphical solver capabilities within a \{CAD\} environment, for determining the 3D total operational workspace as well as solving the forward kinematic problem (FKP) of PPRMs. The approach consists in considering the mobile platform separately attached to each limb that we disconnect from the rest of the mechanism. The geometric construction of the spaces reachable by the end-effector is performed by using Boolean intersections of the vertex volumes, respectively the vertex surfaces, relative to each limb for 3D total workspace determination, respectively for \{FKP\} resolution. By combining in the same 3D graphical environment several geometric entities associated to the PPRM, such as workspace volume, singularity surface, and the different solutions of the FKP, this approach allows designers, in a user-friendly way, to generate the singularity-free trajectories connecting different assembly modes. The approach presented in this paper is mostly useful for the architectures of 3-DOF parallel robotic manipulators for which an algebraic closed form solution does not exist for the forward kinematic model and the singularity-free trajectory planning between assembly modes is not a trivial task. It is applied for several \{PPRMs\} such as: 3-RPR, 3-RRR, 3-PPR, 3-RRP, 3-PRP, 3-PRR, 3-RRR, and 3-RPR. "
}
@article{Adamson2016644,
title = "A Cloud Service Control Approach for Distributed and Adaptive Equipment Control in Cloud Environments ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "644 - 649",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.020",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115010999",
author = "Goran Adamson and Magnus Holm and Philip Moore and Lihui Wang",
keywords = "Adaptive control",
keywords = "Adaptive manufacturing",
keywords = "Cloud manufacturing ",
abstract = "Abstract A developing trend within the manufacturing shop-floor domain is the move of manufacturing activities into cloud environments, as scalable, on-demand and pay-per-usage cloud services. This will radically change traditional manufacturing, as borderless, distributed and collaborative manufacturing missions between volatile, best suited groups of partners will impose a multitude of advantages. The evolving Cloud Manufacturing (CM) paradigm will enable this new manufacturing concept, and on-going research has described many of its anticipated core virtues and enabling technologies. However, a major key enabling technology within \{CM\} which has not yet been fully addressed is the dynamic and distributed planning, control and execution of scattered and cooperating shop-floor equipment, completing joint manufacturing tasks. In this paper, the technological perspective for a cloud service-based control approach is described, and how it could be implemented. Existing manufacturing resources, such as soft, hard and capability resources, can be packaged as cloud services, and combined to create different levels of equipment or manufacturing control, ranging from low-level control of single machines or devices (e.g. Robot Control-as-a-Service), up to the execution of high level multi-process manufacturing tasks (e.g. Manufacturing-as-a-Service). A multi-layer control approach, featuring adaptive decision-making for both global and local environmental conditions, is proposed. This is realized through the use of a network of intelligent and distributable decision modules such as event-driven Function Blocks, enabling run-time manufacturing activities to be performed according to actual manufacturing conditions. The control system's integration to the \{CM\} cloud service management functionality is also described. "
}
@article{Pop201679,
title = "ARMCO: Advanced topics in resource management for ubiquitous cloud computing: An adaptive approach ",
journal = "Future Generation Computer Systems ",
volume = "54",
number = "",
pages = "79 - 81",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15002484",
author = "Florin Pop and Maria Potop-Butucaru",
keywords = "Resource management",
keywords = "Task scheduling",
keywords = "Adaptive methods",
keywords = "Cloud computing",
keywords = "Ubiquitous systems ",
abstract = "Abstract Cloud Computing can be seen as one of the latest major evolution in computing offering unlimited possibility to use \{ICT\} in various domains: business, smart cities, medicine, environmental computing, mobile systems, design and implementation of cyber-infrastructures. The recent expansion of Cloud Systems has led to adapting resource management solutions for large number of wide distributed and heterogeneous datacenters. The adaptive methods used in this context are oriented on: self-stabilizing, self-organizing and autonomic systems; dynamic, adaptive and machine learning based distributed algorithms; fault tolerance, reliability, availability of distributed systems. The pay-per-use economic model of Cloud Computing comes with a new challenge: maximizing the profit for service providers, minimizing the total cost for customers and being friendly with the environment. This special issue presents advances in virtual machine assignment and placement, multi-objective and multi-constraints job scheduling, resource management in federated Clouds and in heterogeneous environments, dynamic topology for data distribution, workflow performance improvement, energy efficiency techniques and assurance of Service Level Agreements. "
}
@article{Casas2016a,
title = "A balanced scheduler with data reuse and replication for scientific workflows in cloud computing systems ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X1500388X",
author = "Israel Casas and Javid Taheri and Rajiv Ranjan and Lizhe Wang and Albert Y. Zomaya",
keywords = "Cloud computing",
keywords = "Scientific workflow",
keywords = "Scheduling",
keywords = "Virtual machine",
keywords = "Data-intensive computing",
keywords = "Big data ",
abstract = "Abstract Cloud computing provides substantial opportunities to researchers who demand pay-as-you-go computing systems. Although cloud provider (e.g., Amazon Web Services) and application provider (e.g., biologists, physicists, and online gaming companies) both have specific performance requirements (e.g. application response time), it is the cloud scheduler’s responsibility to map the application to underlying cloud resources. This article presents a Balanced and file Reuse–Replication Scheduling (BaRRS) algorithm for cloud computing environments to optimally schedule scientific application workflows. BaRRS splits scientific workflows into multiple sub-workflows to balance system utilization via parallelization. It also exploits data reuse and replication techniques to optimize the amount of data that needs to be transferred among tasks at run-time. BaRRS analyzes the key application features (e.g., task execution times, dependency patterns and file sizes) of scientific workflows for adapting existing data reuse and replication techniques to cloud systems. Further, BaRRS performs a trade-off analysis to select the optimal solution based on two optimization constraints: execution time and monetary cost of running scientific workflows. BaRRS is compared with a state-of-the-art scheduling approach; experiments prove its superior performance. Experiments include four well known scientific workflows with different dependency patterns and data file sizes. Results were promising and also highlighted most critical factors affecting execution of scientific applications on clouds. "
}
@article{Liu20161101,
title = "Detection based object labeling of 3D point cloud for indoor scenes ",
journal = "Neurocomputing ",
volume = "174, Part B",
number = "",
pages = "1101 - 1106",
year = "2016",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215014617",
author = "Wei Liu and Shaozi Li and Donglin Cao and Songzhi Su and Rongrong Ji",
keywords = "Point cloud",
keywords = "Labeling",
keywords = "Object detection",
keywords = "RGB-D ",
abstract = "Abstract While much exciting progress is being made in 3D reconstruction of scenes, object labeling of 3D point cloud for indoor scenes has been left as a challenge issue. How should we explore the reference images of 3D scene, in aid of scene parsing? In this paper, we propose a framework for 3D indoor scenes labeling, based upon object detection on the RGB-D frames of 3D scene. First, the point cloud is segmented into homogeneous segments. Then, we utilize object detectors to assign class probabilities to pixels in every RGB-D frame. After that, the class probabilities are projected into the segments. Finally, we perform accurate inference on a \{MRF\} model over the homogeneous segments, in combination with geometry cues to output the labels. Experiment on the challenging RGB-D Object Dataset demonstrates that our detection based approach produces accurate labeling and improves the robustness of small object detection for indoor scenes. "
}
@article{Ingrand201710,
title = "Deliberation for autonomous robots: A survey ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "10 - 44",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2014.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0004370214001350",
author = "Felix Ingrand and Malik Ghallab",
keywords = "Robotics",
keywords = "Deliberation",
keywords = "Planning",
keywords = "Acting",
keywords = "Monitoring",
keywords = "Observing",
keywords = "Learning ",
abstract = "Abstract Autonomous robots facing a diversity of open environments and performing a variety of tasks and interactions need explicit deliberation in order to fulfill their missions. Deliberation is meant to endow a robotic system with extended, more adaptable and robust functionalities, as well as reduce its deployment cost. The ambition of this survey is to present a global overview of deliberation functions in robotics and to discuss the state of the art in this area. The following five deliberation functions are identified and analyzed: planning, acting, monitoring, observing, and learning. The paper introduces a global perspective on these deliberation functions and discusses their main characteristics, design choices and constraints. The reviewed contributions are discussed with respect to this perspective. The survey focuses as much as possible on papers with a clear robotics content and with a concern on integrating several deliberation functions. "
}
@article{Tapoglou2016661,
title = "Cloud-based Job Dispatching Using Multi-criteria Decision Making ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "661 - 666",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.081",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115011609",
author = "Nikolaos Tapoglou and Jorn Mehnen",
keywords = "Job allocation",
keywords = "Cloud manufacturing",
keywords = "Multi criteria decision making ",
abstract = "Abstract The dynamic nature of modern workshops and the change in availability of manufacturing equipment affects the allocation of manufacturing jobs. In order to cope with these requirements a module that ranks manufacturing equipment and proposes the best fitted machine to perform a specific manufacturing task according to capabilities, availability and suitability is needed. This paper presents such a framework for allocating tasks to manufacturing equipment according to the capabilities, the availability and the running cost of the manufacturing equipment. The decisions are made by using a multi-criteria decision making tool running in a Cloud environment with data being fed through web based protocols. The novelty of the proposed system lies in the fact that the solution is based on a Cloud Manufacturing environment and the selection process is based on the latest information regarding the machine tool data, received through a web interface. The functionality of the module is illustrated through a case study. "
}
@article{Schauer201654,
title = "Performance comparison between state-of-the-art point-cloud based collision detection approaches on the \{CPU\} and \{GPU\} ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "54 - 59",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.125",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325630",
author = "Johannes Schauer and Janusz Bedkowski and Karol Majek and Andreas Nuchter",
keywords = "k-d tree",
keywords = "CUDA",
keywords = "parallel algorithms",
keywords = "3D point clouds",
keywords = "regular grid decompositio ",
abstract = "Abstract: We present two fundamentally different approaches to detect collisions between two point clouds and compare their performance on multiple datasets. A collision between points happens if they are closer to each other than a given threshold radius. One approach utilizes the main \{CPU\} with a k-d tree datastructure to efficiently carry out fixed range searches around points in 3D while the other mainly executes on a \{GPU\} using a regular grid decomposition technique implemented in the \{CUDA\} framework. We will show how massively parallel 3D range searches on a grid based datastructure on a \{GPU\} performs similarly well as a tree based approach on the \{CPU\} with orders of magnitude less parallelization. We also show how each method scales with varying input sizes and how they perform differently well depending on the spatial structure of the input data. "
}
@incollection{Chaulya2016351,
title = "Chapter 7 - Application of Cloud Computing Technology in Mining Industry ",
editor = "Chaulya, S.K.  and Prasad, G.M. ",
booktitle = "Sensing and Monitoring Technologies for Mines and Hazardous Areas ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "351 - 396",
isbn = "978-0-12-803194-0",
doi = "https://doi.org/10.1016/B978-0-12-803194-0.00007-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128031940000076",
author = "S.K. Chaulya and G.M. Prasad",
keywords = "Cloud system",
keywords = "Mine automation",
keywords = "Safety management",
keywords = "Asset management",
keywords = "Knowledge sharing ",
abstract = "Abstract A cloud computing system, which is the latest version of computing models available, has practically revolutionized the information technology. It distinguishes itself from other computing paradigms due to its unique characteristics, such as the ability to handle massive data, the power of virtualization, scalability, elasticity, agility, resource pooling capability, and dependable security. Moreover, it is very cost effective and can be useful for individual as well as industries. The mining industry, which is facing several challenges of varied complexities, can reap the benefits of this technology in different areas such as mine automation, knowledge sharing, process improvement, safety management, equipment condition monitoring, environmental impact assessment and management, environmental modeling, tracking of miners and moveable mining machinery, asset management, efficiency improvement in all facets of mining activities, and remote operations. Cloud computing technology, which within its short term of only few years has already shown potential for turning to be a major driver of growth for several industries, can help by enhancing production, increasing safety and bringing economic benefits to mining industry. "
}
@article{Mourtzis2016655,
title = "A Cloud-based Approach for Maintenance of Machine Tools and Equipment Based on Shop-floor Monitoring ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "655 - 660",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.069",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115011488",
author = "Dimitris Mourtzis and Ekaterini Vlachou and Nikolaos Milas and Nikitas Xanthopoulos",
keywords = "Monitoring",
keywords = "Maintenance",
keywords = "Cloud manufacturing ",
abstract = "Abstract Maintenance and its cost continue, over the years, to draw the attention of production management since the unplanned failures decrease the reliability of the system and also the return of investments. Advanced maintenance techniques that capture and process shop-floor information can reduce costs and increase the sustainability of an enterprise. This paper presents a condition-based preventive maintenance approach integrated into a machine monitoring framework. The latter acquires data from shop-floor machine tools and analyses them through an information fusion technique to support the condition-based preventive maintenance operations. The proposed approach is developed into a software service, deployed on a Cloud environment. The service gathers and processes data, such as their actual processing time and machining time per tool, related to the operation of machine tools and equipment and calculates the expected remaining useful life of components. Moreover, it provides notifications to machine tool operators and maintenance departments, as well as it enables the communication among them using mobile technology. The framework is applied to a case study with data obtained from a machining SME. "
}
@article{Saab201538,
title = "Partial mobile application offloading to the cloud for energy-efficiency with security measures ",
journal = "Sustainable Computing: Informatics and Systems ",
volume = "8",
number = "",
pages = "38 - 46",
year = "2015",
note = "Special Issue on Computing for a Greener Water/Energy/Emissions Nexus; edited by Carol J. Miller.andSpecial Issue on Green Mobile Cloud Computing (Green MCC); edited by Danielo G. Gomes, Rafael Tolosana-Calasanz, and Nazim Agoulmine. ",
issn = "2210-5379",
doi = "https://doi.org/10.1016/j.suscom.2015.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S2210537915000396",
author = "Salwa Adriana Saab and Farah Saab and Ayman Kayssi and Ali Chehab and Imad H. Elhajj",
keywords = "Offloading",
keywords = "Mobile cloud computing",
keywords = "Free sequence protocol",
keywords = "Energy efficiency",
keywords = "Power consumption ",
abstract = "Abstract Mobile applications are becoming computationally intensive nowadays due to the increasing convenience, reliance on, and sophistication of smartphones. Nevertheless, battery lifetime remains a major obstacle that prohibits the large-scale adoption of such apps. Mobile cloud computing is a promising solution whereby apps are partially processed in the cloud to minimize the overall energy consumption of smartphones. However, this will not necessarily save energy if there is no systematic mechanism to evaluate the effect of offloading an app onto the cloud. In this paper, we present a mathematical model that represents this energy consumption optimization problem. We propose an algorithm to dynamically solve the problem while taking security measures into account. We also propose the free sequence protocol (FSP) that allows for the dynamic execution of apps according to their call graph. Our experimental setup consists of an Android smartphone and a Java server in the cloud. The results demonstrate that our approach saves battery lifetime and enhances performance. They also show the effects of workload amount, network type, computation cost, security operations, signal strength, and call graph structure on the optimized overall energy consumption. "
}
@article{Brant2015478,
title = "A novel system for cloud-based micro additive manufacturing of metal structures ",
journal = "Journal of Manufacturing Processes ",
volume = "20, Part 3",
number = "",
pages = "478 - 484",
year = "2015",
note = "Additive Manufacturing ",
issn = "1526-6125",
doi = "https://doi.org/10.1016/j.jmapro.2015.06.020",
url = "http://www.sciencedirect.com/science/article/pii/S1526612515000651",
author = "Anne Brant and Murali M. Sundaram",
keywords = "Cloud-manufacturing",
keywords = "Additive manufacturing",
keywords = "Electrochemical deposition ",
abstract = "Abstract Cloud-based computing holds enormous potential for collaboration, cost-saving, streamlining, and versatility of manufacturing. Additive manufacturing, being a computer-based system that can save point-by-point data of parts to be manufactured, can be easily integrated into the cloud. Preliminary work was done to test the cloud-based application of an in-house micro metal additive manufacturing by electrochemical deposition process. The system was linked to commercial cloud and email access for constant real-time communication from any user with a phone, tablet, or personal computer. The process could be started, stopped, altered, and queried remotely via the cloud. Input parameters (i.e.: geometry, tool size) and preliminary design rules (i.e.: current feedback threshold value) were specified. Plots of output performance, time, and current information were communicated back to the user on-demand, as well as stored on the cloud long-term. The cloud could then link input parameters to the history of system performance on such input parameters in a cloud-stored database. An experiment was set up to optimize horizontal deposition parameters based on deposition resolution, and save these values into the cloud for future use, The experiment was successfully executed and demonstrates the advantage of long-term storage, knowledge sharing, and convenience that the cloud offers for the manufacturing realm. "
}
@article{Deshmukh20161075,
title = "Kinematic Modeling of an Automated Laser Line Point Cloud Scanning System ",
journal = "Procedia Manufacturing ",
volume = "5",
number = "",
pages = "1075 - 1091",
year = "2016",
note = "44th North American Manufacturing Research Conference, \{NAMRC\} 44, June 27-July 1, 2016, Blacksburg, Virginia, United States ",
issn = "2351-9789",
doi = "https://doi.org/10.1016/j.promfg.2016.08.078",
url = "http://www.sciencedirect.com/science/article/pii/S2351978916300907",
author = "Kiran Deshmukh and Jeremy L. Rickli and Ana Djuric",
keywords = "automated scanning",
keywords = "point clouds",
keywords = "laser-line scanner",
keywords = "mechanical linkages ",
abstract = "Abstract This paper describes the geometric transformation of coordinates in the elements of an automated laser line scanning system caused by movements required for scanning a component surface. The automated scanning system elements are a laser line scanner mounted on a robot arm or a probe tip with coordinate measuring machine. A major challenge is determining the kinematic relationship between the elements of an automated laser scanning system that functions as a mechanical linkage in order to obtain a trajectory for scanning a surface. This paper solves the forward kinematic equations to get the validation pose for the elements of the system, derives the equation of component surface considering a spherical component, and uses inverse kinematics to characterize the movement of the entire automated scanning system on the point trajectory. The result is the position and orientation matrix for the laser line scanner beam and its movement on the trajectory in relation to a component surface. This kinematic chain of linkages and the obtained poses of point trajectory on the component surface is a starting point for future work that aims to develop optimal scan paths that can collect “best” point cloud datasets. The outcomes of this work contribute to enhancing the use of laser line scanners for inspection of component surfaces in manufacturing, remanufacturing, and reverse engineering applications. "
}
@article{Tao201648,
title = "Impact of transpacific aerosol on air quality over the United States: A perspective from aerosol–cloud–radiation interactions ",
journal = "Atmospheric Environment ",
volume = "125, Part A",
number = "",
pages = "48 - 60",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.10.083",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015304994",
author = "Zhining Tao and Hongbin Yu and Mian Chin",
keywords = "Transpacific aerosol",
keywords = "Aerosol–cloud–radiation interactions",
keywords = "NU-WRF",
keywords = "U.S. air quality ",
abstract = "Abstract Observations have well established that aerosols from various sources in Asia, Europe, and Africa can travel across the Pacific and reach the contiguous United States (U.S.) at least on episodic bases throughout a year, with a maximum import in spring. The imported aerosol not only can serve as an additional source to regional air pollution (e.g., direct input), but also can influence regional air quality through the aerosol–cloud–radiation (ACR) interactions that change local and regional meteorology. This study assessed impacts of the transpacific aerosol on air quality, focusing on surface ozone and PM2.5, over the U.S. using the \{NASA\} Unified Weather Research Forecast model. Based on the results of 3-month (April to June of 2010) simulations, the impact of direct input (as an additional source) of transpacific aerosol caused an increase of surface PM2.5 concentration by approximately 1.5 µg m−3 over the west coast and about 0.5 µg m−3 over the east coast of the U.S. By influencing key meteorological processes through the \{ACR\} interactions, the transpacific aerosol exerted a significant effect on both surface PM2.5 (±6 µg m−3) and ozone (±12 ppbv) over the central and eastern U.S. This suggests that the transpacific transport of aerosol could either improve or deteriorate local air quality and complicate local effort toward the compliance with the U.S. National Ambient Air Quality Standards. "
}
@article{Hely201773,
title = "Feasibility study of robotic fibre placement on intersecting multi-axial revolution surfaces ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "73 - 79",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301661",
author = "Clement Hely and Lionel Birglen and Wen-Fang Xie",
keywords = "Automated fibre placement",
keywords = "Path planning",
keywords = "Multi-axial closed surfaces ",
abstract = "Abstract In this paper, the first steps towards using a robotic workcell for the automated fibre placement (AFP) manufacturing of Y-shaped tubes are proposed. The proposed workcell is constituted of a standard serial manipulator holding the fibre placement toolhead combined to a rotary table on which the part where the fibres must be laid out is attached. The investigations carried out in this work explore the feasibility of this setup and more precisely the path planning aspect. To this aim two novel path planning algorithms are presented generalizing the techniques proposed in the literature for open-contoured and cylindrical surfaces. In the first, the maximal geodesic curvature typically allowed in \{AFP\} is disregarded to generate continuous paths with a constant placement angle on the branches without any gaps or overlaps. Subsequently, a second algorithm, taking into account this curvature constraint, is presented. These algorithms were implemented in a software using the MATLAB™ suite. Finally, an algorithm to optimize the motion of the robotic system is presented and simulations are discussed. "
}
@article{Sutherland20111262,
title = "Posterior Rhabdosphincter Reconstruction During Robotic Assisted Radical Prostatectomy: Results From a Phase \{II\} Randomized Clinical Trial ",
journal = "The Journal of Urology ",
volume = "185",
number = "4",
pages = "1262 - 1267",
year = "2011",
note = "",
issn = "0022-5347",
doi = "https://doi.org/10.1016/j.juro.2010.11.085",
url = "http://www.sciencedirect.com/science/article/pii/S0022534710051967",
author = "Douglas E. Sutherland and Brian Linder and Anna M. Guzman and Mark Hong and Harold A. Frazier II and Jason D. Engel and Fernando J. Bianco Jr.",
keywords = "prostatic neoplasms",
keywords = "prostatectomy",
keywords = "treatment outcome",
keywords = "urinary incontinence",
keywords = "robotics ",
abstract = "Purpose Posterior rhabdosphincter reconstruction following radical prostatectomy was designed to improve early urinary continence. We executed a randomized clinical trial to test this conjecture in men undergoing robotic radical prostatectomy. Materials and Methods We conducted a phase \{II\} randomized clinical trial intended to detect a 25% difference in 3-month continence outcomes defined by a patient response of 0 or 1 to question 5 of the Expanded Prostate Cancer Index Composite questionnaire urinary domain, comparing standard running vesicourethral anastomosis (controls) to posterior rhabdosphincter reconstruction followed by standard running vesicourethral anastomosis (posterior rhabdosphincter reconstruction treated). Patients had clinically localized prostate cancer and were blinded. Surgeons were notified of computer randomization after prostate excision. Further continence outcomes were assessed by analysis of Expanded Prostate Cancer Index Composite questionnaire questions 1 and 12, International Prostate Symptom Score and 24-hour pad weights. Statistical significance was defined as p &lt;0.05 Results A total of 94 patients were randomized, 47 to each arm. Preoperative clinical and functional variables were equivalent between study arms. There were no complications associated with either anastomotic technique. Of the 87 evaluable patients 62 (71.3%) met our 3-month continence definition. The null hypothesis was not rejected as 33 (81%) controls and 29 (63%) posterior rhabdosphincter reconstruction treated patients were continent at 3 months (chi-square p = 0.07, Fisher exact p = 0.1). Likewise there was no significant difference between arms in 24-hour pad weights (p = 0.14), International Prostate Symptom Score (p = 0.4), absence of daily leaks (p = 0.4) or perception of urinary function (p = 0.4). Conclusions In this randomized clinical trial posterior rhabdosphincter reconstruction offered no advantage for return of early continence after robotic assisted radical prostatectomy. "
}
@article{skraba2015819,
title = "Speech-controlled cloud-based wheelchair platform for disabled persons ",
journal = "Microprocessors and Microsystems ",
volume = "39",
number = "8",
pages = "819 - 828",
year = "2015",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001581",
author = "Andrej skraba and Radovan Stojanovic and Anton Zupan and Andrej Koložvari and Davorin Kofjac",
keywords = "Cyber-physical system",
keywords = "Internet of things",
keywords = "Computer cloud, HTML5",
keywords = "JavaScript",
keywords = "ECMA Script",
keywords = "speech recognition",
keywords = "Devices for rehabilitation",
keywords = "Wheelchair",
keywords = "Node.js ",
abstract = "Abstract This paper describes the development of a prototype speech-controlled cloud-based wheelchair platform. The control of the platform is implemented using a low-cost WebKit Speech \{API\} in the cloud. The description of the cloud-based wheelchair control system is provided. In addition to the voice control, a \{GUI\} is implemented, which works in a web browser as well as on mobile devices providing live video streaming. Development was done in two phases: first, a small, initial prototype was developed and, second, a full size prototype was build. The accuracy of the speech recognition system was estimated as ranging from approximately 60% to up to 97%, dependent on the speaker. The speech-controlled system latency was measured as well as the latency when the control is provided via touch on a so-called smart device. Measured latencies ranged from 0.4 s to 1.3 s. The platform was also clinically tested, providing promising results of cloud-based speech recognition for further implementation. The developed platform is based on a Quad Core \{ARM\} Mini \{PC\} \{GK802\} running Ubuntu Linux and an Arduino \{UNO\} Microcontroller. Software development was done in JavaScript/ECMA Script, applying node.js. "
}
@article{Lim201561,
title = "Point cloud modeling using the homogeneous transformation for non-cooperative pose estimation ",
journal = "Acta Astronautica ",
volume = "111",
number = "",
pages = "61 - 76",
year = "2015",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515000429",
author = "Tae W. Lim",
keywords = "Non-cooperative pose estimation",
keywords = "Homogeneous transformation",
keywords = "Point cloud modeling",
keywords = "Flash lidar",
keywords = "Proximity operation ",
abstract = "Abstract A modeling process to simulate point cloud range data that a lidar (light detection and ranging) sensor produces is presented in this paper in order to support the development of non-cooperative pose (relative attitude and position) estimation approaches which will help improve proximity operation capabilities between two adjacent vehicles. The algorithms in the modeling process were based on the homogeneous transformation, which has been employed extensively in robotics and computer graphics, as well as in recently developed pose estimation algorithms. Using a flash lidar in a laboratory testing environment, point cloud data of a test article was simulated and compared against the measured point cloud data. The simulated and measured data sets match closely, validating the modeling process. The modeling capability enables close examination of the characteristics of point cloud images of an object as it undergoes various translational and rotational motions. Relevant characteristics that will be crucial in non-cooperative pose estimation were identified such as shift, shadowing, perspective projection, jagged edges, and differential point cloud density. These characteristics will have to be considered in developing effective non-cooperative pose estimation algorithms. The modeling capability will allow extensive non-cooperative pose estimation performance simulations prior to field testing, saving development cost and providing performance metrics of the pose estimation concepts and algorithms under evaluation. The modeling process also provides “truth” pose of the test objects with respect to the sensor frame so that the pose estimation error can be quantified. "
}
@article{Whelan20153,
title = "Incremental and batch planar simplification of dense point cloud maps ",
journal = "Robotics and Autonomous Systems ",
volume = "69",
number = "",
pages = "3 - 14",
year = "2015",
note = "Selected papers from 6th European Conference on Mobile Robots ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.08.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001961",
author = "T. Whelan and L. Ma and E. Bondarev and P.H.N. de With and J. McDonald",
keywords = "Planar simplification",
keywords = "Point clouds",
keywords = "Mapping",
keywords = "Plane segmentation",
keywords = "Triangulation",
keywords = "Incremental ",
abstract = "Abstract Dense RGB-D \{SLAM\} techniques and high-fidelity \{LIDAR\} scanners are examples from an abundant set of systems capable of providing multi-million point datasets. These datasets quickly become difficult to process due to the sheer volume of data, typically containing significant redundant information, such as the representation of planar surfaces with millions of points. In order to exploit the richness of information provided by dense methods in real-time robotics, techniques are required to reduce the inherent redundancy of the data. In this paper we present a method for incremental planar segmentation of a gradually expanding point cloud map and a method for efficient triangulation and texturing of planar surface segments. Experimental results show that our incremental segmentation method is capable of running in real-time while producing a segmentation faithful to what would be achieved using a batch segmentation method. Our results also show that the proposed planar simplification and triangulation algorithm removes more than 90% of the input planar points, leading to a triangulation with only 10% of the original quantity of triangles per planar segment. Additionally, our texture generation algorithm preserves all colour information contained within planar segments, resulting in a visually appealing and geometrically accurate simplified representation. "
}
@article{Xu2015355,
title = "Cloud asset for urban flood control ",
journal = "Advanced Engineering Informatics ",
volume = "29",
number = "3",
pages = "355 - 365",
year = "2015",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2015.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S147403461500018X",
author = "Gangyan Xu and George Q. Huang and Ji Fang",
keywords = "Cloud asset",
keywords = "Smart object",
keywords = "Cloud-based applications",
keywords = "Mobile agent",
keywords = "Urban flood control ",
abstract = "Abstract The performance of physical assets has become a major determinant success factor for urban flood control. However, managing these assets is always challenging as there are a huge number of diverse assets involved, which are distributed throughout the city, and owned by different agencies. Aiming at improving the management efficiency of these assets, and ensuring their performance, this paper proposes the concept of cloud asset based on cloud computing, mobile agent, and various smart devices. Through hardware integration and software encapsulation, cloud asset could sense its real-time status, adapt to varied working scenarios, be controlled remotely, and shared among agencies. It enables accurate real-time control of every asset, and thus improves the management efficiency and effectiveness. This paper first presents the concept of cloud asset with its technical architecture, and then analyses the software agent model for cloud asset, which is the key enabler to realize \{UPnP\} (Universal Plug and Play) management of assets, and provides mobility and intelligence for them. After that, the framework of cloud asset-enabled workflow management is built, in which cloud asset could be easily found and dynamically invoked by different workflows. Finally, a demonstrative case is provided to verify the effectiveness of cloud asset. "
}
@article{Zehe2015157,
title = "\{SEMSim\} Cloud Service: Large-scale urban systems simulation in the cloud ",
journal = "Simulation Modelling Practice and Theory ",
volume = "58, Part 2",
number = "",
pages = "157 - 171",
year = "2015",
note = "Special issue on Cloud Simulation ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X15000805",
author = "Daniel Zehe and Alois Knoll and Wentong Cai and Heiko Aydt",
keywords = "Simulation",
keywords = "Cloud-based simulation",
keywords = "Performance evaluation",
keywords = "Urban systems simulations",
keywords = "High performance computing",
keywords = "Traffic simulation",
keywords = "Agent-based simulation ",
abstract = "Abstract Large-scale urban systems simulations are complex and with a large number of active simulation entities the computational workload is extensive. Workstation computers have only limited capabilities of delivering results for large-scale simulations. This leads to the problem that many researchers and engineers have to either reduce the scope of their experiments or fail to execute as many experiments as they would like in a given time frame. The use of high-performance computing (HPC) infrastructure offers a solution to the problem. Users of such simulations are often domain experts with no or little experience with \{HPC\} environments. In addition users do not necessarily have access to an HPC. In this paper we propose an architecture for a cloud-based urban systems simulation platform which specifically aims at making large-scale simulations available to typical users. The proposed architecture also addresses the issue of data confidentiality. In addition we describe the Scalable Electro-Mobility Simulation (SEMSim) Cloud Service that implements the proposed architecture. "
}
@article{Caglar2015255,
title = "Cloud-hosted simulation-as-a-service for high school \{STEM\} education ",
journal = "Simulation Modelling Practice and Theory ",
volume = "58, Part 2",
number = "",
pages = "255 - 273",
year = "2015",
note = "Special issue on Cloud Simulation ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X1500101X",
author = "Faruk Caglar and Shashank Shekhar and Aniruddha Gokhale and Satabdi Basu and Tazrian Rafi and John Kinnebrew and Gautam Biswas",
keywords = "Cloud",
keywords = "Modeling",
keywords = "Simulation-as-a-service",
keywords = "STEM ",
abstract = "Abstract Despite their advanced status, nations such as the United States of America continue to face a \{STEM\} (science, technology, engineering and mathematics) crisis in their education system. Lack of effective teaching modalities that can leverage real-world examples to stimulate student interest in \{STEM\} concepts are identified as one of the reasons for this crisis. To address these challenges, our research is investigating the use of innovative and attractive modeling and simulation frameworks for concurrent, interactive and collaborative \{STEM\} education where vehicular traffic serves as the real-world example to reify \{STEM\} concepts. Existing traffic-related tools, such as traffic simulators, however, do not provide: (1) intuitive abstractions to construct, refine, and simulate various traffic models that are commensurate to the level of high school students, (2) concurrent and scalable model execution, and (3) collaborative learning environments. On the other hand, although intuitive abstractions such as Google Maps exist, these abstractions do not support semantics for dynamic behavior, which is representative of real-world traffic scenarios. To overcome both these challenges and address the \{STEM\} problem, this paper presents a Cloud-based, Collaborative, and Scaled-up Modeling and Simulation Framework for \{STEM\} Education called C2SuMo. The key contribution of this paper lies in the design and implementation of a cloud-based, elastic modeling and simulation framework that provides an intuitive, model-driven, collaborative, and concurrent visual simulation environment for \{STEM\} education. The paper also reports on insights we gained conducting a user study involving over sixty high school students. "
}
@article{Yu20155,
title = "Computer-Integrated Manufacturing, Cyber-Physical Systems and Cloud Manufacturing – Concepts and relationships ",
journal = "Manufacturing Letters ",
volume = "6",
number = "",
pages = "5 - 9",
year = "2015",
note = "",
issn = "2213-8463",
doi = "https://doi.org/10.1016/j.mfglet.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S2213846315000176",
author = "Chunyang Yu and Xun Xu and Yuqian Lu",
keywords = "Cloud Manufacturing",
keywords = "Cyber-Physical Systems",
keywords = "Computer Integrated Manufacturing",
keywords = "Industry 4.0",
keywords = "Internet of Things ",
abstract = "Abstract Computers are deeply entrenched in modern manufacturing systems, giving rise to technologies such as Computer Integrated Manufacturing, Cyber-Physical Systems and most recently Cloud Manufacturing. These technologies have evolved based on existing or similar technologies or manufacturing paradigms. Some misunderstandings exist among these technologies. In spite of similarities, there are sufficient differences among themselves. To start off, the circumstances under which these technologies were incepted and developed are different. There are different methodologies associated with them. Discussions in this paper are made in relationship to Information Technology, Industry and Services. "
}
@article{Huang201530,
title = "Development of cloud-based automatic virtual metrology system for semiconductor industry ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "34",
number = "",
pages = "30 - 43",
year = "2015",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000186",
author = "Hsien-Cheng Huang and Yu-Chuan Lin and Min-Hsiung Hung and Chia-Chun Tu and Fan-Tien Cheng",
keywords = "Automatic virtual metrology (AVM)",
keywords = "Factory-wide deployment",
keywords = "Cloud computing",
keywords = "Virtualization",
keywords = "Production quality prediction of wafer",
keywords = "Cloud-based \{AVM\} system ",
abstract = "Abstract Automatic virtual metrology (AVM) is the highest-level technology for virtual metrology (VM) applications from the perspective of automation, which could facilitate fast factory-wide deployment of \{VM\} systems. However, the existing \{AVM\} system suffered several limitations during its practical deployment and operation in a fab for semiconductor manufacturing. In this paper, by leveraging the advantages of cloud computing, we propose an approach of building cloud-based \{AVM\} systems, which can effectively resolve these limitations. First, a cloud-based architecture is designed based on a private cloud to virtualize all servers of the \{AVM\} system for resolving the limitations of using physical servers, such as incurring high hardware cost, occupying a lot of shop-floor space, and needing complex efforts in managing \{VM\} servers. Then, three automatic functional mechanisms (i.e., automatic-deployment mechanism, automatic-scaling mechanism, and automatic-serving mechanism) are developed in an extra server (i.e., the virtual machine administrator server) to automate the deployment of \{VM\} servers, to automatically scale out/in the number of \{VM\} servers on demand, and to automatically dispatch \{VM\} servers to serve the requested \{VM\} tasks in parallel. Such an architecture design could significantly reduce the efforts of migrating the original \{AVM\} system to the cloud. Integrated testing results show that the proposed cloud-based \{AVM\} system could successfully overcome the limitations of the existing \{AVM\} system, while demonstrating a significant performance improvement over the existing \{AVM\} system in predicting the production quality of wafers. Most existing VM-related literature focused on the development of the \{VM\} models. To our knowledge, no papers have coped with the issues of plant-wide deployment and operation of \{VM\} systems by using cloud computing. This paper could be a useful reference for industrial practitioners to construct cloud-based \{AVM\} systems. "
}
@article{Santoli1999117,
title = "Hyper-interspersed nano/MEMS-architecture design for new concepts in miniature robotics for space exploration ",
journal = "Acta Astronautica ",
volume = "44",
number = "2–4",
pages = "117 - 122",
year = "1999",
note = "Missions to the Outer Solar System and Beyond ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(99)00037-5",
url = "http://www.sciencedirect.com/science/article/pii/S0094576599000375",
author = "Salvatore Santoli",
abstract = "Launch weight and volume requirements are substantially decreased by reduction of probe size in exploration mission systems, as mass and volume both scale as the third power of system size. Accordingly, the already quite developed \{MEMS\} (Micro Electro Mechanical System) technology, that offers low cost, small, light weight, and increasingly reliable devices through durability and redundancy, is strongly attractive as a near-term technology for significantly reducing the cost to launch and operate space systems. It is shown that the final goal of \{MEMS\} technology, i.e. the merging through solid state microdcvices of the functions of sensing, computation, communication and actuation, can lead to a new, biomimetic kind of miniature robotics, particularly suitable for planetary exploration, through molecular mono- electronics/MEMS integration jointly with a hyper-interspersed architecture made up of autonomous units embodying sensors, information processors and actuators. The problem tackled here concerns the basic design of such miniature robots, from some μm to insect size, featuring finely structured intelligent autonomous parts as smart skins, sensory and manipulating members working on the analogue external reality and communicating with their inner molecular level nondiscrete pseudo-analogue information processing networks. The (mesoscopic network)/MEMS units are shown to embody a quantum mechanical/macroscopic world connection, in which the nondiscrete molecular devices allow the automaton parts to perform very complex, fast information processing operations as metaphores of bionic functions like learning, attention, and decision making under uncertain conditions, this last due to the stochasticity inherent in the quantum network. Flexible architectures instead of von Neumann type rigid architectures in addition to hyper-interspersion of autonomous units can be realized through such nano/MEMS devices, and the μm — cm size of the whole robots and their organs allow dynamic biochemical, possibly reaction - diffusion, spatially separated highly nonlinear systems to be exploited as additional primitive computing devices (e.g. chemical oscillators, dissipative biomolecular distributed systems, planar photoactivated enzyme biosensors). Each interspersed unit can be designed as a multilevel nondiscrete system according to the information processing “rank” to be obtained in simulating the biological nervous system activity. "
}
@article{Chao201546,
title = "Cloud E-learning for Mechatronics: \{CLEM\} ",
journal = "Future Generation Computer Systems ",
volume = "48",
number = "",
pages = "46 - 59",
year = "2015",
note = "Special Section: Business and Industry Specific Cloud ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2014.10.033",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X14002271",
author = "Kuo-Ming Chao and Anne E. James and Antonios G. Nanos and Jen-Hsiang Chen and Sergiu-Dan Stan and Ionut Muntean and Giorgio Figliolini and Pierluigi Rea and Chedli B. Bouzgarrou and Pavel Vitliemov and Joshua Cooper and Jurgen van Capelle",
keywords = "Cloud computing",
keywords = "Mechatronics",
keywords = "E-learning",
keywords = "Remote virtual laboratories",
keywords = "Community",
keywords = "Ecosystem ",
abstract = "Abstract This paper describes results of the \{CLEM\} project, Cloud E-learning for Mechatronics. \{CLEM\} is an example of a domain-specific cloud that is especially tuned to the needs of \{VET\} (Vocational, Education and Training) teachers. An interesting development has been the creation of remote laboratories in the cloud. Learners can access such laboratories to support their practical learning of mechatronics without the need to set up laboratories at their own institutions. The cloud infrastructure enables multiple laboratories to come together virtually to create an ecosystem for educators and learners. From such a system, educators can pick and mix materials to create suitable courses for their students and the learners can experience different types of devices and laboratories through the cloud. The paper provides an overview of this new cloud-based e-learning approach and presents the results. The paper explains how the use of cloud computing has enabled the development of a new method, showing how a holistic e-learning experience can be obtained through use of static, dynamic and interactive material together with facilities for collaboration and innovation. "
}
@article{Pajarinen2017213,
title = "Robotic manipulation of multiple objects as a \{POMDP\} ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "213 - 228",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215000570",
author = "Joni Pajarinen and Ville Kyrki",
keywords = "POMDP",
keywords = "Planning under uncertainty",
keywords = "Task planning",
keywords = "Manipulation",
keywords = "Unknown objects",
keywords = "Multiple objects",
keywords = "Cluttered environment ",
abstract = "Abstract This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our \{POMDP\} model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online \{POMDP\} method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step \{POMDP\} planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience. "
}
@article{Rashidi2017,
title = "Outcome comparisons between high-volume robotic and laparoscopic surgeons in a large healthcare system ",
journal = "The American Journal of Surgery ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0002-9610",
doi = "https://doi.org/10.1016/j.amjsurg.2017.03.034",
url = "http://www.sciencedirect.com/science/article/pii/S0002961016311126",
author = "Laila Rashidi and Chris Neighorn and Amir Bastawrous",
abstract = "Abstract Robotic colorectal surgery has been performed for nearly a decade, but has been criticized for high cost. We sought to assess outcomes of colorectal operations performed by surgeons with higher experience in robotics and laparoscopy across a large health system. We performed a retrospective review of colon or rectal resections performed between January 2013 and May 2016 within the Providence Health and Services. Surgeons were only included if they performed 30 or more procedures with an approach per year. We assessed outcomes including operative time, hospital length of stay, complications, readmission, conversion to open rates and total direct costs. When comparing the two groups, robotics surgery had a decreased length of hospital stay, lower conversion rate, and longer operative time. There was no statistical difference between complications and rate of readmission. There was no statistically significant difference in total direct cost. These data do suggest that high volume robotic surgery can carry the benefit of a lower length of stay and lower conversion rate, while not incurring an increase in total cost, complication or readmissions. "
}
@article{Barazzetti201571,
title = "Cloud-to-BIM-to-FEM: Structural simulation with accurate historic \{BIM\} from laser scans ",
journal = "Simulation Modelling Practice and Theory ",
volume = "57",
number = "",
pages = "71 - 87",
year = "2015",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X15000994",
author = "Luigi Barazzetti and Fabrizio Banfi and Raffaella Brumana and Gaia Gusmeroli and Mattia Previtali and Giuseppe Schiantarelli",
keywords = "BIM",
keywords = "FEM",
keywords = "Interoperability",
keywords = "Point cloud",
keywords = "Structural simulation ",
abstract = "Abstract The complexity of historic constructions, with irregular geometry, inhomogeneous materials, variable morphology, alterations and damages, poses numerous challenges in the digital modeling and simulation of structural performances under different types of actions. Although recent developments in Building Information Modeling have introduced advanced simulation capabilities, the numerical characterization of historic buildings is still a challenging task for the lack of reliable procedures for structural simulation. This paper presents an innovative two-step methodology (Cloud-to-BIM-to-FEM) able to convert a historic \{BIM\} into a finite element model for structural simulation. The generation of the \{BIM\} (Cloud-to-BIM) is carried out with an accurate survey that integrates geometrical aspects, diagnostic analysis based on destructive and non-destructive inspections, material information, element interconnections, and architectural and structural considerations. The \{BIM\} is then turned into a finite element model (BIM-to-FEM) with a geometric rationalization which preserves irregularities and anomalies, such as verticality deviation and variable thickness. After setting material properties, loads, and boundary conditions, the structural simulation is run with a detailed model that respects the uniqueness and authenticity of the historic building, without the typical excessive geometric simplifications of the shape. A real case study is illustrated and discussed to prove that a rigorous Cloud-to-BIM-to-FEM workflow allows the generation of an accurate historic \{BIM\} from a set of laser scanning point clouds. Structural simulation was carried out with a 3D mesh derived from the \{BIM\} in order to take into consideration the geometrical irregularity of a castle. Here, the advantages and disadvantages of the proposed approach are illustrated and discussed. "
}
@article{Weinmann2015286,
title = "Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "105",
number = "",
pages = "286 - 304",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.01.016",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615000349",
author = "Martin Weinmann and Boris Jutzi and Stefan Hinz and Clement Mallet",
keywords = "Point cloud",
keywords = "Neighborhood selection",
keywords = "Feature extraction",
keywords = "Feature selection",
keywords = "Classification",
keywords = "3D scene analysis ",
abstract = "Abstract 3D scene analysis in terms of automatically assigning 3D points a respective semantic label has become a topic of great importance in photogrammetry, remote sensing, computer vision and robotics. In this paper, we address the issue of how to increase the distinctiveness of geometric features and select the most relevant ones among these for 3D scene analysis. We present a new, fully automated and versatile framework composed of four components: (i) neighborhood selection, (ii) feature extraction, (iii) feature selection and (iv) classification. For each component, we consider a variety of approaches which allow applicability in terms of simplicity, efficiency and reproducibility, so that end-users can easily apply the different components and do not require expert knowledge in the respective domains. In a detailed evaluation involving 7 neighborhood definitions, 21 geometric features, 7 approaches for feature selection, 10 classifiers and 2 benchmark datasets, we demonstrate that the selection of optimal neighborhoods for individual 3D points significantly improves the results of 3D scene analysis. Additionally, we show that the selection of adequate feature subsets may even further increase the quality of the derived results while significantly reducing both processing time and memory consumption. "
}
@article{Serrano201514,
title = "Wavelength dependence of the effective cloud optical depth ",
journal = "Journal of Atmospheric and Solar-Terrestrial Physics ",
volume = "130–131",
number = "",
pages = "14 - 22",
year = "2015",
note = "",
issn = "1364-6826",
doi = "https://doi.org/10.1016/j.jastp.2015.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S1364682615000929",
author = "D. Serrano and M.J. Marin and M. Nunez and M.P. Utrillas and S. Gandia and J.A. Martinez-Lozano",
keywords = "Cloud optical depth (τ)",
keywords = "UV Erythemal radiation (UVER)",
keywords = "Broadband",
keywords = "Overcast skies",
keywords = "Multiple scattering models ",
abstract = "Abstract This study examines the wavelength dependence of cloud optical depth. To accomplish this task two different wavelength bands of the solar spectrum were considered in the cloud optical depth retrieval which was conducted in Valencia, Spain. The first retrieval used global irradiance measurements in the \{UVER\} range taken from a YES-UVB-1 radiometer in combination with multiple scattering model estimates; while the second retrieval was obtained in the Broadband range, with measurements of global solar surface irradiance from a \{CM6\} pyranometer and a multiple scattering model. Whilst the dependence of the cloud optical depth (τ) on the wavelength is small, the best result was displayed by the \{SBDART\} model with less than 2% deviation between two ranges and moderately worse results were obtained with the LibRadtran model. Finally, seasonal statistical data for optical depth are presented for 2011 and 2012. "
}
@article{Sharifzadeh2016301,
title = "Robust Surface Abnormality Detection for a Robotic Inspection System ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "21",
pages = "301 - 308",
year = "2016",
note = "7th \{IFAC\} Symposium on Mechatronic Systems \{MECHATRONICS\} 2016Loughborough University, Leicestershire, UK, 5—8 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.572",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316321620",
author = "Sara Sharifzadeh and Istvan Biro and Niels Lohse and Peter Kinnell",
keywords = "Automatic abnormality detection",
keywords = "Point Cloud analysis",
keywords = "Feature extraction",
keywords = "Feature classification",
keywords = "Adaptive smoothing",
keywords = "surface inspection ",
abstract = "Abstract: The detection of surface abnormalities on large complex parts represents a significant automation challenge. This is particularly true when surfaces are large (multiple square metres) but abnormalities are small (less than one mm square), and the surfaces of interest are not simple flat planes. One possible solution is to use a robot-mounted laser line scanner, which can acquire fast surface measurements from large complex geometries. The problem with this approach is that the collected data may vary in quality, and this makes it difficult to achieve accurate and reliable inspection. In this paper a strategy for abnormality detection on highly curved Aluminum surfaces, using surface data obtained by a robot-mounted laser scanner, is presented. Using the laser scanner, data is collected from surfaces containing abnormalities, in the form of surface dents or bumps, of approximately one millimeter in diameter. To examine the effect of scan conditions on abnormality detection, two different curved test surfaces are used, and in addition the lateral spacing of laser scans was also varied. These variables were considered because they influence the distribution of points, in the point cloud (PC), that represent an abnormality. The proposed analysis consists of three main steps. First, a pre-processing step consisting of a fine smoothing procedure followed by a global noise analysis is carried out. Second, an abnormality classifier is trained based on a set of predefined surface abnormalities. Third, the trained classifier is used on suspicious areas of the surface in a general unsupervised thresholding step. This step saves computational time as it avoids analyzing every surface data point. Experimental results show that, the proposed technique can successfully find all present abnormalities for both training and test sets with minor false positives and no false negatives. "
}
@article{Schauer2015440,
title = "Collision detection between point clouds using an efficient k-d tree implementation ",
journal = "Advanced Engineering Informatics ",
volume = "29",
number = "3",
pages = "440 - 458",
year = "2015",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2015.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S1474034615000348",
author = "Johannes Schauer and Andreas Nuchter",
keywords = "Collision detection",
keywords = "Interference detection",
keywords = "k-d tree",
keywords = "Kinematic laser scanning",
keywords = "3D point clouds ",
abstract = "Abstract Context: An important task in civil engineering is the detection of collisions of a 3D model with an environment representation. Existing methods using the structure gauge provide an insufficient measure because the model either rotates or because the trajectory makes tight turns through narrow passages. This is the case in either automotive assembly lines or in narrow train tunnels. Objective: Given two point clouds, one of the environment and one of a model and a trajectory with six degrees of freedom along which the model moves through the environment, find all colliding points of the environment with the model within a certain clearance radius. Method: This paper presents two collision detection (CD) methods called kd-CD and kd-CD-simple and two penetration depth (PD) calculation methods called kd-PD and kd-PD-fast. All four methods are based on searches in a k-d tree representation of the environment. The creation of the k-d tree, its search methods and other features will be explained in the scope of their use to detect collisions and calculate depths of penetration. Results: The algorithms are benchmarked by moving the point cloud of a train wagon with 2.5 million points along the point cloud of a 1144 m long train track through a narrow tunnel with overall 18.92 million points. Points where the wagon collides with the tunnel wall are visually highlighted with their penetration depth. With a safety margin of 5 cm kd-PD-simple finds all colliding points on its trajectory which is sampled into 19,392 positions in 77 s on a standard desktop machine of 1.6 GHz. Conclusion: The presented methods for collision detection and penetration depth calculation are shown to solve problems for which the structure gauge is an insufficient measure. The underlying k-d tree is shown to be an effective data structure for the required look-up operations. "
}
@article{Cerroni201516,
title = "Cross-layer resource orchestration for cloud service delivery: A seamless \{SDN\} approach ",
journal = "Computer Networks ",
volume = "87",
number = "",
pages = "16 - 32",
year = "2015",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615001644",
author = "Walter Cerroni and Molka Gharbaoui and Barbara Martini and Aldo Campi and Piero Castoldi and Franco Callegati",
keywords = "Cloud computing",
keywords = "Software-defined networking",
keywords = "Service-oriented networks",
keywords = "Resource orchestration",
keywords = "Anycast service model ",
abstract = "Abstract One of the main challenges of cloud-based service provisioning is to deploy a coordinated control of both application- and network-layer resources in order to provide adaptive service data delivery and adequate user service experiences. In this work we propose a signaling framework architecture for cross-layer resource orchestration, where service awareness provided by session control is effectively combined with the flexibility of software-defined network control. Following a hands-on approach, the proposed solution takes advantage of existing and commonly deployed technologies aiming at an incremental deployment of the software-defined control mechanisms for the purpose of cross-functional service orchestration. The signaling framework is presented and validated through experimental activities carried out on a test-bed reproducing a realistic cloud-based service scenario. Results are compared against an analytical model that allows to investigate and quantify the sensitivity of the cloud-based service performance to the most relevant system parameters. The study demonstrates that a critical role is played by the limitations of the response time of real devices such as commercial routers, and highlights how orchestration functions can mitigate the effect of such limitations while addressing scalability of the overall system. "
}
@article{JafariNavimipour201565,
title = "Behavioral modeling and automated verification of a Cloud-based framework to share the knowledge and skills of human resources ",
journal = "Computers in Industry ",
volume = "68",
number = "",
pages = "65 - 77",
year = "2015",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514002127",
author = "Nima Jafari Navimipour and Ahmad Habibizad Navin and Amir Masoud Rahmani and Mehdi Hosseinzadeh",
keywords = "Expert Cloud",
keywords = "Cloud computing",
keywords = "Model checking",
keywords = "System verification",
keywords = "Virtualization",
keywords = "Human knowledge ",
abstract = "Abstract Expert Cloud as a new class of Cloud computing systems by employing the Internet infrastructures and Cloud computing concepts enables its users to request the skill, knowledge and expertise of human resources without any information about their location. It makes the communication between the \{HRs\} more efficient, reduces the cost of service, increases the variety of knowledge and information, facilitates employment of the \{HR\} in organizations, decreases customer response time and improves the service delivery methods. However, one facet that is still being less cared and that may introduce potential errors and faults regards the architectural problems and components analysis of Expert Cloud. Therefore, in this paper, we verify and check the specification, composition and architecture of the Expert Cloud via NuSMV model checker, Argo \{UML\} and Rebeca Verifier tools. The approach extracts the checking properties in the form of \{LTL\} and \{CTL\} formulas of control behaviors and automatically verifies the properties in operational behaviors. Also, experimental results indicate that the system is reachable, fair and deadlock-free. "
}
@article{Mojtahedzadeh201599,
title = "Support relation analysis and decision making for safe robotic manipulation tasks ",
journal = "Robotics and Autonomous Systems ",
volume = "71",
number = "",
pages = "99 - 117",
year = "2015",
note = "Emerging Spatial Competences: From Machine Perception to Sensorimotor Intelligence ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003145",
author = "Rasoul Mojtahedzadeh and Abdelbaki Bouguerra and Erik Schaffernicht and Achim J. Lilienthal",
keywords = "Scene analysis",
keywords = "Machine learning",
keywords = "Decision making",
keywords = "World models",
keywords = "Robotic manipulation ",
abstract = "Abstract In this article, we describe an approach to address the issue of automatically building and using high-level symbolic representations that capture physical interactions between objects in static configurations. Our work targets robotic manipulation systems where objects need to be safely removed from piles that come in random configurations. We assume that a 3D visual perception module exists so that objects in the piles can be completely or partially detected. Depending on the outcome of the perception, we divide the issue into two sub-issues: (1) all objects in the configuration are detected; (2) only a subset of objects are correctly detected. For the first case, we use notions from geometry and static equilibrium in classical mechanics to automatically analyze and extract act and support relations between pairs of objects. For the second case, we use machine learning techniques to estimate the probability of objects supporting each other. Having the support relations extracted, a decision making process is used to identify which object to remove from the configuration so that an expected minimum cost is optimized. The proposed methods have been extensively tested and validated on data sets generated in simulation and from real world configurations for the scenario of unloading goods from shipping containers. "
}
@article{Hanheide2017119,
title = "Robot task planning and explanation in open and uncertain worlds ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "119 - 150",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S000437021500123X",
author = "Marc Hanheide and Moritz Gobelbecker and Graham S. Horn and Andrzej Pronobis and Kristoffer Sjoo and Alper Aydemir and Patric Jensfelt and Charles Gretton and Richard Dearden and Miroslav Janicek and Hendrik Zender and Geert-Jan Kruijff and Nick Hawes and Jeremy L. Wyatt",
keywords = "Open-world planning",
keywords = "Planning under uncertainty",
keywords = "Commonsense knowledge",
keywords = "Mobile robotics",
keywords = "Probabilistic reasoning",
keywords = "Failure explanation",
keywords = "Assumptive planning",
keywords = "Retaskability ",
abstract = "Abstract A long-standing goal of \{AI\} is to enable robots to plan in the face of uncertain and incomplete information, and to handle task failure intelligently. This paper shows how to achieve this. There are two central ideas. The first idea is to organize the robot's knowledge into three layers: instance knowledge at the bottom, commonsense knowledge above that, and diagnostic knowledge on top. Knowledge in a layer above can be used to modify knowledge in the layer(s) below. The second idea is that the robot should represent not just how its actions change the world, but also what it knows or believes. There are two types of knowledge effects the robot's actions can have: epistemic effects (I believe X because I saw it) and assumptions (I'll assume X to be true). By combining the knowledge layers with the models of knowledge effects, we can simultaneously solve several problems in robotics: (i) task planning and execution under uncertainty; (ii) task planning and execution in open worlds; (iii) explaining task failure; (iv) verifying those explanations. The paper describes how the ideas are implemented in a three-layer architecture on a mobile robot platform. The robot implementation was evaluated in five different experiments on object search, mapping, and room categorization. "
}
@article{Weber201596,
title = "Automatic registration of unordered point clouds acquired by Kinect sensors using an overlap heuristic ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "102",
number = "",
pages = "96 - 109",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614002895",
author = "T. Weber and R. Hansch and O. Hellwich",
keywords = "Point cloud fusion",
keywords = "Point cloud registration",
keywords = "Microsoft Kinect ",
abstract = "Abstract This paper proposes and evaluates a pipeline to automatically register point clouds captured by depth sensors like the Microsoft Kinect. The method neither makes assumptions about the view order of the sensors, nor uses any kind of other task-dependent prior knowledge. All point clouds within the input set are aligned in a common, global coordinate system by a successive application of pairwise registration steps. The order of the individual transformations is automatically derived from a global point cloud graph, which uses the overlap of two individual point clouds to establish a weighted link between them. The experiments prove the generality of the proposed approach by applying it to data from a single but moving sensor, multiple Kinects that run simultaneously, as well as laser scanning data. The obtained accuracies in terms of the mean nearest point neighbor distance are below 0.01% of the maximum point distance of the reference data in all cases. "
}
@article{Serrano201550,
title = "Relationship between the effective cloud optical depth and different atmospheric transmission factors ",
journal = "Atmospheric Research ",
volume = "160",
number = "",
pages = "50 - 58",
year = "2015",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515000861",
author = "D. Serrano and M.J. Marin and M. Nunez and S. Gandia and M.P. Utrillas and J.A. Martinez-Lozano",
keywords = "Cloud optical depth (COD)",
keywords = "UV Erythemal Radiation (UVER)",
keywords = "Broadband",
keywords = "Overcast skies",
keywords = "Multiple scattering models",
keywords = "Transmission factors ",
abstract = "Abstract This study examines the sensitivity of cloud optical depth (COD) for overcast conditions to radiation transmission using data collected in Valencia, Spain. These relationships are provided as simple empirical functions, therefore avoiding the need to apply complex model minimisation schemes to obtain COD. Comparisons are presented between \{COD\} obtained by a minimization method and several radiation transmission factors comprising a clearness index (kt), a modified version (kt'), a cloud modification factor (CMF) and its modified version (CMF'). Additionally, a statistical model of \{COD\} proposed by J.C. Barnard and C.N. Long (2004) is tested with our data. Statistical relationships between \{COD\} and these variables were developed for measurements in the ultraviolet Erythema Radiation (UVER) range as well as for broadband measurements covering the full solar spectrum. Measurements collected in 2011 were used to develop power and exponential relationships relating \{COD\} to the above transmission factors, and subsequently tested with independent data collected in 2012. In general, expressions relating \{COD\} to \{CMF\} perform better and exhibit a higher correlation than equivalent expressions relating \{COD\} to clearness indices, especially in the \{UVER\} range. The expression of Barnard and Long is potentially adequate for the estimation of \{COD\} for both \{UVER\} and broadband solar radiation in Valencia, but the regression coefficients need tuning for local conditions. "
}
@article{Yu201518,
title = "Ant colony optimization applied to web service compositions in cloud computing ",
journal = "Computers & Electrical Engineering ",
volume = "41",
number = "",
pages = "18 - 27",
year = "2015",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2014.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0045790614003139",
author = "Qiang Yu and Ling Chen and Bin Li",
keywords = "Service composition",
keywords = "Multi-cloud base",
keywords = "Cloud combination",
keywords = "Ant colony optimization ",
abstract = "Abstract Rapid developments in cloud computing technology mean that many different web services are now published and available in cloud data centers. There has recently been an increasing amount of interest in web service composition, because it is important in practical applications. However, most traditional service composition methods can only find service composition sequences in a single cloud, and cannot consider a multi-cloud service base. It is challenging to efficiently find a composition across multiple clouds, because it involves service compositions and combinatorial optimization. In this paper, we present a greedy algorithm called Greedy-WSC and an ant colony optimization based algorithm called ACO-WSC, which attempt to select cloud combinations that are feasible and use the minimum number of clouds. Our experimental results show that the proposed ant colony optimization method can effectively and efficiently find cloud combinations with a minimal number of clouds. "
}
@article{Wang2015786,
title = "WRCloud: A Novel \{WEEE\} Remanufacturing Cloud System ",
journal = "Procedia \{CIRP\} ",
volume = "29",
number = "",
pages = "786 - 791",
year = "2015",
note = "The 22nd \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.02.011",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115000505",
author = "Xi Vincent Wang and Lihui Wang",
keywords = "Cloud Manufacturing",
keywords = "Cloud Remanufacturing",
keywords = "WEEE",
keywords = "WEEE Recovery",
keywords = "WEEE Recycle ",
abstract = "Abstract Cloud manufacturing is a new manufacturing paradigm that offers manufacturing capabilities in terms of Cloud services. As a specific type of manufacturing, Waste Electrical and Electronic Equipment (WEEE) remanufacturing experiences difficulties in system integration, data exchange and resource management, especially when the products reach the end of lifecycle. Thus it is possible to introduce the Cloud manufacturing paradigm into \{WEEE\} remanufacturing environment, to overcome the obstacles and bottlenecks. In this paper, a novel Cloud-based system is developed to support \{WEEE\} remanufacturing. The \{WEEE\} recycle/recovery capabilities are integrated and deployed as flexible services in the Cloud. Supporting mechanisms and technologies are also developed, which are presented and evaluated via case studies. "
}
@article{Yan201565,
title = "Comparison of CERES-MODIS cloud microphysical properties with surface observations over Loess Plateau ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "153",
number = "",
pages = "65 - 76",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part \{II\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003811",
author = "Hongru Yan and Jianping Huang and Patrick Minnis and Yuhong Yi and Sunny Sun-Mack and Tianhe Wang and Takashi Y. Nakajima",
keywords = "Validation",
keywords = "Cloud microphysical properties",
keywords = "Satellite ",
abstract = "Abstract To enhance the utility of satellite-derived cloud properties for studying the role of clouds in climate change and the hydrological cycle in semi-arid areas, it is necessary to know their uncertainties. This paper estimates the uncertainties of several cloud properties by comparing those derived over the China Loess Plateau from the MODerate-resolution Imaging Spectroradiometer (MODIS) on Terra and Aqua by the Clouds and Earth׳s Radiant Energy System (CERES) with surface observations at the Semi-Arid Climate and Environment Observatory of Lanzhou University (SACOL). The comparisons use data from January 2008 to June 2010 limited to single layer and overcast stratus conditions during daytime. Cloud optical depths (τ) and liquid water paths (LWP) from both Terra and Aqua generally track the variation of the surface counterparts with modest correlation, while cloud effective radius (re) is only weakly correlated with the surface retrievals. The mean differences between Terra and the \{SACOL\} retrievals are −4.7±12.9, 2.1±3.2 μm and 30.2±85.3 g m−2 for τ, re and LWP, respectively. The corresponding differences for Aqua are 2.1±8.4, 1.2±2.9 μm and 47.4±79.6 g m−2, respectively. Possible causes for biases of satellite retrievals are discussed through statistical analysis and case studies. Generally, the CERES-MODIS cloud properties have a bit larger biases over the Loess Plateau than those in previous studies over other locations. "
}
@article{Saut20141742,
title = "Grasping objects localized from uncertain point cloud data ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "12",
pages = "1742 - 1754",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001389",
author = "Jean-Philippe Saut and Serena Ivaldi and Anis Sahbani and Philippe Bidaud",
keywords = "Robotic grasping",
keywords = "Multi-fingered hand",
keywords = "Inverse kinematics ",
abstract = "Abstract Robotic grasping is very sensitive to how accurate is the pose estimation of the object to grasp. Even a small error in the estimated pose may cause the planned grasp to fail. Several methods for robust grasp planning exploit the object geometry or tactile sensor feedback. However, object pose range estimation introduces specific uncertainties that can also be exploited to choose more robust grasps. We present a grasp planning method that explicitly considers the uncertainties on the visually-estimated object pose. We assume a known shape (e.g. primitive shape or triangle mesh), observed as a–possibly sparse–point cloud. The measured points are usually not uniformly distributed over the surface as the object is seen from a particular viewpoint; additionally this non-uniformity can be the result of heterogeneous textures over the object surface, when using stereo-vision algorithms based on robust feature-point matching. Consequently the pose estimation may be more accurate in some directions and contain unavoidable ambiguities. The proposed grasp planner is based on a particle filter to estimate the object probability distribution as a discrete set. We show that, for grasping, some ambiguities are less unfavorable so the distribution can be used to select robust grasps. Some experiments are presented with the humanoid robot iCub and its stereo cameras. "
}
@article{Jerbic2015847,
title = "Robot Assisted 3D Point Cloud Object Registration ",
journal = "Procedia Engineering ",
volume = "100",
number = "",
pages = "847 - 852",
year = "2015",
note = "25th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2014 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.01.440",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815004671",
author = "Bojan Jerbic and Filip suligoj and Marko svaco and Bojan sekoranja",
keywords = "Point cloud data",
keywords = "position estimation",
keywords = "object recognition",
keywords = "machine learning",
keywords = "stereovision ",
abstract = "Abstract In this paper we describe a method for registration of 3D point clouds that represent objects of interest. A stereovision system is used to capture point clouds of a static environment, robot arm and an unknown object. By moving the robot arm in the environment the proposed system defines known occupied zones and is able to identify the robot arm. In order to identify a complete point cloud presentation of the robot gripper it is rotated in front of a stereovision camera and its geometry is captured from different angles. Iterative closest point algorithm is used to determine a rigid transformation between every new robot pose so the original point cloud can be appended with the transformed one. When the robot is holding a new object the registration procedure is repeated and known elements (environment, robot arm and gripper) are removed so that the object can be identified. "
}
@article{Talhi2015288,
title = "Towards a Cloud Manufacturing systems modeling methodology ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "288 - 293",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.096",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315003353",
author = "A. Talhi and J.C. Huet and V. Fortineau and S. Lamouri",
keywords = "Ontology",
keywords = "Cloud Manufacturing",
keywords = "ASDI",
keywords = "modeling ",
abstract = "Abstract In this study we present an adaptation of \{ASDI\} (Analysis-Specification-Design- Impelmenation) methodology to the Cloud Manufacturing domain. Cloud Manufacturing is an emerging paradigm in which dynamically scalable and virtualized manufacturing resources are provided to the users as services over the Internet. In order to implement a Cloud Manufacturing platform that will map manufacturing users and providers we propose a modeling methodology named ASDI-Onto. It uses ontologies as modeling approaches to model the Cloud Manufacturing domain and introduce the outlines of the future work. "
}
@article{Nurunnabi20151404,
title = "Outlier detection and robust normal-curvature estimation in mobile laser scanning 3D point cloud data ",
journal = "Pattern Recognition ",
volume = "48",
number = "4",
pages = "1404 - 1419",
year = "2015",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2014.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0031320314004312",
author = "Abdul Nurunnabi and Geoff West and David Belton",
keywords = "Feature extraction",
keywords = "Plane fitting",
keywords = "Point cloud denoising",
keywords = "Robust saliency feature",
keywords = "Segmentation",
keywords = "Surface reconstruction ",
abstract = "Abstract This paper proposes two robust statistical techniques for outlier detection and robust saliency features, such as surface normal and curvature, estimation in laser scanning 3D point cloud data. One is based on a robust z-score and the other uses a Mahalanobis type robust distance. The methods couple the ideas of point to plane orthogonal distance and local surface point consistency to get Maximum Consistency with Minimum Distance (MCMD). The methods estimate the best-fit-plane based on most probable outlier free, and most consistent, points set in a local neighbourhood. Then the normal and curvature from the best-fit-plane will be highly robust to noise and outliers. Experiments are performed to show the performance of the algorithms compared to several existing well-known methods (from computer vision, data mining, machine learning and statistics) using synthetic and real laser scanning datasets of complex (planar and non-planar) objects. Results for plane fitting, denoising, sharp feature preserving and segmentation are significantly improved. The algorithms are demonstrated to be significantly faster, more accurate and robust. Quantitatively, for a sample size of 50 with 20% outliers the proposed MCMD_Z is approximately 5, 15 and 98 times faster than the existing methods: uLSIF, \{RANSAC\} and RPCA, respectively. The proposed MCMD_MD method can tolerate 75% clustered outliers, whereas, \{RPCA\} and \{RANSAC\} can only tolerate 47% and 64% outliers, respectively. In terms of outlier detection, for the same dataset, MCMD_Z has an accuracy of 99.72%, 0.4% false positive rate and 0% false negative rate; for RPCA, \{RANSAC\} and uLSIF, the accuracies are 97.05%, 47.06% and 94.54%, respectively, and they have misclassification rates higher than the proposed methods. The new methods have potential for local surface reconstruction, fitting, and other point cloud processing tasks. "
}
@article{Hernandez2015977,
title = "Cloud Configuration Modelling: A Literature Review from an Application Integration Deployment Perspective ",
journal = "Procedia Computer Science ",
volume = "64",
number = "",
pages = "977 - 983",
year = "2015",
note = "Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2015 October 7-9, 2015 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.616",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915027519",
author = "Inma Hernandez and Sandro Sawicki and Fabricia Roos-Frantz and Rafael Z. Frantz",
keywords = "Enterprise Application Integration",
keywords = "Optimisation",
keywords = "Cloud-computing",
keywords = "Cloud Service Model",
keywords = "Service Variability. ",
abstract = "Abstract Enterprise Application Integration has played an important role in providing methodologies, techniques and tools to develop integration solutions, aiming at reusing current applications and supporting the new demands that arise from the evolution of business processes in companies. Cloud-computing is part of a new reality in which companies have at their disposal a high-capacity \{IT\} infrastructure at a low-cost, in which integration solutions can be deployed and run. The charging model adopted by cloud-computing providers is based on the amount of computing resources consumed by clients. Such demand of resources can be computed either from the implemented integration solution, or from the conceptual model that describes it. It is desirable that cloud-computing providers supply detailed conceptual models describing the variability of services and restrictions between them. However, this is not the case and providers do not supply the conceptual models of their services. The conceptual model of services is the basis to develop a process and provide supporting tools for the decision-making on the deployment of integration solutions to the cloud. In this paper, we review the literature on cloud configuration modelling, and compare current proposals based on a comparison framework that we have developed. "
}
@article{Wu2015169,
title = "Tolerance Design and Adjustment of Complex Customized Product Based on Cloud Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "27",
number = "",
pages = "169 - 175",
year = "2015",
note = "13th \{CIRP\} conference on Computer Aided Tolerancing ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.04.061",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115003236",
author = "Zijian Wu and Zhenbo Gao and Yanlong Cao and Xiaoping Ye and Jiangxin Yang",
keywords = "cloud manufacturing",
keywords = "quality loss",
keywords = "manufacturing cost",
keywords = "dynamic tolerance adjustment ",
abstract = "Abstract A local and temporal separated manufacturing becomes possible, which can enhance the economic efficiency of the production. Complex products such as spacecraft, large \{CNC\} Machine, large compressor face challenges in their development process. The cloud manufacturing which is based on the development of cloud computing and Internet of Things system makes the collaborative manufacturing process of complex customized product become rapid intelligent efficient and of low-energy consumption. Cloud Manufacturing is a new manufacturing pattern which organizes the manufacturing resource to provide customers with all kinds of manufacturing services as needed. Customers who have taken part in this kind of manufacturing process could integrate the resource anytime anywhere according to the product requirement. Different from the traditional manufacturing pattern, Cloud manufacturing is multi-selective dynamic and the process may be across the stage. With more resources in the manufacturing process involved, cost of the manufacturing may be increased, so the cloud manufacturing is more suitable for small batch manufacture process of large and complex manufacturing process of customized products. In this article, we put forward a dynamic tolerance design and management framework of complex customized product based on cloud manufacturing. When the product comes into the manufacturing process, the dimension might be overflown of the acceptable zone which had been designed in the engineering phase, therefore we introduce a dynamic control that at every stage of the manufacturing we re-organize the resource based on the real-time information of the manufacturing cloud (in other word, ability of the manufacturing service) and the performance of former service. To ensure the function of the product expressed integrality and assembly process carried out smoothly, we could obtain the target optimal solution of dynamic allocation process of the tolerance on the follow-up process according to the minimum goal of the cost time and quality loss in dynamic adjustment and process stability. "
}
@article{Tedeschi201547,
title = "Security Aspects in Cloud Based Condition Monitoring of Machine Tools ",
journal = "Procedia \{CIRP\} ",
volume = "38",
number = "",
pages = "47 - 52",
year = "2015",
note = "Proceedings of the 4th International Conference on Through-life Engineering Services ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.07.046",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115008057",
author = "Stefano Tedeschi and Jorn Mehnen and Nikolaos Tapoglou and Roy Rajkumar",
keywords = "Cloud",
keywords = "Remote Maintenance",
keywords = "Machine Tool",
keywords = "Secure Communications",
keywords = "Remote Monitoring ",
abstract = "Abstract In the modern competitive environments companies must have rapid production systems that are able to deliver parts that satisfy highest quality standards. Companies have also an increased need for advanced machines equipped with the latest technologies in maintenance to avoid any reduction or interruption of production. Eminent therefore is the need to monitor the health status of the manufacturing equipment in real time and thus try to develop diagnostic technologies for machine tools. This paper lays the foundation for the creation of a safe remote monitoring system for machine tools using a Cloud environment for communication between the customer and the maintenance service company. Cloud technology provides a convenient means for accessing maintenance data anywhere in the world accessible through simple devices such as PC, tablets or smartphones. In this context the safety aspects of a Cloud system for remote monitoring of machine tools becomes crucial and is, thus the focus of this paper. "
}
@incollection{LaurieLau201517,
title = "Chapter 2 - Cybercrime in cloud: Risks and responses in Hong Kong, Singapore ",
editor = "Ko, Ryan  and Choo, Kim-Kwang Raymond ",
booktitle = "The Cloud Security Ecosystem ",
publisher = "Syngress",
edition = "",
address = "Boston",
year = "2015",
pages = "17 - 35",
isbn = "978-0-12-801595-7",
doi = "https://doi.org/10.1016/B978-0-12-801595-7.00002-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780128015957000021",
author = "Yiu Chung Laurie Lau",
keywords = "Cloud computing",
keywords = "Hong Kong",
keywords = "Singapore",
keywords = "Key factors shaping “Response”",
keywords = "Mainlandization",
keywords = "Discussion ",
abstract = "Abstract The popularity and commercialization of the “Internetwork” began in the late 1990s through the interconnection of computer networks using special gateways or routers to transfer packets of electronic data. As with many things in life, Internetwork technology has had both positive and negative effects on society, and Asia has been no exception. One of the negative effects has been a surge in Internet crime. According to a report released by the Gartner Consulting Group, in 2013 smart phone sales exceeded regular phone sales for the first time, with 968 million smart phones sold, representing 54% of the global mobile phone total and an increase of 54% from 2012. The popularity and technology of the mobile Internetwork, especially the smart mobile phone web, has changed the Internetwork landscape through the concept of cloud computing. Cloud computing is distributed computing over a network, using a program or application that can run on many connected computers and in different locations around the globe simultaneously at a reduced cost. This distributed cloud computing presents law enforcement authorities with the unique challenge of policing Internet crime. Cloud computing relies on sharing resources to achieve coherence, and in doing so creates economies of scale for converged infrastructures and shared services. Accordingly, one problem facing the authorities is the presence of trans- and multijurisdictional crimes. In this chapter, I explore this topic in the contexts of Hong Kong and Singapore, as both are key players on the international stage, especially in relation to international finance and information technology. In both locations, infrastructure works to maintain global financial center status. The remainder of this chapter is organized as follows. A brief overview of the development of cloud computing is followed by an examination of cybercrime risks in the cloud. Then, I review how the authorities in Hong Kong and Singapore respond to cybercrime risks and explore the current government policies on cloud computing, particularly in fighting cybercrime. "
}
@article{Lin2014292,
title = "Interactions between biomass-burning aerosols and clouds over Southeast Asia: Current status, challenges, and perspectives ",
journal = "Environmental Pollution ",
volume = "195",
number = "",
pages = "292 - 307",
year = "2014",
note = "",
issn = "0269-7491",
doi = "https://doi.org/10.1016/j.envpol.2014.06.036",
url = "http://www.sciencedirect.com/science/article/pii/S0269749114002838",
author = "Neng-Huei Lin and Andrew M. Sayer and Sheng-Hsiang Wang and Adrian M. Loftus and Ta-Chih Hsiao and Guey-Rong Sheu and N. Christina Hsu and Si-Chee Tsay and Somporn Chantara",
keywords = "Biomass-burning aerosol",
keywords = "Aerosol–cloud interaction",
keywords = "7-SEAS",
keywords = "Remote sensing",
keywords = "Aerosol chemistry",
keywords = "Southeast Asia ",
abstract = "Abstract The interactions between aerosols, clouds, and precipitation remain among the largest sources of uncertainty in the Earth's energy budget. Biomass-burning aerosols are a key feature of the global aerosol system, with significant annually-repeating fires in several parts of the world, including Southeast Asia (SEA). \{SEA\} in particular provides a “natural laboratory” for these studies, as smoke travels from source regions downwind in which it is coupled to persistent stratocumulus decks. However, \{SEA\} has been under-exploited for these studies. This review summarizes previous related field campaigns in SEA, with a focus on the ongoing Seven South East Asian Studies (7-SEAS) and results from the most recent \{BASELInE\} deployment. Progress from remote sensing and modeling studies, along with the challenges faced for these studies, are also discussed. We suggest that improvements to our knowledge of these aerosol/cloud effects require the synergistic use of field measurements with remote sensing and modeling tools. "
}
@article{Mourtzis20159,
title = "Cloud-based Integrated Shop-floor Planning and Control of Manufacturing Operations for Mass Customisation ",
journal = "Procedia \{CIRP\} ",
volume = "33",
number = "",
pages = "9 - 16",
year = "2015",
note = "9th \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering - \{CIRP\} \{ICME\} '14 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115006472",
author = "D. Mourtzis and M. Doukas and C. Lalas and N. Papakostas",
keywords = "Production Planning and Control",
keywords = "Mass Customisation",
keywords = "Decision-making",
keywords = "Software as a Service",
keywords = "Cloud Manufacturing ",
abstract = "Abstract The shift of traditional mass producing industries towards mass customisation practices is nowadays evident. However, if not implemented properly, mass customisation can lead to disturbances in material flow and severe reduction in productivity. This paper discusses the design and development of a Cloud-based production planning and control system for discrete manufacturing environments, referred to as i-MRP. The proposed approach takes into consideration capacity constraints, lot sizing and priority control in a ‘bucket-less’ manufacturing environment. The i-MRP system offers simultaneous shop scheduling and material planning, where material and capacity constraints are considered together in a continuous time environment. A number of feasible alternative shop schedules and material plan combinations are formed and are evaluated on the Cloud platform where the i-MRP engine is hosted. The Cloud platform enables mobility, since it is device and location independent, as well as it minimises the cost of \{IT\} infrastructure ownership, which is especially important for SMEs. The performance of the i-MRP system has been studied in an \{SME\} from the textile sector, using real production data. The system demonstrates high performance in cases of short production times, high value inventory and frequent, small deliveries by suppliers. The i-MRP can be easily integrated with legacy \{IT\} systems as an interfaced functional module under the Software as a Service (SaaS) architecture. "
}
@article{Kaaouache20151061,
title = "Solving bin Packing Problem with a Hybrid Genetic Algorithm for \{VM\} Placement in Cloud ",
journal = "Procedia Computer Science ",
volume = "60",
number = "",
pages = "1061 - 1069",
year = "2015",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.151",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915022784",
author = "Mohamed Amine Kaaouache and Sadok Bouamama",
keywords = "Genetic algorithms",
keywords = "Bin Packing",
keywords = "Heuristics",
keywords = "Infeasible solutions",
keywords = "Virtual machine placement",
keywords = "Cloud Computing ",
abstract = "Abstract The Bin Packing Problem's purpose (BPP) is to find the minimum number of bins needed to pack a given set of objects of known sizes so that they do not exceed the capacity of each bin. This problem is known to be NP- Hard. In this paper, we propose an hybrid genetic algorithm using \{BFD\} (Best Fit Decreasing) to deal with infeasible solution due to the bin-used representation. Experimental results showed the effectiveness of our approach for infeasible chromosomes thereby improving the quality of the obtained solution. This will give a good result for the virtual machine placement in Cloud to minimize energy since it looks like a BPP. "
}
@article{ShahdiPashaki20151140,
title = "Group technology-based model and cuckoo optimization algorithm for resource allocation in cloud computing ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "1140 - 1145",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.237",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315004760",
author = "S. Shahdi-Pashaki and Ehsan Teymourian and Vahid Kayvanfar and GH.M. Komaki and A. Sajadi",
keywords = "Cloud computing",
keywords = "Group technology",
keywords = "Virtual machine",
keywords = "Cuckoo optimization algorithm ",
abstract = "Abstract The control of operational costs is one of the main goals of resource management problem in cloud computing (CC). This paper presents a new mathematical model based on group technology (GT) to map the virtual machines (VMs) to workflows in order to control some costs (e.g. transfer costs, penalty costs and server cost) when the \{VMs\} are running. \{GT\} is a well-known manufacturing technique in industrial environments which can control some measures (e.g. part movements, resource utilization). In large size problems a cuckoo optimization algorithm (COA) is proposed. To test the effectiveness of our approaches, we first generate a set of problems randomly and then compare the model and \{COA\} with a well-known algorithm in literature called Round robin (RR). Analyzing the computational results proves that our approaches give better performance than RR. "
}
@article{Cho2015442,
title = "A Framework for Cloud-based Energy Evaluation and Management for Sustainable Decision Support in the Built Environments ",
journal = "Procedia Engineering ",
volume = "118",
number = "",
pages = "442 - 448",
year = "2015",
note = "Defining the future of sustainability and resilience in design, engineering and construction ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.08.445",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815021001",
author = "Yong K. Cho and Haorong Li and JeeWoong Park and Keke Zheng",
keywords = "As-built modeling",
keywords = "cloud computing",
keywords = "Automated Building System",
keywords = "retrofit",
keywords = "energy ",
abstract = "Abstract This paper introduces a framework which can advance traditional building auditing and energy management methods in terms of cost, convenience of automatic and remote data (e.g., 3D geometry and thermal values) collection, system control, and comprehension and dissemination of results using a proposed cloud-based software as a service (CSaaS) system as a decision support tool. The decision support tool can help decision makers improve their buildings by providing reliable and visualized information of the building's energy performance through an easy-to-use interactive virtual evaluation system in a publicly accessible cyberspace. The proposed open decision-support platform is expected to ultimately reduce the public's energy consumption and invigorate the nation's economy by vitalizing sustainable product manufacture and retrofit construction industries. "
}
@incollection{Colombo201567,
title = "Chapter 4 - Industrial Agents in the Era of Service-Oriented Architectures and Cloud-Based Industrial Infrastructures ",
editor = "Leitao, Paulo  and Karnouskos, Stamatis ",
booktitle = "Industrial Agents ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2015",
pages = "67 - 87",
isbn = "978-0-12-800341-1",
doi = "https://doi.org/10.1016/B978-0-12-800341-1.00004-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780128003411000048",
author = "Armando Walter Colombo and Stamatis Karnouskos and Joao Marco Mendes and Paulo Leitao",
keywords = "Industrial agents",
keywords = "Service-oriented architecture",
keywords = "Cloud system",
keywords = "Industrial system",
keywords = "Simulation",
keywords = "Cyber-physical system",
keywords = "Collaborative automation ",
abstract = "Abstract The umbrella paradigm underpinning novel collaborative industrial systems is to consider the set of intelligent system units as a conglomerate of distributed, autonomous, intelligent, proactive, fault-tolerant, and reusable units, which operate as a set of cooperating entities. The application of the industrial agents paradigm is well-fit to act as an enabler for mastering such collaborative industrial systems, especially in conjunction with the prevalence of service-oriented architectures and cloud technologies. The overall combination is seen as promising in the effort to unleash the benefit stemming from the utilization of such sophisticated industrial systems. "
}
@article{Subirats201570,
title = "Assessing and forecasting energy efficiency on Cloud computing platforms ",
journal = "Future Generation Computer Systems ",
volume = "45",
number = "",
pages = "70 - 94",
year = "2015",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2014.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X14002428",
author = "Josep Subirats and Jordi Guitart",
keywords = "Cloud computing",
keywords = "Energy efficiency",
keywords = "Ecological efficiency",
keywords = "Forecasting",
keywords = "Green computing",
keywords = "IaaS provider ",
abstract = "Abstract IaaS providers have become interested in optimising their infrastructure energy efficiency. To do so, their \{VM\} placement algorithms need to know the current and future energy efficiency at different levels (Virtual Machine, node, infrastructure and service levels) and for potential actions such as service deployment or \{VM\} deployment, migration or cancellation. This publication provides a mathematical formulation for the previous aspects, as well as the design of a \{CPU\} utilisation estimator used to calculate the aforementioned forecasts. The correct adjustment of the estimators’ configuration parameters has been proved to lead to considerable precision improvements. When running Web workloads, estimators focused on noise filtering provide the best precision even if they react slowly to changes, whereas reactive predictors are desirable for batch workloads. Furthermore, the precision when running batch workloads partially depends on each execution. Finally, it has been observed that the forecasts precision degradation as such forecasts are performed for a longer time period in the future is smaller when running web workloads. "
}
@article{Altenkirch2008428,
title = "Robotic sample manipulation for stress and texture determination on neutron and synchrotron X-ray diffractometers ",
journal = "Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment ",
volume = "584",
number = "2–3",
pages = "428 - 435",
year = "2008",
note = "",
issn = "0168-9002",
doi = "https://doi.org/10.1016/j.nima.2007.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0168900207021638",
author = "J. Altenkirch and A. Steuwer and P.J. Withers and T. Buslaps and U. Berger",
keywords = "Neutron diffraction",
keywords = "Synchrotron X-ray diffraction",
keywords = "Sample manipulation",
keywords = "Robotics",
keywords = "Automation ",
abstract = "In this paper we report on a new robotic arm system for fast, accurate and flexible sample manipulation for stress and texture analysis in geometrically complex engineering components on neutron and synchrotron X-ray diffractometers. A Staeubli serial six-axis robotic arm offering full six degrees of freedom for sample movement, with a spatial positioning accuracy of the order of tens of microns has been commissioned. Reverse engineering and 3D visualization techniques are employed to control the sample manipulation procedure. Two basic applications of the system, one for stress measurements using synchrotron X-ray diffraction using the sin2 ψ inclination method, and one for pole figure determination for texture analysis using neutron diffraction, are presented. The former required measurements at eight angles for each measurement location; the latter a full quadrant of solid angle with the centre of the sample maintained stationary. With new robotic arms being produced with higher payloads (the current one is limited to 9 kg), but similar positional uncertainties, robotic sample manipulation offers very flexible measurement strategies for complex geometries, without the need for repeated manual intervention for sample reorientation. "
}
@article{Tenorth2017151,
title = "Representations for robot knowledge in the KnowRob framework ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "151 - 169",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215000843",
author = "Moritz Tenorth and Michael Beetz",
keywords = "Knowledge representation",
keywords = "Autonomous robots",
keywords = "Knowledge-enabled robotics ",
abstract = "Abstract In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in \{AI\} research, and propose to re-consider a \{KR\} system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation. The KnowRob system has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot's performance. "
}
@article{Schneider2014636,
title = "Integrated approach to robotic machining with macro/micro-actuation ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "30",
number = "6",
pages = "636 - 647",
year = "2014",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000271",
author = "Ulrich Schneider and Bjo¨rn Olofsson and Olof So¨rnmo and Manuel Drust and Anders Robertsson and Martin Hagele and Rolf Johansson",
keywords = "Robotic machining",
keywords = "Macro/micro-actuation",
keywords = "Contact operations",
keywords = "Model-based control",
keywords = "Optical tracking ",
abstract = "Abstract A novel integrated approach to high-accuracy machining with industrial robots is presented in this paper. By combining a conventional industrial robot with an external compensation mechanism, a significantly higher bandwidth of the control of the relative position between the tool and the workpiece can be achieved. A model-based feedback controller for the compensation mechanism, as well as a mid-ranging control architecture for the combined system with the robot and the compensation mechanism are developed. The system performance is evaluated in extensive machining experiments, and the workpiece accuracies achieved are quantified and compared to the corresponding results obtained with state-of-the-art approaches to robotic machining. It is shown that the proposed approach to machining offers significantly higher accuracy, up to eight times improvement for milling in steel, where the required process forces, and thus the exhibited position deviations of the robot, are significant. "
}
@article{Buribayeva2015722,
title = "An Autonomous Emergency Warning System Based on Cloud Servers and \{SNS\} ",
journal = "Procedia Computer Science ",
volume = "60",
number = "",
pages = "722 - 729",
year = "2015",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.225",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915023522",
author = "Gulbanu Buribayeva and Taizo Miyachi and Azamat Yeshmukhametov and Yutaro Mikami",
keywords = "cloud computing",
keywords = "autonomous waning",
keywords = "disaster",
keywords = "sensors network",
keywords = "evacuation map ; ",
abstract = "Abstract There are no warning systems for earthquake, fire and gas disasters in Almaty (Kazakhstan). We propose an autonomous emergency warning system that provides useful awareness against unpredictable disasters. The system mainly consists of sensor network, disaster information mapping server, \{SNS\} module, and web server. When the system detects a disaster it distributes real-time warnings with levels of danger and signs of severe damages by the sensor data and \{GPS\} position to residents by both \{SNS\} (twitter) and the Website with Google maps including real-time safety places. We built a prototype system and could confirm the effectiveness of the warning system. "
}
@article{Yin20146920,
title = "A novel \{TCF\} calibration method for robotic visual measurement system ",
journal = "Optik - International Journal for Light and Electron Optics ",
volume = "125",
number = "23",
pages = "6920 - 6925",
year = "2014",
note = "",
issn = "0030-4026",
doi = "https://doi.org/10.1016/j.ijleo.2014.08.049",
url = "http://www.sciencedirect.com/science/article/pii/S0030402614010134",
author = "Shibin Yin and Yin Guo and Yongjie Ren and Jigui Zhu and Shourui Yang and Shenghua Ye",
keywords = "TCF",
keywords = "Robotic visual measurement system",
keywords = "Calibration",
keywords = "Collision recovery ",
abstract = "Abstract An accurate \{TCF\} (tool control frame) model is essential for high-accuracy robot off-line programming. Meanwhile, \{TCF\} calibration is an important procedure for production recovery after robot collides in industrial field. This article proposes a novel \{TCF\} calibration method in robotic visual measurement system in which the robot \{TCF\} is defined based on the model of visual sensor and a standard sphere with known diameter is utilized as the calibration target. With the translational and rotational movements of the industrial robot, the visual senor measures the center of standard sphere from multiple different robot postures, \{TCF\} orientation and \{TCP\} position are determined in two steps. Robot off-line programming is performed based on the \{TCF\} calibration result, and robot collision is simulated on an \{ABB\} \{IRB2400\} industrial robot. Experimental results have validated the effectiveness and efficiency of the standard sphere-based \{TCF\} calibration method, which could control the deviation of an identical featured point within 0.5 mm measured before and after collision recovery. "
}
@article{Mezgar2014657,
title = "The challenge of networked enterprises for cloud computing interoperability ",
journal = "Computers in Industry ",
volume = "65",
number = "4",
pages = "657 - 674",
year = "2014",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514000335",
author = "Istvan Mezgar and Ursula Rauschecker",
keywords = "Cloud computing",
keywords = "Networked enterprise",
keywords = "Interoperability",
keywords = "Manufacturing",
keywords = "Standardization ",
abstract = "Abstract Manufacturing enterprises have to organize themselves into effective system architectures forming different types of Networked Enterprises (NE) to match fast changing market demands. Cloud Computing (CC) is an important up to date computing concept for NE, as it offers significant financial and technical advantages beside high-level collaboration possibilities. As cloud computing is a new concept the solutions for handling interoperability, portability, security, privacy and standardization challenges have not been solved fully yet. The paper introduces the main characteristics of future Internet-based enterprises and the different \{CC\} models. An overview is given on interoperability and actual standardization issues in \{CC\} environments. A taxonomy on possible connecting forms of networked enterprises and cloud-based \{IT\} systems with reference on interoperability is introduced, parallel presenting four use cases as well. Finally, an example of connecting cloud and \{NE\} is presented as an effective application of cloud computing in manufacturing industry. "
}
@article{Richter2014114,
title = "Concepts and techniques for integration, analysis and visualization of massive 3D point clouds ",
journal = "Computers, Environment and Urban Systems ",
volume = "45",
number = "",
pages = "114 - 124",
year = "2014",
note = "",
issn = "0198-9715",
doi = "https://doi.org/10.1016/j.compenvurbsys.2013.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0198971513000653",
author = "Rico Richter and Jurgen Dollner",
keywords = "3D point clouds",
keywords = "System architecture",
keywords = "Classification",
keywords = "Out-of-core",
keywords = "Visualization ",
abstract = "Abstract Remote sensing methods, such as LiDAR and image-based photogrammetry, are established approaches for capturing the physical world. Professional and low-cost scanning devices are capable of generating dense 3D point clouds. Typically, these 3D point clouds are preprocessed by \{GIS\} and are then used as input data in a variety of applications such as urban planning, environmental monitoring, disaster management, and simulation. The availability of area-wide 3D point clouds will drastically increase in the future due to the availability of novel capturing methods (e.g., driver assistance systems) and low-cost scanning devices. Applications, systems, and workflows will therefore face large collections of redundant, up-to-date 3D point clouds and have to cope with massive amounts of data. Hence, approaches are required that will efficiently integrate, update, manage, analyze, and visualize 3D point clouds. In this paper, we define requirements for a system infrastructure that enables the integration of 3D point clouds from heterogeneous capturing devices and different timestamps. Change detection and update strategies for 3D point clouds are presented that reduce storage requirements and offer new insights for analysis purposes. We also present an approach that attributes 3D point clouds with semantic information (e.g., object class category information), which enables more effective data processing, analysis, and visualization. Out-of-core real-time rendering techniques then allow for an interactive exploration of the entire 3D point cloud and the corresponding analysis results. Web-based visualization services are utilized to make 3D point clouds available to a large community. The proposed concepts and techniques are designed to establish 3D point clouds as base datasets, as well as rendering primitives for analysis and visualization tasks, which allow operations to be performed directly on the point data. Finally, we evaluate the presented system, report on its applications, and discuss further research challenges. "
}
@article{Altaratz201438,
title = "Review: Cloud invigoration by aerosols—Coupling between microphysics and dynamics ",
journal = "Atmospheric Research ",
volume = "140–141",
number = "",
pages = "38 - 60",
year = "2014",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2014.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S0169809514000106",
author = "O. Altaratz and I. Koren and L.A. Remer and E. Hirsch",
keywords = "Aerosol and cloud",
keywords = "Cloud and precipitation",
keywords = "Climate ",
abstract = "Abstract The cloud invigoration effect refers here to the link between an increase in aerosol loading and deepening of convective clouds. The effect can be reflected also in a larger cloud fraction and an increase in the condensate mass that is distributed higher in the atmospheric column. Identifying the invigoration effect by aerosols requires attributing certain changes in cloud dynamics to changes in cloud microphysics. More than 10 years of extensive research using data collected in field experiments, analysis of satellite measurements and the employment of state-of-the-art numerical models have been used in an attempt to study this elusive phenomenon. Despite these intensive efforts, the validity of the invigoration effect and the possibility of climate responses to this effect are still considered to be open questions. In this review observational evidence and modeling results for cloud invigoration are discussed. Studies that indicate convective cloud invigoration effects, as well as studies that suggest no or even opposite effects are summarized. A coherent physical mechanism that describes a chain of processes that takes place under the proper conditions in the core of a convective cloud provides explanation for the “ideal” case of invigoration reported by observations and numerical modeling, while the competition between core-based vs. margin-based processes explains the cases that deviate from the “ideal”. Because convective clouds play a key role in the Earth's radiation balance, in the water cycle and atmospheric circulations, invigoration implies possible consequences at scales ranging from a single cloud up to the global. "
}
@article{Kinnell2017,
title = "Autonomous metrology for robot mounted 3D vision systems ",
journal = "\{CIRP\} Annals - Manufacturing Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0007-8506",
doi = "https://doi.org/10.1016/j.cirp.2017.04.069",
url = "http://www.sciencedirect.com/science/article/pii/S0007850617300690",
author = "Peter Kinnell and Tom Rymer and John Hodgson and Laura Justham and Mike Jackson",
keywords = "Metrology",
keywords = "Cognitive robotics",
keywords = "3D image processing ",
abstract = "Abstract Using a metrology system simulation approach, an algorithm is presented to determine the best position for a robot mounted 3D vision system. Point cloud data is simulated, taking into account sensor performance, to create a ranked list of the best camera positions. These can be used by a robot to autonomously determine the most advantageous camera position for locating a target object. The algorithm is applied to an Ensenso active stereo 3D camera. Results show that when used in combination with a \{RANSAC\} object recognition algorithm, it increased positional precision by two orders of magnitude, from worst to best case. "
}
@article{DrewsJr20131696,
title = "Novelty detection and segmentation based on Gaussian mixture models: A case study in 3D robotic laser mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1696 - 1709",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001115",
author = "Paulo Drews -Jr. and Pedro Nunez and Rui P. Rocha and Mario Campos and Jorge Dias",
keywords = "Novelty detection",
keywords = "Gaussian mixture model",
keywords = "3D robotic mapping ",
abstract = "Abstract This article proposes a framework to detect and segment changes in robotics datasets, using 3D robotic mapping as a case study. The problem is very relevant in several application domains, not necessarily related with mobile robotics, including security, health, industry and military applications. The aim is to identify significant changes by comparing current data with previous data provided by sensors. This feature is extremely challenging because large amounts of noisy data must be processed in a feasible way. The proposed framework deals with novelty detection and segmentation in robotic maps using clusters provided by Gaussian Mixture Models (GMMs). \{GMMs\} provides a feature space that enables data compression and effective processing. Two alternative criteria to detect changes in the \{GMM\} space are compared: a greedy technique based on the Earth Mover’s Distance (EMD); and a structural matching algorithm that fulfills both absolute (global matching) and relative constraints (structural matching). The proposed framework is evaluated with real robotic datasets and compared with other methods known from literature. With this purpose, 3D mapping experiments are carried out with both simulated data and real data from a mobile robot equipped with a 3D range sensor. "
}
@article{Hulik201486,
title = "Continuous plane detection in point-cloud data based on 3D Hough Transform ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "25",
number = "1",
pages = "86 - 97",
year = "2014",
note = "Visual Understanding and Applications with RGB-D Cameras ",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2013.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S104732031300062X",
author = "Rostislav Hulik and Michal Spanel and Pavel Smrz and Zdenek Materna",
keywords = "RGB-D sensor",
keywords = "Point cloud",
keywords = "Hough Transform",
keywords = "Plane detection",
keywords = "PCL library",
keywords = "RANSAC",
keywords = "Computer vision",
keywords = "Shape extraction ",
abstract = "Abstract This paper deals with shape extraction from depth images (point clouds) in the context of modern robotic vision systems. It presents various optimizations of the 3D Hough Transform used for plane extraction from point cloud data. Presented enhancements of standard methods address problems related to noisy data, high memory requirements for the parameter space and computational complexity of point accumulations. The realised robust plane detector benefits from a continuous point cloud stream generated by a depth sensor over time. It is used for iterative refinements of the results. The system is compared to a state-of-the-art RANSAC-based plane detector from the Point Cloud Library (PCL). Experimental results show that it overcomes the \{PCL\} alternative in the stability of plane detection and in the number of negative detections. This advantage is crucial for robotic applications, e.g., when a robot approaches a wall, it can be consistently recognized. The paper concludes with a discussion of further promising optimisation that will be implemented as a future step. "
}
@article{Janjai2014111,
title = "Modeling the luminous efficacy of direct and diffuse solar radiation using information on cloud, aerosol and water vapor in the tropics ",
journal = "Renewable Energy ",
volume = "66",
number = "",
pages = "111 - 117",
year = "2014",
note = "",
issn = "0960-1481",
doi = "https://doi.org/10.1016/j.renene.2013.11.070",
url = "http://www.sciencedirect.com/science/article/pii/S0960148113006587",
author = "S. Janjai and J. Prathumsit and S. Buntoung and R. Wattan and S. Pattarapanitchai and I. Masiri",
keywords = "Daylight",
keywords = "Luminous efficacy",
keywords = "Satellite-derived cloud index",
keywords = "Modeling",
keywords = "Aerosol optical depth",
keywords = "Tropics ",
abstract = "Abstract This paper presents luminous efficacy models for direct and diffuse solar irradiance using information on cloud, aerosol and water vapor in the tropics. The model is based on five years (2007–2011) of diffuse illuminance and irradiance measurements and two years of direct illuminance and irradiance measurements, April 2010–March 2012. Data are taken at four solar radiation monitoring stations in Thailand, specifically Chiang Mai (18.78 °N, 98.98 °E) in the Northern region, Ubon Ratchathani (15.25 °N, 104.87 °E) in the Northeastern region, Nakhon Pathom (13.82 °N, 100.04 °E) in the Central region and Songkhla (7.20 °N, 100.60 °E) in the Southern region. The models express luminous efficacy as functions of the aerosol optical depth and precipitable water, obtained from the \{AERONET\} network, and a cloud index for hourly time scales derived from the MTSAT-1R satellite. The model performance is good when validated against independent data from these stations. Root mean square differences (RMSD) of 9.7% and 6.8% for direct normal efficacy and diffuse efficacy, respectively are obtained. The models compared favorably with most existing models when tested against these independent data. "
}
@article{RodriguezGarcia2014295,
title = "Creating a semantically-enhanced cloud services environment through ontology evolution ",
journal = "Future Generation Computer Systems ",
volume = "32",
number = "",
pages = "295 - 306",
year = "2014",
note = "Special Section: The Management of Cloud Systems, Special Section: Cyber-Physical Society and Special Section: Special Issue on Exploiting Semantic Technologies with Particularization on Linked Data over Grid and Cloud Architectures ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13001684",
author = "Miguel angel Rodriguez-Garcia and Rafael Valencia-Garcia and Francisco Garcia-Sanchez and J. Javier Samper-Zapater",
keywords = "Semantic annotation",
keywords = "Ontology evolution",
keywords = "Cloud computing",
keywords = "Information extraction",
keywords = "Knowledge management",
keywords = "Ontology",
keywords = "Semantic web ",
abstract = "Abstract Currently, the availability of Web resources has grown enormously to the point that whatever a user needs at a given moment can potentially be found on the Internet. These resources are not limited to data items anymore, functionality delivered through some sort of service architectural model is also offered on the Internet. In the last few years, cloud computing has emerged as one of the most popular computing models to provide services over the Internet. However, as the number of available cloud services increases, the problem of service discovery and selection arises. Experience indicates that semantic technologies can provide the basis for enhanced and more precise search processes. In this paper, we present a platform that makes use of semantic technologies and techniques to facilitate the discovery of cloud resources meeting the users’ needs. We propose an architecture that puts together semantic annotation techniques, ontology evolution, term extraction and indexing resources to semantically annotate cloud services, and a semantic search engine that leverages the semantic description of the cloud resources to find them from keyword-based searches. A comprehensive evaluation of the tool in the \{ICT\} domain has produced very promising results and is also presented in this article. "
}
@article{Li2014187,
title = "Observations of residual submicron fine aerosol particles related to cloud and fog processing during a major pollution event in Beijing ",
journal = "Atmospheric Environment ",
volume = "86",
number = "",
pages = "187 - 192",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.12.044",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013009898",
author = "Zhengqiang Li and Tom Eck and Ying Zhang and Yuhuan Zhang and Donghui Li and Li Li and Hua Xu and Weizhen Hou and Yang Lv and Philippe Goloub and Xingfa Gu",
keywords = "Residual size",
keywords = "Submicron fine mode aerosol",
keywords = "Size distribution",
keywords = "Cloud",
keywords = "Fog",
keywords = "Haze ",
abstract = "Abstract Residual aerosols, the particles left behind after droplet evaporation, are important tracers for aerosols processed by cloud and/or fog. Based on ground-based \{CIMEL\} sun–sky radiometer measurements during an extreme winter pollution event in Beijing, we present observations of the decrease of residual aerosol with dissipation of cloud and an unusual case of residual aerosol increase after partial dissipation of fog. This unusual increase might be an important mechanism for the haze growth in polluted regions. The aerosol single scattering albedo is found to increase with the increase of residual aerosol. We also find that residual aerosol dominated cases with significant water content gain can occur in a short time (e.g. one hour) with the increase of aerosol volume size and decrease of particle number. A lognormal residual aerosol size distribution model is proposed based on sun–sky radiometer measurements with center peak radius at 0.44 micron and geometric standard deviation of about 1.49. "
}
@article{Fernandes2014372,
title = "CaRINA Intelligent Robotic Car: Architectural design and applications ",
journal = "Journal of Systems Architecture ",
volume = "60",
number = "4",
pages = "372 - 392",
year = "2014",
note = "",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2013.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S1383762113002841",
author = "Leandro C. Fernandes and Jefferson R. Souza and Gustavo Pessin and Patrick Y. Shinzato and Daniel Sales and Caio Mendes and Marcos Prado and Rafael Klaser and Andre Chaves Magalhaes and Alberto Hata and Daniel Pigatto and Kalinka Castelo Branco and Valdir Grassi Jr. and Fernando S. Osorio and Denis F. Wolf",
keywords = "Autonomous vehicle architecture",
keywords = "Embedded system design",
keywords = "Robotic vehicle navigation",
keywords = "Computer vision",
keywords = "Machine learning",
keywords = "Intelligent systems ",
abstract = "Abstract This paper presents the development of two outdoor intelligent vehicles platforms named CaRINA I and CaRINA II, their system architecture, simulation tools, and control modules. It also describes the development of the intelligent control system modules allowing the mobile robots and vehicles to navigate autonomously in controlled urban environments. Research work has been carried out on tele-operation, driver assistance systems, and autonomous navigation using the vehicles as platforms to experiments and validation. Our robotic platforms include mechanical adaptations and the development of an embedded software architecture. This paper addresses the design, sensing, decision making, and acting infrastructure and several experimental tests that have been carried out to evaluate both platforms and proposed algorithms. The main contributions of this work is the proposed architecture, that is modular and flexible, allowing it to be instantiated into different robotic platforms and applications. The communication and security aspects are also investigated. "
}
@article{Mateos20141216,
title = "Efficiency of clouds on shortwave radiation using experimental data ",
journal = "Applied Energy ",
volume = "113",
number = "",
pages = "1216 - 1219",
year = "2014",
note = "",
issn = "0306-2619",
doi = "https://doi.org/10.1016/j.apenergy.2013.08.060",
url = "http://www.sciencedirect.com/science/article/pii/S0306261913007046",
author = "D. Mateos and M. Anton and A. Valenzuela and A. Cazorla and F.J. Olmo and L. Alados-Arboledas",
keywords = "Cloud efficiency",
keywords = "Shortwave radiation",
keywords = "Clouds",
keywords = "Overcast conditions",
keywords = "Cloud optical depth ",
abstract = "Abstract An extended data set of ground-based measurements of shortwave radiation, and cloud optical depth (COD) has been used to evaluate the surface cloud radiative forcing (CRF) in the shortwave range under overcast conditions (confirmed with sky images) at Granada, Spain. \{CRF\} varies in linear way with the logarithm of the \{COT\} showing a high correlation. The slope of the regression line (b) exhibits a clear dependence on solar zenith angle (SZA). The change in \{CRF\} per COD-unit is the cloud forcing efficiency (CFE), which is defined as the \{CRF\} derivate with respect to COD. In this case, \{CFE\} = b/COD. Experimental \{CFE\} varies between −160 W m−2 per COD-unit for \{SZA\} = 14° and \{COD\} = 1, and −0.3 W m−2 per COD-unit for \{SZA\} = 80° and \{COD\} = 50. The largest values of \{CFE\} are observed at low \{SZA\} and low COD. These empirical results are corroborated by radiative transfer simulations carried out by LibRadtran code. "
}
@article{Wu201494,
title = "Cloud-based Manufacturing: Old Wine in New Bottles? ",
journal = "Procedia \{CIRP\} ",
volume = "17",
number = "",
pages = "94 - 99",
year = "2014",
note = "Variety Management in ManufacturingProceedings of the 47th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.01.035",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114002674",
author = "Dazhong Wu and David W. Rosen and Lihui Wang and Dirk Schaefer",
keywords = "cloud-based manufacturing",
keywords = "distributed manufacturing",
keywords = "cloud computing. ",
abstract = "Abstract Cloud-based manufacturing (CBM), also referred to as cloud manufacturing, is a form of decentralized and networked manufacturing evolving from other relevant manufacturing systems such as web- and agent-based manufacturing. An ongoing debate on \{CBM\} in the research community revolves around several aspects such as definitions, key characteristics, computing architectures, programming models, file systems, operational processes, information and communication models, and new business models pertaining to CBM. One question, in particular, has often been raised: Is cloud-based manufacturing a new paradigm, or is it just old wine in new bottles? Based on the discussion of the key characteristics of CBM, the derivation of requirements that an ideal \{CBM\} system should satisfy, and a thorough comparison between \{CBM\} and other relevant manufacturing systems, we provide supporting evidence that allows us to conclude that \{CBM\} is definitely a new paradigm that will revolutionize manufacturing. "
}
@article{Goodarzi2014320,
title = "Cloud Computing Security by Integrating Classical Encryption ",
journal = "Procedia Computer Science ",
volume = "42",
number = "",
pages = "320 - 326",
year = "2014",
note = "Medical and Rehabilitation Robotics and Instrumentation (MRRI2013) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.11.069",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914015075",
author = "Koorosh Goodarzi and Abbas karimi",
keywords = "cryptographic algorithms",
keywords = "cloud computing",
keywords = "classical and modern cryptographic algorithms ",
abstract = "Abstract Cloud calculation provides sharing of the spread sources and the services related to the organizations or websites users. As cloud computing of distributed resource is shared in an open environment, the security is the biggest problem in software development. On one hand user controls data and process on his own computer and on the other hand, data services provided by the company and the vendor are kept in the cloud so that the user does not know where to store the data and has no control over it. In this paper, we try a hybrid methodology of modern and classic cryptographic algorithms for providing data security in a cloud environment. "
}
@article{Tao2014183,
title = "A study of urban pollution and haze clouds over northern China during the dusty season based on satellite and surface observations ",
journal = "Atmospheric Environment ",
volume = "82",
number = "",
pages = "183 - 192",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013007632",
author = "Minghui Tao and Liangfu Chen and Zifeng Wang and Pengfei Ma and Jinhua Tao and Songlin Jia",
keywords = "Urban pollution",
keywords = "Satellite",
keywords = "Haze clouds",
keywords = "Dust transport",
keywords = "Northern China ",
abstract = "Abstract This paper presents a multi-scale study on formation process of urban pollution and haze clouds as well as their interactions over northern China in spring using integrated satellite and surface observations. Several extreme haze events occurred in Beijing area in March 2013, but primary atmospheric pollutants in the urban pollution exhibited inconsistent variations with the widespread haze clouds observed by satellites. Two typical types of haze event were found in Beijing area. Type-1 haze pollution appeared in stagnant weather conditions, during which PM2.5 was &lt;200 μg m−3 with a short duration within 1–2 days. By contrast, strong northwestern winds prevailed in type-2 haze events with durative and intense temperature inversion near surface. Meanwhile, PM2.5 concentration exceeded ∼400 μg m−3 in type-2 pollution, and the heavy pollution can last 3–5 days. Different from urban pollution, our results show that the thick haze clouds were dominated by mixing of floating dust and anthropogenic pollutants in the middle and upper part, accompanied by hygroscopic growth of fine particles. Elevated coarse dust particles were prevalent over northern China, which accounted for a predominant fraction in the columnar optical volume during all the haze events. Furthermore, comparison between satellite and surface observations indicates that haze clouds above surface had no significant direct contribution to the serious urban pollution. In addition, mixing of dust and anthropogenic pollutants at high altitudes regulates regional aerosol optical properties throughout the whole March. "
}
@article{Gomez2007171,
title = "A \{ROBOTIC\} \{SYSTEM\} \{FOR\} \{PCBS\} \{INSPECTION\} \{BASED\} \{ON\} \{COMPUTER\} \{VISION\} \{AND\} \{MOBILE\} \{PROBES\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "3",
pages = "171 - 176",
year = "2007",
note = "8th \{IFAC\} Workshop on Intelligent Manufacturing Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070523-3-ES-4908.00029",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015403453",
author = "J. Gomez and J. Gamez and A.G. Gonzalez and L. Nieto and S. Satorres and A. Sanchez",
keywords = "Robotics",
keywords = "Automatic Testing",
keywords = "Position Control",
keywords = "Visual pattern recognition ",
abstract = "Abstract In this paper a new robotized inspection system for \{PCBs\} is presented. Electrical and optical tests are carried out by the system, using four mobile probes where two micro \{CCD\} cameras are mounted. This new approach becomes a costless and quick setup alternative to the currently used spiked beds for those applications of prototyping developments where maximum flexibility is demanded for the inspection system. A computer vision system provides the capacity for optical inspections where visual tests, like part presence/absence or polarity, can be performed. "
}
@article{VincentWang2013232,
title = "An interoperable solution for Cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "4",
pages = "232 - 247",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2013.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584513000069",
author = "Xi Vincent Wang and Xun W. Xu",
keywords = "Cloud",
keywords = "Cloud computing",
keywords = "Cloud manufacturing",
keywords = "Service-oriented architecture",
keywords = "STEP ",
abstract = "Cloud manufacturing is a new concept extending and adopting the concept of Cloud computing for manufacturing. The aim is to transform manufacturing businesses to a new paradigm in that manufacturing capabilities and resources are componentized, integrated and optimized globally. This study presents an interoperable manufacturing perspective based on Cloud manufacturing. A literature search has been undertaken regarding Cloud architecture and technologies that can assist Cloud manufacturing. Manufacturing resources and capabilities are discussed in terms of Cloud service. A service-oriented, interoperable Cloud manufacturing system is proposed. Service methodologies are developed to support two types of Cloud users, i.e., customer user and enterprise user, along with standardized data models describing Cloud service and relevant features. Two case studies are undertaken to evaluate the proposed system. Cloud technology brings into manufacturing industry with a number of benefits such as openness, cost-efficiency, resource sharing and production scalability. "
}
@article{Zou20131459,
title = "Iso-parametric tool-path planning for point clouds ",
journal = "Computer-Aided Design ",
volume = "45",
number = "11",
pages = "1459 - 1468",
year = "2013",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2013.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0010448513001255",
author = "Qiang Zou and Jibin Zhao",
keywords = "Tool path",
keywords = "Point cloud",
keywords = "Meshless",
keywords = "Conformal parameterization",
keywords = "Linear interpolation ",
abstract = "Abstract Due to the compute-intensiveness and the lack of robustness of the algorithms for reconstruction of meshes and spline surfaces from point clouds, there is a need for further research in the topic of direct tool-path planning based on point clouds. In this paper, a novel approach for planning iso-parametric tool-path from a point cloud is presented. Since such planning falls into the iso-parametric category, it intrinsically depends on the parameterization of point clouds. Accordingly, a point-based conformal map is employed to build the parameterization. Based on it, formulas of computing path parameters are derived, which are much simpler than the conventional ones. By regularizing parameter domain and on the basis of the previous formulas, boundary conformed tool-path can be generated with forward and side step calculated against specified chord deviation and scallop height, respectively. Experimental results are given to illustrate the effectiveness of the proposed methods. "
}
@article{Xiao20131641,
title = "Three-dimensional point cloud plane segmentation in both structured and unstructured environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1641 - 1652",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001152",
author = "Junhao Xiao and Jianhua Zhang and Benjamin Adler and Houxiang Zhang and Jianwei Zhang",
keywords = "3D point cloud",
keywords = "Plane segmentation",
keywords = "Region growing ",
abstract = "Abstract This paper focuses on three-dimensional (3D) point cloud plane segmentation. Two complementary strategies are proposed for different environments, i.e., a subwindow-based region growing (SBRG) algorithm for structured environments, and a hybrid region growing (HRG) algorithm for unstructured environments. The point cloud is decomposed into subwindows first, using the points’ neighborhood information when they are scanned by the laser range finder (LRF). Then, the subwindows are classified as planar or nonplanar based on their shape. Afterwards, only planar subwindows are employed in the former algorithm, whereas both kinds of subwindows are used in the latter. In the growing phase, planar subwindows are investigated directly (in both algorithms), while each point in nonplanar subwindows is investigated separately (only in HRG). During region growing, plane parameters are computed incrementally when a subwindow or a point is added to the growing region. This incremental methodology makes the plane segmentation fast. The algorithms have been evaluated using real-world datasets from both structured and unstructured environments. Furthermore, they have been benchmarked against a state-of-the-art point-based region growing (PBRG) algorithm with regard to segmentation speed. According to the results, \{SBRG\} is 4 and 9 times faster than \{PBRG\} when the subwindow size is set to 3×3 and 4×4 respectively; \{HRG\} is 4 times faster than \{PBRG\} when the subwindow size is set to 4×4. Open-source code for this paper is available at https://github.com/junhaoxiao/TAMS-Planar-Surface-Based-Perception.git. "
}
@article{Wu2013564,
title = "Cloud manufacturing: Strategic vision and state-of-the-art ",
journal = "Journal of Manufacturing Systems ",
volume = "32",
number = "4",
pages = "564 - 579",
year = "2013",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2013.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0278612513000411",
author = "Dazhong Wu and Matthew John Greer and David W. Rosen and Dirk Schaefer",
keywords = "Cloud manufacturing (CM)",
keywords = "Distributed systems",
keywords = "Resource sharing",
keywords = "Automation and control ",
abstract = "Abstract Cloud manufacturing, a service oriented, customer centric, demand driven manufacturing model is explored in both its possible future and current states. A unique strategic vision for the field is documented, and the current state of technology is presented from both industry and academic viewpoints. Key commercial implementations are presented, along with the state of research in fields critical to enablement of cloud manufacturing, including but not limited to automation, industrial control systems, service composition, flexibility, business models, and proposed implementation models and architectures. Comparison of the strategic vision and current state leads to suggestions for future work, including research in the areas of high speed, long distance industrial control systems, flexibility enablement, business models, cloud computing applications in manufacturing, and prominent implementation architectures. "
}
@article{Arka2014114,
title = "Collaborative Compressed I-cloud Medical Image Storage with Decompress Viewer ",
journal = "Procedia Computer Science ",
volume = "42",
number = "",
pages = "114 - 121",
year = "2014",
note = "Medical and Rehabilitation Robotics and Instrumentation (MRRI2013) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.11.041",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914014793",
author = "Israna Hossain Arka and Kalaivani Chellappan",
keywords = "medical imaging",
keywords = "cloud storage",
keywords = "compression",
keywords = "decompression",
keywords = "mobile devices",
keywords = "data security",
keywords = "collaborative. ",
abstract = "Abstract Healthcare collaborative approach is anticipated to be an appropriate solution for disease management structure in the growing global population. Efficient disease management structure needs deep analytical skills in making effective decisions based on medical data. The nature of medical data being huge in size has been categorized as big data. Big data management in a collaborative environment needs multiple technological integrations. In this paper we have proposed an independent cloud based collaborative medical image storage and mobile viewer assisted with effective compression and decompression technique with unique security structure design. The proposed design has considered deep technology exploitation to offer medical image access via mobile devices by considering all the current constraints in terms of storage, image clarity and security. The proposed architecture allows both patient and medical practioners to have a cost effective approach in disease management and treatment process. It also introduces healthcare analysts and practitioners to the advancements in the computing field to effectively handle and make inferences from voluminous and heterogeneous healthcare data. Due to the broad nature of the topic, our primary emphasis will be on introducing healthcare data repositories, challenges, and concepts in data science. Not much focus will be on describing the details of any particular techniques and/or solutions in image compression, security and the medical field in particular other than convenient data access opportunity framework. "
}
@article{Anil2013507,
title = "Deviation analysis method for the assessment of the quality of the as-is Building Information Models generated from point cloud data ",
journal = "Automation in Construction ",
volume = "35",
number = "",
pages = "507 - 516",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001003",
author = "Engin Burak Anil and Pingbo Tang and Burcu Akinci and Daniel Huber",
keywords = "As-is Building Information Modeling",
keywords = "BIM",
keywords = "Laser scanning",
keywords = "Point clouds",
keywords = "Quality assessment",
keywords = "Quality inspection ",
abstract = "Abstract Generating three-dimensional (3D) as-is Building Information Models (BIMs), representative of the existing conditions of buildings, from point cloud data collected by laser scanners is becoming common practice. However, generation of such models currently is mostly performed manually, and errors can be introduced during data collection, pre-processing, and modeling. This paper presents a method for assessing the quality of as-is \{BIMs\} generated from point cloud data by analyzing the patterns of geometric deviations between the model and the point cloud data. The fundamental assumption is that the point cloud and the as-is \{BIM\} generated from the point cloud should corroborate in the depiction of the components and their spatial attributes. Major geometric deviations between as-is models and point clouds can indicate potential errors introduced during data collection, processing and/or model generation. The research described in this paper provides a taxonomy for patterns of deviations and sources of errors and demonstrates that it is possible to identify the source, magnitude, and nature of errors by analyzing the deviation patterns. The method is validated through a comparison with the currently adopted physical measurement method in a case study. The results show that the deviation analysis method is capable of identifying almost six times more errors with more than 40% time savings compared to the physical measurement method. "
}
@article{Stock2014320,
title = "Cloud-based Platform to Facilitate Access to Manufacturing \{IT\} ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "320 - 328",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.045",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010762",
author = "Daniel Stock and Matthias Stohr and Ursula Rauschecker and Thomas Bauernhansl",
keywords = "Manufacturing",
keywords = "cloud",
keywords = "software engineering",
keywords = "service orientation",
keywords = "manufacturing \{IT\} ",
abstract = "Abstract Today information technology is one of the main enablers of efficient production due to its ability to support manufacturing planning, execution, and optimization. However, most of the tools that provide these features are extremely complex and require on-site installation, individual configuration, administration, maintenance, etc. In many cases, the costs and efforts involved are too high for small and medium sized enterprises (SMEs) to bear. As a result, such companies are often unable to exploit the full potentials of manufacturing-related software systems. To overcome this problem, an \{IT\} infrastructure has been developed at Fraunhofer \{IPA\} which makes it easier to access manufacturing IT. The associated \{IT\} services, which are also accessible to SMEs, offer features for product tracking, process monitoring and control, etc., and are embedded in a cloud-based infrastructure, configurable to specific factory demands and accessible via apps (e.g. mobile devices). This paper addresses the relevant infrastructure requirements, such as security, equipment integration, \{IT\} service management, workflow management and execution as well as user-specific app configuration. The basic architecture of the developed infrastructure is then discussed on the basis of these. The concept of engineering apps is taken as an example to underline the main benefits of such an infrastructure. "
}
@article{Citak2013268,
title = "Unicompartmental knee arthroplasty: Is robotic technology more accurate than conventional technique? ",
journal = "The Knee ",
volume = "20",
number = "4",
pages = "268 - 271",
year = "2013",
note = "",
issn = "0968-0160",
doi = "https://doi.org/10.1016/j.knee.2012.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0968016012002232",
author = "Mustafa Citak and Eduardo M. Suero and Musa Citak and Nicholas J. Dunbar and Sharon H. Branch and Michael A. Conditt and Scott A. Banks and Andrew D. Pearle",
keywords = "Robotic-assisted",
keywords = "Unicompartmental knee arthroplasty",
keywords = "Navigation",
keywords = "Accuracy ",
abstract = "Background Robotic-assisted unicompartmental knee arthroplasty (UKA) with rigid bone fixation'can significantly improve implant placement and leg alignment'. The aim of this cadaveric study was to determine whether the use of robotic systems with dynamic bone tracking would provide more accurate \{UKA\} implant positioning compared to the conventional manual technique. Methods Three-dimensional CT-based preoperative plans were created to determine the desired position and orientation for the tibial and femoral components. For each pair of cadaver knees, \{UKA\} was performed using traditional instrumentation on the left side and using a haptic robotic system on the right side. Postoperative \{CT\} scans were obtained and 3D-to-3D iterative closest point registration was performed. Implant position and orientation were compared to the preoperative plan. Results Surgical \{RMS\} errors for femoral component placement were within 1.9 mm and 3.7° in all directions of the planned implant position for the robotic group, while \{RMS\} errors for the manual group were within 5.4 mm and 10.2°. Average \{RMS\} errors for tibial component placement were within 1.4 mm and 5.0° in all directions for the robotic group; while, for the manual group, \{RMS\} errors were within 5.7 mm and 19.2°. Conclusions \{UKA\} was more precise using a semiactive robotic system with dynamic bone tracking technology compared to the manual technique. "
}
@article{GuerreroRascado2013210,
title = "Retrieval and variability analysis of optically thin cloud optical depths from a Cimel sun-photometer ",
journal = "Atmospheric Research ",
volume = "127",
number = "",
pages = "210 - 220",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512003511",
author = "J.L. Guerrero-Rascado and M.J. Costa and A.M. Silva and F.J. Olmo",
keywords = "Cloud optical depth",
keywords = "Sun-photometer",
keywords = "Optically thin clouds ",
abstract = "In this work we propose a technique to retrieve optical depths for optically thin clouds. This method complements the current performance of \{AERONET\} for optically thick cloud measurements using data eliminated by the cloud-screening algorithm that are not useful to derive aerosol properties, therefore inexpensively increasing the capabilities of the sun-photometers. The proposed method is based on the computation of the apparent cloud optical depths and on a forward scattering correction method that exploits state-of-the-art ice cloud scattering models. This complementary procedure is applied to Cimel sun-photometer measurements performed at the evora Geophysics Centre (Portugal, 38.6°N, 7.9°W, 293 m asl) included in the \{AERONET\} network in order to obtain a climatology of optical depths for optically thin clouds over middle-latitude continental regions of the southwestern Iberian Peninsula. Main features regarding annual and seasonal variability and the relative changes in the infrared radiative forcing from 2007 to 2010 are also reported and analyzed. "
}
@article{Santos2013178,
title = "Modeling Saharan desert dust radiative effects on clouds ",
journal = "Atmospheric Research ",
volume = "127",
number = "",
pages = "178 - 194",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512003262",
author = "D. Santos and M.J. Costa and A.M. Silva and R. Salgado",
keywords = "Atmospheric modeling",
keywords = "Cloud and aerosol radiative effects",
keywords = "Global warming",
keywords = "Radiative transfer ",
abstract = "This work aims at studying the Saharan desert dust storm effects on clouds. This is done through the investigation of the possible modifications that mineral desert dust aerosols may exert on clouds, modifying their properties and also through the estimation of the cloud radiative forcing in the presence of this type of aerosols, during strong desert dust events that occurred in the end of May 2006 and in the beginning of September 2007. The assessment of the cloud radiative forcing is made at a regional scale both at the top of the atmosphere (TOA) and at the surface levels. The results are obtained from numerical simulations with a mesoscale atmospheric model (MesoNH) over Portugal area and nearby Atlantic Ocean. From the results obtained it is possible to observe that, for all days under study, a cooling effect is always found both at the \{TOA\} and surface levels. Also, for these two levels and for clouds developing in a dusty atmosphere, a more pronounced cooling effect (more negative cloud radiative forcing values) is found compared with the corresponding cloud radiative forcing values for clouds developing in a dust free atmosphere. "
}
@article{Katsaros20132077,
title = "A service framework for energy-aware monitoring and \{VM\} management in Clouds ",
journal = "Future Generation Computer Systems ",
volume = "29",
number = "8",
pages = "2077 - 2091",
year = "2013",
note = "Including Special sections: Advanced Cloud Monitoring Systems &amp; The fourth \{IEEE\} International Conference on e-Science 2011 — e-Science Applications and Tools &amp; Cluster, Grid, and Cloud Computing ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2012.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X12002269",
author = "Gregory Katsaros and Josep Subirats and J. Oriol Fito and Jordi Guitart and Pierre Gilet and Daniel Espling",
keywords = "Monitoring",
keywords = "Cloud",
keywords = "Energy efficiency",
keywords = "Energy consumption ",
abstract = "The monitoring of QoS parameters in Services Computing as well as in Clouds has been a functionality provided by all contemporary systems. As the optimization of energy consumption becomes a major concern for system designers and administrators, it can be considered as another QoS metric to be monitored. In this paper, we present a service framework that allows us to monitor the energy consumption of a Cloud infrastructure, calculate its energy efficiency, and evaluate the gathered data in order to put in place an effective virtual machine (VM) management. In that context, a simulation scenario of an eco-driven \{VM\} placement policy resulted in a 14% improvement of the infrastructure’s energy efficiency. In total, the proposed approaches and implementations have been validated against a testbed, producing very promising results regarding the prospect of energy efficiency as an important quality factor in Clouds. "
}
@article{BeserraGomes2013496,
title = "Efficient 3D object recognition using foveated point clouds ",
journal = "Computers & Graphics ",
volume = "37",
number = "5",
pages = "496 - 508",
year = "2013",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2013.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0097849313000459",
author = "Rafael Beserra Gomes and Bruno Marques Ferreira da Silva and Lourena Karin de Medeiros Rocha and Rafael Vidal Aroca and Luiz Carlos Pacheco Rodrigues Velho and Luiz Marcos Garcia Goncalves",
keywords = "Point cloud",
keywords = "3D object recognition",
keywords = "Moving fovea ",
abstract = "Abstract Recent hardware technologies have enabled acquisition of 3D point clouds from real world scenes in real time. A variety of interactive applications with the 3D world can be developed on top of this new technological scenario. However, a main problem that still remains is that most processing techniques for such 3D point clouds are computationally intensive, requiring optimized approaches to handle such images, especially when real time performance is required. As a possible solution, we propose the use of a 3D moving fovea based on a multiresolution technique that processes parts of the acquired scene using multiple levels of resolution. Such approach can be used to identify objects in point clouds with efficient timing. Experiments show that the use of the moving fovea shows a seven fold performance gain in processing time while keeping 91.6% of true recognition rate in comparison with state-of-the-art 3D object recognition methods. "
}
@article{Givehchi2016,
title = "Cloud-DPP for distributed process planning of mill-turn machining operations ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515301587",
author = "Mohammad Givehchi and Azadeh Haghighi and Lihui Wang",
keywords = "Multi-tasking machine",
keywords = "Mill-turn part",
keywords = "Function block-based adaptive distributed process planning",
keywords = "Machine mode ",
abstract = "Abstract Today, the dynamic market requires manufacturing firms to possess a high degree of adaptability to deal with shop-floor uncertainties. Specifically targeting \{SMEs\} active in the metal cutting sector who normally deal with intensive process planning problems, researchers have tried to address the subject. Among proposed solutions, Cloud-DPP elaborates a two-layer distributed adaptive process planning based on function-block technology and cloud concept. One of the challenges of companies is to machine as many part features as possible in a single setup on a single machine. Nowadays, multi-tasking machines are widely used due to their various advantages such as reducing setup times and increasing part accuracy. However, they also possess programming challenges because of their complex configuration and multiple machining functions. This paper reports the latest state of design and implementation of Cloud-DPP methodology to support parts with a combination of milling and turning features, and process planning for multi-tasking machining centers with special functionalities to minimize the number of setups. The contributions of this work are: representation of machining states and part transfer functionality, support of multi-tasking machines in adaptive setup merging, development of special function blocks to handle sub-setups and transitions, and finally generation of function-block network for the merged setups. The developed prototype is validated through a case study. "
}
@article{Herrero2017,
title = "Skill based robot programming: Assembly, vision and Workspace Monitoring skill interaction ",
journal = "Neurocomputing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2016.09.133",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217305441",
author = "Hector Herrero and Amine Abou Moughlbay and Jose Luis Outon and Damien Salle and Karmele Lopez de Ipina",
keywords = "Robotics",
keywords = "Flexibility",
keywords = "Skill based programming",
keywords = "State machine",
keywords = "Easy programming",
keywords = "Vision skills",
keywords = "Collaborative robots",
keywords = "Workspace Monitoring ",
abstract = "Abstract The skill based programming eases the robot program generation, its similarity to human behavior allows non expert operators maintaining, adapting or creating robotic applications. The use of skills requires different approaches for the interaction between them, especially for sharing information. The presented approach combines the skill based programming using a state machine for low level robot execution management. With the proposed framework the interaction and communication between skills is improved. The work presented below is focused on the use of vision skills and safe Workspace Monitoring, for addressing a real use case where interaction with robot motions (organized as assembly skills) is required. "
}
@article{Morales2017355,
title = "Social robotic wheelchair centered on passenger and pedestrian comfort ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "355 - 362",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S092188901630570X",
author = "Yoichi Morales and Takahiro Miyashita and Norihiro Hagita",
keywords = "Human–robot comfortable interaction",
keywords = "Social navigation",
keywords = "Spatial cognition ",
abstract = "Abstract The use of robot technology such as robotic wheelchairs is crucial to provide services for super-aging societies. A social issue in current robotic wheelchairs is the lack of passenger and pedestrian comfort considerations. This paper proposes a balanced navigation model for the passenger and pedestrians in terms of social issues regarding wheelchair navigation. The model considers comfort requirements for the passenger and pedestrians and is used to compute social wheelchair paths. Model validation was performed with human participants in the case of a single passenger and a pedestrian where experimental results show that overall comfort should be considered for computing socially accepted paths. Passengers and pedestrians scored the paths computed by the social planner as more comfortable than state of the art shortest paths. "
}
@article{Jiang201351,
title = "A numerical study of the effect of different aerosol types on East Asian summer clouds and precipitation ",
journal = "Atmospheric Environment ",
volume = "70",
number = "",
pages = "51 - 63",
year = "2013",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2012.12.039",
url = "http://www.sciencedirect.com/science/article/pii/S135223101300006X",
author = "Yiquan Jiang and Xiaohong Liu and Xiu-Qun Yang and Minghuai Wang",
keywords = "Aerosol",
keywords = "Cloud",
keywords = "Precipitation",
keywords = "Climate",
keywords = "Community Atmospheric Model version 5 ",
abstract = "In this study, the anthropogenic aerosol impact on the summer monsoon clouds and precipitation in East Asia is investigated using the \{NCAR\} Community Atmospheric Model version 5 (CAM5), a state-of-the-art climate model considering aerosol direct, semi-direct and indirect effects. The effects of all anthropogenic aerosols, and anthropogenic black carbon (BC), sulfate, and primary organic matter (POM) are decomposed from different sensitivity simulations. Anthropogenic sulfate and \{POM\} reduce the solar flux reaching the surface directly by scattering the solar radiation, and indirectly by increasing the cloud droplet number concentration and cloud liquid water path over East China. The surface air temperature over land is reduced, and the precipitation in North China is suppressed. Unlike anthropogenic sulfate and POM, anthropogenic \{BC\} does not have a significant effect on the air temperature at the surface, because of the reduction of the cloud liquid water path and the weakening of shortwave cloud forcing by its semi-direct effect. The anthropogenic \{BC\} strengthens the southwesterly wind over South China and leads to stronger deep convection at the 25°N–30°N latitudinal band. The effect of all anthropogenic aerosols on air temperature, clouds, and precipitation is not a linear summation of effects from individual anthropogenic sulfate, \{BC\} and POM. Overall all anthropogenic aerosols suppress the precipitation in North China and enhance the precipitation in South China and adjacent ocean regions. "
}
@article{Munaro201342,
title = "3D flow estimation for human action recognition from colored point clouds ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "5",
number = "",
pages = "42 - 51",
year = "2013",
note = "Extended versions of selected papers from the Third Annual Meeting of the \{BICA\} Society (BICA 2012) ",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2013.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X13000431",
author = "Matteo Munaro and Gioia Ballin and Stefano Michieletto and Emanuele Menegatti",
keywords = "Action recognition",
keywords = "3D motion flow",
keywords = "IAS-Lab Action Dataset",
keywords = "Colored point clouds",
keywords = "RGB-D data",
keywords = "Kinect ",
abstract = "Abstract Motion perception and classification are key elements exploited by humans for recognizing actions. The same principles can serve as a basis for building cognitive architectures which can recognize human actions, thus enhancing challenging applications such as human robot interaction, visual surveillance, content-based video analysis and motion capture. In this paper, we propose an autonomous system for real-time human action recognition based on 3D motion flow estimation. We exploit colored point cloud data acquired with a Microsoft Kinect and we summarize the motion information by means of a 3D grid-based descriptor. Finally, temporal sequences of descriptors are classified with the Nearest Neighbor technique. We also present a newly created public dataset for RGB-D human action recognition which contains 15 actions performed by 12 different people. Our overall system is tested on this dataset and on the dataset used in Ballin, Munaro, and Menegatti (2012), showing the effectiveness of the proposed approach in recognizing about 90% of the actions. "
}
@article{Meng20132361,
title = "Parameterization of point-cloud freeform surfaces using adaptive sequential learning \{RBFnetworks\} ",
journal = "Pattern Recognition ",
volume = "46",
number = "8",
pages = "2361 - 2375",
year = "2013",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2013.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S003132031300054X",
author = "Qinggang Meng and Baihua Li and Horst Holstein and Yonghuai Liu",
keywords = "Surface parameterization",
keywords = "Point clouds",
keywords = "Adaptive sequential learning ",
abstract = "We propose a self-organizing Radial Basis Function (RBF) neural network method for parameterization of freeform surfaces from larger, noisy and unoriented point clouds. In particular, an adaptive sequential learning algorithm is presented for network construction from a single instance of point set. The adaptive learning allows neurons to be dynamically inserted and fully adjusted (e.g. their locations, widths and weights), according to mapping residuals and data point novelty associated to underlying geometry. Pseudo-neurons, exhibiting very limited contributions, can be removed through a pruning procedure. Additionally, a neighborhood extended Kalman filter (NEKF) was developed to significantly accelerate parameterization. Experimental results show that this adaptive learning enables effective capture of global low-frequency variations while preserving sharp local details, ultimately leading to accurate and compact parameterization, as characterized by a small number of neurons. Parameterization using the proposed \{RBF\} network provides simple, low cost and low storage solutions to many problems such as surface construction, re-sampling, hole filling, multiple level-of-detail meshing and data compression from unstructured and incomplete range data. Performance results are also presented for comparison. "
}
@article{Kwon2013618,
title = "Development of optimized point cloud merging algorithms for accurate processing to create earthwork site models ",
journal = "Automation in Construction ",
volume = "35",
number = "",
pages = "618 - 624",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S092658051300006X",
author = "Soonwook Kwon and Mina Lee and Moonju Lee and Sukhan Lee and Junbok Lee",
keywords = "3D point",
keywords = "Automatic construction",
keywords = "Merging algorithm",
keywords = "3D laser scanner",
keywords = "Stereo vision",
keywords = "Earthwork",
keywords = "Point cloud ",
abstract = "Abstract Because of the nature of earthwork, there are difficulties in improving productivity due to situational variability and task complexity. Therefore, automation is receiving attention as a method to improve productivity. This study was conducted as a part of the \{IES\} (Intelligent Excavator System). The \{IES\} (Intelligent Excavator System) is intended for development of unmanned and remote controlled excavation systems for earthwork. The purpose of this study was to develop algorithms to merge two models acquired by a 3D laser scanner and Stereovision system in real time. To develop accurate and fast merging algorithms, \{ICP\} (Iterative Closest Point)-based merging algorithms and normal vectors were applied. Algorithms to merge the two models and to reflect the characteristics of the necessary earthwork will be proposed. "
}
@article{Amoretti2013767,
title = "Efficient autonomic cloud computing using online discrete event simulation ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "73",
number = "6",
pages = "767 - 776",
year = "2013",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2013.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0743731513000336",
author = "Michele Amoretti and Francesco Zanichelli and Gianni Conte",
keywords = "Cloud management",
keywords = "Autonomic computing",
keywords = "Discrete event simulation ",
abstract = "Abstract Interest is growing in open source tools that let organizations build IaaS clouds using their own internal infrastructures, alone or in conjunction with external ones. A key component in such private/hybrid clouds is virtual infrastructure management, i.e., the dynamic orchestration of virtual machines, based on the understanding and prediction of performance at scale, with uncertain workloads and frequent node failures. Part of the research community is trying to solve this and other IaaS problems looking to Autonomic Computing techniques, that can provide, for example, better management of energy consumption, quality of service (QoS), and unpredictable system behaviors. In this context, we first recall the main features of the \{NAM\} framework devoted to the design of distributed autonomic systems. Then we illustrate the organization and policies of a NAM-based Workload Manager, focusing on one of its components, the Capacity Planner. We show that, when it is not possible to obtain optimal energy-aware plans analytically, sub-optimal plans can be autonomically obtained using online discrete event simulation. Specifically, the proposed approach allows to cope with a broader range of working conditions and types of workloads. "
}
@article{Tarchinskaya2013335,
title = "Cloud-based Engineering Design and Manufacturing: State-of-the-Art ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "9",
pages = "335 - 340",
year = "2013",
note = "7th \{IFAC\} Conference on Manufacturing Modelling, Management, and Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130619-3-RU-3018.00632",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016343087",
author = "Ekaterina Tarchinskaya and Victor Taratoukhine and Martin Matzner",
keywords = "Manufacturing",
keywords = "engineering design",
keywords = "cloud computing",
keywords = "agile manufacturing",
keywords = "business processes ",
abstract = "Abstract Cloud-based technologies proliferated in the past few years, while the manufacturing industry moved towards digitization and network. Therefore, cloud-based technologies have been adopted in the development of new generation manufacturing systems which orchestrate different activities, including product design, process and task planning, production, customer service, etc. These new cloud-ingrained technologies have the potential to change the collaboration of product development partners, the processing and sharing of information as well as utilization rates of critical equipment. Cloud-based technologies affect many aspects of manufacturing activities, and they therefore have the power to enable new or change existing business models of the manufacturing industry. Based on the literature review, this paper analyzes the latest requirements, challenges, and trends of the manufacturing industry. It structures the findings in the coherent manner and further hypothesizes how cloud computing may address identified requirements and challenges as well as realize or support new concepts in manufacturing. "
}
@article{Ferreira2013366,
title = "Cloudlet Architecture for Dashboard in Cloud and Ubiquitous Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "12",
number = "",
pages = "366 - 371",
year = "2013",
note = "Eighth \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.09.063",
url = "http://www.sciencedirect.com/science/article/pii/S221282711300704X",
author = "Luis Ferreira and Goran Putnik and Manuela Cunha and Zlata Putnik and Helio Castro and Catia Alves and Vaibhav Shah and Maria Leonilde R. Varela",
keywords = "Cloud Manufacturing",
keywords = "Ubiquitous Manufacturing",
keywords = "Pragmatics",
keywords = "User Pragmatics",
keywords = "Interoperability",
keywords = "User Experiencee",
keywords = "Cloudlet ",
abstract = "Abstract The aim of this paper is to present a cloudlet architecture for dashboard in Cloud and Ubiquitous Manufacturing. In practice means that, with Cloud Computing adoption, Manufacturing requires management applications where ubiquity and effectiveness are enabled. If ubiquity and resources scalability, availability and capacity can be well supported by cloud, pragmatics instruments are required to support effectiveness. The architecture here presented shows the integration of enriched existing (cloud) services, as instances of resources, with layers of new services towards direct and synchronous communication between users. These Rich Internet Application (RIA) components, here named cloudlets, integration, follow dashboards organization patterns and will be supported by emergent web3.0 interaction technologies. In fact, the paper proposes a new Presentation Layer to be used in \{UMS\} and (that may be used) in any multi-layer cloud-based web application. "
}
@article{LD20132292,
title = "Honey bee behavior inspired load balancing of tasks in cloud computing environments ",
journal = "Applied Soft Computing ",
volume = "13",
number = "5",
pages = "2292 - 2303",
year = "2013",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2013.01.025",
url = "http://www.sciencedirect.com/science/article/pii/S1568494613000446",
author = "Dhinesh Babu L.D. and P. Venkata Krishna",
keywords = "Load balancing",
keywords = "Cloud computing",
keywords = "Priorities of tasks",
keywords = "Honey bee behavior",
keywords = "Performance evaluation ",
abstract = "Scheduling of tasks in cloud computing is an NP-hard optimization problem. Load balancing of non-preemptive independent tasks on virtual machines (VMs) is an important aspect of task scheduling in clouds. Whenever certain \{VMs\} are overloaded and remaining \{VMs\} are under loaded with tasks for processing, the load has to be balanced to achieve optimal machine utilization. In this paper, we propose an algorithm named honey bee behavior inspired load balancing (HBB-LB), which aims to achieve well balanced load across virtual machines for maximizing the throughput. The proposed algorithm also balances the priorities of tasks on the machines in such a way that the amount of waiting time of the tasks in the queue is minimal. We have compared the proposed algorithm with existing load balancing and scheduling algorithms. The experimental results show that the algorithm is effective when compared with existing algorithms. Our approach illustrates that there is a significant improvement in average execution time and reduction in waiting time of tasks on queue. "
}
@article{Posfai2013347,
title = "Interactions of mineral dust with pollution and clouds: An individual-particle \{TEM\} study of atmospheric aerosol from Saudi Arabia ",
journal = "Atmospheric Research ",
volume = "122",
number = "",
pages = "347 - 361",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512004310",
author = "Mihaly Posfai and Duncan Axisa and eva Tompa and Evelyn Freney and Roelof Bruintjes and Peter R. Buseck",
keywords = "Individual aerosol particles",
keywords = "Desert dust",
keywords = "Smectite",
keywords = "Cloud microphysics ",
abstract = "Abstract Aerosol particles from desert dust interact with clouds and influence climate on regional and global scales. The Riyadh (Saudi Arabia) aerosol campaign was initiated to study the effects of dust particles on cloud droplet nucleation and cloud properties. Here we report the results of individual-particle studies of samples that were collected from an aircraft in April 2007. We used analytical transmission electron microscopy, including energy-dispersive X-ray spectrometry, electron diffraction, and imaging techniques for the morphological, chemical, and structural characterization of the particles. Dust storms and regional background conditions were encountered during four days of sampling. Under dusty conditions, the coarse (supermicrometer) fraction resembles freshly crushed rock. The particles are almost exclusively mineral dust grains and include common rock-forming minerals, among which clay minerals, particularly smectites, are most abundant. Unaltered calcite grains also occur, indicating no significant atmospheric processing. The particles have no visible coatings but some contain traces of sulfur. The fine (submicrometer) fraction is dominated by particles of anthropogenic origin, primarily ammonium sulfate (with variable organic coating and some with soot inclusions) and combustion-derived particles (mostly soot). In addition, submicrometer, iron-bearing clay particles also occur, many of which are internally mixed with ammonium sulfate, soot, or both. We studied the relationships between the properties of the aerosol and the droplet microphysics of cumulus clouds that formed above the aerosol layer. Under dusty conditions, when a large concentration of coarse-fraction mineral particles was in the aerosol, cloud drop concentrations were lower and droplet diameters larger than under regional background conditions, when the aerosol was dominated by submicrometer sulfate particles. "
}
@article{Dermaku201364,
title = "Reducing of the latency between the client and server using Heuristic Partitioning Approaches on Cloud Computing Architecture ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "8",
pages = "64 - 68",
year = "2013",
note = "15th \{IFAC\} Workshop on International Stability, Technology, and Culture ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130606-3-XK-4037.00034",
url = "http://www.sciencedirect.com/science/article/pii/S147466701634215X",
author = "A. Dermaku and N. Demaku and Xh. Bajrami",
keywords = "Cloud",
keywords = "Computing",
keywords = "Middleware",
keywords = "Client-Server",
keywords = "Hypergraph",
keywords = "Partitioning ",
abstract = "Abstract Cloud computing has become a significant trend in recent years and is a widely speeding among industry that are ready for noticeable deployments in coming years. Because cloud computing addresses a key difficulties surrounding large scale data processing, and because there are many difficulties that current technology is facing with there is a need to find ways improving the services to the client by introducing new techniques for upgrading the service. One of the ways is to improve the latency between the two points of communications (nodes). In this paper we proposed a new model that minimizes the time needed to transfer data from the cloud using heuristic algorithms (approaches). These approaches find the optimal path between different servers or routers, where servers presents nodes on the communications graph. The client-server architecture model presented in this paper will help users to access the cloud and to retrieve the data and application faster by funding the optimal route "
}
@incollection{Partridge2017,
title = "Artificial Intelligence☆ ",
editor = "",
booktitle = "Reference Module in Neuroscience and Biobehavioral Psychology ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2017",
pages = " - ",
isbn = "978-0-12-809324-5",
doi = "https://doi.org/10.1016/B978-0-12-809324-5.02995-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128093245029953",
author = "D. Partridge",
keywords = "AI",
keywords = "Cognitive science",
keywords = "Computational theory of mind",
keywords = "Emergent mind theory",
keywords = "Machine learning",
keywords = "Machine translation",
keywords = "Neural computing",
keywords = "Robotics",
keywords = "Superintelligence",
keywords = "Turing test ",
abstract = "Abstract A broad survey of the full scope of activities aimed at developing computer systems that exhibit various aspects of intelligence—language understanding, vision, learning and robotics. The survey is developed from a basis of programming philosophy, either procedural or declarative (such as logic programming), and deductive versus inductive. This latter class of implementation is explained in terms of neural computing. The survey concludes with philosophical speculation—emergent mind theory versus computational theory of mind, the Turing Test and the notions of superintelligence. "
}
@article{Salfer2017,
title = "Finances and returns for robotic dairies ",
journal = "Journal of Dairy Science ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0022-0302",
doi = "https://doi.org/10.3168/jds.2016-11976",
url = "http://www.sciencedirect.com/science/article/pii/S0022030217301297",
author = "J.A. Salfer and K. Minegishi and W. Lazarus and E. Berning and M.I. Endres",
keywords = "automatic milking system",
keywords = "economic analysis",
keywords = "net annual impact",
keywords = "economic simulation ",
abstract = "\{ABSTRACT\} Automatic milking systems (AMS) became commercially available in the early 1990s. These systems provide flexibility and improve the lifestyle of farmers installing them. Because of the larger capital cost per kilogram of milk produced, observational studies in Europe and simulation studies have shown \{AMS\} to be less profitable than milking parlor systems, although previous findings are somewhat mixed. Improved performance of newer generations of AMS, better facility design to accommodate cow behavior, and better management of these facilities have the potential to make \{AMS\} more profitable. Wage rates are also increasing and sourcing high-quality milking labor is challenging. We developed partial budget simulations to model profitability of \{AMS\} compared with parlor systems for 120-, 240-, and 1,500-cow farms. Both the 120-cow and 240-cow \{AMS\} were more profitable than the parlor systems. However, the 1,500-cow parlor system was more profitable than the AMS. Breakeven labor analysis of the 1,500-cow system showed that at a wage inflation rate of 1% and a 0.91 kg/d lower milk production with the \{AMS\} system, the breakeven labor rate was $27.02/h. If the farm is able to achieve similar milk production between the 2 systems and wage inflation averages 3% over the 30-yr time horizon, the breakeven wage rate drops to $17.11/h. The major management factors that influenced the net annual impact were changes in milking labor cost and milk production. Another significant factor affecting net annual impact was the economic life of the AMS. An economic life of 13 yr or longer was required for an \{AMS\} to have a consistently positive net annual impact (depending on milk production per cow and labor cost). For every 227-kg increase in daily milk production per AMS, net annual income increased approximately $4,100. Cost-effective ways to optimize milk per \{AMS\} are to minimize attaching and milking times and to optimize milking settings. "
}
@article{Holtewert2013527,
title = "Virtual Fort Knox Federative, Secure and Cloud-based Platform for Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "527 - 532",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.027",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002965",
author = "Philipp Holtewert and Rolf Wutzke and Joachim Seidelmann and Thomas Bauernhansl",
keywords = "Smart Factory",
keywords = "Cloud",
keywords = "Ubiquitous computing",
keywords = "production system",
keywords = "information management ",
abstract = "Abstract In future the engineer and \{IT\} world will grow together. Networking and linking of information from the physical production and the digital world enable an optimization in manufacturing. Within the research project Virtual Fort Knox at the Fraunhofer \{IPA\} in Germany, a federative, secure and cloud-based platform for distributed service-oriented applications in plant operation is developed. The challenge is to establish a platform for the manufacturing to improve data processing and intelligent, cooperative networking. Data and information have to be saved, read and used on a flexible, simple and scalable way. This paper presents our research work in developing the platform by the description of the transformation process to the networked factory. The main aspects are consistent, integrated security across all components, community cloud for IT-decentralization respectively data, cooperation and competence distribution. "
}
@article{Riggs2013521,
title = "Disassembly Liaison Graphs Inspired by Word Clouds ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "521 - 526",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.026",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002953",
author = "Robert J. Riggs and S. Jack Hu",
keywords = "Disassembly",
keywords = "liaison graphs",
keywords = "word clouds ",
abstract = "Abstract Liaison or connection graphs depict physical mates between components in a graphical representation but do not incorporate any precedence relations or order of assembly or disassembly of components. For the context of disassembly, we developed a method to graphically show not only the physical mates between components but also the disassembly precedence relations amongst all the components. The transformation of a liaison graph into a weighted liaison graph (WLG) is inspired by the generation of word clouds from the visual design domain where component nodes are weighted and colored to depict disassembly precedence relations. A \{WLG\} allows users to quickly comprehend the order of disassembly and component embeddedness. "
}
@article{Chromy2013268,
title = "Creating Three-Dimensional Computer Models Using Robotic Manipulator and Laser Scanners ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "28",
pages = "268 - 273",
year = "2013",
note = "12th \{IFAC\} Conference on Programmable Devices and Embedded Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130925-3-CZ-3023.00037",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015373365",
author = "Adam Chromy and Petra Kocmanova and Luděk Žalud",
keywords = "Robotic manipulators",
keywords = "laser scanners",
keywords = "3D models",
keywords = "Epson \{C3\} robotic manipulator ",
abstract = "Abstract This paper presents scanning system providing three-dimensional models. Use of laser scanner mounted on robotic manipulator provides very flexible device capable of building models of both tiny detailed structures and large object. It could be used in many various applications, especially in health care, where it brings lot of advantages comparing to present scanning systems. Mechanical constitution, interfacing approaches and operating principles of this device are described. "
}
@article{Yu2012125,
title = "An integrated analysis of aerosol above clouds from A-Train multi-sensor measurements ",
journal = "Remote Sensing of Environment ",
volume = "121",
number = "",
pages = "125 - 131",
year = "2012",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2012.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S0034425712000454",
author = "Hongbin Yu and Yan Zhang and Mian Chin and Zhaoyan Liu and Ali Omar and Lorraine A. Remer and Yuekui Yang and Tianle Yuan and Jianglong Zhang",
keywords = "Aerosols",
keywords = "Clouds ",
abstract = "Quantifying above-cloud aerosol can help improve the assessment of aerosol intercontinental transport and climate impacts. In this study we conduct an integrated analysis of aerosols above clouds by using multi-sensor A-Train measurements, including above-cloud aerosol optical depth at 532 nm (AOD532) from \{CALIPSO\} lidar, the \{UV\} aerosol index (AI) from OMI, and cloud fraction and cloud optical depth (COD) from MODIS. The analysis of Saharan dust outflow and Southwest African smoke outflow regions shows that the above-cloud \{AOD\} correlates positively with \{AI\} in an approximately linear manner, and that the AOD532/AI ratio decreases with increasing COD. The dependence of AOD532/AI ratio on \{COD\} doesn't depend on aerosol type when potential biases in the \{CALIOP\} \{AOD\} measurements are empirically accounted for. Our results may suggest the potential of combining \{OMI\} \{AI\} and \{MODIS\} cloud measurements to empirically derive above-cloud \{AOD\} with a spatial coverage much more extensive than \{CALIPSO\} measurements, which needs to be further explored in the future. "
}
@article{Mayachita2013380,
title = "Implementation of Entertaining Robot on \{ROS\} Framework ",
journal = "Procedia Technology ",
volume = "11",
number = "",
pages = "380 - 387",
year = "2013",
note = "4th International Conference on Electrical Engineering and Informatics, \{ICEEI\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.12.206",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313003605",
author = "Inneke Mayachita and Rizka Widyarini and Hadi Rasyid Sono and Adrianto Ravi Ibrahim and Widyawardana Adiprawita",
keywords = "ROS",
keywords = "cloud robotics",
keywords = "interactive",
keywords = "PeopleBot ",
abstract = "Abstract As technologies are continually growing, there should be an option to implement technologies such as robots as entertainer at the tourism places, replacing the old-fashioned clowns and mascots. However, robots with a lot of features need relatively complex data processing. By implementing cloud robotics, all process and data calculation will be done by computers which are separated from the body of the robot. To implement this new robotics system, we use PeopleBot as the main physical platform, three computers, and a tablet. Communication between devices occurs via network and be facilitated by Robot Operating System (ROS) framework. Robot has some features such as Layout, image capture and storage in cloud, navigation, crowd detection, and speech recognition "
}
@article{Valilai2013110,
title = "A collaborative and integrated platform to support distributed manufacturing system using a service-oriented approach based on cloud computing paradigm ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "110 - 127",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000932",
author = "Omid Fatahi Valilai and Mahmoud Houshmand",
keywords = "\{STEP\} standard",
keywords = "Modularity",
keywords = "XML",
keywords = "Distributed product development",
keywords = "Cloud computing",
keywords = "Service-oriented manufacturing",
keywords = "Collaborative product development ",
abstract = "Today's manufacturing enterprises struggle to adopt cost-effective manufacturing systems. Overview of the recent manufacturing enterprises shows that successful global manufacturing enterprises have distributed their manufacturing capabilities over the globe. The successes of global manufacturing enterprises depend upon the entire worldwide integration of their product development processes and manufacturing operations that are distributed over the globe. Distributed manufacturing agents' collaboration and manufacturing data integrity play a major role in global manufacturing enterprises' success. There are number of works, conducted to enable the distributed manufacturing agents to collaborate with each other. To achieve the manufacturing data integrity through manufacturing processes, numbers of solutions have been proposed which one of the successful solutions is to use \{ISO\} 10303 (STEP) standard. However, adopting this standard one can recognize antonym effects of integration and collaboration approaches that weaken both integration and collaboration capabilities of manufacturing agents. In our latest work, we had developed an integrated and collaborative manufacturing platform named LAYMOD. Albeit the platform in question was through enough to be applied in various collaborative and integrated \{CAx\} systems, its embedded structure hampers its application for collaboration in distributed manufacturing systems. To achieve an integrated and collaborative platform for distributed manufacturing agents, this paper proposes a service-oriented approach. This approach is originated from cloud computing paradigm known as one of the technologies which enables a major transformation in manufacturing industry. Also, to maintain the product data integration based on the \{STEP\} standard, a new service-oriented approach is proposed. This approach is in parallel to the new capability of the \{STEP\} standard for supporting \{XML\} data structures. The result is a new platform named XMLAYMOD. \{XMLAYMOD\} is able to support distributed manufacturing collaboration and data integration based on the \{STEP\} standard. The different aspects of this platform to fulfill the requirements of distributed collaboration and also to overcome the lacks of the \{STEP\} standard are discussed through a brief case study. "
}
@article{Wang20124034,
title = "Multidimensional particle swarm optimization-based unsupervised planar segmentation algorithm of unorganized point clouds ",
journal = "Pattern Recognition ",
volume = "45",
number = "11",
pages = "4034 - 4043",
year = "2012",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2012.04.023",
url = "http://www.sciencedirect.com/science/article/pii/S0031320312002038",
author = "Lin Wang and Jianfu Cao and Chongzhao Han",
keywords = "Unorganized point clouds",
keywords = "Unsupervised planar segmentation",
keywords = "Multidimensional particle swarm optimization",
keywords = "Objective function ",
abstract = "This paper presents an unsupervised planar segmentation algorithm of unorganized point clouds based on multidimensional (MD) particle swarm optimization (PSO). A robust objective function of the unsupervised planar segmentation is established according to clustering distances of \{PSO\} clustering algorithm and inliers of random sample consensus (RANSAC) method. After that, \{MD\} \{PSO\} algorithm is adopted to optimize the objective function, where the optimal number and positions of the segmented planar patches are sought simultaneously. In order not to get trapped in local optima, a modification strategy of the global best (GB) position of swarm in each dimension is added to the \{MD\} \{PSO\} algorithm. Thus the unsupervised planar segmentation of point clouds is realized. Experimental results demonstrate the high planar segmentation accuracy of the proposed algorithm. "
}
@article{Kaipa201617,
title = "Addressing perception uncertainty induced failure modes in robotic bin-picking ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "42",
number = "",
pages = "17 - 38",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515300971",
author = "Krishnanand N. Kaipa and Akshaya S. Kankanhalli-Nagendra and Nithyananda B. Kumbla and Shaurya Shriyam and Srudeep Somnaath Thevendria-Karthic and Jeremy A. Marvel and Satyandra K. Gupta",
abstract = "Abstract We present a comprehensive approach to handle perception uncertainty to reduce failure rates in robotic bin-picking. Our focus is on mixed-bins. We identify the main failure modes at various stages of the bin-picking task and present methods to recover from them. If uncertainty in part detection leads to perception failure, then human intervention is invoked. Our approach estimates the confidence in the part match provided by an automated perception system, which is used to detect perception failures. Human intervention is also invoked if uncertainty in estimated part location and orientation leads to a singulation planning failure. We have developed a user interface that enables remote human interventions when necessary. Finally, if uncertainty in part posture in the gripper leads to failure in placing the part with the desired accuracy, sensor-less fine-positioning moves are used to correct the final placement errors. We have developed a fine-positioning planner with a suite of fine-motion strategies that offer different tradeoffs between completion time and postural accuracy at the destination. We report our observations from system characterization experiments with a dual-armed Baxter robot, equipped with a Ensenso three-dimensional camera, to perform bin-picking on mixed-bins. "
}
@article{Prabhu201741,
title = "The dawn of unmanned analytical laboratories ",
journal = "TrAC Trends in Analytical Chemistry ",
volume = "88",
number = "",
pages = "41 - 52",
year = "2017",
note = "",
issn = "0165-9936",
doi = "https://doi.org/10.1016/j.trac.2016.12.011",
url = "http://www.sciencedirect.com/science/article/pii/S0165993616302916",
author = "Gurpur Rakesh D. Prabhu and Pawel L. Urban",
keywords = "Automated assay",
keywords = "Flow techniques",
keywords = "High throughput",
keywords = "Microfluidics",
keywords = "Robotics ",
abstract = "Abstract The twentieth century has brought enormous developments in instrumentation for chemical analysis. However, most of the state-of-the-art analytical instruments still require a substantial investment of human labor. In the twenty first century, some laboratories need to analyze thousands of samples every day, at the same time maintaining high repeatability. To cope with the growing requirements of modern science and industry, it is necessary to automate most or the entire sample handling steps. Thus, a number of automated analytical approaches have been developed, including: continuous flow analysis, flow injection analysis, microfluidic systems, micro total analysis systems, microtiter plate-compatible systems, centrifugal analyzers, cartridge analyzers, autosamplers, multi-axis robots, and total laboratory automation facilities. Automation of chemical analyses speeds up tedious operations related to the handling of samples and reagents, thus creating new possibilities for science and industry. However, when automating analytical laboratories, socioeconomic and safety aspects need to be taken into account. "
}
@article{Thuot201386,
title = "Remote robotic underwater grinding system and modeling for rectification of hydroelectric structures ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "86 - 95",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000889",
author = "Dominique Thuot and Zhaoheng Liu and Henri Champliaud and Julien Beaudry and Pierre-Luc Richard and Michel Blain",
keywords = "Underwater grinding process",
keywords = "Grinding modeling",
keywords = "Material removal rate (MRR)",
keywords = "Water drag effect",
keywords = "Air injector",
keywords = "Robotic grinding ",
abstract = "A submersible grinding robot has been designed to automate the dam gate metallic structure repair process. In order to measure and control the amount of material removed during the process, an empirical approach for modeling the material removal rate (MRR) of the underwater grinding application is proposed and presented in this paper. The objective is to determine the \{MRR\} in terms of the process parameters such as cutting speed and grinding power over a range of variable wheel diameters. Experiments show that water causes drag and a significant loss of power occurs during grinding. An air injector encasing the grinding wheel has been prototyped, and it is shown that power loss can be reduced by up to 80%. A model, based on motor characterization and empirical relations among system and process parameters, is developed for predicting \{MRR\} which will be used for the robotic grinding control system. A validation is carried out through experiments, and confirms the good accuracy of the model for predicting the depth of cut for underwater grinding. A comparative study for dry and underwater grinding is also conducted through experiments and shows that the \{MRR\} is higher for underwater grinding than in dry conditions at low cutting speeds. "
}
@article{Xu201275,
title = "From cloud computing to cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "28",
number = "1",
pages = "75 - 86",
year = "2012",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2011.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584511000949",
author = "Xun Xu",
keywords = "Cloud computing",
keywords = "Cloud manufacturing",
keywords = "Service-oriented business model ",
abstract = "Cloud computing is changing the way industries and enterprises do their businesses in that dynamically scalable and virtualized resources are provided as a service over the Internet. This model creates a brand new opportunity for enterprises. In this paper, some of the essential features of cloud computing are briefly discussed with regard to the end-users, enterprises that use the cloud as a platform, and cloud providers themselves. Cloud computing is emerging as one of the major enablers for the manufacturing industry; it can transform the traditional manufacturing business model, help it to align product innovation with business strategy, and create intelligent factory networks that encourage effective collaboration. Two types of cloud computing adoptions in the manufacturing sector have been suggested, manufacturing with direct adoption of cloud computing technologies and cloud manufacturing—the manufacturing version of cloud computing. Cloud computing has been in some of key areas of manufacturing such as IT, pay-as-you-go business models, production scaling up and down per demand, and flexibility in deploying and customizing solutions. In cloud manufacturing, distributed resources are encapsulated into cloud services and managed in a centralized way. Clients can use cloud services according to their requirements. Cloud users can request services ranging from product design, manufacturing, testing, management, and all other stages of a product life cycle. "
}
@article{Chew20116724,
title = "Tropical cirrus cloud contamination in sun photometer data ",
journal = "Atmospheric Environment ",
volume = "45",
number = "37",
pages = "6724 - 6731",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011008375",
author = "Boon Ning Chew and James R. Campbell and Jeffrey S. Reid and David M. Giles and Ellsworth J. Welton and Santo V. Salinas and Soo Chin Liew",
keywords = "AERONET",
keywords = "Aerosol particles",
keywords = "Cirrus clouds",
keywords = "Lidar",
keywords = "MPLNET",
keywords = "Southeast Asia",
keywords = "Sun photometer ",
abstract = "Cirrus clouds are endemic to Southeast Asia and are a source of potential bias in regional passive aerosol remote sensing datasets. Here, performance of the cloud-screening algorithm for the ground-based Aerosol Robotic Network (AERONET) sun photometer data is evaluated for cirrus cloud contamination at Singapore (1.30° N, 103.77° E). Using twelve months of concurrent \{AERONET\} Level 1.5 and 2.0 cloud-screened aerosol optical depth (AOD) data, and collocated Level 1.0 Micro-Pulse Lidar Network (MPLNET) measurements, we investigate the baseline \{AOD\} bias due to cirrus cloud presence. Observations are considered for a primary sample of all data and a secondary sample where \{AERONET\} data are restricted to a zenith viewing angle ≤ 45°. Cirrus clouds are present in zenith-viewing \{MPL\} profiles for 34% and 23% of these samples respectively. Based on approximations of cirrus cloud optical properties necessary to estimate cloud optical depth from the single-channel lidar signal, and assuming partial forward scattering of diffuse light by cirrus clouds into the sun photometer’s field of view, we estimate a range in \{AOD\} bias due to unscreened cloud presence of 0.034 to 0.060 and 0.031 to 0.055 ± 0.01 for the primary and secondary sample respectively. From the analysis of \{AERONET\} \{AOD\} for the angle-limited subset alone, we also derive a positive \{AOD\} bias of 0.034, which is comparable to the lower bounds for the estimated cloud bias reported for our datasets. These findings, which we attribute to the prevalence of cirrus clouds present from regional convection, are higher than previous reports of global \{AOD\} bias in the Moderate Resolution Infrared Spectroradiometer (MODIS) satellite-borne measurements due to residual cirrus cloud presence. "
}
@article{Gilbert201675,
title = "Evaluation of Absorbable Hemostatic Powder for Prevention of Lymphoceles Following Robotic Prostatectomy With Lymphadenectomy ",
journal = "Urology ",
volume = "98",
number = "",
pages = "75 - 80",
year = "2016",
note = "",
issn = "0090-4295",
doi = "https://doi.org/10.1016/j.urology.2016.06.071",
url = "http://www.sciencedirect.com/science/article/pii/S0090429516305520",
author = "Daniel R. Gilbert and Jordan Angell and Ronney Abaza",
abstract = "Objective To determine whether lymphoceles can be prevented after robotic prostatectomy with pelvic lymph node dissection (PLND), we performed a prospective randomized study using an absorbable hemostatic agent (Arista AH). The most common complications of \{PLND\} for prostate cancer are related to lymphocele formation, which occur in 30%-50% of patients according to studies that performed screening imaging. Although most are asymptomatic, when intervention is required the cost and morbidity are high. Materials and Methods Of 100 patients enrolled, 88 completed the study. Each patient served as his or her own control, with Arista \{AH\} placed over the field of \{PLND\} on only one side in a randomized fashion as revealed only after bilateral \{PLND\} was completed. All patients underwent screening pelvic computed tomography scan 3 months later, with radiologists blinded to the Arista \{AH\} treated side. A significant lymphocele was defined as a fluid collection 3 cm or greater in any plane. Results The mean lymph node yield was 8.1 nodes. Fourteen lymphoceles were identified. Five occurred on the side where Arista \{AH\} was used vs 9 on untreated sides (5.7% vs 10.2%, P = .248). When they occurred, there was no statistically significant difference in lymphocele size between treated and untreated sides (P = .441). No lymphoceles were symptomatic. Conclusion Although the lymphocele rate with Arista \{AH\} was 5.7% compared with 10.2% without it, this was not a statistically significant difference potentially because the study was underpowered due to an unusually low baseline rate of lymphoceles. A larger study is warranted to determine whether using a hemostatic agent like Arista \{AH\} can prevent lymphoceles. "
}
@article{Morariu20121862,
title = "Resource Monitoring in Cloud Platforms with Tivoli Service Automation Management ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "6",
pages = "1862 - 1868",
year = "2012",
note = "14th \{IFAC\} Symposium on Information Control Problems in Manufacturing ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-RO-2023.00439",
url = "http://www.sciencedirect.com/science/article/pii/S147466701633422X",
author = "Octavian Morariu and Theodor Borangiu",
keywords = "Cloud Computing",
keywords = "Metering",
keywords = "Monitoring",
keywords = "IBM CloudBurst",
keywords = "JADE ",
abstract = "Abstract Cloud computing promises a radical new way in design of the \{IT\} systems. Due to advances in virtualization technology in the last decade this paradigm has gained a lot of traction among the \{IT\} managers, offering a new perspective in design and development of the next generation software and hardware applications. One of the most appealing characteristics of cloud computing is the pay-as-you-go model which allows customers to start with a small \{IT\} investment and grow as required, minimizing risks. For cloud providers, in order to be able to sustain this business model it is important to be able to gather and process usage metrics of the resources provided in order to generate accurate invoices for customers. This paper presents the metrics collections used with each cloud offering (IaaS, PaaS and SaaS) and proposes a novel architecture for collecting these metrics using a Multi Agent System platform, together with a Web \{J2EE\} application for real time data visualization and reporting. The solution is built and presented in the context of \{IBM\} CloudBurst 2.1, managed by \{IBM\} Tivoli Service Automation Manager (TSAM) software stack, while virtualization is provided by \{VMware\} \{ESX\} 4.0 hypervisor with \{VMware\} vCenter solution. "
}
@article{Dragoicea20121702,
title = "A Service Science Knowledge Environment in the Cloud ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "6",
pages = "1702 - 1707",
year = "2012",
note = "14th \{IFAC\} Symposium on Information Control Problems in Manufacturing ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-RO-2023.00438",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016333961",
author = "Monica Dragoicea and Theodor Borangiu",
keywords = "Service Science",
keywords = "service system",
keywords = "value co-creation",
keywords = "ontology",
keywords = "cloud computing ",
abstract = "Abstract This paper emphasize the way in which the co-creation of value can profit from semantic-driven social software, taking into consideration the case of educational services delivered in the cloud. The solution is delivered in the context of the POS-DRU Project no. 57748 “INSEED - Strategic Program Fostering Service Innovation Through Open, Continuous education” and it approaches conception and development of an open, collaborative, interactive environment to gather around universities, industry, governmental agencies and European institutions in order to foster service innovation by means of information / proves / technological transfer of the research results aiming to develop sustainable service systems solutions. In this respect, a specification proposal for a collaborative service process based on co-creation of value between educational service providers and consumers is presented. As a case study, a deployment proposal in the \{IBM\} Cloud environment for the \{INSEED\} project is depicted. "
}
@article{Giokas201233,
title = "Cloud point–dispersive μ-solid phase extraction of hydrophobic organic compounds onto highly hydrophobic core–shell Fe2O3@C magnetic nanoparticles ",
journal = "Journal of Chromatography A ",
volume = "1251",
number = "",
pages = "33 - 39",
year = "2012",
note = "",
issn = "0021-9673",
doi = "https://doi.org/10.1016/j.chroma.2012.06.054",
url = "http://www.sciencedirect.com/science/article/pii/S002196731200948X",
author = "Dimosthenis L. Giokas and Qing Zhu and Qinmin Pan and Alberto Chisvert",
keywords = "Cloud point extraction",
keywords = "Dispersive micro-solid phase extraction",
keywords = "Highly hydrophobic magnetic nanoparticles",
keywords = "Ultrasound-assisted back-extraction",
keywords = "UV filters ",
abstract = "A novel two-step extraction technique combining cloud point extraction (CPE) with dispersive micro-solid phase extraction (D-μ-SPE) is presented in this work for the first time. The method involves initial extraction of the target analytes by \{CPE\} in the micelles of a non-ionic surfactant medium; then highly hydrophobic polysiloxane-coated core–shell Fe2O3@C magnetic nanoparticles (MNPs) are used to retrieve the micellar phase. In that manner, the micellar phase containing the analytes is the target of the D-μ-SPE step rather than the analytes directly. \{MNPs\} are then collected by the application of an adscititious magnetic field overcoming the need for specific steps associated with \{CPE\} such as centrifugation to separate the surfactant-rich phase, refrigeration of the condensed micellar phase to reduce its viscosity or appropriate apparatus that enable direct sampling of the surfactant-rich phase. A noteworthy feature of the method is the introduction of highly oleophilic MNPs, which afford rapid and quantitative mass transfer of the surfactant phase, as opposed to other more conventional hydrophobic nanoparticles. In that manner, fast and reproducible extraction is accomplished, lending improved analytical features compared to conventional CPE, such as reduced analysis time and relative inertness to surfactant concentration and equilibration temperature. The analytes were recovered from the surface of \{MNPs\} by ultrasound-assisted back-extraction in a water-immiscible organic solvent where analytes are readily partitioned but the surfactant has limited solubility, thus minimizing its interference during chromatographic detection. As an analytical demonstration, different \{UV\} absorbing chemicals with various physico-chemical properties were used as model organic compounds for optimizing the parameters associated with this novel two-step extraction approach. The proposed method, combining two different and efficient techniques, offers satisfactory analytical features in terms of repeatability (4.5–7.5%), reproducibility (7.0–14.9%) and accuracy (88.5–97.2%). Most importantly it poses as an alternative and fast method for sample pretreatment opening new insights in surfactant-mediated extractions. "
}
@article{Ipina2012966,
title = "Satellite and ground detection of very dense smoke clouds produced on the islands of the Parana river delta that affected a large region in Central Argentina ",
journal = "Advances in Space Research ",
volume = "49",
number = "5",
pages = "966 - 977",
year = "2012",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2011.12.009",
url = "http://www.sciencedirect.com/science/article/pii/S0273117711008313",
author = "A. Ipina and G.M. Salum and E. Crino and R.D. Piacentini",
keywords = "Smoke cloud",
keywords = "Burned Biomass Debris",
keywords = "Satellite data",
keywords = "Ground data",
keywords = "Parana river",
keywords = "Delta island ",
abstract = "Intense fires were produced on the Parana river delta islands, Argentina, during most part of 2008, by a combination of an exceptionally dry period and the farmers’ use of a fire land-cleaning technique. In April 2008, those fires significantly affected the nearby regions and their inhabitants, from Rosario city to Buenos Aires mega-city. In this work we present satellite as well as ground Aerosol Optical Depth (AOD) at 550 nm data obtained during the propagation of pollution clouds to the central zone of Argentina. The highest value (1.18) was registered at Buenos Aires by atmospheric remote sensing, using the satellite instrument MODIS/Terra on April 18th 2008 at 10:35 local time (= \{UT\} − 3 h). On the same day, ground air quality detectors also measured in this city the highest Total Suspended Particle (TSP) value of the month, 2.02 mg/m3. The AOD(550) daily variation at Rosario Astronomical Observatory, which is located near the Parana riverside, was derived by combining solar ultraviolet erythemal irradiance data (measured with a \{YES\} biometre) with model calculations. On April 25th 2008, from 12:00 to 15:30 local time, a rather high and constant AOD(550) value was registered, with a mean value of (0.90 ± 0.21). Cities located on the side of the Rosario–Buenos Aires highway (San Nicolas, Baradero and San Pedro) were also affected, showing a mean AOD(550) between the Rosario and Buenos Aires values. The particulate matter was collected with gridded samplers placed on the Parana river islands as well as at the Rosario Observatory. They were analysed with a Scanning Electron Microscope (SEM) and mainly showed a biological origin. Even if normally large particles travel small distances from the source, organic aerosol in the range of 40–100 μm and complex asymmetric structures were registered several kilometres away from the aerosol sources on the islands. Another event of intense \{UV\} index attenuation (98.6%) occurred on September 18th 2008, due to very dense smoke clouds that extended over the Rosario area for several hours. The clouds were driven away from the fires by East–northeast and East–southeast winds. The minimum value of this index measured around noon allows to derive a maximum AOD(550)max = (3.65 ± 0.90) at 12:45 local time. Soot clouds extended over the Parana river, transporting Burned Biomass Debris (BBD) that deposited on Rosario. In particular, burned leaves and small branches with dimensions of 1–20 cm were collected. The mean (BBD) particles deposited on the ground from 7:00 to 19:00 local time were (0.92 ± 0.20) BBD/(m2 h). The main purpose of the present work is to contribute to the understanding and quantification of the impact of very dense smoke clouds and \{BBD\} that directly and indirectly affected a densely populated area. All the events originated in a very particular and fragile region such as a river delta (with its specific native plants) were registered by using a multi-instrument approach (satellite as well as ground based devices). The analysis of these events, as detailed in this manuscript, was used as a scientific reference for the judicial claim made at the Supreme Court of Justice of Argentina by the National University of Rosario, against the authorities of the Entre Rios Province where the islands of the Parana river are placed, in order to take the necessary measures for the suspension of the biomass burning in these islands. "
}
@article{Natali2011151,
title = "Graph-based representations of point clouds ",
journal = "Graphical Models ",
volume = "73",
number = "5",
pages = "151 - 164",
year = "2011",
note = "",
issn = "1524-0703",
doi = "https://doi.org/10.1016/j.gmod.2011.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S1524070311000099",
author = "Mattia Natali and Silvia Biasotti and Giuseppe Patanè and Bianca Falcidieno",
keywords = "Graph-based representations",
keywords = "Point clouds",
keywords = "Shape abstraction",
keywords = "Shape comparison ",
abstract = "This paper introduces a skeletal representation, called Point Cloud Graph, that generalizes the definition of the Reeb graph to arbitrary point clouds sampled from m-dimensional manifolds embedded in the d-dimensional space. The proposed algorithm is easy to implement and the graph representation yields to an effective abstraction of the data. Finally, we present experimental results on point-sampled surfaces and volumetric data that show the robustness of the Point Cloud Graph to non-uniform point distributions and its usefulness for shape comparison. "
}
@article{Steenstra20161050,
title = "Analyses of robotic traverses and sample sites in the Schrodinger basin for the \{HERACLES\} human-assisted sample return mission concept ",
journal = "Advances in Space Research ",
volume = "58",
number = "6",
pages = "1050 - 1065",
year = "2016",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2016.05.041",
url = "http://www.sciencedirect.com/science/article/pii/S0273117716302630",
author = "Edgar S. Steenstra and Dayl J.P. Martin and Francesca E. McDonald and Sarinya Paisarnsombat and Christian Venturino and Sean O’Hara and Abigail Calzada-Diaz and Shelby Bottoms and Mark K. Leader and Kurt K. Klaus and Wim van Westrenen and Debra H. Needham and David A. Kring",
keywords = "Schrodinger",
keywords = "Moon",
keywords = "Exploration",
keywords = "Lunar",
keywords = "Sample return mission ",
abstract = "Abstract The International Space Exploration Coordination Group (ISECG) developed an integrated Global Exploration Roadmap (GER) that outlines plans for human-assisted sample return from the lunar surface in ∼2024 and for human presence on the lunar surface in ∼2028. Previous studies have identified the Schrodinger basin, situated on the far side of the Moon, as a prime target for lunar science and exploration where a significant number of the scientific concepts reviewed by the National Research Council (NRC, 2007) can be addressed. In this study, two robotic mission traverses within the Schrodinger basin are proposed based on a 3 year mission plan in support of the \{HERACLES\} human-assisted sample return mission concept. A comprehensive set of modern remote sensing data (LROC imagery, \{LOLA\} topography, \{M3\} and Clementine spectral data) has been integrated to provide high-resolution coverage of the traverses and to facilitate identification of specific sample localities. We also present a preliminary Concept of Operations (ConOps) study based on a set of notional rover capabilities and instrumental payload. An extended robotic mission to the Schrodinger basin will allow for significant sample return opportunities from multiple distinct geologic terrains and will address multiple high-priority \{NRC\} (2007) scientific objectives. Both traverses will offer the first opportunity to (i) sample pyroclastic material from the lunar farside, (ii) sample Schrodinger impact melt and test the lunar cataclysm hypothesis, (iii) sample deep crustal lithologies in an uplifted peak ring and test the lunar magma ocean hypothesis and (iv) explore the top of an impact melt sheet, enhancing our ability to interpret Apollo samples. The shorter traverse will provide the first opportunity to sample farside mare deposits, whereas the longer traverse has significant potential to collect \{SPA\} impact melt, which can be used to constrain the basin-forming epoch. These robotic missions will revalidate existing lunar surface capabilities and pioneer new ones and, thus, provide important precursor results for subsequent human missions to the lunar surface. "
}
@article{Iqbal2011871,
title = "Adaptive resource provisioning for read intensive multi-tier applications in the cloud ",
journal = "Future Generation Computer Systems ",
volume = "27",
number = "6",
pages = "871 - 879",
year = "2011",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2010.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X10002098",
author = "Waheed Iqbal and Matthew N. Dailey and David Carrera and Paul Janecek",
keywords = "Cloud computing",
keywords = "Adaptive resource management",
keywords = "Quality of service",
keywords = "Multi-tier applications",
keywords = "Service-Level Agreement",
keywords = "Scalability ",
abstract = "A Service-Level Agreement (SLA) provides surety for specific quality attributes to the consumers of services. However, current \{SLAs\} offered by cloud infrastructure providers do not address response time, which, from the user’s point of view, is the most important quality attribute for Web applications. Satisfying a maximum average response time guarantee for Web applications is difficult for two main reasons: first, traffic patterns are highly dynamic and difficult to predict accurately; second, the complex nature of multi-tier Web applications increases the difficulty of identifying bottlenecks and resolving them automatically. This paper proposes a methodology and presents a working prototype system for automatic detection and resolution of bottlenecks in a multi-tier Web application hosted on a cloud in order to satisfy specific maximum response time requirements. It also proposes a method for identifying and retracting over-provisioned resources in multi-tier cloud-hosted Web applications. We demonstrate the feasibility of the approach in an experimental evaluation with a testbed EUCALYPTUS-based cloud and a synthetic workload. Automatic bottleneck detection and resolution under dynamic resource management has the potential to enable cloud infrastructure providers to provide \{SLAs\} for Web applications that guarantee specific response time requirements while minimizing resource utilization. "
}
@article{Santos2017116,
title = "Spatio-temporal exploration strategies for long-term autonomy of mobile robots ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "116 - 126",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.016",
url = "http://www.sciencedirect.com/science/article/pii/S092188901630690X",
author = "Joao Machado Santos and Tomas Krajnik and Tom Duckett",
keywords = "Mobile robotics",
keywords = "Spatio-temporal exploration",
keywords = "Long-term autonomy ",
abstract = "Abstract We present a study of spatio-temporal environment representations and exploration strategies for long-term deployment of mobile robots in real-world, dynamic environments. We propose a new concept for life-long mobile robot spatio-temporal exploration that aims at building, updating and maintaining the environment model during the long-term deployment. The addition of the temporal dimension to the explored space makes the exploration task a never-ending data-gathering process, which we address by application of information-theoretic exploration techniques to world representations that model the uncertainty of environment states as probabilistic functions of time. We evaluate the performance of different exploration strategies and temporal models on real-world data gathered over the course of several months. The combination of dynamic environment representations with information-gain exploration principles allows to create and maintain up-to-date models of continuously changing environments, enabling efficient and self-improving long-term operation of mobile robots. "
}
@article{Kerr2016165,
title = "Investigation of synthetic aperture methods in ultrasound surface imaging using elementary surface types ",
journal = "Ultrasonics ",
volume = "72",
number = "",
pages = "165 - 176",
year = "2016",
note = "",
issn = "0041-624X",
doi = "https://doi.org/10.1016/j.ultras.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0041624X16301408",
author = "W. Kerr and S.G. Pierce and P. Rowe",
keywords = "Ultrasound imaging",
keywords = "Total Focussing Method",
keywords = "Synthetic Aperture Focussing Method",
keywords = "Full Matrix Capture",
keywords = "Robotics ",
abstract = "Abstract Synthetic aperture imaging methods have been employed widely in recent research in non-destructive testing (NDT), but uptake has been more limited in medical ultrasound imaging. Typically offering superior focussing power over more traditional phased array methods, these techniques have been employed in \{NDT\} applications to locate and characterise small defects within large samples, but have rarely been used to image surfaces. A desire to ultimately employ ultrasonic surface imaging for bone surface geometry measurement prior to surgical intervention motivates this research, and results are presented for initial laboratory trials of a surface reconstruction technique based on global thresholding of ultrasonic 3D point cloud data. In this study, representative geometry artefacts were imaged in the laboratory using two synthetic aperture techniques; the Total Focusing Method (TFM) and the Synthetic Aperture Focusing Technique (SAFT) employing full and narrow synthetic apertures, respectively. Three high precision metallic samples of known geometries (cuboid, sphere and cylinder) which featured a range of elementary surface primitives were imaged using a 5 MHz, 128 element 1D phased array employing both \{SAFT\} and \{TFM\} approaches. The array was manipulated around the samples using a precision robotic positioning system, allowing for repeatable ultrasound derived 3D surface point clouds to be created. A global thresholding technique was then developed that allowed the extraction of the surface profiles, and these were compared with the known geometry samples to provide a quantitative measure of error of 3D surface reconstruction. The mean errors achieved with optimised \{SAFT\} imaging for the cuboidal, spherical and cylindrical samples were 1.3 mm, 2.9 mm and 2.0 mm respectively, while those for \{TFM\} imaging were 3.7 mm, 3.0 mm and 3.1 mm, respectively. These results were contrary to expectations given the higher information content associated with the \{TFM\} images. However, it was established that the reduced error associated with the \{SAFT\} technique was associated with significant reductions in side lobe levels of approximately 24 dB in comparison to \{TFM\} imaging, although this came at the expense of reduced resolution and coverage. "
}
@article{Chan2016257,
title = "Automatic Point Cloud Registration Using a Single Octagonal Lamp Pole ",
journal = "Photogrammetric Engineering & Remote Sensing ",
volume = "82",
number = "4",
pages = "257 - 269",
year = "2016",
note = "",
issn = "0099-1112",
doi = "https://doi.org/10.14358/PERS.82.4.257",
url = "http://www.sciencedirect.com/science/article/pii/S0099111216300817",
author = "Ting On Chan and Derek D. Lichti and David Belton and Hoang Long Nguyen",
abstract = "Abstract Registration is an essential procedure for merging point clouds defined in different coordinate systems associated to different scanner positions and orientations. It is usually the first step before the point clouds are further processed to provide spatial information of a scene to support engineering applications. In this paper, a new automatic registration method based on a novel geometric model of a polygonal object is presented. Since the cross section of the shaft of many lamp poles is octagonal, registration based on an octagonal pyramid model is proposed. The presented method only requires a single, common octagonal lamp pole observed in both point clouds, though actual overlap of the point clouds is not strictly required. It can be performed as long as the model parameters can be estimated by fitting the point observations to the model. Moreover, no user interaction is needed to derive approximate values, so the proposed registration can be completely automated. Three independent datasets captured by two scanners were used to verify the method. The registration accuracies in the horizontal and vertical directions were up to 11.7 mm and 4.4 mm at approximately 62 m and 17 m away from the scanner, respectively. With such high accuracies, the estimated registration parameters can serve as a set of initial parameters for fine registration using algorithm such as the iterative closest point (icp). "
}
@article{Tsai2011843,
title = "Machine vision based path planning for a robotic golf club head welding system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "27",
number = "4",
pages = "843 - 849",
year = "2011",
note = "Conference papers of Flexible Automation and Intelligent ManufacturingIntelligent manufacturing and services ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2011.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584511000196",
author = "Ming J. Tsai and Hong-Wen Lee and Nai-Jun Ann",
keywords = "Machine vision",
keywords = "Robotic welding system",
keywords = "Path planning ",
abstract = "A path planning method based on machine vision techniques is constructed for a golf-club head robotic welding system. This system uses 3D machine vision techniques to recognize the weldseam and generates a welding path for the robot. The location of the weldseam is discovered by applying a Sobel mask to the captured data. A Laplace mask is also useful to filter out the noise points due to the scatter light refraction of tack-welding spots. The weldseam is then replenished and smoothed out by a B-spline curve fitting. The task frame of the weldseam is computed by finding the tangent, normal, and bi-normal of the curve. The robotic welding path is obtained by further rotations and translation along the axes of the task frame according to the requirement of the welding attitude. The developed machine vision technique and the mathematic framework pertaining to the generation of a welding task frame can readily be used for various three-dimensional welding tasks. "
}
@article{Chikhaoui2016234,
title = "Kinematics and performance analysis of a novel concentric tube robotic structure with embedded soft micro-actuation ",
journal = "Mechanism and Machine Theory ",
volume = "104",
number = "",
pages = "234 - 254",
year = "2016",
note = "",
issn = "0094-114X",
doi = "https://doi.org/10.1016/j.mechmachtheory.2016.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094114X16301100",
author = "Mohamed Taha Chikhaoui and Kanty Rabenorosoa and Nicolas Andreff",
keywords = "Continuum robot",
keywords = "Kinematics",
keywords = "Holonomy",
keywords = "Redundancy",
keywords = "Soft micro-actuators",
keywords = "Intracorporeal microrobotics ",
abstract = "Abstract Continuum robots have shown astounding abilities to assist surgeons reaching confined spaces in the human body. Thus, accurate control of these manipulators, and particularly concentric tube robots, is required in order to achieve intracorporeal microrobotic interventions. We present hereby an improvement of this kinematic structure based on embedded soft micro-actuators. Two models for single and double direction curvature control are introduced. We demonstrate that kinematics are enhanced with respect to the standard approach in terms of holonomy, actuation redundancy and workspace covering. Further kinematic analysis enables the detection of singular configurations. The number of the end-effector pose occurrences that can be reached in a given volume (one cubic millimeter) are computed as well. Finally, the advantages of the novel structures are proven using performance indices. "
}
@article{HidalgoPena2013370,
title = "Web-based and Interactive Learning - Recognition Method for a Humanoid Robot ",
journal = "Procedia Technology ",
volume = "7",
number = "",
pages = "370 - 376",
year = "2013",
note = "3rd Iberoamerican Conference on Electronics Engineering and Computer Science, \{CIIECC\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.04.046",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313000479",
author = "Enrique Hidalgo-Pena and Luis F. Marin-Urias and Fernando Montes-Gonzalez and Antonio Marin-Hernandez and Homero Rios-Figueroa",
keywords = "One-class Classification",
keywords = "PCA",
keywords = "Object Recognition",
keywords = "Cloud Robotics",
keywords = "Service Robots ",
abstract = "In this paper an Object Learning and Recognition method for a Humanoid is presented. This method tries to take advantage of the Cloud Resources, since it is based on image web search in order to build training sets for learn about objects appearance. In case of unavailability of Internet access, the robot would ask human to show the object and take the images from its camera. This way, our method aims to be a flexible and natural Human-Robot Interaction framework and to give as much autonomy as possible to the robot. "
}
@article{Edwards2017391,
title = "Research note: Machinery, manumission, and economic machinations ",
journal = "Journal of Business Research ",
volume = "70",
number = "",
pages = "391 - 394",
year = "2017",
note = "",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2016.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0148296316304994",
author = "David J. Edwards and Erika Parn and Peter E.D. Love and Hatem El-Gohary",
keywords = "Big data",
keywords = "Computerization",
keywords = "Robotics",
keywords = "Off-highway plant and machinery ",
abstract = "Abstract This research note reports upon advancements in computerization and big data creation within the off-highway plant and machinery sector. A thematic literature review synthesizes a disparate range of research initiatives and industrial developments and highlights specific examples of technological developments. A discussion regarding impact upon future employment concludes that rather than creating mass unemployment, computerization will change the employment horizon and continue to shape the global economic community. Education is quintessentially important to humanity which must master the machine and not become a slave to technology. Future proofing of educational provisions will therefore feature heavily in tomorrow's employment market. This provocative research note advances new ideas and theoretical perspectives that are specifically designed to stimulate academic debate in this novel and rapidly developing area of scientific endeavor. "
}
@article{Morwald2016141,
title = "Modeling connected regions in arbitrary planar point clouds by robust B-spline approximation ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "141 - 151",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002948",
author = "Thomas Morwald and Jonathan Balzer and Markus Vincze",
keywords = "B-spline",
keywords = "Reconstruction",
keywords = "Curve fitting",
keywords = "Boundary fitting",
keywords = "Concave hull",
keywords = "Surface trimming ",
abstract = "Abstract This paper presents an algorithm for robustly approximating the boundary of a domain, latent in a planar set of scattered points, by a B-spline curve. The algorithm is characterized by three key features: First, we propose a distance measure, called the Asymmetric Distance (AD), which allows for handling outliers inside the curve and finding the outer boundary or concave hull by specifying very natural parameters like smoothness and accuracy. Second, we provide a solution to the problem of unknown required degrees of freedom by Error-Adaptive Knot Insertion (EAKI). During the iterations of our re-weighted least-squares formulation, we check for regions of high error on the curve and locally increase the degrees of freedom if necessary. Third, we present a method to handle deep and narrow concavities, called Concavity Filling (CF). The curve is examined for areas of large distances to the closest data points. In these regions, we explicitly strap the curve to internal points to force it to bend inwards and fill the concavity. Compared with the state of the art, our method shows fundamental improvement in terms of robustness and applicability to real-world data. For 3D reconstruction of organized and unorganized point clouds, prevalent in robotic \{RGBD\} perception, we achieve higher robustness compared to state-of-the-art methods and compression rates up to a factor of 300. We have integrated our code into the Point Cloud Library (PCL) and created a tutorial that guides through the steps of the algorithm (see footnote 1). "
}
@article{Ramisa2016936,
title = "A 3D descriptor to detect task-oriented grasping points in clothing ",
journal = "Pattern Recognition ",
volume = "60",
number = "",
pages = "936 - 948",
year = "2016",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316301558",
author = "Arnau Ramisa and Guillem Alenya and Francesc Moreno-Noguer and Carme Torras",
keywords = "3D descriptor",
keywords = "Recognition",
keywords = "Detection",
keywords = "Grasping",
keywords = "Manipulation",
keywords = "Robotics ",
abstract = "Abstract Manipulating textile objects with a robot is a challenging task, especially because the garment perception is difficult due to the endless configurations it can adopt, coupled with a large variety of colors and designs. Most current approaches follow a multiple re-grasp strategy, in which clothes are sequentially grasped from different points until one of them yields a recognizable configuration. In this work we propose a method that combines 3D and appearance information to directly select a suitable grasping point for the task at hand, which in our case consists of hanging a shirt or a polo shirt from a hook. Our method follows a coarse-to-fine approach in which, first, the collar of the garment is detected and, next, a grasping point on the lapel is chosen using a novel 3D descriptor. In contrast to current 3D descriptors, ours can run in real time, even when it needs to be densely computed over the input image. Our central idea is to take advantage of the structured nature of range images that most depth sensors provide and, by exploiting integral imaging, achieve speed-ups of two orders of magnitude with respect to competing approaches, while maintaining performance. This makes it especially adequate for robotic applications as we thoroughly demonstrate in the experimental section. "
}
@incollection{Medini2017151,
title = "Chapter 5 - Building a Web of Things with Avatars: A comprehensive approach for concern management in WoT applications ",
editor = "Sheng, Quan Z. and Qin, Yongrui and Yao, Lina  and Benatallah, Boualem ",
booktitle = "Managing the Web of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2017",
pages = "151 - 180",
isbn = "978-0-12-809764-9",
doi = "https://doi.org/10.1016/B978-0-12-809764-9.00007-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012809764900007X",
author = "Lionel Medini and Michael Mrissa and El-Mehdi Khalfi and Mehdi Terdjimi and Nicolas Le Sommer and Philippe Capdepuy and Jean-Paul Jamont and Michel Occello and Lionel Touseau",
keywords = "Cyber-physical systems",
keywords = "Distributed robotics",
keywords = "Semantic interoperability disruption–tolerant networks",
keywords = "Contextual adaptation",
keywords = "Multi-agent systems ",
abstract = "Abstract The Web of Things (WoT) relies on Web standards to enable interoperability between physical objects (things) and build applications using them. While most approaches (Cyber-Physical Systems, Internet of Things) require complex domain-driven software design that combines different disciplines such as electronics, networks and computing, we believe that generic solutions are needed to support WoT applications across the variety of things and application domains. To this end, we propose the notion of avatar as a Web-compliant software extension of a thing. Avatars achieve interoperability between things using semantic technologies and expose high-level functionalities as \{RESTful\} resources. They can collaborate with other avatars and form standard-compliant WoT applications that match end-users' needs. We detail the notion of avatar and describe how avatar-based WoT infrastructures can improve the quality of Web of Things applications. We show how their architecture allows avatars to embed advances in different areas, and focus on contributions at different levels: tolerance to network disconnection, contextual adaptation and multi-agent negotiation. "
}
@incollection{Beer2017359,
title = "Chapter 15 - Affective Human–Robot Interaction ",
editor = "Jeon, Myounghoon ",
booktitle = "Emotions and Affect in Human Factors and Human-Computer Interaction ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2017",
pages = "359 - 381",
isbn = "978-0-12-801851-4",
doi = "https://doi.org/10.1016/B978-0-12-801851-4.00015-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012801851400015X",
author = "Jenay M. Beer and Karina R. Liles and Xian Wu and Sujan Pakala",
keywords = "affective robotics",
keywords = "social robotics",
keywords = "educational robotics",
keywords = "aging-in-place",
keywords = "human-robot interaction",
keywords = "HRI ",
abstract = "Abstract Affective \{HRI\} is an emerging field. This area of study is essential in the development and application of robots in social environments. In this chapter, we specifically cover three social environments: caring for the aging population, companionship, and education. Through this review, important affective themes are identified across these application areas, such as facial expression, user expectation, and user acceptance. However, future research is needed to better understand long-term adoption, individual differences, and varying user needs. "
}
@article{Underwood201683,
title = "Mapping almond orchard canopy volume, flowers, fruit and yield using lidar and vision sensors ",
journal = "Computers and Electronics in Agriculture ",
volume = "130",
number = "",
pages = "83 - 96",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2016.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916308249",
author = "James P. Underwood and Calvin Hung and Brett Whelan and Salah Sukkarieh",
keywords = "Robotics",
keywords = "Sensing",
keywords = "Machine vision",
keywords = "Lidar",
keywords = "Multi-sensor fusion",
keywords = "Orchard yield mapping ",
abstract = "Abstract This paper present a mobile terrestrial scanning system for almond orchards, that is able to efficiently map flower and fruit distributions and to estimate and predict yield for individual trees. A mobile robotic ground vehicle scans the orchard while logging data from on-board lidar and camera sensors. An automated software pipeline processes the data offline, to produce a 3D map of the orchard and to automatically detect each tree within that map, including correct associations for the same trees seen on prior occasions. Colour images are also associated to each tree, leading to a database of images and canopy models, at different times throughout the season and spanning multiple years. A canopy volume measure is derived from the 3D models, and classification is performed on the images to estimate flower and fruit density. These measures were compared to individual tree harvest weights to assess the relationship to yield. A block of approximately 580 trees was scanned at peak bloom, fruit-set and just before harvest for two subsequent years, with up to 50 trees individually harvested for comparison. Lidar canopy volume had the strongest linear relationship to yield with R 2 = 0.77 for 39 tree samples spanning two years. An additional experiment was performed using hand-held photography and image processing to measure fruit density, which exhibited similar performance ( R 2 = 0.71 ). Flower density measurements were not strongly related to yield, however, the maps show clear differentiation between almond varieties and may be useful for other studies. "
}
@article{Munaro201697,
title = "3D robot perception with Point Cloud Library ",
journal = "Robotics and Autonomous Systems ",
volume = "78",
number = "",
pages = "97 - 99",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.12.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015003176",
abstract="",
author = "Matteo Munaro and Radu B. Rusu and Emanuele Menegatti"
}
@incollection{Sivabalan2016363,
title = "Chapter 12 - Robotic-Based Agriculture for Rural Renaissance: Drones and Biosensors ",
editor = "Viviana Scognamiglio, Giuseppina Rea, Fabiana Arduini and Giuseppe Palleschi",
booktitle = "Biosensors for Sustainable Food - New Opportunities and Technical Challenges",
publisher = "Elsevier",
year = "2016",
volume = "74",
pages = "363 - 375",
series = "Comprehensive Analytical Chemistry ",
issn = "0166-526X",
doi = "https://doi.org/10.1016/bs.coac.2016.04.017",
url = "http://www.sciencedirect.com/science/article/pii/S0166526X16300708",
abstract=   "",
author = "K.C. Siva balan",
keywords = "Biosensors",
keywords = "Crop management and protection",
keywords = "Drone technology",
keywords = "Food quality and safety",
keywords = "Soil fertility",
keywords = "Surveillance "
}
@article{Kuss2016545,
title = "Detection of Workpiece Shape Deviations for Tool Path Adaptation in Robotic Deburring Systems ",
journal = "Procedia \{CIRP\} ",
volume = "57",
number = "",
pages = "545 - 550",
year = "2016",
note = "Factories of the Future in the digital environment - Proceedings of the 49th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.094",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116312483",
author = "Alexander Kuss and Manuel Drust and Alexander Verl",
keywords = "Deburring",
keywords = "Industrial Robot System",
keywords = "Shape Deviation",
keywords = "CAD Model ",
abstract = "Abstract Robotic systems have the potential to automate deburring processes along edges of arbitrarily shaped workpieces. The desired robot movement can be realized by proper trajectory planning using the computer-aided design (CAD) model of the manufactured workpiece. A fundamental problem is that geometric shape deviations between the nominal \{CAD\} model and the manufactured parts might be beyond acceptable limits for correct execution of the deburring process. This paper proposes a novel, easy to implement and practical approach to detect shape deviations of workpieces for automatic adaptation of robotic deburring processes. The approach only uses dimensional tolerance specifications of the manufactured part provided by the product design to derive possible variations of the workpiece geometry model. A matching process is performed between point clouds for each of the considered variants and a measured point cloud from the manufactured workpiece using an Iterative Closest Point (ICP) approach. Resulting point distances are used for evaluation of shape similarity between the compared point clouds. Finally, the most similar geometry model is identified for subsequent trajectory planning and workpiece localization. Experimental validation is performed by an industrial robot equipped with a stereo camera for shape sensing and a milling tool for subsequent execution of a deburring process. The results demonstrate the effectiveness and practicality of the proposed approach in industrial applications and an increased deburring quality. "
}
@article{daSilva2016108,
title = "A Cloud-based Architecture for the Internet of Things targeting Industrial Devices Remote Monitoring and Control ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "108 - 113",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.137",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325885",
author = "Ademir F. da Silva and Ricardo L. Ohta and Marcelo N. dos Santos and Alecio P.D. Binotto",
keywords = "Internet of Things (IoT)",
keywords = "Industry 4.0",
keywords = "Tele-maintenanc ",
abstract = "Abstract: The process of acquiring, analysing and managing data obtained by sensors and actuators in industrial environments can benefit from modern Cloud-based platforms towards a complete implementation of the Industrie 4.0 concept. The analysis of huge data sets produced by these sensors (Big Data) could allow quick and accurate decision making. For example, productivity improvements can be achieved by analysing device performance and degradation for real-time feedback on configuration and optimization. This work proposes a Cloud-based architecture for Internet of Things (IoT) applications to improve the deployment of smart industrial systems based on remote monitoring and control. By using specific technologies available as a service, we demonstrate the proposed architecture on an automated electric induction motor use case. This approach includes layers for sensor network data gathering, data transformation between standard protocols, message queuing, real-time data analysis, reporting for further analysis, and real-time control. Particularly, by using the proposed architecture, we remotely monitored, controlled and processed data produced by sensors and actuators coupled to the motor. Preliminary results indicate this foundation can support predictive methods and management of automated systems in the Industrie 4.0 context. "
}
@article{Nguyen20162,
title = "A Smart Shoe for building a real-time 3D map ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "2 - 12",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516300401",
author = "Luan V. Nguyen and Hung M. La and Jesus Sanchez and Tam Vu",
keywords = "Robotics",
keywords = "3D map",
keywords = "Real-time 3D map algorithms",
keywords = "SLAM ",
abstract = "Abstract Three dimensional (3D) mapping of environments has gained tremendous attention, from academic to industry to military, owing to the ever increasing needs of environmental modeling as well as monitoring. While many highly effective techniques have been reported thus far, a few even turned into commercial products, none has explored the use of wearable sensors to capture human foot motion, gait, and phase for 3D map construction, especially in the Architecture, Engineering, and Construction (AEC) domain. In this work, we propose a smart (and wearable) shoe, called “Smart Shoe”, which integrates multiple laser scanners and an inertial measurement unit (IMU) to build a 3D map of environments in real time. Such a Smart Shoe can be a potential tool for floor plan surveying, construction process monitoring, planning renovations, space usage planning, managing building maintenance and other tasks in the \{AEC\} domain. Besides, this Smart Shoe could assist disabled people (blind people) to navigate and avoid obstacles in the unknown environment. In another case, the shoes may help firefighters quickly model and recognize objects in the firing, dark, and smoky buildings where traditional camera-based approaches might not be applicable. We integrate this shoe with a novel foot localization algorithm that produces a smooth and accurate pose and trajectory of human walking, which is the key enabling technique to minimize data registration errors from laser point cloud. "
}
@incollection{Pradilla2016125,
title = "Chapter 7 - Micro Virtual Machines (MicroVMs) for Cloud-assisted Cyber-Physical Systems (CPS) ",
editor = "Buyya, Rajkumar  and Dastjerdi, Amir Vahid ",
booktitle = "Internet of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2016",
pages = "125 - 142",
isbn = "978-0-12-805395-9",
doi = "https://doi.org/10.1016/B978-0-12-805395-9.00007-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053959000071",
author = "J.V. Pradilla and C.E. Palau",
keywords = "Cyber-Physical Systems (CPS)",
keywords = "Internet of Things (IoT)",
keywords = "Sensor Observation Service (SOS)",
keywords = "Micro Virtual Machines (MicroVM)",
keywords = "Sensor Web Enablement (SWE)",
keywords = "eHealth",
keywords = "Precision Agriculture (PA)",
keywords = "domotic ",
abstract = "Abstract Cyber-Physical Systems (CPS) need to adapt to the changing physical world and expand their capabilities dynamically. To meet this need, this chapter proposes a three-tier architecture that integrates: cloud computing, fog computing, and networks of sensors/actuators. It also provides an implementation of the proposed architecture, based on the use of Micro Virtual Machines (MicroVM) and the Sensor Observation Service (SOS), combining the isolation of virtual machines with the standardization of storage and information-exchange under the Sensor Web Enablement (SWE) framework. Subsequently, the proposed architecture is coupled to the Internet of Things (IoT), and three use-cases that can be applied are addressed: eHealth, precision agriculture, and domotics; these three use-cases clarify the benefits of the implementation of the architecture and illustrate the interactions between its composing levels. "
}
@article{Guzzo2009214,
title = "Robotic surgical training of the urologic oncologist ",
journal = "Urologic Oncology: Seminars and Original Investigations ",
volume = "27",
number = "2",
pages = "214 - 217",
year = "2009",
note = "Training the Urologic Oncologist of the Future: Where are the Challenges? ",
issn = "1078-1439",
doi = "https://doi.org/10.1016/j.urolonc.2008.09.019",
url = "http://www.sciencedirect.com/science/article/pii/S1078143908002408",
author = "Thomas J. Guzzo and Mark L. Gonzalgo",
keywords = "Robotic surgery",
keywords = "Training",
keywords = "Oncology ",
abstract = "Robotic-assisted surgery has become an increasingly popular approach to the treatment of a variety of urologic malignancies. The use of minimally invasive techniques for treatment of genitourinary cancers has evolved from conventional laparoscopy to the use of robotic-assisted instrumentation. Many questions remain regarding the safest and most effective way to teach robotic surgery to trainees. Work hour restrictions, medical and legal concerns, and the unique operative set-up of the robotic system have made it increasingly difficult to provide “hands on” operative training to residents and fellows. We review the current literature regarding robotic surgical training, highlight potentially effective training strategies, and discuss future improvements in robotic surgical training of the urologic oncologist. "
}
@article{Jin2016104,
title = "Multi-LeapMotion sensor based demonstration for robotic refine tabletop object manipulation task ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "1",
number = "1",
pages = "104 - 113",
year = "2016",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2016.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S2468232216000111",
author = "Haiyang Jin and Qing Chen and Zhixian Chen and Ying Hu and Jianwei Zhang",
keywords = "LeapMotion sensor",
keywords = "Muti-sensor fusion",
keywords = "Tele-operative demonstration",
keywords = "Gesture recognition",
keywords = "Tabletop object manipulation ",
abstract = "Abstract In some complicated tabletop object manipulation task for robotic system, demonstration based control is an efficient way to enhance the stability of execution. In this paper, we use a new optical hand tracking sensor, LeapMotion, to perform a non-contact demonstration for robotic systems. A Multi-LeapMotion hand tracking system is developed. The setup of the two sensors is analyzed to gain a optimal way for efficiently use the informations from the two sensors. Meanwhile, the coordinate systems of the Mult-LeapMotion hand tracking device and the robotic demonstration system are developed. With the recognition to the element actions and the delay calibration, the fusion principles are developed to get the improved and corrected gesture recognition. The gesture recognition and scenario experiments are carried out, and indicate the improvement of the proposed Multi-LeapMotion hand tracking system in tabletop object manipulation task for robotic demonstration. "
}
@article{Parcheta201619,
title = "A robotic approach to mapping post-eruptive volcanic fissure conduits ",
journal = "Journal of Volcanology and Geothermal Research ",
volume = "320",
number = "",
pages = "19 - 28",
year = "2016",
note = "",
issn = "0377-0273",
doi = "https://doi.org/10.1016/j.jvolgeores.2016.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S037702731630021X",
author = "Carolyn E. Parcheta and Catherine A. Pavlov and Nicholas Wiltsie and Kalind C. Carpenter and Jeremy Nash and Aaron Parness and Karl L. Mitchell",
keywords = "Hawaiian fountains",
keywords = "Fissure",
keywords = "Robots",
keywords = "Mapping",
keywords = "3D model ",
abstract = "Abstract VolcanoBot was developed to map volcanic vents and their underlying conduit systems, which are rarely preserved and generally inaccessible to human exploration. It uses a PrimeSense Carmine 1.09 sensor for mapping and carries an \{IR\} temperature sensor, analog distance sensor, and an inertial measurement unit (IMU) inside a protective shell. The first field test succeeded in collecting valuable scientific data but revealed several needed improvements, including more rugged cable connections and mechanical couplers, increased ground clearance, and higher-torque motors for uphill mobility. The second field test significantly improved on all of these aspects but it traded electrical ruggedness for reduced data collection speed. Data collected by the VolcanoBots, while intermittent, yield the first insights into the cm-scale geometry of volcanic fissures at depths of up to 25 m. VolcanoBot was deployed at the 1969 Mauna Ulu fissure system on Kīlauea volcano in Hawai'i. It collected first-of-its-kind data from inside the fissure system. We hypothesized that 1) fissure sinuosity should decrease with depth, 2) irregularity should be persistent with depth, 3) any blockages in the conduit should occur at the narrowest points, and 4) the fissure should narrow with depth until it is too narrow for VolcanoBot to pass or is plugged with solidified lava. Our field campaigns did not span enough lateral or vertical area to test sinuosity. The preliminary data indicate that 1) there were many irregularities along fissures at depth, 2) blockages occurred, but not at obviously narrow locations, and 3) the conduit width remained a consistent 0.4–0.5 m for most of the upper 10 m that we analyzed. "
}
@article{Jaklic2015143,
title = "Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century \{AD\} Roman shipwreck near Sutivan on island Brac, Croatia ",
journal = "Journal of Archaeological Science ",
volume = "62",
number = "",
pages = "143 - 152",
year = "2015",
note = "",
issn = "0305-4403",
doi = "https://doi.org/10.1016/j.jas.2015.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0305440315002447",
author = "Ales Jaklic and Miran Eric and Igor Mihajlovic and Žiga Stopinsek and Franc Solina",
keywords = "Multi-image photogrammetry",
keywords = "Under-water archeology",
keywords = "Marble blocks",
keywords = "Segmentation",
keywords = "3D models",
keywords = "Superquadrics ",
abstract = "Abstract Multi-image photogrammetry can in favorable conditions even under water generate large clouds of 3D points which can be used for visualization of sunken heritage. For analysis of under-water archeological sites and comparison of artifacts, more compact shape models must be reconstructed from 3D points, where each object or a part of it is modeled individually. Volumetric models and superquadric models in particular are good candidates for such modeling since automated methods for their reconstruction and segmentation from 3D points exist. For the study case we use an underwater wreck site of a Roman ship from 2nd/3rd century \{AD\} located near Sutivan on island Brac in Croatia. We demonstrate how superquadric models of sarcophagi and other stone blocks can be reconstructed from an unsegmented cloud of 3D points obtained by multi-image photogrammetry. We compare the dimensions of stone objects measured directly on the corresponding 3D point cloud with dimensions of the reconstructed superquadric models and discuss other advantages of these volumetric models. The average difference between point-to-point measurements of stone blocks and the dimensions of the corresponding superquadric model is on the order of few centimeters. "
}
@article{Joskowicz201684,
title = "Computer Aided Orthopaedic Surgery: Incremental shift or paradigm change? ",
journal = "Medical Image Analysis ",
volume = "33",
number = "",
pages = "84 - 90",
year = "2016",
note = "20th anniversary of the Medical Image Analysis journal (MedIA) ",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2016.06.036",
url = "http://www.sciencedirect.com/science/article/pii/S136184151630113X",
author = "Leo Joskowicz and Eric J. Hazan",
keywords = "Computer Aided Orthopaedic Surgery",
keywords = "Image guided surgery",
keywords = "Medical robotics",
keywords = "Review article for 20th anniversary issue ",
abstract = "Abstract Computer Aided Orthopaedic Surgery (CAOS) is now about 25 years old. Unlike Neurosurgery, Computer Aided Surgery has not become the standard of care in Orthopaedic Surgery. In this paper, we provide the technical and clinical context raised by this observation in an attempt to elucidate the reasons for this state of affairs. We start with a brief outline of the history of CAOS, review the main \{CAOS\} technologies, and describe how they are evaluated. We then identify some of the current publications in the field and present the opposing views on their clinical impact and their acceptance by the orthopaedic community worldwide. We focus on total knee replacement surgery as a case study and present current clinical results and contrasting opinions on \{CAOS\} technologies. We then discuss the challenges and opportunities for research in medical image analysis in \{CAOS\} and in musculoskeletal radiology. We conclude with a suggestion that while \{CAOS\} acceptance may be more moderate than that of other fields in surgery, it still has a place in the arsenal of useful tools available to orthopaedic surgeons. "
}
@article{Kuenzel201621,
title = "SmartSite: Intelligent and autonomous environments, machinery, and processes to realize smart road construction projects ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "21 - 33",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.03.012",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516300528",
author = "Robin Kuenzel and Jochen Teizer and Marcus Mueller and Alexander Blickle",
keywords = "Automation and robotics",
keywords = "Equipment",
keywords = "Lean organization and management",
keywords = "Logistics management",
keywords = "Multi-agent systems",
keywords = "Road infrastructure construction",
keywords = "Rollers and compactors",
keywords = "Sensors",
keywords = "Supply chain ",
abstract = "Abstract This article presents an overview of the SmartSite research project that adopts machine learning, decision theory and distributed artificial intelligence to design and test a multi-agent system (MAS) for asphalt road construction. SmartSite puts major emphasis on sensing and communication technologies that integrate real-time automated information exchange in the supply chain of road construction. As part of the larger SmartSite project, this article introduces a novel real-time path planning system for compactors and presents the results of several simulation and field realistic experiments conducted to evaluate the system in a sophisticated simulation and harsh construction environment, respectively. The system operates based on Belief-Desire-Intention (BDI) software agents and real-time sensory inputs. The newly developed integrated and information rich process benefits asphalt compactor operators, as they are now capable to control their machinery and react to changing environmental, material-related and process-related disturbances or changes. This improves the quality of the delivery and laying of asphalt material, prevents compactors from over-compacting certain road segments, increases the road's pavement longevity during the operational life cycle phase; refocuses the work tasks of the site managers, and reduces the construction budget and schedule. The system's ability to maneuver an asphalt roller during real-word operation also makes it an important step towards a fully automated asphalt compactor. "
}
@article{Kalogerakis2009282,
title = "Extracting lines of curvature from noisy point clouds ",
journal = "Computer-Aided Design ",
volume = "41",
number = "4",
pages = "282 - 292",
year = "2009",
note = "Point-based Computational Techniques ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2008.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448508002273",
author = "Evangelos Kalogerakis and Derek Nowrouzezahrai and Patricio Simari and Karan Singh",
keywords = "Lines of curvature",
keywords = "Robust curvature estimation",
keywords = "Point cloud denoising",
keywords = "Outlier rejection",
keywords = "Quad mesh construction ",
abstract = "We present a robust framework for extracting lines of curvature from point clouds. First, we show a novel approach to denoising the input point cloud using robust statistical estimates of surface normal and curvature which automatically rejects outliers and corrects points by energy minimization. Then the lines of curvature are constructed on the point cloud with controllable density. Our approach is applicable to surfaces of arbitrary genus, with or without boundaries, and is statistically robust to noise and outliers while preserving sharp surface features. We show our approach to be effective over a range of synthetic and real-world input datasets with varying amounts of noise and outliers. The extraction of curvature information can benefit many applications in CAD, computer vision and graphics for point cloud shape analysis, recognition and segmentation. Here, we show the possibility of using the lines of curvature for feature-preserving mesh construction directly from noisy point clouds. "
}
@article{Misimi201684,
title = "\{GRIBBOT\} – Robotic 3D vision-guided harvesting of chicken fillets ",
journal = "Computers and Electronics in Agriculture ",
volume = "121",
number = "",
pages = "84 - 100",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2015.11.021",
url = "http://www.sciencedirect.com/science/article/pii/S0168169915003701",
author = "Ekrem Misimi and Elling Ruud Oye and Aleksander Eilertsen and John Reidar Mathiassen and Olav Berg asebO and Tone Gjerstad and Jan Buljo and Oystein Skotheim",
keywords = "Flexible automation",
keywords = "Visual servoing",
keywords = "Robot",
keywords = "Chicken",
keywords = "Harvesting",
keywords = "Gripper ",
abstract = "Abstract In Norway, the final stage of front half chicken harvesting is still a manual operation due to a lack of automated systems that are suitably flexible with regard to production efficiency and raw material utilisation. This paper presents the ‘GRIBBOT’ – a novel 3D vision-guided robotic concept for front half chicken harvesting. It functions using a compliant multifunctional gripper tool that grasps and holds the fillet, scrapes the carcass, and releases the fillet using a downward pulling motion. The gripper has two main components; a beak and a supporting plate. The beak scrapes the fillet down the rib cage of the carcass following a path determined by the anatomical boundary between the meat and the bone of the rib cage. The supporting plate is actuated pneumatically in order to hold the fillet. A computer vision algorithm was developed to process images from an RGB-D camera (Kinect v2) and locate the grasping point in 3D as the initial contact point of the gripper with the chicken carcass for harvesting operation. Calibration of camera and robot was performed so that the grasping point was defined using 3D coordinates within the robot’s base coordinate frame and tool centre point. A feed-forward Look-and-Move control algorithm was used to control the robot arm and generate the motion trajectories, based on the 3D coordinates of the grasping point as calculated from the computer vision algorithm. The results of an experimental proof-of-concept demonstration showed that \{GRIBBOT\} was successful both in scraping the carcass, grasping chicken fillets automatically and in completing the front half fillet harvesting process. It demonstrated a potential for the flexible robotic automation of the chicken fillet harvesting operation. Its commercial application, with further development, can result in automated fillet harvesting, while future research may also lead to optimal raw material utilisation. \{GRIBBOT\} shows that there is potential to automate even the most challenging processing operations currently carried out manually by human operators. "
}
@article{Rusu2008927,
title = "Towards 3D Point cloud based object maps for household environments ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "11",
pages = "927 - 941",
year = "2008",
note = "Semantic Knowledge in Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001140",
author = "Radu Bogdan Rusu and Zoltan Csaba Marton and Nico Blodow and Mihai Dolha and Michael Beetz",
keywords = "Environment object model",
keywords = "Point cloud data",
keywords = "Geometrical reasoning ",
abstract = "This article investigates the problem of acquiring 3D object maps of indoor household environments, in particular kitchens. The objects modeled in these maps include cupboards, tables, drawers and shelves, which are of particular importance for a household robotic assistant. Our mapping approach is based on \{PCD\} (point cloud data) representations. Sophisticated interpretation methods operating on these representations eliminate noise and resample the data without deleting the important details, and interpret the improved point clouds in terms of rectangular planes and 3D geometric shapes. We detail the steps of our mapping approach and explain the key techniques that make it work. The novel techniques include statistical analysis, persistent histogram features estimation that allows for a consistent registration, resampling with additional robust fitting techniques, and segmentation of the environment into meaningful regions. "
}
@article{Barnfather201629,
title = "Photogrammetric measurement process capability for metrology assisted robotic machining ",
journal = "Measurement ",
volume = "78",
number = "",
pages = "29 - 41",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2015.09.045",
url = "http://www.sciencedirect.com/science/article/pii/S0263224115005126",
author = "J.D. Barnfather and M.J. Goodfellow and T. Abram",
keywords = "Photogrammetry",
keywords = "Performance",
keywords = "Uncertainty",
keywords = "Inspection ",
abstract = "Abstract This paper documents the findings of experiments done to assess the capability of a photogrammetric measurement process for use in a metrology assisted robotic machining application. Capability is judged from the perspective of uncertainty and error across various part geometries over several days. The influence of operator technique on error and point acquisition ability for challenging geometry is also assessed. The process is found to be resistant to short-term error drift when operating in a controlled environment but systematic and random errors are demonstrated to be highly dependent on geometry. Operator influence on capability is found to be minimal when scanning freeform geometry, although this is unlikely for more complex parts. Acquisition of inspection points on cylindrical pockets is found to be a limitation. Technological development opportunities are highlighted in the context of the metrology assistance application considered. Overall, a thorough assessment of the measurement process capability is made and findings provide a quantification of current state, setting a base case for comparing research progress against. "
}
@article{Chan2009640,
title = "Image-guided robotic neurosurgery—an in vitro and in vivo point accuracy evaluation experimental study ",
journal = "Surgical Neurology ",
volume = "71",
number = "6",
pages = "640 - 647",
year = "2009",
note = "",
issn = "0090-3019",
doi = "https://doi.org/10.1016/j.surneu.2008.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0090301908005806",
author = "Frank Chan and Irwan Kassim and Charles Lo and Chi Long Ho and David Low and Beng Ti Ang and Ivan Ng",
keywords = "Stereotactic brain biopsy",
keywords = "Robotic surgery",
keywords = "Image Guided Surgery",
keywords = "Stereotactic neurosurgery ",
abstract = "Background We describe the development of a prototype neurosurgical robotic system called NISS. The aim is to implement a robotic system capable of achieving accurate registration of robotic coordinate systems based on \{CT\} images, so that it can be used in clinical application. This system has been refined with a better level of predictability, reliability, and robustness sufficient for animal trial evaluation in stereotactic biopsy of brain lesions. Methods Point accuracy evaluation of \{NISS\} began with an in vitro study. The in vitro robotic application accuracy result was 0.1 ± 0.05 mm and absolute needle-to-target deviation was 0.3 ± 0.2 mm. An in vivo experiment approach of using steel balls of 1.56-mm-diameter as targets inside the brain of an anaesthetized dog was used to evaluate the performance accuracy of \{NISS\} stereotactic probe placement. Five dogs underwent surgical insertion of steel balls into the brain, and the steel balls were served as targets to be reached by a core needle (1.56-mm-diameter). The experiment was carried out by precise manipulation of the needle to reach the steel ball using frameless stereotactic localization principles. Results A total of 9 needle results were collected from procedures involving 5 dogs. In the first 5 procedures on 3 dogs, the results were less than 1.9 mm, with an average of 1.3 ± 0.5 mm. The remaining 4 procedures on 2 dogs yielded results of less than 0.7 mm, with an average of 0.3 ± 0.2 mm. Conclusion The in vitro and in vivo studies represent the first approach toward evaluating targeting accuracy of a robotic surgery system by using stereotactics biopsy application in a living subject. "
}
@article{Abayowa201568,
title = "Automatic registration of optical aerial imagery to a LiDAR point cloud for generation of city models ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "106",
number = "",
pages = "68 - 81",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001434",
author = "Bernard O. Abayowa and Alper Yilmaz and Russell C. Hardie",
keywords = "Scene modeling",
keywords = "Aerial imagery",
keywords = "Sensor fusion",
keywords = "LiDAR",
keywords = "3D registration ",
abstract = "Abstract This paper presents a framework for automatic registration of both the optical and 3D structural information extracted from oblique aerial imagery to a Light Detection and Ranging (LiDAR) point cloud without prior knowledge of an initial alignment. The framework employs a coarse to fine strategy in the estimation of the registration parameters. First, a dense 3D point cloud and the associated relative camera parameters are extracted from the optical aerial imagery using a state-of-the-art 3D reconstruction algorithm. Next, a digital surface model (DSM) is generated from both the LiDAR and the optical imagery-derived point clouds. Coarse registration parameters are then computed from salient features extracted from the LiDAR and optical imagery-derived DSMs. The registration parameters are further refined using the iterative closest point (ICP) algorithm to minimize global error between the registered point clouds. The novelty of the proposed approach is in the computation of salient features from the DSMs, and the selection of matching salient features using geometric invariants coupled with Normalized Cross Correlation (NCC) match validation. The feature extraction and matching process enables the automatic estimation of the coarse registration parameters required for initializing the fine registration process. The registration framework is tested on a simulated scene and aerial datasets acquired in real urban environments. Results demonstrates the robustness of the framework for registering optical and 3D structural information extracted from aerial imagery to a LiDAR point cloud, when co-existing initial registration parameters are unavailable. "
}
@article{Triantafyllou2016233,
title = "A geometric approach to robotic unfolding of garments ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "233 - 243",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.025",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002201",
author = "Dimitra Triantafyllou and Ioannis Mariolis and Andreas Kargakos and Sotiris Malassiotis and Nikos Aspragathos",
keywords = "Garment manipulation",
keywords = "Shape analysis",
keywords = "Unfolding ",
abstract = "Abstract This work presents a novel approach to autonomous unfolding of garments by means of a dual arm robotic manipulator. The proposed approach is based on the observation that a garment can be brought to an approximately planar configuration if it is held by two points on its outline. This step facilitates the detection of another set of points that when grasped the garment will naturally unfold. A robust method for successively detecting such boundary points on images of garments hanging from a single point was developed. The manipulated garment is then laid on a flat surface and matched to a set of foldable templates using shape analysis techniques. Using the established correspondences with the template’s landmark points the garment is re-grasped by such two points that it will naturally unfold in a spread out configuration. The adopted framework has been experimentally evaluated using a dual industrial manipulator and a variety of garments. The produced results indicate the feasibility and robustness of the proposed approach. "
}
@article{Andreoli201579,
title = "\{PIXE\} micro-mapping of minor elements in Hypatia, a diamond bearing carbonaceous stone from the Libyan Desert Glass area, Egypt: Inheritance from a cold molecular cloud? ",
journal = "Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms ",
volume = "363",
number = "",
pages = "79 - 85",
year = "2015",
note = "14th International Conference on Particle Induced X-ray Emission ",
issn = "0168-583X",
doi = "https://doi.org/10.1016/j.nimb.2015.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0168583X1500837X",
author = "M.A.G. Andreoli and W.J. Przybylowicz and J. Kramers and G. Belyanin and J. Westraadt and M. Bamford and J. Mesjasz-Przybylowicz and A. Venter",
keywords = "Hypatia",
keywords = "Pre-solar dust",
keywords = "Micro-PIXE",
keywords = "Dynamic Analysis ",
abstract = "Abstract Matter originating from space, particularly if it represents rare meteorite samples, is ideally suited to be studied by Particle Induced X-ray Emission (PIXE) as this analytical technique covers a broad range of trace elements and is per se non-destructive. We describe and interpret a set of micro-PIXE elemental maps obtained on two minute (weighing about 25 and 150 mg), highly polished fragments taken from Hypatia, a controversial, diamond-bearing carbonaceous pebble from the \{SW\} Egyptian desert. \{PIXE\} data show that Hypatia is chemically heterogeneous, with significant amounts of primordial S, Cl, P and at least 10 elements with Z &gt; 21 (Ti, V, Cr, Mn, Fe, Ni, Os, Ir) locally attaining concentrations above 500 ppm. Si, Al, Ca, K, O also occur, but are predominantly confined to cracks and likely represent contamination from the desert environment. Unusual in the stone is poor correlation between elements within the chalcophile (S vs. Cu, Zn) and siderophile (i.e.: Fe vs. Ni, Ir, Os) groups, whereas other siderophiles (Mn, Mo and the Platinum group elements (PGEs)) mimic the distribution of lithophile elements such as Cr and V. Worthy of mention is also the presence of a globular domain (O ∼ 120 μm) that is C and metals-depleted, yet Cl (P)-enriched (&gt;3 wt.% and 0.15 wt.% respectively). While the host of the Cl remains undetermined, this chemical unit is enclosed within a broader domain that is similarly C-poor, yet Cr–Ir rich (up to 1.2 and 0.3 wt.% respectively). Our data suggest that the pebble consists of shock-compacted, primitive carbonaceous material enriched in cold, pre-solar dust. "
}
@article{Bao2016265,
title = "Field-based Robotic Phenotyping for Sorghum Biomass Yield Component Traits Characterization Using Stereo Vision ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "265 - 270",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.049",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316123",
author = "Yin Bao and Lie Tang",
keywords = "Field phenotyping",
keywords = "biomass sorghum",
keywords = "plant height",
keywords = "stem diameter",
keywords = "leaf area",
keywords = "vegetation volume",
keywords = "semi-global stereo matching ",
abstract = "Abstract: Sorghum is known as a major potential feedstock for biofuel production. Being able to efficiently discover genetic control of many traits over a large number of genotypes, genome-wide association study (GWAS) has become a powerful tool for studying sorghum biomass yield components. However, automated high-throughput field-based plant phenotyping is now the bottleneck for scaling up such experiments. This paper presents an auto-guidance enabled utility tractor which navigates itself between crop rows with a predefined path while collecting stereo images of sorghum samples from both sides of the vehicle. Three levels of stereo camera heads were instrumented to capture images of plants up to 3 meters tall. The stereo images were processed offline to reconstruct 3D point clouds using Semi-Global Block Matching. A semi-automated software interface was developed to measure stem diameter due to the strict sampling strategy and the complexity of high-density crop canopy. An automated hedge-based feature extraction pipeline was proposed to quantify other variations in plant architecture traits such as plant height, leaf area index (LAI) and vegetation volume index (VVI). The stem diameter measured using the semiautomatic method showed high correlation (0.958) to hand measurement. "
}
@article{Jiang20093839,
title = "Registration for 3-D point cloud using angular-invariant feature ",
journal = "Neurocomputing ",
volume = "72",
number = "16–18",
pages = "3839 - 3844",
year = "2009",
note = "Financial EngineeringComputational and Ambient Intelligence (IWANN 2007) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2009.05.013",
url = "http://www.sciencedirect.com/science/article/pii/S0925231209001702",
author = "Jun Jiang and Jun Cheng and Xinglin Chen",
keywords = "3-D registration",
keywords = "ICP",
keywords = "Angular invariant",
keywords = "Curvature invariant",
keywords = "3-D point cloud ",
abstract = "This paper proposes an angular-invariant feature for 3-D registration procedure to perform reliable selection of point correspondence. The feature is a k -dimensional vector, and each element within the vector is an angle between the normal vector and one of its k nearest neighbors. The angular feature is invariant to scale and rotation transformation, and is applicable for the surface with small curvature. The feature improves the convergence and error without any assumptions about the initial transformation. Besides, no strict sampling strategy is required. Experiments illustrate that the proposed angular-based algorithm is more effective than iterative closest point (ICP) and the curvature-based algorithm. "
}
@article{Iocchi2015258,
title = "RoboCup@Home: Analysis and results of evolving competitions for domestic and service robots ",
journal = "Artificial Intelligence ",
volume = "229",
number = "",
pages = "258 - 281",
year = "2015",
note = "",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215001174",
author = "Luca Iocchi and Dirk Holz and Javier Ruiz-del-Solar and Komei Sugiura and Tijn van der Zant",
keywords = "Robotic competitions",
keywords = "Artificial intelligence and robotics",
keywords = "Benchmarking ",
abstract = "Abstract Scientific competitions are becoming more common in many research areas of artificial intelligence and robotics, since they provide a shared testbed for comparing different solutions and enable the exchange of research results. Moreover, they are interesting for general audiences and industries. Currently, many major research areas in artificial intelligence and robotics are organizing multiple-year competitions that are typically associated with scientific conferences. One important aspect of such competitions is that they are organized for many years. This introduces a temporal evolution that is interesting to analyze. However, the problem of evaluating a competition over many years remains unaddressed. We believe that this issue is critical to properly fuel changes over the years and measure the results of these decisions. Therefore, this article focuses on the analysis and the results of evolving competitions. In this article, we present the RoboCup@Home competition, which is the largest worldwide competition for domestic service robots, and evaluate its progress over the past seven years. We show how the definition of a proper scoring system allows for desired functionalities to be related to tasks and how the resulting analysis fuels subsequent changes to achieve general and robust solutions implemented by the teams. Our results show not only the steadily increasing complexity of the tasks that RoboCup@Home robots can solve but also the increased performance for all of the functionalities addressed in the competition. We believe that the methodology used in RoboCup@Home for evaluating competition advances and for stimulating changes can be applied and extended to other robotic competitions as well as to multi-year research projects involving Artificial Intelligence and Robotics. "
}
@article{Polewski2015252,
title = "Detection of fallen trees in \{ALS\} point clouds using a Normalized Cut approach trained by simulation ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "105",
number = "",
pages = "252 - 271",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615000271",
author = "Przemyslaw Polewski and Wei Yao and Marco Heurich and Peter Krzystek and Uwe Stilla",
keywords = "Precision forestry",
keywords = "Dead trees",
keywords = "Normalized Cut",
keywords = "LiDAR",
keywords = "Learning",
keywords = "Vegetation mapping ",
abstract = "Abstract Downed dead wood is regarded as an important part of forest ecosystems from an ecological perspective, which drives the need for investigating its spatial distribution. Based on several studies, Airborne Laser Scanning (ALS) has proven to be a valuable remote sensing technique for obtaining such information. This paper describes a unified approach to the detection of fallen trees from \{ALS\} point clouds based on merging short segments into whole stems using the Normalized Cut algorithm. We introduce a new method of defining the segment similarity function for the clustering procedure, where the attribute weights are learned from labeled data. Based on a relationship between Normalized Cut’s similarity function and a class of regression models, we show how to learn the similarity function by training a classifier. Furthermore, we propose using an appearance-based stopping criterion for the graph cut algorithm as an alternative to the standard Normalized Cut threshold approach. We set up a virtual fallen tree generation scheme to simulate complex forest scenarios with multiple overlapping fallen stems. This simulated data is then used as a basis to learn both the similarity function and the stopping criterion for Normalized Cut. We evaluate our approach on 5 plots from the strictly protected mixed mountain forest within the Bavarian Forest National Park using reference data obtained via a manual field inventory. The experimental results show that our method is able to detect up to 90% of fallen stems in plots having 30–40% overstory cover with a correctness exceeding 80%, even in quite complex forest scenes. Moreover, the performance for feature weights trained on simulated data is competitive with the case when the weights are calculated using a grid search on the test data, which indicates that the learned similarity function and stopping criterion can generalize well on new plots. "
}
@article{Yandun2016457,
title = "Classifying Agricultural Terrain for Machinery Traversability Purposes* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "457 - 462",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.083",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316469",
author = "Francisco J. Yandun and Eduard Gregorio and Marcos Zuniga and Alexandre Escola and Joan R. Rosell-Polo and Fernando A. Auat Cheein",
keywords = "Agricultural robotics",
keywords = "terrain classification",
keywords = "terramechanics modelling",
keywords = "pattern recognition ",
abstract = "Abstract: The detection of the type of soil surface where a robotic vehicle is navigating on is an important issue for performing several agricultural tasks. Satisfactory results in activities such as seeding, plowing, fertilizing, among others depend on a correct identification of the vehicle environment, specially its contact interface with the ground. In the this work, the implementation of a supervised image texture classifier to recognize five different classes of typical agricultural soil surfaces is presented and analysed. The sensing device is the Microsoft Kinect for Windows V2, which allows to acquire RGB, \{IR\} and depth data. Only \{IR\} and depth data were used for the processing, since color information becomes unreliable under different illumination conditions. Two data acquisition modes allowed to validate and to apply the system in real operation conditions. The accuracy of the classifier was assessed under different configuration parameters, obtaining up to 93 percent of success rate, in ideal conditions. Real field conditions were simulated by placing the sensor over a moving wagon, obtaining up to 86 percent of success rate, showing in this way the usability of a low cost sensor such as the Kinect \{V2\} for agricultural robotics. "
}
@article{Odegard2016486,
title = "A new method for underwater archaeological surveying using sensors and unmanned platforms ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "23",
pages = "486 - 493",
year = "2016",
note = "10th \{IFAC\} Conference on Control Applications in Marine SystemsCAMS 2016Trondheim, Norway, 13—16 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.453",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316320419",
author = "Oyvind Odegard and Asgeir J. SOrensen and Roy E. Hansen and Martin Ludvigsen",
keywords = "Wreck",
keywords = "sensors",
keywords = "marine archaeology",
keywords = "underwater robotics",
keywords = "control",
keywords = "navigation ",
abstract = "Abstract: As most of the world’s oceans are inaccessible to diving archaeologists, we must rely on advanced underwater technology and marine robotics to explore, map and investigate ship wrecks in these areas. New sensors and unmanned sensor platforms represent huge potentials for archaeological applications, but require a scrutinous look at how established archaeological methods and approaches must be adapted or rejected to optimize the results. Surveys done on a disintegrated wreck site with acoustic sensors like side scan sonar and synthetic aperture sonar, and optical sensors like stereo cameras, video and underwater hyperspectral imager, are compiled to serve as a case study to demonstrate the method. Challenges regarding guidance, navigation and control are discussed. "
}
@article{Shah2016248,
title = "Development of a Mobile Robotic Phenotyping System for Growth Chamber-based Studies of Genotype x Environment Interactions ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "248 - 253",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.046",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316093",
author = "D. Shah and L. Tang and Jingyao Gai and R. Putta-Venkata",
keywords = "3D Reconstruction",
keywords = "Phenotyping",
keywords = "Mobile robots",
keywords = "Robot arm",
keywords = "Robot probing",
keywords = "Growth chamber ",
abstract = "Abstract: To increase understanding of the interaction between phenotype and genotype x environment to improve crop performance, large amounts of phenotypic data are needed. Studying plants of a given strain under multiple environments can greatly help to reveal their interactions. To collect the labor-intensive data required to perform experiments in this area, a Mecanum-wheeled, magnetic-tape-following indoor rover has been developed to accurately and autonomously move between and inside growth chambers. Integration of the motor controllers, a robot arm, and a Microsoft Kinect (v2) 3D sensor was achieved in a customized C++ program. Detecting and segmenting plants in a multi-plant environment is a challenging task, which can be aided by integration of depth data into these algorithms. Image-processing functions were implemented to filter the depth image to minimize noise and remove undesired surfaces, reducing the memory requirement and allowing the plant to be reconstructed at a higher resolution in real-time. Three-dimensional meshes representing plants inside the chamber were reconstructed using the Kinect SDK’s KinectFusion. After transforming user-selected points in camera coordinates to robot-arm coordinates, the robot arm is used in conjunction with the rover to probe desired leaves, simulating the future use of sensors such as a fluorimeter and Raman spectrometer. This paper reports the system architecture and some preliminary results of the system. "
}
@article{Morell201455,
title = "Geometric 3D point cloud compression ",
journal = "Pattern Recognition Letters ",
volume = "50",
number = "",
pages = "55 - 62",
year = "2014",
note = "Depth Image Analysis ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2014.05.016",
url = "http://www.sciencedirect.com/science/article/pii/S016786551400172X",
author = "Vicente Morell and Sergio Orts and Miguel Cazorla and Jose Garcia-Rodriguez",
keywords = "3D data",
keywords = "Compression",
keywords = "Kinect ",
abstract = "Abstract The use of 3D data in mobile robotics applications provides valuable information about the robot’s environment but usually the huge amount of 3D information is unmanageable by the robot storage and computing capabilities. A data compression is necessary to store and manage this information but preserving as much information as possible. In this paper, we propose a 3D lossy compression system based on plane extraction which represent the points of each scene plane as a Delaunay triangulation and a set of points/area information. The compression system can be customized to achieve different data compression or accuracy ratios. It also supports a color segmentation stage to preserve original scene color information and provides a realistic scene reconstruction. The design of the method provides a fast scene reconstruction useful for further visualization or processing tasks. "
}
@article{Mutz2016439,
title = "Large-scale mapping in complex field scenarios using an autonomous car ",
journal = "Expert Systems with Applications ",
volume = "46",
number = "",
pages = "439 - 462",
year = "2016",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.10.045",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415007496",
author = "Filipe Mutz and Lucas P. Veronese and Thiago Oliveira-Santos and Edilson de Aguiar and Fernando A. Auat Cheein and Alberto Ferreira De Souza",
keywords = "Robotics",
keywords = "Autonomous vehicles",
keywords = "SLAM",
keywords = "GraphSLAM",
keywords = "Mapping ",
abstract = "Abstract In this paper, we present an end-to-end framework for precise large-scale mapping with applications in autonomous driving. In special, the problem of mapping complex environments, with features changing from tree-lined streets to urban areas with dense traffic, is studied. The robotic car is equipped with an odometry sensor, a 3D LiDAR Velodyne HDL-32E, a IMU, and a low cost GPS, and the data generated by these sensors are integrated in a pose-based GraphSLAM estimator. A new strategy for identification and correction of odometry data using evolutionary algorithms is presented. This new strategy makes odometry data significantly more consistent with GPS. Loop closures are detected using \{GPS\} data, and GICP, a 3D point cloud registration algorithm, is used to estimate the displacement between the different travels over the same region. After path estimation, 3D LiDAR data is used to build an occupancy grid mapping of the environment. A detailed mathematical description of how occupancy evidence can be calculated from the point clouds is given, and a submapping strategy to handle memory limitations is presented as well. The proposed framework is tested in three real world environments with different sizes, and features: a parking lot, a university beltway, and a city neighborhood. In all cases, satisfactory maps were built, with precise loop closures even when the vehicle traveled long distances between them. "
}
@article{Azariadis2007832,
title = "Product design using point-cloud surfaces: A recursive subdivision technique for point parameterization ",
journal = "Computers in Industry ",
volume = "58",
number = "8–9",
pages = "832 - 843",
year = "2007",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2007.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361507000528",
author = "Philip Azariadis and Nickolas Sapidis",
keywords = "Point-cloud",
keywords = "Point-set surfaces",
keywords = "Parameterization",
keywords = "Dynamic base surfaces",
keywords = "Point-based modelling ",
abstract = "This paper presents a method for parameterizing three-dimensional (3D) point-clouds using a recursive subdivision approach. The proposed solution adapts ideas from emerging point-based geometric modelling and extends the dynamic base surfaces (DBS) concept in order to improve the accuracy of the produced parameterizations. Using the new approach it is possible to compute parameterizations for point-clouds which may be “thick” or with a varying density. Indicative examples are presented to illustrate the benefits of the proposed method. "
}
@article{Eissa201517,
title = "Validating surface downwelling solar irradiances estimated by the McClear model under cloud-free skies in the United Arab Emirates ",
journal = "Solar Energy ",
volume = "114",
number = "",
pages = "17 - 31",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2015.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X15000316",
author = "Yehia Eissa and Saima Munawwar and Armel Oumbe and Philippe Blanc and Hosni Ghedira and Lucien Wald and Helène Bru and Dominique Goffe",
keywords = "Aerosols",
keywords = "Atmosphere",
keywords = "MACC",
keywords = "Solar radiation ",
abstract = "Abstract McClear, a fast model based on a radiative transfer solver, exploits the atmospheric properties provided by the EU-funded \{MACC\} project (Monitoring Atmospheric Composition and Climate) to estimate the surface downwelling solar irradiances for cloud-free instances. This article presents the first validation of the McClear model for the specific climate of the United Arab Emirates where skies are frequently cloud-free but turbid. McClear accurately estimates the global horizontal irradiance measured every 10 min at seven sites. The bias ranges from −9 W m−2 (−1% of the mean observed irradiance) to +35 W m−2 (+6%). The root mean square error (RMSE) ranges from 22 W m−2 (4%) to 47 W m−2 (8%) and the coefficient of determination ranges from 0.980 to 0.990. Estimates of the direct irradiance at normal incidence exhibit an underestimation that is attributed to the overestimation of the aerosol optical depth in the \{MACC\} data set and not accounting for the circumsolar radiation in McClear. The corresponding bias ranges from −57 W m−2 (−8%) to +6 W m−2 (+1%). The \{RMSE\} ranges from 62 W m−2 (9%) to 87 W m−2 (13%) and the coefficient of determination ranges from 0.830 to 0.863. When compared to two other models in the literature, McClear is better able to capture the temporal variability of the direct irradiance at normal incidence. The validation results remain comparable for the global horizontal irradiance. "
}
@article{Lanouette201578,
title = "Residual mechanical properties of a carbon fibers/PEEK space robotic arm after simulated orbital debris impact ",
journal = "International Journal of Impact Engineering ",
volume = "84",
number = "",
pages = "78 - 87",
year = "2015",
note = "",
issn = "0734-743X",
doi = "https://doi.org/10.1016/j.ijimpeng.2015.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0734743X15001086",
author = "Anne-Marie Lanouette and Marie-Josee Potvin and Francis Martin and Dany Houle and Daniel Therriault",
keywords = "Carbon fiber/PEEK",
keywords = "Hypervelocity impact (HVI)",
keywords = "Micrometeoroid and orbital debris (MMOD)",
keywords = "Mechanical properties after impact",
keywords = "Fatigue testing ",
abstract = "Abstract The robotic arm on the International Space Station, Canadarm2, is susceptible to damage by orbital debris impact; evaluating its residual stiffness and resistance is thus of prime importance. Four cylinders, made of 19-ply carbon fiber IM7/PEEK laminates, each with a diameter of 35 cm, representative of the structure of Canadarm2, were subjected to hypervelocity impacts. Aluminum projectiles with diameters of 5.56 mm and 7.94 mm and velocities of ∼7 km/s were used for the tests. Imaging of the damaged zones was performed and the cylinders were thereafter subjected to fatigue tests by bending them under load amplitudes of ∼2.5 kNm or ∼4.5 kNm. The damaged zones were positioned close to the neutral plane in one test and far from the neutral plane in three tests. Damage propagation was detected using ∼4.5 kNm load amplitude for the damage that was far from the neutral plane, demonstrating that impacts of this nature on Canadarm2 could be problematic for its continued use at this level of loading. "
}
@article{Borangiu2009299,
title = "Flexible 3D Trajectory Teaching and Following for Various Robotic Applications ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "16",
pages = "299 - 304",
year = "2009",
note = "9th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090909-4-JP-2010.00052",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015306522",
author = "Theodor Borangiu and Alexandru Dumitrache and Anamaria Dogar",
keywords = "Robotic manipulators",
keywords = "trajectory learning",
keywords = "laser range finder",
keywords = "robot vision ",
abstract = "Abstract This paper addresses an actual problem regarding complex industrial robot applications. Based on the fact that no \{CAD\} model for the processed parts is available, the application presented here consists in a 3D accurate path following, applicable in various robot tasks. Using a sensor-based 3D path learning procedure available in automatic or manual mode, the 6 d.o.f industrial robot will be able to reproduce in real-time the learned trajectory. Calibration and synchronization aspects are presented, and experimental results are provided and analyzed. "
}
@article{Cattani2006310,
title = "Influence of aerosol particles from biomass burning on cloud microphysical properties and radiative forcing ",
journal = "Atmospheric Research ",
volume = "82",
number = "1–2",
pages = "310 - 327",
year = "2006",
note = "14th International Conference on Clouds and Precipitation14th \{ICCP14th\} International Conference on Clouds and Precipitation ",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2005.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169809506000433",
author = "E. Cattani and M.J. Costa and F. Torricella and V. Levizzani and A.M. Silva",
keywords = "Aerosol–cloud interactions",
keywords = "Cloud parameter retrieval",
keywords = "Radiative transfer",
keywords = "Remote sensing ",
abstract = "Aerosol from biomass burning has been shown to strongly modify cloud microphysical properties and cloud lifetime through the so-called “indirect effect.” However, in the case of a lack of wet scavenging, it stays suspended for days to weeks and can be transported to considerable distances within an elevated layer above low-level cloud tops with minimal aerosol–cloud interactions. The observations carried out during the Southern African Regional Science Initiative (SAFARI) 2000 dry season field campaign often revealed the presence of an elevated biomass-burning aerosol layer above a semi-permanent stratiform cloud deck off the southern African coasts. MODerate-resolution Imaging Spectroradiometer (MODIS) cloud products were used to investigate the existence of an aerosol indirect effect on convective clouds. Results are presented documenting cloud effective radius and cloud radiative forcing variations due to the presence of the aerosol during the development of convective clouds. Radiative transfer simulations in the visible (0.8 μm, VIS) and near-infrared (1.6, 2.1 and 3.7 μm, NIR) wavelengths were instrumental in establishing the extent of the influence of a biomass-burning aerosol layer overlying a water cloud sheet on the \{MODIS\} satellite retrieval of cloud parameters, in particular the effective radius and the optical thickness. The radiative transfer simulations suggest that the presence of the aerosol induces a significant underestimation of the cloud optical thickness, whereas an underestimation of the retrieved effective radius is more pronounced in the retrieval that makes use of the 1.6 μm waveband than the 2.1 and 3.7 μm wavebands. The \{MODIS\} cloud products of 3 days of the \{SAFARI\} 2000 campaign were analyzed to determine whether the aerosol induced biases evidenced by the simulations also affect the operational cloud property retrieval. Cloud parameters, in particular the effective radius, are usually employed as indicators of the occurrence of aerosol–cloud interaction according to the “indirect effect.” However, these results highlight some of the difficulties associated with satellite retrievals of cloud properties and show the importance of an accurate sighting of the cloud and aerosol layer top and bottom heights in order to prevent erroneous detections of indirect effects. "
}
@article{Moghaddam2015828,
title = "Manufacturing-as-a-Service—From e-Work and Service-Oriented Architecture to the Cloud Manufacturing Paradigm ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "828 - 833",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.186",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315004255",
author = "Mohsen Moghaddam and Jose Reinaldo Silva and Shimon Y. Nof",
keywords = "Manufacturing Paradigm",
keywords = "Collaborative Control Theory (CCT)",
keywords = "Service design ",
abstract = "Abstract After consolidation of classic manufacturing line, several alternative arrangements have been experimented and modeled to explore emerging features such as non-linearity, integration, flexibility, and decentralization by the virtue of holonic and agent-based technologies. All this transformation reflects remarkable evolution in manufacturing systems and emergence of a ubiquitous culture introduced by e- Work and supported by Information and Communication Technologies (ICT). Yet, there is a new paradigm shift emerging in manufacturing: the tendency to move from the traditional product- /production-oriented manufacturing to service-oriented manufacturing. Such tendency is being spread in academic work as well as in today's management decisions. This article briefly reviews and analyzes the emerging coalition between collaborative e-Manufacturing and Service-Oriented Architecture (SOA) towards the fonnation of a new manufacturing paradigm composed of a cloud of sendees that enable the notion of Manufacturing-as-a-Service (MaaS). "
}
@article{Kumar2016975,
title = "Smart Autonomous Gardening Rover with Plant Recognition Using Neural Networks ",
journal = "Procedia Computer Science ",
volume = "93",
number = "",
pages = "975 - 981",
year = "2016",
note = "Proceedings of the 6th International Conference on Advances in Computing and Communications ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.07.289",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916315356",
author = "V. Sathiesh Kumar and I. Gogul and M. Deepan Raj and S.K. Pragadesh and J. Sarathkumar Sebastin",
keywords = "Intelligent agriculture robotics",
keywords = "floriculture",
keywords = "horticulture",
keywords = "arboriculture",
keywords = "plant recognition methods",
keywords = "neural networks",
keywords = "Internet of things ",
abstract = "Abstract Modernization of our environment (pruning trees for constructing tall buildings) results in climatic changes and ecological imbalance. To mitigate the effect, gardening (to plant trees and shrubs) becomes more and more important than just a hobby. Besides, maintenance of a garden is a tedious process and also time-consuming. Often the gardener lacks in knowledge about the requirements of plant (nutrient and the amount of water to be sprayed) to enhance its growth. In this regard, it is necessary to build an autonomous gardening robotic vehicle which automatically identifies and classifies the plant species using feature extraction algorithms (Scale Invariant Feature Transform (SIFT), Speeded-Up Robust Features (SURF), Oriented \{FAST\} and Rotated \{BRIEF\} (ORB)) and neural networks, respectively. It also measures the key parameters for gardening such as temperature, humidity, heat level, wind speed, wind direction and soil moisture. The data acquired from the on-board sensors of the gardening rover are sent to the cloud storage platform on a regular basis. Based on the acquired data and history, future predictions are made to maintain the garden more effectively and efficiently. A website and an android application are developed for monitoring and controlling the rover from a remote area. This system is a combination of new technologies involving an interdisciplinary approach to carry out precision gardening using Internet of Things (IoT). "
}
@article{Fischinger201660,
title = "Hobbit, a care robot supporting independent living at home: First prototype and lessons learned ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "60 - 78",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014002140",
author = "David Fischinger and Peter Einramhof and Konstantinos Papoutsakis and Walter Wohlkinger and Peter Mayer and Paul Panek and Stefan Hofmann and Tobias Koertner and Astrid Weiss and Antonis Argyros and Markus Vincze",
keywords = "Social robotics",
keywords = "Robots for elderly",
keywords = "Care robot for independent living ",
abstract = "Abstract One option to address the challenge of demographic transition is to build robots that enable aging in place. Falling has been identified as the most relevant factor to cause a move to a care facility. The Hobbit project combines research from robotics, gerontology, and human–robot interaction to develop a care robot which is capable of fall prevention and detection as well as emergency detection and handling. Moreover, to enable daily interaction with the robot, other functions are added, such as bringing objects, offering reminders, and entertainment. The interaction with the user is based on a multimodal user interface including automatic speech recognition, text-to-speech, gesture recognition, and a graphical touch-based user interface. We performed controlled laboratory user studies with a total of 49 participants (aged 70 plus) in three \{EU\} countries (Austria, Greece, and Sweden). The collected user responses on perceived usability, acceptance, and affordability of the robot demonstrate a positive reception of the robot from its target user group. This article describes the principles and system components for navigation and manipulation in domestic environments, the interaction paradigm and its implementation in a multimodal user interface, the core robot tasks, as well as the results from the user studies, which are also reflected in terms of lessons we learned and we believe are useful to fellow researchers. "
}
@article{Men2014223,
title = "Hue-assisted automatic registration of color point clouds ",
journal = "Journal of Computational Design and Engineering ",
volume = "1",
number = "4",
pages = "223 - 232",
year = "2014",
note = "",
issn = "2288-4300",
doi = "https://doi.org/10.7315/JCDE.2014.022",
url = "http://www.sciencedirect.com/science/article/pii/S2288430014500334",
author = "Hao Men and Kishore Pochiraju",
keywords = "Computational geometry",
keywords = "Mesh processing",
keywords = "Reverse engineering",
keywords = "Building information modeling (BIM)",
keywords = "Computer graphics ",
abstract = "Abstract This paper describes a variant of the extended Gaussian image based registration algorithm for point clouds with surface color information. The method correlates the distributions of surface normals for rotational alignment and grid occupancy for translational alignment with hue filters applied during the construction of surface normal histograms and occupancy grids. In this method, the size of the point cloud is reduced with a hue-based down sampling that is independent of the point sample density or local geometry. Experimental results show that use of the hue filters increases the registration speed and improves the registration accuracy. Coarse rigid transformations determined in this step enable fine alignment with dense, unfiltered point clouds or using Iterative Common Point (ICP) alignment techniques. "
}
@article{Chui2008270,
title = "Direct 5-axis tool-path generation from point cloud input using 3D biarc fitting ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "24",
number = "2",
pages = "270 - 286",
year = "2008",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2006.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584507000038",
author = "K.L. Chui and W.K. Chiu and K.M. Yu",
keywords = "Machining",
keywords = "Reverse engineering",
keywords = "5-Axis tool-path",
keywords = "3D biarc",
keywords = "Point cloud",
keywords = "Triangular mesh ",
abstract = "In reverse engineering, geometrical information of a product is obtained directly from a physical shape by a digitizing device. To fabricate the product, manufacturing information (usually tool-path) must be generated from a \{CAD\} model. The data digitized must be processed and in most cases, a surface model is constructed from them using some of the surface fitting technologies. However, these technologies are usually complicated and the process for constructing a surface patch from a massive digitizing data is time-consuming. To simplify the process for getting tool-path information, a simple algorithm is proposed in this paper. The algorithm is used to generate a 5-axis machining tool-path. Instead of implementing any complicated surface fitting techniques, a direct method is proposed for constructing three-dimensional (3D) triangular mesh from the digitizing data with the mesh points considered as the tool contact locations. Depending on the locations of the points digitized, a decimation procedure is applied such that some of the digitizing data will be filtered out. Then, the tool axis orientations which must be determined in 5-axis tool-path are calculated and the tool center locations are determined accordingly. A 3D biarc fitting technique is applied for all the tool center locations so that a complete 5-axis tool-path is obtained. "
}
@incollection{King20081932,
title = "\{ROBOTIC\} \{ARCHAEOLOGY\} \{ON\} \{THE\} \{DEEP\} \{OCEAN\} \{FLOOR\} ",
editor = "Pearsall, Deborah M. ",
booktitle = "Encyclopedia of Archaeology ",
publisher = "Academic Press",
edition = "",
address = "New York",
year = "2008",
pages = "1932 - 1940",
isbn = "978-0-12-373962-9",
doi = "https://doi.org/10.1016/B978-012373962-9.00434-9",
url = "http://www.sciencedirect.com/science/article/pii/B9780123739629004349",
author = "Thomas F. King",
keywords = "Archaeology",
keywords = "Deep ocean",
keywords = "Ethics",
keywords = "Remotely operated vehicles",
keywords = "Remote sensing",
keywords = "Robotic Shipwreck",
keywords = "Salvage",
keywords = "Submersible",
keywords = "Technology ",
abstract = "Technology developed by the military, the telecommunications industry, and oil and gas interests has been adapted to allow the conduct of high-precision archaeological survey and excavation on the deep ocean floor, hundreds of meters below the surface. Side-scan sonar and other exploration tools can be used to map the distribution of anomalies on the sea bed, which then can be inspected using deep-diving robotic submersibles. Sites of interest, such as shipwrecks, can be excavated using remotely operated vehicles (ROVs) controlled by archaeologists in control ships on the surface. This technology is very expensive to be within the budgets of many museums and academic institutions; it is employed for archaeological purposes by a small number of commercial shipwreck exploration firms. Since these firms typically market some of the material they recover, most mainstream archaeologists have ethical difficulty cooperating with them, but some positive working relationships have been developed. If deep ocean archaeology is to continue, such relationships will probably have to become more common place. "
}
@article{Nabil201537,
title = "Soft material modeling for robotic task formulation and control in the muscle separation process ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "32",
number = "",
pages = "37 - 53",
year = "2015",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000787",
author = "Essahbi Nabil and Bouzgarrou Belhassen-Chedli and Gogu Grigore",
keywords = "Robotized anatomical cutting",
keywords = "Soft material dynamical modeling",
keywords = "Dynamic trajectory generation ",
abstract = "Abstract This paper introduces a global approach for the muscle separation process in the meat industry by using a multi-arm robotic system. Process control is based on both physical modeling of soft material and vision perception. Mechanical models appropriate for real-time applications are examined and compared through simulation results. In order to take into account material anisotropy, a new formulation based on mass-spring discretization, is proposed. While geometrical model construction uses \{MRI\} techniques, physical parameters are determined by the use of rheological tests. The cutting model for muscle separation is therefore considered through three approaches based on knife position, pull-off strength and experimental cutting forces. In order to generate robotic cutting tasks, a new algorithm using the curvature estimation of a 3D surface mesh is introduced. This enables the cutting-tool path generation and updating. "
}
@article{Zamuda201693,
title = "Constrained differential evolution optimization for underwater glider path planning in sub-mesoscale eddy sampling ",
journal = "Applied Soft Computing ",
volume = "42",
number = "",
pages = "93 - 118",
year = "2016",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2016.01.038",
url = "http://www.sciencedirect.com/science/article/pii/S1568494616300266",
author = "Ales Zamuda and Jose Daniel Hernandez Sosa and Leonhard Adler",
keywords = "Differential evolution",
keywords = "Constraint handling",
keywords = "Underwater robotics",
keywords = "Underwater glider path planning",
keywords = "Sub-mesoscale ocean eddy sampling ",
abstract = "Abstract This paper presents an approach for tackling constrained underwater glider path planning (UGPP), where the feasible path area is defined as a corridor around the border of an ocean eddy. The objective of the glider here is to sample the oceanographic variables more efficiently while keeping a bounded trajectory. Therefore, we propose a solution based on differential evolution (DE) algorithm mechanisms, including in its configuration self-adaptation of control parameters, population size reduction, ϵ-constraint handling with adjustment, and mutation based on elitistic best vector. Different aspects of this \{DE\} configuration are studied for the constrained \{UGPP\} challenge, on a prepared benchmark set comprised of 28 different specialized scenarios. The \{DE\} configurations were tested over a benchmark set over 51 independent runs for each \{DE\} configuration aspect. Comparison and suitability for the combination of these mechanisms is reported, through the per-scenario and aggregated statistical performance differences, including different constraint handling definition strategies, different \{DE\} mutation strategies’ configurations, and population sizing parameterizations. Our proposed solution outranked all other compared algorithms, keeping a trajectory within the limits with 100% success rate in all physically feasible scenarios; on average, it improved the randomly initialized trajectories fitness by roughly 50%, even reaching perfect fitness (all-around, 360-degree eddy corridor sampling) in some scenarios. "
}
@article{Lyapustin200712,
title = "Analysis of MODIS–MISR calibration differences using surface albedo around \{AERONET\} sites and cloud reflectance ",
journal = "Remote Sensing of Environment ",
volume = "107",
number = "1–2",
pages = "12 - 21",
year = "2007",
note = "Multi-angle Imaging SpectroRadiometer (MISR) Special IssueMISR Special Issue ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2006.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S0034425706004299",
author = "A. Lyapustin and Y. Wang and R. Kahn and J. Xiong and A. Ignatov and R. Wolfe and A. Wu and B. Holben and C. Bruegge",
keywords = "MODIS",
keywords = "MISR",
keywords = "Calibration",
keywords = "AERONET",
keywords = "Surface albedo",
keywords = "Cloud regression ",
abstract = "\{MODIS\} and \{MISR\} are two Earth Observing System instruments flown onboard the Terra satellite. Their synergistic use could greatly benefit the broad user community by ensuring a global view of the Earth with high-quality products. A necessary condition for data fusion is radiometric calibration agreement between the two instruments. Earlier studies showed about 3% absolute radiometric difference between \{MISR\} and respective \{MODIS\} land bands in the visible and near-IR spectrum, which are also used in aerosol and cloud research. This study compared two surface albedo products derived from \{MODIS\} and \{MISR\} \{L1B\} data using the AERONET-based Surface Reflectance Validation Network (ASRVN). The \{ASRVN\} shows a positive MISR–MODIS albedo bias of + (0.01–0.03). Cross-sensor calibration inconsistencies were identified as a primary cause of the albedo biases. To establish an independent MODIS–MISR calibration link, top-of-atmosphere \{MODIS\} and \{MISR\} reflectances were regressed against each other over liquid water clouds. The empirical regression results have been adjusted for the differences in the respective \{MISR\} and \{MODIS\} spectral responses using radiative transfer simulations. The MISR–MODIS band gain differences for the top-of-atmosphere reflectance estimated with this technique are + 6.0% in the Blue, + 3.3% in the Green, + 2.7% in the Red, and + 0.8% in the \{NIR\} band. Applying the derived values to rescale the \{MODIS\} or \{MISR\} \{L1B\} data is shown to significantly reduce the cross-sensor \{ASRVN\} surface albedo biases. An absolute calibration scale for both sensors could be established based on independent ground-based measurements of the surface albedo at selected \{AERONET\} sites. "
}
@article{vanderMeer2016288,
title = "Full 3-dimensional digital workflow for multicomponent dental appliances: A proof of concept ",
journal = "The Journal of the American Dental Association ",
volume = "147",
number = "4",
pages = "288 - 291",
year = "2016",
note = "",
issn = "0002-8177",
doi = "https://doi.org/10.1016/j.adaj.2015.11.018",
url = "http://www.sciencedirect.com/science/article/pii/S0002817715011423",
author = "W. Joerd van der Meer and Arjan Vissink and Yijin Ren",
keywords = "Orthodontic appliances",
keywords = "technology",
keywords = "robotics ",
abstract = "AbstractBackground The authors used a 3-dimensional (3D) printer and a bending robot to produce a multicomponent dental appliance to assess whether 3D digital models of the dentition are applicable for a full digital workflow. Methods The authors scanned a volunteer’s dentition with an intraoral scanner (Lava Chairside Oral Scanner C.O.S., 3M). A digital impression was used to design 2 multicomponent orthodontic appliances. Biocompatible acrylic baseplates were produced with the aid of a 3D printer. The metal springs and clasps were produced by a bending robot. The fit of the 2 appliances was assessed by 2 experienced orthodontists. Results The authors assessed both orthodontic appliances with the volunteer’s dentition and found the fit to be excellent. Conclusions Clinicians can fully produce a multicomponent dental appliance consisting of both an acrylic baseplate and other parts, such as clasps, springs, or screws, using a digital workflow process without the need for a physical model of the patient’s dentition. Practical Implications Plaster models can be superfluous for orthodontic treatment as digital models can be used in all phases of a full digital workflow in orthodontics. The arduous task of making a multicomponent dental appliance that involves bending wires can possibly be replaced by a computer, design software, a 3D printer, and a bending robot. "
}
@article{He2015354,
title = "An efficient registration algorithm based on spin image for LiDAR 3D point cloud models ",
journal = "Neurocomputing ",
volume = "151, Part 1",
number = "",
pages = "354 - 363",
year = "2015",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2014.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0925231214012120",
author = "Yuqing He and Yuangang Mei",
keywords = "3D model registration",
keywords = "Spin image",
keywords = "KD tree ",
abstract = "Abstract Spin image is a good point feature descriptor of the 3D surface and has been used in model registration for many applications from medical image processing to cooperation of multiple robots. However, researches show that current Spin-Image based Registration (SIR) algorithms present disadvantages in computational efficiency and robustness. Thus in this paper, aiming at 3D model acquired from LiDAR sensor, a new \{SIR\} algorithm is proposed to solve these problems. The new algorithm is on the basis of a new-constructed three-dimensional feature space, which, composed of the curvature, the Tsallis entropy of spin image, and the reflection intensity of laser sensor, is combined with the concept of KD-tree to firstly realize the primary key point matching, i.e., to find the Corresponding Point Candidate Set (CPCS). After that, spin-image based corresponding point searching is conducted with respect to each \{CPCS\} to precisely obtain the final corresponding points. The most absorbing advantages of the proposed method are as the following two aspects: on one hand, due to the introduction of the extra features, the fault corresponding relation introduced by spin image based method can be effectively reduced and thus the registration precision and robustness can be improved greatly; on the other hand, the \{CPCS\} obtained using low-dimensional feature space and KD-tree reduces extraordinarily the computational burden due to spin-image based correspondence searching. This greatly improves the computational efficiency of the proposed algorithm. Finally, in order to verify the feasibility and validity of the proposed algorithm, experiments are conducted and the results are analyzed. "
}
@article{Song201547,
title = "A comparison study of algorithms for surface normal determination based on point cloud data ",
journal = "Precision Engineering ",
volume = "39",
number = "",
pages = "47 - 55",
year = "2015",
note = "",
issn = "0141-6359",
doi = "https://doi.org/10.1016/j.precisioneng.2014.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S014163591400124X",
author = "Tao Song and Fengfeng(Jeff) Xi and Shuai Guo and Zhifa Ming and Yu Lin",
keywords = "Normal determination",
keywords = "Dynamic sampling method",
keywords = "Measuring error ",
abstract = "Abstract Robot applications in manufacturing of aircraft sheet metal parts require real-time methods for determining the surface normal using a digitized point data set measured by a 3D laser scanner. For this reason, six archived surface normal algorithms are compared. Though using different weights, these methods are all set to determine the surface normal at a given point by averaging the surface normals of the adjacent facets. In this paper, a comparison study is designed with a nearest neighboring method searching for adjacent facets, along with the introduction of a dynamic sampling method to investigate the effect of the resolution of a data set on the accuracy of surface normal determination. Three performance indices are proposed including the total number of final data points, the number of times of up-sampling and the total computing time. Three geometric models are considered including a sphere representing an aircraft cockpit, a cylinder representing a fuselage, and an ellipsoid representing a wing. The laser scanner error is modeled by a log-normal distribution. While all the six methods can generate satisfactory results in error-free case, the simulation results indicate that in error case \{MWE\} (mean weighted equally) and \{MWAAT\} (mean weighted by areas of adjacent triangles) are not favorable while the other four methods exhibit no obvious difference. "
}
@article{Tsai2006134,
title = "Recognition of quadratic surface of revolution using a robotic vision system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "22",
number = "2",
pages = "134 - 143",
year = "2006",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2005.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584505000268",
author = "Ming J. Tsai and Jia H. Hwung and Tien-Fu Lu and Hung-Yao Hsu",
keywords = "Reverse engineering",
keywords = "Robotic vision",
keywords = "Feature recognition",
keywords = "Quadratic surface",
keywords = "Curve fitting",
keywords = "Image process ",
abstract = "Reverse engineering using 3D scanners has been gaining increasing popularity. One challenging task that remains is to recognize the geometric feature from the cloud data scanned. In this study, a robotic vision system is used to recognize quadratic surfaces of revolution on an object. The top-view image of an object is used to detect the surface boundary by loop analysis technique. The boundary of a single surface is extracted according to the 2D loop of that surface. The robot then projects laser lines through the principal axes of the loop to get the sectional curves. The surface is recognized by a curve-fitting method based on the characteristics of these curves. This study provides a simple and faster method to detect the manufacture features on an object that contains quadratic surfaces. The data structure can be output in \{IGES\} format for re-design or rapid manufacture of the object. "
}
@article{Lienard2016264,
title = "Embedded, real-time \{UAV\} control for improved, image-based 3D scene reconstruction ",
journal = "Measurement ",
volume = "81",
number = "",
pages = "264 - 269",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2015.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0263224115006739",
author = "Jean Lienard and Andre Vogs and Demetrios Gatziolis and Nikolay Strigul",
keywords = "3D reconstruction",
keywords = "Aerial robotics",
keywords = "Computer vision",
keywords = "Robotics in agriculture and forestry",
keywords = "Real-time photogrammetry ",
abstract = "Abstract Unmanned Aerial Vehicles (UAVs) are already broadly employed for 3D modeling of large objects such as trees and monuments via photogrammetry. The usual workflow includes two distinct steps: image acquisition with \{UAV\} and computationally demanding post-flight image processing. Insufficient feature overlaps across images is a common shortcoming in post-flight image processing resulting in the failure of 3D reconstruction. Here we propose a real-time control system that overcomes this limitation by targeting specific spatial locations for image acquisition thereby providing sufficient feature overlap. We initially benchmark several implementations of the Scale-Invariant Feature Transform (SIFT) feature identification algorithm to determine whether they allow real-time execution on the low-cost processing hardware embedded on the UAV. We then experimentally test our \{UAV\} platform in virtual and real-life environments. The presented architecture consistently decreases failures and improves the overall quality of 3D reconstructions. "
}
@article{Hoffmann2014833,
title = "Adaptive robotic tool use under variable grasps ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "833 - 846",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000244",
author = "Heiko Hoffmann and Zhichao Chen and Darren Earl and Derek Mitchell and Behnam Salemi and Jivko Sinapov",
keywords = "Grasping",
keywords = "Manipulation",
keywords = "Computer vision",
keywords = "Tactile sense",
keywords = "Kinematics",
keywords = "Adaptive systems ",
abstract = "Abstract Successful robotic manipulation of human tools will greatly advance robotic collaboration with humans in manufacturing and robotic assistance in human environments, e.g., in hospitals, offices, and homes. In these settings, the robot needs to grasp a tool (e.g., a drill) before using it, rather than rely on the tool being firmly attached to the robot’s end effector. Thus, when using the tool, the robot has to account for the uncertainty in the hand-tool interface, since the grasp will vary between trials. To address this challenge, we propose a new framework in which control-relevant parameters are extracted about the uncertain interface between palm and tool tip. Our approach allows a robot to control position and force at the tool tip using either visual or tactile feedback. In addition, the proposed framework allows a robot to move the tip of a tool along a surface, despite uncertainty about how the tool is held in the hand and uncertainty about the structure of the surface. We demonstrated the feasibility of our new approach on two robotic platforms: the \{DARPA\} \{ARM\} robot operating a hand-held drill and an \{ST\} Robotics \{R17\} robot drawing with a pencil. "
}
@article{RuizSarmiento20158805,
title = "Scene object recognition for mobile robots through Semantic Knowledge and Probabilistic Graphical Models ",
journal = "Expert Systems with Applications ",
volume = "42",
number = "22",
pages = "8805 - 8816",
year = "2015",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.07.033",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415004935",
author = "Jose-Raul Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Object recognition",
keywords = "Semantic Knowledge",
keywords = "Probabilistic Graphical Models",
keywords = "Mobile robotics",
keywords = "Expert systems",
keywords = "Autonomous agents ",
abstract = "Abstract Scene object recognition is an essential requirement for intelligent mobile robots. In addition to geometric or appearance features, modern recognition systems strive to incorporate contextual information, normally modelled through Probabilistic Graphical Models (PGMs) or Semantic Knowledge (SK). However, these approaches, separately, show some weaknesses that limit their application, e.g., the exponential complexity of the probabilistic inference over \{PGMs\} or the inability of \{SK\} to handle uncertainty. This paper presents a hybrid PGM-SK system for object recognition that integrates both techniques reducing their individual limitations and gaining in probabilistic inference efficiency, performance robustness, uncertainty handling, and providing coherent results according to domain knowledge codified by a human expert. We support this claim with an extensive experimental evaluation according to both recognition success and time requirements in real scenarios from two datasets (NYU2 and UMA-offices). The yielded figures support the suitability of the hybrid PGM-SK recognition system, and its applicability to mobile robotic agents. "
}
@article{Elor201490,
title = "“Robot Cloud” gradient climbing with point measurements ",
journal = "Theoretical Computer Science ",
volume = "547",
number = "",
pages = "90 - 103",
year = "2014",
note = "",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2014.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S0304397514004617",
author = "Yotam Elor and Alfred M. Bruckstein",
keywords = "Source-seeking",
keywords = "Point measurement",
keywords = "Gradient",
keywords = "Fume tracking ",
abstract = "Abstract A scalar-field gradient climbing process for a large group of simple, low-capability mobile robotic agents using only point measurements is proposed and analyzed. The agents are assumed to be memoryless and to lack direct communication abilities. Their only implicit form of communication is by sensing the position of the members of the group. The proposed gradient following algorithm is based on a basic gathering algorithm. The gathering algorithm is augmented by controlling the agents' speed as follows: agents that sense a higher value of the field move slower toward the group center than those sensing lower values, thereby causing the swarm to drift in the direction of the underlying field gradient. Furthermore, a random motion component is added to each agent in order to prevent gathering and allow sampling of the scalar field. We prove that in the proposed algorithm, the group is cohesive and indeed follows the gradient of the scalar field. We also discuss an algorithm based on a more restrictive sensing capabilities for the agents. "
}
@article{Capellan2016175,
title = "Handling of Frequent Design Changes in an Automated Assembly Cell for Electronic Products ",
journal = "Procedia \{CIRP\} ",
volume = "54",
number = "",
pages = "175 - 180",
year = "2016",
note = "6th \{CIRP\} Conference on Learning Factories ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.05.066",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116305236",
author = "Alvaro Capellan and Olivier Roulet-Dubonnet",
keywords = "Automation",
keywords = "Flexible assembly",
keywords = "Machine vision",
keywords = "Robotics",
keywords = "Electronic products ",
abstract = "Abstract This paper presents a prototype flexible assembly cell used for the assembly of electronic products. The cell is the first prototype version of the coming assembly system for fire sensors at Autronica. It is developed specifically for testing different concepts to reduce development time for design changes and introduction of new variants. The cell consists of a robot, grippers, sensors, vision systems and fixturing systems which have been selected for in-line adaptivity and reconfiguration. The topics of developing generic vision programs and reducing programming time for vision and robot have been central. The aspects needed to be addressed during development are presented together with considered and chosen solutions. These solutions are also discussed and compared to other systems presented in recent publications on flexible assembly. "
}
@article{Wrede2016259,
title = "Vertical Integration and Service Orchestration for Modular Production Systems Using Business Process Models ",
journal = "Procedia Technology ",
volume = "26",
number = "",
pages = "259 - 266",
year = "2016",
note = "3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2016.08.035",
url = "http://www.sciencedirect.com/science/article/pii/S2212017316303826",
author = "Sebastian Wrede and Oliver Beyer and Christoph Dreyer and Michael Wojtynek and Jochen Steil",
keywords = "Modular Production System",
keywords = "Business Process Model and Notation",
keywords = "Service-Oriented Architecture",
keywords = "Robotics ",
abstract = "Abstract Individualized production challenges established manufacturing approaches in terms of modularization, flexibility and efficient reconfiguration. Modular production systems with high flexibility, capable of interacting with products and humans, and vertically integrated with the business environment provide new possibilities for overcoming these challenges. Such flexible manufacturing approaches require seamless integration between all involved parties from the enterprise resource planning level down to the shop floor. Service-oriented architectures with standards geared towards automation claim to provide easier development and integration of modular production systems. However, in order to support the desired flexibility and integrability, a coherent modeling approach for manufacturing processes is required, in particular focusing on the orchestration between production tasks, resources, humans and services. To address these challenges, we introduce in this contribution a system-level approach for flexible manufacturing comprised of reconfigurable modular production cells, which can be easily composed into production lines. Reconfigurability is achieved through exchangeable process components, the use of lightweight robot manipulators as versatile handling subsystems as well as a cell control scheme based on executable business process models to allow runtime service orchestration. The systemic approach can be applied to realize a customer specific production down to lot size one and was validated in a vertically integrated production line manufacturing an industrial product with high variability. The resulting system has been exhibited at different trade fairs and demonstrates our interpretation of the SmartFactory paradigm for individualized production. "
}
@article{Bausch2016583,
title = "3D Printing onto Unknown Uneven Surfaces* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "21",
pages = "583 - 590",
year = "2016",
note = "7th \{IFAC\} Symposium on Mechatronic Systems \{MECHATRONICS\} 2016Loughborough University, Leicestershire, UK, 5—8 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.664",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316322765",
author = "Nils Bausch and David P. Dawkins and Regina Frei and Susanne Klein",
keywords = "3D printing",
keywords = "3D scanning",
keywords = "conformal printing",
keywords = "sensors",
keywords = "robotics",
keywords = "control",
keywords = "mechatronic system ",
abstract = "Abstract: Since its inception, 3D printing has seen a wide area of applications, but a general approach to printing onto unknown objects has not been tackled yet. Nowadays 3D scanning technology can be used for reverse engineering. Multiple axis machines enable the creation of object layers at diferent deposition angles, and printing on uneven surfaces is achieved by conformal printing. In this paper, a new methodology is presented, which combines 3D scanning, multiple axis 3D printing, and conformal printing to create an afordable 3D printing system, which can deposit material onto a priori unknown uneven objects. A prototype system was developed, which can print a frst layer on top of a previously unknown object. The creation of further layers is work in progress. The application areas for such a method could include repairing structures, product customization, printing security features on existing objects, adding functionality by, for example, printing antennas on items, and modifying prosthetics to fit individual patients. "
}
@article{Viejo2014174,
title = "Combining visual features and Growing Neural Gas networks for robotic 3D \{SLAM\} ",
journal = "Information Sciences ",
volume = "276",
number = "",
pages = "174 - 185",
year = "2014",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.02.053",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514001595",
author = "Diego Viejo and Jose Garcia-Rodriguez and Miguel Cazorla",
keywords = "GNG",
keywords = "SLAM",
keywords = "3D registration ",
abstract = "Abstract The use of 3D data in mobile robotics provides valuable information about the robot’s environment. Traditionally, stereo cameras have been used as a low-cost 3D sensor. However, the lack of precision and texture for some surfaces suggests that the use of other 3D sensors could be more suitable. In this work, we examine the use of two sensors: an infrared \{SR4000\} and a Kinect camera. We use a combination of 3D data obtained by these cameras, along with features obtained from 2D images acquired from these cameras, using a Growing Neural Gas (GNG) network applied to the 3D data. The goal is to obtain a robust egomotion technique. The \{GNG\} network is used to reduce the camera error. To calculate the egomotion, we test two methods for 3D registration. One is based on an iterative closest points algorithm, and the other employs random sample consensus. Finally, a simultaneous localization and mapping method is applied to the complete sequence to reduce the global error. The error from each sensor and the mapping results from the proposed method are examined. "
}
@article{HosseininavehA20141197,
title = "Towards fully automatic reliable 3D acquisition: From designing imaging network to a complete and accurate point cloud ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1197 - 1207",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000670",
author = "Ali Hosseininaveh A. and Ben Sargeant and Tohid Erfani and Stuart Robson and Mark Shortis and Mona Hess and Jan Boehm",
keywords = "Stereo imaging network",
keywords = "Kinect fusion",
keywords = "Multi-view stereo",
keywords = "Automatic 3D acquisition",
keywords = "Inverse kinematics",
keywords = "Particle Swarm Optimization ",
abstract = "Abstract This paper describes a novel system for accurate 3D digitization of complex objects. Its main novelties can be seen in the new approach, which brings together different systems and tools in a unique platform capable of automatically generating an accurate and complete model for an object of interest. This is performed through generating an approximate model of the object, designing a stereo imaging network for the object with this model and capturing the images at the designed postures through exploiting an inverse kinematics method for a non-standard six degree of freedom robot. The images are then used for accurate and dense 3D reconstruction using photogrammetric multi-view stereo method in two modes, including resolving scale with baseline and with control points. The results confirm the feasibility of using Particle Swarm Optimization in solving inverse kinematics for this non-standard robot. The system provides this opportunity to test the effect of incidence angle on imaging network design and shows that the matching algorithms work effectively for incidence angle of 10°. The accuracy of the final point cloud generated with the system was tested in two modes through a comparison with a dataset generated with a close range 3D colour laser scanner. "
}
@article{Stefas201610,
title = "Vision-Based \{UAV\} Navigation in Orchards* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "10 - 15",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315646",
author = "Nikolaos Stefas and Haluk Bayram and Volkan Isler",
keywords = "Vision-based navigation",
keywords = "Unmanned Aerial Vehicles",
keywords = "Agricultural Robotics ",
abstract = "Abstract: Unmanned Aerial Vehicles (UAV) are becoming increasingly common in agricultural applications. Currently, they are primarily used to fly over fields in open space. Navigation inside orchard-like environments remains challenging. We study the problem of orchard navigation with cameras on an aerial vehicle. We study both the controller and the vision component. For the vision component, we provide two methods for detecting orchard rows with frontal facing cameras. In the monocular case, we present a pipeline to extract the geometry of tree rows when there is a well defined path structure. In the binocular case, we present a depth-based navigation algorithm to extract the rows. For the controller component, we design a controller that uses both frontal and downward facing cameras and provides reliable performance even on the presence of strong wind disturbances. "
}
@article{Carlson2016389,
title = "Robot Station Optimization for Minimizing Dress Pack Problems ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "389 - 394",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.01.022",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116000342",
author = "Johan S. Carlson and Jonas Kressin and Tomas Hermansson and Robert Bohlin and Mathias Sundback and Henri Hansson",
keywords = "automation",
keywords = "simulation",
keywords = "motion planning",
keywords = "optimization",
keywords = "robotics and dress packs ",
abstract = "Abstract Problems with robot dress packs are one of the major reasons for online adjustments of robot motions and for down time in robot stations. A factory study showed that many robots wear out more than one dress pack per year. The life length variation was in fact shown considerable, ranging from years to only months. The dress packs consist of attached cables and hoses which typically have significant impact on allowed robot configurations and motions in the station. In this paper, we present novel simulation methods for improving robot configurations and motions during off-line programming and optimization of robot stations. The proposed method is applied to a stud welding station resulting in the elimination of several problems related to the dress packs. "
}
@article{Hassaan201616,
title = "Precision Forestry: Trees Counting in Urban Areas Using Visible Imagery based on an Unmanned Aerial Vehicle ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "16 - 21",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315658",
author = "Omair Hassaan and Ahmad Kamal Nasir and Hubert Roth and M. Fakhir Khan",
keywords = "Precision Forestry",
keywords = "Robotics",
keywords = "Vision",
keywords = "UAV ",
abstract = "Abstract: This research work describes an approach to count trees in an urban environment. Furthermore it addresses the problems involved in detection of trees in aerial imagery. This work can be used to solve the problem of forest degradation and deforestation. Right now forest man labor isn’t efficient enough to detect or prevent this problem. A multi-rotor \{UAV\} equipped with high resolution \{RGB\} camera was used to acquire aerial images and to count number of trees in surveyed area. Various issues involved in the robust implementation of proposed algorithm are discussed. The result of successful implementation of the proposed algorithm on multiple scenarios are also presented and we show that our naive approach is able to achieve ≈ 0.72 accuracy within reasonable amount of time. "
}
@incollection{Luxton20161,
title = "Chapter 1 - An Introduction to Artificial Intelligence in Behavioral and Mental Health Care ",
editor = "Luxton, David D. ",
booktitle = "Artificial Intelligence in Behavioral and Mental Health Care ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2016",
pages = "1 - 26",
isbn = "978-0-12-420248-1",
doi = "https://doi.org/10.1016/B978-0-12-420248-1.00001-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780124202481000015",
author = "David D. Luxton",
keywords = "Artificial intelligence",
keywords = "behavioral health",
keywords = "mental health",
keywords = "health care",
keywords = "expert systems",
keywords = "virtual reality",
keywords = "robotics",
keywords = "virtual intelligent agents ",
abstract = "Artificial intelligence (AI) technologies and techniques have useful purposes in just about every domain of behavioral and mental health care including clinical decision-making, treatments, assessment, self-care, healthcare management, research and more. This introductory chapter provides an overview of \{AI\} and includes definitions of common terms and concepts to provide a foundation for what is discussed in subsequent chapters. Recent technological innovations are highlighted to demonstrate emerging capabilities and forthcoming opportunities. The benefits of the use of \{AI\} in mental health care are also discussed. "
}
@incollection{Salgues2016161,
title = "12 - The Technologies that Could Change Everything ",
editor = "Salgues, Bruno ",
booktitle = "Health Industrialization ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "161 - 184",
isbn = "978-1-78548-147-5",
doi = "https://doi.org/10.1016/B978-1-78548-147-5.50012-6",
url = "http://www.sciencedirect.com/science/article/pii/B9781785481475500126",
author = "Bruno Salgues",
keywords = "Artificial zeolites",
keywords = "Biometry",
keywords = "Biotechnology",
keywords = "3D printing",
keywords = "Graphene",
keywords = "Information technology",
keywords = "Nanoproducts",
keywords = "Nanosystems",
keywords = "Patient’s data",
keywords = "Robotics ",
abstract = "Abstract: The technologies with the potential to “change everything” have to do with substitution or switching approaches. "
}
@article{Haidegger20131215,
title = "Applied ontologies and standards for service robots ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1215 - 1223",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S092188901300105X",
author = "Tamas Haidegger and Marcos Barreto and Paulo Goncalves and Maki K. Habib and Sampath Kumar Veera Ragavan and Howard Li and Alberto Vaccarella and Roberta Perrone and Edson Prestes",
keywords = "Service robotics",
keywords = "Robot ontologies",
keywords = "Robot standards",
keywords = "Human–robot interaction ",
abstract = "Abstract Service robotics is an emerging application area for human-centered technologies. The rise of household and personal assistance robots forecasts a human–robot collaborative society. One of the robotics community’s major task is to streamline development trends, work on the harmonization of taxonomies and ontologies, along with the standardization of terms, interfaces and technologies. It is important to keep the scientific progress and public understanding synchronous, through efficient outreach and education. These efforts support the collaboration among research groups, and lead to widely accepted standards, beneficial for both manufacturers and users. This article describes the necessity of developing robotics ontologies and standards focusing on the past and current research efforts. In addition, the paper proposes a roadmap for service robotics ontology development. The \{IEEE\} Robotics &amp; Automation Society is sponsoring the working group Ontologies for Robotics and Automation. The efforts of the Working group are presented here, aiming to connect the cutting edge technology with the users of these services—the general public. "
}
@incollection{Kala201611,
title = "2 - Basics of Autonomous Vehicles ",
editor = "Kala, Rahul ",
booktitle = "On-Road Intelligent Vehicles ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2016",
pages = "11 - 35",
isbn = "978-0-12-803729-4",
doi = "https://doi.org/10.1016/B978-0-12-803729-4.00002-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128037294000027",
author = "Rahul Kala",
keywords = "Autonomous vehicles",
keywords = "Control",
keywords = "Intelligent vehicles",
keywords = "Localization",
keywords = "Mobile robotics",
keywords = "Motion planning",
keywords = "Sensing",
keywords = "Vision ",
abstract = "Abstract The technology behind autonomous vehicles is interesting and challenging. The chapter, in a nutshell, discusses the complete technology and shows how autonomous vehicles get the capability to navigate autonomously in traffic scenarios. The hardware of autonomous vehicles, from a computational perspective, consists of sensors including vision cameras, RADARs, ultrasonics and LIDARs, along with an Inertial Measurement Unit and motion encoders to enable the vehicles estimate the position. The vehicles are driven with the help of steering, brake and throttle using the drive-by-wire technology which facilitates driving using computer programmes. The vision systems are responsible for looking at the operational scenario and making inferences, which are used to make the map of the world by a mapping module. The localization module uses the vision and map information to estimate the vehicle's pose. Motion-planning algorithms do all the decision-making including computing trajectories for operation, which are followed by using control algorithms. "
}
@article{Overmeyer2016425,
title = "Multimodal speech and gesture control of AGVs, including EEG-based measurements of cognitive workload ",
journal = "\{CIRP\} Annals - Manufacturing Technology ",
volume = "65",
number = "1",
pages = "425 - 428",
year = "2016",
note = "",
issn = "0007-8506",
doi = "https://doi.org/10.1016/j.cirp.2016.04.030",
url = "http://www.sciencedirect.com/science/article/pii/S0007850616300300",
author = "Ludger Overmeyer and Florian Podszus and Lars Dohrmann",
keywords = "Logistics",
keywords = "Cognitive robotics",
keywords = "Electroencephalography ",
abstract = "Abstract Automated guided vehicles (AGVs) with autonomous behavior and decentralized human–machine interaction (HMI) are suitable for use in logistics. To facilitate natural interaction, \{HMI\} may involve both speech and gesture control. This paper presents a new cognitive approach based on electroencephalography (EEG) for multimodal \{HMI\} combining speech and gesture control for \{AGVs\} used in logistics. The results indicate that implicit EEG-based measures such as alertness and relaxation significantly affect speech control performance. Consequently, monitoring the user's cognitive workload during logistic operations may lead to a substantial improvement in work performance. "
}
@article{Ohde2013269,
title = "Spectral effects of Saharan dust on photosynthetically available radiation in comparison to the influence of clouds ",
journal = "Journal of Atmospheric and Solar-Terrestrial Physics ",
volume = "102",
number = "",
pages = "269 - 280",
year = "2013",
note = "",
issn = "1364-6826",
doi = "https://doi.org/10.1016/j.jastp.2013.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S1364682613001806",
author = "T. Ohde and H. Siegel",
keywords = "Spectral effect",
keywords = "Saharan dust",
keywords = "Solar irradiance",
keywords = "Photosynthetically available radiation",
keywords = "Northwest Africa ",
abstract = "Abstract Measurements of downward irradiance at sea level in the area off Northwest Africa in February 2008 were analyzed to determine the spectral effects of atmospheric dust and clouds on solar irradiance and photosynthetically available radiation. For the first time not only the pure spectral effects of dust and clouds were considered but also the spectral modifications by sky conditions with dust and clouds together in the atmosphere. The influence of dust on spectral distribution of downward irradiance is smaller than that of clouds reducing the incoming radiation. The spectral effect of pure dust causes deviations of up to 6% at 400 nm compared to the clear sky case. In contrast, the deviations in the case of clouds are up to 31%. Furthermore, atmospheric dust modifies the spectral effect of clouds. In the case of clouds reducing the incoming radiation, the spectral effect depends mainly on the ratio between clouds and dust in the atmosphere. The spectral dependence changes if the optical properties of clouds or dust predominate. Dust increases the spectral effect of clouds mainly in the blue spectral range in the case of clouds enhancing the incoming radiation. An important result was the parameterization of the spectral effects of different atmospheric conditions by power functions. The functions depend on the wavelength and the introduced normalization factors describing the effect of clouds and atmospheric dust on the magnitude of downward irradiance. The parameterization was used to investigate the influence of the spectral effects on photosynthetically available radiation. Their correct knowledge is important for many applications such as biology experiments and ecological modeling. The influence of spectral effects compared to clear sky case is in the order of few percents for all considered atmospheric cases. The spectral effects of different types of clouds reduce or enhance the photosynthetically available radiation up to 6.1% or 1.9%, respectively. Atmospheric dust modifies the influence of spectral effects of clouds on photosynthetically available radiation in dependence on the ratio of clouds to dust. "
}
@article{Amrhein201468,
title = "Characterization of aqueous two phase systems by combining lab-on-a-chip technology with robotic liquid handling stations ",
journal = "Journal of Chromatography A ",
volume = "1367",
number = "",
pages = "68 - 77",
year = "2014",
note = "",
issn = "0021-9673",
doi = "https://doi.org/10.1016/j.chroma.2014.09.042",
url = "http://www.sciencedirect.com/science/article/pii/S0021967314014575",
author = "Sven Amrhein and Marie-Luise Schwab and Marc Hoffmann and Jurgen Hubbuch",
keywords = "Aqueous two phase system",
keywords = "Tie line",
keywords = "Density",
keywords = "High throughput",
keywords = "Phase separation",
keywords = "Lab-on-a-chip",
keywords = "Microfluidics ",
abstract = "Abstract Over the last decade, the use of design of experiment approaches in combination with fully automated high throughput (HTP) compatible screenings supported by robotic liquid handling stations (LHS), adequate fast analytics and data processing has been developed in the biopharmaceutical industry into a strategy of high throughput process development (HTPD) resulting in lower experimental effort, sample reduction and an overall higher degree of process optimization. Apart from \{HTP\} technologies, lab-on-a-chip technology has experienced an enormous growth in the last years and allows further reduction of sample consumption. A combination of \{LHS\} and lab-on-a-chip technology is highly desirable and realized in the present work to characterize aqueous two phase systems with respect to tie lines. In particular, a new high throughput compatible approach for the characterization of aqueous two phase systems regarding tie lines by exploiting differences in phase densities is presented. Densities were measured by a standalone micro fluidic liquid density sensor, which was integrated into a liquid handling station by means of a developed generic Tip2World interface. This combination of liquid handling stations and lab-on-a-chip technology enables fast, fully automated, and highly accurate density measurements. The presented approach was used to determine the phase diagram of \{ATPSs\} composed of potassium phosphate (pH 7) and polyethylene glycol (PEG) with a molecular weight of 300, 400, 600 and 1000 Da respectively in the presence and in the absence of 3% (w/w) sodium chloride. Considering the whole \{ATPS\} characterization process, two complete \{ATPSs\} could be characterized within 24 h, including four runs per \{ATPS\} for binodal curve determination (less than 45 min/run), and tie line determination (less than 45 min/run for \{ATPS\} preparation and 8 h for density determination), which can be performed fully automated over night without requiring man power. The presented methodology provides a cost, time and material effective approach for characterization of \{ATPS\} phase diagram on base on highly accurate and comprehensive data. By this means the derived data opens the door for a more detailed description of \{ATPS\} towards generating mechanistic based models, since molecular approaches such as \{MD\} simulations or molecular descriptions along the line of \{QSAR\} heavily rely on accurate and comprehensive data. "
}
@article{Sanz20158,
title = "A benchmarking perspective of underwater intervention systems★ ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "8 - 13",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002414",
author = "P.J. Sanz and J. Perez and J. Sales and A. Penalver and J.J. Fernandez and D. Fornas and R. Marin and J.C. Garcia",
keywords = "Underwater simulator",
keywords = "Benchmarking",
keywords = "Underwater intervention",
keywords = "Robotics ",
abstract = "Abstract This paper presents recent progress concerning benchmarking issues in the underwater robotics manipulation context. After a very intensive 6-years period of work, under several funding research projects, all of them in the aforementioned area, a strong know-how has been developed. As part of this expertise, a new underwater simulation tool has been implemented. This platform enables the integration, simulation, comparative analysis and experimentation on real data and a detailed characterization of the results, using as input a simple web-based user interface. In fact, our previous experience in related research projects has evidenced the necessity of testing, comparing and evaluating different algorithms in similar conditions. So, the similarity between the virtual scenario, where the benchmarking will be performed, and the real one, will determine the quality of the results. In that sense, a methodology is presented which updates the scenario with real information each time a real trial is performed. Benchmarking, a very active robotic area in nowadays, is the underlying problem to solve. In summary, the main functionalities for benchmarking available in the simulation platform will be highlighted, by using some case studies concerning object tracking under visibility changes, object tracking under variable water current and 3D reconstruction subject to different optical conditions. "
}
@article{Borrmann2015105,
title = "Evaluation of Methods for Robotic Mapping of Cultural Heritage Sites ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "10",
pages = "105 - 110",
year = "2015",
note = "2nd \{IFAC\} Conference on Embedded Systems, Computer Intelligence and Telematics \{CESCIT\} 2015Maribor, Slovenia, 22-24 June 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.08.116",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315009830",
author = "Dorit Borrmann and Robin Hess and Daniel Eck and Hamidreza Houshiar and Andreas Nuchter and Klaus Schilling",
keywords = "laser scanning",
keywords = "3D modeling",
keywords = "multi-sensors ",
abstract = "Abstract In archaeological studies the use of new technologies has moved into focus in the past years creating new challenges such as the processing of the massive amounts of data. In this paper we present steps and processes for smart 3D modelling of environments by use of the mobile robot Irma3D. A robot that is equipped with multiple sensors, most importantly a photo camera and a laser scanner, enables the automation of most of the processes, including data acquisition and registration. The robot was tested in the Wurzburg Residence. Methods for automatic 3D color reconstructions of cultural heritage sites are evaluated in this paper. "
}
@article{Wilson20141901,
title = "The Prevalence of Nodal Upstaging During Robotic Lung Resection in Early Stage Non-Small Cell Lung Cancer ",
journal = "The Annals of Thoracic Surgery ",
volume = "97",
number = "6",
pages = "1901 - 1907",
year = "2014",
note = "",
issn = "0003-4975",
doi = "https://doi.org/10.1016/j.athoracsur.2014.01.064",
url = "http://www.sciencedirect.com/science/article/pii/S0003497514003865",
author = "Jennifer L. Wilson and Brian E. Louie and Robert J. Cerfolio and Bernard J. Park and Eric Vallières and Ralph W. Aye and Ahmed Abdel-Razek and Ayesha Bryant and Alexander S. Farivar",
abstract = "Background Pathologic nodal upstaging can be considered a surrogate for completeness of nodal evaluation and quality of surgery. We sought to determine the rate of nodal upstaging and disease-free and overall survival with a robotic approach in clinical stage I NSCLC. Methods We retrospectively reviewed patients with clinical stage I \{NSCLC\} after robotic lobectomy or segmentectomy at three centers from 2009 to 2012. Data were collected primarily based on Society of Thoracic Surgeons database elements. Results Robotic anatomic lung resection was performed in 302 patients. The majority were right sided (192; 63.6%) and of the upper lobe (192; 63.6%). Most were clinical stage \{IA\} (237; 78.5%). Pathologic nodal upstaging occurred in 33 patients (10.9% [pN1 20, 6.6%; pN2 13, 4.3%]). Hilar (pN1) upstaging occurred in 3.5%, 8.6%, and 10.8%, respectively, for cT1a, cT1b, and cT2a tumors. Comparatively, historic hilar upstage rates of video-assisted thoracoscopic surgery (VATS) versus thoracotomy for cT1a, cT1b, and cT2a were 5.2%, 7.1%, and 5.7%, versus 7.4%, 8.8%, and 11.5%, respectively. Median follow-up was 12.3 months (range, 0 to 49). Forty patients (13.2%) had disease recurrence (local 11, 3.6%; regional 7, 2.3%; distant 22, 7.3%). The 2-year overall survival was 87.6%, and the disease-free survival was 70.2%. Conclusions The rate of nodal upstaging for robotic resection appears to be superior to \{VATS\} and similar to thoracotomy data when analyzed by clinical T stage. Both disease-free and overall survival were comparable to recent \{VATS\} and thoracotomy data. A larger series of matched open, \{VATS\} and robotic approaches is necessary. "
}
@article{Rocha2014605,
title = "Object recognition and pose estimation for industrial applications: A cascade system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "30",
number = "6",
pages = "605 - 621",
year = "2014",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000313",
author = "Luis F. Rocha and Marcos Ferreira and V. Santos and A. Paulo Moreira",
keywords = "Pattern recognition",
keywords = "Flexible manufacturing",
keywords = "Autonomous systems",
keywords = "Robotics",
keywords = "Spray coating ",
abstract = "Abstract The research work presented in this paper focuses on the development of a 3D object localization and recognition system to be used in robotics conveyor coating lines. These requirements were specified together with enterprises with small production series seeking a full robotic automation of their production line that is characterized by a wide range of products in simultaneous manufacturing. Their production process (for example heat or coating/painting treatments) limits the use of conventional identification systems attached to the object in hand. Furthermore, the mechanical structure of the conveyor introduces geometric inaccuracy in the object positioning. With the correct classification and localization of the object, the robot will be able to autonomously select the right program to execute and to perform coordinate system corrections. A cascade system performed with Support Vector Machine and the Perfect Match (point cloud geometric template matching) algorithms was developed for this purpose achieving 99.5% of accuracy. The entire recognition and pose estimation procedure is performed in a maximum time range of 3 s with standard off the shelf hardware. It is expected that this work contributes to the integration of industrial robots in highly dynamic and specialized production lines. "
}
@article{Li2015229,
title = "Cognitive assisted living ambient system: a survey ",
journal = "Digital Communications and Networks ",
volume = "1",
number = "4",
pages = "229 - 252",
year = "2015",
note = "",
issn = "2352-8648",
doi = "https://doi.org/10.1016/j.dcan.2015.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S2352864815000589",
author = "Ruijiao Li and Bowen Lu and Klaus D. McDonald-Maier",
keywords = "Assitive living",
keywords = "Digital communication",
keywords = "Smart home",
keywords = "Robotics",
keywords = "Sensor network ",
abstract = "Abstract The demographic change towards an aging population is creating a significant impact and introducing drastic challenges to our society. We therefore need to find ways to assist older people to stay independently and prevent social isolation of these population. Information and Communication Technologies (ICT) provide various solutions to help older adults to improve their quality of life, stay healthier, and live independently for a time. Ambient Assisted Living (AAL) is a field to investigate innovative technologies to provide assistance as well as healthcare and rehabilitation to impaired seniors. The paper provides a review of research background and technologies of AAL. "
}
@article{delaPuente201580,
title = "Feature based graph \{SLAM\} with high level representation using rectangles ",
journal = "Robotics and Autonomous Systems ",
volume = "63, Part 1",
number = "",
pages = "80 - 88",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S092188901400181X",
author = "Paloma de la Puente and Diego Rodriguez-Losada",
keywords = "Mobile robotics",
keywords = "Feature based SLAM",
keywords = "Environment modeling ",
abstract = "Abstract In mobile robotics, feature based maps are very popular for the representation of the environment. Some of the main advantages of these maps are final compactness and expressivity, aspects that make storage easier and simplify higher level reasoning. Most existing approaches, however, stick to low level features such as points, segments and sometimes circles, corners or splines. This paper presents the incorporation of rectangles as higher level features in a feature based graph Simultaneous Localization and Mapping (SLAM) framework for the consideration of the structure of the environment in the mapping process. "
}
@article{Harada20141463,
title = "Validating an object placement planner for robotic pick-and-place tasks ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "10",
pages = "1463 - 1477",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.05.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001092",
author = "Kensuke Harada and Tokuo Tsuji and Kazuyuki Nagata and Natsuki Yamanobe and Hiromu Onda",
keywords = "Grasp",
keywords = "Manipulation",
keywords = "Pick and place",
keywords = "Object place ",
abstract = "Abstract This paper proposes an object placement planner for a grasped object during pick-and-place tasks. The proposed planner automatically determines the pose of an object that is stably placed near a user-assigned point on the environment surface. In our proposed method, first the polygon models of both the object and the environment are clustered, with each cluster being approximated by a planar region. The position/orientation of an object placed on the environment surface can be determined by selecting a pair of clusters: one from the object and the other from the environment. We furthermore conduct several tests to determine the position/orientation of the object, namely the Convexity Test, the Contact Test and the Stability Test. We demonstrate that, by using the polygon model of the environment that is obtained by means of conversion of the point cloud, we can determine the position/orientation of an object and can thereby realize a pick-and-place task. "
}
@article{Matsuda2014416,
title = "Configuration of a Production Control System through Cooperation of Software Units Using their Capability Profiles in the Cloud Environment ",
journal = "Procedia \{CIRP\} ",
volume = "17",
number = "",
pages = "416 - 421",
year = "2014",
note = "Variety Management in ManufacturingProceedings of the 47th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.01.044",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114002790",
author = "Michiko Matsuda and Kiminobu Kodama and Satoshi Noguchi and Sakuyuki Onishi and Toshikatsu Asano and Takuya Horikita and Kousuke Komatsubara",
keywords = "manufacturing application system",
keywords = "dynamic configuration",
keywords = "capability profile matching ",
abstract = "Abstract Recent manufacturing systems including application software for production control are required to have high flexibility and fast changeability. In response to this, this paper proposes the development and operation methodology for production control applications which are configured by cooperation of manufacturing software units provided by different vendors using capability profiling technology. In this methodology, a profile matcher uses the manufacturing software capability profile repository to find and select adequate software units by capability profile matching with the required capability profile. The manufacturing software capability profile repository can be organized using a standardized method given by \{ISO\} 16100 to describe capabilities of manufacturing software units in terms of the capability profile. Based on information from the matcher's output, the production control application has been configured by combining selected software units. The application configurator organizes the production control application by plug-and-play of software units which match the capability profile with the requirement. A profile matcher has been implemented. The experimentation that configured an application in a cloud environment that communicates with the equipment on the floor has been successfully done on a commercially available cloud service. This trial shows the potential for the proposed methodology as a solution for a quick and flexible configuration of a production control system. "
}
@article{OuYang2005338,
title = "Determining gouge-free ball-end mills for 3D surface machining from point cloud data ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "21",
number = "4–5",
pages = "338 - 345",
year = "2005",
note = "14th International Conference on Flexible Automation and Intelligent Manufacturing14th International Conference on Flexible Automation and Intelligent Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2004.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584504001164",
author = "Daoshan OuYang and Benjamin A. Van Nest and Hsi-Yung Feng",
keywords = "Tool selection",
keywords = "Ball-end mill",
keywords = "Gouging",
keywords = "Sculptured surface",
keywords = "Point cloud data ",
abstract = "This paper presents an algorithm to automatically determine the optimal size of the ball-end milling tool used for the three-axis finish machining of free-form surfaces directly from discrete coordinate data points. The tool is considered optimal if it is of the largest possible diameter that can access every data point without causing an overcut situation or gouging the other data points. Two well-developed techniques in computational geometry, Voronoi diagram and Delaunay triangulation, are used to establish the geometric relationship among data points from which the information required to determine the optimal tool size is extracted. The result of Delaunay triangulation is a set of tetrahedrons, with the data points as vertices, which define a corresponding set of empty circum-spheres. Each data point is a vertex of several tetrahedrons and the largest of the corresponding circum-spheres represents a valid estimation of the optimal tool size at the point. Since the data points are only a sample of the original 3D surface, accuracy of the estimated tool size can be improved by using the approximated normal vector at the data point. The estimated tool size is evaluated by comparing it to its theoretical value. Extensive simulation tests show that a robust and accurate method of determining the optimal ball-end mill size has been developed. "
}
@article{AuatCheein2015361,
title = "Real-time approaches for characterization of fully and partially scanned canopies in groves ",
journal = "Computers and Electronics in Agriculture ",
volume = "118",
number = "",
pages = "361 - 371",
year = "2015",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2015.09.017",
url = "http://www.sciencedirect.com/science/article/pii/S0168169915002926",
author = "Fernando A. Auat Cheein and Jose Guivant and Ricardo Sanz and Alexandre Escola and Francisco Yandun and Miguel Torres-Torriti and Joan R. Rosell-Polo",
keywords = "Crown volume",
keywords = "LiDAR sensor",
keywords = "Mobile terrestrial laser scanner",
keywords = "Agricultural robotics ",
abstract = "Abstract Efficient information management in orchard characterization leads to more efficient agricultural processes. In this brief, a set of computational geometry methods are presented and evaluated for orchard characterization; in particular, for the estimation of canopy volume and shape in groves and orchards using a LiDAR (Light Detection And Ranging) sensor mounted on an agricultural service unit. The proposed approaches were evaluated and validated in the field, showing they are convergent in the estimation process and that they are able to estimate the crown volume for fully scanned canopies in real time; for partially observed tree crowns, accuracy decreases up to 30% (the worst case). The latter is the major contribution of this brief since it implies that the automated service unit does not need to cover all alley-ways for an accurate modeling of the orchard, thus saving valuable resources. "
}
@article{Tao2013632,
title = "Satellite observation of abnormal yellow haze clouds over East China during summer agricultural burning season ",
journal = "Atmospheric Environment ",
volume = "79",
number = "",
pages = "632 - 640",
year = "2013",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.07.033",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013005542",
author = "Minghui Tao and Liangfu Chen and Zifeng Wang and Jinhua Tao and Lin Su",
keywords = "Yellow haze",
keywords = "Agricultural burning",
keywords = "Satellite",
keywords = "Dust transport",
keywords = "East China ",
abstract = "Abstract Durative haze clouds with unusual yellow color appeared in East China in agricultural burning period during June 8–12 in 2012, causing extreme air pollution in densely populated regions including Jiangsu, Hubei, and the Yangtze River Delta. The spatial variation, vertical structure, optical properties, as well as formation process, were investigated using combined multiple satellite observations, ground measurements, and meteorological data. Different from previous studies, our analysis reveals that the yellow haze clouds were caused by mixing and interaction among airborne dust, fire emissions, and urban pollution under humid conditions. The pollution layers were 3–5 km thick, and their vertical structures were very inhomogeneous, with dust mostly distributed in the upper part and mixing of fires smoke and urban haze concentrated near surface. Compared with fire smoke, the dust-like haze clouds exhibited different optical properties with higher volume depolarization ratio and notable increase in coarse mode aerosols. Although fire emissions and urban pollution may play a more important role in surface pollution, we conclude that dust transport and high humidity were the main reason that the haze pollution was much heavier than that in previous years. In addition, regional concentrated fires only occurred in several days, and fire count was inconsistent with regional average aerosol loading. The long-range transport of fire emissions can be overestimated. In order to avoid such regional pollution event, our results also suggest that the strict measures in fire management should be extended from special periods to normal season. "
}
@article{Moller20131415,
title = "Cleaning robot navigation using panoramic views and particle clouds as landmarks ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1415 - 1439",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001371",
author = "Ralf Moller and Martin Krzykawski and Lorenz Gerstmayr-Hillen and Michael Horst and David Fleer and Janina de Jong",
keywords = "Cleaning robot",
keywords = "Visual navigation",
keywords = "Particle filter",
keywords = "Topological-metrical map ",
abstract = "Abstract The paper describes a visual method for the navigation of autonomous floor-cleaning robots. The method constructs a topological map with metrical information where place nodes are characterized by panoramic images and by particle clouds representing position estimates. Current image and position estimate of the robot are interrelated to landmark images and position estimates stored in the map nodes through a holistic visual homing method which provides bearing and orientation estimates. Based on these estimates, a position estimate of the robot is updated by a particle filter. The robot’s position estimates are used to guide the robot along parallel, meandering lanes and are also assigned to newly created map nodes which later serve as landmarks. Computer simulations and robot experiments confirm that the robot position estimate obtained by this method is sufficiently accurate to keep the robot on parallel lanes, even in the presence of large random and systematic odometry errors. This ensures an efficient cleaning behavior with almost complete coverage of a rectangular area and only small repeated coverage. Furthermore, the topological-metrical map can be used to completely cover rooms or apartments by multiple meander parts. "
}
@article{Yusuf201515,
title = "Application of acoustic directional data for audio event recognition via HMM/CRF in perimeter surveillance systems ",
journal = "Robotics and Autonomous Systems ",
volume = "72",
number = "",
pages = "15 - 28",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S092188901500086X",
author = "Syed A. Yusuf and David J. Brown and Alan Mackinnon",
keywords = "Robotics",
keywords = "Automation",
keywords = "Hidden Markov models",
keywords = "Conditional Random Fields",
keywords = "Audio event detection",
keywords = "Machine learning",
keywords = "Artificial intelligence ",
abstract = "Abstract Audio event detection (AED) and recognition is a signal processing and analysis domain used in a wide range of applications including surveillance, home automation and behavioral assessment. The field presents numerous challenges to the current state-of-the-art due to its highly nonlinear nature. High false alarm rates (FARs) in such applications particularly limit the capabilities of vision-based perimeter monitoring systems by inducing high operator dependence. On the other hand, conventional fence-based vibration detectors and pressure-driven “taut wires” offer high sensitivity at the cost of a high \{FAR\} due to debris, animals and weather. This work reports an audio event identification methodology implemented as a test-bed system for a surveillance application to reduce FAR, maximize blind-spot coverage and improve audio event classification accuracy. The first phase utilizes a nonlinear autoregressive classifier to locate and classify discrete audio events via an exogenous sound direction variable to improve classifier confidence. The second phase implements a time-series-based system to recognize various audio activity groups from nominal everyday sound events such as traffic and muffled speech. The discretely labeled data is thus trained with \{HMM\} and Conditional Random Field classifiers and reports a substantial improvement in classification accuracies of indoor human activities. "
}
@article{Kwon200467,
title = "Fitting range data to primitives for rapid local 3D modeling using sparse range point clouds ",
journal = "Automation in Construction ",
volume = "13",
number = "1",
pages = "67 - 81",
year = "2004",
note = "The best of \{ISARC\} 2002 ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2003.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580503000773",
author = "Soon-Wook Kwon and Frederic Bosche and Changwan Kim and Carl T. Haas and Katherine A. Liapi",
keywords = "Sparse range point clouds",
keywords = "3D workspace modeling",
keywords = "Fitting and matching objects",
keywords = "Merging objects ",
abstract = "Techniques to rapidly model local spaces, using 3D range data, can enable implementation of: (1) real-time obstacle avoidance for improved safety, (2) advanced automated equipment control modes, and (3) as-built data acquisition for improved quantity tracking, engineering, and project control systems. The objective of the research reported here was to develop rapid local spatial modeling tools. Algorithms for fitting sparse range point clouds to geometric primitives such as spheres, cylinders, and cuboids have been developed as well as methods for merging primitives into assemblies. Results of experiments are presented and practical usage and limitations are discussed. "
}
@article{Mitchell2014567,
title = "Image-Guided Surgery and Emerging Molecular Imaging: Advances to Complement Minimally Invasive Surgery ",
journal = "Urologic Clinics of North America ",
volume = "41",
number = "4",
pages = "567 - 580",
year = "2014",
note = "Advances in Robotic-Assisted Urologic Surgery ",
issn = "0094-0143",
doi = "https://doi.org/10.1016/j.ucl.2014.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094014314000780",
abstract="",
author = "Christopher R. Mitchell and S. Duke Herrell",
keywords = "Image guidance",
keywords = "Robotics",
keywords = "Surgical navigation",
keywords = "Molecular imaging",
keywords = "Urologic surgery "
}
@article{Collins2016248,
title = "\{PE31\} - Live Streaming of robotic surgery from leading educational centres enables global audience interactions with social media and promotion of surgical training ",
journal = "European Urology Supplements ",
volume = "15",
number = "7",
pages = "248 - ",
year = "2016",
note = "13th Meeting of the \{EAU\} Robotic Urology Section ",
issn = "1569-9056",
doi = "https://doi.org/10.1016/S1569-9056(16)15205-4",
url = "http://www.sciencedirect.com/science/article/pii/S1569905616152054",
abstract="",
author = "J.W. Collins and A. Mottrie and A. Hosseini and P. Sooriakumaran and J. Ebbing and R. Sanchez-Salas and S. Tyritzis and A. Nilsson and P. Dasgupta and B. Challacombe and W. Artibani and R. Gaston and T. Piechaud and A. Tewari and K. Badani and H. Falconer and V. Patel and R. Holloway and I. Gill and M. Aron and M. Desai and R. Coelho and K.H. Rha and J. Porter and D.Y. Pushkar and E. Chan and R. Ahlawat and D. Murphy and H. Verhagen and N.P. Wiklund"
}
@article{Schaub20142640,
title = "Autonomous Parking using a Highly Maneuverable Robotic Vehicle ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "2640 - 2645",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00800",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016420082",
author = "Alexander Schaub and Juan Carlos Ramirez de la Cruz and Darius Burschka",
abstract = "Abstract This work presents a novel autonomous parking concept for a four wheel-steerable robotic electric vehicle called \{ROboMObil\} (ROMO). Its extraordinary maneuverability, including rotations and lateral driving, and its capability of autonomous driving is demonstrated in the application of parallel parking. The whole process is described starting with the perception to identify a suitable parking spot in the near environment, planning the maneuver, and executing it autonomously. The proposed parking method is free of assumptions and does not use any information about the environment from an external source. Test results with the real vehicle are presented to show the feasibility of the concept. "
}
@article{Schlenoff201529,
title = "Intention recognition in manufacturing applications ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "29 - 41",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S073658451400057X",
author = "Craig Schlenoff and Zeid Kootbally and Anthony Pietromartire and Marek Franaszek and Sebti Foufou",
keywords = "Intention recognition",
keywords = "Manufacturing kitting",
keywords = "Ontology",
keywords = "State recognition",
keywords = "Human–robot collaboration",
keywords = "Robotics ",
abstract = "Abstract In this article, we present a novel approach to intention recognition, based on the recognition and representation of state information in a cooperative human–robot environment. States are represented by a combination of spatial relations along with cardinal direction information. The output of the Intention Recognition Algorithms will allow a robot to help a human perform a perceived operation or, minimally, not cause an unsafe situation to occur. We compare the results of the Intention Recognition Algorithms to those of an experiment involving human subjects attempting to recognize the same intentions in a manufacturing kitting domain. In almost every case, results show that the Intention Recognition Algorithms performed as well, if not better, than a human performing the same activity. "
}
@article{Liu2015110,
title = "Table-top scene analysis using knowledge-supervised \{MCMC\} ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "110 - 123",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000702",
author = "Ziyuan Liu and Dong Chen and Kai M. Wurm and Georg von Wichert",
keywords = "Knowledge representation and reasoning",
keywords = "Robotics",
keywords = "Scene analysis",
keywords = "Abstract models",
keywords = "Semantic modelling ",
abstract = "Abstract In this paper, we propose a probabilistic approach to generate abstract scene graphs from uncertain 6D pose estimates. We focus on generating a semantic understanding of the perceived scenes that well explains the composition of the scene and the inter-object relations. The proposed system is realized by our knowledge-supervised \{MCMC\} sampling technique. We explicitly make use of task-specific context knowledge by encoding this knowledge as descriptive rules in Markov logic networks. We use a probabilistic sensor model to encode the fact that measurements are subject to significant uncertainty. We integrate the measurements with the abstract scene graph in a data driven \{MCMC\} process. Our system is fully probabilistic and links the high-level abstract scene description to uncertain low level measurements. Moreover, false estimates of the object poses and hidden objects of the perceived scenes can be systematically detected using the defined Markov logic knowledge base. The effectiveness of our approach is demonstrated and evaluated in real world experiments. "
}
@article{Oyekan2015134,
title = "A vision-based terrain morphology estimation model inspired by the avian hippocampus ",
journal = "Digital Communications and Networks ",
volume = "1",
number = "2",
pages = "134 - 140",
year = "2015",
note = "",
issn = "2352-8648",
doi = "https://doi.org/10.1016/j.dcan.2015.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S2352864815000218",
author = "John Oyekan",
keywords = "Micro-UAV",
keywords = "Hippocampus",
keywords = "Avian",
keywords = "Neuroscience",
keywords = "Robotics",
keywords = "Terrain morphology ",
abstract = "Abstract Homing pigeons are known for their ability to return home after being released from a location spanning up to hundreds of miles. They make use of detected visual features in the environment, the earth׳s magnetic field as well as using the hippocampus region of the brain to construct spatial maps of the environment. This is unlike present day \{UAVs\} that rely on \{GPS\} and radio/satellite communications with a ground station, both of which might not be available during a major disaster scenario such as a solar flare. In this paper, we take inspiration from the avian hippocampus and develop a preliminary model for estimating a terrain׳s morphology using visually detected features on the terrain. This could then be used to localise a portable micro-UAV during a demining task for humanitarian purposes in third world countries affected by buried land mines from previous wars. Our goal is that in future, the presented model and algorithm in this work would enable effective coverage of an affected area using the visual information obtained from the environment. "
}
@article{Ni20132135,
title = "Vision-based virtual force guidance for tele-robotic system ",
journal = "Computers & Electrical Engineering ",
volume = "39",
number = "7",
pages = "2135 - 2144",
year = "2013",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2013.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0045790613001900",
author = "Tao Ni and Hongyan Zhang and Peng Xu and Hironao Yamada",
abstract = "Abstract In order to improve operator performance and understanding within remote environment, a vision-based virtual forced guidance control methodology for tele-robotic system is presented. The remote operation of the construction robot is achieved by manipulating the graphic robot in a virtual environment. Based on binocular vision, the ground surface is modeled as an elevation map, and the task objects are recognized from video images and reconstructed using the Power Crust algorithm. The virtual guidance forces consisting of a pair of attractive force and repulsive force from the objects and obstacles are used to enhance the multi-task manipulation of the tele-robotic system. "
}
@article{Elseberg201376,
title = "One billion points in the cloud – an octree for efficient processing of 3D laser scans ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "76",
number = "",
pages = "76 - 88",
year = "2013",
note = "Terrestrial 3D modelling ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612001888",
author = "Jan Elseberg and Dorit Borrmann and Andreas Nuchter",
keywords = "Octree",
keywords = "Tree data structure",
keywords = "Data compression",
keywords = "Frustum culling",
keywords = "Ray casting",
keywords = "RANSAC",
keywords = "Nearest neighbor search ",
abstract = "Automated 3-dimensional modeling pipelines include 3D scanning, registration, data abstraction, and visualization. All steps in such a pipeline require the processing of a massive amount of 3D data, due to the ability of current 3D scanners to sample environments with a high density. The increasing sampling rates make it easy to acquire Billions of spatial data points. This paper presents algorithms and data structures for handling these data. We propose an efficient octree to store and compress 3D data without loss of precision. We demonstrate its usage for an exchange file format, fast point cloud visualization, sped-up 3D scan matching, and shape detection algorithms. We evaluate our approach using typical terrestrial laser scans. "
}
@incollection{Finch2014235,
title = "10 - Precision farming ",
editor = "Finch, H.J.S. and , and Samuel, A.M. and ,  and Lane, G.P.F. ",
booktitle = "Lockhart & Wiseman’s Crop Husbandry Including Grassland (Ninth Edition) ",
publisher = "Woodhead Publishing",
edition = "Ninth Edition",
address = "",
year = "2014",
pages = "235 - 244",
isbn = "978-1-78242-371-3",
doi = "https://doi.org/10.1533/9781782423928.2.235",
url = "http://www.sciencedirect.com/science/article/pii/B9781782423713500102",
author = "H.J.S. Finch and A.M. Samuel and G.P.F. Lane",
keywords = "cost-benefit",
keywords = "auto-steering",
keywords = "controlled traffic",
keywords = "real-time kinetics",
keywords = "variable rate application",
keywords = "robotics ",
abstract = "Abstract: This chapter looks briefly at the history of precision farming techniques and how they have evolved up to the present day. It covers the costs and benefits of the technology and techniques, and then describes the various mapping methods that can take place on-farm these days. It discusses the use of auto-steering and variable rate application in particular. It also discusses the difficulties sometimes encountered when interpreting data. Finally it looks at the possible future of precision farming, with its potential use of robotics and data management. "
}
@article{Guerreiro20141116,
title = "Automatic 2-D LiDAR geometric calibration of installation bias ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1116 - 1129",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000906",
author = "Bruno J. Guerreiro and Carlos Silvestre and Paulo Oliveira",
keywords = "Calibration",
keywords = "Range sensing",
keywords = "Special orthogonal group",
keywords = "Mapping",
keywords = "Aerial robotics ",
abstract = "Abstract This paper proposes two estimation algorithms for the determination of the attitude installation matrix for 2-D light detection and ranging (LiDAR) systems on board unmanned aerial vehicles (UAVs). While a comparative calibration algorithm assumes the existence of a known calibration surface, an automatic calibration algorithm does not require any prior knowledge of the trajectories of the vehicle or the terrain where the calibration mission is performed. The proposed calibration algorithms rely on the minimization of the errors between the measured point cloud and a representation of the known calibration surface or, alternatively, the errors between several acquired point clouds, by comparing each measured point cloud with a surface representation of the others. The resulting optimization problems are addressed using two techniques: (i) nonlinear optimization, where the attitude installation rotation matrix is parameterized by the Z Y X Euler angles, and (ii) optimization on Riemannian manifolds, enabling the estimation of the attitude installation matrix on the group of special orthogonal matrices \{SO\} ( 3 ) . The proposed calibration techniques are extensively validated and compared using both simulated and experimental LiDAR data sets, demonstrating their accuracy and performance. "
}
@article{Senin201339,
title = "Point set augmentation through fitting for enhanced \{ICP\} registration of point clouds in multisensor coordinate metrology ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "39 - 52",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000877",
author = "N. Senin and B.M. Colosimo and M. Pacella",
keywords = "Multisensor data fusion",
keywords = "Coordinate metrology",
keywords = "Registration",
keywords = "Measurement error",
keywords = "Iterative Closest Point (ICP)",
keywords = "Model fitting ",
abstract = "In multisensor coordinate metrology scenarios involving the fusion of homogenous data, specifically 3D point clouds like those originated by \{CMMs\} and structured light scanners, the problem of registration, i.e. the proper localization of the clouds in the same coordinate system, is of central importance. For fine registration, known variants of the Iterative Closest Point (ICP) algorithm are commonly adopted; however, no attempt seems to be done to tweak such algorithms to better suit the distinctive multisensor nature of the data. This work investigates an original approach that targets issues which are specific to multisensor coordinate metrology scenarios, such as coexistence of point sets with different densities, different spatial arrangements (e.g. sparse \{CMM\} points vs. gridded sets from light scanners), and different noise levels associated to the point sets depending on the metrological performances of the sensors involved. The proposed approach is based on combining known \{ICP\} variants with novel point set augmentation techniques, where new points are added to existing sets with the purpose of improving registration performance and robustness to measurement error. In particular, augmentation techniques based on advanced fitting solutions promote a paradigm shift for registration, which is not seen as a geometric problem consisting in moving point sets as close as possible to each other, but as a problem where it is not the original points, but the underlying geometries that must be brought together. In this work, promising combinations of \{ICP\} and point augmentation techniques are investigated through the application to virtual scenarios involving synthetic geometries and simulated measurements. Guidelines for approaching registration problems in industrial scenarios involving multisensor data fusion are also provided. "
}
@article{Sansoni2014222,
title = "Optoranger: A 3D pattern matching method for bin picking applications ",
journal = "Optics and Lasers in Engineering ",
volume = "54",
number = "",
pages = "222 - 231",
year = "2014",
note = "",
issn = "0143-8166",
doi = "https://doi.org/10.1016/j.optlaseng.2013.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0143816613002303",
author = "Giovanna Sansoni and Paolo Bellandi and Fabio Leoni and Franco Docchio",
keywords = "3D metrology",
keywords = "Bin picking",
keywords = "Robotics",
keywords = "3D matching",
keywords = "3D segmentation ",
abstract = "Abstract This paper presents a new method, based on 3D vision, for the recognition of free-form objects in the presence of clutters and occlusions, ideal for robotic bin picking tasks. The method can be considered as a compromise between complexity and effectiveness. A 3D point cloud representing the scene is generated by a triangulation-based scanning system, where a fast camera acquires a blade projected by a laser source. Image segmentation is based on 2D images, and on the estimation of the distances between point pairs, to search for empty areas. Object recognition is performed using commercial software libraries integrated with custom-developed segmentation algorithms, and a database of model clouds created by means of the same scanning system. Experiments carried out to verify the performance of the method have been designed by randomly placing objects of different types in the Robot work area. The preliminary results demonstrate the excellent ability of the system to perform the bin picking procedure, and the reliability of the method proposed for automatic recognition of identity, position and orientation of the objects. "
}
@incollection{Pickering2015645,
title = "Cybernetics ",
editor = "Wright, James D. ",
booktitle = "International Encyclopedia of the Social & Behavioral Sciences (Second Edition) ",
publisher = "Elsevier",
edition = "Second Edition",
address = "Oxford",
year = "2015",
pages = "645 - 650",
isbn = "978-0-08-097087-5",
doi = "https://doi.org/10.1016/B978-0-08-097086-8.85005-9",
url = "http://www.sciencedirect.com/science/article/pii/B9780080970868850059",
author = "Andrew Pickering",
keywords = "Actor-network theory",
keywords = "Agency",
keywords = "Complexity",
keywords = "Counterculture",
keywords = "Cyborgs",
keywords = "Enframing",
keywords = "Interdisciplinarity",
keywords = "Mangle of practice",
keywords = "Modernity",
keywords = "Ontology",
keywords = "Poiesis",
keywords = "Politics",
keywords = "Posthumanism",
keywords = "Robotics",
keywords = "Technocracy",
keywords = "Technologies of the self ",
abstract = "Abstract This article reviews developments in cybernetics from the 1940s to the present, focusing on the most radical threads, those that foreground key questions of agency, performance, and emergence. It explores cybernetic intersections with fields including science and technology studies, brain science, psychiatry and antipsychiatry, biological computing, management, the environment, the arts, architecture, nonmodern spirituality, and the counterculture of the 1960s. It concludes with a discussion of the politics of cybernetics. "
}
@article{Yoshihara2012422,
title = "Topologically robust B-spline surface reconstruction from point clouds using level set methods and iterative geometric fitting algorithms ",
journal = "Computer Aided Geometric Design ",
volume = "29",
number = "7",
pages = "422 - 434",
year = "2012",
note = "Geometric Modeling and Processing 2012 ",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2012.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S0167839612000337",
author = "Hiroki Yoshihara and Tatsuya Yoshii and Tadahiro Shibutani and Takashi Maekawa",
keywords = "Level set method",
keywords = "Iterative geometric fitting method",
keywords = "B-spline surfaces",
keywords = "Catmull–Clark subdivision surfaces",
keywords = "Quadrilateral mesh ",
abstract = "In this paper, we present a procedure for automatically reconstructing an arbitrary topological surface from an unorganized point data set; this surface will have three representations, namely quadrilateral meshes, Catmull–Clark subdivision surfaces, and B-spline surfaces. Our novel reconstruction method adapts a level set method to capture the topology of the point clouds in a robust manner and then employs an iterative geometric fitting algorithm to generate high-quality Catmull–Clark subdivision surfaces. A quadrilateral mesh is generated by projecting the control net of the resulting Catmull–Clark surface onto its limit surface. Finally, the control net of the Catmull–Clark surface is converted to that of a B-spline surface. The reconstructed models of topologically complex models show the effectiveness of the proposed algorithm. "
}
@article{Tamas201476,
title = "3D semantic interpretation for robot perception inside office environments ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "32",
number = "",
pages = "76 - 87",
year = "2014",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2014.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0952197614000566",
author = "Levente Tamas and Lucian Cosmin Goron",
keywords = "Robotics",
keywords = "Perception",
keywords = "Segmentation",
keywords = "Registration",
keywords = "Indoor mapping ",
abstract = "Abstract Making sense out of human indoor environments is an essential feature for robots. The paper at hand presents a system for semantic interpretation of our surrounding indoor environments such as offices and kitchens. The perception and the interpretation of the measured data are essential tasks for any intelligent system. There are different techniques for processing 3D point clouds. The majority of them include acquisition, iterative registration, segmentation, or classification stages. We describe a generic pipeline for indoor data processing and semantic information extraction. The proposed pipeline is validated using several data sets collected using different 3D sensing devices. "
}
@article{Schutlz201355,
title = "Classes in the cloud ",
journal = "New Scientist ",
volume = "217",
number = "2905",
pages = "55 - ",
year = "2013",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(13)60511-4",
url = "http://www.sciencedirect.com/science/article/pii/S0262407913605114",
author = "Nora Schutlz",
abstract = "Massive Open Online Courses (MOOCs) offer “the world's best courses, online, for free”. Nora Schultz answers your burning questions "
}
@article{Carley201271,
title = "Significant decadal channel change 58–67 years post-dam accounting for uncertainty in topographic change detection between contour maps and point cloud models ",
journal = "Geomorphology ",
volume = "179",
number = "",
pages = "71 - 88",
year = "2012",
note = "",
issn = "0169-555X",
doi = "https://doi.org/10.1016/j.geomorph.2012.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169555X12003819",
author = "Jennifer K. Carley and Gregory B. Pasternack and Joshua R. Wyrick and Jesse R. Barker and Paul M. Bratovich and Duane A. Massa and Gary D. Reedy and Thomas R. Johnson",
keywords = "Channel change",
keywords = "Geomorphic change detection",
keywords = "Uncertainly analysis",
keywords = "Dam impacts",
keywords = "Gravel-bed river",
keywords = "Fluvial geomorphology ",
abstract = "Construction of digital elevation models (DEMs) and the subtraction of \{DEMs\} between different points in time as a method to determine temporal patterns of scour and fill is a highly valuable procedure emerging in geomorphology. These \{DEMs\} of Differences (DoDs) must be assessed for error in order to distinguish actual topographic change from uncertainty and surface error. Current methods include: (1) uniformly excluding all values that fall below a minimum threshold; (2) using a spatially variable approach such as the construction of minimum Level of Detection (LoD) grids; or (3) the creation of a fuzzy inference system. Although spatially variable methods for determining error have been more accurate in excluding noise without discarding large amounts of meaningful data, a challenge remains in performing DoDs against preexisting contour-based maps for which no original point data are available. The goals of this study were to (1) develop a method that overcomes the unknown point density of contour (and other historical) data sets and allows for some assessment of DoD uncertainty on the basis of information on topographic variability, (2) perform comprehensive uncertainty analysis testing to understand the opportunities and constraints associated with this new method, and (3) report and interpret the overall pattern and volume of decadal topographic change for a regulated river 67 years post-dam in light of alternate conjectured mechanisms of post-dam longitudinal profile adjustment. The key feature of the new approach is the introduction of a high-density artificial point grid that samples the topographic variability evident in the available historical data set. The testbed used to develop and assess this new DoD method was the ~ 37.5-km lower Yuba River, California. Historical data consisted of 0.6-m contours from a 1999 survey, while a more detailed point cloud was available for the most recent survey in 2006–2008. To evaluate uncertainty in the method, this study applied seven different uncertainty metrics of varying strictness (t = 1, t = 1.96, uniform 0.3-m exclusion, t = 1 plus uniform 0.3 m exclusion, t = 1 with LoD minimum at 0.3, t = 1.96 plus uniform 0.3-m exclusion, and t = 1.96 with LoD minimum at 0.3) and two different DoD adjustment methods (exclusion and subtraction). A stringent approach involving joint use of the contour half-interval and the spatially distributed LoD grid at a 95% confidence limit excluded 44.3% of the study area from spatial assessment of channel change and volumetric change computation. This preferred approach yielded an estimated 2.518 million m3 of total scour and 2.455 million m3 of total fill in 7–9 years. After considering different mapping epochs, the net annual average export was 17,000 m3 (~ 32,500 tons) to the Feather River and a river-valley sediment yield of 2205 tons/km2/year. This amount is 36% of the post-dam annual yield of gravel and cobble to the upstream reservoir that blocks sediment conveyance into the study domain, suggesting that the lowland system is still highly dynamic 67 years after the dam was built. The scientific significance of this is that the response of rivers to dams can be far more long-lasting and complex, depending on the suite of cumulative societal impacts to rivers. The ability to account for spatially explicit DoD uncertainty (i.e., data retention when uncertainty is low and data removal when uncertainty is high) when comparing historic contour-based and modern point cloud-based \{DEMs\} will allow for more detailed and reliable DoDs and sediment budgets in these cases. "
}
@article{Henn201317,
title = "Model driven reconstruction of roofs from sparse \{LIDAR\} point clouds ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "76",
number = "",
pages = "17 - 29",
year = "2013",
note = "Terrestrial 3D modelling ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612002043",
author = "Andre Henn and Gerhard Groger and Viktor Stroh and Lutz Plumer",
keywords = "Reconstruction",
keywords = "Building",
keywords = "Data mining",
keywords = "Classification",
keywords = "LIDAR",
keywords = "Three-dimensional ",
abstract = "This article presents a novel, fully automatic method for the reconstruction of three-dimensional building models with prototypical roofs (CityGML LoD2) from \{LIDAR\} data and building footprints. The proposed method derives accurate results from sparse point data sets and is suitable for large area reconstruction. Sparse \{LIDAR\} data are widely available nowadays. Robust estimation methods such as RANSAC/MSAC, are applied to derive best fitting roof models in a model-driven way. For the identification of the most probable roof model, supervised machine learning methods (Support Vector Machines) are used. In contrast to standard approaches (where the best model is selected via \{MDL\} or AIC), supervised classification is able to incorporate additional features enabling a significant improvement in model selection accuracy. "
}
@article{Folch2012165,
title = "Validation of the \{FALL3D\} ash dispersion model using observations of the 2010 Eyjafjallajokull volcanic ash clouds ",
journal = "Atmospheric Environment ",
volume = "48",
number = "",
pages = "165 - 183",
year = "2012",
note = "Volcanic ash over Europe during the eruption of Eyjafjallajoekull on Iceland, April-May 2010 ",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.06.072",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011006960",
author = "A. Folch and A. Costa and S. Basart",
keywords = "Volcanic ash dispersion",
keywords = "Numerical model",
keywords = "Model validation",
keywords = "2010 Eyjafjallajokull eruption ",
abstract = "During April–May 2010 volcanic ash clouds from the Icelandic Eyjafjallajokull volcano reached Europe causing an unprecedented disruption of the EUR/NAT region airspace. Civil aviation authorities banned all flight operations because of the threat posed by volcanic ash to modern turbine aircraft. New quantitative airborne ash mass concentration thresholds, still under discussion, were adopted for discerning regions contaminated by ash. This has implications for ash dispersal models routinely used to forecast the evolution of ash clouds. In this new context, quantitative model validation and assessment of the accuracies of current state-of-the-art models is of paramount importance. The passage of volcanic ash clouds over central Europe, a territory hosting a dense network of meteorological and air quality observatories, generated a quantity of observations unusual for volcanic clouds. From the ground, the cloud was observed by aerosol lidars, lidar ceilometers, sun photometers, other remote-sensing instruments and in-situ collectors. From the air, sondes and multiple aircraft measurements also took extremely valuable in-situ and remote-sensing measurements. These measurements constitute an excellent database for model validation. Here we validate the \{FALL3D\} ash dispersal model by comparing model results with ground and airplane-based measurements obtained during the initial 14–23 April 2010 Eyjafjallajokull explosive phase. We run the model at high spatial resolution using as input hourly-averaged observed heights of the eruption column and the total grain size distribution reconstructed from field observations. Model results are then compared against remote ground-based and in-situ aircraft-based measurements, including lidar ceilometers from the German Meteorological Service, aerosol lidars and sun photometers from \{EARLINET\} and \{AERONET\} networks, and flight missions of the German \{DLR\} Falcon aircraft. We find good quantitative agreement, with an error similar to the spread in the observations (however depending on the method used to estimate mass eruption rate) for both airborne and ground mass concentration. Such verification results help us understand and constrain the accuracy and reliability of ash transport models and it is of enormous relevance for designing future operational mitigation strategies at Volcanic Ash Advisory Centers. "
}
@article{Aziz2012333,
title = "Potential for Providing Augmented Reality Elements in Special Education via Cloud Computing ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "333 - 339",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.181",
url = "http://www.sciencedirect.com/science/article/pii/S1877705812025672",
author = "Kamarulzaman Ab Aziz and Nor Azlina Ab Aziz and Anuar Mohd Yusof and Avijit Paul",
keywords = "Advance learning tools",
keywords = "attention deficit hyperactivity disorder (ADHD)",
keywords = "special education ",
abstract = "Technology has definitely enhanced the learning process. This is not only true for the main stream education programmes but also in education programmes for students with special needs. This paper observes two technological trends, namely cloud computing and augmented reality within the context of the Malaysian special education delivery. It is recognised that augmented reality offers significant benefits to the learning process. It is also true that the Malaysian government has embarked the establishment of cloud computing sector in the country. This paper draws attention to the synergistic possibility of providing \{AR\} enhanced education for the special needs students in Malaysia via cloud computing. "
}
@article{Bell201464,
title = "Microblogging as a mechanism for human–robot interaction ",
journal = "Knowledge-Based Systems ",
volume = "69",
number = "",
pages = "64 - 77",
year = "2014",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2014.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0950705114001932",
author = "David Bell and Theodora Koulouri and Stanislao Lauria and Robert D. Macredie and James Sutton",
keywords = "Twitter",
keywords = "Human–robot interfaces",
keywords = "Architectures for social robotics",
keywords = "Computational intelligence for knowledge acquisition",
keywords = "Social media retrieval ",
abstract = "Abstract This paper presents a novel approach to social data analysis, exploring the use of microblogging to manage interaction between humans and robots, and presenting and evaluating an architecture that extends the use of social networks to connect humans and devices. The approach uses natural language processing – in the form of simple grammar-based techniques – to extract features of interest from textual data retrieved from a microblogging platform in real-time and generate appropriate executable code for the robot. The simple rule-based solution exploits some of the ‘natural’ constraints imposed by microblogging platforms to manage the potential complexity of the interactions and create bi-directional communication. In order to evaluate the developed system, an analysis of real-time, user-generated social media data is presented. The analysis demonstrates the feasibility of producing programmes from the social media data which lead to executable actions by a front-end application – an approach of immediate relevance to web-based systems, like question–answering engines, personal digital assistants, and smart home/office devices. "
}
@incollection{Havens2016245,
title = "Chapter 11 - Using Thermal Imagers for Animal Ecology ",
editor = "Havens, Kirk J.  and Sharp, Edward J. ",
booktitle = "Thermal Imaging Techniques to Survey and Monitor Animals in the Wild ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2016",
pages = "245 - 314",
isbn = "978-0-12-803384-5",
doi = "https://doi.org/10.1016/B978-0-12-803384-5.00011-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128033845000117",
author = "Kirk J. Havens and Edward J. Sharp",
keywords = "viewing angle",
keywords = "reflectivity",
keywords = "emissivity",
keywords = "survey area",
keywords = "apparent temperature difference",
keywords = "spatial distribution",
keywords = "thermal signatures",
keywords = "heat transfer",
keywords = "atmospheric transmission",
keywords = "animal ecology",
keywords = "detectability",
keywords = "poikilotherms",
keywords = "homotherms",
keywords = "atmospheric effects",
keywords = "solar loading",
keywords = "diurnal cycle",
keywords = "swath width",
keywords = "survey geometry",
keywords = "FOV-footprint",
keywords = "automated detection",
keywords = "robotic vision",
keywords = "panning",
keywords = "water vapor",
keywords = "relative humidity",
keywords = "atmospheric scattering",
keywords = "aerosols",
keywords = "red-cockaded woodpecker",
keywords = "precipitation",
keywords = "cloud cover",
keywords = "shading effects",
keywords = "tree cavities",
keywords = "thermal shadows",
keywords = "background clutter",
keywords = "emissivity",
keywords = "transects",
keywords = "thermal contrast",
keywords = "bedding sites",
keywords = "signature lifetimes ",
abstract = "Abstract A successful session of collecting thermal imagery in the field requires that the survey planning take into account how to best use the factors and techniques that we can control and integrate them with those that we cannot control. This chapter deals with the effects of phenomena that have a dominating influence on the quality of imagery gathered in the field. The effects of the atmosphere, diurnal cycle, and continually changing micrometeorological conditions are beyond our control but must always be included in the planning of a data-gathering effort. In the sections that follow we provide insight on how these continually changing gifts of nature affect thermal images and how to best manage their deleterious side effects on the imagery and at the same time use the advantageous side of these effects to help optimize the detectability. "
}
@article{Galvez2012174,
title = "Particle swarm optimization for non-uniform rational B-spline surface reconstruction from clouds of 3D data points ",
journal = "Information Sciences ",
volume = "192",
number = "",
pages = "174 - 192",
year = "2012",
note = "Swarm Intelligence and Its Applications ",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2010.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0020025510005529",
author = "Akemi Galvez and Andres Iglesias",
keywords = "Surface reconstruction",
keywords = "Reverse engineering",
keywords = "Surface parameterization",
keywords = "Surface fitting",
keywords = "Particle swarm optimization",
keywords = "NURBS surface ",
abstract = "This work investigates the use of particle swarm optimization (PSO) to recover the shape of a surface from clouds of (either organized or scattered) noisy 3D data points, a challenging problem that appears recurrently in a wide range of applications such as \{CAD\} design, data visualization, virtual reality, medical imaging and movie industries. In this paper, we apply a \{PSO\} approach in order to reconstruct a non-uniform rational B-spline (NURBS) surface of a certain order from a given set of 3D data points. In this case, surface reconstruction consists of two main tasks: (1) surface parameterization and (2) surface fitting. Both tasks are critical but also troublesome, leading to a high-dimensional non-linear optimization problem. Our method allows us to obtain all relevant surface data (i.e., parametric values of data points, knot vectors, control points and their weights) in a shot and no pre-/post-processing is required. Furthermore, it yields very good results even in presence of problematic features, such as multi-branches, high-genus or self-intersections. Seven examples including open, semiclosed, closed, zero-genus, high-genus surfaces and real-world scanned objects, described in free-form, parametric and implicit forms illustrate the good performance of our approach and its superiority over previous approaches in terms of accuracy and generality. "
}
@article{Wilson201197,
title = "Positive perspectives on cloud security ",
journal = "Information Security Technical Report ",
volume = "16",
number = "3–4",
pages = "97 - 101",
year = "2011",
note = "Cloud Security ",
issn = "1363-4127",
doi = "https://doi.org/10.1016/j.istr.2011.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1363412711000471",
author = "Piers Wilson",
abstract = "The adoption of cloud computing has faced challenges and there are concerns about the risks, the loss of control of data and the assurance of security and access control. This paper aims to show that these should be viewed as requirements which need to be fulfilled, but that the overriding benefits from cloud computing are such that businesses could face real challenges in future if they resist adoption and so the risks need to be, and can be, faced with a more positive outlook given this more balanced view. "
}
@article{Stork201282,
title = "Towards a scientific foundation for engineering Cognitive Systems – A European research agenda, its rationale and perspectives ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "1",
number = "",
pages = "82 - 91",
year = "2012",
note = "",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X12000072",
author = "Hans-Georg Stork",
keywords = "Cognitive systems",
keywords = "Bio-inspiration",
keywords = "Robotics",
keywords = "Cognitive robotics",
keywords = "Research agendas",
keywords = "Public funding ",
abstract = "For more than 10 years, beginning in the early 2000s, the European Commission has been supporting targeted research in the fields of Cognitive Systems and Robotics. In this note we discuss the rationale of the underlying research agenda (including its relevance to the \{BICA\} challenge), structure the large set of funded projects, and outline perspectives for future research. "
}
@article{Hammoudi2012971,
title = "Recovering Occlusion-Free Textured 3D Maps of Urban Facades by a Synergistic Use of Terrestrial Images, 3D Point Clouds and Area-Based Information ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "971 - 980",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.271",
url = "http://www.sciencedirect.com/science/article/pii/S1877705812026719",
author = "Karim Hammoudi and Fadi Dornaika and Bahman Soheilian and Bruno Vallet and John McDonald and Nicolas Paparoditis",
keywords = "Mobile Platform",
keywords = "Optical Sensors",
keywords = "Vision Sensors",
keywords = "Range Sensors",
keywords = "Sensor Fusion",
keywords = "Sensor Data Processing",
keywords = "Terrestrial-based Facade Modeling",
keywords = "Facade Texturing",
keywords = "Virtual Reality ",
abstract = "In this paper we present a practical approach for generating an occlusion-free textured 3D map of urban facades by the synergistic use of terrestrial images, 3D point clouds and area-based information. Particularly in dense urban environments, the high presence of urban objects in front of the facades causes significant difficulties for several stages in computational building modeling. Major challenges lie on the one hand in extracting complete 3D facade quadrilateral delimitations and on the other hand in generating occlusion-free facade textures. For these reasons, we describe a straightforward approach for completing and recovering facade geometry and textures by exploiting the data complementarity of terrestrial multi-source imagery and area-based information. "
}
@article{Keren2014400,
title = "Kindergarten Social Assistive Robot (KindSAR) for children’s geometric thinking and metacognitive development in preschool education: A pilot study ",
journal = "Computers in Human Behavior ",
volume = "35",
number = "",
pages = "400 - 412",
year = "2014",
note = "",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2014.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0747563214001319",
author = "Guy Keren and Marina Fridin",
keywords = "Architecture for educational technology system",
keywords = "Elementary education",
keywords = "Intelligent tutoring systems",
keywords = "Interactive learning environments",
keywords = "Interdisciplinary projects ",
abstract = "Abstract Kindergarten Social Assistive Robot (KindSAR) is an innovative tool promotes children’s development through social interaction. This pilot study demonstrates how KindSAR can assist educational staff in the teaching of geometric thinking and in promoting the metacognitive development by engaging children in interactive play activities. Children’s reactions and performances were video recorded for analysis. Most children exhibited positive interaction with the robot and a high level of enjoyment. Our results showed that their performances on geometric thinking and metacognitive tasks were improved while they “played” with the robot. To measure children’s learning we have developed a novel measure of cognitive learning, which we call “velocity of learning”. This study demonstrates the feasibility and expected benefits of incorporating KindSAR in preschool education. "
}
@article{Chotiprayanakul201211,
title = "Human–robot–environment interaction interface for robotic grit-blasting of complex steel bridges ",
journal = "Automation in Construction ",
volume = "27",
number = "",
pages = "11 - 23",
year = "2012",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2012.04.014",
url = "http://www.sciencedirect.com/science/article/pii/S0926580512000702",
author = "P. Chotiprayanakul and D.K. Liu and G. Dissanayake",
keywords = "Steel bridge maintenance",
keywords = "Grit-blasting",
keywords = "Human–robot–environment interaction",
keywords = "Haptic interface ",
abstract = "This paper presents a human-robot-environment interaction (HREI) interface using haptic feedback for a grit-blasting robot operating in close proximity to a complex steel bridge structure. The productivity requirements dictate the need for efficient algorithms for mapping, exploration, and collision-free motion planning. While a large portion of the grit-blasting operation can be automated, a tele-operation is essential to deal with some difficult to access sections such as edges, complex corners, and surfaces which can only be approached through hole. A 3-dimensional virtual force field (3D-VF2) method is developed for capturing the relationship between the robot and its environment. A novel haptic force generation method and a workspace mapping algorithm allow intuitive interaction between the operator and the robot through haptic feedback. The strategies presented are verified in extensive simulations and experiments conducted on a steel bridge with a prototype grit-blasting robot. "
}
@article{Mezgar201111949,
title = "Cloud Computing Technology for Networked Enterprises ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11949 - 11954",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.00702",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016455369",
author = "Istvan Mezgar",
keywords = "Keywords:",
keywords = "Architectures",
keywords = "enterprise integration",
keywords = "interoperability",
keywords = "manufacturing",
keywords = "networks ",
abstract = "Abstract Today manufacturing enterprises have to organize themselves into effective system architectures to match fast changing market demands. These architectures can be realized only by using computer networks in order to co-ordinate the production of the distributed units forming different types of networked enterprises (NE). Cloud Computing (CC) is an important up to date computing technology for Networked Enterprises, as it offers significant financial and technical advantages beside high level collaboration possibilities. The paper introduces the main characteristics of future internet based enterprises and the different \{CC\} models. Additionally the advantages and disadvantages of cloud computing have been summarized giving special focus on interoperability challenges. "
}
@article{Alam20101162,
title = "Monitoring spatio-temporal variations in aerosols and aerosol–cloud interactions over Pakistan using \{MODIS\} data ",
journal = "Advances in Space Research ",
volume = "46",
number = "9",
pages = "1162 - 1176",
year = "2010",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2010.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S0273117710004084",
author = "Khan Alam and Muhammad Jawed Iqbal and Thomas Blaschke and Salman Qureshi and Gulzar Khan",
keywords = "Modis",
keywords = "Hysplit",
keywords = "AOD",
keywords = "CF",
keywords = "CTP",
keywords = "CTT ",
abstract = "Clouds are important elements in climatic processes and interactions between aerosols and clouds are therefore a hot topic for scientific research. Aerosols show both spatial and temporal variations, which can lead to variations in the microphysics of clouds. In this research, we have examined the spatial and temporal variations in aerosol particles over Pakistan and the impact of these variations on various optical properties of clouds, using Moderate Resolution Imaging Spectroradiometer (MODIS) data from the Terra satellite. We used the Hybrid Single Particle Lagrangian Integrated Trajectory (HYSPLIT) model for trajectory analysis to reveal the origins of air masses, with the aim of understanding these spatial and temporal variabilities in aerosol concentrations. We also documented seasonal variations in patterns of aerosol optical depth (AOD) over Pakistan, for which the highest values occur during the monsoon season (June–August). We then analyzed the relationships between \{AOD\} and four other cloud parameters, namely water vapour (WV), cloud fraction (CF), cloud top temperature (CTT) and cloud top pressure (CTP). Regional correlation maps and time series plots for aerosol (AOD) and cloud parameters were produced to provide a better understanding of aerosol–cloud interaction. The analyses showed strong positive correlations between \{AOD\} and \{WV\} for all of the eight cities investigated. The correlation between \{AOD\} and \{CF\} was positive for those cities where the air masses were predominantly humid, but negative for those cities where the air masses were relatively dry and carried a low aerosol abundance. These correlations were clearly dependent on the meteorological conditions for all of the eight cities investigated. Because of the observed AOD–CF relationship, the co-variation of \{AOD\} with \{CTP\} and \{CTT\} may be attributable to large-scale meteorological variations: \{AOD\} showed a positive correlation with \{CTP\} and \{CTT\} in northern regions of Pakistan and a negative correlation in southern regions. "
}
@article{Tresset2013348,
title = "Portrait drawing by Paul the robot ",
journal = "Computers & Graphics ",
volume = "37",
number = "5",
pages = "348 - 363",
year = "2013",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2013.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0097849313000149",
author = "Patrick Tresset and Frederic Fol Leymarie",
keywords = "Fine arts",
keywords = "Media arts",
keywords = "Computer graphics",
keywords = "Non-photorealistic rendering (NPR)",
keywords = "Computer vision",
keywords = "Robotics ",
abstract = "We describe Paul, a robotic installation that produces observational face drawings of people. Paul is a naive drawer: it does not have highlevel knowledge of the structures constitutive of the human face (such as the mouth, nose, eyes) nor the capability of learning expertise based on experience as a human would. However, Paul is able to draw using the equivalent of an artist's stylistic signature based on a number of processes mimicking drawing skills and technique, which together form a drawing cycle. Furthermore, we present here our first efforts in implementing two different versions of visual feedback to permit the robot to iteratively augment and improve a drawing which initially is built from a process of salient lines recovery. The first form of visual feedback we study we refer to as computational as it involves a purely internal (memory-based) representation of regions to render via shading by the robot. The second version we call physical as it involves the use of a camera as an ‘eye’ taking new snapshots of the artefact in progress. This is then analysed to take decisions on where and how to render shading next. A main point we emphasise in this work is the issue of embodiment of graphical systems, in our case in a robotic platform. We present our arguments in favour of such a position for the graphics community to reflect upon. Finally, we emphasise that the drawings produced by Paul have been considered of interest by fine art professionals in recent international art fairs and exhibitions, as well as by the public at large. One drawing is now in the Victoria and Albert museum collection. We identify a number of factors that may account for such perceived qualities of the produced drawings. "
}
@article{Brun20116382,
title = "Mapping aerosol intrusion in Himalayan valleys using the Moderate Resolution Imaging Spectroradiometer (MODIS) and Cloud–Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) ",
journal = "Atmospheric Environment ",
volume = "45",
number = "35",
pages = "6382 - 6392",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.08.026",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011008466",
author = "Julien Brun and Prabhakar Shrestha and Ana P. Barros",
keywords = "Aerosol",
keywords = "Intrusion",
keywords = "River valley",
keywords = "High resolution",
keywords = "MODIS",
keywords = "CALIPSO",
keywords = "Nepal ",
abstract = "Mapping the spatial and temporal distribution of aerosols along mountain ranges is an important step toward elucidating orographic aerosol–cloud–rainfall interactions. This requires high spatial resolution aerosol observations over complex topography, which are not currently available either from ground-based observing systems or from remote-sensing products. Here, a novel approach is presented that relies on visible channels from \{MODIS\} Rapid Response data at 250 m spatial resolution to extract the daytime aerosol run-up (intrusion length and height) from the Indo-Gangetic Plains to the High Himalaya. Intrusion length and height are determined from the intersection of topography with the MODIS-derived aerosol plume using an adaptive object-classification algorithm. The methodology is demonstrated for a case study of the Arun River in eastern Nepal. Results of run-up extraction are examined along with the Total Attenuated Backscatter (Level 1B at 532 nm) from \{CALIPSO\} to investigate the regional variability of aerosol. During the pre-monsoon season, \{CALIPSO\} nighttime profiles show the presence of a slanted dust layer following the envelope topography. This is consistent with upper level transport of aerosol by north-westerly winds associated with high-frequency dust storms. In the winter, the signal is weaker, and the nighttime elevated aerosol layer is flat and remains below the envelope orography consistent with blocking conditions. For both seasons, the daytime aerosol layer detected from \{MODIS\} observations is always below the ridges. This suggests that in addition to seasonal variability governed by synoptic conditions, there is a distinct diurnal cycle in the North–South transport of aerosol between the Himalayas and the IGP. "
}
@article{Paul2013136,
title = "A novel surface segmentation approach for robotic manipulator-based maintenance operation planning ",
journal = "Automation in Construction ",
volume = "29",
number = "",
pages = "136 - 147",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2012.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580512001483",
author = "Gavin Paul and Ngaiming Kwok and Dikai Liu",
keywords = "Surface segmentation",
keywords = "Manipulator trajectory planning",
keywords = "Maintenance operations ",
abstract = "This paper presents a novel approach to segmenting a three-dimensional surface map by considering the task requirements and the movements of an industrial robot manipulator. Maintenance operations, such as abrasive blasting, that are performed by a field robot manipulator can be made more efficient by exploiting surface segmentation. The approach in this paper utilises an aggregate of multiple connectivity graphs, with graph edges defined by task constraints, and graph vertices that correspond to small, maintenance-specific target surfaces, known as Scale-Like Discs (SLDs). The task constraints for maintenance operations are based on the characteristics of neighbouring SLDs. The combined connectivity graphs are analysed to find clusters of vertices, thus segmenting the surface map into groups of related SLDs. Experiments conducted in three typical bridge maintenance environments have shown that the approach can reduce garnet usage by 10%–40% and reduce the manipulator joint movements by up to 35%. "
}
@article{Reina20121377,
title = "Self-learning classification of radar features for scene understanding ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "11",
pages = "1377 - 1388",
year = "2012",
note = "Towards Autonomous Robotic Systems 2011 ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012000462",
author = "Giulio Reina and Annalisa Milella and James Underwood",
keywords = "Field robotics",
keywords = "Radar-based perception",
keywords = "Self-learning classifier ",
abstract = "Autonomous driving is a challenging problem in mobile robotics, particularly when the domain is unstructured, as in an outdoor setting. In addition, field scenarios are often characterized by low visibility as well, due to changes in lighting conditions, weather phenomena including fog, rain, snow and hail, or the presence of dust clouds and smoke. Thus, advanced perception systems are primarily required for an off-road robot to sense and understand its environment recognizing artificial and natural structures, topology, vegetation and paths, while ensuring, at the same time, robustness under compromised visibility. In this paper the use of millimeter-wave radar is proposed as a possible solution for all-weather off-road perception. A self-learning approach is developed to train a classifier for radar image interpretation and autonomous navigation. The proposed classifier features two main stages: an adaptive training stage and a classification stage. During the training stage, the system automatically learns to associate the appearance of radar data with class labels. Then, it makes predictions based on past observations. The training set is continuously updated online using the latest radar readings, thus making it feasible to use the system for long range and long duration navigation, over changing environments. Experimental results, obtained with an unmanned ground vehicle operating in a rural environment, are presented to validate this approach. A quantitative comparison with laser data is also included showing good range accuracy and mapping ability as well. Finally, conclusions are drawn on the utility of millimeter-wave radar as a robotic sensor for persistent and accurate perception in natural scenarios. "
}
@article{Li199899,
title = "Uncertainty reasoning based on cloud models in controllers ",
journal = "Computers & Mathematics with Applications ",
volume = "35",
number = "3",
pages = "99 - 123",
year = "1998",
note = "",
issn = "0898-1221",
doi = "https://doi.org/10.1016/S0898-1221(97)00282-4",
url = "http://www.sciencedirect.com/science/article/pii/S0898122197002824",
author = "D. Li and D. Cheung and Xuemei Shi and V. Ng",
keywords = "Uncertainty modeling",
keywords = "Linguistic atom",
keywords = "Compatibility cloud",
keywords = "Virtual cloud",
keywords = "Cloud generator ",
abstract = "The methodology of fuzzy reasoning has been shown to be very useful technology for modeling complex nonlinear systems. However, the most commonly used method for reasoning with fuzzy systems models, the Mamdani-Zadeh paradigm, faces many criticisms, particularly from the probability community. A new mathematical representation of linguistic concepts is presented in this paper. With the new model of normal compatibility clouds and a virtual rule engine, a novel uncertainty reasoning technology is proposed. It not only serves as a foundation of linguistic control, but also integrating fuzziness and randomness in an inseparable way. A case study is given to clean up many doubts raised in the debate between fuzzy theory and probability theory researchers, and to give a good interpretation of the Mamdani-Zadeh operations for the defuzzification strategy as well. The architecture of such a controller shows the advantages in hardware implementations. "
}
@article{Javidrad2011397,
title = "Contour curve reconstruction from cloud data for rapid prototyping ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "27",
number = "2",
pages = "397 - 404",
year = "2011",
note = "Translational Research – Where Engineering Meets Medicine ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584510001079",
author = "F. Javidrad and A.R. Pourmoayed",
keywords = "Reverse engineering",
keywords = "Contour curve",
keywords = "Rapid prototyping",
keywords = "Interval B-spline ",
abstract = "In this study, a method for generation of sectional contour curves directly from cloud point data is given. This method computes contour curves for rapid prototyping model generation via adaptive slicing, data points reducing and B-spline curve fitting. In this approach, first a cloud point data set is segmented along the component building direction to a number of layers. The points are projected to the mid-plane of the layer to form a 2-dimensional (2D) band of scattered points. These points are then utilized to construct a boundary curve. A number of points are picked up along the band and a B-spline curve is fitted. Then points are selected on the B-spline curve based on its discrete curvature. These are the points used as centers for generation of circles with a user-define radius to capture a piece of the scattered band. The geometric center of the points lying within these circles is treated as a control point for a B-spline curve fitting that represents a boundary contour curve. The advantage of this method is simplicity and insensitivity to common small inaccuracies. Two experimental results are included to demonstrate the effectiveness and applicability of the proposed method. "
}
@article{Hiremath201441,
title = "Laser range finder model for autonomous navigation of a robot in a maize field using a particle filter ",
journal = "Computers and Electronics in Agriculture ",
volume = "100",
number = "",
pages = "41 - 50",
year = "2014",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2013.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0168169913002470",
author = "Santosh A. Hiremath and Gerie W.A.M. van der Heijden and Frits K. van Evert and Alfred Stein and Cajo J.F. ter Braak",
keywords = "Probabilistic robotics",
keywords = "Autonomous navigation",
keywords = "Particle filter",
keywords = "Laser range finder ",
abstract = "Abstract Autonomous navigation of robots in an agricultural environment is a difficult task due to the inherent uncertainty in the environment. Many existing agricultural robots use computer vision and other sensors to supplement Global Positioning System (GPS) data when navigating. Vision based methods are sensitive to ambient lighting conditions. This is a major disadvantage in an outdoor environment. The current study presents a novel probabilistic sensor model for a 2D range finder (LIDAR) from first principles. Using this sensor model, a particle filter based navigation algorithm (PF) for autonomous navigation in a maize field was developed. The algorithm was tested in various field conditions with varying plant sizes, different row patterns and at several scanning frequencies. Results showed that the Root Mean Squared Error of the robot heading and lateral deviation were equal to 2.4 degrees and 0.04 m, respectively. It was concluded that the performance of the proposed navigation method is robust in a semi-structured agricultural environment. "
}
@article{Healy201377,
title = "Artificial interfaces (“AI”) in surgery: Historic development, current status and program implementation in the public health sector ",
journal = "Surgical Oncology ",
volume = "22",
number = "2",
pages = "77 - 85",
year = "2013",
note = "",
issn = "0960-7404",
doi = "https://doi.org/10.1016/j.suronc.2012.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S096074041200093X",
author = "Donagh A. Healy and Shane P. Murphy and John P. Burke and John C. Coffey",
keywords = "Robotic colorectal surgery",
keywords = "Da Vinci surgical system",
keywords = "Telepresence",
keywords = "Telerobotics",
keywords = "Robotics ",
abstract = "The past two decades have seen considerable advances in the application of artificial interfaces (AI) in surgery. Several have been developed including \{AESOP\} (Automated Endoscopic System for Optimal Positioning), Zeus and the Da Vinci Surgical System (DVSS). Whilst each has advantages \{DVSS\} is being used increasingly across multiple surgical specialities. These developments generate many challenges in an era where the emphasis is increasingly on safer and cost-effective surgery. Whilst the role of \{DVSS\} is firmly established in urologic and gynaecologic surgery, the role of \{DVSS\} in gastrointestinal surgery is evolving. Recent data indicate that it is at least as oncologically effective, whilst providing numerous benefits (e.g. reduced conversion and complication rates) over traditional laparoscopic approaches. The increasing adoption of AI/DVSS worldwide places institutes and health sectors under increasing pressure to adopt and develop such programs. This article provides (1) an update on the current status of \{AI\} in surgery in general and in colorectal surgery and (2) an appraisal of the cost implications of the establishment and implementation of AI/DVSS–based provisions in the public health sector. The numerous challenges faced generate many opportunities in the implementation of present and future surgical technologies. "
}
@article{Sengupta20131206,
title = "Intelligent Platforms for Disease Assessment: Novel Approaches in Functional Echocardiography ",
journal = "JACC: Cardiovascular Imaging ",
volume = "6",
number = "11",
pages = "1206 - 1211",
year = "2013",
note = "",
issn = "1936-878X",
doi = "https://doi.org/10.1016/j.jcmg.2013.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S1936878X13006529",
author = "Partho P. Sengupta",
keywords = "big data",
keywords = "cognitive computing",
keywords = "echocardiography",
keywords = "parametric imaging",
keywords = "robotics ",
abstract = "Accelerating trends in the dynamic digital era (from 2004 onward) has resulted in the emergence of novel parametric imaging tools that allow easy and accurate extraction of quantitative information from cardiac images. This review principally attempts to heighten the awareness of newer emerging paradigms that may advance acquisition, visualization and interpretation of the large functional data sets obtained during cardiac ultrasound imaging. Incorporation of innovative cognitive software that allow advanced pattern recognition and disease forecasting will likely transform the human-machine interface and interpretation process to achieve a more efficient and effective work environment. Novel technologies for automation and big data analytics that are already active in other fields need to be rapidly adapted to the health care environment with new academic-industry collaborations to enrich and accelerate the delivery of newer decision making tools for enhancing patient care. "
}
@article{Faria2012396,
title = "Extracting data from human manipulation of objects towards improving autonomous robotic grasping ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "396 - 410",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.020",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001527",
author = "Diego R. Faria and Ricardo Martins and Jorge Lobo and Jorge Dias",
keywords = "Human demonstration",
keywords = "Manipulation task representation",
keywords = "Motion pattern",
keywords = "Probabilistic object representation",
keywords = "Contact points",
keywords = "Stable grasp ",
abstract = "Humans excel in manipulation tasks, a basic skill for our survival and a key feature in our manmade world of artefacts and devices. In this work, we study how humans manipulate simple daily objects, and construct a probabilistic representation model for the tasks and objects useful for autonomous grasping and manipulation by robotic hands. Human demonstrations of predefined object manipulation tasks are recorded from both the human hand and object points of view. The multimodal data acquisition system records human gaze, hand and fingers 6D pose, finger flexure, tactile forces distributed on the inside of the hand, colour images and stereo depth map, and also object 6D pose and object tactile forces using instrumented objects. From the acquired data, relevant features are detected concerning motion patterns, tactile forces and hand-object states. This will enable modelling a class of tasks from sets of repeated demonstrations of the same task, so that a generalised probabilistic representation is derived to be used for task planning in artificial systems. An object centred probabilistic volumetric model is proposed to fuse the multimodal data and map contact regions, gaze, and tactile forces during stable grasps. This model is refined by segmenting the volume into components approximated by superquadrics, and overlaying the contact points used taking into account the task context. Results show that the features extracted are sufficient to distinguish key patterns that characterise each stage of the manipulation tasks, ranging from simple object displacement, where the same grasp is employed during manipulation (homogeneous manipulation) to more complex interactions such as object reorientation, fine positioning, and sequential in-hand rotation (dexterous manipulation). The framework presented retains the relevant data from human demonstrations, concerning both the manipulation and object characteristics, to be used by future grasp planning in artificial systems performing autonomous grasping. "
}
@article{Mate201195,
title = "Book Review ",
journal = "Fuzzy Sets and Systems ",
volume = "177",
number = "1",
pages = "95 - 97",
year = "2011",
note = "Theme:Fuzzy Interval Analysis ",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2011.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S016501141100087X",
abstract="",
author = "Carlos G. Mate"
}
@article{Burian201263,
title = "Unified Storage for Laser Scanner Data* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "7",
pages = "63 - 66",
year = "2012",
note = "11th IFAC,IEEE International Conference on Programmable Devices and Embedded Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-CZ-3015.00014",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015350631",
author = "F. Burian and L. Zalud and T. Florian and T. Jilek",
keywords = "Robotics",
keywords = "Self-localization",
keywords = "Map building",
keywords = "Laser mapping ",
abstract = "The main goal of this paper is to show a way to resolve interoperability of more different laser proximity scanners into a mapping engine. The idea is to make a software layer with unified data approach to be able to access laser scanner data from different 2D or 3D proximity scanners in unified way. Presented work is a part of project with the aim to make widely accessible data for self-localization algorithms assessment in mobile robotics. All the described algorithms, source code and scanner data will be accessible on project web-page http://www.mapping.uamt.feec.vutbr.cz. "
}
@article{Halbach2013145,
title = "Job planning and supervisory control for automated earthmoving using 3D graphical tools ",
journal = "Automation in Construction ",
volume = "32",
number = "",
pages = "145 - 160",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513000277",
author = "Eric Halbach and Aarne Halme",
keywords = "Earthmoving",
keywords = "Automation",
keywords = "Robotics",
keywords = "Job planning",
keywords = "Supervisory control",
keywords = "Simulation",
keywords = "3D graphics",
keywords = "Wheel loader",
keywords = "Augmented reality ",
abstract = "Abstract Planning tools and algorithms are presented for enabling supervisory control of automated earthmoving performed by a robotic wheel loader. Interactive 3D graphical objects are rendered over a worksite model, and allow a remote human operator to specify high-level plans for pile transfer and area clearing jobs. These are automatically translated into lower-level plans for the machine to follow and are displayed graphically back to the operator, who then mostly monitors work but can intervene in a supervisory capacity. The tools were developed and tested using Matlab, and were able to guide simulated jobs to completion. Outdoor manually-driven tests using snow were also conducted to verify that heightmaps from a 3D laser rangefinder could be used to correctly track progress and generate commands using the same tools and algorithms. Augmented Reality versions of the tools present a concept of how they could be used in real-world applications. "
}
@incollection{Armbrust2011353,
title = "15 - RAVON: The robust autonomous vehicle for off-road navigation ",
editor = "Baudoin, Y. and ,  and Habib, Maki K. ",
booktitle = "Using Robots in Hazardous Environments ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2011",
pages = "353 - 396",
isbn = "978-1-84569-786-0",
doi = "https://doi.org/10.1533/9780857090201.3.353",
url = "http://www.sciencedirect.com/science/article/pii/B9781845697860500150",
author = "C. Armbrust and T. Braun and T. Fohst and M. Proetzsch and A. Renner and B.H. Schafer and K. Berns",
keywords = "autonomous off-road robotics",
keywords = "topological off-road robot navigation",
keywords = "3D obstacle detection",
keywords = "behaviour-based control architecture",
keywords = "sensor data representation ",
abstract = "Abstract: This chapter describes the work of the Robotics Research Lab at the University of Kaiserslautern in the field of autonomous off-road robotics. It introduces concepts developed for hazard detection, terrain classification, and collision-free autonomous navigation. As an example of a system implementing the described techniques, the mobile off-road robot \{RAVON\} is presented. Experiments have been carried out to prove the effectiveness of the approaches. "
}
@article{Nguyen2013247,
title = "Task and Motion Planning for Apple Harvesting Robot* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "18",
pages = "247 - 252",
year = "2013",
note = "4th \{IFAC\} Conference on Modelling and Control in Agriculture, Horticulture and Post Harvest Industry ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130828-2-SF-3019.00063",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349922",
author = "Tien Thanh Nguyen and Erdal Kayacan and Josse De Baedemaeker and Wouter Saeys",
keywords = "motion planning",
keywords = "robotics",
keywords = "apple",
keywords = "harvesting ",
abstract = "Abstract Selective harvesting for seasonal fruits like apples requires intensive manual labour in a short period; however, due to the delicate property of the fruits, it cannot be performed with an existing commercial machine, which urged to be replaced by robots. The goal of this study is to introduce a framework for motion and hierarchical task planning which allows the manipulator to pick apples in the orchard. The hierarchical task planning assures that the manipulator performs the harvesting task in the higher control level in corporation with other components: sensors system, mobile platform while dealing with the complicated and uncertain environment. The motion planning provides the abilities to the manipulator: to avoid the obstacles, to reach the targets, and to perform the detaching movement elaborated from a limited number of predefined strategies. This motion and task planning framework has been successfully evaluated in simulation, and the real-time tests show that the harvesting task is accomplished with assured communication between sensing, planning and executing. "
}
@article{Ratib2011161,
title = "From \{PACS\} to the clouds ",
journal = "European Journal of Radiology ",
volume = "78",
number = "2",
pages = "161 - 162",
year = "2011",
note = "From \{PACS\} to the clouds ",
issn = "0720-048X",
doi = "https://doi.org/10.1016/j.ejrad.2010.12.097",
url = "http://www.sciencedirect.com/science/article/pii/S0720048X11001331",
abstract="",
author = "Osman Ratib"
}
@article{Birk2012361,
title = "Cooperative Cognitive Control for Autonomous Underwater Vehicles (CO3AUVs): overview and progresses in the 3rd project year ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "5",
pages = "361 - 366",
year = "2012",
note = "3rd \{IFAC\} Workshop on Navigation, Guidance and Control of Underwater Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120410-3-PT-4028.00060",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016306292",
author = "Andreas Birk and Antonio Pascoal and Gianluca Antonelli and Andrea Caiti and Giuseppe Casalino and Giovanni Indiveri and Andrea Caffaz",
keywords = "Marine robotics ",
abstract = "Abstract The paper describes the “Cooperative Cognitive Control for Autonomous Underwater Vehicles (Co3AUVs)” EU-project. This is a 7th Framework Program \{STREP\} project under the theme: Information and Communication Technologies Cognitive Systems, Interaction, Robotics. The project duration is February 2009 to January 2012. The aim of Co3AUVs is to develop, implement and test advanced cognitive systems for coordination and cooperative control of multiple AUVs. Several aspects are investigated including 3D perception and mapping, cooperative situation awareness, deliberation and navigation as well as behavioral control strictly linked with the underwater communication challenges. This paper presents an overview of the project with a focus on results from the final 3rd project year. "
}
@article{Tang2010829,
title = "Automatic reconstruction of as-built building information models from laser-scanned point clouds: A review of related techniques ",
journal = "Automation in Construction ",
volume = "19",
number = "7",
pages = "829 - 843",
year = "2010",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2010.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580510000907",
author = "Pingbo Tang and Daniel Huber and Burcu Akinci and Robert Lipman and Alan Lytle",
keywords = "Building information models",
keywords = "Building reconstruction",
keywords = "Laser scanners",
keywords = "Object recognition",
keywords = "Geometric modeling",
keywords = "Relationship modeling",
keywords = "Shape representation ",
abstract = "Building information models (BIMs) are maturing as a new paradigm for storing and exchanging knowledge about a facility. \{BIMs\} constructed from a \{CAD\} model do not generally capture details of a facility as it was actually built. Laser scanners can be used to capture dense 3D measurements of a facility's as-built condition and the resulting point cloud can be manually processed to create an as-built \{BIM\} — a time-consuming, subjective, and error-prone process that could benefit significantly from automation. This article surveys techniques developed in civil engineering and computer science that can be utilized to automate the process of creating as-built BIMs. We sub-divide the overall process into three core operations: geometric modeling, object recognition, and object relationship modeling. We survey the state-of-the-art methods for each operation and discuss their potential application to automated as-built \{BIM\} creation. We also outline the main methods used by these algorithms for representing knowledge about shape, identity, and relationships. In addition, we formalize the possible variations of the overall as-built \{BIM\} creation problem and outline performance evaluation measures for comparing as-built \{BIM\} creation algorithms and tracking progress of the field. Finally, we identify and discuss technology gaps that need to be addressed in future research. "
}
@article{Silva2011411,
title = "World modeling on an \{MSL\} robotic soccer team ",
journal = "Mechatronics ",
volume = "21",
number = "2",
pages = "411 - 422",
year = "2011",
note = "Special Issue on Advances in intelligent robot design for the Robocup Middle Size League ",
issn = "0957-4158",
doi = "https://doi.org/10.1016/j.mechatronics.2010.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0957415810001029",
author = "Joao Silva and Nuno Lau and Antonio J.R. Neves and Joao Rodrigues and Jose Luis Azevedo",
keywords = "Sensor fusion",
keywords = "World model",
keywords = "Kalman filter",
keywords = "Linear regression",
keywords = "Obstacle detection",
keywords = "Visual matching ",
abstract = "When a team of robots is built with the objective of playing soccer, the coordination and control algorithms must reason, decide and actuate based on the current conditions of the robot and its surroundings. This is where sensor and information fusion techniques appear, providing the means to build an accurate model of the world around the robot, based on its own limited sensor information and the also limited information obtained through communication with the team mates. One of the most important elements of the world model is the robot self-localization, as to be able to decide what to do in an effective way, it must know its position in the field of play. In this paper, the team localization algorithm is presented focusing on the integration of visual and compass information. An important element in a soccer game, perhaps the most important, is the ball. To improve the estimations of the ball position and velocity, two different techniques have been developed. A study of the visual sensor noise is presented and, according to this analysis, the resulting noise variation is used to define the parameters of a Kalman filter for ball position estimation. Moreover, linear regression is used for velocity estimation purposes, both for the ball and the robot. This implementation of linear regression has an adaptive buffer size so that, on hard deviations from the path (detected using the Kalman filter), the regression converges faster. A team cooperation method based on sharing the ball position is presented. Other important data during the soccer game is obstacle data. This is an important challenge for cooperation purposes, allowing the improvement of team strategy with ball covering, dribble corridor estimation, pass lines, among other strategic possibilities. Thus, detecting the obstacles is ceasing to be enough and identifying which obstacles are team mates and opponents is becoming a need. An approach for this identification is presented, considering the visual information, the known characteristics of the team robots and shared localization among team members. The described work was implemented on the \{CAMBADA\} team and allowed it to achieve particularly good performances in the last two years, with a 1st and a 3rd place in the world championship RoboCup 2008 and RoboCup 2009 editions, respectively, as well as distinctively achieve 1st place in 2008 and 2009 editions of the Portuguese Robotics Open. "
}
@article{Sinha2009441,
title = "Multi \{UAV\} Coordination for Tracking the Dispersion of a Contaminant Cloud in an Urban Region ",
journal = "European Journal of Control ",
volume = "15",
number = "3–4",
pages = "441 - 448",
year = "2009",
note = "",
issn = "0947-3580",
doi = "https://doi.org/10.3166/ejc.15.441-448",
url = "http://www.sciencedirect.com/science/article/pii/S0947358009709999",
author = "Arpita Sinha and Antonios Tsourdos and Brian White",
keywords = "path planning",
keywords = "cooperative tracking",
keywords = "sensor network",
keywords = "collision avoidance ",
abstract = "In this paper, we develop a mechanism to detect, model and track the shape of a contaminant cloud boundary using air borne sensor swarms. The cloud consists of a transparent gas of nuclear, biological or chemical contaminants and is spreading slowly in an urban environment. A group of Uninhabited aerial vehicles (UAVs), having the required sensors, are made to fly through the cloud to detect the boundary of the cloud. The shape of the cloud is modeled using splinegon and the movement of the cloud is tracked using an observer. The output of the observer is used in the path planning of the UAVs. A simple path planning algorithm is proposed that along with the observer can accurately track the shape of the moving cloud without the knowledge of the initial boundary of the cloud. Simulated experiments are carried out to test the proposed cloud tracking algorithm. "
}
@article{deLeonardo20131416,
title = "Design of the Locomotion and Docking System of the SwarmItFIX Mobile Fixture Agent ",
journal = "Procedia Engineering ",
volume = "64",
number = "",
pages = "1416 - 1425",
year = "2013",
note = "International Conference on Design and Manufacturing (IConDM2013) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2013.09.223",
url = "http://www.sciencedirect.com/science/article/pii/S1877705813017372",
author = "Luis de Leonardo and Dimiter Zlatanov and Matteo Zoppi and Rezia Molfino",
keywords = "Mobile robots",
keywords = "reconfigurable fixtures",
keywords = "aeronautics",
keywords = "manufacturing",
keywords = "robotics. ",
abstract = "Abstract The European project SwarmItFIX has developed a new highly adaptable self-reconfiguring fixturing system which uses a swarm of mobile agents moving freely on a bench and repositioning in real time to better support the machined part. The project investigates the application of robotic multi-agent fixtures for the support of automotive and airplane body panels during their manufacturing and assembly. Each fixturing robot comprises an adjustable end effector, a parallel manipulator, and a mobile-base-docking-bench module. This paper describes the base-bench subsystem which ensures rapid and precise locomotion, as well as secure docking, of the agent during the machining process. The design addresses with particular care the need for a reliable bench-robot coupling and interface as well as the requirement for robustness of the robot's displacements despite the predicaments of the machining environment, such as flying chips, accumulated swarf, spilled fluids, and vibrations. After a brief review of the state of the art, an overview of the whole project is given. Various candidate robot-base designs and locomotion methods are considered and compared. The final design, selected on the basis of the industrial requirements, is described in detail. A prototype of the SwarmItFIX system has been realized within the project and tested on the premises of an Italian aircraft manufacturer. "
}
@article{Sinha20097,
title = "Monitoring the Dispersion of a Contaminant Cloud in an Urban Region by a Swarm of \{UAV\} Sensors ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "22",
pages = "7 - 12",
year = "2009",
note = "1st \{IFAC\} Workshop on Networked Robotics ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20091006-3-US-4006.00002",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015340106",
author = "Arpita Sinha and Antonios Tsourdos and Brian White",
keywords = "Boundary tracking",
keywords = "UAVs path planning",
keywords = "auction mechanism",
keywords = "splinegon ",
abstract = "Abstract In this paper, we develop a mechanism to detect, model and track the shape of a contaminant cloud boundary using air borne sensor swarms. The cloud consists of a transparent gas of nuclear, biological or chemical contaminants and is spreading slowly in an urban environment. A group of UAVs, having the required sensors, are made to fly through the cloud to detect the boundary of the cloud. The shape of the cloud is modeled using splinegon. An observer is designed to track the movement of the cloud. The output of the observer is used in the path planning of the UAVs. The path planning is online, decentralized and considers obstacle avoidance and connectivity maintenance among the UAVs. Simulated experiments are carried out to test the proposed cloud tracking algorithm. "
}
@article{Ntouskos201310,
title = "Saliency prediction in the coherence theory of attention ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "5",
number = "",
pages = "10 - 28",
year = "2013",
note = "Extended versions of selected papers from the Third Annual Meeting of the \{BICA\} Society (BICA 2012) ",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2013.05.012",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X13000479",
author = "Valsamis Ntouskos and Fiora Pirri and Matia Pizzoli and Arnab Sinha and Bruno Cafaro",
keywords = "Visual attention",
keywords = "Saliency prediction",
keywords = "Proto-objects",
keywords = "Visual search",
keywords = "Cognitive robotics",
keywords = "Cognitive vision ",
abstract = "Abstract In the coherence theory of attention, introduced by Rensink, O’Regan, and Clark (2000), a coherence field is defined by a hierarchy of structures supporting the activities taking place across the different stages of visual attention. At the interface between low level and mid-level attention processing stages are the proto-objects; these are generated in parallel and collect features of the scene at specific location and time. These structures fade away if the region is no further attended by attention. We introduce a method to computationally model these structures. Our model is based experimentally on data collected in dynamic 3D environments via the Gaze Machine, a gaze measurement framework. This framework allows to record pupil motion at the required speed and projects the point of regard in the 3D space (Pirri, Pizzoli, &amp; Rudi, 2011; Pizzoli, Rigato, Shabani, &amp; Pirri, 2011). To generate proto-objects the model is extended to vibrating circular membranes whose initial displacement is generated by the features that have been selected by classification. The energy of the vibrating membranes is used to predict saliency in visual search tasks. "
}
@article{SanchezLopez2013416,
title = "A Real-time 3D Pose Based Visual Servoing Implementation for an Autonomous Mobile Robot Manipulator ",
journal = "Procedia Technology ",
volume = "7",
number = "",
pages = "416 - 423",
year = "2013",
note = "3rd Iberoamerican Conference on Electronics Engineering and Computer Science, \{CIIECC\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.04.052",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313000534",
author = "Jose R. Sanchez-Lopez and Antonio Marin-Hernandez and Elvia R. Palacios-Hernandez and Homero V. Rios-Figueroa and Luis F. Marin-Urias",
keywords = "Autonomous Mobile Manipulator",
keywords = "Visual Servoing",
keywords = "Robotic Arm Control",
keywords = "Mobile Robotics ",
abstract = "Today, the manipulation of objects by mobile robots is still a challenging task. This task is commonly decomposed on three stages: a) approaching to the objects, b) path planning and trajectory execution of the manipulator arm and finally c) fine tuning and grasping. In this work is presented an implementation of a 3D pose visual servoing for an autonomous mobile manipulator dealing with the last stage of the manipulation task (fine tuning and grasping). The methodology proposed consists of three steps: a) beginning with a fast monocular image segmentation, followed by b) 3D model reconstruction and finally c) pose estimation to feedback fine tuning manipulation control loop. Objects and end-effector are colored in different colors and their models are supposed to be known. Our mobile manipulator prototype consists of a stereo camera under a binocular stand-alone configuration and an anthropomorphic 7DoF arm with a parallel end-effector (gripper). Our methodology runs in real time and is suitable to perform continuous visual servoing. Experimental results are reported. "
}
@article{Bedkowski2009569,
title = "Improvement of the Robotic System for Disaster and Hazardous Threat Management ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "13",
pages = "569 - 574",
year = "2009",
note = "14th \{IFAC\} Conference on Methods and Models in Automation and Robotics ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090819-3-PL-3002.00099",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015305024",
author = "Janusz Bedkowski and Jakub Piszczek and Piotr Kowalski and Andrzej Masłowski",
abstract = "Abstract Following paper shows an improvement of the robotic system (Masłowski, 2004 and 2006) for disaster and hazardous threat management. The system uses two types of robots for investigating the potential risks in unknown environment – teleoperated and fully autonomous mobile platform. The teleoperated robot equipped with video cameras and 5DOF arm is used for hazardous materials detection and neutralization. The improvement is based on the autonomous mobile robot development based on hybrid composition of 3D laser scanners providing 3D feedback to base station. The idea of real time 3D map building is shown. The new idea of the usage given map to the supervision module of the robotics system is presented. "
}
@article{Bai2013594,
title = "Self-organized sorting of heterotypic agents via a chemotaxis paradigm ",
journal = "Science of Computer Programming ",
volume = "78",
number = "5",
pages = "594 - 611",
year = "2013",
note = "Special section: Principles and Practice of Programming in Java 2009/2010 &amp; Special section: Self-Organizing Coordination ",
issn = "0167-6423",
doi = "https://doi.org/10.1016/j.scico.2012.10.007",
url = "http://www.sciencedirect.com/science/article/pii/S016764231200192X",
author = "Linge Bai and Manolya Eyiyurekli and Peter I. Lelkes and David E. Breen",
keywords = "Chemotaxis",
keywords = "Self-organization",
keywords = "Sorting",
keywords = "Agents",
keywords = "Swarm robotics ",
abstract = "Cell sorting is a fundamental phenomenon in morphogenesis, a process that leads to shape formation in living organisms. The sorting of heterotypic cell populations is produced by a variety of inter-cellular actions, e.g. differential chemotactic response, adhesion, rigidity, and motility. Via a process called chemotaxis, living cells respond to chemicals released by other cells into the environment. Inspired by the biological phenomena of chemotaxis and cell sorting in heterotypic cell aggregates, we propose a chemotaxis-based algorithm that sorts self-organizing heterotypic agents. In our algorithm, two types of agents are initially randomly placed in a toroidal environment. Agents emit a chemical signal and interact with nearby agents. Given the appropriate parameters, the two kinds of agents self-organize into a complex aggregate consisting of a single group of one type of agent surrounded by agents of the second type. This paper describes the chemotaxis-based sorting algorithm, the behaviors of our self-organizing heterotypic agents, evaluation of the final aggregates and parametric studies of the algorithm. "
}
@article{Johnson201356,
title = "Engineering Uncertainty: The role of uncertainty in the design of complex technological and business systems ",
journal = "Futures ",
volume = "50",
number = "",
pages = "56 - 65",
year = "2013",
note = "Exploring Future Business Visions Using Creative Fictional Prototypes ",
issn = "0016-3287",
doi = "https://doi.org/10.1016/j.futures.2013.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0016328713000529",
author = "Brian David Johnson",
keywords = "Science Fiction Prototypes",
keywords = "Design fictions",
keywords = "Uncertainty",
keywords = "Complex systems",
keywords = "Artificial intelligence",
keywords = "Robotics",
keywords = "Experience design",
keywords = "Future business models ",
abstract = "Abstract Engineering Uncertainty is a Science Fiction Prototype that explores the inevitability of uncertainty in increasingly complex computational and business systems. We explore the human, legal, cultural affects and business affects of embracing uncertainty as an engineering and business practice. This new approach to innovation and design could have radical effects on current business theory and practices. "
}
@article{Cooper2009625,
title = "Comparison of robotic and laparoscopic myomectomy: Bedient et al ",
journal = "American Journal of Obstetrics and Gynecology ",
volume = "201",
number = "6",
pages = "625 - 627",
year = "2009",
note = "",
issn = "0002-9378",
doi = "https://doi.org/10.1016/j.ajog.2009.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S0002937809010229",
author = "Amber R. Cooper and Matthew A. Powell and Patricia T. Jimenez and Matrika D. Johnson and Anna Rabinov and Anna S. Graseck",
abstract = "The article below summarizes a roundtable discussion of a study published in this issue of the Journal in light of its methodology, relevance to practice, and implications for future research. Article discussed: Bedient CE, Magrina JF, Noble BN, et al. Comparison of robotic and laparoscopic myomectomy. Am J Obstet Gynecol 2009;201:566.e1-5. The full discussion appears at www.AJOG.org, pages e1-e4. "
}
@article{RoviraMas2012278,
title = "Global-referenced navigation grids for off-road vehicles and environments ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "2",
pages = "278 - 287",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011002107",
author = "Francisco Rovira-Mas",
keywords = "Off-road vehicles",
keywords = "Autonomous navigation",
keywords = "Grid maps",
keywords = "Stereoscopic vision",
keywords = "Global positioning",
keywords = "Agricultural robotics ",
abstract = "The presence of automation and information technology in agricultural environments seems no longer questionable; smart spraying, variable rate fertilizing, or automatic guidance are becoming usual management tools in modern farms. Yet, such techniques are still in their nascence and offer a lively hotbed for innovation. In particular, significant research efforts are being directed toward vehicle navigation and awareness in off-road environments. However, the majority of solutions being developed are based on occupancy grids referenced with odometry and dead-reckoning, or alternatively based on \{GPS\} waypoint following, but never based on both. Yet, navigation in off-road environments highly benefits from both approaches: perception data effectively condensed in regular grids, and global references for every cell of the grid. This research proposes a framework to build globally referenced navigation grids by combining three-dimensional stereo vision with satellite-based global positioning. The construction process entails the in-field recording of perceptual information plus the geodetic coordinates of the vehicle at every image acquisition position, in addition to other basic data as velocity, heading, or \{GPS\} quality indices. The creation of local grids occurs in real time right after the stereo images have been captured by the vehicle in the field, but the final assembly of universal grids takes place after finishing the acquisition phase. Vehicle-fixed individual grids are then superposed onto the global grid, transferring original perception data to universal cells expressed in Local Tangent Plane coordinates. Global referencing allows the discontinuous appendage of data to succeed in the completion and updating of navigation grids along the time over multiple mapping sessions. This methodology was validated in a commercial vineyard, where several universal grids of the crops were generated. Vine rows were correctly reconstructed, although some difficulties appeared around the headland turns as a consequence of unreliable heading estimations. Navigation information conveyed through globally referenced regular grids turned out to be a powerful tool for upcoming practical implementations within agricultural robotics. "
}
@article{Rossi2013139,
title = "Robot trajectory planning by assigning positions and tangential velocities ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "139 - 156",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000415",
author = "Cesare Rossi and Sergio Savino",
keywords = "Robotics",
keywords = "Robot mechanics",
keywords = "Trajectory planning ",
abstract = "A technique for the robot trajectory planning is proposed. The technique mainly consists in controlling a manipulator by assigning not only the way points on the path but also the geometrical tangent of the desired path shape at each of those points. This is achieved by assigning to the control system not only the joint variables { q i } , but also the vector values { q ̇ i } of the velocities that the joints must have when the end-effector passes through each of those trajectory points. In this way if a path is defined by a same number of points, the proposed technique permits to achieve more accurate paths than those obtained by a traditional point to point technique. Finally, some examples are presented making comparisons on same trajectories assigned by different techniques and also an example of a elaborate surface. "
}
@article{Weiss2011265,
title = "Plant detection and mapping for agricultural robots using a 3D \{LIDAR\} sensor ",
journal = "Robotics and Autonomous Systems ",
volume = "59",
number = "5",
pages = "265 - 273",
year = "2011",
note = "Special Issue \{ECMR\} 2009 ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.02.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011000315",
author = "Ulrich Weiss and Peter Biber",
keywords = "Individual plant detection",
keywords = "Plant mapping",
keywords = "3D \{LIDAR\} sensor",
keywords = "Agricultural robotics ",
abstract = "In this article, we discuss the advantages of \{MEMS\} based 3D \{LIDAR\} sensors over traditional approaches like vision or stereo vision in the domain of agricultural robotics and compare these kinds of sensors with typical 3D sensors used on mobile robots. Further, we present an application for such sensors. This application deals with the detection and segmentation of plants and ground, which is one important prerequisite to perform localization, mapping and navigation for autonomous agricultural robots. We show the discrimination of ground and plants as well as the mapping of the plants. Experiments conducted using the \{FX6\} \{LIDAR\} by Nippon Signal were carried out in the simulation environment Gazebo, with artificial maize plants in the laboratory and on a small maize field. Our results show that the tested plants can be reliably detected and segmented from ground, despite the use of the low resolution \{FX6\} sensor. Further, the plants can be localized with high accuracy. "
}
@article{Siebert20141,
title = "Mobile 3D mapping for surveying earthwork projects using an Unmanned Aerial Vehicle (UAV) system ",
journal = "Automation in Construction ",
volume = "41",
number = "",
pages = "1 - 14",
year = "2014",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2014.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0926580514000193",
author = "Sebastian Siebert and Jochen Teizer",
keywords = "Global positioning system (GPS)",
keywords = "Laser scanning",
keywords = "Photogrammetry",
keywords = "Robotic total station (RTS)",
keywords = "Robotic total station (RTS)",
keywords = "Airplane and helicopters",
keywords = "Remotely piloted vehicles (RPV)",
keywords = "Unmanned aerial vehicle (UAV) systems (UAS)",
keywords = "3D range point cloud generation and mapping",
keywords = "Autonomous vision-based infrastructure sensing",
keywords = "Efficiency, productivity, and safety in geomatics and surveying ",
abstract = "Abstract Unmanned Aerial Vehicle (UAV) systems as a data acquisition platform and as a measurement instrument are becoming attractive for many surveying applications in civil engineering. Their performance, however, is not well understood for these particular tasks. The scope of the presented work is the performance evaluation of a \{UAV\} system that was built to rapidly and autonomously acquire mobile three-dimensional (3D) mapping data. Details to the components of the \{UAV\} system (hardware and control software) are explained. A novel program for photogrammetric flight planning and its execution for the generation of 3D point clouds from digital mobile images is explained. A performance model for estimating the position error was developed and tested in several realistic construction environments. Test results are presented as they relate to large excavation and earth moving construction sites. The experiences with the developed \{UAV\} system are useful to researchers or practitioners in need for successfully adapting \{UAV\} technology for their application(s). "
}
@article{Elor201259,
title = "A “thermodynamic” approach to multi-robot cooperative localization ",
journal = "Theoretical Computer Science ",
volume = "457",
number = "",
pages = "59 - 75",
year = "2012",
note = "",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2012.06.038",
url = "http://www.sciencedirect.com/science/article/pii/S030439751200655X",
author = "Yotam Elor and Alfred M. Bruckstein",
keywords = "Localization",
keywords = "Cooperative localization",
keywords = "Multi-agent",
keywords = "Multi-robot",
keywords = "Distributed robotics",
keywords = "Odometry",
keywords = "Dead reckoning ",
abstract = "We propose a new approach to the simultaneous cooperative localization of a very large group of simple robots capable of performing dead-reckoning and sensing the relative position of nearby robots. In the last decade, the use of distributed optimal Kalman filters (KF) to address this problem has been studied extensively. In this paper, we propose to use a very simple encounter based averaging process (denoted by EA). The idea behind \{EA\} is the following: every time two robots meet, they simply average their location estimates. We assume that two robots meet whenever they are close enough to allow relative location estimation and communication. At each meeting event, the robots average their location estimations thus reducing the localization error. Naturally, the frequency of the meetings affects the localization quality. The meetings are determined by the robots’ movement pattern. In this work we consider movement patterns which are “well mixing”, i.e. every robot meets other robots and eventually all of the robots frequently. For such a movement pattern, the time course of the expected localization error is derived. We prove that \{EA\} is asymptotically optimal and requires significantly less computation and communication resources than KF. "
}
@article{Newman20101253,
title = "The \{NASA\} robotic conjunction assessment process: Overview and operational experiences ",
journal = "Acta Astronautica ",
volume = "66",
number = "7–8",
pages = "1253 - 1261",
year = "2010",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2009.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094576509004913",
author = "Lauri Kraft Newman",
keywords = "Conjunction assessment",
keywords = "Collision avoidance ",
abstract = "Orbital debris poses a significant threat to spacecraft health and safety. Recent events such as China's anti-satellite test and the Breeze-M rocket explosion have led to an even greater awareness and concern in the satellite community. Therefore, the National Aeronautics and Space Administration (NASA) has established requirements that routine conjunction assessment screening shall be performed for all maneuverable spacecraft having perigees &lt;2000 km or within 200 km of geosynchronous altitude. NASA's Goddard Space Flight Center (GSFC) has developed an operational collision risk assessment process to protect NASA's high-value unmanned (robotic) assets that has been in use since January 2005. This paper provides an overview of the \{NASA\} robotic conjunction assessment process, including descriptions of the new tools developed to analyze close approach data and of the risk mitigation strategies employed. In addition, statistical data describing the number of conjunctions experienced are presented. A debris avoidance maneuver performed by Aura in June of 2008 is described in detail to illustrate the process. "
}
@incollection{Johnsen2013508,
title = "20 - Underwater hyperspectral imagery to create biogeochemical maps of seafloor properties ",
editor = "Watson, John and ,  and Zielinski, Oliver ",
booktitle = "Subsea Optics and Imaging ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2013",
pages = "508 - 540e",
series = "Woodhead Publishing Series in Electronic and Optical Materials",
isbn = "978-0-85709-341-7",
doi = "https://doi.org/10.1533/9780857093523.3.508",
url = "http://www.sciencedirect.com/science/article/pii/B9780857093417500200",
author = "G. Johnsen and Z. Volent and H. Dierssen and R. Pettersen and M.Van Ardelan and F. SOreide and P. Fearns and M. Ludvigsen and M. Moline",
keywords = "underwater hyperspectral imagery (UHI)",
keywords = "underwater robotics",
keywords = "identifying biogeochemical OOI",
keywords = "digital maps of OOI",
keywords = "optical fingerprints ",
abstract = "Abstract: This chapter presents aspects of underwater hyperspectral imaging (UHI) techniques aimed at mapping biogeochemical objects of interest (OOI) on the seafloor. Case examples of instrument-carrying platforms and biogeochemical applications are given. We discuss how to create high resolution, georeferenced, optically corrected digital underwater maps of different habitats, minerals, substrates, and organisms. Corrections for platform speed and direction, inherent optical properties (IOP), optical path length, dynamic positioning, and pitch/roll/yaw are discussed in the context of using UHI-based optical fingerprints (i.e. spectral reflectance in visible wavelengths) of different targets to create maps that can help discriminate, identify, and quantify OOI, and provide statistical information on relevant seafloor features. "
}
@article{Srinivasa201254,
title = "A bio-inspired kinematic controller for obstacle avoidance during reaching tasks with real robots ",
journal = "Neural Networks ",
volume = "35",
number = "",
pages = "54 - 69",
year = "2012",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2012.07.010",
url = "http://www.sciencedirect.com/science/article/pii/S0893608012001906",
author = "Narayan Srinivasa and Rajan Bhattacharyya and Rashmi Sundareswara and Craig Lee and Stephen Grossberg",
keywords = "Learning",
keywords = "Reach",
keywords = "Robotics",
keywords = "Obstacle avoidance",
keywords = "ART",
keywords = "DIRECT",
keywords = "Attentional shroud",
keywords = "Inverse model",
keywords = "Motor control ",
abstract = "This paper describes a redundant robot arm that is capable of learning to reach for targets in space in a self-organized fashion while avoiding obstacles. Self-generated movement commands that activate correlated visual, spatial and motor information are used to learn forward and inverse kinematic control models while moving in obstacle-free space using the Direction-to-Rotation Transform (DIRECT). Unlike prior \{DIRECT\} models, the learning process in this work was realized using an online Fuzzy \{ARTMAP\} learning algorithm. The DIRECT-based kinematic controller is fault tolerant and can handle a wide range of perturbations such as joint locking and the use of tools despite not having experienced them during learning. The \{DIRECT\} model was extended based on a novel reactive obstacle avoidance direction (DIRECT-ROAD) model to enable redundant robots to avoid obstacles in environments with simple obstacle configurations. However, certain configurations of obstacles in the environment prevented the robot from reaching the target with purely reactive obstacle avoidance. To address this complexity, a self-organized process of mental rehearsals of movements was modeled, inspired by human and animal experiments on reaching, to generate plans for movement execution using DIRECT-ROAD in complex environments. These mental rehearsals or plans are self-generated by using the Fuzzy \{ARTMAP\} algorithm to retrieve multiple solutions for reaching each target while accounting for all the obstacles in its environment. The key aspects of the proposed novel controller were illustrated first using simple examples. Experiments were then performed on real robot platforms to demonstrate successful obstacle avoidance during reaching tasks in real-world environments. "
}
@article{Barfoot2010671,
title = "Field testing of robotic technologies to support ground ice prospecting in martian polygonal terrain ",
journal = "Planetary and Space Science ",
volume = "58",
number = "4",
pages = "671 - 681",
year = "2010",
note = "Exploring other worlds by exploring our own: The role of terrestrial analogue studies in planetary exploration ",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2009.09.021",
url = "http://www.sciencedirect.com/science/article/pii/S0032063309002852",
author = "Timothy D. Barfoot and Paul T. Furgale and Gordon R. Osinski and Nadeem Ghafoor and Kevin K. Williams",
keywords = "Planetary exploration",
keywords = "Ground-penetrating radar",
keywords = "Lidar",
keywords = "Stereo camera",
keywords = "Planetary rover",
keywords = "Analogue studies ",
abstract = "Polygonal terrain, a landform commonly associated with the presence of ground ice, is widespread throughout the high latitudes on Mars. In this paper, we present the results of field testing a potential mission concept for the robotic prospecting of ground ice in polygonal terrain. The focus of the paper is on the key robotic technologies that could be used to implement the concept and the engineering lessons we learned (as opposed to the specific scientific findings of our field tests). In particular, we have found that a lander- or rover-mounted lidar and a rover-borne stereo camera/ground-penetrating radar suite are two important scientific tools that may be used to help pin-point ground ice prior to subsurface sampling. We field tested some aspects of this mission concept on a previously - unstudied polygonal terrain site on Devon Island in the Canadian High Arctic (a common Mars/Moon analogue site) during the summer of 2008. This unique collaboration between technological and scientific communities has led to a deeper understanding of how such a science-driven mission could actually be implemented robotically. "
}
@article{Bernshausen20116851,
title = "Mobile Robot Self Localization and 3D Map Building using a 3D PMD-Camera for tele-robotic applications ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "6851 - 6856",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.01481",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016447063",
author = "Jens Bernshausen and Chanin Joochim and Hubert Roth",
keywords = "\{PMD\} camera",
keywords = "sensor and data fusion",
keywords = "remote sensor data acquisition",
keywords = "mobile robots",
keywords = "telerobotics",
keywords = "self localization",
keywords = "3D map building ",
abstract = "Abstract This work purposes using a 3D \{PMD\} camera as a sensor for mobile robot applications. The use of image sensors for environment detection is substantial and common usage in mobile robot exploration. Laser scanners, 3D stereo vision or a combination of them are be used generally. The \{PMD\} camera is a novel 3D measuring system, which is based on a time-of-flight principle. The main feature is an array sensor, which can measure the distance to the target without scanning. This relatively new technology offers a cost-effective alternative to the mentioned sensors. In the following we present methods for self-localization and 3D map building by remote sensor data acquisition. This allows the teleoperative control of a mobile robot in an unknown environment. To enhance the mobile robot tasks, a \{CCD\} and the \{PMD\} camera are registered in order to create the three dimensional mapping. The \{CCD\} texture data will be overlaid with the \{PMD\} depth data to increase the accuracy of the lateral resolution. The visual input from the \{CCD\} camera not only delivers high resolution texture data, it can also apply for object recognition in clutter environment. "
}
@article{Mandow20101239,
title = "Fast range-independent spherical subsampling of 3D laser scanner points and data reduction performance evaluation for scene registration ",
journal = "Pattern Recognition Letters ",
volume = "31",
number = "11",
pages = "1239 - 1250",
year = "2010",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2010.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0167865510000899",
author = "Anthony Mandow and Jorge L. Martinez and Antonio J. Reina and Jesus Morales",
keywords = "3D measurement system",
keywords = "Laser ranging",
keywords = "Point subsampling",
keywords = "Scene registration",
keywords = "Mobile robotics",
keywords = "Point matching ",
abstract = "Three-dimensional laser range-finders are increasingly being incorporated into applications, such as mobile robotics, that require real-time registration of scene data. However, the computational costs of adaptive range-dependent data selection and point cloud matching grow significantly with the number of points. Therefore, fast range-independent subsampling by uniform or random data reduction is usually performed at a preprocessing step. The paper proposes a new range-independent subsampling algorithm that is more effective for the widely used spherical scanning mechanism. As this type of device measures the ranges by composition of two rotations, it samples certain directions with a higher density, which can distort the registration optimization process. The proposed solution uses sensor characteristics to equalize the measure-direction density of the reduced point cloud. The paper also addresses performance assessment of subsampling methods by contributing three benchmark criteria that do not rely on a particular registration technique: one considers the ground truth transformation between two scans, and the other two are based on the analysis of a single scan. The advantages of spherical subsampling are analyzed through a comparison of range-independent methods and a simple range-dependent one with real scans from three representative scenes (urban, natural, and indoors). "
}
@article{Hung2012170,
title = "Multi-class predictive template for tree crown detection ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "68",
number = "",
pages = "170 - 183",
year = "2012",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612000366",
author = "Calvin Hung and Mitch Bryson and Salah Sukkarieh",
keywords = "Agriculture",
keywords = "Forestry",
keywords = "Vision",
keywords = "Mapping",
keywords = "Engineering",
keywords = "Robotics ",
abstract = "This paper presents a novel approach for automatic segmentation and object detection of tree crowns in airborne images captured from a low-flying Unmanned Aerial Vehicle (UAV) in ecology monitoring applications. Cost effective monitoring in these applications necessitates the use of vision-band-only imaging on the \{UAV\} platform; the reduction in spectral resolution (compared to multi- or hyper-spectral imaging) is balanced by the high spatial resolution available ( ∼ 20 cm/pixel) from the low-flying UAV, when compared to existing satellite or manned-aerial survey data. Our approach to object detection thus uses both geometry and appearance information (through the use of tree shape and shadow information) in addition to spectral information to help accurately distinguish tree crowns within our application. A predictive geometric template for tree detection is constructed using on-board \{UAV\} navigation data, sun lighting information and information about the geometry of the target crown. A two-stage detection algorithm is then used to segment tree crowns based on spectral (colour) information convolved with information from the predictive template. Results of our approach are presented using airborne image data collected from a fixed-wing \{UAV\} during a weed monitoring and mapping mission over farmland in West Queensland, Australia. "
}
@article{HernandezLopez2012196,
title = "Detecting objects using color and depth segmentation with Kinect sensor ",
journal = "Procedia Technology ",
volume = "3",
number = "",
pages = "196 - 204",
year = "2012",
note = "The 2012 Iberoamerican Conference on Electronics Engineering and Computer Science ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2012.03.021",
url = "http://www.sciencedirect.com/science/article/pii/S2212017312002502",
author = "Jose-Juan Hernandez-Lopez and Ana-Linnet Quintanilla-Olvera and Jose-Luis Lopez-Ramirez and Francisco-Javier Rangel-Butanda and Mario-Alberto Ibarra-Manzano and Dora-Luz Almanza-Ojeda",
keywords = "Kinect",
keywords = "Object detection",
keywords = "Mobile robotics",
keywords = "Color segmentation",
keywords = "Depth segmentation ",
abstract = "In order to optimize the movements of a robot, every object found in the work environment must not just be identiﬁed, but located in reference to the robot itself. Usually, object segmentation from an image is achieved using color segmentation. This segmentation can be achieved by processing the R, G and B chromatic components. However, this method has the disadvantage of been very sensitive to the changes on lighting. Converting the \{RGB\} image to the CIE-Lab color space avoids the lack of sensitivity by increasing the accuracy of the color segmentation. Unfortunately, if multiple objects of the same color are presented in the scene, is not possible to identify one of these objects using only this color space. Therefore, we need to consider an additional data source, in this case the depth, in order to discriminate objects that are not in the same plane as the object of interest. In this paper, we introduce an algorithm to detect objects, essentially on indoor environments, using CIE-Lab and depth segmentation techniques. We process the color and depth images provided by the Kinect sensor for proposing a visual strategy with real-time performance "
}
@article{Kappler2012411,
title = "Templates for pre-grasp sliding interactions ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "411 - 423",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001473",
author = "Daniel Kappler and Lillian Y. Chang and Nancy S. Pollard and Tamim Asfour and Rudiger Dillmann",
keywords = "Pre-grasp interaction",
keywords = "Object manipulation",
keywords = "Humanoid robotics",
keywords = "Pushing",
keywords = "Sliding ",
abstract = "In manipulation tasks that require object acquisition, pre-grasp interaction such as sliding adjusts the object in the environment before grasping. This change in object placement can improve grasping success by making desired grasps reachable. However, the additional sliding action prior to grasping introduces more complexity to the motion planning process, since the hand pose relative to the object does not need to remain fixed during the pre-grasp interaction. Furthermore, anthropomorphic hands in humanoid robots have several degrees of freedom that could be utilized to improve the object interaction beyond a fixed grasp shape. We present a framework for synthesizing pre-grasp interactions for high-dimensional anthropomorphic manipulators. The motion planning is tractable because information from pre-grasp manipulation examples reduces the search space to promising hand poses and shapes. In particular, we show the value of organizing the example data according to object category templates. The template information focuses the search based on the object features, resulting in increased success of adapting a template pose and decreased planning time. "
}
@article{Blackmore20101,
title = "FutureFarm: Addressing the needs of the European farm of the future: Findings of the first two years ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "26",
pages = "1 - 17",
year = "2010",
note = "3rd \{IFAC\} Conference in Modelling and Control in Agriculture, Horticulture and Post-Harvest Processing - Agricontrol ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20101206-3-JP-3009.00003",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015310314",
author = "Simon Blackmore and Katerina Apostolidi and Spyros Fountas",
keywords = "Management Information System",
keywords = "Economic and environmental impact",
keywords = "precision farming",
keywords = "robotics",
keywords = "agricultural standards ",
abstract = "Abstract In the future, European farmers will have to effectively manage information on and off their farms to improve economic viability and to reduce environmental impact. To this end, an integrated information system is needed to advise managers of formal instructions, recommended guidelines and implications resulting from different scenarios at the point of decision making during the crop cycle. This will be enabled through better decision making by the farm managers with the help of a management information system. Such an information system has been defined; both its internal parts and the required infrastructure to support it. FutureFarm is an \{EU\} funded 3-year project involving 15 partners from 10 \{EU\} countries. The project addresses wide issues of development from public awareness, decision support, compliance to recognized management standards, socio-economic impact, energy efficiency, biofuels and robotics. The core technology has to take the already extensive experience in Precision Farming research and integrate it into a farmer-based prototype system. In FutureFarm the appropriate tools and technologies have been conceptually designed, prototypes developed and evaluated under practical conditions. Precision Farming as well as robotics are very data intensive and provide a wealth of information that helps to improve crop management and documentation. Based on these technologies a Farm Information Management System has been developed to deal with the information intensive farm of the future. This paper describes the outcomes of the FutureFarm project for the first two years of its duration. "
}
@article{Hanly200419,
title = "Robotic abdominal surgery ",
journal = "The American Journal of Surgery ",
volume = "188",
number = "4, Supplement 1",
pages = "19 - 26",
year = "2004",
note = "",
issn = "0002-9610",
doi = "https://doi.org/10.1016/j.amjsurg.2004.08.020",
url = "http://www.sciencedirect.com/science/article/pii/S000296100400371X",
author = "Eric J. Hanly and Mark A. Talamini",
abstract = "As a whole, abdominal surgeons possess excellent videoendoscopic surgical skills. However, the limitations of laparoscopy—such as reduced range of motion and instrument dexterity and 2-dimensional view of the operative field—have inspired even the most accomplished laparoscopists to investigate the potential of surgical robotics to broaden their application of the minimally invasive surgery paradigm. This review discusses data obtained from articles indexed in the \{MEDLINE\} database written in English and mapped to the following key words: “surgical robotics,” “robotic surgery,” “robotics,” “computer-assisted surgery,” “da Vinci,” “Zeus,” “fundoplication,” “morbid obesity,” “hepatectomy,” “pancreatectomy,” “small intestine,” “splenectomy,” “colectomy,” “adrenalectomy,” and “pediatric surgery.” A limited subset of 387 publications was reviewed to determine article relevance to abdominal robotic surgery. Particular emphasis was placed on reports that limited their discussion to human applications and surgical outcomes. Included are comments about the initial 202 robotic abdominal surgery cases performed at Johns Hopkins University Hospital (Baltimore, MD) from August 2000 to January 2004. Surgical robotic systems are being used to apply laparoscopy to the surgical treatment of diseases in virtually every abdominal organ. Procedures demanding superior visualization or requiring complex reconstruction necessitating extensive suturing obtain the greatest benefit from robotics over conventional laparoscopy. Whereas advanced surgical robotic systems offer the promise of a unique combination of advantages over open and conventional laparoscopic approaches, clinical data demonstrating improved outcomes are lacking for robotic surgical applications within the abdomen. Outcomes data for surgical robotics are essential given the exorbitant costs associated with the use of these tools. "
}
@article{Liu2008576,
title = "Automatic segmentation of unorganized noisy point clouds based on the Gaussian map ",
journal = "Computer-Aided Design ",
volume = "40",
number = "5",
pages = "576 - 594",
year = "2008",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2008.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448508000419",
author = "Yu Liu and Youlun Xiong",
keywords = "Segmentation",
keywords = "Clustering",
keywords = "Gaussian map",
keywords = "Mean shift",
keywords = "Dimensional analysis ",
abstract = "A nonparametric clustering algorithm, called cell mean shift (CMS), is developed to extract clusters of a set of points on the Gaussian sphere S 2 . It is computationally more efficient than the traditional mean shift (MS). Based on the singular value decomposition, the dimensional analysis is introduced to classify these clusters into point-, curve-, and area-form clusters. Each cluster is the Gaussian image of a set of points which will be examined by a connected search in R 3 . An orientation analysis of the Gaussian map to area-form clusters is applied to identify hyperbolic and elliptical regions. A signed point-to-plane distance function is used to identify points of convex and concave regions. Segmentation results of several real as well as synthetic point clouds, together with complexity analyses, are presented. "
}
@article{Malek2010972,
title = "An architecture-driven software mobility framework ",
journal = "Journal of Systems and Software ",
volume = "83",
number = "6",
pages = "972 - 989",
year = "2010",
note = "Software Architecture and Mobility ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2009.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0164121209002842",
author = "Sam Malek and George Edwards and Yuriy Brun and Hossein Tajalli and Joshua Garcia and Ivo Krka and Nenad Medvidovic and Marija Mikic-Rakic and Gaurav S. Sukhatme",
keywords = "Software architecture",
keywords = "Mobility",
keywords = "Quality of service analysis",
keywords = "Robotics ",
abstract = "Software architecture has been shown to provide an appropriate level of granularity for assessing a software system’s quality attributes (e.g., performance and dependability). Similarly, previous research has adopted an architecture-centric approach to reasoning about and managing the run-time adaptation of software systems. For mobile and pervasive software systems, which are known to be innately dynamic and unpredictable, the ability to assess a system’s quality attributes and manage its dynamic run-time behavior is especially important. In the past, researchers have argued that a software architecture-based approach can be instrumental in facilitating mobile computing. In this paper, we present an integrated architecture-driven framework for modeling, analysis, implementation, deployment, and run-time migration of software systems executing on distributed, mobile, heterogeneous computing platforms. In particular, we describe the framework’s support for dealing with the challenges posed by both logical and physical mobility. We also provide an overview of our experience with applying the framework to a family of distributed mobile robotics systems. This experience has verified our envisioned benefits of the approach, and has helped us to identify several avenues of future work. "
}
@article{Caponetti2011223,
title = "Stochastic automata for outdoor semantic mapping using optimised signal quantisation ",
journal = "Control Engineering Practice ",
volume = "19",
number = "3",
pages = "223 - 233",
year = "2011",
note = "Special Section: \{IFAC\} World Congress Application Paper Prize Papers ",
issn = "0967-0661",
doi = "https://doi.org/10.1016/j.conengprac.2010.11.010",
url = "http://www.sciencedirect.com/science/article/pii/S0967066110002571",
author = "Fabio Caponetti and Morten Rufus Blas and Mogens Blanke",
keywords = "Stochastic automata",
keywords = "Robotics",
keywords = "Classification",
keywords = "Probabilistic models",
keywords = "Quantisation ",
abstract = "Autonomous robots require many types of information to obtain intelligent and safe behaviours. For outdoor operations, semantic mapping is essential and this paper proposes a stochastic automaton to localise the robot within the semantic map. For correct modelling and classification under uncertainty, this paper suggests quantising robotic perceptual features, according to a probabilistic description, and then optimising the quantisation. The proposed method is compared with other state-of-the-art techniques that can assess the confidence of their classification. Data recorded on an autonomous agricultural robot are used for verification and the new method is shown to compare very favourably with existing ones. "
}
@article{Beran2011539,
title = "Understanding how children understand robots: Perceived animism in child–robot interaction ",
journal = "International Journal of Human-Computer Studies ",
volume = "69",
number = "7–8",
pages = "539 - 550",
year = "2011",
note = "",
issn = "1071-5819",
doi = "https://doi.org/10.1016/j.ijhcs.2011.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S1071581911000498",
author = "Tanya N. Beran and Alejandro Ramirez-Serrano and Roman Kuzyk and Meghann Fior and Sarah Nugent",
keywords = "Robotics",
keywords = "Children",
keywords = "Developmental psychology",
keywords = "Animism",
keywords = "Child development",
keywords = "Human–robot interaction ",
abstract = "Centuries ago, the existence of life was explained by the presence of a soul (Tylor, 1871). Known as animism, this term was re-defined in the 1970s by Piaget as young children's beliefs that inanimate objects are capable of actions and have life-like qualities. With the development of robots in the 21st century, researchers have begun examining whether animism is apparent in children's impressions of robots. The purpose of this study was to use a model of knowledge structures, or schemata, to examine whether children attribute human qualities of cognition, affect, and behavior to a robot. An experiment was set up at a science center located in a major Western Canadian city, and visitors to the center were invited to participate. A total of 198 children ages 5–16 years (M=8.18 years) with an approximate even number of boys and girls were included. Children completed a semi-structured interview after observing a robot, a small 5 degree of freedom robot arm, perform a block stacking task. Answers to the nine questions about the robot were scored according to whether they referenced humanistic qualities. Results from frequency and content analyses suggest that a significant proportion of children ascribe cognitive, behavioral, and especially affective, characteristics to robots. "
}
@incollection{Gobbi200777,
title = "11 The EV-K2-CNR Pyramid and the \{AERONET\} network (Himalayan atmospheric brown cloud characterization via sunphotometer observations) ",
editor = "Renato Baudo, Gianni Tartari and Elisa Vuillermoz",
booktitle = "Mountains Witnesses of Global Changes Research in the Himalaya and Karakoram: Share-Asia Project",
publisher = "Elsevier",
year = "2007",
volume = "10",
pages = "77 - 82",
series = "Developments in Earth Surface Processes ",
issn = "0928-2025",
doi = "https://doi.org/10.1016/S0928-2025(06)10011-5",
url = "http://www.sciencedirect.com/science/article/pii/S0928202506100115",
author = "Gian Paolo Gobbi and Federico Angelini and Francesca Barnaba and Paolo Bonasoni",
abstract = "A Cimel sunphotometer operating in the framework of the \{AERONET\} project has been installed at the Himalayan Ev-K2-CNR Pyramid (5079 m a.s.l.) in the year 2006, as site Ev-K2-CNR. The observational activity will provide a characterization of the optical and microphysical properties of atmospheric aerosols, in particular of the atmospheric brown cloud (ABC) in the Himalayan region. This paper will describe the Cimel sunphotometer measurement technique, will introduce to the \{AERONET\} programme and will evaluate the contribution of the proposed Ev-K2-CNR \{AERONET\} site to the study of the ABC. "
}
@article{Rusu2008844,
title = "Robots in the kitchen: Exploiting ubiquitous sensing and actuation ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "10",
pages = "844 - 856",
year = "2008",
note = "Network Robot Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.06.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008000912",
author = "Radu Bogdan Rusu and Brian Gerkey and Michael Beetz",
keywords = "Ubiquitous robotics",
keywords = "Sensor network",
keywords = "Software infrastructure",
keywords = "Reusable code ",
abstract = "Our goal is to develop intelligent service robots that operate in standard human environments, automating common tasks. In pursuit of this goal, we follow the ubiquitous robotics paradigm, in which intelligent perception and control, are combined with ubiquitous computing. By exploiting sensors and effectors in its environment, a robot can perform more complex tasks without becoming overly complex itself. Following this insight, we have developed a service robot that operates autonomously in a sensor-equipped kitchen. The robot learns from demonstration, and performs sophisticated tasks, in concert with the network of devices in its environment. We report on the design, implementation, and usage of this system, which is freely available for use, and improvement by others, in the research community. "
}
@article{Aulinas201016,
title = "Submapping \{SLAM\} based on acoustic data from a 6-DOF \{AUV\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "20",
pages = "16 - 21",
year = "2010",
note = "8th \{IFAC\} Conference on Control Applications in Marine Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100915-3-DE-3008.00036",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016334309",
author = "Josep Aulinas and Chee Sing Lee and Joaquim Salvi and Yvan R. Petillot",
keywords = "Autnonomous vehicles",
keywords = "robotics",
keywords = "navigation ",
abstract = "Abstract Autonomous Underwater Vehicles (AUVs) need positioning systems besides the Global Positioning System (GPS), since \{GPS\} does not work in underwater scenarios. Possible solutions are the Simultaneous Localization and Mapping (SLAM) algorithms. \{SLAM\} algorithms aim to build a map while simultaneously localizing the vehicle within this map. However, they offer limited performance when faced with large scale scenarios. For instance, they do not create consistent maps for large areas, mainly because uncertainties increase with the scale of the scenario. In addition, the computational cost increases with the map size. The use of local maps reduces computational cost and improves map consistency. Following this idea, in this paper we propose a new \{SLAM\} approach that uses independent local maps together with a global level stochastic map. The global level contains the relative transformations between local maps. These local maps are updated once a new loop is detected. Local maps that are sharing a high number of features are updated through fusion, maintaining the correlation between landmarks and vehicle. Experimental results on real data obtained from the REMUS-100 \{AUV\} show that our approach is able to obtain large map areas consistently. "
}
@article{Goicoechea2008182,
title = "First robotic monitoring of a lensed quasar: Intrinsic variability of \{SBS\} 0909+532 ",
journal = "New Astronomy ",
volume = "13",
number = "3",
pages = "182 - 193",
year = "2008",
note = "",
issn = "1384-1076",
doi = "https://doi.org/10.1016/j.newast.2007.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S1384107607000875",
author = "L.J. Goicoechea and V.N. Shalyapin and E. Koptelova and R. Gil-Merino and A.P. Zheleznyak and A. Ullan",
keywords = "Gravitational lensing",
keywords = "Galaxies: quasars: general",
keywords = "Galaxies: quasars: individual (SBS 0909+532) ",
abstract = "To go into the details about the variability of the double quasar \{SBS\} 0909+532, we designed a monitoring programme with the 2 m Liverpool Robotic Telescope in the r Sloan filter, spanning 1.5 years from 2005 January to 2006 June. The r-band light curves of the A and B components, several cross-correlation techniques and a large number of simulations (synthetic light curves) lead to a robust delay ΔtBA = −49 ± 6 days (1σ interval) that agrees with our previous results (the B component is leading). Once the time delay and the magnitude offset are known, the magnitude- and time-shifted light curve of image A is subtracted from the light curve of image B. This difference light curve of \{SBS\} 0909+532 is consistent with zero, so any possible extrinsic signal must be very weak, i.e., the observed variability in A and B is basically due to observational noise and intrinsic signal. We then make the combined light curve and analyse its statistical properties (structure functions). The structure function of the intrinsic luminosity is fitted to predictions of simple models of two physical scenarios: accretion disc instabilities and nuclear starbursts. Although, no simple model is able to accurately reproduce the observed trend, symmetric triangular flares in an accretion disc seems to be the best option to account for it. "
}
@article{Li2011324,
title = "Calibration of a multiple axes 3-D laser scanning system consisting of robot, portable laser scanner and turntable ",
journal = "Optik - International Journal for Light and Electron Optics ",
volume = "122",
number = "4",
pages = "324 - 329",
year = "2011",
note = "",
issn = "0030-4026",
doi = "https://doi.org/10.1016/j.ijleo.2010.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0030402610001154",
author = "Jianfeng Li and Ming Chen and Xuebi Jin and Yu Chen and Zhiyong Dai and Zhonghua Ou and Qin Tang",
keywords = "Robotics",
keywords = "Robot vision",
keywords = "Robot \{TCP\} calibration",
keywords = "3-D laser scanner ",
abstract = "A multiple axes 3-D laser scanning system consisting of a portable 3-D laser scanner, a industrial robot and a turntable is demonstrated. By using a criterion sphere, a robot tool center point (TCP) calibration approach is proposed to calibrate the relation between the laser 3-D scanner and the robot end-effector. In this approach, two different translational motions of robot are first made to determine the rotation part, and then at least three different rotational motions are made to determine the translation part. Meanwhile, by using the criterion sphere, a turntable approach is proposed to calibrate the pose of the turntable relative to the robot. In this approach, several rotational angles of turntable and two different heights of the sphere are made to determine the rotational axis of turntable. Experiment is performed on a portable laser scanner mounted on an industrial robot \{ABB\} \{IRB4400\} with a turntable. The experiment results show that the two proposed calibration algorithms are stable and flexible. The application of 3-D measurement is also given to demonstrate the effectiveness and stability of the multiple axes 3-D laser scanning system. "
}
@article{Diner2005495,
title = "The value of multiangle measurements for retrieving structurally and radiatively consistent properties of clouds, aerosols, and surfaces ",
journal = "Remote Sensing of Environment ",
volume = "97",
number = "4",
pages = "495 - 518",
year = "2005",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2005.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0034425705001951",
author = "David J. Diner and Bobby H. Braswell and Roger Davies and Nadine Gobron and Jiannan Hu and Yufang Jin and Ralph A. Kahn and Yuri Knyazikhin and Norman Loeb and Jan-Peter Muller and Anne W. Nolin and Bernard Pinty and Crystal B. Schaaf and Gabriela Seiz and Julienne Stroeve",
keywords = "Multiangle remote sensing",
keywords = "Terra",
keywords = "MISR",
keywords = "CERES",
keywords = "ASTER",
keywords = "MODIS ",
abstract = "Passive optical multiangle observations make possible the retrieval of scene structural characteristics that cannot be obtained with, or require fewer underlying assumptions than, single-angle sensors. Retrievable quantities include aerosol amount over a wide variety of surfaces (including bright targets); aerosol microphysical properties such as particle shape; geometrically-derived cloud-top heights and 3-D cloud morphologies; distinctions between polar clouds and ice; and textural measures of sea ice, ice sheets, and vegetation. At the same time, multiangle data are necessary for accurate retrievals of radiative quantities such as surface and top-of-atmosphere albedos, whose magnitudes are governed by structural characteristics of the reflecting media and which involve angular integration over intrinsically anisotropic intensity fields. Measurements of directional radiation streams also provide independent checks on model assumptions conventionally used in satellite retrievals, such as the application of 1-D radiative transfer theory, and provide data required to constrain more sophisticated, 3-D approaches. In this paper, the value of multiangle remote sensing in establishing physical correspondence and self-consistency between scene structural and radiative characteristics is demonstrated using simultaneous observations from instruments aboard NASA's Terra satellite (MISR, CERES, ASTER, and MODIS). Illustrations pertaining to the remote sensing of clouds, aerosols, ice, and vegetation properties are presented. "
}
@article{Paz2013337,
title = "Modelling Saharan dust transport into the Mediterranean basin with \{CMAQ\} ",
journal = "Atmospheric Environment ",
volume = "70",
number = "",
pages = "337 - 350",
year = "2013",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013000265",
author = "David de la Paz and Michel Vedrenne and Rafael Borge and Julio Lumbreras and Juan Manuel de Andres and Javier Perez and Encarnacion Rodriguez and Angeliki Karanasiou and Teresa Moreno and Elena Boldo and Cristina Linares",
keywords = "Air quality modelling",
keywords = "Dust transport",
keywords = "Particulate matter",
keywords = "CMAQ",
keywords = "DEM",
keywords = "SERCA",
keywords = "Remote sensing",
keywords = "AOT",
keywords = "Saharan dust ",
abstract = "The need for a better quantification of the influence of Saharan dust transport processes on the air quality modelling in the Mediterranean basin led to the formulation of a dust emission module (DEM) integrated into the Air Quality Risk Assessment System for the Iberian Peninsula (SERCA). This paper is focused on the formulation of \{DEM\} based on the \{GOCART\} aerosol model, along with its integration and execution into the air quality model. It also addresses the testing of the module and its evaluation by contrasting results against satellite products such as \{MODIS\} and \{CALIPSO\} and ground-level observations of aerosol optical thickness (AOT) and concentration levels of \{PM10\} for different periods in July 2007. \{DEM\} was found capable of reproducing the spatial (horizontal and vertical) and temporal profiles of Saharan dust outbreaks into the Mediterranean basin and the Atlantic coast of Africa. Moreover, it was observed that its combination with \{CMAQ\} increased the correlation degree between observed and modelled \{PM10\} concentrations at the selected monitoring locations. \{DEM\} also enhanced \{CMAQ\} capabilities to reproduce observed AOT, although significant underestimations remain. The implementation of CMAQ + DEM succeeded in capturing Saharan dust transport into the Iberian Peninsula, with contributions up to 25 and 14 μg m−3 in 1 h and 24 h average \{PM10\} respectively. The general improvement of total \{PM10\} predictions in Spain are however moderate. The analysis of model performance for the main \{PM\} components points out that remaining \{PM10\} underestimation is due to dust local sources missing in the inventories and misrepresentation of organic aerosol processes, which constitutes the main areas for future improvement of \{CMAQ\} capabilities to simulate particulate matter within SERCA. "
}
@article{Wermter2009111,
title = "Multimodal communication in animals, humans and robots: An introduction to perspectives in brain-inspired informatics ",
journal = "Neural Networks ",
volume = "22",
number = "2",
pages = "111 - 115",
year = "2009",
note = "What it Means to Communicate ",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2009.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0893608009000069",
author = "S. Wermter and M. Page and M. Knowles and V. Gallese and F. Pulvermuller and J. Taylor",
keywords = "Multimodal communication",
keywords = "Neural networks",
keywords = "Robotics",
keywords = "Brain-inspired computing ",
abstract = "Recent years have seen convergence in research on brain mechanisms and neurocomputational approaches, culminating in the creation of a new generation of robots whose artificial “brains” respect neuroscience principles and whose “cognitive” systems venture into higher cognitive domains such as planning and action sequencing, complex object and concept processing, and language. The present article gives an overview of selected projects in this general multidisciplinary field. The work reviewed centres on research funded by the \{EU\} in the context of the New and Emergent Science and Technology, NEST, funding scheme highlighting the topic “What it means to be human”. Examples of such projects include learning by imitation (Edici project), examining the origin of human rule-based reasoning (Far), studying the neural origins of language (Neurocom), exploring the evolutionary origins of the human mind (Pkb140404), researching into verbal and non-verbal communication (Refcom), using and interpreting signs (Sedsu), characterising human language by structural complexity (Chlasc), and representing abstract concepts (Abstract). Each of the communication-centred research projects revealed individual insights; however, there had been little overall analysis of results and hypotheses. In the Specific Support Action Nestcom, we proposed to analyse some \{NEST\} projects focusing on the central question “What it means to communicate” and to review, understand and integrate the results of previous communication-related research, in order to develop and communicate multimodal experimental hypotheses for investigation by future projects. The present special issue includes a range of papers on the interplay between neuroinformatics, brain science and robotics in the general area of higher cognitive functions and multimodal communication. These papers extend talks given at the \{NESTCOM\} workshops, at \{ICANN\} (http://www.his.sunderland.ac.uk/nestcom/workshop/icann.html) in Porto and at the first meeting of the Federation of the European Societies of Neuropsychology in Edinburgh in 2008 (http://www.his.sunderland.ac.uk/nestcom/workshop/esn.html). We hope that the collection will give a vivid insight into current trends in the field. "
}
@article{Morse2009875,
title = "Dynamic liquid association: Complex learning without implausible guidance ",
journal = "Neural Networks ",
volume = "22",
number = "7",
pages = "875 - 889",
year = "2009",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2008.10.008",
url = "http://www.sciencedirect.com/science/article/pii/S0893608008002360",
author = "Anthony Morse and Malin Aktius",
keywords = "Echo state networks",
keywords = "Associative learning",
keywords = "Spreading activation",
keywords = "Non-linear associative memory",
keywords = "Cognitive robotics",
keywords = "Conditioning",
keywords = "Priming ",
abstract = "Simple associative networks have many desirable properties, but are fundamentally limited by their inability to accurately capture complex relationships. This paper presents a solution significantly extending the abilities of associative networks by using an untrained dynamic reservoir as an input filter. The untrained reservoir provides complex dynamic transformations, and temporal integration, and can be viewed as a complex non-linear feature detector from which the associative network can learn. Typically reservoir systems utilize trained single layer perceptrons to produce desired output responses. However given that both single layer perceptions and simple associative learning have the same computational limitations, i.e. linear separation, they should perform similarly in terms of pattern recognition ability. Further to this the extensive psychological properties of simple associative networks and the lack of explicit supervision required for associative learning motivates this extension overcoming previous limitations. Finally, we demonstrate the resulting model in a robotic embodiment, learning sensorimotor contingencies, and matching a variety of psychological data. "
}
@article{Azariadis2004607,
title = "Parameterization of clouds of unorganized points using dynamic base surfaces ",
journal = "Computer-Aided Design ",
volume = "36",
number = "7",
pages = "607 - 623",
year = "2004",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(03)00138-6",
url = "http://www.sciencedirect.com/science/article/pii/S0010448503001386",
author = "Phillip N. Azariadis",
keywords = "Parameterization",
keywords = "Reverse engineering",
keywords = "Surface fitting",
keywords = "Base surfaces ",
abstract = "In this paper a new method for parameterizing clouds of unorganized points is presented. The proposed method introduces the notion of dynamic base surfaces (DBS) which are dynamically adapted to the three-dimensional shape implied by the clouds of points. The only assumption regarding the cloud of points is the existence of a boundary defined by a closed path of four curves. The proposed method is based on an iterative procedure where a \{DBS\} is gradually improved approximating more faithfully the fundamental geometry of the cloud of points. Parameterization is achieved by orthogonally projecting the cloud of points onto the DBS. An application of the introduced parameterization method to the well-known surface least-squares fitting is presented which illustrates the effectiveness and the efficiency of the proposed approach. "
}
@article{Azariadis2005109,
title = "Drawing curves onto a cloud of points for point-based modelling ",
journal = "Computer-Aided Design ",
volume = "37",
number = "1",
pages = "109 - 122",
year = "2005",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2004.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448504000892",
author = "Phillip N. Azariadis and Nickolas S. Sapidis",
keywords = "Digital curves",
keywords = "Digital surfaces",
keywords = "Point-based representation",
keywords = "Point projection algorithm",
keywords = "Polylines",
keywords = "Smoothing polylines ",
abstract = "Point-based geometric models are gaining popularity in both the computer graphics and \{CAD\} fields. A related design/modelling problem is the focus of the reported research: drawing curves onto digital surfaces represented by clouds of points. The problem is analyzed and solved, and a set of ‘design tools’ are proposed which allow the user/designer to efficiently perform ‘product development’ (alternative name: ‘detail design’) tasks which require efficient processing of a ‘digital surface’. The primary tool is a robust and efficient point projection algorithm combined with a smoothing technique for producing smooth ‘digital curves’ lying onto the cloud surface. The new design tools are tested on a real-life industrial example with very satisfactory results, which are thoroughly presented in the paper. "
}
@article{Landis2006570,
title = "Robotic exploration of the surface and atmosphere of Venus ",
journal = "Acta Astronautica ",
volume = "59",
number = "7",
pages = "570 - 579",
year = "2006",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2006.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094576506001767",
author = "Geoffrey A. Landis",
abstract = "Venus, the “greenhouse planet,” is a scientifically fascinating place. The \{US\} National Academies of Sciences listed a Venus surface in situ explorer as one of the highest priority planetary science missions. A mission concept for a robotic mission to study the surface and atmosphere of Venus has been designed. The mission includes both surface robots, designed with an operational lifetime of 50 days on the surface of Venus, and also solar-powered airplanes to probe the middle atmosphere. At 450 ∘ C , and with 90 atmospheres of pressure of carbon-dioxide atmosphere, the surface of Venus is a hostile place for operation of a probe. The mission design trade-off looked at three options for surface operation: developing technology to operate at Venus surface temperatures, using an active refrigeration system to lower the temperature inside a “cool electronics enclosure,” or developing a hybrid system, where the computer system and the most temperature-sensitive electronics are on an aerial platform at lower temperature, and less sophisticated surface electronics operate at the ambient surface temperature. This paper presents the mission objectives, discusses the technology options for materials, power systems, electronics, and instruments, and presents a short summary of the mission. "
}
@article{Simond2008777,
title = "What can be done with an embedded stereo-rig in urban environments? ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "9",
pages = "777 - 789",
year = "2008",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2007.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889007001753",
author = "Nicolas Simond and Patrick Rives",
keywords = "Stereo-vision",
keywords = "Mobile robotics",
keywords = "Urban environment",
keywords = "Super-homography",
keywords = "Trajectography",
keywords = "2.5D reconstruction ",
abstract = "The development of the Autonomous Guided Vehicles (AGVs) with urban applications are now possible due to the recent solutions (DARPA Grand Challenge) developed to solve the Simultaneous Localization And Mapping (SLAM) problem: perception, path planning and control. For the last decade, the introduction of \{GPS\} systems and vision have been allowed the transposition of \{SLAM\} methods dedicated to indoor environments to outdoor ones. When the \{GPS\} data are unavailable, the current position of the mobile robot can be estimated by the fusion of data from odometer and/or Inertial Navigation System (INS). We detail in this article what can be done with an uncalibrated stereo-rig, when it is embedded in a vehicle which is going through urban roads. The methodology is based on features extracted on planes: we mainly assume the road at the foreground as the plane common to all the urban scenes but other planes like vertical frontages of buildings can be used if the features extracted on the road are not enough relevant. The relative motions of the coplanar features tracked with both cameras allow us to estimate the vehicle ego-motion with a high precision. Futhermore, the features which don’t check the relative motion of the considered plane can be assumed as obstacles. "
}
@article{Lenac2017197,
title = "Fast planar surface 3D \{SLAM\} using \{LIDAR\} ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "197 - 220",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016303475",
author = "Kruno Lenac and Andrej Kitanov and Robert Cupec and Ivan Petrovic",
keywords = "Mapping",
keywords = "Pose estimation",
keywords = "Point cloud segmentation",
keywords = "Planar surface registration",
keywords = "Planar map",
keywords = "ESDS filter ",
abstract = "Abstract In this paper we propose a fast 3D pose based \{SLAM\} system that estimates a vehicle’s trajectory by registering sets of planar surface segments, extracted from 36 0 ∘ field of view (FOV) point clouds provided by a 3D LIDAR. Full \{FOV\} and planar representation of the map gives the proposed \{SLAM\} system the capability to map large-scale environments while maintaining fast execution time. For efficient point cloud processing we apply image-based techniques to project it to three two-dimensional images. The \{SLAM\} backend is based on Exactly Sparse Delayed State Filter as a non-iterative way of updating the pose graph and exploiting sparsity of the \{SLAM\} information matrix. Finally, our \{SLAM\} system enables reconstruction of the global map by merging the local planar surface segments in a highly efficient way. The proposed point cloud segmentation and registration method was tested and compared with the several state-of-the-art methods on two publicly available datasets. Complete \{SLAM\} system was also tested in one indoor and one outdoor experiment. The indoor experiment was conducted using a research mobile robot Husky \{A200\} to map our university building and the outdoor experiment was performed on the publicly available dataset provided by the Ford Motor Company, in which a car equipped with a 3D \{LIDAR\} was driven in the downtown Dearborn Michigan. "
}
@article{Gunther2017336,
title = "Model-based furniture recognition for building semantic object maps ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "336 - 351",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2014.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S000437021400157X",
author = "Martin Gunther and Thomas Wiemann and Sven Albrecht and Joachim Hertzberg",
keywords = "Semantic map",
keywords = "Incremental mapping",
keywords = "Closed-loop mapping",
keywords = "Model-based object recognition",
keywords = "3D point cloud",
keywords = "CAD model matching",
keywords = "OWL-DL ontology ",
abstract = "Abstract This paper presents an approach to creating a semantic map of an indoor environment incrementally and in closed loop, based on a series of 3D point clouds captured by a mobile robot using an RGB-D camera. Based on a semantic model about furniture objects (represented in an OWL-DL ontology with rules attached), we generate hypotheses for locations and 6DoF poses of object instances and verify them by matching a geometric model of the object (given as a \{CAD\} model) into the point cloud. The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture. We demonstrate the robustness of our approach against occlusion and aperture limitations of the RGB-D frames, and against differences between the \{CAD\} models and the real objects. We evaluate the complete system on two challenging datasets featuring partial visibility and totaling over 800 frames. The results show complementary strengths and weaknesses of processing each frame directly vs. processing the fully registered scene, which accord with intuitive expectations. "
}
@article{Fontmarty2007361,
title = "\{IMPLEMENTATION\} \{OF\} \{HUMAN\} \{PERCEPTION\} \{ALGORITHMS\} \{ON\} A \{MOBILE\} \{ROBOT\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "361 - 366",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00062",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346870",
author = "Mathias Fontmarty and Thierry Germa and Brice Burger and Luis Felipe Marin and Steffen Knoop",
keywords = "Mobile Robotics",
keywords = "Integration",
keywords = "Human Perception ",
abstract = "Abstract During last years, a lot of works in robotic research have explored Human-Robot interactions. Hence, a great challenge in next future will be the personal robot, with perception faculties which will enable a wide range of activities such as human localization and tracking, gesture recognition and interpretation, or object manipulation. In this paper, we will focus on human perception and we will present a human aware system implemented on a mobile robot. This system uses data from various sensors to be able to localize and to track a human presence in a wide range of distances. An exploitation of all these modalities is presented in a demo showing the robot giving an object to a person. "
}
@article{Smirnov2000337,
title = "Cloud-Screening and Quality Control Algorithms for the \{AERONET\} Database ",
journal = "Remote Sensing of Environment ",
volume = "73",
number = "3",
pages = "337 - 349",
year = "2000",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/S0034-4257(00)00109-7",
url = "http://www.sciencedirect.com/science/article/pii/S0034425700001097",
author = "A. Smirnov and B.N. Holben and T.F. Eck and O. Dubovik and I. Slutsker",
abstract = "Automatic globally distributed networks for monitoring aerosol optical depth provide measurements of natural and anthropogenic aerosol loading, which is important in many local and regional studies as well as global change research investigations. The strength of such networks relies on imposing a standardization of measurement and processing, allowing multiyear and large-scale comparisons. The development of the Aerosol Robotic Network (AERONET) for systematic ground-based sunphotometer measurements of aerosol optical depth is an essential and evolving step in this process. The growing database requires the development of a consistent, reproducible, and system-wide cloud-screening procedure. This paper discusses the methodology and justification of the cloud-screening algorithm developed for the \{AERONET\} database. The procedure has been comprehensively tested on experimental data obtained in different geographical and optical conditions. These conditions include biomass burning events in Brazil and Zambia, hazy summer conditions in the Washington \{DC\} area, clean air advected from the Canadian Arctic, and variable cloudy conditions. For various sites our screening algorithm eliminates from ∼20% to 50% of the initial data depending on cloud conditions. Certain shortcomings of the proposed procedure are discussed. "
}
@article{Shao2011181,
title = "Dust cycle: An emerging core theme in Earth system science ",
journal = "Aeolian Research ",
volume = "2",
number = "4",
pages = "181 - 204",
year = "2011",
note = "",
issn = "1875-9637",
doi = "https://doi.org/10.1016/j.aeolia.2011.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S1875963711000085",
author = "Yaping Shao and Karl-Heinz Wyrwoll and Adrian Chappell and Jianping Huang and Zhaohui Lin and Grant H. McTainsh and Masao Mikami and Taichu Y. Tanaka and Xulong Wang and Soonchang Yoon",
keywords = "Dust",
keywords = "Dust cycle",
keywords = "Aeolian processes",
keywords = "Energy cycle",
keywords = "Carbon cycle",
keywords = "Climate change ",
abstract = "The dust cycle is an integral part of the Earth system. Each year, an estimated 2000 Mt dust is emitted into the atmosphere, 75% of which is deposited to the land and 25% to the ocean. The emitted and deposited dust participates in a range physical, chemical and bio-geological processes that interact with the cycles of energy, carbon and water. Dust profoundly affects the energy balance of the Earth system, carries organic material, contributes directly to the carbon cycle and carries iron which is vital to ocean productivity and the ocean-atmosphere \{CO2\} exchange. A deciphering of dust sources, transport and deposition, requires an understanding of the geological controls and climate states – past, present and future. While our knowledge of the dust cycle, its impacts and interactions with the other global-scale bio-geochemical cycles has greatly advanced in the last 30 years, large uncertainties and knowledge gaps still exist. In this review paper, we attempt to provide a benchmark of our present understanding, identify the needs and emphasise the importance of placing the dust issue in the Earth system framework. Our review focuses on (i) the concept of the dust cycle in the context of global biogeochemical cycles; (ii) dust as a climate indicator; (iii) dust modelling; (iv) dust monitoring; and (v) dust parameters. The adoption of a quantitative and global perspective of the dust cycle, underpinned by a deeper understanding of its physical controls, will lead to the reduction of the large uncertainties which presently exist in Earth system models. "
}
@article{Boissenin20071107,
title = "Computer vision methods for optical microscopes ",
journal = "Image and Vision Computing ",
volume = "25",
number = "7",
pages = "1107 - 1116",
year = "2007",
note = "Computer Vision Applications ",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2006.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0262885606002794",
author = "M. Boissenin and J. Wedekind and A.N. Selvan and B.P. Amavasai and F. Caparrelli and J.R. Travis",
keywords = "Computer vision",
keywords = "Microscope imaging",
keywords = "Micro-robotics",
keywords = "Tracking",
keywords = "Depth estimation ",
abstract = "As the fields of micro- and nano-technology mature, there will be an increased need to build tools that are able to work in these areas. Industry will require solutions for assembling and manipulating components, much as it has done in the macro range. With this need in mind, a new set of challenges requiring novel solutions have to be met. One of them is the ability to provide closed-loop feedback control for manipulators. We foresee that machine vision will play a leading role in this area. This paper introduces a technique for integrating machine vision into the field of micro-technology including two methods, one for tracking and one for depth reconstruction under an optical microscope. "
}
@article{ChandranRamesh2007463,
title = "\{ASSESSING\} \{MAP\} \{QUALITY\} \{AND\} \{ERROR\} \{CAUSATION\} \{USING\} \{CONDITIONAL\} \{RANDOM\} \{FIELDS\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "463 - 468",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00079",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016347048",
author = "Manjari Chandran-Ramesh and Paul Newman",
keywords = "Mapping",
keywords = "Map Quality",
keywords = "Navigation",
keywords = "Mobile Robotics ",
abstract = "Abstract This paper is about assessing the quality of maps built by a mobile robot. We extend previous work, which used solely geometric considerations, and use both temporal and spatial properties of the map to perform a binary classification of “plausible” and “suspicious”. The use of the former allows the existence of low quality areas of the map to be attributed to missed loop closure events or local, online mapping errors. With an eye on our intended domain of urban operation, we adopt a Conditional Random Field as the probabilistic framework in which to model the spatial and temporal relationships between planar patches. The map quality labels are derived by using standard graph cuts optimization techniques. The approach is then illustrated with map created of an urban environment using data from a 3D laser range scanner mounted on a mobile robot. "
}
@article{Sermanet2007300,
title = "SPEED-RANGE \{DILEMMAS\} \{FOR\} VISION-BASED \{NAVIGATION\} \{IN\} \{UNSTRUCTURED\} \{TERRAIN\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "300 - 305",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00052",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346778",
author = "Pierre Sermanet and Raia Hadsell and Jan Ben and Ayse Naz Erkan and Beat Flepp and Urs Muller and Yann LeCun",
keywords = "robotics",
keywords = "vision",
keywords = "autonomous navigation",
keywords = "LAGR",
keywords = "control architecture ",
abstract = "Abstract The performance of vision-based navigation systems for off-road mobile robots depends crucially on the resolution of the camera, the sophistication of the visual processing, the latency between image and sensor capture to actuator control, and the period of the control loop. One particularly important design question is whether one should increase the resolution of the camera images, and the range of the obstacle detection algorithms, at the expense of latency and control loop period. We first report experimental results on the resolution-period trade-off with a stereo vision-based navigation system implemented on the \{LAGR\} mobile robot platform. We propose a multi-agent perception and control architecture that combines a sophisticated long-range path detection method operating at high resolution and low frame rate, with a simple stereo-based obstacle detection method operating at low resolution, high frame rate, and low latency. The system combines the advantages of the long-range module for strategic path planning, with the advantages of the short-range module for tactical driving. "
}
@article{Petit2017187,
title = "Tracking elastic deformable objects with an RGB-D sensor for a pizza chef robot ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "187 - 201",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305395",
author = "Antoine Petit and Vincenzo Lippiello and Giuseppe Andrea Fontanelli and Bruno Siciliano",
keywords = "Perception",
keywords = "Deformable object modeling",
keywords = "Registration",
keywords = "Robotic manipulation ",
abstract = "Abstract This paper presents a method for tracking a 3D textureless object which undergoes elastic deformations, using the point cloud data provided by an RGB-D sensor and in real-time. This solution is expected to be useful for enhanced manipulation of humanoid robotic systems, especially in the case of pizza dough to be ideally manipulated by a pizza chef robot. Our tracking framework relies on a prior visual segmentation of the object in the image. The segmented point cloud is registered first in a rigid manner and then by non-rigidly fitting the mesh, based on the Finite Element Method to model elasticity, and on geometrical point-to-point correspondences to compute external forces exerted on the mesh. The system has been evaluated on synthetic and real data, and by integrating it into manipulation experiments on the RoDyMan1 1 http://www.rodyman.eu/. The research leading to these results has been supported by the RoDyMan project, which has received funding from the European Research Council(FP7 IDEAS) under Advanced Grant agreement number 320992. The authors are solely responsible for its content. It does not represent the opinion of the European Community and the Community is not responsible for any use that might be made of the information contained therein. humanoid robotic platform. "
}
@article{Cheng201759,
title = "Modeling of manufacturing service supply–demand matching hypernetwork in service-oriented manufacturing systems ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "59 - 72",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301491",
author = "Ying Cheng and Fei Tao and Dongming Zhao and Lin Zhang",
keywords = "Supply–demand matching",
keywords = "Hypernetwork",
keywords = "Manufacturing service network (S_Net)",
keywords = "Manufacturing task network (T_Net)",
keywords = "Socialization",
keywords = "Cloud manufacturing (CMfg) ",
abstract = "Abstract The supply–demand matching and optimal-allocation of manufacturing resource and manufacturing capability, is always one of the key scientific issues to be addressed and the common objectives to be pursued for various advanced manufacturing systems (AMSs). Especially to the service-oriented manufacturing (SOM) systems (e.g., cloud manufacturing), which is a kind of typical and hot \{AMSs\} nowadays , it is extremely difficult to achieve the optimal allocation of large scales of different manufacturing services and the collaboration of manufacturing activities and business among massive manufacturing enterprises (no matter manufacturing service providers and consumers). Thus, under the current environment of social competition and collaboration, the most important challenge is how to integrate a variety of distributed manufacturing resources and capabilities in the form of manufacturing services efficiently and cost-effectively, as well as various demands or manufacturing tasks. In response to this challenge, the concept of supply–demand matching hypernetwork ( Matching_Net ) of manufacturing services in \{SOM\} system is put forward firstly in this paper. The proposed Matching_Net is constructed with manufacturing service network ( S_Net ), manufacturing task network ( T_Net ), and hyper-edges between those two networks which are revealing the matchable correlations between each service (supply) and each task (demand). Secondly, by comparing with the input or output information of manufacturing services and tasks from the functional view, the intelligent modeling of Matching_Net is illustrated and divided into those three constituent parts respectively. Finally, the simulation is carried out to validate and verify the proposed models and the modeling method. "
}
@article{Moldovan2017,
title = "Elastic systems: Towards cyber-physical ecosystems of people, processes, and things ",
journal = "Computer Standards & Interfaces ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2017.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S092054891630232X",
author = "Daniel Moldovan and Georgiana Copil and Schahram Dustdar",
keywords = "Elasticity",
keywords = "Cloud",
keywords = "IoT",
keywords = "Human-based computing ",
abstract = "Abstract Pervasive mobility and an exponential increase in the number of connected devices are adding to \{IT\} complexity. Users are bypassing traditional \{IT\} to access cloud-based services. Boundaries between computing systems, people, and things are disappearing. New approaches are required to manage today's and tomorrow's increasingly connected and heterogeneous ecosystems of people, computing processes, and things. We envision future elastic systems driven by business requirements, integrating computing, people, and things in open dynamic ecosystems in which all entities collaborate towards common goals. We introduce elasticity as a means of integrating computing processes, people, and things. We identify the core computing fields enabling future elastic systems: (i) hardware and software reusability, (ii) smart things, (iv) adaptation, and (v) human-based computing. We look at the development of these fields, and identify fundamental properties for building future elastic systems. We further envision a new field of research: Elastic Computing. We identify and discuss challenges to be addressed by this field towards realizing future elastic systems: Are existing programming languages and models sufficient for designing and managing future elastic systems? How important are the interactions between people, computers, and things? Can people and things be monitored and controlled like computing resources? "
}
@article{Mishchenko2007325,
title = "Past, present, and future of global aerosol climatologies derived from satellite observations: A perspective ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "106",
number = "1–3",
pages = "325 - 347",
year = "2007",
note = "\{IX\} Conference on Electromagnetic and Light Scattering by Non-Spherical Particles ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2007.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0022407307000192",
author = "Michael I. Mishchenko and Igor V. Geogdzhayev and Brian Cairns and Barbara E. Carlson and Jacek Chowdhary and Andrew A. Lacis and Li Liu and William B. Rossow and Larry D. Travis",
keywords = "Tropospheric aerosols",
keywords = "Remote sensing ",
abstract = "A number of passive satellite instruments have been used to develop global climatologies of terrestrial tropospheric aerosols by analyzing the properties of sunlight reflected by the atmosphere–surface system. The outcome of these efforts are several climatologies which all purport to represent the same aerosol characteristics such as optical thickness and size. However, the quantitative differences between these climatologies have been found to far exceed the corresponding individual uncertainty claims. The magnitude of these differences is alarming and necessitates a detailed critical assessment and integrated analysis that would go far beyond simple intercomparisons of various satellite products and comparisons of satellite aerosol optical thickness results with ground-based sun-photometer data. This paper outlines the framework for a global long-term satellite climatology of aerosol properties based on a consistent combination of previous, current, and near-future satellite retrievals. We also discuss potential future strategies for deriving a much improved aerosol climatology from Earth-orbiting satellites. "
}
@article{Chong1992127,
title = "Cloud height estimation using the visible images from two geosynchronous satellites ",
journal = "Acta Astronautica ",
volume = "26",
number = "2",
pages = "127 - 128",
year = "1992",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/0094-5765(92)90053-L",
url = "http://www.sciencedirect.com/science/article/pii/009457659290053L",
author = "J.Y. Chong and P.S. Toh",
abstract = "The standard technique of deducing the heights of cloud tops from the data acquired by meteorological satellites in geosynchronous orbit is to use radiation emitted in the thermal infrared region of the electromagnetic spectrum. Cloud heights can also be deduced from the radiance in the visible region by using the overlapped images of two adjacent geosynchronous satellites to reconstruct a three-dimensional image. "
}
@article{Nunes2002385,
title = "SPRAY-PAINTING \{MOTION\} \{PLANNING\} \{AND\} \{QUALITY\} \{ANALYSIS\} \{IN\} \{POWDER\} \{COATING\} \{SYSTEMS\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "35",
number = "1",
pages = "385 - 390",
year = "2002",
note = "15th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20020721-6-ES-1901.00066",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015384871",
author = "Urbano Nunes and Antonio Batista and Joao Figueiredo",
keywords = "Automation",
keywords = "Industrial Processes",
keywords = "Process Control",
keywords = "Robotics",
keywords = "Modeling ",
abstract = "Abstract The paper reports results on the automation of the spray-painting process in industrial powder coating plants. The automation of the spray-painting process requires a painting model and the definition of appropriate metrics for painting task validation. Two main topics are addressed in the paper: motion planning of paint deposition and paint quality analysis. A paint quality function is formulated and results concerning experimental analysis are presented. "
}
@article{Choi2017151,
title = "Assessment of the clear-sky bias issue using continuous \{PM10\} data from two \{AERONET\} sites in Korea ",
journal = "Journal of Environmental Sciences ",
volume = "53",
number = "",
pages = "151 - 160",
year = "2017",
note = "",
issn = "1001-0742",
doi = "https://doi.org/10.1016/j.jes.2016.02.020",
url = "http://www.sciencedirect.com/science/article/pii/S1001074216301668",
author = "Yongjoo Choi and Young Sung Ghim",
keywords = "AERONET",
keywords = "Data recovery rate",
keywords = "Cloud amount",
keywords = "Wind speed",
keywords = "Photochemical production",
keywords = "Siberian high ",
abstract = "Abstract A bias in clear-sky conditions that will be involved in estimating particulate matter (PM) concentration from aerosol optical depth (AOD) was examined using \{PM10\} from two Aerosol Robotic Network sites in Korea. The study periods were between 2004 and 2007 at Anmyon and between 2003 and 2011 at Gosan, when both \{PM10\} and \{AOD\} were available. Mean \{PM10\} when \{AOD\} was available (PMAOD) was higher than that from all \{PM10\} data (PMall) by 5.1 and 9.9 μg/m3 at Anmyon and Gosan, which accounted for 11% and 26% of PMall, respectively. Because of a difference between mean \{PM10\} under daytime clear-sky conditions (PMclear) and PMAOD, the variations in ΔPM10, the difference of \{PMall\} from \{PMclear\} rather than from PMAOD, were investigated. Although monthly variations in ΔPM10 at the two sites were different, they were positively correlated to those in ΔT, similarly defined as ΔPM10 except for temperature, at both sites. ΔPM10 at Anmyon decreased to a negative value in January due to an influence of the Siberian continental high-pressure system while ΔPM10 at Gosan was high in winter due to an effect of photochemical production at higher temperatures than at Anmyon. "
}
@article{Kranjc201738,
title = "ClowdFlows: Online workflows for distributed big data mining ",
journal = "Future Generation Computer Systems ",
volume = "68",
number = "",
pages = "38 - 58",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302709",
author = "Janez Kranjc and Roman Orac and Vid Podpecan and Nada Lavrac and Marko Robnik-sikonja",
keywords = "Data mining platform",
keywords = "Cloud computing",
keywords = "Scientific workflows",
keywords = "Batch processing",
keywords = "Map-reduce",
keywords = "Big data ",
abstract = "Abstract The paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. The platform, called ClowdFlows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. As a web application, the ClowdFlows platform poses no software requirements and can be used from any modern browser, including mobile devices. The constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. The server-side software of ClowdFlows can be multiplied and distributed to any number of computing nodes. From a developer’s perspective the platform is easy to extend and supports distributed development with packages. The paper focuses on big data processing in the batch and real-time processing mode. Big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. The batch mode and real-time processing mode are demonstrated with practical use cases. Performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. The ability of ClowdFlows to handle big data sets and its nearly perfect linear speedup is demonstrated. "
}
@article{Madsen1998277,
title = "Optimal landmark selection for triangulation of robot position ",
journal = "Robotics and Autonomous Systems ",
volume = "23",
number = "4",
pages = "277 - 292",
year = "1998",
note = "Intelligent Robotics Systems - SIRS'97 ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/S0921-8890(98)00014-1",
url = "http://www.sciencedirect.com/science/article/pii/S0921889098000141",
author = "Claus B. Madsen and Claus S. Andersen",
keywords = "Triangulation",
keywords = "Self-positioning",
keywords = "Landmarks",
keywords = "Performance characterization",
keywords = "Robustness",
keywords = "Navigation",
keywords = "Mobile robotics",
keywords = "Template matching ",
abstract = "A mobile robot can identify its own position relative to a global environment model by using triangulation based on three landmarks in the environment. It is shown that this procedure may be very sensitive to noise depending on spatial landmark configuration, and relative position between robot and landmarks. A general analysis is presented which permits prediction of the uncertainty in the triangulated position. In addition an algorithm is presented for automatic selection of optimal landmarks. This algorithm enables a robot to continuously base its position computation on the set of available landmarks, which provides the least noise sensitive position estimate. It is demonstrated that using this algorithm can result in more than one order of magnitude reduction in uncertainty. "
}
@article{Xie2016435,
title = "A Fast All-sky Radiation Model for Solar applications (FARMS): Algorithm and performance evaluation ",
journal = "Solar Energy ",
volume = "135",
number = "",
pages = "435 - 445",
year = "2016",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2016.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X16301827",
author = "Yu Xie and Manajit Sengupta and Jimy Dudhia",
keywords = "Solar radiation",
keywords = "Radiative transfer model",
keywords = "Cloud ",
abstract = "Abstract Radiative transfer (RT) models simulating broadband solar radiation have been widely used by atmospheric scientists to model solar resources for various energy applications such as operational forecasting. Due to the complexity of solving the \{RT\} equation, the computation under cloudy conditions can be extremely time consuming though many approximations (e.g. two-stream approach and delta-M truncation scheme) have been utilized. Thus, a more efficient \{RT\} model is crucial for model developers as a new option for approximating solar radiation at the land surface with minimal loss of accuracy. In this study, we developed a fast all-sky radiation model for solar applications (FARMS) using the simplified clear-sky \{RT\} model, REST2, and simulated cloud transmittances and reflectances from Rapid Radiation Transfer Model (RRTM) with a sixteen-stream Discrete Ordinates Radiative Transfer (DISORT). Simulated lookup tables (LUTs) of cloud transmittances and reflectances are created by varying cloud optical thicknesses, cloud particle sizes, and solar zenith angles. Equations with optimized parameters are fitted to the cloud transmittances and reflectances to develop the model. The all-sky solar irradiance at the land surface can then be computed rapidly by combining \{REST2\} with the cloud transmittances and reflectances. This new \{RT\} model is more than 1000 times faster than those currently utilized in solar resource assessment and forecasting since it does not explicitly solve the \{RT\} equation for each individual cloud condition. Our results indicate the accuracy of the fast radiative transfer model is comparable to or better than two-stream approximation in term of computing cloud transmittance and solar radiation. "
}
@article{Rehman20171,
title = "Towards next-generation heterogeneous mobile data stream mining applications: Opportunities, challenges, and future research directions ",
journal = "Journal of Network and Computer Applications ",
volume = "79",
number = "",
pages = "1 - 24",
year = "2017",
note = "",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2016.11.031",
url = "http://www.sciencedirect.com/science/article/pii/S1084804516302995",
author = "Muhammad Habib ur Rehman and Chee Sun Liew and Teh Ying Wah and Muhammad Khurram Khan",
keywords = "Frequent pattern mining",
keywords = "Classification",
keywords = "Clustering",
keywords = "Mobile computing",
keywords = "Cloud computing",
keywords = "Edge computing ",
abstract = "Abstract The convergence of Internet of Things (IoTs), mobile computing, cloud computing, edge computing and big data has brought a paradigm shift in computing technologies. New computing systems, application models, and application areas are emerging to handle the massive growth of streaming data in mobile environments such as smartphones, IoTs, body sensor networks, and wearable devices, to name a few. However, the challenge arises about how and where to process the data streams in order to perform analytic operations and uncover useful knowledge patterns. The mobile data stream mining (MDSM) applications involve a number of operations for, 1) data acquisition from heterogeneous data sources, 2) data preprocessing, 3) data fusion, 4) data mining, and 5) knowledge management. This article presents a thorough review of execution platforms for \{MDSM\} applications. In addition, a detailed taxonomic discussion of heterogeneous \{MDSM\} applications is presented. Moreover, the article presents detailed literature review of methods that are used to handle heterogeneity at application and platform levels. Finally, the gap analysis is articulated and future research directions are presented to develop next-generation \{MDSM\} applications. "
}
@incollection{Sturm2017211,
title = "Chapter 16 - The Case for Standards ",
editor = "Sturm, Rick and Pollard, Carol  and Craig, Julie ",
booktitle = "Application Performance Management (APM) in the Digital Enterprise ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2017",
pages = "211 - 235",
isbn = "978-0-12-804018-8",
doi = "https://doi.org/10.1016/B978-0-12-804018-8.00016-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128040188000164",
author = "Rick Sturm and Carol Pollard and Julie Craig",
keywords = "Application description files (ADFs)",
keywords = "Application response measurement (ARM)",
keywords = "Cloud application management for platforms (CAMP)",
keywords = "Cloud auditing data federation (CADF)",
keywords = "Common information model (CIM)",
keywords = "Component description files (CDFs)",
keywords = "Desktop and mobile architecture for system hardware (DASH)",
keywords = "Global description file (GDF)",
keywords = "IEEE 1220",
keywords = "ISO/IEC 16350",
keywords = "ISO/IEC 17023:2011",
keywords = "ISO/IEC 17963:2013",
keywords = "Object identifier (OID)",
keywords = "Organization for advancing open standards for the information society (OASIS)",
keywords = "POSIX 1387.2",
keywords = "System application \{MIB\} (sysApplMIB)",
keywords = "System management architecture for server management (SMASH)",
keywords = "Tivoli application management specification (AMS)",
keywords = "Web services management (WS-MAN) ",
abstract = "As cloud computing models emerge and evolve in a significant way to deliver reliable, automated services across private, hosted and public environments, standards provide a base of consistent, interoperable management across different cloud service implementations. Brad Anderson, Microsoft General Manager, Management and Services Division As every market matures, so evolves the need for standards. \{HP\} sees that the right balance between industry standards and proprietary technologies propels the industry forward, fostering collaboration and innovation. James Mouton, Hewlett–Packard, Chief Technology Officer, Technology Solutions Group It is not only about open standards, but it is about how these standards all play together for the benefit of the customer. Angel Diaz, \{VP\} \{IBM\} Standards, Open Source and Cloud Labs "
}
@article{Mahmoudabadi2016135,
title = "Efficient terrestrial laser scan segmentation exploiting data structure ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "119",
number = "",
pages = "135 - 150",
year = "2016",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616301083",
author = "Hamid Mahmoudabadi and Michael J. Olsen and Sinisa Todorovic",
keywords = "Terrestrial laser scanning",
keywords = "Segmentation",
keywords = "High Dynamic Range imaging",
keywords = "Computer vision",
keywords = "Point cloud",
keywords = "Lidar ",
abstract = "Abstract New technologies such as lidar enable the rapid collection of massive datasets to model a 3D scene as a point cloud. However, while hardware technology continues to advance, processing 3D point clouds into informative models remains complex and time consuming. A common approach to increase processing efficiently is to segment the point cloud into smaller sections. This paper proposes a novel approach for point cloud segmentation using computer vision algorithms to analyze panoramic representations of individual laser scans. These panoramas can be quickly created using an inherent neighborhood structure that is established during the scanning process, which scans at fixed angular increments in a cylindrical or spherical coordinate system. In the proposed approach, a selected image segmentation algorithm is applied on several input layers exploiting this angular structure including laser intensity, range, normal vectors, and color information. These segments are then mapped back to the 3D point cloud so that modeling can be completed more efficiently. This approach does not depend on pre-defined mathematical models and consequently setting parameters for them. Unlike common geometrical point cloud segmentation methods, the proposed method employs the colorimetric and intensity data as another source of information. The proposed algorithm is demonstrated on several datasets encompassing variety of scenes and objects. Results show a very high perceptual (visual) level of segmentation and thereby the feasibility of the proposed algorithm. The proposed method is also more efficient compared to Random Sample Consensus (RANSAC), which is a common approach for point cloud segmentation. "
}
@incollection{Kangovi2017247,
title = "8 - Applications of Peering Carrier Ethernet Networks ",
editor = "Kangovi, Sachidananda ",
booktitle = "Peering Carrier Ethernet Networks ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2017",
pages = "247 - 271",
isbn = "978-0-12-805319-5",
doi = "https://doi.org/10.1016/B978-0-12-805319-5.00008-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053195000083",
author = "Sachidananda Kangovi",
keywords = "Application-specific performance objective (APO)",
keywords = "CoS performance objective (CPO)",
keywords = "Cyber-physical systems (CPS)",
keywords = "Internet of things (IoT)",
keywords = "IP backhaul",
keywords = "Mobile backhaul",
keywords = "Performance tier (PT)",
keywords = "Private cloud",
keywords = "Public cloud",
keywords = "Streaming and switched video transport",
keywords = "Virtual reality (VR) ",
abstract = "Abstract This chapter describes the taxonomy of customers and their applications. This taxonomy provides a structure and important insight in understanding applications that customers need, use, and pay for. Customer applications are the primary purpose of Carrier Ethernet networks (CENs) and peering \{CENs\} as well as operations and business support systems (OSS/BSS) which provide very important and necessary foundations on which applications ride. The chapter then presents application-specific performance requirements or objectives compiled by \{MEF\} from variety of sources in public domain. These application-specific performance objectives (APOs) are then mapped to MEF-defined standard CoS performance objectives (CPOs) and performance tiers (PTs). This mapping is crucial to standardizing Carrier Ethernet (CE) services particularly in peering CENs. The mapping is also described in this chapter. The chapter then covers the applicable \{CE\} services including Ethernet-access service for peering \{CENs\} to meet the network functionality needed by customer applications. Examples of network functionality include \{IP\} backhaul, mobile backhaul, streaming and switched video transport, site-to-site connectivity, connection for cloud computing services, and network connectivity for emerging applications such as Internet of things (IoT), cyber-physical systems (CPS), and virtual reality (VR). The chapter next dwells, briefly, on a process to convert information about customer applications and topology into a design for a \{CE\} service based on \{CENs\} and peering CENs. Finally, the chapter provides a transition to next steps needed in further enhancing peering of \{CENs\} to accommodate emerging trends which is covered in some detail in the final chapter of this book. "
}
@article{Yumimoto2016121,
title = "Forecasting of Asian dust storm that occurred on May 10–13, 2011, using an ensemble-based data assimilation system ",
journal = "Particuology ",
volume = "28",
number = "",
pages = "121 - 130",
year = "2016",
note = "",
issn = "1674-2001",
doi = "https://doi.org/10.1016/j.partic.2015.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S1674200115001686",
author = "Keiya Yumimoto and Hiroshi Murakami and Taichu Y. Tanaka and Tsuyoshi T. Sekiyama and Akinori Ogi and Takashi Maki",
keywords = "Data assimilation",
keywords = "Aerosol transport model",
keywords = "Ensemble Kalman filter",
keywords = "Satellite observation",
keywords = "Aerosol optical thickness",
keywords = "Asian dust ",
abstract = "Abstract An ensemble-based assimilation system that used the \{MASINGAR\} mk-2 (Model of Aerosol Species \{IN\} the Global AtmospheRe Mark 2) dust forecasting model and satellite-derived aerosol optical thickness (AOT) data, processed in the \{JAXA\} (Japan Aerospace Exploration Agency) Satellite Monitoring for Environmental Studies (JASMES) system with \{MODIS\} (Moderate Resolution Imaging Spectroradiometer) observations, was used to quantify the impact of assimilation on forecasts of a severe Asian dust storm during May 10–13, 2011. The modeled bidirectional reflectance function and observed vegetation index employed in \{JASMES\} enable \{AOT\} retrievals in areas of high surface reflectance, making \{JASMES\} effective for dust forecasting and early warning by enabling assimilations in dust storm source regions. Forecasts both with and without assimilation were validated using \{PM10\} observations from China, Korea, and Japan in the \{TEMM\} \{WG1\} dataset. Only the forecast with assimilation successfully captured the contrast between the core and tail of the dust storm by increasing the \{AOT\} around the core by 70–150% and decreasing it around the tail by 20–30% in the 18-h forecast. The forecast with assimilation improved the agreement with observed \{PM10\} concentrations, but the effect was limited at downwind sites in Korea and Japan because of the lack of observational constraints for a mis-forecasted dust storm due to cloud. "
}
@article{Lauer2017,
title = "Benchmarking \{CMIP5\} models with a subset of \{ESA\} \{CCI\} Phase 2 data using the \{ESMValTool\} ",
journal = "Remote Sensing of Environment ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S003442571730007X",
author = "Axel Lauer and Veronika Eyring and Mattia Righi and Michael Buchwitz and Pierre Defourny and Martin Evaldsson and Pierre Friedlingstein and Richard de Jeu and Gerrit de Leeuw and Alexander Loew and Christopher J. Merchant and Benjamin Muller and Thomas Popp and Maximilian Reuter and Stein Sandven and Daniel Senftleben and Martin Stengel and Michel Van Roozendael and Sabrina Wenzel and Ulrika Willen",
keywords = "\{ESA\} CCI",
keywords = "CMIP",
keywords = "Earth system models",
keywords = "Climate",
keywords = "Model evaluation",
keywords = "ESMValTool",
keywords = "Sea surface temperature",
keywords = "Sea ice",
keywords = "Clouds",
keywords = "Soil moisture",
keywords = "Land cover",
keywords = "Aerosols",
keywords = "Ozone",
keywords = "Greenhouse gases",
keywords = "CO2 ",
abstract = "Abstract The Coupled Model Intercomparison Project (CMIP) is now moving into its sixth phase and aims at a more routine evaluation of the models as soon as the model output is published to the Earth System Grid Federation (ESGF). To meet this goal the Earth System Model Evaluation Tool (ESMValTool), a community diagnostics and performance metrics tool for the systematic evaluation of Earth system models (ESMs) in CMIP, has been developed and a first version (1.0) released as open source software in 2015. Here, an enhanced version of the \{ESMValTool\} is presented that exploits a subset of Essential Climate Variables (ECVs) from the European Space Agency's Climate Change Initiative (ESA CCI) Phase 2 and this version is used to demonstrate the value of the data for model evaluation. This subset includes consistent, long-term time series of \{ECVs\} obtained from harmonized, reprocessed products from different satellite instruments for sea surface temperature, sea ice, cloud, soil moisture, land cover, aerosol, ozone, and greenhouse gases. The \{ESA\} \{CCI\} data allow extending the calculation of performance metrics as summary statistics for some variables and add an important alternative data set in other cases where observations are already available. The provision of uncertainty estimates on a per grid basis for the \{ESA\} \{CCI\} data sets is used in a new extended version of the Taylor diagram and provides important additional information for a more objective evaluation of the models. In our analysis we place a specific focus on the comparability of model and satellite data both in time and space. The \{ESA\} \{CCI\} data are well suited for an evaluation of results from global climate models across \{ESM\} compartments as well as an analysis of long-term trends, variability and change in the context of a changing climate. The enhanced version of the \{ESMValTool\} is released as open source software and ready to support routine model evaluation in \{CMIP6\} and at individual modeling centers. "
}
@article{Gao20172,
title = "Through Life Analysis for Machine Tools: From Design to Remanufacture ",
journal = "Procedia \{CIRP\} ",
volume = "59",
number = "",
pages = "2 - 7",
year = "2017",
note = "Proceedings of the 5th International Conference in Through-life Engineering Services Cranfield University, 1st and 2nd November 2016 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.09.027",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309611",
author = "Robert X. Gao and Peng Wang",
keywords = "sustainable manufacturing",
keywords = "life cycle analysis",
keywords = "remanufacture",
keywords = "cloud manufacturing ",
abstract = "Abstract Increasing awareness of environmental burden calls for a sensible transition of manufacturing from the traditional mode where products have only one cycle of service life after being produced to a sustainable mode where multiple cycles of service life are enabled through material recovery, reuse, and remanufacture. As both the means for product generation and a product of modern manufacturing processes, machine tools have been increasingly viewed as a critical element for improving through life and consequently, sustainability. This paper examines the life cycles of machine tools and recent advancement in extending their life cycles. A life cycle is defined as starting from the design, proceeding through the stages of manufacturing and usage, and completing by the end of the service life. Modular design techniques that facilitate the manufacture and assembly of machine tools and analytical methods for reliable machine state estimation and remaining service life prediction are presented. Extension beyond completion of the first service life is enabled by recover and recycle of material from worn/broken machines, and redesign methods that reduce the amount of new materials to be used for making the same product in the subsequent re-manufacturing processes to ultimately realize materials reuse. Opportunities and challenges for sustainable manufacturing in the context of cloud manufacturing are also highlighted. "
}
@article{Watson201667,
title = "Enterprise system case using Microsoft Dynamics \{GP\} via DynamicsCloud ",
journal = "Journal of Accounting Education ",
volume = "37",
number = "",
pages = "67 - 92",
year = "2016",
note = "",
issn = "0748-5751",
doi = "https://doi.org/10.1016/j.jaccedu.2016.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0748575116300215",
author = "Marcia Weidenmier Watson and Bonnie K. Klamm and Joann Segovia and Mark W. Lehman",
keywords = "Cloud application",
keywords = "Enterprise system",
keywords = "Microsoft Dynamics \{GP\} ",
abstract = "Abstract This case increases your understanding of enterprise systems by applying course concepts in an active-learning setting. Specifically, you build on previous course knowledge by using Microsoft Dynamics \{GP\} via a cloud provider, DynamicsCloud. Cloud applications allow companies to reduce information technology costs and use one consistent platform across the entire company, whether they have one or many locations across the globe. The case consists of three main parts (i.e., system overview, data collection and storage, and information retrieval) and integrates internal controls and exercises within each part of the case. Upon completion of this case, you will understand the basic functions of an enterprise system. Activities require you to collect and process data in the revenue and purchasing cycles, identify internal controls within the system, and provide useful information for decision making. In addition, you gain hands-on experience using an enterprise system and acquire skills that transfer to other enterprise systems or to upgraded versions of Dynamics GP, which companies can use to support global operations. The case should increase accounting information system knowledge, system navigation skills, and the ability to learn on your own. "
}
@article{Fang2016367,
title = "A framework for real-time pro-active safety assistance for mobile crane lifting operations ",
journal = "Automation in Construction ",
volume = "72, Part 3",
number = "",
pages = "367 - 379",
year = "2016",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.08.025",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516301807",
author = "Yihai Fang and Yong K. Cho and Jingdao Chen",
keywords = "Crane safety",
keywords = "Human error",
keywords = "Real-time",
keywords = "Crane motion capturing",
keywords = "Collision hazard analysis",
keywords = "3D reconstruction",
keywords = "Point cloud ",
abstract = "Abstract Despite many safety considerations addressed in lift pre-planning, the ability to provide real-time safety assistance to crane operators and to mitigate human errors during the lifting operation is missing. This research developed a framework for real-time pro-active safety assistance for mobile crane lifting operations. First, crane poses are reconstructed in real-time based on the critical motions of crane parts captured by a sensor system. Second, as-is lift site conditions are automatically modeled and updated based on point cloud data. Lastly, the risk of colliding the crane parts and lifted load into nearby obstructions is pro-actively analyzed and warnings are provided to the operator through a graphical user interface. A prototype system was developed based on the framework and deployed on a mobile crane. Field test results indicate that the system can accurately reconstruct crane motion in real-time and provide pro-active warnings that allow the operator to make timely decisions to mitigate the risk. "
}
@article{Bausch1989159,
title = "Robotic data acquisition of directional reflectance factors ",
journal = "Remote Sensing of Environment ",
volume = "30",
number = "2",
pages = "159 - 168",
year = "1989",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/0034-4257(89)90058-8",
url = "http://www.sciencedirect.com/science/article/pii/0034425789900588",
author = "Walter C. Bausch and Daniel M. Lund and Michael C. Blue",
abstract = "A data collection platform for rapid and repeatable positioning of a down-looking radiometer was constructed using commercially available instru mentation and hardware. The platform also accommodated a second radiometer to measure irradiance at the same instant the other radiometer measured target radiance. Stepper motors position the down-looking radiometer at programmed view zenith and view azimuth angles. A Polycorder and stepper motor interface control the stepper motors while data acquisition is the sole responsibility of the Polycorder. Less than 15 min is required to measure target radiance from a full set of measurements consisting of 182 combinations of view zenith and view azimuth angles. Positioning accuracy of the viewing radiometer is within ± 0.2° for a nominal 15° angular movement. The system has proven to be dependable, easy to use, highly mobile, and adaptable. "
}
@article{Babiceanu2016128,
title = "Big Data and virtualization for manufacturing cyber-physical systems: A survey of the current status and future outlook ",
journal = "Computers in Industry ",
volume = "81",
number = "",
pages = "128 - 137",
year = "2016",
note = "Emerging \{ICT\} concepts for smart, safe and sustainable industrial systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0166361516300471",
author = "Radu F. Babiceanu and Remzi Seker",
keywords = "Sensor-based real-time monitoring",
keywords = "Big Data",
keywords = "Internet of things",
keywords = "Cloud computing",
keywords = "Manufacturing cyber-physical systems ",
abstract = "Abstract The recent advances in sensor and communication technologies can provide the foundations for linking the physical manufacturing facility and machine world to the cyber world of Internet applications. The coupled manufacturing cyber-physical system is envisioned to handle the actual operations in the physical world while simultaneously monitor them in the cyber world with the help of advanced data processing and simulation models at both the manufacturing process and system operational levels. Moreover, a sensor-packed manufacturing system in which each process or piece of equipment makes available event and status information, coupled with market research for true advanced Big Data analytics, seem to be the right ingredients for event response selection and operation virtualization. As a drawback, the resulting manufacturing cyber-physical system will be vulnerable to the inevitable cyber-attacks, unfortunately, so common for the software and Internet-based systems. This reality makes cybersecurity penetration within the manufacturing domain a need that goes uncontested across researchers and practitioners. This work provides a review of the current status of virtualization and cloud-based services for manufacturing systems and of the use of Big Data analytics for planning and control of manufacturing operations. Building on already developed cloud business solutions, cloud manufacturing is expected to offer improved enterprise manufacturing and business decision support. Based on the current state-of-the-art cloud manufacturing solutions and Big Data applications, this work also proposes a framework for the development of predictive manufacturing cyber-physical systems that include capabilities for attaching to the Internet of Things, and capabilities for complex event processing and Big Data algorithmic analytics. "
}
@article{BerkerLogoglu2016558,
title = "CoSPAIR: Colored Histograms of Spatial Concentric Surflet-Pairs for 3D object recognition ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "558 - 570",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.027",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002225",
author = "K. Berker Logoglu and Sinan Kalkan and Alptekin Temizel",
keywords = "3D descriptors",
keywords = "3D object recognition",
keywords = "Point clouds",
keywords = "RGB-D ",
abstract = "Abstract Introduction of RGB-D sensors together with the efforts on open-source point-cloud processing tools boosted research in both computer vision and robotics. One of the key areas which have drawn particular attention is object recognition since it is one of the crucial steps for various applications. In this paper, two spatially enhanced local 3D descriptors are proposed for object recognition tasks: Histograms of Spatial Concentric Surflet-Pairs (SPAIR) and Colored \{SPAIR\} (CoSPAIR). The proposed descriptors are compared against the state-of-the-art local 3D descriptors that are available in Point Cloud Library (PCL) and their object recognition performances are evaluated on several publicly available datasets. The experiments demonstrate that the proposed CoSPAIR descriptor outperforms the state-of-the-art descriptors in both category-level and instance-level recognition tasks. The performance gains are observed to be up to 9.9 percentage points for category-level recognition and 16.49 percentage points for instance-level recognition over the second-best performing descriptor. "
}
@article{Pandey2017,
title = "Exploiting the untapped potential of mobile distributed computing via approximation ",
journal = "Pervasive and Mobile Computing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2017.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S1574119217300494",
author = "Parul Pandey and Dario Pompili",
keywords = "Mobile device clouds",
keywords = "Approximate computing",
keywords = "Mobile perception application",
keywords = "Workflows",
keywords = "Object recognition ",
abstract = "Abstract Mobile computing is one of the largest untapped reservoirs in today’s pervasive computing world as it has the potential to enable a variety of in-situ, real-time applications. Yet, this computing paradigm suffers when the available resources–such as energy in the network, \{CPU\} cycles, memory, I/O data rate–are limited. In this article, the new paradigm of approximate computing is proposed to harness such potential and to enable real-time computation-intensive mobile applications in resource-limited and uncertain environments. A reduction in time and energy consumed by an application is obtained via approximate computing by decreasing the amount of computation needed; such improvement, however, comes with the potential loss in accuracy. Hence, a Mobile Distributed Computing framework, is introduced to determine offline the ‘approximable’ tasks in an application and a light-weight online algorithm is devised to select the approximate version of the tasks in an application during run time. The effectiveness of the proposed approach is validated through extensive simulation and testbed experiments by comparing approximate versus exact-computation performance. "
}
@article{Wang201771,
title = "Pedestrian recognition and tracking using 3D LiDAR for autonomous vehicle ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "71 - 78",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302633",
author = "Heng Wang and Bin Wang and Bingbing Liu and Xiaoli Meng and Guanghong Yang",
keywords = "Pedestrian recognition and tracking",
keywords = "Point clouds",
keywords = "Hash table",
keywords = "GUI design ",
abstract = "Abstract This paper studies the pedestrian recognition and tracking problem for autonomous vehicles using a 3D LiDAR, a classifier trained by \{SVM\} (Support Vector Machine) is used to recognize pedestrians, the recognition performance is further improved with the aid of tracking results. By comparing positions and velocity directions of pedestrians with curb information, alarms will be generated if pedestrians are detected to be on road or close to curbs. The proposed approach has been verified on an autonomous vehicle platform. "
}
@article{Morariu201626,
title = "Redundancy and scalability for virtualized \{MES\} systems with programmable infrastructure ",
journal = "Computers in Industry ",
volume = "81",
number = "",
pages = "26 - 35",
year = "2016",
note = "Emerging \{ICT\} concepts for smart, safe and sustainable industrial systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2015.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0166361515300415",
author = "Octavian Morariu and Theodor Borangiu and Silviu Raileanu and Cristina Morariu",
keywords = "Private cloud",
keywords = "Virtualization",
keywords = "Smart manufacturing",
keywords = "Redundancy",
keywords = "Programmable infrastructure",
keywords = "COBASA",
keywords = "Event driven ",
abstract = "Abstract Virtualization of manufacturing execution system (vMES) workloads offers a set of design and operational advantages to enterprises, the most visible being improved resource utilization and flexibility of the overall solution. This paper explores redundancy and scalability, as other important operational advantages introduced by the use of private clouds for \{MES\} virtualization in the context of the programmable infrastructure (PI) concept. \{PI\} is a new architectural approach in which the computing infrastructure, represented by resources, networks, storage, becomes dynamic and is controlled by the application, in contrast with traditional architectures where the application has to adapt to a static infrastructure. For \{MES\} applications, the adoption of \{PI\} has the potential to add a new layer of flexibility and optimization by allowing quick configuration and re-configuration based on environmental changes, especially in the context of virtualization in private cloud where workloads can be provisioned and de-provisioned in real time. In this context, this paper presents the main redundancy and scalability requirements for the workloads identified in ISA-95.03 based solutions and discusses in detail the strategies to assure the redundancy and scalability requirements of these workloads both individually and at the system level. The main contributions of this paper are therefore the introduction of \{PI\} combined with private cloud virtualization at the \{MES\} layer in order to achieve redundancy and scalability of the control solution. The pilot implementation presented is based on \{PI\} concepts and is realized in practice using \{SOA\} \{BPEL\} and \{IBM\} CloudBurst \{REST\} APIs. The \{MES\} system considered for the pilot implementation adopts a multi-agent vMES architecture having COBASA-type functionality. The experimental results presented in this paper show the system response in a set of failure scenarios, with focus on the reconfiguration time of workloads, and the dynamic response to perturbations in the system. "
}
@article{Grigoriadis201627,
title = "Use of laser interferometry for measuring concrete substrate roughness in patch repairs ",
journal = "Automation in Construction ",
volume = "64",
number = "",
pages = "27 - 35",
year = "2016",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.12.025",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515002733",
author = "Konstantinos Grigoriadis",
keywords = "Concrete",
keywords = "Remote Robotic Hydro-erosion",
keywords = "Substrate surface roughness",
keywords = "Patch repair ",
abstract = "Abstract The overall success and long-term durability of a patch repair is significantly influenced by the bond developed at the interface between the concrete substrate and the repair material. In turn, the bond strength is influenced by the topography (roughness) of the substrate surface after removal of the defective concrete. However, different removal methods of defective concrete produce substrate surfaces with different topographies. Hence, the ability to measure and characterise the topography of substrate surfaces is of great importance for evaluating the effectiveness of different removal methods. In this paper, the effect of two removal methods: electric chipping hammers and Remote Robotic Hydro-erosion (RRH) on the surface roughness is investigated through the use of a prototype non-contact (optical) laser interferometry measuring device. Laboratory results show that the above equipment can be used to characterise substrate roughness and confirm the ability of \{RRH\} to create rougher surfaces as opposed to chipping hammers. "
}
@incollection{Fiedler2017299,
title = "Chapter 17 - The Future of Health Technology Management ",
editor = "Fiedler, Beth Ann ",
booktitle = "Managing Medical Devices Within a Regulatory Framework ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2017",
pages = "299 - 314",
isbn = "978-0-12-804179-6",
doi = "https://doi.org/10.1016/B978-0-12-804179-6.00017-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128041796000174",
author = "B.A. Fiedler",
keywords = "Biomaterials",
keywords = "Cloud computing",
keywords = "Consumer technology",
keywords = "Digital health",
keywords = "Evidence-based medicine",
keywords = "HAPIfork",
keywords = "Health technology management (HTM)",
keywords = "Practice-based medicine",
keywords = "Remote patient monitoring (RPM) ",
abstract = "Abstract The dynamic circumstances in the health system, healthcare delivery, and the envelopment of digital health continue to redefine the definition of health technology management (HTM). This chapter reviews traditional \{HTM\} and encapsulates how emerging technologies—remote patient monitoring (RPM), open software interfaces, and biomaterial development, impact the future of HTM. Further, we suggest that \{HTM\} personnel can optimize existing information to address problems with technology transfer and interoperability by becoming more familiar with the business product development process (PDP), the National Library of Medicine’s Universal Medical Language Systems, and opening collaborative channels for funding and subject matter expertise that expedite regulatory approval and reimbursement. "
}
@article{Servos2017247,
title = "Multi-Channel Generalized-ICP: A robust framework for multi-channel scan registration ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "247 - 257",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016306790",
author = "James Servos and Steven L. Waslander",
keywords = "Scan registration",
keywords = "RGBD point clouds ",
abstract = "Abstract Current state of the art scan registration algorithms which use only position information often fall victim to correspondence ambiguity and degeneracy in the optimization solutions. Other methods which use additional channels, such as color or intensity, often use only a small fraction of the available information and ignore the underlying structural information of the added channels. The proposed method incorporates the additional channels directly into the scan registration formulation to provide information within the plane of the surface. This is achieved by calculating the uncertainty both along and perpendicular to the local surface at each point and calculating nearest neighbor correspondences in the higher dimensional space. The proposed method reduces instances of degenerate transformation estimates and improves both registration accuracy and convergence rate. The method is tested on the Ford Vision and Lidar dataset using both color and intensity channels, as well as with Microsoft Kinect data from the Freiburg \{RGBD\} Office dataset and data obtained from the University of Waterloo campus. "
}
@article{Bietresato20161,
title = "Evaluation of a LiDAR-based 3D-stereoscopic vision system for crop-monitoring applications ",
journal = "Computers and Electronics in Agriculture ",
volume = "124",
number = "",
pages = "1 - 13",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2016.03.017",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916300862",
author = "Marco Bietresato and Giovanni Carabin and Renato Vidoni and Alessandro Gasparetto and Fabrizio Mazzetto",
keywords = "Vision systems",
keywords = "LiDAR",
keywords = "Canopy detection",
keywords = "Volume estimation",
keywords = "Lateral-linear-stereoscopic vision",
keywords = "Agricultural robotic system ",
abstract = "Abstract When dealing with unmanned agricultural vehicles (remotely-controlled vehicles, robots), vision systems are a key-factor for implementing field-solutions having direct interactions with crops. Among all the possible information given by a vision system, the punctual estimation of the canopy volume is surely an interesting parameter: it is related to the crop vegetative status and, hence, it is fundamental for performing and setting-up properly some important field-operations (e.g., pruning/thinning, spraying). A system able to recognize the canopy volume can provide either the input-signals for implementing a robotic real-time site-specific farming system or relevant information for a proper crop management. However, there are many practical difficulties in the field implementation of such a system: complex canopy shapes, different colours, textures and illumination conditions with projected shadows. Terrestrial/aerial vision systems working on visible-light wavelengths and/or 2D-images of crops, although capable of excellent performances, have a computationally-heavy post-processing; therefore, they are unsuitable for implementing low-cost real-time servo-actuated cropping systems (e.g., robotised sprayers). Instead, a vision system composed by two LiDAR sensors aligned vertically, scanning the same targets, could give a sort of stereoscopic vision, here named “lateral-linear-stereoscopic vision”. The aim of this study is assessing the opportunity to use such a system on an automatic or autonomous/robotised implement by performing some preliminary tests in a controlled environment. The resulting system is independent of the lighting conditions (it works also in the dark), is highly reliable (no projected shadows) and data processing is very fast. Although further studies are required to overcome the issues that could arise in a future field implementation, this system has all the premises to be successfully embedded in an automatized monitoring system. "
}
@article{Yoon201633,
title = "Trend estimates of AERONET-observed and model-simulated \{AOTs\} between 1993 and 2013 ",
journal = "Atmospheric Environment ",
volume = "125, Part A",
number = "",
pages = "33 - 47",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.10.058",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015304738",
author = "J. Yoon and A. Pozzer and D.Y. Chang and J. Lelieveld and J. Kim and M. Kim and Y.G. Lee and J.-H. Koo and J. Lee and K.J. Moon",
keywords = "Aerosol optical thickness",
keywords = "AErosol \{RObotic\} NETwork",
keywords = "ECHAM/MESSy atmospheric chemistry model",
keywords = "Trend estimates",
keywords = "Monthly percentiles",
keywords = "Monthly cumulative distributions ",
abstract = "Abstract Recently, temporal changes in Aerosol Optical Thickness (AOT) have been investigated based on model simulations, satellite and ground-based observations. Most \{AOT\} trend studies used monthly or annual arithmetic means that discard details of the generally right-skewed \{AOT\} distributions. Potentially, such results can be biased by extreme values (including outliers). This study additionally uses percentiles (i.e., the lowest 5%, 25%, 50%, 75% and 95% of the monthly cumulative distributions fitted to Aerosol Robotic Network (AERONET)-observed and ECHAM/MESSy Atmospheric Chemistry (EMAC)-model simulated AOTs) that are less affected by outliers caused by measurement error, cloud contamination and occasional extreme aerosol events. Since the limited statistical representativeness of monthly percentiles and means can lead to bias, this study adopts the number of observations as a weighting factor, which improves the statistical robustness of trend estimates. By analyzing the aerosol composition of AERONET-observed and EMAC-simulated \{AOTs\} in selected regions of interest, we distinguish the dominant aerosol types and investigate the causes of regional \{AOT\} trends. The simulated and observed trends are generally consistent with a high correlation coefficient (R = 0.89) and small bias (slope±2σ = 0.75 ± 0.19). A significant decrease in EMAC-decomposed \{AOTs\} by water-soluble compounds and black carbon is found over the \{USA\} and the \{EU\} due to environmental regulation. In particular, a clear reversal in the \{AERONET\} \{AOT\} trend percentiles is found over the USA, probably related to the \{AOT\} diurnal cycle and the frequency of wildfires. In most of the selected regions of interest, EMAC-simulated trends are mainly attributed to the significant changes of the dominant aerosols; e.g., significant decrease in sea salt and water soluble compounds over Central America, increase in dust over Northern Africa and Middle East, and decrease in black carbon and organic carbon over Australia. "
}
@article{Quintana2016643,
title = "Semantic scan planning for indoor structural elements of buildings ",
journal = "Advanced Engineering Informatics ",
volume = "30",
number = "4",
pages = "643 - 659",
year = "2016",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2016.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S1474034616300453",
author = "B. Quintana and S.A. Prieto and A. Adan and A.S. Vazquez",
keywords = "Large-scale 3D scanning",
keywords = "Automatic 3D acquisition",
keywords = "Dense 3D reconstruction",
keywords = "Next best view in 3D environments",
keywords = "Large point cloud processing ",
abstract = "Abstract The objective of this paper is to propose a new semantic 3D data acquisition method which is focused on sensing data belonging to indoor structural elements of buildings. Our system uses and processes 3D information coming from a 3D laser scanner sensor. The presented approach deals with some essential key issues in the scanning world which are rarely dealt with in papers. These are: the final goal of the scanning process, the hypotheses about the scene, lack of dynamic spaces in the next-best-scan-based solutions and the quality evaluation of the data sensed. Whereas most of the Next Best Scan (NBS) based approaches do not discriminate between data and clutter, we propose a scanning process in which potential structural elements of building indoors are learned as a new scan arrives. Our workspace is not a priori hypothesized, but a dynamic space which is updated as a new scan is added. This allows us to deal with more complex shape scenarios (i.e. concave-shaped spaces). Through the so called Structural Element (SE) membership probability, we introduce the data-quality concept in the scanning process which highly reduces the point cloud to be processed. This system has been tested in inhabited indoors and has yielded promising results. An experimental comparison with three close techniques is presented in an extended and detailed experimental section. The results yielded from our experimental work demonstrate the quality and validity of the proposed method. "
}
@article{Pereira2016326,
title = "Self calibration of multiple \{LIDARs\} and cameras on autonomous vehicles ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "326 - 337",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300173",
author = "Marcelo Pereira and David Silva and Vitor Santos and Paulo Dias",
keywords = "Extrinsic calibration",
keywords = "Point cloud",
keywords = "3D data fitting ",
abstract = "Abstract Autonomous navigation is an important field of research and, given the complexity of real world environments, most of the systems rely on a complex perception system combining multiple sensors on board, which reinforces the concern of sensor calibration. Most calibration methods rely on manual or semi-automatic interactive procedures, but reliable fully automatic methods are still missing. However, if some simple objects could be detected and identified automatically by all the sensors from several points of view, then automatic calibration would be possible on the fly. The idea proposed in this paper is to use a ball in motion in front of a set of uncalibrated sensors allowing them to detect its center along the successive positions. This set of centers generates a point cloud per sensor, which, by using segmentation and fitting techniques, allows the calculation of the rigid body transformation among all pairs of sensors. This paper proposes and describes such a method with results demonstrating its validity. "
}
@incollection{Dastjerdi201661,
title = "Chapter 4 - Fog Computing: principles, architectures, and applications ",
editor = "Buyya, Rajkumar  and Dastjerdi, Amir Vahid ",
booktitle = "Internet of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2016",
pages = "61 - 75",
isbn = "978-0-12-805395-9",
doi = "https://doi.org/10.1016/B978-0-12-805395-9.00004-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053959000046",
author = "A.V. Dastjerdi and H. Gupta and R.N. Calheiros and S.K. Ghosh and R. Buyya",
keywords = "Internet of Things",
keywords = "IoT",
keywords = "Web of Things",
keywords = "Cloud of Things",
keywords = "Fog Computing",
keywords = "IoT applications",
keywords = "Edge Computing ",
abstract = "Abstract The Internet of Everything (IoE) solutions gradually bring every object online, and processing data in a centralized cloud does not scale to requirements of such an environment. This is because there are applications such as health monitoring and emergency response that require low latency, so delay caused by transferring data to the cloud and then back to the application can seriously impact the performance. To this end, Fog computing has emerged, where cloud computing is extended to the edge of the network to decrease the latency and network congestion. Fog computing is a paradigm for managing a highly distributed and possibly virtualized environment that provides compute and network services between sensors and cloud data centers. This chapter provides a background and motivations regarding the emergence of Fog computing, and defines its key characteristics. In addition, a reference architecture for Fog computing is presented, and recent related development and applications are discussed. "
}
@article{Panetto201647,
title = "New perspectives for the future interoperable enterprise systems ",
journal = "Computers in Industry ",
volume = "79",
number = "",
pages = "47 - 63",
year = "2016",
note = "Special Issue on Future Perspectives On Next Generation Enterprise Information Systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2015.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361515300312",
author = "Herve Panetto and Milan Zdravkovic and Ricardo Jardim-Goncalves and David Romero and J. Cecil and Istvan Mezgar",
keywords = "Context-aware systems",
keywords = "Cloud-based systems",
keywords = "Enterprises as cyber-physical systems",
keywords = "Interoperability assessment",
keywords = "Semantic interoperability",
keywords = "Enterprise integration",
keywords = "Networked collaborative enterprise",
keywords = "Enterprise information systems ",
abstract = "Abstract The rapid changes in today's socio-economic and technological environment in which the enterprises operate necessitate the identification of new requirements that address both theoretical and practical aspects of the Enterprise Information Systems (EIS). Such an evolving environment contributes to both the process and the system complexity which cannot be handled by the traditional architectures. The constant pressure of requirements for more data, more collaboration and more flexibility motivates us to discuss about the concept of Next Generation \{EIS\} (NG EIS) which is federated, omnipresent, model-driven, open, reconfigurable and aware. All these properties imply that the future enterprise system is inherently interoperable. This position paper presents the discussion that spans several research challenges of future interoperable enterprise systems, specialized from the existing general research priorities and directions of \{IFAC\} Technical Committee 5.3,11 \{IFAC\} Technical Committee 5.3 « Enterprise Integration and Networking », http://www.ifac-tc53.org namely: context-aware systems, semantic interoperability, cyber-physical systems, cloud-based systems and interoperability assessment. "
}
@article{Dix2016,
title = "Human–computer interaction, foundations and new paradigms ",
journal = "Journal of Visual Languages & Computing ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1045-926X",
doi = "https://doi.org/10.1016/j.jvlc.2016.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S1045926X16300088",
author = "Alan Dix",
keywords = "Human–computer interaction",
keywords = "History, ubiquitous computing",
keywords = "Cloud-computing",
keywords = "Design for solitude",
keywords = "Digital fabrication ",
abstract = "Abstract This paper explores the roots of human–computer interaction as a discipline, the various trends which have marked its development, and some of the current and future challenges for research. Human–computer interaction, like any vocational discipline, sits upon three broad foundations: theoretical principles, professional practice and a community of people. As an interdisciplinary field the theoretical roots of \{HCI\} encompass a number of other disciplines including psychology, computing, ergonomics, and social sciences; however, it also has theoretical and practical challenges of its own. The evolving internal and external context of HCI, computers, have become smaller and less costly; this has led to changes in nature of the users and uses of computers, with corresponding impact on society. The paper explores the current challenges of computers from the cloud to digital fabrication and the need to design for solitude. It suggests that \{HCI\} should not just react to the changes around it, but also shape those changes. "
}
@article{Campos2016222,
title = "The Challenges of Cybersecurity Frameworks to Protect Data Required for the Development of Advanced Maintenance ",
journal = "Procedia \{CIRP\} ",
volume = "47",
number = "",
pages = "222 - 227",
year = "2016",
note = "Product-Service Systems across Life Cycle ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.03.059",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116300294",
author = "Jaime Campos and Pankaj Sharma and Erkki Jantunen and David Baglee and Luca Fumagalli",
keywords = "Big data",
keywords = "cloud computing",
keywords = "maintenance engineering",
keywords = "asset management ",
abstract = "Abstract The main objective of the paper is to highlight the important aspects of the data management in condition monitoring and maintenance, especially when the emergent technologies, such as the cloud computing and big data, are to be considered in the maintenance department. In addition, one of the main data management elements highlighted in the current work are the cybersecurity issues which might be one of the biggest obstacles hindering the development of cloud based big data for condition-based maintenance (CBM) purposes. Further, the benefits and current risks of storing a company's data in the cloud are highlighted. The authors discuss as well different data needs in various processes in the area of asset management. In addition, the challenges and issues to be addressed for the optimal use of the company data at the cloud together with the big data approach are addressed. This is seen as an important part in an effort to achieve sustainable information and communication technologies for the industry. "
}
@article{Farahani2016101,
title = "Overview of Telepathology ",
journal = "Clinics in Laboratory Medicine ",
volume = "36",
number = "1",
pages = "101 - 112",
year = "2016",
note = "Pathology Informatics ",
issn = "0272-2712",
doi = "https://doi.org/10.1016/j.cll.2015.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S0272271215001134",
abstract="",
author = "Navid Farahani and Liron Pantanowitz",
keywords = "Telepathology",
keywords = "Digital imaging",
keywords = "Robotic",
keywords = "Static",
keywords = "Teleconsultation",
keywords = "Telemicroscopy",
keywords = "Virtual microscopy",
keywords = "Whole-slide imaging "
}
@article{Oliveira2016312,
title = "Incremental scenario representations for autonomous driving using geometric polygonal primitives ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "312 - 325",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300604",
author = "Miguel Oliveira and Vitor Santos and Angel D. Sappa and Paulo Dias and A. Paulo Moreira",
keywords = "Incremental scene reconstruction",
keywords = "Point clouds",
keywords = "Autonomous vehicles",
keywords = "Polygonal primitives ",
abstract = "Abstract When an autonomous vehicle is traveling through some scenario it receives a continuous stream of sensor data. This sensor data arrives in an asynchronous fashion and often contains overlapping or redundant information. Thus, it is not trivial how a representation of the environment observed by the vehicle can be created and updated over time. This paper presents a novel methodology to compute an incremental 3D representation of a scenario from 3D range measurements. We propose to use macro scale polygonal primitives to model the scenario. This means that the representation of the scene is given as a list of large scale polygons that describe the geometric structure of the environment. Furthermore, we propose mechanisms designed to update the geometric polygonal primitives over time whenever fresh sensor data is collected. Results show that the approach is capable of producing accurate descriptions of the scene, and that it is computationally very efficient when compared to other reconstruction techniques. "
}
@article{Liang201663,
title = "Terrestrial laser scanning in forest inventories ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "115",
number = "",
pages = "63 - 77",
year = "2016",
note = "Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science' ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616000204",
author = "Xinlian Liang and Ville Kankare and Juha Hyyppa and Yunsheng Wang and Antero Kukko and Henrik Haggren and Xiaowei Yu and Harri Kaartinen and Anttoni Jaakkola and Fengying Guan and Markus Holopainen and Mikko Vastaranta",
keywords = "Forest inventory",
keywords = "Point cloud",
keywords = "Terrestrial laser scanning",
keywords = "Mobile laser scanning",
keywords = "Personal laser scanning",
keywords = "Image-based point cloud ",
abstract = "Abstract Decision making on forest resources relies on the precise information that is collected using inventory. There are many different kinds of forest inventory techniques that can be applied depending on the goal, scale, resources and the required accuracy. Most of the forest inventories are based on field sample. Therefore, the accuracy of the forest inventories depends on the quality and quantity of the field sample. Conventionally, field sample has been measured using simple tools. When map is required, remote sensing materials are needed. Terrestrial laser scanning (TLS) provides a measurement technique that can acquire millimeter-level of detail from the surrounding area, which allows rapid, automatic and periodical estimates of many important forest inventory attributes. It is expected that \{TLS\} will be operationally used in forest inventories as soon as the appropriate software becomes available, best practices become known and general knowledge of these findings becomes more wide spread. Meanwhile, mobile laser scanning, personal laser scanning, and image-based point clouds became capable of capturing similar terrestrial point cloud data as TLS. This paper reviews the advances of applying \{TLS\} in forest inventories, discusses its properties with reference to other related techniques and discusses the future prospects of this technique. "
}
@article{Nahangi201536,
title = "Automated assembly discrepancy feedback using 3D imaging and forward kinematics ",
journal = "Automation in Construction ",
volume = "56",
number = "",
pages = "36 - 46",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515000837",
author = "Mohammad Nahangi and Jamie Yeung and Carl T. Haas and Scott Walbridge and Jeffrey West",
keywords = "Realignment feedback",
keywords = "Fabrication error",
keywords = "Deviation analysis",
keywords = "Refit and plumbness",
keywords = "Robotic forward kinematics",
keywords = "3D imaging",
keywords = "Laser scanning",
keywords = "Pipelines",
keywords = "Pipe spools ",
abstract = "Abstract Assembly of steel structures, modules, and pipe spools requires cycles of fitting and alignment in fabrication facilities and on construction sites. To minimize this work, good discrepancy feedback for automated refitting and realignment is required. A framework for such feedback is presented here that overcomes current limitations. It commences with a constrained registration step to overcome the incapabilities of the current discrepancy analysis approaches. By borrowing concepts from robotic kinematics and 3D image alignment theories, forward kinematics models are generated link by link, and thus provide the means for a local discrepancy analysis for quantifying the deviations autonomously. Experiments show that the proposed approach is suitably accurate and sufficiently fast to be employed for real-time feedback in order to systematically and automatically develop the realignment plans required for refitting and realigning assemblies, which is the key contribution of the work presented in this paper. "
}
@article{Mourtzis2016637,
title = "Energy Consumption Estimation for Machining Processes Based on Real-time Shop Floor Monitoring via Wireless Sensor Networks ",
journal = "Procedia \{CIRP\} ",
volume = "57",
number = "",
pages = "637 - 642",
year = "2016",
note = "Factories of the Future in the digital environment - Proceedings of the 49th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.110",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116312641",
author = "Dimitris Mourtzis and Ekaterini Vlachou and Nikolaos Milas and George Dimitrakopoulos",
keywords = "Wireless Sensor Network",
keywords = "Monitoring",
keywords = "Cloud manufacturing",
keywords = "CBR ",
abstract = "Abstract The increasing concern about the depletion of the energy repositories places the energy efficiency issues in high priority. In the manufacturing sector, the improvement of energy efficiency is a challenging task due to the complexity of manufacturing systems and the requirements for flexible operation targeting highly customised products. Towards this end, the estimation of the energy consumption of a machining task, and therefore the machining cost, is necessary. This paper presents a machine tool monitoring methodology that integrates sensory systems, a scheduling module, and human operators to perform real-time monitoring on the shop-floor. A monitoring system is designed to capture real-time measurements from sensors attached on machine tools and perform the necessary pre-processing to transmit these measurements to a Cloud server via wireless sensor networks. Furthermore, the input from human operators is utilized to collect the machining parameters. The collected information is fused through an information fusion mechanism to extract meaningful results. The results are stored in a database for the reuse in future tasks by estimating the energy consumption of new cases, through a case-based reasoning approach, prior the job dispatching. Therefore, the machining parameters of the new case can be modified targeting energy consumption reduction. The proposed system is delivered as a Cloud software-as-a-service to realise the philosophy of Cloud manufacturing. "
}
@article{Katsaros2016480,
title = "Estimation and forecasting of ecological efficiency of virtual machines ",
journal = "Future Generation Computer Systems ",
volume = "55",
number = "",
pages = "480 - 494",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15000035",
author = "Gregory Katsaros and Pascal Stichler and Josep Subirats and Jordi Guitart",
keywords = "Ecological efficiency",
keywords = "Cloud computing",
keywords = "Virtual machine",
keywords = "Energy consumption",
keywords = "Monitoring ",
abstract = "Abstract The massive development of the cloud marketplace is leading to an increase in the number of the Data Centers (DCs) globally and eventually to an increase of the \{CO\} 2 related footprint. The calculation of the impact of Virtual Machines (VMs) on the environment is a challenging task, not only due to the technical difficulties but also due to the lack of information from the energy providers. The ecological efficiency of a system captures the relationship between the performance of the system with its environmental footprint. In this paper we present a methodology for the estimation and prediction of the ecological efficiency of \{VMs\} in private cloud infrastructures. We specifically focus on the information management starting from the energy resources in a region, the energy consumption and the performance of the resources and finally the calculation of ecological efficiency of a VM. To this end, we have designed and implemented a framework through which the ecological efficiency of a running \{VM\} can be assessed and the ecological efficiency of a \{VM\} to be deployed can be forecasted. The presented framework is being evaluated through several private cloud scenarios with \{VM\} deployments in hosts located in Germany. "
}
@article{Takimoto20167,
title = "Rough Surface Wear Analysis Using Image Processing Techniques ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "31",
pages = "7 - 12",
year = "2016",
note = "12th \{IFAC\} Workshop on Intelligent Manufacturing Systems \{IMS\} 2016Austin, Texas, USA, 5—7 December 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.12.153",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316328233",
author = "Rogerio Yugo Takimoto and Marcos de Sales Guerra Tsuzuki and Edson Kenji Ueda and Andre Kubagawa Sato and Thiago de Castro Martins and Tiago Cousseau and Deniol Tanaka and Amilton Sinatora",
keywords = "Point Cloud Registration",
keywords = "Image Processing",
keywords = "Rigid Transform",
keywords = "ICP",
keywords = "SIFT ",
abstract = "Abstract: Due to the great interest of the automotive industry to quickly and systematically evaluate low wear quantities a new approach based on image processing is presented. By comparing the captured rough surface point cloud using optical interferometry before and after wear, the proposed algorithm was able to estimate the amount of volume wear and mass loss. The proposed algorithm has two main steps. In the first step, the 3D point clouds obtained before and after wear are mapped to 2D images, and conventional edge detection algorithms are applied. Keypoints are determined using the \{SIFT\} algorithm on both images (before and after the wear), followed by the use of the \{RANSAC\} algorithm to create a good 2D registration between both 2D images. In the second step an enhanced \{ICP\} algorithm is used to perform a 3D registration. The main advantage of this method is the visualization of the wear geometry provided by the wear topography. The proposed algorithm was tested and the results are presented. "
}
@incollection{Mallet2016299,
title = "7 - Digital Terrain Models Derived from Airborne LiDAR Data ",
editor = "Baghdadi, Nicolas  and Zribi, Mehrez ",
booktitle = "Optical Remote Sensing of Land Surface ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "299 - 319",
isbn = "978-1-78548-102-4",
doi = "https://doi.org/10.1016/B978-1-78548-102-4.50007-7",
url = "http://www.sciencedirect.com/science/article/pii/B9781785481024500077",
author = "Clement Mallet and Nicolas David",
keywords = "Airborne LiDAR Data",
keywords = "Digital terrain models",
keywords = "3D point clouds",
keywords = "Evaluation",
keywords = "Filtering",
keywords = "Interpolation",
keywords = "Morphological filtering",
keywords = "Non-geometric information",
keywords = "Progressive densification ",
abstract = "Abstract: This chapter focuses on the automatic generation of Digital Terrain Models (DTMs) on the basis of the three-dimensional (3D) point clouds generated by airborne topographic LiDAR sensors. A \{DTM\} is a mathematical representation (model) of the ground surface, most often in the form of a regular grid, in which a unique elevation value is assigned to each pixel. Thus, objects, including permanent off-ground components such as vegetation and buildings, can be detected. When the latter are included, reference is made to the digital surface model (DSM), used to analyze the ground surface visible from the sky (i.e. the surface which can be obtained natively in standard optical imagery). "
}
@article{Kocifaj201540,
title = "Unified model of radiance patterns under arbitrary sky conditions ",
journal = "Solar Energy ",
volume = "115",
number = "",
pages = "40 - 51",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2015.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X15000894",
author = "Miroslav Kocifaj",
keywords = "Sky radiance patterns",
keywords = "Stochastic cloud coverage",
keywords = "Aerosols",
keywords = "Light scattering ",
abstract = "Abstract The radiance/luminance patterns that simulate more realistic skies are urgently needed in lighting engineering applications to model daylight availability in exterior and interior spaces. Undoubtedly, the angular behavior of sky radiance/luminance is a key factor determining the daylight conditions in rooms with variable orientations and window sizes. Therefore, much effort is currently expended in search of a universal, scalable daylight model that accepts actual meteorological situations. The natural sky radiances are neither monotonic nor smooth functions of zenith/azimuth angle, primarily due to the presence of broken cloud arrays or single clouds scattered over the whole sky vault. In this paper we show how we have addressed the phenomena and developed a universal sky radiance model for a turbid, cloudy atmosphere. This model accommodates higher scattering orders, aerosol optics, surface albedo, and the statistically relevant contributions of single clouds. The radiance at ground depends on the bulk characteristics of cloud fields, such as spectral optical thickness, spectral reflectance, altitude, positions on the sky, sizes, and shapes. We have shown that single scattering approximation fails to reproduce the radiance in the circumsolar region when clouds block the direct solar beams. The single scattering concept also overestimates reflection by individual clouds. Incorporation of double scattering into a computational model generally makes the radiance patterns smooth and less steep at the edges of clouds as commonly occur in nature. The numerical demonstrations are based on UniSky Simulator (Kocifaj and Fecko, 2014) which allows for modeling of various cloud configurations and is available for public use. "
}
@article{Winkler20152,
title = "Chemistry space–time ",
journal = "Perspectives in Science ",
volume = "6",
number = "",
pages = "2 - 14",
year = "2015",
note = "Proceedings of the Beilstein Bozen Symposium 2014 – Chemistry and Time ",
issn = "2213-0209",
doi = "https://doi.org/10.1016/j.pisc.2015.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S2213020915000270",
author = "David A. Winkler",
keywords = "Primordial chemistry",
keywords = "Radioastronomical spectroscopy",
keywords = "Amino acids",
keywords = "Materials space",
keywords = "Evolutionary algorithms",
keywords = "High throughput robotic synthesis ",
abstract = "Abstract As Einstein identified so clearly, space and time are intimately related. We discuss the relationship between time and Euclidean space using spectroscopic and radioastronomical studies of interstellar chemistry as an example. Given the finite speed of light, we are clearly studying chemical reactions occurring tens of thousands of years ago that may elucidate the primordial chemistry of this planet several billion years ago. We also explore space of a different kind – chemical space, with many more dimensions than the four we associate as space–time. Vast chemical spaces also need very efficient (computational) methods for their exploration to overcome this ‘curse of dimensionality’. We discuss methods by which the time to explore these new spaces can be very substantially reduced, opening the discovery useful new materials that are the key to our future. "
}
@article{Costa2016113,
title = "Robust 3/6 DoF self-localization system with selective map update for mobile robot platforms ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "113 - 140",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.030",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002250",
author = "Carlos M. Costa and Heber M. Sobreira and Armando J. Sousa and Germano M. Veiga",
keywords = "Self-localization",
keywords = "Simultaneous localization and mapping",
keywords = "Point cloud registration",
keywords = "Geometric feature matching ",
abstract = "Abstract Mobile robot platforms capable of operating safely and accurately in dynamic environments can have a multitude of applications, ranging from simple delivery tasks to advanced assembly operations. These abilities rely heavily on a robust navigation stack, which requires stable and accurate pose estimations within the environment. To solve this problem, a modular localization system suitable for a wide range of mobile robot platforms was developed. By using LIDAR/RGB-D data, the proposed system is capable of achieving 1–2 cm in translation error and 1°–3° degrees in rotation error while requiring only 5–35 ms of processing time (in 3 and 6 DoF respectively). The system was tested in three robot platforms and in several environments with different sensor configurations. It demonstrated high accuracy while performing pose tracking with point cloud registration algorithms and high reliability when estimating the initial pose using feature matching techniques. The system can also build a map of the environment with surface reconstruction and incrementally update it with either the full field of view of the sensor data or only the unknown sections, which allows to reduce the mapping processing time and also gives the possibility to update a \{CAD\} model of the environment without degrading the detail of known static areas due to sensor noise. "
}
@article{Salvini2015209,
title = "Application of an integrated geotechnical and topographic monitoring system in the Lorano marble quarry (Apuan Alps, Italy) ",
journal = "Geomorphology ",
volume = "241",
number = "",
pages = "209 - 223",
year = "2015",
note = "",
issn = "0169-555X",
doi = "https://doi.org/10.1016/j.geomorph.2015.04.009",
url = "http://www.sciencedirect.com/science/article/pii/S0169555X15002111",
author = "Riccardo Salvini and Claudio Vanneschi and Silvia Riccucci and Mirko Francioni and Domenico Gullì",
keywords = "Marble quarry",
keywords = "Slope stability",
keywords = "Rock buttress",
keywords = "Monitoring system",
keywords = "Robotic total station",
keywords = "Displacement analysis ",
abstract = "Abstract Accurate slope stability analysis is essential for human activity in high-risk geological contexts. This may, however, not be enough in the case of quarrying where the dynamic and evolving environment also requires effective monitoring. A well-designed monitoring system requires the acquisition of a huge dataset over time, improving knowledge of the study area and helping to refine prediction from stability analysis. This paper reports the implementation of an integrated monitoring system in a marble quarry in the Apuan Alps (Italy) and some of the results obtained. The equipment consists of a traditional geotechnical monitoring system (extensometers, crackmeters and clinometers) and two modern topographic monitoring systems (a terrestrial interferometer and a robotic total station). This work aims to provide in-depth knowledge of the large scale rock mass behaviour as a result of marble exploitation, thereby allowing continuous excavation. The results highlight the importance of integrating different monitoring systems. "
}
@article{Oksa2015134,
title = "OpenCRP Ecosystem Demonstration Platform ",
journal = "Procedia Computer Science ",
volume = "76",
number = "",
pages = "134 - 138",
year = "2015",
note = "2015 \{IEEE\} International Symposium on Robotics and Intelligent Sensors (IEEE IRIS2015) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.12.323",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915038247",
author = "Petri Oksa and Pekka Loula and Teemu Alapaholuoma",
keywords = "Open-source softwares",
keywords = "mobile robot",
keywords = "cloud computing",
keywords = "ecosystem",
keywords = "PaaS ",
abstract = "Abstract Mobile robots with service-oriented functions are stepping to our lives in hospitals, hospices and industries where robots can help to assist or perform all the arduous working duties. A lot of laborious processes are found that can be automatized, e.g. in hospital medicine delivery and food servery to ward for patients. This paper presents a pilot- and demonstration environment for multiple open-source mobile robots sharing their collected data with each other via a private cloud. The presented platform, OpenCRP, introduces a novel ecosystem based on an open-source software frameworks and robots. "
}
@article{Staranowicz2015102,
title = "Practical and accurate calibration of RGB-D cameras using spheres ",
journal = "Computer Vision and Image Understanding ",
volume = "137",
number = "",
pages = "102 - 114",
year = "2015",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215000703",
author = "Aaron N. Staranowicz and Garrett R. Brown and Fabio Morbidi and Gian-Luca Mariottini",
keywords = "RGB-D cameras",
keywords = "Camera calibration",
keywords = "Robotic vision ",
abstract = "Abstract RGB-Depth (or RGB-D) cameras are increasingly being adopted in robotic and vision applications, including mobile robot localization and mapping, gesture recognition, and at-home healthcare monitoring. As with any other sensor, calibrating RGB-D cameras is needed to increase their sensing accuracy, especially since the manufacturer’s calibration parameters might change between models. In this paper, we present a novel RGB-D camera-calibration algorithm for the estimation of the full set of intrinsic and extrinsic parameters. Our method is easy to use, can be utilized with any arrangement of \{RGB\} and depth sensors, and only requires that a spherical object (e.g., a basketball) is moved in front of the camera for a few seconds. Our image-processing pipeline automatically and robustly detects the moving calibration object while rejecting noise and outliers in the image data. Our calibration method uses all the frames of the detected sphere and leverages novel analytical results on the multi-view projection of spheres to accurately estimate all the calibration parameters. Extensive numerical simulations and real-world experiments have been conducted to validate our algorithm and compare its performance with that of other state-of-the-art calibration methods. An RGB-D Calibration Toolbox for \{MATLAB\} is also made freely available for the scientific community. "
}
@incollection{Sennewald2016235,
title = "24 - Computers and Effective Security Management1 ",
editor = "Sennewald, Charles A. and ,  and Baillie, Curtis ",
booktitle = "Effective Security Management (Sixth Edition) ",
publisher = "Butterworth-Heinemann",
edition = "Sixth Edition",
address = "",
year = "2016",
pages = "235 - 249",
isbn = "978-0-12-802774-5",
doi = "https://doi.org/10.1016/B978-0-12-802774-5.00024-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780128027745000241",
author = "Charles A. Sennewald and Curtis Baillie",
keywords = "central processing unit (CPU)",
keywords = "cloud storage",
keywords = "database",
keywords = "electronic access control system",
keywords = "encryption",
keywords = "firewall",
keywords = "hard drive",
keywords = "hardware",
keywords = "Internet",
keywords = "intranet",
keywords = "local area network (LAN)",
keywords = "memory",
keywords = "multimedia",
keywords = "network",
keywords = "peripherals",
keywords = "portable device",
keywords = "social networking",
keywords = "spreadsheet",
keywords = "wide area network (WAN)",
keywords = "word processing ",
abstract = "The computer has become an indispensable security management tool, changing information processing and affecting the way Security Managers work. Chapter 24 talks about the computer most Security Managers interface with, the PC. Specifically, the topics of hardware, including cloud storage, peripherals, and networks; software, including database management, spreadsheets, desktop publishing, encryption software, graphics, computer-aided design, and geographic information systems (GIS) and global positioning systems (GPS); telecommunications, including electronic mail and messaging, and teleconferencing; the Internet, including online services and social networking; intranets, including specialized programs, integration, and monitoring; artificial intelligence; and multimedia are described. Finally, the risk of using \{PCs\} is addressed. "
}
@article{Oliveira2016614,
title = "3D object perception and perceptual learning in the \{RACE\} project ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "614 - 626",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002146",
author = "Miguel Oliveira and Luis Seabra Lopes and Gi Hyun Lim and S. Hamidreza Kasaei and Ana Maria Tome and Aneesh Chauhan",
keywords = "3D object perception",
keywords = "Point-Cloud Library",
keywords = "Dual memory systems",
keywords = "Open-ended learning",
keywords = "Interactive learning ",
abstract = "Abstract This paper describes a 3D object perception and perceptual learning system developed for a complex artificial cognitive agent working in a restaurant scenario. This system, developed within the scope of the European project RACE, integrates detection, tracking, learning and recognition of tabletop objects. Interaction capabilities were also developed to enable a human user to take the role of instructor and teach new object categories. Thus, the system learns in an incremental and open-ended way from user-mediated experiences. Based on the analysis of memory requirements for storing both semantic and perceptual data, a dual memory approach, comprising a semantic memory and a perceptual memory, was adopted. The perceptual memory is the central data structure of the described perception and learning system. The goal of this paper is twofold: on one hand, we provide a thorough description of the developed system, starting with motivations, cognitive considerations and architecture design, then providing details on the developed modules, and finally presenting a detailed evaluation of the system; on the other hand, we emphasize the crucial importance of the Point Cloud Library (PCL) for developing such system.11 This paper is a revised and extended version of Oliveira et al. (2014). "
}
@article{Paul20151,
title = "INVERITAS: A facility for hardware-in-the-loop long distance movement simulation for rendezvous and capture of satellites and other autonomous objects ",
journal = "Acta Astronautica ",
volume = "116",
number = "",
pages = "1 - 24",
year = "2015",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515002374",
author = "J. Paul and A. Dettmann and B. Girault and J. Hilljegerdes and F. Kirchner and I. Ahrns and J. Sommer",
keywords = "Orbital servicing",
keywords = "Hardware-in-the-loop",
keywords = "Robotic manipulation",
keywords = "GNC",
keywords = "Pose estimation ",
abstract = "Abstract This paper describes the hardware-in-the-loop (HIL) long distance movement simulation system that was designed and built at the \{DFKI\} \{RIC\} for the \{INVERITAS\} project. It can simulate rendezvous and capture maneuvers between a Client satellite and a Servicer satellite in Earth orbit for scenarios where the semi-autonomous Servicer repairs, refuels, or re-orbits the Client which can otherwise become inoperable and eventually end up as space debris. The simulation system is a hardware-in-the-loop simulation system, meaning it incorporates real hardware like mock-ups of the Client and the Servicer, real sensors like stereocamera systems, a LIDAR, as well as sensor data processing hardware. Controlled by the simulation, the mock-ups are moved in reality so that the Servicer׳s sensors perceive the Client like in the real situation. One of the main tasks in the development of the simulator was the reduction of the twelve unconstrained degrees of freedom of two free-floating objects to ten constrained degrees of freedom of the \{INVERITAS\} movement hardware. A number of behaviors of the control system described in this paper enable it to use the given workspace efficiently to fit trajectories of the two satellites into it. The system reaches an accuracy of a few centimeters that is sufficient to test sensor data processing and navigation algorithms of the Servicer in closed-loop, meaning that the autonomous decisions of the Servicer can be based on the real sensor input. We also present methods and \{HIL\} test results concerning the sensors, sensory data processing and \{GNC\} (guidance, navigation and control) software of the functional Servicer mock-up that was developed in the \{INVERITAS\} project. Finally, the paper includes future plans of how the \{HIL\} simulator can be improved in accuracy and flexibility. "
}
@article{Ichim2016539,
title = "Semantic parametric body shape estimation from noisy depth sequences ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "539 - 549",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002249",
author = "Alexandru Eugen Ichim and Federico Tombari",
keywords = "3D body modeling",
keywords = "3D body tracking",
keywords = "Depth data",
keywords = "Point Cloud Library ",
abstract = "Abstract The paper proposes a complete framework for tracking and modeling articulated human bodies from sequences of range maps acquired from off-the-shelf depth cameras. In particular, we propose an original approach for fitting a pre-defined parametric shape model to depth data by exploiting the 3D body pose tracked through a sequence of range maps. To this goal, we make use of multiple types of constraints and cues embedded into a unique cost function, which is then efficiently minimized. Our framework is able to yield compact semantic tags associated to the estimated body shape by leveraging on semantic body modeling from MakeHuman and \{L1\} relaxation, and relies on the tools and algorithms provided by the open source Point Cloud Library (PCL), representing a good integration of the functionalities available therein. "
}
@article{Eizicovits20141208,
title = "Efficient sensory-grounded grasp pose quality mapping for gripper design and online grasp planning ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1208 - 1219",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000554",
author = "Danny Eizicovits and Sigal Berman",
keywords = "Robotic manipulators",
keywords = "Grasping",
keywords = "Graspability map ",
abstract = "Abstract The gentle grasping and manipulation of objects in dense un-structured environments, such as the agricultural, food processing, or home environments constitute a formidable challenge for robotic systems. Knowledge regarding wrist poses (wrist positions and orientations) that may lead to successful grasps is especially important in such environments for both gripper design and online grasp planning. Graspability maps store grasp quality grades at different wrist poses in object-centered coordinates. Previously graspability maps were derived based on object models in a lengthy, offline process and thus had limited usability. We have developed geometry-based grasp quality measures related to classical grasp quality measures, which can be determined directly from a 3D point cloud. This facilitates embedding agent perception capabilities within the grasp quality determination. Additionally by scanning the object’s surface for finger contact points rather than scanning the volume of the bounding box about the object, and by using parallel computation, graspability map computation-time is considerably reduced, facilitating online computation of multiple measures. We validate the developed measures in a physical environment, show that computation-time can be reduced by more than 90% with very low reduction in map quality, and show the applicability of the developed methods for both simple and complex objects. "
}
@article{Shabanov201529,
title = "Evaluation of the performance of Suomi \{NPP\} \{VIIRS\} top of canopy vegetation indices over \{AERONET\} sites ",
journal = "Remote Sensing of Environment ",
volume = "162",
number = "",
pages = "29 - 44",
year = "2015",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715000504",
author = "N. Shabanov and M. Vargas and T. Miura and A. Sei and A. Danial",
keywords = "VIIRS",
keywords = "Vegetation indices",
keywords = "AERONET",
keywords = "Match-up",
keywords = "Clouds",
keywords = "Aerosol",
keywords = "Snow ",
abstract = "Abstract The Suomi \{NPP\} \{VIIRS\} Vegetation Index (VI) Environment Data Record (EDR) includes the Top Of the Atmosphere Normalized Difference Vegetation Index (TOA NDVI) and the Top Of the Canopy Enhanced Vegetation Index (TOC EVI). \{TOC\} \{NDVI\} will be included in the \{VI\} \{EDR\} suite for the upcoming JPSS-1 and JPSS-2 missions. Currently, the \{VIIRS\} \{VI\} suite is undergoing extensive Calibration and Validation (Cal/Val) activities to quantify product performance and to provide guidance for algorithm improvement. In this study we utilized \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) based Surface Reflectance (SR) match-up data sets. Match-ups are pairs of \{VIIRS\} \{SR\} and \{SR\} derived from atmospheric correction of \{VIIRS\} \{TOA\} reflectances using \{AERONET\} ground measurements (aerosol and water vapor parameters) and ancillary data. Atmospheric correction is performed with the Second Simulation of a Satellite Signal in the Solar Spectrum (6S) radiative transfer code, the same code used in the operational \{VIIRS\} atmospheric correction. Daily time series January 1, 2013–March 31, 2014 of 101 × 101 pixel window match-up subsets at 375 m \{VIIRS\} Imagery resolution, centered at the selected \{AERONET\} site locations were used. The overall objective of the study was to characterize the performance of the \{VIIRS\} \{TOC\} \{VIs\} (TOC \{EVI\} and \{TOC\} NDVI) over \{AERONET\} sites as a function of accuracy of inputs of atmospheric correction algorithm (aerosol, water vapor and others) and quality control screening (cloud and snow masks). We performed three types of analyses: (1) analysis of overall performance of \{VI\} product over all sites, (2) analysis of time series over select sites representative of vegetation types, and (3) sensitivity analysis of \{VI\} to cloud, aerosols and snow contamination. Over the period of time series average Accuracy, Precision and Uncertainty statistics were 0.009, 0.035, and 0.038, respectively, for \{TOC\} \{NDVI\} and − 0.004, 0.015, and 0.016, respectively, for \{TOC\} EVI. Those statistics were derived based on screening to retain only confidently clear, snow free, non-urban pixels. The reason for the substantial difference in the performance of \{VIs\} is a different sensitivity of \{VIs\} to residual atmospheric contamination. According to our study \{VIIRS\} cloud mask performed reasonably. However, Aerosol Optical Thickness (AOT) was substantially overestimated in the vicinity of clouds, which resulted in overcorrection of \{VIIRS\} visible channels and ultimately overestimation of \{TOC\} NDVI. \{TOC\} EVI, on the other hand, remained largely unaffected, as an atmospherically resistant index. \{TOC\} \{EVI\} was also found to be less sensitive to residual snow contamination. Results of this study indicate the need to develop VI-specific quality control, which effectively screens data based on index sensitivity to atmospheric contamination. Monitoring \{VIIRS\} \{VIs\} over \{AERONET\} sites has been automated with a web-based \{STAR\} \{JPSS\} \{VI\} Monitor. "
}
@article{Hu2015343,
title = "G-SHOT: \{GPU\} accelerated 3D local descriptor for surface matching ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "30",
number = "",
pages = "343 - 349",
year = "2015",
note = "",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2015.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S1047320315000875",
author = "Linjia Hu and Saeid Nooshabadi",
keywords = "3D Object local descriptor",
keywords = "Point signature",
keywords = "Surface matching",
keywords = "SHOT",
keywords = "Computer vision",
keywords = "Point cloud library",
keywords = "Parallel algorithm",
keywords = "GPU",
keywords = "Real-time processing",
keywords = "Point cloud ",
abstract = "Abstract Signature of histogram of orientations (SHOT) as a novel 3D object local descriptor can achieves a good balance between descriptiveness and robustness in surface matching. However, its computation workload is much higher than the other 3D local descriptors. This paper investigates the development of suitable massively parallel algorithms on the graphics processing unit (GPU) for computation of high density and large scale 3D object local descriptors through two alternative parallel algorithms; one exact, and one approximate. Both algorithms exhibit outstanding speedup performance. The exact parallel descriptor comes at no cost to the descriptiveness, with a speedup factor of up to 40.70, with respect to the serial \{SHOT\} on the central processing unit (CPU). The approximate version achieves a corresponding speedup factor of up to 54 with minor degradation in descriptiveness. The proposed algorithms are integrated into point cloud library (PCL), a open source project for image and point cloud. "
}
@article{Theiler2015126,
title = "Globally consistent registration of terrestrial laser scans via graph optimization ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "109",
number = "",
pages = "126 - 138",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001987",
author = "Pascal Willy Theiler and Jan Dirk Wegner and Konrad Schindler",
keywords = "Point cloud registration",
keywords = "Terrestrial laser scanning",
keywords = "Geometric matching",
keywords = "Global consistency",
keywords = "Loop closure",
keywords = "Energy minimization ",
abstract = "Abstract In this paper we present a framework for the automatic registration of multiple terrestrial laser scans. The proposed method can handle arbitrary point clouds with reasonable pairwise overlap, without knowledge about their initial orientation and without the need for artificial markers or other specific objects. The framework is divided into a coarse and a fine registration part, which each start with pairwise registration and then enforce consistent global alignment across all scans. While we put forward a complete, functional registration system, the novel contribution of the paper lies in the coarse global alignment step. Merging multiple scans into a consistent network creates loops along which the relative transformations must add up. We pose the task of finding a global alignment as picking the best candidates from a set of putative pairwise registrations, such that they satisfy the loop constraints. This yields a discrete optimization problem that can be solved efficiently with modern combinatorial methods. Having found a coarse global alignment in this way, the framework proceeds by pairwise refinement with standard ICP, followed by global refinement to evenly spread the residual errors. The framework was tested on six challenging, real-world datasets. The discrete global alignment step effectively detects, removes and corrects failures of the pairwise registration procedure, finally producing a globally consistent coarse scan network which can be used as initial guess for the highly non-convex refinement. Our overall system reaches success rates close to 100% at acceptable runtimes &lt; 1 h, even in challenging conditions such as scanning in the forest. "
}
@article{Farahani2015223,
title = "Overview of Telepathology ",
journal = "Surgical Pathology Clinics ",
volume = "8",
number = "2",
pages = "223 - 231",
year = "2015",
note = "Pathology Informatics ",
issn = "1875-9181",
doi = "https://doi.org/10.1016/j.path.2015.02.018",
url = "http://www.sciencedirect.com/science/article/pii/S1875918115000367",
author = "Navid Farahani and Liron Pantanowitz",
keywords = "Telepathology",
keywords = "Digital imaging",
keywords = "Robotic",
keywords = "Static",
keywords = "Teleconsultation",
keywords = "Telemicroscopy",
keywords = "Virtual microscopy",
keywords = "Whole-slide imaging ",
abstract = "Abstract Telepathology is the practice of remote pathology using telecommunication links to enable the electronic transmission of digital pathology images. Telepathology can be used for remotely rendering primary diagnoses, second opinion consultations, quality assurance, education, and research purposes. The use of telepathology for clinical patient care has been limited mostly to large academic institutions. Barriers that have limited its widespread use include prohibitive costs, legal and regulatory issues, technologic drawbacks, resistance from pathologists, and above all a lack of universal standards. This article provides an overview of telepathology technology and applications. "
}
@article{Morariu201527,
title = "vMES: Virtualization aware manufacturing execution system ",
journal = "Computers in Industry ",
volume = "67",
number = "",
pages = "27 - 37",
year = "2015",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514001924",
author = "Octavian Morariu and Theodor Borangiu and Silviu Raileanu",
keywords = "MES",
keywords = "Virtualization",
keywords = "Private cloud",
keywords = "Shop floor",
keywords = "Resource allocation",
keywords = "ISA-95 ",
abstract = "Abstract The large scale emergence in the last decade of various cloud solutions, ranging from software-as-a-service (SaaS) based solutions for business process management and implementation to very sophisticated private cloud solutions capable of high performance computing (HPC) and efficient virtualization, constitute the building blocks for engineering the next generation of flexible enterprise systems that can respond with great agility to changes in their environment. These new technologies are adopted at a certain level by manufacturing enterprises in order to advance in a new era of mass customization where flexibility, scalability and agility are the differentiating factors. In this context, this paper introduces the virtualized manufacturing execution system (vMES), an intermediate layer in the manufacturing stack, and discusses the advantages and limitations offered by this approach for manufacturing enterprises. A classification of \{MES\} workloads based on the ISA-95 function model is presented, focusing on the virtualization techniques suitable for each workload, considering the algorithms and technologies used and the virtualization overhead. A pilot vMES implementation using a parallel process for smart resource provisioning and automatic scaling is also presented. The pilot implementation using six Adept robots and one \{IBM\} CloudBurst 2.1 private cloud and an ISA-95 based \{MES\} is described; the virtualization sequence is analyzed in several scenarios of resource workload collocation on physical cloud blades with and without perturbations. "
}
@article{Weinmann201547,
title = "Distinctive 2D and 3D features for automated large-scale scene analysis in urban areas ",
journal = "Computers & Graphics ",
volume = "49",
number = "",
pages = "47 - 57",
year = "2015",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2015.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S0097849315000072",
author = "M. Weinmann and S. Urban and S. Hinz and B. Jutzi and C. Mallet",
keywords = "3D scene analysis",
keywords = "Point cloud",
keywords = "Feature",
keywords = "Classification",
keywords = "Large-scale",
keywords = "Urban ",
abstract = "Abstract We propose a new methodology for large-scale urban 3D scene analysis in terms of automatically assigning 3D points the respective semantic labels. The methodology focuses on simplicity and reproducibility of the involved components as well as performance in terms of accuracy and computational efficiency. Exploiting a variety of low-level 2D and 3D geometric features, we further improve their distinctiveness by involving individual neighborhoods of optimal size. Due to the use of individual neighborhoods, the methodology is not tailored to a specific dataset, but in principle designed to process point clouds with a few millions of 3D points. Consequently, an extension has to be introduced for analyzing huge 3D point clouds with possibly billions of points for a whole city. For this purpose, we propose an extension which is based on an appropriate partitioning of the scene and thus allows a successive processing in a reasonable time without affecting the quality of the classification results. We demonstrate the performance of our methodology on two labeled benchmark datasets with respect to robustness, efficiency, and scalability. "
}
@article{Panwar201664,
title = "A survey on 5G: The next generation of mobile communication ",
journal = "Physical Communication ",
volume = "18, Part 2",
number = "",
pages = "64 - 84",
year = "2016",
note = "Special Issue on Radio Access Network Architectures and Resource Management for 5G ",
issn = "1874-4907",
doi = "https://doi.org/10.1016/j.phycom.2015.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S1874490715000531",
author = "Nisha Panwar and Shantanu Sharma and Awadhesh Kumar Singh",
keywords = "Cloud radio access networks",
keywords = "Cognitive radio networks",
keywords = "D2D communication",
keywords = "Dense deployment",
keywords = "Multi-tier heterogeneous network",
keywords = "Tactile Internet ",
abstract = "Abstract The rapidly increasing number of mobile devices, voluminous data, and higher data rate are pushing to rethink the current generation of the cellular mobile communication. The next or fifth generation (5G) cellular networks are expected to meet high-end requirements. The 5G networks are broadly characterized by three unique features: ubiquitous connectivity, extremely low latency, and very high-speed data transfer. The 5G networks would provide novel architectures and technologies beyond state-of-the-art architectures and technologies. In this paper, our intent is to find an answer to the question: “what will be done by 5G and how?” We investigate and discuss serious limitations of the fourth generation (4G) cellular networks and corresponding new features of 5G networks. We identify challenges in 5G networks, new technologies for 5G networks, and present a comparative study of the proposed architectures that can be categorized on the basis of energy-efficiency, network hierarchy, and network types. Interestingly, the implementation issues, e.g., interference, QoS, handoff, security–privacy, channel access, and load balancing, hugely effect the realization of 5G networks. Furthermore, our illustrations highlight the feasibility of these models through an evaluation of existing real-experiments and testbeds. "
}
@article{Salotti20152484,
title = "Small rover exploration capabilities ",
journal = "Advances in Space Research ",
volume = "55",
number = "10",
pages = "2484 - 2491",
year = "2015",
note = "Terrestrial Fieldwork to Support in situ Resource Utilization (ISRU) and Robotic Resource Prospecting for Future Activities in Space ",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2014.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0273117714006401",
author = "Jean-Marc Salotti and Corentin Laithier and Benoit Machut and Aurelien Marie and Audrey Bruneau and Gernot Gromer and Bernard H. Foing",
keywords = "Moon and Mars exploration",
keywords = "Rover",
keywords = "Mars analog",
keywords = "Human/robotic performance ",
abstract = "Abstract For a human mission to the Moon or Mars, an important question is to determine the best strategy for the choice of surface vehicles. Recent studies suggest that the first missions to Mars will be strongly constrained and that only small unpressurized vehicles will be available. We analyze the exploration capabilities and limitations of small surface vehicles from the user perspective. Following the “human centered design” paradigm, the team focused on human systems interactions and conducted the following experiments: – The Austrian Space Forum (OeWF) coordinated a Mars analog research program in Morocco in February 2013. During this 23-nation expedition, we studied surface mobility aspects in challenging terrains also to be expected on Mars. Two test subjects in high-fidelity spacesuit simulators and driving All-Terrain Vehicles (ATV, aka quads) had to traverse various obstacles found in a desert region and answer a list of questions about their vehicle, the obstacles and possible options to go further. – Another member of our team participated in the \{ILEWG\} EuroMoonMars 2013 simulation at the Mars Desert Research Station in Utah during the same period of time. Although the possible traverses were restricted, a similar study with analog space suits and quads has been carried out. – Other experiments have been conducted in an old rock quarry close to Bordeaux, France. An expert in the use of quads for all types of terrains performed a demonstration and helped us to characterize the difficulties, the risks and advantages and drawbacks of different vehicles and tools. The vehicles that will be used on the surface of Mars have not been defined yet. Nevertheless, the results of our project already show that using a light and unpressurized vehicle (in the order of 150 kg) for the mobility on the Martian surface can be a true advantage. Part of the study was dedicated to the search for appropriate tools that could be used to make the vehicles easier to handle, safer to use and more efficient in the field to cross an obstacle. The final recommendation is to use winches and ramps, which already are widely used by quad drivers. We report on the extension of the reachable areas if such tools were available. This work has been supported by ILEWG, EuroMoonMars and the Austrian Space Forum (OEWF). "
}
@article{Corti2016584,
title = "A metrological characterization of the Kinect \{V2\} time-of-flight camera ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "584 - 594",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002195",
author = "Andrea Corti and Silvio Giancola and Giacomo Mainetti and Remo Sala",
keywords = "Time-of-flight",
keywords = "Kinect v2",
keywords = "Characterization",
keywords = "Point Cloud Library",
keywords = "GUM",
keywords = "Metrological qualification ",
abstract = "Abstract A metrological characterization process for time-of-flight (TOF) cameras is proposed in this paper and applied to the Microsoft Kinect V2. Based on the Guide to the Expression of Uncertainty in Measurement (GUM), the uncertainty of a three-dimensional (3D) scene reconstruction is analysed. In particular, the random and the systematic components of the uncertainty are evaluated for the single sensor pixel and for the complete depth camera. The manufacturer declares an uncertainty in the measurement of the central pixel of the sensor of about few millimetres (Kinect for Windows Features, 2015), which is considerably better than the first version of the Microsoft Kinect (Chow et al., 2012  [1]). This work points out that performances are highly influenced by measuring conditions and environmental parameters of the scene; actually the 3D point reconstruction uncertainty can vary from 1.5 to tens of millimetres. "
}
@article{Charalampous2015166,
title = "Thorough robot navigation based on \{SVM\} local planning ",
journal = "Robotics and Autonomous Systems ",
volume = "70",
number = "",
pages = "166 - 180",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015000342",
author = "Konstantinos Charalampous and Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Path planning",
keywords = "SVM",
keywords = "Robot navigation",
keywords = "Point cloud ",
abstract = "Abstract A prerequisite for autonomous robot navigation is the extraction of a path that is both efficient and safe in terms of collision. Towards this end, the paper in hand presents a novel local path planning method, incorporating the support vector machines (SVM) theory. The original \{SVM\} based module exploits a 2D map of points which are considered to be obstacles, so as to culminate in a collision free path. A unique attribute of the proposed \{SVM\} based local path planning algorithm is that it considers the consecutive positions of the global path trajectory, the embodiment of the robot and clusters the obstacles accordingly. Thus, the derived trajectory is a physically constrained path inasmuch as it considers the maximum margin notion of the \{SVM\} theory. Instead of providing a purely theoretical approach for local planning assessed using only artificial data, we integrate our local planner into an autonomous navigation system which is evaluated in real-world scenarios in order to show its efficacy. The latter framework firstly constructs a global 3D metric map of the perceived environment and then it converts it into a 2D map upon which a global path planner unrolls. The global map grows incrementally, by registering the collected point clouds over the robot’s route towards a goal position. Moreover, the navigation is supported by an obstacle detection strategy based on v-disparity images. The system–and, consequently, the presented local path planner–was evaluated in long range outdoors scenarios, navigating successfully within congestive environments. "
}
@article{Brenner2016227,
title = "A Seamless Convergence of the Digital and Physical Factory Aiming in Personalized Product Emergence Process (PPEP) for Smart Products within \{ESB\} Logistics Learning Factory at Reutlingen University ",
journal = "Procedia \{CIRP\} ",
volume = "54",
number = "",
pages = "227 - 232",
year = "2016",
note = "6th \{CIRP\} Conference on Learning Factories ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.06.108",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309672",
author = "Beate Brenner and Vera Hummel",
keywords = "Seamless",
keywords = "digital cloud-based and physical learning factory",
keywords = "personalized product development",
keywords = "3D experience software",
keywords = "collaborative interactive environment",
keywords = "Industrie4.0 principles",
keywords = "SCRUM ",
abstract = "Abstract A seamless convergence of the digital and physical factory aiming in personalized Product Emergence Process (PPEP) for smart products within \{ESB\} Logistics Learning Factory at Reutlingen University. A completely new business model with reference to Industrie4.0 and facilitated by 3D Experience Software in today's networked society in which customers expect immediate responses, delightful experience and simple solutions is one of the mission scenarios in the \{ESB\} Logistics Learning Factory at \{ESB\} Business School (Reutlingen University). The business experience platform provides software solutions for every organization in the company respectively in the factory. An interface with dashboards, project management apps, 3D - design and construction apps with high end visualization, manufacturing and simulation apps as well as intelligence and social network apps in a collaborative interactive environment help the user to learn the creation of a value end to end process for a personalized virtual and later real produced product. Instead of traditional ways of working and a conventional operating factory real workers and robots work semi-intuitive together. Centerpiece in the self-planned interim factory is the smart personalized product, uniquely identifiable and locatable at all times during the production process – a scooter with an individual colored mobile phone – holder for any smart phone produced with a 3D printer in lot size one. Smart products have in the future solutions incorporated internet based services – designed and manufactured - at the costs of mass products. Additionally the scooter is equipped with a retrievable declarative product memory. Monitoring and control is handled by sensor tags and a raspberry positioned on the product. The engineering design and implementation of a changeable production system is guided by a self-execution system that independently find amongst others esplanade workplaces. The imparted competences to students and professionals are project management method SCRUM, customization of workflows by Industrie4.0 principles, the enhancements of products with new personalized intelligent parts, electrical and electronic self-programmed components and the control of access of the product memory information, to plan in a digital engineering environment and set up of the physical factory to produce customer orders. The gained action-orientated experience refers to the chances and requirements for holistic digital and physical systems. "
}
@article{Huxtable201646,
title = "On Servitization of the Manufacturing Industry in the \{UK\} ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "46 - 51",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.042",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116307922",
author = "James Huxtable and Dirk Schaefer",
keywords = "Servitization",
keywords = "Industry 4.0",
keywords = "Big Data",
keywords = "Cloud-Based Design and Manufacturing",
keywords = "Cyber Security",
keywords = "Autonomy ",
abstract = "Abstract For a number of years, an increase in manufacturing-related service activities being provided by third parties rather than “in-house” departments has been observed. This trend appears to be strengthening in the context of the Industry 4.0 landscape. The purpose of this paper is to investigate in what sense and at what rate the domain of manufacturing in the \{UK\} is transitioning into a major service-oriented field and what types of manufacturing-related activities are most/least suitable for future servitization. Hence, the paper addresses the following questions: i) To what extent has Servitization been adopted in the UK? – What impact is Industry 4.0 currently making? ii) What types of services are currently being offered as a result of industry 4.0? iii) What pros/cons/opportunities/threats does Industry 4.0 bring to British Servitization? – What wider economic issues will make an impact? The research summarized in this paper presents an answer to the outlined questions and draws conclusions as to how this field may further develop in future. The main contributions of this research are the closing of a critical gap in literature by investigating the relationships between the two fields of Servitization and Industry 4.0, and the creation of a framework to allow companies to make themselves aware of Industry 4.0-related services, whilst ensuring these new service innovations are offered in-line with their current business model. "
}
@article{Monica2016627,
title = "A KinFu based approach for robot spatial attention and view planning ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "627 - 640",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001980",
author = "Riccardo Monica and Jacopo Aleotti and Stefano Caselli",
keywords = "KinectFusion",
keywords = "Point Cloud Library",
keywords = "Robot spatial attention ",
abstract = "Abstract When a user and a robot share the same physical workspace the robot may need to keep an updated 3D representation of the environment. Indeed, robot systems often need to reconstruct relevant parts of the environment where the user executes manipulation tasks. This paper proposes a spatial attention approach for a robot manipulator with an eye-in-hand Kinect range sensor. Salient regions of the environment, where user manipulation actions are more likely to have occurred, are detected by applying a clustering algorithm based on Gaussian Mixture Models applied to the user hand trajectory. A motion capture sensor is used for hand tracking. The robot attentional behavior is driven by a next-best view algorithm that computes the most promising range sensor viewpoints to observe the detected salient regions, where potential changes in the environment have occurred. The environment representation is built upon the \{PCL\} KinFu Large Scale project [1], an open source implementation of KinectFusion. KinFu has been modified to support the execution of the next-best view algorithm directly on the \{GPU\} and to properly manage voxel data. Experiments are reported to illustrate the proposed attention based approach and to show the effectiveness of GPU-based next-best view planning compared to the same algorithm executed on the CPU. "
}
@article{Brad2015498,
title = "Employing Smart Units and Servitization towards Reconfigurability of Manufacturing Processes ",
journal = "Procedia \{CIRP\} ",
volume = "30",
number = "",
pages = "498 - 503",
year = "2015",
note = "7th Industrial Product-Service Systems Conference - PSS, industry transformation for sustainability and business ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.02.154",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115004679",
author = "Stelian Brad and Mircea Murar",
keywords = "sevicization",
keywords = "reconfigurability",
keywords = "smart units",
keywords = "robotic systems",
keywords = "embedded systems ",
abstract = "Abstract Increasing environmental concerns together with the need for sustainable consumption and production gave birth to the concept of product service-system. This paperwork presents how the concept of product-service systems (PSS), also known as servitization, can increase performance within the value creation chain in the manufacturing environment by deployingits key features within smart manufacturing units to provide them withreconfigurabilityproperties. Highlights on how thekey feature of a product-service system can be used to enable the deployment of reconfigurability within smart manufacturing units towards achieving the concept of reconfigurable manufacturing systems are revealed in the first part of the paper.Considering the new economic models, the ever changing society needs and the effects of disruptive innovations, a business model for manufacturing environmentis further proposed. The business model deploys small scale reconfigurable manufacturing systems by means of smart manufacturing units, intelligent information management platforms, cloud computing services and Internet of Things. An experimental test bench is afterwards presentedin this context. Three similar manufacturing scenarios are considered and reproduced viaa mix ofsix smart manufacturing units and interfaces. The goal of these scenarios isto test the feasibility of servitization towards achieving reconfigurability of smart units.Several industrial equipment among which a dual-arm industrial robot, two electro-mechanical grippers, two electro-mechanical axes and two proximity sensors areintegrated with the embedded system to enable the deployment of \{PSS\} features. Also, how servitization is deployed within available smart units, their generic architecture and how they are interconnected is presented in the paper,together with advantages and constraints of the proposed experimental approach. The paper ends with conclusions, remarks regarding the experimental tests and further research directions. "
}
@incollection{Kaklauskas2016413,
title = "17 - Intelligent decision-support systems and the Internet of Things for the smart built environment ",
editor = "Pacheco-Torgal, Fernando and , and Rasmussen, Erik and , and Granqvist, Claes-Goran and , and Ivanov, Volodymyr and , and Kaklauskas, Arturas and ,  and Makonin, Stephen ",
booktitle = "Start-Up Creation ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2016",
pages = "413 - 449",
isbn = "978-0-08-100546-0",
doi = "https://doi.org/10.1016/B978-0-08-100546-0.00017-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780081005460000170",
author = "A. Kaklauskas and R. Gudauskas",
keywords = "Built environment",
keywords = "Cloud computing",
keywords = "Machine-to-machine",
keywords = "Internet of Things ",
abstract = "Abstract Potential applications of the Internet of Things (IoT) for the built environment are many and various, fitting into almost all activities done by persons, organizations, and the community as a whole. The active use of electronics, software, sensors, and network connectivity has taken off in the built environment, and these physical devices operating in the built environment can send and receive data via the existing Internet infrastructure. This chapter outlines the general theory (the definition, characteristics, components, etc.) and analyses several specific examples and applications of the IoT in the built environment. It proceeds with an analysis of possibilities to integrate intelligent decision support systems with IoT in the built environment. Such instances are not numerous in the world. The chapter also discusses the main trends and the future of IoT in the built environment. It then ends with the IoT start-ups. "
}
@article{Tiedemann2016570,
title = "An Automotive Distributed Mobile Sensor Data Collection with Machine Learning Based Data Fusion and Analysis on a Central Backend System ",
journal = "Procedia Technology ",
volume = "26",
number = "",
pages = "570 - 579",
year = "2016",
note = "3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2016.08.071",
url = "http://www.sciencedirect.com/science/article/pii/S2212017316304182",
author = "Tim Tiedemann and Christian Backe and Thomas Vogele and Peter Conradi",
keywords = "Sensor Cloud",
keywords = "Pervasive Computing",
keywords = "Distributed ML",
keywords = "IoT",
keywords = "Big Data ",
abstract = "Abstract One of the most extensive examples for ubiquitous computing today is automotion. The equipment of sensors and independent computing devices in current vehicles is vast if not endless. Furthermore, traffic infrastructure is realized using global and local computing devices. Communication initiated by the car itself (e.g., to an emergency hotline) will be obligatory in some countries soon. And finally, by using a smart phone the driver brings an additional powerful computing device and sensor set to the vehicle. However, all these automotive sensors and computing devices are used just for fixed (and in most cases single) purposes. Data exchange between vehicles or vehicles and infrastructure is rarely done. And dynamic changes like compensating for a broken sensor with available other data, using old sensor equipment for new functions, or improving old driver assistance systems with new sensors is not possible, either. The objective of the collaborative research project Smart Adaptive Data Aggregation (SADA) is to develop technologies that enable linking data from distributed mobile on-board sensors (on vehicles) with data from previously unknown stationary (e.g., infrastructure) or mobile sensors (e.g., other vehicles, smart devices). One focus of the project is the dynamic and fully-automated switching between different sensors or sensor configurations, including the adaptation of data fusion processes. Technically, one important component for some of the \{SADA\} use cases is a central backend system that (1) collects sensor data of the vehicles and/or the infrastructure, (2) fuses these data, and (3) carries out machine learning (ML) based analysis of the data to generate new information for the drivers (sometimes refered to by the term “virtual sensors”). The article gives a short overview of the \{SADA\} project and describes in more detail the concept of the backend system architec- ture, the user interface, and the methods and processes needed for a demonstration use-case. "
}
@article{Berglund2016697,
title = "On The Trade-off between Data Density and Data Capture Duration in 3D Laser Scanning for Production System Engineering ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "697 - 701",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.141",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116000366",
author = "Jonatan Berglund and Erik Lindskog and Bjorn Johansson",
keywords = "3D scanning",
keywords = "Virtual",
keywords = "Production",
keywords = "Point cloud ",
abstract = "Abstract 3D laser scanning is a technology for capture of spatial data in three dimensions. The technology originates from the field of surveying and has since been spread to several other application areas. In the realm of production system engineering, 3D laser scanning is primarily used to verify equipment installation. Lately applications for the 3D scan data are emerging also when it comes to the planning of the installations and the use of the equipment. The motivation for using 3D scan data in the case of planning is primarily to have up-to-date and verified spatial data, including any undocumenter alterations from drawings and models. The process of capturing 3D scan data requires access to an unmoving production system which can be costly, either due to stopping produciton or by accessing it during nights or weekends. The more detailed the data collection is, the more time is required. Therefore there is a need to accurately define and plan the minimum data density requirement. This paper evaluates the effect of data density, and thus data collection duration, in a production system application. Data capture duration is shown to impact the usability of the resulting data. To further understand the trade-off and be able to use it as decision support there needs to be an analysis of the additional time and data storage costs created by increasing the number of scan locations. "
}
@article{Badr20152623,
title = "Resilient and Trustworthy Dynamic Data-driven Application Systems (DDDAS) Services for Crisis Management Environments ",
journal = "Procedia Computer Science ",
volume = "51",
number = "",
pages = "2623 - 2637",
year = "2015",
note = "International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.05.370",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915011783",
author = "Youakim Badr and Salim Hariri and Youssif AL-Nashif and Erik Blasch",
keywords = "rDaaS",
keywords = "resilience",
keywords = "cloud computing",
keywords = "service-oriented computing",
keywords = "trust and security ",
abstract = "Abstract Future crisis management systems needresilient and trustworthy infrastructures to quickly develop reliable applications and processes, andensure end-to-end security, trust, and privacy. Due to the multiplicity and diversity of involved actors, volumes of data, and heterogeneity of shared information;crisis management systems tend to be highly vulnerable and subjectto unforeseen incidents. As a result, the dependability of crisis management systems can be at risk. This paper presents a cloud-based resilient and trustworthy infrastructure (known as rDaaS) to quickly develop securecrisis management systems. The rDaaSintegrates the Dynamic Data-DrivenApplication Systems (DDDAS) paradigm into a service-oriented architectureover cloud technology andprovidesa set of resilient DDDAS-As-A Service (rDaaS)components to build secure and trusted adaptable crisis processes. The rDaaSalso ensures resilience and security by obfuscating the execution environment andapplying Behavior Software Encryption and Moving Technique Defense. A simulation environment for a nuclear plant crisis managementcase study is illustrated to build resilient and trusted crisis response processes. "
}
@article{Xie2015114,
title = "Study of the scanning lidar on the atmospheric detection ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "150",
number = "",
pages = "114 - 120",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part I ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003677",
author = "Chenbo Xie and Ming Zhao and Bangxin Wang and Zhiqing Zhong and Lin Wang and Dong Liu and Yingjian Wang",
keywords = "Scanning lidar",
keywords = "Polarization",
keywords = "Aerosol",
keywords = "Cloud ",
abstract = "Abstract The scanning polarization Mie lidar (SPML) system has been developed and is described. The lidar system has two detection channels to receive the parallel and perpendicular polarization components at the laser wavelength of 532 nm, which indicates the nonsphericity of aerosol and cloud particles. It can take the horizontal, vertical and conical scans of the atmosphere with the elevation and azimuth motors. This paper discusses the current capability of the \{SPML\} lidar and its results. The observation shows that the \{SPML\} lidar can provide the multi-dimensional views of the atmosphere which is impossible to achieve with other ground-based vertically pointing lidars. It is helpful to track and monitor aerosol plumes in urban area, to determinate the planetary boundary layer height and to enhance the measurement of atmosphere in the lower height where the geometrical form factor of lidar system affects. "
}
@article{RamirezPedraza2015189,
title = "Deteccion de Automoviles en Escenarios Urbanos Escaneados por un Lidar ",
journal = "Revista Iberoamericana de Automatica e Informatica Industrial \{RIAI\} ",
volume = "12",
number = "2",
pages = "189 - 198",
year = "2015",
note = "",
issn = "1697-7912",
doi = "https://doi.org/10.1016/j.riai.2015.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1697791215000084",
author = "Alfonso Ramirez-Pedraza and Jose-Joel Gonzalez-Barbosa and Francisco-Javier Ornelas-Rodriguez and Angel-Ivan Garcia-Moreno and Adan Salazar-Garibay and Erick-Alejandro Gonzalez-Barbosa",
keywords = "Nube de Puntos 3D",
keywords = "LIDAR",
keywords = "Segmentacion 3D.",
keywords = "3D point cloud",
keywords = "Lidar",
keywords = "3D Segmentation. ",
abstract = "Abstract Detection of vehicles on 3D point clouds is performed by using the algorithm presented in this work. Point clouds correspond to urban environments and were acquired with the \{LIDAR\} Velodyne HDL-64E. The environment is considered semi-structured so that can be modeled using planes. Vehicle detection is carried out on to stages, segmentation and indexation. First stage is at the same time composed of three sub-stages. In the first one the principal plane (in this case the floor) is extracted, in the second sub-stage secondary planes are extracted using a tailored version of Hough's method, secondary planes are those perpendicular to the main plane. Finally in the third sub-stage and using MeanShift method, the remaining objects are segmented. Indexation on its side is divided into two sub-stages, in the first one, last segmented objects using MeanShift method are modeled using histograms according to the direction of the object's 3D points normal; in the second stage histograms are compared to those previously stored on a database of object's histograms. Optimizing of detection thresholds was carried out through \{ROC\} analysis. Two databases were used during the experiments, the first \{DB\} have 4500 objects and was used for \{ROC\} analysis training; the second one contained 3000 objects and was used for verification. "
}
@article{Urbanova201577,
title = "Testing photogrammetry-based techniques for three-dimensional surface documentation in forensic pathology ",
journal = "Forensic Science International ",
volume = "250",
number = "",
pages = "77 - 86",
year = "2015",
note = "",
issn = "0379-0738",
doi = "https://doi.org/10.1016/j.forsciint.2015.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0379073815001073",
author = "Petra Urbanova and Petr Hejna and Mikolas Jurda",
keywords = "Postmortem documentation",
keywords = "Optical surface scanning",
keywords = "Photogrammetry",
keywords = "Point cloud comparison ",
abstract = "Abstract Three-dimensional surface technologies particularly close range photogrammetry and optical surface scanning have recently advanced into affordable, flexible and accurate techniques. Forensic postmortem investigation as performed on a daily basis, however, has not yet fully benefited from their potentials. In the present paper, we tested two approaches to 3D external body documentation – digital camera-based photogrammetry combined with commercial Agisoft PhotoScan® software and stereophotogrammetry-based Vectra H1®, a portable handheld surface scanner. In order to conduct the study three human subjects were selected, a living person, a 25-year-old female, and two forensic cases admitted for postmortem examination at the Department of Forensic Medicine, Hradec Kralove, Czech Republic (both 63-year-old males), one dead to traumatic, self-inflicted, injuries (suicide by hanging), the other diagnosed with the heart failure. All three cases were photographed in 360° manner with a Nikon 7000 digital camera and simultaneously documented with the handheld scanner. In addition to having recorded the pre-autopsy phase of the forensic cases, both techniques were employed in various stages of autopsy. The sets of collected digital images (approximately 100 per case) were further processed to generate point clouds and 3D meshes. Final 3D models (a pair per individual) were counted for numbers of points and polygons, then assessed visually and compared quantitatively using \{ICP\} alignment algorithm and a cloud point comparison technique based on closest point to point distances. Both techniques were proven to be easy to handle and equally laborious. While collecting the images at autopsy took around 20 min, the post-processing was much more time-demanding and required up to 10 h of computation time. Moreover, for the full-body scanning the post-processing of the handheld scanner required rather time-consuming manual image alignment. In all instances the applied approaches produced high-resolution photorealistic, real sized or easy to calibrate 3D surface models. Both methods equally failed when the scanned body surface was covered with body hair or reflective moist areas. Still, it can be concluded that single camera close range photogrammetry and optical surface scanning using Vectra \{H1\} scanner represent relatively low-cost solutions which were shown to be beneficial for postmortem body documentation in forensic pathology. "
}
@article{Zahawi2015287,
title = "Using lightweight unmanned aerial vehicles to monitor tropical forest recovery ",
journal = "Biological Conservation ",
volume = "186",
number = "",
pages = "287 - 295",
year = "2015",
note = "",
issn = "0006-3207",
doi = "https://doi.org/10.1016/j.biocon.2015.03.031",
url = "http://www.sciencedirect.com/science/article/pii/S0006320715001421",
author = "Rakan A. Zahawi and Jonathan P. Dandois and Karen D. Holl and Dana Nadwodny and J. Leighton Reid and Erle C. Ellis",
keywords = "Canopy structure",
keywords = "Costa Rica",
keywords = "Drone",
keywords = "Ecosynth",
keywords = "Hexacopter",
keywords = "LiDAR",
keywords = "Point cloud model ",
abstract = "Abstract Large areas of tropical lands are being removed from agriculture and restored to address conservation goals. However, monitoring the ecological value of these efforts at the individual land-owner scale is rare, owing largely to issues of cost and accessibility. Traditional field-based measures for assessing forest recovery and habitat quality can be labour intensive and costly. Here we assess whether remote sensing measurements from lightweight unmanned aerial vehicles (UAV) are a cost-effective substitute for traditional field measures. An inexpensive UAV-based remote sensing methodology, “Ecosynth”, was applied to measure forest canopy structure across field plots in a 7–9-yr tropical forest restoration study in southern Costa Rica. Ecosynth methods combine aerial images from consumer-grade digital cameras with computer vision software to generate 3D ‘point cloud’ models of vegetation at high spatial resolutions. Ecosynth canopy structure measurements were compared to field-based measures and their ability to predict the abundance of frugivorous birds; key seed dispersers that are sensitive to canopy structure. Ecosynth canopy height measurements were highly correlated with field-based measurements (R2 ⩾ 0.85), a result comparable in precision to LiDAR-based remote sensing measurements. Ecosynth parameters were also strongly correlated with above-ground biomass (R2 ⩾ 0.81) and percent canopy openness (R2 = 0.82). Correlations were weaker with proportion-based measures such as canopy roughness (R2 = 0.53). Several Ecosynth metrics (e.g., canopy openness and height) predicted frugivore presence and abundance at levels of accuracy similar to those of field-based measurements. Ecosynth \{UAV\} remote-sensing provides an effective alternate methodology to traditional field-based measures of evaluating forest structure and complexity across landscapes. Furthermore, given the volume of data that can be generated in a single flight plan, as well as the ability to use the technology in remote areas, these methods could expand the scope of studies on forest dynamics and recovery when combined with field-based calibration plots. "
}
@article{Wang20152603,
title = "Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring ",
journal = "Procedia Computer Science ",
volume = "51",
number = "",
pages = "2603 - 2612",
year = "2015",
note = "International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.05.368",
url = "http://www.sciencedirect.com/science/article/pii/S187705091501176X",
author = "Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson",
keywords = "Bayesian Computational Sensor Networks",
keywords = "Uncertainty",
keywords = "Structural Health Monitoring",
keywords = "Cloud Computing ",
abstract = "Abstract The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments. "
}
@article{Gazzarata20151124,
title = "A Standardized \{SOA\} Based Solution to Guarantee the Secure Access to \{EHR\} ",
journal = "Procedia Computer Science ",
volume = "64",
number = "",
pages = "1124 - 1129",
year = "2015",
note = "Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2015 October 7-9, 2015 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.582",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915027179",
author = "Giorgia Gazzarata and Roberta Gazzarata and Mauro Giacomini",
keywords = "auditability",
keywords = "access control",
keywords = "interoperability",
keywords = "secure use of cloud for clinical data ",
abstract = "Abstract Continued advances in science and technology and general improvements in environmental and social conditions is extending the population's life expectancy with the consequence that a person can undergo many episodes of healthcare during lifetime. In this context, the Electronic Health Record (EHR) represents a fundamental tool to support treatment continuity, education and research. The economic restrictions in healthcare and the need to increase efficiency in term of cost/effectiveness ration could lead institutional organizations to choose cloud solutions to host the EHR. In this paper, a cloud infrastructure architecture, focus on the \{EHR\} and based on \{SOA\} (Service Oriented Architecture) paradigm, which is able both to completely support technical, semantic and process interoperability, and to guarantee security, is proposed. In order to achieve this goal, the indications and the standards proposed by Healthcare Services Specification Project (HSSP) was adopted. Different situations can be managed by the proposed architecture and are described: the user access to an encrypted resource in EHR, the availability of \{EHR\} content for external Decision Support Systems, the update of \{EHR\} content, the management of semantic of clinical data exchanged among distributed healthcare organizations. Finally, the authors propose a discussion on the proposed solution. "
}
@article{Ridao2015227,
title = "Intervention AUVs: The next challenge ",
journal = "Annual Reviews in Control ",
volume = "40",
number = "",
pages = "227 - 241",
year = "2015",
note = "",
issn = "1367-5788",
doi = "https://doi.org/10.1016/j.arcontrol.2015.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S1367578815000541",
author = "Pere Ridao and Marc Carreras and David Ribas and Pedro J. Sanz and Gabriel Oliver",
keywords = "Autonomous Vehicles",
keywords = "Robotic Manipulators",
keywords = "Marine Systems ",
abstract = "Abstract While commercially available \{AUVs\} are routinely used in survey missions, a new set of applications exist which clearly demand intervention capabilities. The maintenance of permanent underwater observatories, submerged oil wells, cabled sensor networks, pipes and the deployment and recovery of benthic stations are a few of them. These tasks are addressed nowadays using manned submersibles or work-class ROVs, equipped with teleoperated arms under human supervision. Although researchers have recently opened the door to future I-AUVs, a long path is still necessary to achieve autonomous underwater interventions. This paper reviews the evolution timeline in autonomous underwater intervention systems. Milestone projects in the state of the art are reviewed, highlighting their principal contributions to the field. To the best of the authors’ knowledge, only three vehicles have demonstrated some autonomous intervention capabilities so far: ALIVE, \{SAUVIM\} and \{GIRONA\} 500, being the last one the lightest one. In this paper \{GIRONA\} 500 I-AUV is presented and its software architecture discussed. Recent results in different scenarios are reported: (1) valve turning and connector plugging/unplugging while docked to a subsea panel, (2) free floating valve turning using learning by demonstration, and (3) multipurpose free-floating object recovery. The paper ends discussing the lessons learned so far. "
}
@article{Zhu20151171,
title = "Research on 3D Virtual Environment Modeling Technology for Space Tele-robot ",
journal = "Procedia Engineering ",
volume = "99",
number = "",
pages = "1171 - 1178",
year = "2015",
note = "2014 Asia-Pacific International Symposium on Aerospace Technology, \{APISAT2014\} September 24-26, 2014 Shanghai, China ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.12.700",
url = "http://www.sciencedirect.com/science/article/pii/S187770581403817X",
author = "Biyu Zhu and Aiguo Song and Xiaonong Xu and Song Li",
keywords = "Virtual environment",
keywords = "3D modeling",
keywords = "Tele-robot system",
keywords = "Point cloud data",
keywords = "RANSAC ",
abstract = "Abstract To overcome the time delay in tele-robot system, a new 3D virtual environment modeling technology is proposed in this paper. The interactions between slave robot and environment can be attained in advance in a 3D virtual environment in the master side, therefore an accurate operation of space tele-robot can be realized and the effect of time delay would be minimized. Firstly, 3D virtual interaction scenario is modeled as a point cloud data image, and the target objects are recognized from the image and reconstructed by using Random Sample And Consensus (RANSAC) algorithm. Secondly, an effective method is proposed to modify the position of virtual robot and calculate the virtual interactive force between the virtual robot and the virtual objects. Lastly, the experiment is completed with the time delay. The errors are lower (10% F.S.), while virtual interaction force is compared with the real force measured by the force sensor. Experimental results show that this 3D virtual environment modeling method is effective and reliable for space tele-robot control. "
}
@article{Watanabe20151664,
title = "A Framework to Evaluate the Performance of Disperse Productive System through Sustainability Performance Indicators ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "1664 - 1669",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.325",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315005649",
author = "Edson H. Watanabe and Mauricio F. Blos and Robson M. da Silva and Fabricio Junqueira and Diolino J. Santos Filho and Paulo E. Miyagi",
keywords = "sustainability",
keywords = "performance evaluation",
keywords = "Petri net",
keywords = "framework",
keywords = "disperse productive systems",
keywords = "cloud computing ",
abstract = "Abstract Productive systems (PS) should currently consider the efficient use of resources (such as technological transformation, handling and material transport) besides the dispersed distribution of productive plants and sustainability concepts to allow the adequate use of environmental resources and reduce costs through local facilities. However, in the literature there are not widely accepted criteria to evaluate this class of Sustainable and Dispersed Productive Systems (SDPS). Therefore, this work introduces a framework for \{SDPS\} performance evaluation by extending the system requirements in the ANSI/ISA-95 standard specifications. Petri net (PN) technique and its extension, Production Flow Schema (PFS), are used to systematize the collection of production data and indexes to evaluating the \{SDPS\} performance. Cloud computing technology is also considered to provide resources to access information from SDPS. The presented method allows obtaining and choosing the better indicator for sustainable SDPS. "
}
@article{Choobari2014152,
title = "The global distribution of mineral dust and its impacts on the climate system: A review ",
journal = "Atmospheric Research ",
volume = "138",
number = "",
pages = "152 - 165",
year = "2014",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2013.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0169809513003281",
author = "O. Alizadeh Choobari and P. Zawar-Reza and A. Sturman",
keywords = "Mineral dust aerosols",
keywords = "Radiative forcing",
keywords = "Semi-directly",
keywords = "Indirect effect",
keywords = "Climate system",
keywords = "Cloud microphysics ",
abstract = "Abstract Mineral dust aerosols, the tiny soil particles suspended in the atmosphere, have a key role in the atmospheric radiation budget and hydrological cycle through their radiative and cloud condensation nucleus effects. Current understanding of spatial and temporal variations of mineral dust, as well as its impacts on the climate system and cloud properties is outlined. Mineral dust aerosols are blown into the atmosphere mainly from arid and semi-arid regions where annual rainfall is extremely low and substantial amounts of alluvial sediment have been accumulated over long periods. They are subject to long-range transport of an intercontinental scale, including North African dust plumes over the Atlantic Ocean, summer dust plumes from the Arabian Peninsula over the Arabian Sea and Indian Ocean and spring dust plumes from East Asia over the Pacific Ocean. Mineral dust aerosols influence the climate system and cloud microphysics in multiple ways. They disturb the climate system directly by scattering and partly absorbing shortwave and longwave radiation, semi-directly by changing the atmospheric cloud cover through evaporation of cloud droplets (i.e. the cloud burning effect), and indirectly by acting as cloud and ice condensation nuclei, which changes the optical properties of clouds (i.e. the first indirect effect), and may decrease or increase precipitation formation (i.e. the second indirect effect). Radiative forcing by mineral dust is associated with changes in atmospheric dynamics that may change the vertical profile of temperature and wind speed, through which a feedback effect on dust emission can be established. "
}
@article{Bosse201556,
title = "Unified Distributed Computing and Co-ordination in Pervasive/Ubiquitous Networks with Mobile Multi-Agent Systems using a Modular and Portable Agent Code Processing Platform ",
journal = "Procedia Computer Science ",
volume = "63",
number = "",
pages = "56 - 64",
year = "2015",
note = "The 6th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2015)/ The 5th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2015)/ Affiliated Workshops ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.312",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915024400",
author = "Stefan Bosse",
keywords = "Sensor Networks",
keywords = "Cloud Computing",
keywords = "Mobile Agents",
keywords = "Heterogeneous Networks",
keywords = "Embedded Systems",
keywords = "Agent Processing Platform ",
abstract = "Abstract A novel and unified approach for reliable distributed and parallel computing using mobile agents is introduced. The agents can be deployed in large scale and hierarchical network environments crossing barriers transparently. The networks can consist of high- and low-resource nodes ranging from generic computers to microchips, and the supported network classes range from body area networks to the Internet including any kind of sensor and ambient network. Agents are represented by mobile program code that can be modified at run-time. The presented approach enables the development of sensor clouds and smart systems of the future integrated in daily use computing environments and the Internet. Agents can migrate between different hardware and software platforms by migrating the program code of the agent, embedding the state and the data of an agent, too. The entire information exchange and coordination of agents with other agents and the environment is performed by using a tuple space database. Beside architecture specific hardware and software implementations of the agent processing platform, there is a JavaScript (JS) implemen- tation layered on the top of a distributed management layer. The \{JS\} platform enables the integration of Multi-agent Systems (MAS) in Internet server and application environments (e.g., \{WEB\} browser). Agents can migrate transparently between hardware-level sensor networks and \{WEB\} browser applications or network servers and vice versa without any transformation required. "
}
@article{Francis2014776,
title = "Observations of wind direction by automated analysis of images from Mars and the \{MSL\} rover ",
journal = "Acta Astronautica ",
volume = "94",
number = "2",
pages = "776 - 783",
year = "2014",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2013.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094576513003548",
author = "Raymond Francis and John Moores and Kenneth McIsaac and David Choi and Gordon Osinski",
keywords = "Computer vision",
keywords = "Normalized cross-correlation",
keywords = "Winds",
keywords = "Clouds",
keywords = "Planetary atmospheres",
keywords = "Mars Science Laboratory ",
abstract = "Abstract Past missions to Mars have revealed the presence of clouds in the atmosphere, visible both from the surface and from orbit. Where atmospheric sounding instrumentation is not available, the motion of such clouds can be used as a proxy for wind observations. Such observations aid in the study of the Martian climate, as well as of mass and moisture transport in the atmosphere. An understanding of the water cycle on Mars has important implications for models of the transport, distribution, and preservation of any biomarkers which might exist from past or present life on the planet. The present work describes an algorithm for automated image analysis, the function of which is to identify clouds in sequences of images of the Martian sky, and to track their movement across frames in the sequence to allow a calculation of the wind vector. The system is currently under development using imagery from previous surface missions, particularly the Phoenix lander, for reference and test. Past work has used these images for manual tracking of clouds and wind estimation; the current effort aims to automate the process to allow faster and more accurate analysis. The work will be finalized with the availability of data from the NavCam imager aboard the Mars Science Laboratory (MSL) rover, now operating on Mars since August 2012. Once tested with the \{MSL\} imagery, the system will be used for regular observations of the wind in the atmosphere near the \{MSL\} landing site. The image-analysis strategy used in the algorithm is presented, and its performance to date in recognizing the types of clouds expected on Mars is described. The tracking performance between frames in the reference data is shown, and the future utility of the system is described. The work is undertaken under a \{NASA\} Participating Scientist project, with support from the Canadian Space Agency. "
}
@article{Nurunnabi2014106,
title = "Robust statistical approaches for local planar surface fitting in 3D laser scanning data ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "96",
number = "",
pages = "106 - 122",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614001762",
author = "Abdul Nurunnabi and David Belton and Geoff West",
keywords = "3D modelling",
keywords = "Feature extraction",
keywords = "Normal estimation",
keywords = "Outlier",
keywords = "Plane fitting",
keywords = "Point cloud",
keywords = "Robustness",
keywords = "Segmentation",
keywords = "Surface reconstruction ",
abstract = "Abstract This paper proposes robust methods for local planar surface fitting in 3D laser scanning data. Searching through the literature revealed that many authors frequently used Least Squares (LS) and Principal Component Analysis (PCA) for point cloud processing without any treatment of outliers. It is known that \{LS\} and \{PCA\} are sensitive to outliers and can give inconsistent and misleading estimates. \{RANdom\} \{SAmple\} Consensus (RANSAC) is one of the most well-known robust methods used for model fitting when noise and/or outliers are present. We concentrate on the recently introduced Deterministic Minimum Covariance Determinant estimator and robust PCA, and propose two variants of statistically robust algorithms for fitting planar surfaces to 3D laser scanning point cloud data. The performance of the proposed robust methods is demonstrated by qualitative and quantitative analysis through several synthetic and mobile laser scanning 3D data sets for different applications. Using simulated data, and comparisons with LS, PCA, RANSAC, variants of \{RANSAC\} and other robust statistical methods, we demonstrate that the new algorithms are significantly more efficient, faster, and produce more accurate fits and robust local statistics (e.g. surface normals), necessary for many point cloud processing tasks. Consider one example data set used consisting of 100 points with 20% outliers representing a plane. The proposed methods called DetRD-PCA and DetRPCA, produce bias angles (angle between the fitted planes with and without outliers) of 0.20° and 0.24° respectively, whereas LS, \{PCA\} and \{RANSAC\} produce worse bias angles of 52.49°, 39.55° and 0.79° respectively. In terms of speed, DetRD-PCA takes 0.033 s on average for fitting a plane, which is approximately 6.5, 25.4 and 25.8 times faster than RANSAC, and two other robust statistical methods, respectively. The estimated robust surface normals and curvatures from the new methods have been used for plane fitting, sharp feature preservation and segmentation in 3D point clouds obtained from laser scanners. The results are significantly better and more efficiently computed than those obtained by existing methods. "
}
@article{Mahowald201453,
title = "The size distribution of desert dust aerosols and its impact on the Earth system ",
journal = "Aeolian Research ",
volume = "15",
number = "",
pages = "53 - 71",
year = "2014",
note = "",
issn = "1875-9637",
doi = "https://doi.org/10.1016/j.aeolia.2013.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S1875963713000736",
author = "Natalie Mahowald and Samuel Albani and Jasper F. Kok and Sebastian Engelstaeder and Rachel Scanza and Daniel S. Ward and Mark G. Flanner",
keywords = "Desert dust",
keywords = "Size distribution",
keywords = "Biogeochemistry",
keywords = "Radiative effects",
keywords = "Indirect effects on clouds ",
abstract = "Abstract The global cycle of desert dust aerosols responds strongly to climate and human perturbations, and, in turn, impacts climate and biogeochemistry. Here we focus on desert dust size distributions, how these are characterized, emitted from the surface, evolve in the atmosphere, and impact climate and biogeochemistry. Observations, theory and global model results are synthesized to highlight the evolution and impact of dust sizes. Individual particles sizes are, to a large extent, set by the soil properties and the mobilization process. The lifetime of different particle sizes controls the evolution of the size distribution as the particles move downwind, as larger particles fall out more quickly. The dust size distribution strongly controls the radiative impact of the aerosols, as well as their interactions with clouds. The size of particles controls how far downwind they travel, and thus their ability to impact biogeochemistry downwind of the source region. "
}
@article{Chougule2014212,
title = "Development of patient specific implants for Minimum Invasive Spine Surgeries (MISS) from non-invasive imaging techniques by reverse engineering and additive manufacturing techniques ",
journal = "Procedia Engineering ",
volume = "97",
number = "",
pages = "212 - 219",
year = "2014",
note = "'12th Global Congress on Manufacturing and Management' \{GCMM\} - 2014 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.12.244",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814033037",
author = "V.N. Chougule and A.V. Mulay and B.B. Ahuja",
keywords = "Point Cloud Data",
keywords = "CT scans",
keywords = "Image Processing",
keywords = "threshold",
keywords = "NURBs",
keywords = "free form surface ",
abstract = "Abstract Reverse Engineering and Rapid Prototyping are extensively used technologies by both research and industrial community for rapid developments in various industrial as well as Bio-medical applications. Recent advances in computer technology and Bio-medicines enabled Computer Aided Design (CAD) to find many novel applications in Bio-medical engineering and integration of \{CAD\} and Bio-medical technology is usually referred as Bio-CAD. The major objective of the current research work is to generate an efficient algorithm for generation of free form surface from non-invasive \{CT\} scan images. Minimally Invasive Spine Surgery (MISS) have enabled spinal surgeons to select patients and treat several spinal disorders like degenerative disc disease, herniated disc, fractures, tumors, infections, instability, deformity, etc. with less disruption of muscles, which enables patient towards faster recovery to normal functions, reduces operative blood loss. In this paper, it is proposed to extract point cloud data from stalk of non-invasive \{CT\} scan images by using Image Processing techniques and Reverse Engineering approach. This point cloud data is to be processed for noise reduction, point cloud data segmentation and \{CAD\} model generation. This image-based \{CAD\} modeling approach begins with the acquisition of \{CT\} scan in \{DICOM\} 3.0 format. The point cloud estimation is based on threshold techniques and edge detection method. This point cloud data is used for construction of 3D \{CAD\} model by fitting free form \{NURB\} surface between theses points and then fitting surface between these curve networks by swept blend technique. An efficient and robust algorithm has been developed for generation of curves from unorganized point cloud data. "
}
@article{Popescu201475,
title = "Direct Toolpath Generation Based on Graph Theory for Milling Roughing ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "75 - 80",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.013",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010440",
author = "Daniela Popescu and Florin Popister and Sorin Popescu and Calin Neamtu and Mircia Gurzau",
keywords = "direct toolpath",
keywords = "graph theory",
keywords = "cloud points",
keywords = "roughing ",
abstract = "Abstract The paper presents a tool path generation methodology for roughing operation based on the oriented graph theory. The cutting areas are identified using an original method that is based on a bicolor and binary map. The toolpath is generated using the searching Dijkstra algorithm inside a graph in order to find the single-source shortest path. The method was employed in order to be applied on ordered and/or unordered point clouds. The entire algorithm was implemented into a mathematic calculus solution which allows the import of point clouds and its processing until the final \{NC\} code is generated. "
}
@article{Law2014287,
title = "Direct normal irradiance forecasting and its application to concentrated solar thermal output forecasting – A review ",
journal = "Solar Energy ",
volume = "108",
number = "",
pages = "287 - 307",
year = "2014",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2014.07.008",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X14003466",
author = "Edward W. Law and Abhnil A. Prasad and Merlinde Kay and Robert A. Taylor",
keywords = "\{DNI\} forecasting",
keywords = "Numerical weather prediction",
keywords = "Time series analysis",
keywords = "Cloud motion vector",
keywords = "Forecast accuracy",
keywords = "Concentrated solar thermal power ",
abstract = "Abstract Solar irradiance forecasting can reduce the uncertainty of solar power plant output caused by solar irradiance intermittency. Concentrated solar thermal (CST) plants generate electricity from the direct normal irradiance (DNI) component of solar irradiance. Different forecasting methods have been recommended for a range of forecast horizons relevant to electricity generation. High \{DNI\} forecast accuracy is important for achieving accurate forecasts of \{CST\} plant output which are shown to increase \{CST\} plant profitability. This paper reviews the \{DNI\} forecast accuracy of numerical weather prediction models, time series analysis methods, cloud motion vectors, and hybrid methods. The results of the reviewed papers are summarised to identify the best \{DNI\} forecast accuracy for particular forecast horizons. The application of \{DNI\} forecasts to operate \{CST\} plants is also briefly reviewed. This paper found that additional research is required for time series analysis methods to corroborate current results and for satellite-based cloud motion vectors to establish \{DNI\} forecast accuracy. It was also concluded that future research should use the same error metrics to report results to facilitate fair comparison of \{DNI\} forecast accuracy from different studies. In addition, the creation of a common high quality \{DNI\} data set to evaluate all forecasting methods would also help to verify best forecast accuracy. The review of \{DNI\} forecasting for \{CST\} plants found that using accurate 2-day ahead \{DNI\} forecasts can increase revenue and decrease penalty costs. Future research should investigate benefits from using short-term \{DNI\} forecasts from the intra-hour forecast horizon up to the 6-h forecast horizon to determine \{CST\} plant operation. Another aspect to research is to determine whether the benefit of \{DNI\} forecasts for a \{CST\} plant is affected by different regulations in different electricity markets. "
}
@article{BarOr2012280,
title = "Radiative properties of humidified aerosols in cloudy environment ",
journal = "Atmospheric Research ",
volume = "118",
number = "",
pages = "280 - 294",
year = "2012",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512002402",
author = "R.Z. Bar-Or and I. Koren and O. Altaratz and E. Fredj",
keywords = "Remote sensing",
keywords = "Aerosols",
keywords = "Clouds",
keywords = "Cloud field",
keywords = "Radiative transfer ",
abstract = "The remotely sensed aerosol retrievals in the transition zone between clouds and clear sky (“the twilight zone”) are affected by aerosol humidification, undetectable clouds, and complex cloud radiative 3D effects. Recent studies that have estimated this total effect, found a strong exponential dependence of the aerosol retrievals on the distance from the nearest cloud, up to 30 km. In this study, we estimate the net effect of aerosol humidification on the aerosol optical depth (AOD) and aerosol fine-mode fraction (FMF). For this purpose, a new parameterization of the relative humidity (RH) as a function of the distance from the nearest cloud is presented, and calculated for shallow warm Cumulus cloud fields, based on large eddy simulation results. The results show an exponential increase in the relative humidity near clouds, from its background values (far from clouds), with an e-fold exponential distance scale of 90–300 m from the cloud edge. This finding suggests that at least for warm Cumulus cloud fields, the variations of the mean \{RH\} values are negligible at distances larger than ~ 0.5 km from clouds, when taking into account humidification effects and therefore, the total effect of the twilight zone on aerosol retrievals is not dominated by aerosol humidification at distances of 0.5–30 km from clouds. Closer examination of the aerosol humidification effect on aerosol retrievals near clouds is then presented, using a radiative transfer model (SHDOM). We estimate the sensitivity of humidified aerosol retrievals to the physical aerosol properties. We show that the humidified aerosol optical depth (AOD) is constantly increasing near clouds, for all aerosol types and size distributions, due to aerosol hygroscopic growth. On the contrary, the humidified aerosol fine-mode fraction (FMF) is found to be sensitive to the aerosol physical properties, showing variant shapes near clouds. "
}
@article{Xue201445,
title = "China Collection 2.0: The aerosol optical depth dataset from the synergetic retrieval of aerosol properties algorithm ",
journal = "Atmospheric Environment ",
volume = "95",
number = "",
pages = "45 - 58",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.06.019",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014004658",
author = "Yong Xue and Xingwei He and Hui Xu and Jie Guang and Jianping Guo and Linlu Mei",
keywords = "Aerosol optical depth",
keywords = "Gas absorption",
keywords = "SRAP",
keywords = "Cloud mask",
keywords = "MODIS",
keywords = "China Collection 2.0 ",
abstract = "Abstract A wide range of data products have been published since the operation of the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor on NASA's \{TERRA\} and \{AQUA\} satellites. Based on DarkTarget and DeepBlue method, \{NASA\} has published Aerosol Optical Depth (AOD) products Collection 5.0 and Collection 5.1 at 10 km spatial resolution. The Collection 6.0 will be published soon with spatial resolution of 3 km. Although validated globally, regional and systematic errors are still found in the MODIS-retrieved \{AOD\} products. This is especially remarkable for bright heterogeneous land surface, such as mainland China. In order to solve the aerosol retrieval problem over heterogeneous bright land surface, the Synergetic Retrieval of Aerosol Properties algorithm (SRAP) has been developed based on the synergetic use of the \{MODIS\} data of \{TERRA\} and \{AQUA\} satellites. Using the \{SRAP\} algorithm, we produced \{AOD\} dataset-China Collection 2.0, dated from August 2002 to August 2012, and compared the \{AOD\} results with \{AErosol\} Robotic \{NETwork\} (AERONET) and Chinese Meteorological Administration Aerosol Remote Sensing Network (CARSNET) measurements. We find that 62% of China Collection 2.0 \{AOD\} values are within an expected error (EE) range of ±(0.05 + 20%) and that 56% are within an \{EE\} range of ±(0.05 + 15%) when compared with AERONET-observed values. For \{CARSNET\} validation, we find that 60% of China Collection 2.0 \{AOD\} values are within an expected error (EE) range of ±(0.05 + 20%) and that 53% are within an \{EE\} range of ±(0.05 + 15%). In addition, we also compare the \{AOD\} results with \{MODIS\} aerosol products, the cross validation shows that the two \{AOD\} have good consistency. Monthly averaged \{AOD\} results show that \{AOD\} is generally high in China's eastern coastal region from March to August, and \{AOD\} is not more than 0.5 in other months. Season averaged results show that the higher values of \{AOD\} are mostly distributed in eastern and southern China. "
}
@article{Chen2013159,
title = "Internet of intelligent things and robot as a service ",
journal = "Simulation Modelling Practice and Theory ",
volume = "34",
number = "",
pages = "159 - 171",
year = "2013",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2012.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X12000469",
author = "Yinong Chen and Hualiang Hu",
keywords = "Internet of Things",
keywords = "Robot as a Service",
keywords = "Decentralized autonomous system",
keywords = "Distributed intelligence",
keywords = "Context-aware computing",
keywords = "Cloud computing ",
abstract = "The development of computing and communication systems has gone through a spiral cycle of centralization and decentralization paradigms. The earliest computer systems are centralized mainframe computers. The paradigm moved to decentralized as networked stations became more dependable, extensible and cost-effective. The decentralized systems have their limitations and inconveniences. The virtualization and cloud computing paradigm creates a centralized system that appears to users to be a centralized system, where computing and communication resources are not in the client computers but in an integrated infrastructure that is accessible anywhere and anytime. Nevertheless, the implementation of the centralized infrastructure is equipped with decentralized and redundant resources, which makes the system more dependable as any component failures can be tolerated internally. The Internet of Things extends the cloud computing concept beyond computing and communication to include everything, particularly, the physical devices. This paper discusses the architectures, interfaces, and behaviors of intelligent devices connected to the cloud computing environment. Robot as a Service is the case study, which has all the key features of Internet of Intelligent Things: autonomous, mobile, sensing, and action taking. The goal is to further extend the centralized cloud computing environment into a decentralized system to complete another cycle of the spiral development. The idea of achieving the goal is through autonomous and intelligent mobile physical services or robots as services to form local pool of intelligent devices and that can make local decisions without communicate with the cloud. "
}
@article{Oh2013311,
title = "Estimation of aerosol direct radiative effects for all-sky conditions from \{CERES\} and \{MODIS\} observations ",
journal = "Journal of Atmospheric and Solar-Terrestrial Physics ",
volume = "102",
number = "",
pages = "311 - 320",
year = "2013",
note = "",
issn = "1364-6826",
doi = "https://doi.org/10.1016/j.jastp.2013.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S1364682613001855",
author = "Hye-Ryun Oh and Yong-Sang Choi and Chang-Hoi Ho and Myeong-Jae Jeong",
keywords = "All-sky aerosol direct radiative effect",
keywords = "Satellite observation",
keywords = "Cloud ",
abstract = "Abstract Satellite observations have shown the global average of the aerosol direct radiative effect (DRE) at the top of the atmosphere to be approximately −5.0 W m−2. Although there is a general consensus on this quantity, it is essentially biased toward clear-sky conditions. To circumvent this limitation, the present study introduces a new method for retrieving the global \{DRE\} of aerosol over the region of 60°S–60°N for all-sky conditions (both clear and cloudy skies). The all-sky \{DRE\} was calculated on a monthly basis by combining the measured \{DRE\} for a clear sky and the simulated \{DRE\} for a cloudy sky in 1°×1° grids. For the measured clear-sky DRE, we employed aerosol, cloud, and radiation fluxes from the Cloud and Earth's Radiant Energy System (CERES) instrument and the Moderate Resolution Imaging Spectroradiometer (MODIS) onboard the Terra satellite for May 2000–December 2005. For the simulated cloudy-sky DRE, we performed radiative transfer modeling with the \{MODIS\} cloud properties in addition to the aerosol optical properties independently estimated in this study that include asymmetry factor and single scattering albedo. The results show that the global mean±standard deviation of \{DRE\} for the all-sky scene is −3.1±1.0 W m−2, which is weaker than that for the clear-sky only. This is in good agreement with the global estimates from previous studies based on different methods. The main advantage of our method is near-real-time estimation of monthly global all-sky \{DRE\} that has physical consistency with the \{CERES\} data. "
}
@article{Ridao201412146,
title = "Intervention AUVs: The Next Challenge ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "12146 - 12159",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02819",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016435494",
author = "Pere Ridao and Marc Carreras and David Ribas and Pedro J. Sanz and Gabriel Oliver",
keywords = "Autonomous Vehicles",
keywords = "Robotic Manipulators",
keywords = "Marine Systems ",
abstract = "Abstract While commercially available \{AUVs\} are routinely used in survey missions, a new set of applications exists which clearly demand intervention capabilities. The maintenance of: permanent observatories underwater; submerged oil wells; cabled sensor networks; pipes; and the deployment and recovery of benthic stations are but a few of them. These tasks are addressed nowadays using manned submersibles or work-class ROVs, equipped with teleoperated arms under human supervision. Although researchers have recently opened the door to future I-AUVs, a long path is still necessary to pave the way to underwater intervention applications performed in an autonomous way. This paper reviews the evolution timeline in autonomous underwater intervention systems. Milestone projects in the state of the art are reviewed, highlighting their principal contributions to the field. To the best of the authors knowledge only three vehicles have demonstrated some autonomous intervention capabilities so far: ALIVE, \{SAUVIM\} and \{GIRONA\} 500 I-AUV. Next, \{GIRONA\} 500 I-AUV is presented and its software architecture discussed. Recent results in different scenarios are reported: 1) Valve turning and connector plugging/unplugging while docked to a sub-sea panel, 2) Free floating valve turning using learning by demonstration, and 3) Free floating multipurpose multisensory based object recovery. The paper ends discussing the lessons learned so far and presenting the authors view of the future. "
}
@incollection{Holler2014245,
title = "Chapter 11 - Industrial Automation ",
editor = "Holler, Jan and , and Tsiatsis, Vlasios and , and Mulligan, Catherine and , and Karnouskos, Stamatis and , and Avesand, Stefan and ,  and Boyle, David ",
booktitle = "From Machine-To-Machine to the Internet of Things ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2014",
pages = "245 - 253",
isbn = "978-0-12-407684-6",
doi = "https://doi.org/10.1016/B978-0-12-407684-6.00011-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780124076846000115",
author = "Jan Holler and Vlasios Tsiatsis and Catherine Mulligan and Stamatis Karnouskos and Stefan Avesand and David Boyle",
keywords = "Architecture",
keywords = "Cloud",
keywords = "Collaborative Automation Industrial Automation",
keywords = "Control",
keywords = "Cyber-Physical Systems",
keywords = "Factory of the Future",
keywords = "Monitoring",
keywords = "SOA",
keywords = "Web Services ",
abstract = "The industrial systems of the future are complex systems composed of vast numbers of devices interacting with each other and with enterprise systems. Modern technologies such as web services, service-oriented architectures (SOAs), the cloud, etc. make it possible for sophisticated infrastructures to emerge in future factories. We take a closer look at key visionary aspects that are expected to be introduced in the industrial automation domain in the years to come, and the pivotal role of \{M2M\} and IoT. Additionally, we investigate the impact on the collaboration of machines among themselves and with enterprise systems and their services. "
}
@article{HongSeok2014931,
title = "Development of an Inspection System for Defect Detection in Pressed Parts Using Laser Scanned Data ",
journal = "Procedia Engineering ",
volume = "69",
number = "",
pages = "931 - 936",
year = "2014",
note = "24th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.03.072",
url = "http://www.sciencedirect.com/science/article/pii/S187770581400318X",
author = "Park Hong-Seok and Tuladhar Upendra Mani",
keywords = "Inspection system",
keywords = "Pressed parts",
keywords = "Segmentation",
keywords = "Point cloud registration",
keywords = "Iterative closest point",
keywords = "Laser scanner ",
abstract = "Abstract In past few decades several researches have been conducted in the field of 3D parts inspection system. The accuracy level of manufactured parts has been improved remarkably within this period. The use of laser sensors in 3D part measurement process has introduced a significant improvement in data acquisition process regarding time and cost. However for quality control process, due to lack of appropriate technique to process and inspect the scanned point cloud data, high accuracy level could not have been achieved so far. Therefore the industries are still compelled to use same traditional coordinate measuring machines (CMMs) despite of being very slow. In this paper, a robust inspecting technique to detect defects in 3D pressed parts has been proposed. Point cloud data are segmented for the extraction of features. These segmented features are used for shape matching during feature based registration process to localize them with the respective \{CAD\} model and bring into same coordinate frame. A modified Iterative closest point (ICP) algorithm is proposed for the registration process. After the registration has been completed these scanned model and \{CAD\} model are compared to find defects in the manufactured parts. "
}
@article{Srivathsan2015602,
title = "Health Monitoring System by Prognotive Computing Using Big Data Analytics ",
journal = "Procedia Computer Science ",
volume = "50",
number = "",
pages = "602 - 609",
year = "2015",
note = "Big Data, Cloud and Computing Challenges ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.04.092",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915005931",
author = "M. Srivathsan and K. Yogesh Arjun",
keywords = "Analytics",
keywords = "Big data",
keywords = "Cloud Computing",
keywords = "Cognitive Computing",
keywords = "Fuzzy Logic",
keywords = "MapReduce",
keywords = "Natural Language Processing",
keywords = "Prognition",
keywords = "Prognotive computing",
keywords = "Pseudo-Intelligence",
keywords = "Virtualization ",
abstract = "Abstract Big data is a modern age concept that is used to process large amount of data in various fields ranging from medical, remote sensing, customer service etc., The Medical Sphere is a tangential aspect to every individual's life.Technological advancement in this field has reached a saturation.A break-throughcan be achieved by Prognotive computing. Prognotive Computing is related to big data analytics as the process may require the collection, processing and analysis of extremely large volume of structured and unstructured biomedical data stemming from a wide range of experiments and surveys collected by hospitals, laboratories, pharmaceutical companies or even social media which is implemented by using existing tools for Big Data. The result of prognosis will improve the efficiency in providing better living to people. "
}
@incollection{Feuerbacher2014981,
title = "Chapter 46 - Strategies of Modern Solar System Exploration ",
editor = "Spohn, Tilman and Breuer, Doris  and Johnson, Torrence V. ",
booktitle = "Encyclopedia of the Solar System (Third Edition) ",
publisher = "Elsevier",
edition = "Third Edition",
address = "Boston",
year = "2014",
pages = "981 - 997",
isbn = "978-0-12-415845-0",
doi = "https://doi.org/10.1016/B978-0-12-415845-0.00046-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780124158450000463",
author = "Berndt Feuerbacher and Bernhard Hufenbach",
keywords = "Global exploration road map",
keywords = "Human spaceflight",
keywords = "Human-robotic partnership",
keywords = "In situ resource utilization (ISRU)",
keywords = "International space exploration coordination group (ISECG)",
keywords = "Radiation hazard",
keywords = "Space exploration",
keywords = "Strategic mission scenario ",
abstract = "Abstract The exploration of the solar system is a continuous challenge for humanity. Its benefits include innovation, culture and inspiration, and peaceful global cooperation. Ambitious future goals such as the human exploration of Mars are very demanding and require international cooperation on a global scale. Long-term strategies to implement solar system exploration missions rely on a suitable cooperation framework between participating nations and on an agreement on common goals and objectives. This is followed by an exploration road map defining the mission scenario, suitable design reference missions, and finally detailed long-term work plans for the partners. An increasing number of nations is getting interested in space and may be part of a future global exploration effort. In addition, commercial companies develop business in deep space. Judged from the present world spending in civil space programs, and compared to the cost implications of the Apollo program, a human flight to Mars can be considered affordable. A first cooperation initiative by 14 national space agencies has been established to jointly develop a global exploration road map with the objective of an affordable and sustainable human mission to Mars. "
}
@article{Zhang2013126,
title = "Multiple Vehicle-like Target Tracking Based on the Velodyne LiDAR* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "126 - 131",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00058",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349211",
author = "Liang Zhang and Qingquan Li and Ming Li and Qingzhou Mao and Andreas Nuchter",
keywords = "Multi-Target Tracking",
keywords = "Velodyne Lidar",
keywords = "Multiple Hypothesis Tracking",
keywords = "Dynamic Point Cloud Registration ",
abstract = "Abstract This paper proposes a novel multiple vehicle-like target tracking method based on a Velodyne \{HDL64E\} light detection and ranging (LiDAR) system. The proposed method combines multiple hypothesis tracking (MHT) algorithm with dynamic point cloud registration (DPCR), which is able to solve the multiple vehicle-like target tracking in highly dynamic urban environments without any auxiliary information from \{GPS\} or IMU. Specifically, to track targets consistently, the \{DPCR\} is developed to calculate accurately the pose of the ego-vehicle for the transformation of raw measurements taken in the moving coordinate systems into a static absolute coordinate system; while in turn, \{MHT\} helps to improve the performance of \{DPCR\} by discriminating and removing the dynamic points from the scene. Furthermore, the proposed \{MHT\} method is also able to solve the occlusion problem existing in the point cloud. Experiments on sets of urban environments prove that the presented method is effective and robust, even in highly dynamic environments. "
}
@article{Guo2015196,
title = "A novel local surface feature for 3D object recognition under clutter and occlusion ",
journal = "Information Sciences ",
volume = "293",
number = "",
pages = "196 - 213",
year = "2015",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514009219",
author = "Yulan Guo and Ferdous Sohel and Mohammed Bennamoun and Jianwei Wan and Min Lu",
keywords = "Local surface feature",
keywords = "3D object recognition",
keywords = "Point-cloud",
keywords = "Feature description",
keywords = "Clutter",
keywords = "Occlusion ",
abstract = "Abstract This paper presents a highly distinctive local surface feature called the TriSI feature for recognizing 3D objects in the presence of clutter and occlusion. For a feature point, we first construct a unique and repeatable Local Reference Frame (LRF) using the implicit geometrical information of neighboring triangular faces. We then generate three signatures from the three orthogonal coordinate axes of the LRF. These signatures are concatenated and then compressed into a TriSI feature. Finally, we propose an effective 3D object recognition algorithm based on hierarchical feature matching. We tested our TriSI feature on two popular datasets. Rigorous experimental results show that the TriSI feature was highly descriptive and outperformed existing algorithms under all levels of Gaussian noise, Laplacian noise, shot noise, varying mesh resolutions, occlusion, and clutter. Moreover, we tested our TriSI-based 3D object recognition algorithm on four standard datasets. The experimental results show that our algorithm achieved the best overall recognition results on these datasets. "
}
@article{Niemeyer2014152,
title = "Contextual classification of lidar data and building object detection in urban areas ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "87",
number = "",
pages = "152 - 165",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2013.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0924271613002359",
author = "Joachim Niemeyer and Franz Rottensteiner and Uwe Soergel",
keywords = "LIDAR",
keywords = "Point cloud",
keywords = "Classification",
keywords = "Urban",
keywords = "Contextual",
keywords = "Building",
keywords = "Detection ",
abstract = "Abstract In this work we address the task of the contextual classification of an airborne LiDAR point cloud. For that purpose, we integrate a Random Forest classifier into a Conditional Random Field (CRF) framework. It is a flexible approach for obtaining a reliable classification result even in complex urban scenes. In this way, we benefit from the consideration of context on the one hand and from the opportunity to use a large amount of features on the other hand. Considering the interactions in our experiments increases the overall accuracy by 2%, though a larger improvement becomes apparent in the completeness and correctness of some of the seven classes discerned in our experiments. We compare the Random Forest approach to linear models for the computation of unary and pairwise potentials of the CRF, and investigate the relevance of different features for the LiDAR points as well as for the interaction of neighbouring points. In a second step, building objects are detected based on the classified point cloud. For that purpose, the \{CRF\} probabilities for the classes are plugged into a Markov Random Field as unary potentials, in which the pairwise potentials are based on a Potts model. The 2D binary building object masks are extracted and evaluated by the benchmark \{ISPRS\} Test Project on Urban Classification and 3D Building Reconstruction. The evaluation shows that the main buildings (larger than 50 m2) can be detected very reliably with a correctness larger than 96% and a completeness of 100%. "
}
@article{Touvet2012473,
title = "A biomimetic reach and grasp approach for mechanical hands ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "473 - 486",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001497",
author = "F. Touvet and N. Daoud and J.-P. Gazeau and S. Zeghloul and M.A. Maier and S. Eskiizmirliler",
keywords = "Reach",
keywords = "Grasp",
keywords = "Movement kinematics",
keywords = "LWPR",
keywords = "Robotic hand",
keywords = "Matching Units ",
abstract = "Reach and grasp are the two key functions of human prehension. The Central Nervous System controls these two functions in a separate but interdependent way. The choice between different solutions to reach and grasp an object–provided by multiple and redundant degrees of freedom (dof)–depends both on the properties and on the use (affordance) of the object to be manipulated. This same control paradigm, i.e. subdivision of prehension into reach and grasp as well as the corresponding multimodal (sensory/motor) information fusion schemes, can also be applied to a mechanical hand carried by a robotic arm. The robotic arm will then be responsible for positioning the hand with respect to the object, and the hand will then grasp and manipulate the object. In this article, we present a biomimetic sensory–motor control scheme in the aim of providing an object-dependent and intelligent reach and grasp ability to such systems. The proposed model is based on a multi-network architecture which incorporates multiple Matching Units trained by a statistical learning algorithm (LWPR). Matching Units perform a multimodal signal integration by correlating sensory and motor information analogous to that observed in cerebral neuronal networks. The simulated network of multiple Matching Units provided estimations of object-dependent 5-finger grasp configurations with endpoint positional errors in the order of a few millimeters. For validation, these estimations were then applied to the control of movement kinematics on an experimental robot composed of a 6 dof robot arm carrying a 16 dof mechanical 4-finger hand. Precision of the kinematics control was such that successful reach, grasp and lift was obtained in all the tests. "
}
@article{Kahnert201441,
title = "Review: Model particles in atmospheric optics ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "146",
number = "",
pages = "41 - 58",
year = "2014",
note = "Electromagnetic and Light Scattering by Nonspherical Particles \{XIV\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314000715",
author = "Michael Kahnert and Timo Nousiainen and Hannakaisa Lindqvist",
keywords = "Scattering",
keywords = "Aerosols",
keywords = "Ice clouds",
keywords = "Mineral dust",
keywords = "Black carbon",
keywords = "Cosmic dust",
keywords = "Regolith ",
abstract = "Abstract This review paper provides an overview over model geometries for computing light scattering by small particles. The emphasis is on atmospheric optics, although much of this review will also be relevant to neighbouring fields, in particular to astronomy. Various morphological particle properties are discussed, such as overall nonsphericity, pristine shapes, aggregation, and different forms of inhomogeneity, e.g. porous and compact inhomogeneous morphologies, as well as encapsulated aggregates. Models employed to reproduce the optical properties of complex particles range from strongly simplified to highly realistic and morphologically sophisticated model geometries. Besides reviewing the most recent literature, we discuss the idea behind models of varying degree of complexity with regard to the intended use of the models. Applications range from fundamental studies of light scattering processes to routine applications of particle optics look-up tables in operational modelling systems. "
}
@article{Cortes2012673,
title = "Cooperative detection of areas of rapid change in spatial fields ",
journal = "Automatica ",
volume = "48",
number = "4",
pages = "673 - 681",
year = "2012",
note = "",
issn = "0005-1098",
doi = "https://doi.org/10.1016/j.automatica.2012.01.014",
url = "http://www.sciencedirect.com/science/article/pii/S0005109812000295",
author = "Jorge Cortes",
keywords = "Robotic sensor networks",
keywords = "Hybrid systems",
keywords = "Distributed detection",
keywords = "Spatial fields",
keywords = "Wombling ",
abstract = "This paper proposes a distributed coordination algorithm for robotic sensor networks to detect boundaries that separate areas of rapid change of planar spatial phenomena. We consider an aggregate objective function, termed wombliness, to measure the change of the spatial field along the closed polygonal curve defined by the location of the sensors. We encode the network task as the optimization of the wombliness and characterize the smoothness properties of the objective function. In general, the complexity of the spatial phenomena may make the gradient flow cause self-intersections in the polygonal curve described by the network. We design the hybrid wombling algorithm that allows for network splitting and merging and guarantees local convergence to the critical configurations of the wombliness, while monotonically optimizing it. The technical approach combines ideas from statistical estimation, dynamical systems, and hybrid modeling and design. "
}
@article{FU20141680,
title = "Line Matching Across Views Based on Multiple View Stereo ",
journal = "Acta Automatica Sinica ",
volume = "40",
number = "8",
pages = "1680 - 1689",
year = "2014",
note = "",
issn = "1874-1029",
doi = "https://doi.org/10.1016/S1874-1029(14)60017-3",
url = "http://www.sciencedirect.com/science/article/pii/S1874102914600173",
author = "Kang-Ping FU and Shu-Han SHEN and Zhan-Yi HU",
keywords = "Multi-view line matching",
keywords = "multiple view stereo (MVS)",
keywords = "feature matching",
keywords = "3D point clouds ",
abstract = "Abstract A graph-based multiple view line matching method is proposed based on results of multiple view stereo (MVS) algorithms. With the 3D points and their visibility information provided by MVS, point-line correspondences are firstly established through 3D-to-2D re-projection. Each image line detected in different views is described using a 3D point set as well as a unit vector representing its coarse 3D direction. From such a description, pairwise similarity and consistency are evaluated. Then, a graph is constructed to contain all image lines as nodes. To get a unified node distance measure, a spectral graph analysis method is employed. Finally, a modified \{DBSCAN\} algorithm is introduced to obtain reliable line matches from the graph. Experiments show that our method is more robust and exhibits better accuracy than the existing methods. "
}
@article{Zhou2013107,
title = "Vision-Based Window Estimation for \{MAV\} in Unknown Urban Environments* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "30",
pages = "107 - 111",
year = "2013",
note = "2nd \{IFAC\} Workshop on Research, Education and Development of Unmanned Aerial Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20131120-3-FR-4045.00026",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015402794",
author = "Shuting Zhou and Gerardo Flores and Rogelio Lozano and Pedro Castillo",
keywords = "Computer vision",
keywords = "Window estimation",
keywords = "Stereo vision",
keywords = "Kinect",
keywords = "Point cloud ",
abstract = "Abstract This paper addresses the issue of window estimation of a micro Air Vehicle (MAV) in unknown urban environments. The \{MAV\} is required to navigate from an initial and outdoor position to a final position inside a building. This paper develops two vision-based methods using the information provided by the onboard vision system. To effectively identify the target and estimate the distance between the camera carrier and target, firstly a stereo camera system is applied. Besides, we propose another approach using point cloud captured by a RGB-D camera. "
}
@article{Forrest2010706,
title = "Performance evaluation of underwater platforms in the context of space exploration ",
journal = "Planetary and Space Science ",
volume = "58",
number = "4",
pages = "706 - 716",
year = "2010",
note = "Exploring other worlds by exploring our own: The role of terrestrial analogue studies in planetary exploration ",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2009.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0032063309002475",
author = "A.L. Forrest and B.E. Laval and D.S.S. Lim and D.R. Williams and A.C. Trembanis and M.M. Marinova and R. Shepard and A.L. Brady and G.F. Slater and M.L. Gernhardt and C.P. McKay",
keywords = "Autonomous underwater vehicle",
keywords = "Human–robotic interface",
keywords = "Performance metrics",
keywords = "Exploration metrics",
keywords = "Remotely operated vehicle",
keywords = "DeepWorker ",
abstract = "Robotic platforms are essential for future human planetary and lunar exploration as they can operate in more extreme environments with a greater endurance than human explorers. In this era of space exploration, a terrestrial analog that can be used for development of the coordination between manned and robotic vehicles will optimize the scientific return of future missions while concurrently minimizing the downtime of both human explorers and robotic platforms. This work presents the use of underwater exploratory robots – autonomous underwater vehicles (AUV), remotely operated vehicles (ROV), and manned submersibles – as analogues for mixed human–robot exploration of space. Subaqueous settings present diverse challenges for navigation, operation and recovery that require the development of an exploration model of a similar complexity as required for space exploration. To capitalize on the strengths of both robotic and human explorers this work presents lessons learnt with respect to the fields of human–robotic interface (HRI) and operator training. These are then used in the development of mission evaluation tools: (1) a task efficiency index (TEI), (2) performance metrics, and (3) exploration metrics. Although these independent evaluations were useful for specific missions, further refinement will be required to fully evaluate the strengths and capabilities of multiple platforms in a human–robotic exploration campaign in order to take advantage of unforeseen science opportunities in remote settings. "
}
@article{Ishikawa2013259,
title = "An automated mineral classifier using Raman spectra ",
journal = "Computers & Geosciences ",
volume = "54",
number = "",
pages = "259 - 268",
year = "2013",
note = "",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2013.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S0098300413000253",
author = "Sascha T. Ishikawa and Virginia C. Gulick",
keywords = "Mineral classification",
keywords = "Raman spectroscopy",
keywords = "Machine learning",
keywords = "Mars",
keywords = "Robotic exploration",
keywords = "Igneous rocks ",
abstract = "We present a robust and autonomous mineral classifier for analyzing igneous rocks. Our study shows that machine learning methods, specifically artificial neural networks, can be trained using spectral data acquired by in situ Raman spectroscopy in order to accurately distinguish among key minerals for characterizing the composition of igneous rocks. These minerals include olivine, quartz, plagioclase, potassium feldspar, mica, and several pyroxenes. On average, our classifier performed with 83 percent accuracy. Quartz and olivine, as well as the pyroxenes, were classified with 100 percent accuracy. In addition to using traditional features such as the location of spectral bands and their shapes, our automated mineral classifier was able to incorporate fluorescence patterns, which are not as easily perceived by humans, into its classification scheme. The latter was able to improve the classification accuracy and is an example of the robustness of our classifier. "
}
@article{Zhang2013170,
title = "Unsupervised skeleton extraction and motion capture from 3D deformable matching ",
journal = "Neurocomputing ",
volume = "100",
number = "",
pages = "170 - 182",
year = "2013",
note = "Special issue: Behaviours in video ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2011.11.032",
url = "http://www.sciencedirect.com/science/article/pii/S0925231212003499",
author = "Quanshi Zhang and Xuan Song and Xiaowei Shao and Ryosuke Shibasaki and Huijing Zhao",
keywords = "Skeleton extraction",
keywords = "3D point cloud sequence ",
abstract = "This paper presents a novel method to extract skeletons of complex articulated objects from 3D point cloud sequences collected by the Kinect. Our approach is more robust than the traditional video-based and stereo-based approaches, as the Kinect directly provides 3D information without any markers, 2D-to-3D-transition assumptions, and feature point extraction. We track all the raw 3D points on the object, and utilize the point trajectories to determine the object skeleton. The point tracking is achieved by the 3D non-rigid matching based on the Markov Random Field (MRF) Deformation Model. To reduce the large computational cost of the non-rigid matching, a coarse-to-fine procedure is proposed. To the best of our knowledge, this is the first to extract skeletons of highly deformable objects from 3D point cloud sequences by point tracking. Experiments prove our method's good performance, and the extracted skeletons are successfully applied to the motion capture. "
}
@article{Cheng20111173,
title = "Performance evaluation of ultra wideband technology for construction resource location tracking in harsh environments ",
journal = "Automation in Construction ",
volume = "20",
number = "8",
pages = "1173 - 1184",
year = "2011",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000732",
author = "T. Cheng and M. Venugopal and J. Teizer and P.A. Vela",
keywords = "3D",
keywords = "Accuracy",
keywords = "Error analysis",
keywords = "Laser scanning",
keywords = "Location tracking",
keywords = "Ultra wideband",
keywords = "Robotic Total Station",
keywords = "RFID",
keywords = "Safety",
keywords = "Visualization ",
abstract = "Emerging wireless remote sensing technologies offer significant potential to advance the management of construction processes by providing real-time access to the locations of workers, materials, and equipment. Unfortunately, little is known regarding the accuracy, reliability, and practical benefits of an emerging technology, effectively impeding widespread adoption. This paper evaluates a commercially-available Ultra Wideband (UWB) system for real-time, mobile resource location tracking in harsh construction environments. A focus of this paper is to measure the performance of the \{UWB\} technology for tracking mobile resources in real-world construction settings. To assess tracking accuracy, location error rates for select \{UWB\} track signals are obtained by automatically tracking a single entity using a Robotic Total Station (RTS) for ground truth. Furthermore, to demonstrate the benefits of \{UWB\} technology, the paper provides case studies of resource tracking for analysis of worksite operations. The work demonstrates the applicability of \{UWB\} for the design of construction management support tools. "
}
@article{Osmankovic2012594,
title = "Increasing the precision of reconstructed 3D model of indoor robot environment by elimination of problematic points1 ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "594 - 598",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00121",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336746",
author = "Dinko Osmankovic and Jasmin Velagic",
keywords = "3D modeling",
keywords = "surface reconstruction",
keywords = "point cloud",
keywords = "clustering",
keywords = "visualization ",
abstract = "Abstract In the process of reconstructing the 3D environment from the point cloud acquired from 3D laser the main objective is to obtain the model that is as precise as possible. Reconstruction algorithms greatly rely on the input data precision. Unfortunately, the point clouds regularly contains points that are problematic for the reconstruction. They are mostly associated with the reflection of laser beams off the semi–transparent surfaces, e.g. windows. This paper proposes the method for eliminating such points based on K–means clustering in order to increase the accuracy of the reconstructed 3D model. "
}
@article{Bernal2013591,
title = "Performance Evaluation of Optical Scanner Based on blue \{LED\} Structured Light ",
journal = "Procedia Engineering ",
volume = "63",
number = "",
pages = "591 - 598",
year = "2013",
note = "The Manufacturing Engineering Society International Conference, \{MESIC\} 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2013.08.261",
url = "http://www.sciencedirect.com/science/article/pii/S1877705813014744",
author = "C. Bernal and B. de Agustina and M.M. Marin and A.M. Camacho",
keywords = "Point cloud",
keywords = "reverse engineering",
keywords = "accuracy",
keywords = "traceability",
keywords = "uncertainty ",
abstract = "Abstract Non-contact 3D digitizing scanners based in structured light projection are increasingly more accurate, fastest and affordable. The purpose of this work was to determine the quality, accuracy and traceability of the data provided by new \{LED\} technology scanner of structured light Comet \{L3D\} (Steinbichler) acquired by the Department. Calibration of the equipment and accuracy analysis was carried out with a calibration plate and a number of gauge blocks of different sizes. The accuracy range of the scanner has been established through multiple digitizations showing the dependence on influential factors such as the characteristics of the object and scanning procedure. Although many factors influence, accuracies announced by manufacturer have been achieved under optimal conditions and it has been noted that the quality of the point clouds (density, noise, dispersion of points) provided by Comet \{L3D\} system is higher than that obtained with laser technology devices. "
}
@article{Neves2011399,
title = "An efficient omnidirectional vision system for soccer robots: From calibration to object detection ",
journal = "Mechatronics ",
volume = "21",
number = "2",
pages = "399 - 410",
year = "2011",
note = "Special Issue on Advances in intelligent robot design for the Robocup Middle Size League ",
issn = "0957-4158",
doi = "https://doi.org/10.1016/j.mechatronics.2010.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0957415810000863",
author = "Antonio J.R. Neves and Armando J. Pinho and Daniel A. Martins and Bernardo Cunha",
keywords = "Robotic vision",
keywords = "Omnidirectional vision systems",
keywords = "Color-based object detection",
keywords = "Shape-based object detection",
keywords = "Vision system calibration ",
abstract = "Robotic soccer is nowadays a popular research domain in the area of multi-robot systems. In the context of RoboCup, the Middle Size League is one of the most challenging. This paper presents an efficient omnidirectional vision system for real-time object detection, developed for the robotic soccer team of the University of Aveiro, CAMBADA. The vision system is used to find the ball and white lines, which are used for self-localization, as well as to find the presence of obstacles. Algorithms for detecting these objects and also for calibrating most of the parameters of the vision system are presented in this paper. We also propose an efficient approach for detecting arbitrary \{FIFA\} balls, which is an important topic of research in the Middle Size League. The experimental results that we present show the effectiveness of our algorithms, both in terms of accuracy and processing time, as well as the results that the team has been achieving: 1st place in RoboCup 2008, 3rd place in 2009 and 1st place in the mandatory technical challenge in RoboCup 2009, where the robots have to play with an arbitrary standard \{FIFA\} ball. "
}
@incollection{Wasklewicz2013130,
title = "3.6 Digital Terrain Modeling ",
editor = "Shroder, John F. ",
booktitle = "Treatise on Geomorphology ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2013",
pages = "130 - 161",
isbn = "978-0-08-088522-3",
doi = "https://doi.org/10.1016/B978-0-12-374739-6.00048-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780123747396000488",
author = "T. Wasklewicz and D.M. Staley and K. Reavis and T. Oguchi",
keywords = "Airborne laser scanning",
keywords = "Cloud segmentation",
keywords = "Decimation",
keywords = "Digital elevation model",
keywords = "Digital terrain model",
keywords = "Filtering",
keywords = "Interferometric synthetic-aperture radar",
keywords = "Light detection and ranging",
keywords = "Point clouds",
keywords = "Terrestrial laser scanning",
keywords = "Terrestrial photogrammetry ",
abstract = "Geomorphologists require quantitative information about the land surface. New sensors can now measure elevation changes at a variety of scales and these data are used to generate digital terrain model (DTM) that accurately characterize topography. A variety of \{DTM\} analytics are used to support a multitude of geomorphological studies. However, there are numerous issues involving representation, sampling, interpolation, and error assessment and correction, which must be addressed before using the elevation data. Data reduction, filtering, and accuracy are key aspects to consider. Knowledge of these issues is critical for terrain analysis and the communication of information derived from a DTM. "
}
@incollection{Li2014279,
title = "9 - Evolving academic libraries in the future ",
editor = "Li, LiLi ",
booktitle = "Scholarly Information Discovery in the Networked Academic Learning Environment ",
publisher = "Chandos Publishing",
edition = "",
address = "Oxford",
year = "2014",
pages = "279 - 309",
series = "Chandos Information Professional Series",
isbn = "978-1-84334-763-7",
doi = "https://doi.org/10.1533/9781780634449.4.279",
url = "http://www.sciencedirect.com/science/article/pii/B9781843347637500093",
author = "LiLi Li",
keywords = "Apple iWatch",
keywords = "artificial intelligence",
keywords = "Barnes &amp; Noble",
keywords = "cloud storage",
keywords = "Google Chrome",
keywords = "Google Chromebook",
keywords = "Google Fiber",
keywords = "Google Glass",
keywords = "Google Inside Search",
keywords = "Google Knowledge Graph",
keywords = "IBM Watson",
keywords = "machine translation",
keywords = "wearable computer",
keywords = "XiaoTu ",
abstract = "Abstract: In today’s information society, cutting edge and emerging technologies are greatly impacting information resources and services in academic libraries worldwide. The beginning of the rise of the wearable computer suggests that today’s information society is moving toward the post-PC era. Although the future fate of academic libraries is still debatable, the tragedy predicted by Brian T. Sullivan11. Brian T. Sullivan is an instructional librarian at Alfred University, New York. to happen by 2050 is extremely unlikely. Instead, combined with innovative information technologies, future academic libraries will become more vigorous in our networked academic learning environment. As \{IT\} architecture evolves, so high-speed digital applications and highly intellectual robots will shape new creative and innovative information resources and services in the academic library of the future. "
}
@incollection{Andress2014277,
title = "Chapter 16 - The Future of Cyber War ",
editor = "Andress, Jason  and Winterfeld, Steve ",
booktitle = "Cyber Warfare (Second Edition) ",
publisher = "Syngress",
edition = "Second Edition",
address = "Boston",
year = "2014",
pages = "277 - 289",
isbn = "978-0-12-416672-1",
doi = "https://doi.org/10.1016/B978-0-12-416672-1.00016-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780124166721000167",
author = "Jason Andress and Steve Winterfeld",
keywords = "Black Swan event",
keywords = "Capability surprise",
keywords = "Cloud computing",
keywords = "Cyber Response Framework",
keywords = "Cyber time ",
abstract = "Abstract When it comes to cyber war, it can be impractical to predict the future. However, this does not mean one should resign all hope and take a “come what may” attitude toward cyber warfare and cybersecurity. A deep understanding and awareness of cyber threats and their prevention and mitigation is crucial if the United States is to maintain leadership in this arena. But before this can occur, leaders must agree on whether a “cyber war” is being waged today, identify associated problems, and determine how to solve them. This closing chapter focuses on the future of cyber war. After setting the stage for their examination of the issue, the authors identify some near-term trends and the most likely and most dangerous courses of action. They round out the chapter with a discussion on new technologies and their inherent problems, and then look at cyber war from an international perspective. "
}
@article{Niola2010543,
title = "A new real-time shape acquisition with a laser scanner: first test results ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "26",
number = "6",
pages = "543 - 550",
year = "2010",
note = "19th International Conference on Flexible Automation and Intelligent ManufacturingLean manufacturing and Services ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.06.026",
url = "http://www.sciencedirect.com/science/article/pii/S0736584510000773",
author = "Vincenzo Niola and Cesare Rossi and Sergio Savino",
keywords = "Shape acquisition",
keywords = "Laser scanner",
keywords = "Robotic application ",
abstract = "The first results of a new method for real-time shape acquisition with a laser scanner are presented. The new method is essentially based on the use of a laser beam and a web-cam. A digital filter parameters identification was studied for the laser line detection in the image. After this, a model for the reconstruction in real-time of the laser line in the space was developed. The first test rig was just conceived to validate the method; hence, no high resolution cameras were adopted. Nevertheless, the tests have showed encouraging results. Tests were made on both plane and non-plane surfaces. First of all, it was confirmed that it is possible to calibrate the intrinsic parameters of the video system, the position of the image plane and the laser plane in a given frame, all in the same time. Moreover the surface shapes were recognized and recorded with an appreciable accuracy. The tests also showed that the proposed method can be used for robotic applications, such as robotic kinematic calibration and 3D surfaces recognition and recording. For this last purpose, the test rig is fitted on a robot arm that permits to the scanner device to ‘observe’ the 3D object from different and known positions. "
}
@article{Ma2011338,
title = "New dust aerosol identification method for spaceborne lidar measurements ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "112",
number = "2",
pages = "338 - 345",
year = "2011",
note = "International Symposium on Atmospheric Light Scattering and Remote Sensing (ISALSaRS’09) ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2010.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022407310003109",
author = "Yingying Ma and Wei Gong and Pucai Wang and Xiuqing Hu",
keywords = "CALIPSO",
keywords = "SVM (the support vector machine)",
keywords = "Aerosol",
keywords = "Cloud ",
abstract = "Classification is a critical step in the backscatter lidar data processing to accurately retrieve extinction and backscatter profiles of atmospheric aerosols and clouds. Different schemes, such as the probability distribution functions (PDFs) method, have been used in the cloud and aerosol classification. In this paper, we attempt to use the support vector machine (SVM) to discriminate aerosols from clouds, with a focus on dust aerosol classification in China. To demonstrate the feasibility of the \{SVM\} classifier, we chose dust storms that occurred in the Gobi and Taklimakan deserts and observed by the \{CALIPSO\} lidar in spring time 2007. The results show that the \{SVM\} can correctly identify the dust storms. "
}
@article{Bohg2012779,
title = "Task-based Grasp Adaptation on a Humanoid Robot ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "779 - 786",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00174",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016337041",
author = "Jeannette Bohg and Kai Welke and Beatriz Leon and Martin Do and Dan Song and Walter Wohlkinger and Marianna Madry and Aitor Aldoma and Markus Przybylski and Tamim Asfour and Higinio Marti and Danica Kragic and Antonio Morales and Markus Vincze",
keywords = "Robotic Grasping and Manipulation",
keywords = "Task-based Grasp Synthesis",
keywords = "Visual Servoing",
keywords = "Attention",
keywords = "Segmentation",
keywords = "Object categorization",
keywords = "System Integration ",
abstract = "Abstract In this paper, we present an approach towards autonomous grasping of objects according to their category and a given task. Recent advances in the field of object segmentation and categorization as well as task-based grasp inference have been leveraged by integrating them into one pipeline. This allows us to transfer task-specific grasp experience between objects of the same category. The effectiveness of the approach is demonstrated on the humanoid robot ARMAR-IIIa. "
}
@article{GolparvarFard20111143,
title = "Evaluation of image-based modeling and laser scanning accuracy for emerging automated performance monitoring techniques ",
journal = "Automation in Construction ",
volume = "20",
number = "8",
pages = "1143 - 1155",
year = "2011",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.04.016",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000707",
author = "Mani Golparvar-Fard and Jeffrey Bohn and Jochen Teizer and Silvio Savarese and Feniosky Pena-Mora",
keywords = "Progress monitoring",
keywords = "Image-based modeling",
keywords = "Structure from motion",
keywords = "Laser scanning",
keywords = "Computer aided design",
keywords = "Construction field imagery",
keywords = "Range point clouds",
keywords = "As-built modeling ",
abstract = "Accurate and rapid assessment of the as-built status on any construction site provides the opportunity to understand the current performance of a project easily and quickly. Rapid project assessment further identifies discrepancies between the as-built and as-planned progress, and facilitates decision making on the necessary remedial actions. Currently, manual visual observations and surveying are the most dominant data capturing techniques but they are time-consuming, error-prone, and infrequent, making quick and reliable decision-making difficult. Therefore, research on new approaches that allow automatic recognition of as-built performance and visualization of construction progress is essential. This paper presents and compares two methods for obtaining point cloud models for detection and visualization of as-built status for construction projects: (1) A new method of automated image-based reconstruction and modeling of the as-built project status using unordered daily construction photo collections through analysis of Structure from Motion (SfM); (2) 3D laser scanning and analysis of the as-built dense point cloud models. These approaches provide robust means for recognition of progress, productivity, and quality on a construction site. In this paper, an overview of the newly developed automated image-based reconstruction approach and exclusive features which distinct it from other image-based or conventional photogrammetric techniques is presented. Subsequently the terrestrial laser scanning approach carried out for reconstruction and comparison of as-built scenes is presented. Finally the accuracy and usability of both of these techniques for metric reconstruction, automated production of point cloud models, 3D \{CAD\} shape modeling, and as-built visualizations is evaluated and compared on eight different case studies. It is shown that for precise defect detection or alignment tasks, image-based point cloud models may not be as accurate and dense as laser scanners' point cloud models. Nonetheless image-based point cloud models provide an opportunity to extract as-built semantic information (i.e., progress, productivity, quality and safety) through the content of the images, are easy to use, and do not need add burden on the project management teams by requiring expertise for data collection or analysis. Finally image-based reconstruction automatically provides photo alignment with point cloud models and enables image-based renderings which can remarkably impact automated performance monitoring and as-built visualizations. "
}
@article{Rieffel2014169,
title = "Private aggregation for presence streams ",
journal = "Future Generation Computer Systems ",
volume = "31",
number = "",
pages = "169 - 181",
year = "2014",
note = "Special Section: Advances in Computer Supported Collaboration: Systems and Technologies ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13001088",
author = "Eleanor G. Rieffel and Jacob T. Biehl and Adam J. Lee and William van Melle",
keywords = "Privacy",
keywords = "Presence systems",
keywords = "Awareness",
keywords = "Access control",
keywords = "Cloud computing",
keywords = "Homomorphic encryption ",
abstract = "Abstract Collaboration technologies must support information sharing between collaborators, but must also take care not to share too much information or share information too widely. Systems that share information without requiring an explicit action by a user to initiate the sharing must be particularly cautious in this respect. Presence systems are an emerging class of applications that support collaboration. Through the use of pervasive sensors, these systems estimate user location, activities, and available communication channels. Because such presence data are sensitive, to achieve wide-spread adoption, sharing models must reflect the privacy and sharing preferences of their users. This paper looks at the role that privacy-preserving aggregation can play in addressing certain user sharing and privacy concerns with respect to presence data. We define conditions to achieve CollaPSE (Collaboration Presence Sharing Encryption) security, in which (i) an individual has full access to her own data, (ii) a third party performs computation on the data without learning anything about the data values, and (iii) people with special privileges called “analysts” can learn statistical information about groups of individuals, but nothing about the individual values contributing to the statistic other than what can be deduced from the statistic. More specifically, analysts can decrypt aggregates without being able to decrypt the individual values contributing to the aggregate. Based in part on studies we carried out that illustrate the need for the conditions encapsulated by CollaPSE security, we designed and implemented a family of CollaPSE protocols. We analyze their security, discuss efficiency tradeoffs, describe extensions, and review more recent privacy-preserving aggregation work. "
}
@article{Chao2013301,
title = "Structure Based Derived Uniform Formula for Siphon, Its Complementary Set and T-characteristic Vectors ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "9",
pages = "301 - 306",
year = "2013",
note = "7th \{IFAC\} Conference on Manufacturing Modelling, Management, and Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130619-3-RU-3018.00549",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016343026",
author = "Dinel Yuh Chao and Yen-Liang Pan and Wei-Hsiang Liao",
keywords = "Petri nets",
keywords = "siphons",
keywords = "supervisory control",
keywords = "cloud computing",
keywords = "flexible manufacturing systems ",
abstract = "Abstract Unmarked siphons in a Petri net modeling concurrent systems such as those in cloud computing induce deadlocks. The number of siphons grows exponentially with the size of a net. This problem can be relieved by computing compound (or strongly dependent) siphons based on basic siphons. A basic (resp. compound) siphon can be synthesized from an elementary (resp. compound called alternating) resource circuit. It however cannot be extended to cases where two elementary circuits intersect at a directed path rather than a single place (i.e., corresponding to a weakly dependent siphon). This paper develops a uniform formula not only for both cases but also valid for the complementary set of siphon and characteristic vectors. We further propose to generalize it to a compound siphon consisting of n basic siphons. This helps simplify the computation and the computer implementation to shorten the program size. Also, the formula is easier to be memorized without consulting the references due to the same underlying physics. "
}
@article{Krol2012206,
title = "Elastic Infrastructure for Interactive Data Farming Experiments ",
journal = "Procedia Computer Science ",
volume = "9",
number = "",
pages = "206 - 215",
year = "2012",
note = "Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.04.022",
url = "http://www.sciencedirect.com/science/article/pii/S1877050912001433",
author = "Dariusz Krol and Bartosz Kryza and Michal Wrzeszcz and Lukasz Dutka and Jacek Kitowski",
keywords = "data farming",
keywords = "cloud computing",
keywords = "agent-based simulation",
keywords = "military mission planning ",
abstract = "With the increasing availability of high performance computing power, new possibilities with respect to simulation and analysis become available and feasible. One of such methodologies is data farming, where large amounts of data are generated through simulation of several configurations from large parameter space and then analyzed for patterns. Unfortunately, the availability of versatile data farming systems is very limited and none of existing solutions allows integration with novel Cloud solutions. In this paper, we present our system, which is a flexible solution for running very large Data Farming experiments on both intranet clusters as well as on remote computational resources, including public Clouds. Another important aspect of the presented system is the support of interactive Data Farming experiments with online analysis of partial experiment results and experiment extending capability. Sample application of our system is present on military mission planning support scenario. "
}
@article{deMiguel2011136,
title = "Sensitivity analysis of ratio between ultraviolet and total shortwave solar radiation to cloudiness, ozone, aerosols and precipitable water ",
journal = "Atmospheric Research ",
volume = "102",
number = "1–2",
pages = "136 - 144",
year = "2011",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2011.06.019",
url = "http://www.sciencedirect.com/science/article/pii/S0169809511002109",
author = "Argimiro de Miguel and David Mateos and Julia Bilbao and Roberto Roman",
keywords = "Solar erythemal ultraviolet radiation",
keywords = "Total shortwave radiation",
keywords = "Cloud effect",
keywords = "Radiative transfer",
keywords = "Aerosol effect",
keywords = "Ozone effect ",
abstract = "The present study is focused on the influence of atmospheric factors (ozone, aerosols, precipitable water and, mainly, clouds) on the ratio (measured and modelled) between \{UV\} erythemal (UVER) and total shortwave (SW) solar radiation. The ratio between \{UV\} total (UVT) and \{SW\} is also analysed. Previous studies showed that the shortest wavelengths are less attenuated by the presence of clouds than the longest ones. This effect is confirmed in this study; however, another effect is shown for low solar zenith angles because the UVER/SW ratio values present a decreasing trend with cloud cover, which is enhanced by different average ozone column values in each situation. Simulations performed with the libRadtran 1.4 model show different behaviour of UVER/SW and UVT/SW ratios too. These trends are produced by the effects of solar zenith angle, cloud properties, ozone absorption, aerosol load and Rayleigh scattering. The ozone produces an important fall in the values of this ratio with a factor of − 0.3% DU− 1. An increase of the precipitable water column of the atmosphere leads to a growth of the UVER/SW ratio, while its dependence on the aerosol optical thickness shows the opposite behaviour. Particularly, two cases are studied with changes on the aerosol optical thickness (AOT) and the total ozone column (TOC). Falls about 7% in the values of the UVER/SW ratio are observed under a high \{AOT\} (~ 0.3 at 1020 nm) or under a significant decrease in the \{TOC\} (~15 DU). With respect to UVT/SW ratio, measurements and simulations point out no dependence on solar zenith angle in a cloudy scenario. "
}
@article{Rosenfeld201166,
title = "Pollution and dust aerosols modulating tropical cyclones intensities ",
journal = "Atmospheric Research ",
volume = "102",
number = "1–2",
pages = "66 - 76",
year = "2011",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2011.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0169809511001840",
author = "Daniel Rosenfeld and Michal Clavner and Ronit Nirel",
keywords = "Tropical cyclone",
keywords = "Cloud-aerosols",
keywords = "Hurricane prediction",
keywords = "Cloud seeding",
keywords = "Hurricane mitigation ",
abstract = "Tropical cyclones (TC) are propelled mostly by realization of latent heat that is stored in vapor coming off warm sea surfaces. The heating occurs when the vapor condenses into cloud drops. Re-evaporation of the cloud water takes back the released heat, whereas precipitation of the water as rain fixates the heat in the air. Therefore, it is expected that \{TC\} intensities would be sensitive to precipitation forming processes that affect the amount and distribution of latent heat release. This has been simulated by numerical models, which showed that cloud condensation nuclei (CCN) aerosols weaken the storms apparently by slowing the conversion of cloud drops into precipitation. If so, we should expect that storm predictions that do not take this aerosol effect into account would over-predict \{TC\} intensities. Here we show that increased aerosols quantities in a \{TC\} periphery can explain about 8% of the forecast errors of the TC. Indeed, actual intensities of polluted \{TCs\} were found to be on average lower than their predicted values, providing supporting observational evidence to the hypothesis. It was also found that \{TC\} intensity might be more susceptible to the impacts of aerosols during their developing stages and less in the \{TC\} mature and dissipating stages. "
}
@article{Jeyarani2012811,
title = "Design and implementation of adaptive power-aware virtual machine provisioner (APA-VMP) using swarm intelligence ",
journal = "Future Generation Computer Systems ",
volume = "28",
number = "5",
pages = "811 - 821",
year = "2012",
note = "Special Section: Energy efficiency in large-scale distributed systems ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2011.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X11001130",
author = "R. Jeyarani and N. Nagaveni and R. Vasanth Ram",
keywords = "\{VM\} provisioning",
keywords = "Resource dynamics",
keywords = "Cloud computing",
keywords = "Particle Swarm Optimization (PSO)",
keywords = "Dynamic adaptive PSO",
keywords = "Power saving states",
keywords = "Dynamic Voltage Frequency Scaling (DVFS)",
keywords = "Power conservation ",
abstract = "Cloud computing aims at providing dynamic leasing of server capabilities as scalable, virtualized services to end users. Our work focuses on the Infrastructure as a Service (IaaS) model where custom Virtual Machines (VM) are launched in appropriate servers available in a data center. The cloud data center taken into consideration is heterogeneous and large scale in nature. Such a resource pool is basically characterized by high resource dynamics caused by non-linear variation in the availability of processing elements, memory size, storage capacity, bandwidth and power drawn resulting from the sporadic nature of workload. Apart from the said resource dynamics, our proposed work also considers the processor transitions to various sleep states and their corresponding wake up latencies that are inherent in contemporary enterprise servers. The primary objective of the proposed metascheduler is to map efficiently a set of \{VM\} instances onto a set of servers from a highly dynamic resource pool by fulfilling resource requirements of maximum number of workloads. As the cloud data centers are overprovisioned to meet the unexpected workload surges, huge power consumption has become one of the major issues of concern. We have proposed a novel metascheduler called Adaptive Power-Aware Virtual Machine Provisioner (APA-VMP) that schedules the workload in such a way that the total incremental power drawn by the server pool is minimum without compromising the performance objectives. The APA-VMP makes use of swarm intelligence methodology to detect and track the changing optimal target servers for \{VM\} placement very efficiently. The scenario was experimented by novel Self-adaptive Particle Swarm Optimization (SAPSO) for \{VM\} provisioning, which makes best possible use of the power saving states of idle servers and instantaneous workload on the operational servers. It is evident from the results that there is a significant reduction in the power numbers against the existing strategies. "
}
@article{Cook201222,
title = "Pervasive computing at scale: Transforming the state of the art ",
journal = "Pervasive and Mobile Computing ",
volume = "8",
number = "1",
pages = "22 - 35",
year = "2012",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2011.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S1574119211001416",
author = "Diane J. Cook and Sajal K. Das",
keywords = "Smart environments",
keywords = "Energy harvesting",
keywords = "Cloud computing",
keywords = "Smart phones",
keywords = "Behavior modeling",
keywords = "Internet of things ",
abstract = "The remarkable recent progress in computing power, sensors and embedded devices, smart phones, wireless communications and networking technologies, combined with emerging data mining techniques, cloud computing and social networking paradigms has enabled us to create pervasive computing systems and services with diverse applications and global accessibility. In this paper, we assess the current state of the art of pervasive computing at scale (PeCS) and look ahead to future directions the field can pursue together with challenges it will need to overcome. "
}
@incollection{Vegas2012457,
title = "9.24 - High-Throughput Approaches ",
editor = "Matyjaszewski, Krzysztof  and Moller, Martin ",
booktitle = "Polymer Science: A Comprehensive Reference ",
publisher = "Elsevier",
edition = "",
address = "Amsterdam",
year = "2012",
pages = "457 - 484",
isbn = "978-0-08-087862-1",
doi = "https://doi.org/10.1016/B978-0-444-53349-4.00231-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780444533494002314",
author = "A.J. Vegas and D.G. Anderson",
keywords = "Automation",
keywords = "Collection",
keywords = "Combinatorial",
keywords = "Discovery",
keywords = "Evaluation",
keywords = "Formulation",
keywords = "High-throughput",
keywords = "Library",
keywords = "Methods",
keywords = "Parameter",
keywords = "Platform",
keywords = "Polymer",
keywords = "Robotic",
keywords = "Screening",
keywords = "Synthesis ",
abstract = "Abstract The discovery and development of polymeric materials is fundamental to numerous industrial, commercial, and medicinal applications. A major challenge in polymer research is evaluating the large number of parameters involved in developing new materials for these applications. High-throughput combinatorial methods are rising to the challenges posed by polymer research and are well-suited to query the parameters in polymer synthesis, characterization, and evaluation. Laboratory automation previously feasible for only large companies has now become accessible to academic research groups, greatly enhancing efforts to apply combinatorial methods. Here we provide an overview of the area as it applies to medicinal, commercial, and industrial applications. "
}
@article{Lindskog2013419,
title = "Visualization Support for Virtual Redesign of Manufacturing Systems ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "419 - 424",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002783",
author = "Erik Lindskog and Jonatan Berglund and Johan Vallhagen and Bjorn Johansson",
keywords = "Virtual manufacturing",
keywords = "Production systems",
keywords = "Visualization",
keywords = "3D laser scanning",
keywords = "Point clouds ",
abstract = "Abstract Rapidly changing products and market demand call for manufacturing systems to be continuously adapted and developed. The process of modifying manufacturing systems requires large amounts of planning involving contributions from personnel across an organization. These people need a shared understanding of the future system, including but not limited to its design, functions, and expected performance. One common representation in the virtual manufacturing system domain are 2D \{CAD\} layouts. Typical problems with such traditional 2D models are that only experts understand the content fully. For increased understanding, 3D \{CAD\} models could bridge the gap between different areas of expertise. However, creating 3D models representing the complete system is traditionally time-consuming, resulting in oversimplified models or limited to parts of the system. Furthermore, such models normally contain uncertainty about building-related geometries that could incur costly mistakes if used as basis for decisions, e.g. realizing during installation of a machine that roof-beams interfere with the planned placement. This paper evaluates what type of problems can be solved with better visualization support, e.g. issues concerning workshop-layout, production flow, workplace design, etc. The evaluation is based on two case studies at different manufacturing sites during ongoing system redesign processes. The case studies implemented visualization using a combination of \{CAD\} models and 3D laser scanned as-built data of the current system and facility. The vision is to implement the Lean concept of “Go to Gemba” for a future state in a virtual environment. Bringing this concept into the early phases of manufacturing system redesign has the potential to facilitate the creation of a shared understanding of the future system within cross-functional project teams. "
}
@article{Nuchter2013119,
title = "Irma3D — An Intelligent Robot for Mapping Applications* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "29",
pages = "119 - 124",
year = "2013",
note = "3rd \{IFAC\} Symposium on Telematics Applications ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20131111-3-KR-2043.00011",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015343767",
author = "Andreas Nuchter and Jan Elseberg and Dorit Borrmann",
keywords = "Irma3D",
keywords = "mobile robots",
keywords = "3D mapping",
keywords = "laser scanning",
keywords = "3D point cloud coloring ",
abstract = "Abstract Motivated by the increasing need of rapid characterization of environments in 3D, we designed a robot system that automates the work of an operator of terrestrial laser scanners. The built system enables to work without using special targets or markers and thus enables the surveyors to save more than 75% of the time spent in the field. Another impulse for developing the platform is the demand for a remote multi-sensor inspection tool. The robot is capable of surveying remote sites or danger areas, such as plants, underground mines, tunnels, caves, or channels. The results are precise, multi-modal digital 3D maps. This paper presents the recently developed robot Irma3D, its hardware, the developed interconnected software modules, the associated sensor calibration methods and a few applications. "
}
@article{Davidson2013203,
title = "Least-squares Fit of Measured Points for Square Line-profiles ",
journal = "Procedia \{CIRP\} ",
volume = "10",
number = "",
pages = "203 - 210",
year = "2013",
note = "The Twelfth \{CIRP\} Conference on Computer Aided Tolerancing ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.08.032",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113005817",
author = "J. Davidson and S. Savaliya and Jami J. Shah",
keywords = "Least-squares",
keywords = "regression",
keywords = "pseudoinverse",
keywords = "fit",
keywords = "profile",
keywords = "point-cloud",
keywords = "CMM data reduction ",
abstract = "Abstract The pseudoinverse of a rectangular matrix is used to compute the least-squares fit of a set of points that have been measured along a line-profile. Tolerances on line profiles are used to control cross-sectional shapes of parts, such as turbine blades. The specified profile is treated as a moving platform of a hypothetical, redundant, and planar in-parallel-actuated robot, and all the measured points are presumed to be fixed in it. The locations of the linear actuators are represented with screw (torsor) coordinates, and these are arranged in a matrix equation that relates the three small displacements of the platform to the corresponding deviations (treated as small displacements) of the measured points. The Moore-Penrose (pseudoinverse) solution uniquely produces displacements of the platform which correspond to the least-squares minimum for the deviations at all of the measured points. "
}
@incollection{Perez201321,
title = "Chapter 2 - Semi-Empirical Satellite Models ",
editor = "Kleissl, Jan ",
booktitle = "Solar Energy Forecasting and Resource Assessment ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2013",
pages = "21 - 48",
isbn = "978-0-12-397177-7",
doi = "https://doi.org/10.1016/B978-0-12-397177-7.00002-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780123971777000024",
author = "Richard Perez and Tomas Cebecauer and Marcel suri",
keywords = "satellite solar resource",
keywords = "SolarAnywhere",
keywords = "GOES",
keywords = "Meteosat",
keywords = "GeoModel",
keywords = "topographic shading",
keywords = "cloud index ",
abstract = "Abstract This chapter discusses the basic principles of solar-irradiance modeling based on the use of input data from geostationary satellites and atmospheric models. Two operational approaches (SUNY/SolarAnywhere and SolarGIS), which are based on the use of semi-empirical models, are presented in the context of recent developments. "
}
@article{LaasBourez20091270,
title = "A new algorithm for optical observations of space debris with the \{TAROT\} telescopes ",
journal = "Advances in Space Research ",
volume = "44",
number = "11",
pages = "1270 - 1278",
year = "2009",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2009.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0273117709003895",
author = "Myrtille Laas-Bourez and Gwendoline Blanchet and Michel Boër and Etienne Ducrotte and Alain Klotz",
keywords = "Space debris",
keywords = "Image processing",
keywords = "Robotic telescopes",
keywords = "Mathematical morphology ",
abstract = "Since 2004, we observe satellites in the geostationary orbit with a network of robotic ground based fully automated telescopes called TAROT. One of them is located in France and the second at ESO, La Silla, Chile. The system processes the data in real time. Its wide field of view is useful for the discovery, the systematic survey and for the tracking of both catalogued and un-catalogued objects. We present a new source extraction algorithm based on morphological mathematic, which has been tested and is currently under implementation in the standard pipeline. Using this method, the observation strategy will correlate the measurements of the same object on successive images and give better detection rate and false alarm rate than the previous one. The overall efficiency and quality of the survey of the geostationary orbit has drastically improved and we can now detect satellites and debris in different orbits like Geostationary Transfer Orbit (GTO). Results obtained in real conditions with \{TAROT\} are presented. "
}
@article{Barbero2011188,
title = "Comparative study of different digitization techniques and their accuracy ",
journal = "Computer-Aided Design ",
volume = "43",
number = "2",
pages = "188 - 206",
year = "2011",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2010.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0010448510002150",
author = "Basilio Ramos Barbero and Elena Santos Ureta",
keywords = "Reverse engineering (RE)",
keywords = "Tomography",
keywords = "CT",
keywords = "Surface mesh",
keywords = "3D CAD",
keywords = "Laser scanner",
keywords = "3D point cloud",
keywords = "Reconstruction mesh",
keywords = "Point cloud data reduction",
keywords = "Accuracy ",
abstract = "The various manufacturers of digitization systems speak of the effectiveness and accuracy of their tools under optimal conditions, but actual experimentation with simple or complex objects and different materials yields results that on occasions refute the effectiveness of those systems. In order to help choose a digitization system on the basis of its accuracy and the quality of the distribution of points and triangular meshes, in the field of reverse engineering, we compared five digitization techniques (three versions of the laser scanner, a fringe projection version and an X-ray version): (1) an ordered point cloud obtained with a laser incorporated in a CMM, (2) a disordered point cloud obtained with a manual laser the position of which is determined with a Krypton Camera, (3) an Exascan manual laser with targets, (4) an ordered point cloud obtained by high precision Computerized Tomography (CT) and (5) an Atos fringe projection scanner with targets. Each of the three calibrated pieces (a sphere, a cylinder and a gauge block) was measured five times by the five digitization systems to confirm the accuracy of the measurement. A comparison was also made of the meshes generated by the five software packages (Focus-Inspection, Metris, VxScan, Mimics and Atos) of the five digitization systems for the three calibrated pieces and two more complex pieces (a bone and an automobile window winder pulley) to determine meshing quality. Finally, all the pieces were meshed by triangulation in the Catia \{V5\} \{DSE\} (Digitized Shape Editor) module in order to test the quality of the points distribution. "
}
@article{Prasad20103385,
title = "Implications of high altitude desert dust transport from Western Sahara to Nile Delta during biomass burning season ",
journal = "Environmental Pollution ",
volume = "158",
number = "11",
pages = "3385 - 3391",
year = "2010",
note = "",
issn = "0269-7491",
doi = "https://doi.org/10.1016/j.envpol.2010.07.035",
url = "http://www.sciencedirect.com/science/article/pii/S0269749110003301",
author = "Anup K. Prasad and Hesham El-Askary and Menas Kafatos",
keywords = "Dust transport",
keywords = "Sahara desert",
keywords = "Dust model",
keywords = "Black cloud",
keywords = "Biomass burning ",
abstract = "The air over major cities and rural regions of the Nile Delta is highly polluted during autumn which is the biomass burning season, locally known as black cloud. Previous studies have attributed the increased pollution levels during the black cloud season to the biomass or open burning of agricultural waste, vehicular, industrial emissions, and secondary aerosols. However, new multi-sensor observations (column and vertical profiles) from satellites, dust transport models and associated meteorology present a different picture of the autumn pollution. Here we show, for the first time, the evidence of long range transport of dust at high altitude (2.5–6 km) from Western Sahara and its deposition over the Nile Delta region unlike current Models. The desert dust is found to be a major contributor to the local air quality which was previously considered to be due to pollution from biomass burning enhanced by the dominant northerly winds coming from Europe. "
}
@article{Schwiegelshohn20101104,
title = "Perspectives on grid computing ",
journal = "Future Generation Computer Systems ",
volume = "26",
number = "8",
pages = "1104 - 1115",
year = "2010",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2010.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X10000907",
author = "Uwe Schwiegelshohn and Rosa M. Badia and Marian Bubak and Marco Danelutto and Schahram Dustdar and Fabrizio Gagliardi and Alfred Geiger and Ladislav Hluchy and Dieter Kranzlmuller and Erwin Laure and Thierry Priol and Alexander Reinefeld and Michael Resch and Andreas Reuter and Otto Rienhoff and Thomas Ruter and Peter Sloot and Domenico Talia and Klaus Ullmann and Ramin Yahyapour and Gabriele von Voigt",
keywords = "Grid computing",
keywords = "Virtual research environment",
keywords = "Grid applications",
keywords = "Grid middleware",
keywords = "Cloud computing ",
abstract = "Grid computing has been the subject of many large national and international \{IT\} projects. However, not all goals of these projects have been achieved. In particular, the number of users lags behind the initial forecasts laid out by proponents of grid technologies. This underachievement may have led to claims that the grid concept as a whole is on its way to being replaced by Cloud computing and various X-as-a-Service approaches. In this paper, we try to analyze the current situation and to identify promising directions for future grid development. Although there are shortcomings in current grid systems, we are convinced that the concept as a whole remains valid and can benefit from new developments, including Cloud computing. Furthermore, we strongly believe that some future applications will require the grid approach and that, as a result, further research is required in order to turn this concept into reliable, efficient and user-friendly computing platforms. "
}
@article{Zhang2011377,
title = "Typical Virtual Appliances: An optimized mechanism for virtual appliances provisioning and management ",
journal = "Journal of Systems and Software ",
volume = "84",
number = "3",
pages = "377 - 387",
year = "2011",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2010.11.925",
url = "http://www.sciencedirect.com/science/article/pii/S0164121210003249",
author = "Tianle Zhang and Zhihui Du and Yinong Chen and Xiang Ji and Xiaoying Wang",
keywords = "Cloud computing",
keywords = "Virtualization",
keywords = "Virtual appliance",
keywords = "Infrastructure as a service ",
abstract = "A computing infrastructure requirement in the cloud computing environment can be specified and composed using virtual appliances, which forms the infrastructure-as-a-service (IaaS). Due to the diversity of user requirements, a large number of virtual appliances may be needed. We propose a mechanism called Typical Virtual Appliances (TVAs), an efficient method for providing virtual appliances. In this paper, we present the concept of \{TVAs\} and formulate it as an optimization problem with given constraints. With analysis of the software download logs of real web sites, we discover that the number of user requirements follows a quadratic polynomial distribution, and the user requirements are clustered in nature. According to this finding, we develop a clustering-based \{TVAs\} generation algorithm, and we show that this algorithm can achieve the optimal result. The clustering algorithm can generate TVAs, which can be transformed to other virtual appliances easily and efficiently. We further design a \{TVA\} Management System (TVAMS) to support this mechanism. The simulation results show that our method can meet most of the user requirements efficiently with low storage overhead. "
}
@article{Bi2010403,
title = "Advances in 3D data acquisition and processing for industrial applications ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "26",
number = "5",
pages = "403 - 413",
year = "2010",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S073658451000013X",
author = "Z.M. Bi and Lihui Wang",
keywords = "Vision-based system",
keywords = "Data acquisition",
keywords = "Data processing",
keywords = "3D images",
keywords = "Point clouds",
keywords = "Surface reconstruction. ",
abstract = "A critical task of vision-based manufacturing applications is to generate a virtual representation of a physical object from a dataset of point clouds. Its success relies on reliable algorithms and tools. Many effective technologies have been developed to solve various problems involved in data acquisition and processing. Some articles are available on evaluating and reviewing these technologies and underlying methodologies. However, for most practitioners who lack a strong background on mathematics and computer science, it is hard to understand theoretical fundamentals of the methodologies. In this paper, we intend to survey and evaluate recent advances in data acquisition and progressing, and provide an overview from a manufacturing perspective. Some potential manufacturing applications have been introduced, the technical gaps between the practical requirements and existing technologies discussed, and research opportunities identified. "
}
@article{Gogouvitis2012193,
title = "Workflow management for soft real-time interactive applications in virtualized environments ",
journal = "Future Generation Computer Systems ",
volume = "28",
number = "1",
pages = "193 - 209",
year = "2012",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2011.05.017",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X11000999",
author = "Spyridon Gogouvitis and Kleopatra Konstanteli and Stefan Waldschmidt and George Kousiouris and Gregory Katsaros and Andreas Menychtas and Dimosthenis Kyriazis and Theodora Varvarigou",
keywords = "Workflow management",
keywords = "Quality of service",
keywords = "Cloud computing",
keywords = "Service oriented infrastructures",
keywords = "Soft real-time applications ",
abstract = "Many applications, especially the ones implementing multi-user collaborative environments, fall within the context of soft real-time systems in which only small deviations from timing constraints are allowed. The advancements in distributed computing have made it possible to follow a service oriented approach, taking advantage of the benefits this provides. In this context, applications consist of soft real-time critical application service components that interact with each other to provide the corresponding application functionality, forming application workflows. In this paper we present a new architectural design and implementation of a Workflow Management approach. This approach covers enacting soft real-time application service components according to a workflow description language, synchronizing the application components, monitoring the execution and reacting to events within a distributed virtualized environment. We also demonstrate the operation of the implemented mechanism and evaluate its effectiveness using an application scenario with soft real-time interactivity characteristics, namely Film post-production, under realistic settings. "
}
@article{Herman2009344,
title = "Development and First In Vivo Trial of EvoLap, an Active Laparoscope Positioner ",
journal = "Journal of Minimally Invasive Gynecology ",
volume = "16",
number = "3",
pages = "344 - 349",
year = "2009",
note = "",
issn = "1553-4650",
doi = "https://doi.org/10.1016/j.jmig.2009.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S1553465009001204",
author = "Benoît Herman and Khanh Tran Duy and Bruno Dehez and Roland Polet and Benoit Raucent and Etienne Dombre and Jacques Donnez",
keywords = "Compact laparoscope manipulator",
keywords = "Ergonomic control interface",
keywords = "Robotic assistant ",
abstract = "To determine essential specifications for an active endoscope holder, a survey of laparoscopic procedures was conducted. A review of the literature highlighted the advantages and limitations of existing scope-holding systems. From this analysis, basic requirements were listed for such devices. Pursuant to this, an ergonomic and user-friendly laparoscope manipulator was designed to assist the surgeon. A first in vivo procedure demonstrated feasibility of the device and its value in clinical practice, enabling surgeons to work more comfortably. "
}
@incollection{Lomenie2011255,
title = "Chapter 4 - Point Set Analysis ",
editor = "Peter W. Hawkes",
booktitle = "Advances in Imaging and Electron Physics",
publisher = "Elsevier",
year = "2011",
volume = "167",
pages = "255 - 294",
series = "Advances in Imaging and Electron Physics ",
issn = "1076-5670",
doi = "https://doi.org/10.1016/B978-0-12-385985-3.00004-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780123859853000043",
author = "Nicolas Lomenie and Georges Stamon",
keywords = "Point set",
keywords = "point cloud",
keywords = "mathematical morphology",
keywords = "mesh",
keywords = "Delaunay triangulation",
keywords = "image analysis",
keywords = "sparse representation",
keywords = "nonlinear filtering ",
abstract = "Abstract Dealing with imaging issues usually entails handling digital radiometric images. However, visual data can be efficiently handled as geometric point sets either due to the nature of the acquisition device or the intrinsic redundancy within large amounts of radiometric data. Most research works about geometric structures are related to computer graphics and image synthesis; meshes as graph representations have been involved only in a few image analysis issues to date. Yet, much room remains for completing the visual analysis tools as most image analysis algorithms are designed ro radiometric data distributed over a regular grid. We propose to extend the standard image analysis toolbox to unstructured point sets usually connected via mesh structures such as Delaunay triangulations. A particular focus on mathematical morphology sheds light on the potential applications of these ideas. More specifically, applications to digital microscopy imaging issues are discussed and preliminary results are presented. "
}
@article{Gamon2006246,
title = "A mobile tram system for systematic sampling of ecosystem optical properties ",
journal = "Remote Sensing of Environment ",
volume = "103",
number = "3",
pages = "246 - 254",
year = "2006",
note = "Spectral Network ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2006.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S0034425706001581",
author = "John A. Gamon and Yufu Cheng and Helen Claudio and Loren MacKinney and Daniel A. Sims",
keywords = "Robotic tram system",
keywords = "Spectral reflectance",
keywords = "NDVI",
keywords = "Disturbance",
keywords = "Chaparral",
keywords = "FLUXNET",
keywords = "SpecNet ",
abstract = "Reliable and repeatable field sampling methods are needed for monitoring ecosystem optical properties linked to carbon flux. Here we describe a tram system, consisting of a dual-detector spectrometer mounted on a robotic cart for mobile sampling of ecosystem spectral reflectance. To illustrate the application of this system for monitoring dynamic ecosystem activity, we illustrate how the tram can be used for exploring the multiple factors influencing the Normalized Difference Vegetation Index (NDVI), a measure of vegetation greenness and a key optical indicator of vegetation carbon dioxide assimilation. With this system, we collected five years of \{NDVI\} data for a chaparral ecosystem in Southern California subject to extreme disturbance. Key factors affecting \{NDVI\} at this site included snow cover, sky conditions (clear vs. cloudy), time of day, season, species composition, and environmental perturbations such as rainfall, drought and fire. Applications of this tram system include ecosystem monitoring, satellite validation, and developing surface-atmosphere flux models from remote sensing. "
}
@article{Nuchter2010963,
title = "Study of parameterizations for the rigid body transformations of the scan registration problem ",
journal = "Computer Vision and Image Understanding ",
volume = "114",
number = "8",
pages = "963 - 980",
year = "2010",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2010.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S107731421000072X",
author = "Andreas Nuchter and Jan Elseberg and Peter Schneider and Dietrich Paulus",
keywords = "3D scan matching",
keywords = "3D point cloud registration",
keywords = "ICP algorithm ",
abstract = "The iterative closest point (ICP) algorithm is the de facto standard for geometric alignment of three-dimensional models when an initial relative pose estimate is available. The basis of the algorithm is the minimization of an error function that takes point correspondences into account. Four closed-form solution methods are known for minimizing this function. This paper presents novel linear solutions to the scan registration problem, i.e., to the problem of putting and aligning 3D scans in a common coordinate system. We extend the methods for registering n-scans in a global and simultaneous fashion, such that the registration of the nth scan influences all previous registrations in one step. "
}
@article{Lever2008177,
title = "Revised solar-power budget for Cool Robot polar science campaigns ",
journal = "Cold Regions Science and Technology ",
volume = "52",
number = "2",
pages = "177 - 190",
year = "2008",
note = "Research in Cryospheric Science and Engineering ",
issn = "0165-232X",
doi = "https://doi.org/10.1016/j.coldregions.2007.02.009",
url = "http://www.sciencedirect.com/science/article/pii/S0165232X07000390",
author = "J.H. Lever and L.E. Ray",
keywords = "Robotic vehicle",
keywords = "Over-snow mobility",
keywords = "Antarctica",
keywords = "Greenland",
keywords = "Autonomous robot ",
abstract = "Why develop polar robots? Logistics costs predominate polar-science budgets to maintain safe human operations in extreme environments. Robots could reduce this logistics burden and thus expand research opportunities in the Polar Regions. With the funding from the National Science Foundation, we have developed first ground vehicle specifically designed to conduct long-duration autonomous science campaigns over terrestrial ice sheets. The 60-kg, solar-powered Cool Robot measures 1.2 × 1.2 × 1 m and can carry or tow 20–80 kg science payloads. A low-profile, four-wheel-drive chassis supports a five-sided, lightweight box of solar cells that capture significant reflected sunlight from the snowfield. The robot is zero emissions, so it can conduct clean snow and air measurements without being trailed by its own pollutants. A fleet of Cool Robots could support many other polar science projects, including biological sampling, glaciology surveys, and upper atmosphere or magnetosphere observations using broadly spaced instrument arrays. We present here revisions to the Cool Robot's solar-power input model to account for the effects of diffuse-sky radiation, a significant source of radiation for cloudy conditions common in Greenland. The main effect of increasing diffuse-sky radiation, for fixed global radiation, is to increase the diurnal variation in solar-power input to the robot. The revised model agrees well with irradiance measurements and the robot's measured power budget during a long-duration test conducted in Greenland. It thus allows us to adapt the Cool Robot to the specific needs of polar science campaigns with some confidence. For two-month science campaigns in Antarctica or Greenland, the Cool Robot has sufficient power margin to carry a 20-kg payload, or tow an 80-kg sled, over 1000 km per month. Under most conditions, 100–300 W are available to power the payload. The robot must yet demonstrate reliable long-distance operation. Nevertheless, results to date suggest it holds the potential to conduct significant autonomous science campaigns in Antarctica and Greenland. "
}
@article{Bosche2008499,
title = "Automated retrieval of 3D \{CAD\} model objects in construction range images ",
journal = "Automation in Construction ",
volume = "17",
number = "4",
pages = "499 - 512",
year = "2008",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2007.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580507001148",
author = "F. Bosche and C.T. Haas",
keywords = "Laser scanner",
keywords = "Range point cloud",
keywords = "Computer aided design",
keywords = "Data registration",
keywords = "Automated object recognition ",
abstract = "Automated and robust retrieval of three-dimensional (3D) Computer-Aided Design (CAD) objects from laser scanned data would have many potentially valuable applications in construction engineering and management. For example, it would enable automated progress assessment for effortless productivity tracking, automated 3D image database searching for forensic and legal analysis, and real-time local modeling for automated equipment control and safety. After reviewing and analyzing previous research in the field of automated object recognition, this paper presents a new approach for robust automated recognition/retrieval of 3D \{CAD\} objects in range point clouds in the Architectural/Engineering/Construction &amp; Facility Management (AEC-FM) context. This approach is validated in laboratory experiments. A first experiment demonstrates that this new approach can efficiently and robustly automatically retrieve 3D \{CAD\} model objects in construction laser scanned data. A second experiment demonstrates how this approach can be used for efficiently assessing construction progress. The results presented here are preliminary but conclusive for proof of concept. More extensive field experiments in this and other application areas will follow to characterize performance trade-offs in practice. "
}
@article{Kokhanovsky2007372,
title = "Aerosol remote sensing over land: A comparison of satellite retrievals using different algorithms and instruments ",
journal = "Atmospheric Research ",
volume = "85",
number = "3–4",
pages = "372 - 394",
year = "2007",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2007.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0169809507000439",
author = "A.A. Kokhanovsky and F.-M. Breon and A. Cacciari and E. Carboni and D. Diner and W. Di Nicolantonio and R.G. Grainger and W.M.F. Grey and R. Holler and K.-H. Lee and Z. Li and P.R.J. North and A.M. Sayer and G.E. Thomas and W. von Hoyningen-Huene",
keywords = "Satellite remote sensing",
keywords = "Atmospheric optics",
keywords = "Aerosols ",
abstract = "An inter-comparison study of the aerosol optical thickness (AOT) at 0.55 μm retrieved using different satellite instruments and algorithms based on the analysis of backscattered solar light is presented for a single scene over central Europe on October 13th, 2005. For the first time comparisons have been performed for as many as six instruments on multiple satellite platforms. Ten different algorithms are briefly discussed and inter-compared. It was found that on the scale of a single pixel there can be large differences in \{AOT\} retrieved over land using different retrieval techniques and instruments. However, these differences are not as pronounced for the average \{AOT\} over land. For instance, the average \{AOT\} at 0.55 μm for the area 7–12E, 49–53N was equal to 0.14 for MISR, \{NASA\} \{MODIS\} and \{POLDER\} algorithms. It is smaller by 0.01 for the \{ESA\} \{MERIS\} aerosol product and larger by 0.04 for the \{MERIS\} \{BAER\} algorithm. \{AOT\} as derived using \{AATSR\} gives on average larger values as compared to all other instruments, while \{SCIAMACHY\} retrievals underestimate the aerosol loading. These discrepancies are explained by uncertainties in a priori assumptions used in the different algorithms and differences in the sensor characteristics. Validation against \{AERONET\} shows that \{MERIS\} provides the most accurate \{AOT\} retrievals for this scene. "
}
@article{Mamei2006443,
title = "Case studies for self-organization in computer science ",
journal = "Journal of Systems Architecture ",
volume = "52",
number = "8–9",
pages = "443 - 460",
year = "2006",
note = "Nature-Inspired Applications and Systems ",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2006.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S1383762106000166",
author = "Marco Mamei and Ronaldo Menezes and Robert Tolksdorf and Franco Zambonelli",
keywords = "Self-organization metaphors",
keywords = "Middleware",
keywords = "Information systems and management",
keywords = "Security",
keywords = "Robotic system",
keywords = "Networks ",
abstract = "Self-organization is bound to greatly affect computer science. The simplicity and yet power of self-organized models will allow researchers to propose efficient solutions to problems never before thought possible to be addressed efficiently. The published works in the field clearly demonstrate the potential of this approach. This paper first reviews a number of interesting self-organization phenomena found in nature, then it discusses their potential applicability in several computer science application scenarios. "
}
@article{Kim2005666,
title = "Rapid, on-site spatial information acquisition and its use for infrastructure operation and maintenance ",
journal = "Automation in Construction ",
volume = "14",
number = "5",
pages = "666 - 684",
year = "2005",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2005.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580505000403",
author = "Changwan Kim and Carl T. Haas and Katherine A. Liapi",
keywords = "Sparse point cloud",
keywords = "On-site spatial information acquisition",
keywords = "3d CAD",
keywords = "Dense laser scanning system",
keywords = "Obstacle-avoidance system ",
abstract = "Site modeling can be useful in various safety-enhancement applications and for as-built data acquisition. In this article, a rapid, on-site, spatial-modeling method using a “sparse point cloud” approach that represents construction sites in an efficient manner is proposed. The various procedures used in the modeling process are explained. The results of the experiments performed on actual construction sites are described, as are case studies of the modeling method per se. An example of the application of the proposed site modeling method to the simulation of obstacle-avoidance in the operation of equipment on an industrial construction project is also presented. "
}
@article{Tagliaferri20042739,
title = "REM/ROSS: a powerful tool for monitoring the prompt afterglow of γ-ray bursts ",
journal = "Advances in Space Research ",
volume = "34",
number = "12",
pages = "2739 - 2743",
year = "2004",
note = "New X-Ray Results, the Next Generation of X-Ray Observatories and Gamma Ray Burst Afterglow Physics ",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2003.03.072",
url = "http://www.sciencedirect.com/science/article/pii/S0273117704006349",
author = "G. Tagliaferri and F.M. Zerbi and G. Chincarini and G. Ghisellini and M. Rodonò and E. Palazzi and L.A. Antonelli and P. Conconi and S. Covino and G. Cutispoto and E. Molinari and L. Nicastro and G. Tosti",
keywords = "γ-ray bursts afterglow",
keywords = "Robotic telescopes",
keywords = "IR astronomy ",
abstract = "Observations of the prompt afterglow of γ-ray burst events are unanimously considered of paramount importance for \{GRB\} science and cosmology. Such observations at \{NIR\} wavelengths are even more promising allowing the monitoring of high-z Ly-α absorbed bursts as well as events occurring in dusty star-forming regions. In these pages we present rapid eye mount (REM), a fully robotized fast slewing telescope equipped with a high throughput \{NIR\} (Z, J, H, K) camera dedicated to detecting the prompt \{IR\} afterglow. \{REM\} can discover objects at extremely high redshift and trigger large telescopes to observe them. The \{REM\} telescope will simultaneously feed \{REM\} optical slitless spectrograph (ROSS) via a dichroic. \{ROSS\} will intensively monitor the prompt optical continuum of \{GRB\} afterglows. The synergy between the REM-IR camera and the \{ROSS\} spectrograph makes \{REM\} a powerful observing tool for any kind of fast transient phenomena. Beside its ambitious scientific goals, \{REM\} is also technically challenging since it represent the first attempt to locate a \{NIR\} camera on a small telescope providing, with ROSS, unprecedented simultaneous wavelength coverage on a telescope of this size. "
}
@article{Guinan2004647,
title = "Seeing double in the local group: extragalactic binaries ",
journal = "New Astronomy Reviews ",
volume = "48",
number = "9",
pages = "647 - 658",
year = "2004",
note = "Extragalactic Binaries ",
issn = "1387-6473",
doi = "https://doi.org/10.1016/j.newar.2004.03.016",
url = "http://www.sciencedirect.com/science/article/pii/S1387647304000338",
author = "Edward F Guinan",
keywords = "Binaries: eclipsing",
keywords = "Stars: distances",
keywords = "Stars: fundamental parameters",
keywords = "Magellanic clouds",
keywords = "Galaxies: \{M31\} ",
abstract = "Eclipsing binaries, both inside and outside our Galaxy, are proving to be powerful tools for studying a wide spectrum of astrophysical problems. They are also are extremely valuable for providing fundamental quantities such as stellar masses, radii, luminosities, ages and distances. Recently, eclipsing binaries are turning out to be accurate distance indicators for star clusters inside our Galaxy and for determining accurate distances to nearby galaxies – such as the Magellanic Clouds and the Andromeda Galaxy. Also with eclipsing binaries, it is possible to study the physical properties and determine evolution for a wide variety of objects that are lucky enough to be binary members. These objects include pre-main sequence stars, main sequence stars, giants, supergiants, various pulsating stars, white dwarfs, black holes and even exosolar planets. At the present time over 7000 eclipsing binaries have been discovered in Local Group galaxies. These systems are mostly members of the Magellanic Clouds and the Andromeda Galaxy. But also an increasing number of extragalactic binaries are being found as members of dwarf elliptical galaxies and low surface density irregular galaxy members of the Local Group. It will be important to study the properties of eclipsing binaries that have formed in galaxies with vastly different dynamical, star formation, and chemical histories than our home Galaxy. The study of these binaries may provide clues about the star formation rates and dynamics of their host galaxies as well as the possible effects of varying chemical abundance on stellar evolution and structure. An overview of eclipsing and interacting binary star systems in exterior galaxies is presented that traces the development of this emerging field of research. Also discussed are some recent developments and future expectations for the study of extragalactic binaries. "
}
@article{Keun200692,
title = "Metabonomic modeling of drug toxicity ",
journal = "Pharmacology & Therapeutics ",
volume = "109",
number = "1–2",
pages = "92 - 106",
year = "2006",
note = "",
issn = "0163-7258",
doi = "https://doi.org/10.1016/j.pharmthera.2005.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0163725805001403",
author = "Hector C. Keun",
keywords = "Metabonomics",
keywords = "Metabolomics",
keywords = "Metabolic profiling",
keywords = "Toxicity",
keywords = "Pharmacogenomics",
keywords = "Systems biology ",
abstract = "Global metabolic profiling (metabonomics/metabolomics) has shown particular promise in the area of toxicology and drug development. In both preclinical screening and mechanistic exploration, metabolic profiling can offer rapid, noninvasive toxicological information that is robust and reproducible, with little or no added technical resources to existing studies in drug metabolism and toxicity. In this review, the study design and analytical technology required for metabonomics are discussed, along with key examples of how fundamental questions in drug development can be addressed. Strategies for metabonomic data analysis in toxicity assessment are detailed in both principle and practice, together with a description of toxicologically relevant metabolic biomarkers. Extended into the assessment of efficacy and toxicity in the clinic, metabonomics may prove crucial in making personalized therapy and pharmacogenomics a reality. "
}
@article{Parikh19991389,
title = "An evolutionary system for recognition and tracking of synoptic-scale storm systems ",
journal = "Pattern Recognition Letters ",
volume = "20",
number = "11–13",
pages = "1389 - 1396",
year = "1999",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/S0167-8655(99)00110-5",
url = "http://www.sciencedirect.com/science/article/pii/S0167865599001105",
author = "J.A Parikh and J.S DaPonte and J.N Vitale and G Tselioudis",
keywords = "Cloud tracking",
keywords = "Evolutionary computation",
keywords = "Optical flow",
keywords = "Self-organizing maps",
keywords = "k-nearest neighbor analysis ",
abstract = "An evolutionary system was developed for generation of complete tracks of northern midlatitude synoptic-scale storm systems based on optical flow and cloud motion analyses of global satellite-based datasets produced by the International Satellite Cloud Climatology Project (ISCCP). The tracking results were compared with low sea level pressure anomaly (SLPA) tracks obtained from the \{NASA\} Goddard Institute for Space Studies (GISS). The \{SLPA\} tracks were produced at \{GISS\} by analysis of meteorological, ground-based National Center for Environmental Prediction (NCEP) datasets. Results from the evolutionary system were also compared with results from using (a) the k-nearest neighbor rule (k-NN) and (b) self-organizing maps (SOM) to determine correspondences between consecutive locations within a track. The consistency of our evolutionary storm tracking results with the behavior of the low sea level pressure anomaly tracks, the ability of our evolutionary system to generate and evaluate complete tracks, and the close comparison between the results obtained by the evolutionary, k-NN, and \{SOM\} analyses of the ISCCP-derived datasets at tracking steps in which proximity or optical flow information sufficed to determine movement, demonstrate the applicability and the potential of evolutionary systems for tracking midlatitude storm systems through low-resolution \{ISCCP\} cloud product datasets. "
}
@article{Wiemann2016218,
title = "Optimizing Triangle Mesh Reconstructions of Planar Environments ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "218 - 223",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.735",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316310114",
author = "Thomas Wiemann and Kai Lingemann and Joachim Hertzberg",
keywords = "3D Mapping",
keywords = "Surface Reconstruction",
keywords = "Mesh Optimization",
keywords = "Segmentation ",
abstract = "Abstract Automatic surface reconstruction from point cloud data is an active field of research in robotics, as polygonal representations are compact and geometrically precise. Standard meshing algorithms produce many redundant triangles. Therefore methods for optimization are required. In this paper we present and evaluate a mesh optimization algorithm for robotic applications that was specially designed to exploit the planar structure of typical indoor environments. "
}
@article{Lattuati1982145,
title = "Closed contour extraction application to meteorological pictures ",
journal = "Pattern Recognition ",
volume = "15",
number = "3",
pages = "145 - 152",
year = "1982",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/0031-3203(82)90065-6",
url = "http://www.sciencedirect.com/science/article/pii/0031320382900656",
author = "V Lattuati and D Lemoine",
keywords = "Meteorological satellite",
keywords = "Cloud cover",
keywords = "Contour extraction",
keywords = "Context",
keywords = "Blurred image ",
abstract = "This paper deals with the problem of closed contour extraction for noisy images whose boundaries are very fuzzy. The method used relies on simple arguments: reduction by adaptive quantization, filtering of the reduced-levels image contours and spots detection. Application of this method to meteorological satellite images proved to be successful while classical methods would have failed. "
}
@article{Fanello2017151,
title = "Visual recognition for humanoid robots ",
journal = "Robotics and Autonomous Systems ",
volume = "91",
number = "",
pages = "151 - 168",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015301810",
author = "Sean Ryan Fanello and Carlo Ciliberto and Nicoletta Noceti and Giorgio Metta and Francesca Odone",
keywords = "Human–Robot Interaction",
keywords = "Learning and interaction",
keywords = "Visual recognition",
keywords = "Sparse representations",
keywords = "iCub ",
abstract = "Abstract Visual perception is a fundamental component for most robotics systems operating in human environments. Specifically, visual recognition is a prerequisite to a large variety of tasks such as tracking, manipulation, human–robot interaction. As a consequence, the lack of successful recognition often becomes a bottleneck for the application of robotics system to real-world situations. In this paper we aim at improving the robot visual perception capabilities in a natural, human-like fashion, with a very limited amount of constraints to the acquisition scenario. In particular our goal is to build and analyze a learning system that can rapidly be re-trained in order to incorporate new evidence if available. To this purpose, we review the state-of-the-art coding–pooling pipelines for visual recognition and propose two modifications which allow us to improve the quality of the representation, while maintaining real-time performances: a coding scheme, Best Code Entries (BCE), and a new pooling operator, Mid-Level Classification Weights (MLCW). The former focuses entirely on sparsity and improves the stability and computational efficiency of the coding phase, the latter increases the discriminability of the visual representation, and therefore the overall recognition accuracy of the system, by exploiting data supervision. The proposed pipeline is assessed from a qualitative perspective on a Human–Robot Interaction (HRI) application on the iCub platform. Quantitative evaluation of the proposed system is performed both on in-house robotics data-sets (iCubWorld) and on established computer vision benchmarks (Caltech-256, \{PASCAL\} \{VOC\} 2007). As a byproduct of this work, we provide for the robotics community an implementation of the proposed visual recognition pipeline which can be used as perceptual layer for more complex robotics applications. "
}
@article{Litany2017284,
title = "ASIST: Automatic semantically invariant scene transformation ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "284 - 299",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216301102",
author = "Or Litany and Tal Remez and Daniel Freedman and Lior Shapira and Alex Bronstein and Ran Gal",
keywords = "Semantic segmentation",
keywords = "Object recognition",
keywords = "Random forest",
keywords = "Iterative closest point",
keywords = "Alternating minimization",
keywords = "Pose estimation",
keywords = "Registration ",
abstract = "Abstract We present ASIST, a technique for transforming point clouds by replacing objects with their semantically equivalent counterparts. Transformations of this kind have applications in virtual reality, repair of fused scans, and robotics. \{ASIST\} is based on a unified formulation of semantic labeling and object replacement; both result from minimizing a single objective. We present numerical tools for the efficient solution of this optimization problem. The method is experimentally assessed on new datasets of both synthetic and real point clouds, and is additionally compared to two recent works on object replacement on data from the corresponding papers. "
}
@article{Carnevale2016144,
title = "Will robots know us better than we know ourselves? ",
journal = "Robotics and Autonomous Systems ",
volume = "86",
number = "",
pages = "144 - 151",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.027",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305449",
author = "Antonio Carnevale",
keywords = "Robots",
keywords = "Privacy",
keywords = "Techno-regulation",
keywords = "Philosophy of technology",
keywords = "Critical culture of technology ",
abstract = "Abstract This paper aims to highlight some conceptual aspects on the impact of robotics on our concept of privacy. In those areas where robotics applications will invade the privacy of individuals as computers or mobile phones do today, the current idea of privacy will no longer suffice to ensure the right level of people’s protection. If we think to answer or stop the forthcoming controversies only relying on self-regulation of private parties, we will escape the real challenge: the next generation of robots does not affect solely persons and their individual rights, but the entire structure of society. This article assumes the robotics–privacy relationship as a clear illustration of how the technology–society nexus should be regulated in the future. We need approaches that are contextual–normativeand that should be politically addressed to the creation of a critical culture of technology. "
}
@article{Kopacek201411425,
title = "Ethical and social aspects of robots ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "11425 - 11430",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00857",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016434324",
author = "P. Kopacek",
keywords = "Robots",
keywords = "Ethics",
keywords = "Social Aspects",
keywords = "System “Human-Robot”",
keywords = "EoL of robots ",
abstract = "Abstract Robotics is a very fast growing field especially in the last years and is a discipline based on: mechanics, physics/mathematics, control engineering, electr(on)ics, computer science. Therefore robots are frequently used as examples for Mechatronic Systems. Robotics unifies two cultures: Science and humanities. The effort to design roboethics should make the unity of these two cultures a primary assumption. This means that experts shall view Robotics as a whole - in spite of the current early stage which recalls a melting pot. Some decades ago social aspects of robotics were discussed. Because of the results and the rapid development of this field ethical issues became more and more important. Therefore the term roboethics was introduced in the literature. The main goal of this contribution is to present and discuss this subject, probably at the first time, from the viewpoint of robotics. First an overview from a practical, robotics viewpoint will be given. Then a short presentation of currently and in the future available robots and some ideas about the ethical problems are discussed. Special emphasis is on the ethical behavior of the system “human-robot” and “End of Life – EoL” management. "
}
@article{Kopacek201267,
title = "Roboethics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "10",
pages = "67 - 72",
year = "2012",
note = "14th \{IFAC\} Workshop on International Stability and Systems Engineering ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120611-3-IE-4029.00015",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015337137",
author = "P. Kopacek",
keywords = "Robots, Artificial Intelligence, Ethics, Social Aspects. ",
abstract = "Abstract Robotics is a very fast growing field especially in the last years. Begin of the 90's a new generation of mobile, intelligent, cooperative robots grows up. This new generation opens new applications areas like in the household, for medical and rehabilitation applications, in the entertainment industry as well as for leisure and hobby. Current developing trends are humanoid robots and robots supporting the human in everyday life. Other intensive research areas are cooperative robots, bio inspired robots, ubiquitous robots and cloud robots. Robotics is a new science as well as a branch or a field of application of Engineering. Some decades ago social aspects of robotics were discussed. Because of the results and the rapid development of this field ethical issues became more and more important. Therefore the term Roboethics was introduced in the literature. In this contribution a first overview from a practical viewpoint will be given. "
}
@incollection{Christ2014641,
title = "Chapter 23 - The Future of \{ROV\} Technology ",
editor = "Christ, Robert D. and ,  and Wernli, Robert L. ",
booktitle = "The \{ROV\} Manual (Second Edition) ",
publisher = "Butterworth-Heinemann",
edition = "Second Edition",
address = "Oxford",
year = "2014",
pages = "641 - 661",
isbn = "978-0-08-098288-5",
doi = "https://doi.org/10.1016/B978-0-08-098288-5.00023-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780080982885000233",
author = "Robert D. Christ and Robert L. Wernli Sr.",
keywords = "Structurally Compliant Vehicles",
keywords = "Autonomous Underwater Vehicles",
keywords = "Hybrid Vehicles",
keywords = "Fiber-Optic Linked ROVs",
keywords = "Batteries",
keywords = "Underwater Structure Inspection",
keywords = "Underwater Radio Frequency Communications",
keywords = "Inductive Coupling",
keywords = "The “Inter-Sea-Net”",
keywords = "The Future of \{ROV\} Technology ",
abstract = "In this final chapter, we delve into the future of remotely operated vehicle technology. This chapter covers both current developmental initiatives along with the authors’ “crystal ball” look into the future of subsea robotics. "
}
@incollection{Klancar2017207,
title = "Chapter 5 - Sensors Used in Mobile Systems ",
editor = "Klancar, Gregor and , and Zdesar, Andrej and , and Blažic, Saso and ,  and skrjanc, Igor ",
booktitle = "Wheeled Mobile Robotics ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2017",
pages = "207 - 288",
isbn = "978-0-12-804204-5",
doi = "https://doi.org/10.1016/B978-0-12-804204-5.00005-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128042045000056",
author = "Gregor Klancar and Andrej Zdesar and Saso Blažic and Igor skrjanc",
keywords = "Sensors",
keywords = "Pose estimation",
keywords = "Transformations",
keywords = "Dead reckoning",
keywords = "Active markers",
keywords = "Features ",
abstract = "Abstract Sensors are one of the key elements in mobile robotics. Together with other essential elements, they enable mobile robots to autonomously perform their actions, such as trajectory tracking, to locate and track targets, act safely by preventing collisions, and to localize and map the environment. Although they play a vital role they are also a limiting factor in mobile robotics because perfect, robust, and available sensors that would directly measure robot location are usually not available. Therefore, this chapter starts by introducing the different transformations that are later needed to relate local sensor-measured information to the information in robot coordinates. Then the main methods and sensors used to estimate robot pose are presented. They need to be a part of every robot localization system. The chapter ends with brief overview of sensors, their classifications, and main characteristics. "
}
@article{RomeroGonzalez2017181,
title = "On robot indoor scene classification based on descriptor quality and efficiency ",
journal = "Expert Systems with Applications ",
volume = "79",
number = "",
pages = "181 - 193",
year = "2017",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.02.040",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417301318",
author = "Cristina Romero-Gonzalez and Jesus Martinez-Gomez and Ismael Garcia-Varea and Luis Rodriguez-Ruiz",
keywords = "Indoor scenes",
keywords = "Semantic classification",
keywords = "Multi-source classification",
keywords = "Descriptor combination",
keywords = "Spatial pyramid technique ",
abstract = "Abstract Indoor scene classification is usually approached from a computer vision perspective. However, in some fields like robotics, additional constraints must be taken into account. Specifically, in systems with low resources, state-of-the-art techniques (CNNs) cannot be successfully deployed. In this paper, we try to close this gap between theoretical approaches and real world solutions by performing an in-depth study of the factors that influence classifiers performance, that is, size and descriptor quality. To this end, we perform a thorough evaluation of the visual and depth data obtained with an RGB-D sensor to propose techniques to build robust descriptors that can enable real-time indoor scene classification. Those descriptors are obtained by properly selecting and combining visual and depth information sources. "
}
@article{Kim2015306,
title = "Adaptive buffer control for distributed autonomous robust routing in mobile surveillance robots ",
journal = "Computers & Electrical Engineering ",
volume = "43",
number = "",
pages = "306 - 316",
year = "2015",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2014.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0045790614002602",
author = "Joongheon Kim and Song-Nam Hong",
keywords = "60 GHz",
keywords = "Wireless video streaming",
keywords = "Stochastic optimization",
keywords = "Buffer management",
keywords = "Distributed autonomous robust routing",
keywords = "Mobile surveillance robots ",
abstract = "Abstract This paper proposes a distributed and autonomous routing algorithm for distributed mobile surveillance robotics platforms using 60 \{GHz\} wireless technologies. According to the fact that 60 \{GHz\} wireless signals are too weak to survive in long-distance or non-line-of-sight situations due to high attenuation, advanced communication algorithms are required including beamforming, beam training, and multi-hop routing. For multi-hop robust distributed routing, each robotics platform computes the amounts of power allocation for transmitting packets from its own buffer. The amount of power allocation is determined by solving joint stochastic optimization of (i) the minimization of the summation of time average expected power consumption and (ii) the buffer stability in each unit time slot. The performance of the proposed algorithm is evaluated and it is observed that the proposed algorithm achieves desired performance. "
}
@article{Stumm2016269,
title = "Human-Machine Interaction for Intuitive Programming of Assembly Tasks in Construction ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "269 - 274",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.02.108",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116003905",
author = "Sven Stumm and Johannes Braumann and Sigrid Brell-Cokcan",
keywords = "Robot programming",
keywords = "Skill based programming",
keywords = "Visual programming",
keywords = "CAD based programming",
keywords = "Gesture recognition",
keywords = "Construction ",
abstract = "Abstract A variety of robot programming techniques exists ranging from constraint based over skill based programming to learning by demonstration. In order to extend their applicability propose to join some of these approaches. We therefore combine visual \{CAD\} based programming with skill based programming through demonstration. This constitutes the basis of the outlines strategy. We then employ human feedback through hand gestures for incremental parameter modification. We propose this approach in order to potentially lower times to production for new products and allow efficient use of robotics in low lot-sizes especially in the context of assembly for construction. "
}
@article{Droeschel2017104,
title = "Continuous mapping and localization for autonomous navigation in rough terrain using a 3D laser scanner ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "104 - 115",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015303110",
author = "David Droeschel and Max Schwarz and Sven Behnke",
keywords = "Mapping",
keywords = "Localization",
keywords = "Rough terrain ",
abstract = "Abstract For autonomous navigation in difficult terrain, such as degraded environments in disaster response scenarios, robots are required to create a map of an unknown environment and to localize within this map. In this paper, we describe our approach to simultaneous localization and mapping that is based on the measurements of a 3D laser-range finder. We aggregate laser-range measurements by registering sparse 3D scans with a local multiresolution surfel map that has high resolution in the vicinity of the robot and coarser resolutions with increasing distance, which corresponds well to measurement density and accuracy of our sensor. By modeling measurements by surface elements, our approach allows for efficient and accurate registration and leverages online mapping and localization. The incrementally built local dense 3D maps of nearby key poses are registered against each other. Graph optimization yields a globally consistent dense 3D map of the environment. Continuous registration of local maps with the global map allows for tracking the 6D robot pose in real time. We assess the drivability of the terrain by analyzing height differences in an allocentric height map and plan cost-optimal paths. The system has been successfully demonstrated during the \{DARPA\} Robotics Challenge and the \{DLR\} SpaceBot Camp. In experiments, we evaluate accuracy and efficiency of our approach. "
}
@article{Sand2013341,
title = "Closing the loops: An industrial perspective on the present and future impact of control ",
journal = "European Journal of Control ",
volume = "19",
number = "5",
pages = "341 - 350",
year = "2013",
note = "The Path of Control ",
issn = "0947-3580",
doi = "https://doi.org/10.1016/j.ejcon.2013.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0947358013000897",
author = "Guido Sand and Peter Terwiesch",
abstract = "Abstract This paper provides an industrial perspective on the present and future trends and impact of control. Applications in power systems, process automation and robotics are discussed against business, environmental, and technology trends, so as to outline current and future fields of control research and application. "
}
@article{Navarrete2016550,
title = "3DCOMET: 3D compression methods test dataset ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "550 - 557",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002237",
author = "Javier Navarrete and Vicente Morell and Miguel Cazorla and Diego Viejo and Jose Garcia-Rodriguez and Sergio Orts-Escolano",
keywords = "3D data",
keywords = "Data compression",
keywords = "Dataset ",
abstract = "Abstract The use of 3D data in mobile robotics applications provides valuable information about the robot’s environment. However usually the huge amount of 3D information is difficult to manage due to the fact that the robot storage system and computing capabilities are insufficient. Therefore, a data compression method is necessary to store and process this information while preserving as much information as possible. A few methods have been proposed to compress 3D information. Nevertheless, there does not exist a consistent public benchmark for comparing the results (compression level, distance reconstructed error, etc.) obtained with different methods. In this paper, we propose a dataset composed of a set of 3D point clouds with different structure and texture variability to evaluate the results obtained from 3D data compression methods. We also provide useful tools for comparing compression methods, using as a baseline the results obtained by existing relevant compression methods. "
}
@incollection{Kelley2014343,
title = "Chapter 14 - Intent Recognition for Human–Robot Interaction ",
editor = "Sukthankar, Gita and , and Geib, Christopher and , and Bui, Hung Hai and , and Pynadath, David V. and ,  and Goldman, Robert P. ",
booktitle = "Plan, Activity, and Intent Recognition ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2014",
pages = "343 - 365",
isbn = "978-0-12-398532-3",
doi = "https://doi.org/10.1016/B978-0-12-398532-3.00014-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780123985323000142",
author = "Richard Kelley and Alireza Tavakkoli and Christopher King and Amol Ambardekar and Liesl Wigand and Monica Nicolescu and Mircea Nicolescu",
keywords = "Intent",
keywords = "Hidden Markov model",
keywords = "Context",
keywords = "Lexical graph",
keywords = "Human–robot interaction ",
abstract = "Abstract For robots to operate in social environments, they must be able to recognize human intentions. In the context of social robotics, intent recognition must rely on imperfect sensors, such as depth cameras, and must operate in real time. This chapter introduces several approaches for recognizing intentions by physical robots. We show how such systems can use sensors, such as the Microsoft Kinect, as well as temporal and contextual information obtained from resources such as Wikipedia. "
}
@article{Woods2016298,
title = "Lidar-based relative navigation with respect to non-cooperative objects ",
journal = "Acta Astronautica ",
volume = "126",
number = "",
pages = "298 - 311",
year = "2016",
note = "Space Flight Safety ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2016.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515301661",
author = "John O. Woods and John A. Christian",
keywords = "Relative navigation",
keywords = "Spacecraft rendezvous",
keywords = "LIDAR",
keywords = "OUR-CVFH ",
abstract = "Abstract Most navigation solutions which make use of lidar for proximity operations with respect to non-cooperative objects rely on the iterative closest point, or icp, algorithm. For correct convergence, icp requires a good initial guess as to the 6 degree-of-freedom relative pose of a client object. Some solutions require manual pose initialization; and template matching — refined by icp — was recently demonstrated as an automated solution for initialization. Additionally, some have used the output of one icp iteration as the initial guess for the next, which is inherently dangerous (since bad icp poses are propagated forward in time by the filter, by icp, or by both; and because it introduces measurement errors that are correlated with the a priori state errors). We demonstrate the use of a method borrowed from personal robotics, our-cvfh (for Oriented, Unique, and Repeatable Clustered Viewpoint Feature Histograms), for rendezvous with a tumbling object in low earth orbit as well as an asteroid in a heliocentric orbit. Our strategy requires no initial pose estimate, and refines our-cvfh results with icp; we demonstrate its utility as part of a full navigation solution with a dual-state inertial extended Kalman filter. "
}
@article{Yu201670,
title = "Scene parsing using graph matching on street-view data ",
journal = "Computer Vision and Image Understanding ",
volume = "145",
number = "",
pages = "70 - 80",
year = "2016",
note = "Light Field for Computer Vision ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216000175",
author = "Tianshu Yu and Ruisheng Wang",
keywords = "Scene parsing",
keywords = "Graph matching",
keywords = "Markov random field",
keywords = "Street view ",
abstract = "Abstract Scene parsing, using both images and range data, is one of the key problems in computer vision and robotics. In this paper, a street scene parsing scheme that takes advantages of images from perspective cameras and range data from LiDAR is presented. First, pre-processing on the image set is performed and the corresponding point cloud is segmented according to semantics and transformed into an image pose. A graph matching approach is introduced into our parsing framework, in order to identify similar sub-regions from training and test images in terms of both local appearance and spatial structure. By using the sub-graphs inherited from training images, as well as the cues obtained from point clouds, this approach can effectively interpret the street scene via a guided \{MRF\} inference. Experimental results show a promising performance of our approach. "
}
@article{Kopacek201521,
title = "Automation and \{TECIS\} ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "24",
pages = "21 - 27",
year = "2015",
note = "16th \{IFAC\} Conference on Technology, Culture and International Stability \{TECIS\} 2015Sozopol, Bulgaria, 24–27 September 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.12.050",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315026749",
author = "P. Kopacek",
keywords = "Process Automation",
keywords = "Manufacturing Automation",
keywords = "Robots",
keywords = "Social aspects",
keywords = "Ethics ",
abstract = "Abstract Process - and manufacturing automation as well as robotics are currently one of the fast growing fields in automation. Advanced process control, cyber-physical systems, industry 4.0 and “advanced robots” are not longer a headline. They are in realization. As a consequence of these developments new social, ethical and human questions appear. Therefore this contribution is a first trial to merge selected items from the scope of the \{IF\} \{AC\} \{TC\} \{TECIS\} with these new questions. As a result first ideas to solve these problems are presented and shortly discussed. Finally suggestions for further research topics are given "
}
@article{Li2016352,
title = "Dexterous grasping under shape uncertainty ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "352 - 364",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001967",
author = "Miao Li and Kaiyu Hang and Danica Kragic and Aude Billard",
keywords = "Dexterous grasping",
keywords = "Shape uncertainty",
keywords = "Grasp control",
keywords = "Grasp learning ",
abstract = "Abstract An important challenge in robotics is to achieve robust performance in object grasping and manipulation, dealing with noise and uncertainty. This paper presents an approach for addressing the performance of dexterous grasping under shape uncertainty. In our approach, the uncertainty in object shape is parametrized and incorporated as a constraint into grasp planning. The proposed approach is used to plan feasible hand configurations for realizing planned contacts using different robotic hands. A compliant finger closing scheme is devised by exploiting both the object shape uncertainty and tactile sensing at fingertips. Experimental evaluation demonstrates that our method improves the performance of dexterous grasping under shape uncertainty. "
}
@incollection{Kangovi2017273,
title = "9 - Next Steps in Peering Carrier Ethernet Networks ",
editor = "Kangovi, Sachidananda ",
booktitle = "Peering Carrier Ethernet Networks ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2017",
pages = "273 - 278",
isbn = "978-0-12-805319-5",
doi = "https://doi.org/10.1016/B978-0-12-805319-5.00009-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053195000095",
author = "Sachidananda Kangovi",
keywords = "Automatic protection switching mechanism",
keywords = "Ethernet interconnect points (EIP)",
keywords = "Network function virtualization",
keywords = "Next steps in operations and business support systems (OSS/BSS)",
keywords = "Next steps in peering Carrier Ethernet networks (CENs)",
keywords = "Smart connected planet",
keywords = "Virtual reality ",
abstract = "Abstract We now have come to the last chapter of this book, journeying through the changing landscape beginning with the invention of telephone in 1876 to the present state of information and communication technology in 2016 where peering carrier Ethernet networks (CENs) are poised to play an important role in \{IP\} backhaul, mobile backhaul, streaming and switched video transport, site-to-site connectivity, and connections for cloud computing services to facilitate network connectivity for existing as well as emerging applications like cyber-physical systems, robotics, and virtual reality. In this journey, we have seen how Ethernet evolved as the most adopted protocol in layer 2, resulting in over 90% of \{LAN\} traffic around the globe on Ethernet today. Further enhancements in Ethernet led to Ethernet over \{DWDM\} at layer 1 which extended its reach beyond \{LAN\} to MAN, RAN, and WAN. In this journey, we also saw that to leverage benefits of Ethernet technology including higher bandwidth, low frame delay, low frame delay variation, and low frame loss probability as well as elimination of multiple protocol translations, MEF-defined and standardized carrier Ethernet services, making them reliable, scalable, and carrier grade resulting in CENs. The expansion of \{CENs\} has now necessitated peering of CENs. Demands of higher bandwidth and performance by emerging applications on data networks and the push by operators to lower Capex and Opex are propelling \{CENs\} and peering \{CENs\} right in the front and the center. In this chapter, we will examine some of the next steps needed in the Ethernet technology and peering \{CENs\} and also in operations and business support systems (OSS/BSS) to meet the growing demands because these provide important foundation for subscriber applications and are critical to the operations of the service providing and access providing operators. "
}
@article{Charalampous201785,
title = "Recent trends in social aware robot navigation: A survey ",
journal = "Robotics and Autonomous Systems ",
volume = "93",
number = "",
pages = "85 - 104",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016302287",
author = "Konstantinos Charalampous and Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Metric mapping",
keywords = "Semantic mapping",
keywords = "Proxemics",
keywords = "Social mapping ",
abstract = "Abstract With the robots tending to accumulate more and more capabilities beyond the level of acting in a deterministic fashion, the idea of introducing them into our every day lives seems to be closer now. Robotics systems and techniques appeared during the recent years have achieved astonishing potential to perceive and interpret their surrounding not only as low level features but also close to human understandable concepts. Such advances, in conjunction with the aspiration to incorporate robots into domestic or public places, led to the flourishing of fields dealing with their response in human presence. Following this notion, the field of social mapping was recently introduced in order to manage the shared space among robots and individuals in an ordinary fashion. This manuscript aims to systemize the recent literature by describing the required levels of robot perception, focusing on methods related to robot’s social awareness, the availability of datasets these methods can be compared with, as well as issues that remain open and need to be confronted when robots operate in close proximity with humans. "
}
@article{Kasaei2016312,
title = "GOOD: A global orthographic object descriptor for 3D object recognition and manipulation ",
journal = "Pattern Recognition Letters ",
volume = "83, Part 3",
number = "",
pages = "312 - 320",
year = "2016",
note = "Efficient Shape Representation, Matching, Ranking, and its Applications ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2016.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167865516301684",
author = "S. Hamidreza Kasaei and Ana Maria Tome and Luis Seabra Lopes and Miguel Oliveira",
keywords = "3D object recognition",
keywords = "Object Perception",
keywords = "Orthographic projection ",
abstract = "Abstract Object representation is one of the most challenging tasks in robotics because it must provide reliable information in real-time to enable the robot to physically interact with the objects in its environment. To ensure robustness, a global object descriptor must be computed based on a unique and repeatable object reference frame. Moreover, the descriptor should contain enough information enabling to recognize the same or similar objects seen from different perspectives. This paper presents a new object descriptor named Global Orthographic Object Descriptor (GOOD) designed to be robust, descriptive and efficient to compute and use. We propose a novel sign disambiguation method, for computing a unique reference frame from the eigenvectors obtained through Principal Component Analysis of the point cloud of the target object view captured by a 3D sensor. Three principal orthographic projections and their distribution matrices are computed by exploiting the object reference frame. The descriptor is finally obtained by concatenating the distribution matrices in a sequence determined by entropy and variance features of the projections. Experimental results show that the overall classification performance obtained with \{GOOD\} is comparable to the best performances obtained with the state-of-the-art descriptors. Concerning memory and computation time, \{GOOD\} clearly outperforms the other descriptors. Therefore, \{GOOD\} is especially suited for real-time applications. The estimated object’s pose is precise enough for real-time object manipulation tasks. "
}
@article{Yang201545,
title = "Hierarchical extraction of urban objects from mobile laser scanning data ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "99",
number = "",
pages = "45 - 57",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S092427161400255X",
author = "Bisheng Yang and Zhen Dong and Gang Zhao and Wenxia Dai",
keywords = "Mobile laser scanning",
keywords = "Multi-scale supervoxel",
keywords = "Segmentation",
keywords = "Object extraction",
keywords = "Classification",
keywords = "Filtering ",
abstract = "Abstract Point clouds collected in urban scenes contain a huge number of points (e.g., billions), numerous objects with significant size variability, complex and incomplete structures, and variable point densities, raising great challenges for the automated extraction of urban objects in the field of photogrammetry, computer vision, and robotics. This paper addresses these challenges by proposing an automated method to extract urban objects robustly and efficiently. The proposed method generates multi-scale supervoxels from 3D point clouds using the point attributes (e.g., colors, intensities) and spatial distances between points, and then segments the supervoxels rather than individual points by combining graph based segmentation with multiple cues (e.g., principal direction, colors) of the supervoxels. The proposed method defines a set of rules for merging segments into meaningful units according to types of urban objects and forms the semantic knowledge of urban objects for the classification of objects. Finally, the proposed method extracts and classifies urban objects in a hierarchical order ranked by the saliency of the segments. Experiments show that the proposed method is efficient and robust for extracting buildings, streetlamps, trees, telegraph poles, traffic signs, cars, and enclosures from mobile laser scanning (MLS) point clouds, with an overall accuracy of 92.3%. "
}
@article{MartinezGomez2016641,
title = "Semantic localization in the \{PCL\} library ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "641 - 648",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001943",
author = "Jesus Martinez-Gomez and Vicente Morell and Miguel Cazorla and Ismael Garcia-Varea",
keywords = "Semantic localization",
keywords = "PCL",
keywords = "3D features",
keywords = "Classification ",
abstract = "Abstract The semantic localization problem in robotics consists in determining the place where a robot is located by means of semantic categories. The problem is usually addressed as a supervised classification process, where input data correspond to robot perceptions while classes to semantic categories, like kitchen or corridor. In this paper we propose a framework, implemented in the \{PCL\} library, which provides a set of valuable tools to easily develop and evaluate semantic localization systems. The implementation includes the generation of 3D global descriptors following a Bag-of-Words approach. This allows the generation of fixed-dimensionality descriptors from any type of keypoint detector and feature extractor combinations. The framework has been designed, structured and implemented to be easily extended with different keypoint detectors, feature extractors as well as classification models. The proposed framework has also been used to evaluate the performance of a set of already implemented descriptors, when used as input for a specific semantic localization system. The obtained results are discussed paying special attention to the internal parameters of the BoW descriptor generation process. Moreover, we also review the combination of some keypoint detectors with different 3D descriptor generation techniques. "
}
@article{Liu201748,
title = "Online RGB-D person re-identification based on metric model update ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "2",
number = "1",
pages = "48 - 55",
year = "2017",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2017.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S2468232217300215",
author = "Hong Liu and Liang Hu and Liqian Ma",
keywords = "Person re-identification",
keywords = "Online metric model update",
keywords = "Face information",
keywords = "Skeleton information ",
abstract = "Abstract Person re-identification (re-id) on robot platform is an important application for human-robot-interaction (HRI), which aims at making the robot recognize the around persons in varying scenes. Although many effective methods have been proposed for surveillance re-id in recent years, re-id on robot platform is still a novel unsolved problem. Most existing methods adapt the supervised metric learning offline to improve the accuracy. However, these methods can not adapt to unknown scenes. To solve this problem, an online re-id framework is proposed. Considering that robotics can afford to use high-resolution RGB-D sensors and clear human face may be captured, face information is used to update the metric model. Firstly, the metric model is pre-trained offline using labeled data. Then during the online stage, we use face information to mine incorrect body matching pairs which are collected to update the metric model online. In addition, to make full use of both appearance and skeleton information provided by RGB-D sensors, a novel feature funnel model (FFM) is proposed. Comparison studies show our approach is more effective and adaptable to varying environments. "
}
@article{Lambert2007421,
title = "A \{METHODOLOGY\} \{FOR\} \{ASSESSING\} \{ROBOT\} \{AUTONOMOUS\} \{FUNCTIONALITIES\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "421 - 426",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00072",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346973",
author = "M. Lambert and R. Jaulmes and A. Godin and E. Moline and D. Dufourd",
keywords = "Autonomous vehicles – Behaviours – Algorithms – Database – Performance evaluation ",
abstract = "Abstract Autonomous navigation of unmanned vehicles takes advantage of advanced robotics technologies. However, it is rather difficult to assess their performance as no common benchmark is available. Thus, for its own needs, the French Defence procurement agency proposes an evaluation methodology for perception based behaviours. It relies on a reference database comprising both real acquisitions and simulated data. "
}
@article{Christensen2017,
title = "Approximation and online algorithms for multidimensional bin packing: A survey ",
journal = "Computer Science Review ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1574-0137",
doi = "https://doi.org/10.1016/j.cosrev.2016.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S1574013716301356",
author = "Henrik I. Christensen and Arindam Khan and Sebastian Pokutta and Prasad Tetali",
keywords = "Approximation algorithms",
keywords = "Online algorithms",
keywords = "Multidimensional packing and covering",
keywords = "Bin packing",
keywords = "Multidimensional scheduling",
keywords = "Geometric packing ",
abstract = "Abstract The bin packing problem is a well-studied problem in combinatorial optimization. In the classical bin packing problem, we are given a list of real numbers in ( 0 , 1 ] and the goal is to place them in a minimum number of bins so that no bin holds numbers summing to more than 1. The problem is extremely important in practice and finds numerous applications in scheduling, routing and resource allocation problems. Theoretically the problem has rich connections with discrepancy theory, iterative methods, entropy rounding and has led to the development of several algorithmic techniques. In this survey we consider approximation and online algorithms for several classical generalizations of bin packing problem such as geometric bin packing, vector bin packing and various other related problems. There is also a vast literature on mathematical models and exact algorithms for bin packing. However, this survey does not address such exact algorithms. In two-dimensional geometric bin packing, we are given a collection of rectangular items to be packed into a minimum number of unit size square bins. This variant has a lot of applications in cutting stock, vehicle loading, pallet packing, memory allocation and several other logistics and robotics related problems. In d -dimensional vector bin packing, each item is a d -dimensional vector that needs to be packed into unit vector bins. This problem is of great significance in resource constrained scheduling and in recent virtual machine placement in cloud computing. We also consider several other generalizations of bin packing such as geometric knapsack, strip packing and other related problems such as vector scheduling, vector covering etc. We survey algorithms for these problems in offline and online setting, and also mention results for several important special cases. We briefly mention related techniques used in the design and analysis of these algorithms. In the end we conclude with a list of open problems. "
}
@article{Kaddah2016117,
title = "Road marking features extraction using the VIAPIX® system ",
journal = "Optics Communications ",
volume = "371",
number = "",
pages = "117 - 127",
year = "2016",
note = "",
issn = "0030-4018",
doi = "https://doi.org/10.1016/j.optcom.2016.03.065",
url = "http://www.sciencedirect.com/science/article/pii/S003040181630236X",
author = "W. Kaddah and Y. Ouerhani and A. Alfalou and M. Desthieux and C. Brosseau and C. Gutierrez",
keywords = "Optical correlation",
keywords = "POF filter",
keywords = "VIAPIX system",
keywords = "Road marks ",
abstract = "Abstract Precise extraction of road marking features is a critical task for autonomous urban driving, augmented driver assistance, and robotics technologies. In this study, we consider an autonomous system allowing us lane detection for marked urban roads and analysis of their features. The task is to relate the georeferencing of road markings from images obtained using the VIAPIX® system. Based on inverse perspective mapping and color segmentation to detect all white objects existing on this road, the present algorithm enables us to examine these images automatically and rapidly and also to get information on road marks, their surface conditions, and their georeferencing. This algorithm allows detecting all road markings and identifying some of them by making use of a phase-only correlation filter (POF). We illustrate this algorithm and its robustness by applying it to a variety of relevant scenarios. "
}
@article{Parisi2017208,
title = "Emergence of multimodal action representations from neural network self-organization ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "208 - 221",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S138904171630050X",
author = "German I. Parisi and Jun Tani and Cornelius Weber and Stefan Wermter",
keywords = "Human action recognition",
keywords = "multimodal integration",
keywords = "self-organizing neural networks ",
abstract = "Abstract The integration of multisensory information plays a crucial role in autonomous robotics to forming robust and meaningful representations of the environment. In this work, we investigate how robust multimodal representations can naturally develop in a self-organizing manner from co-occurring multisensory inputs. We propose a hierarchical architecture with growing self-organizing neural networks for learning human actions from audiovisual inputs. The hierarchical processing of visual inputs allows to obtain progressively specialized neurons encoding latent spatiotemporal dynamics of the input, consistent with neurophysiological evidence for increasingly large temporal receptive windows in the human cortex. Associative links to bind unimodal representations are incrementally learned by a semi-supervised algorithm with bidirectional connectivity. Multimodal representations of actions are obtained using the co-activation of action features from video sequences and labels from automatic speech recognition. Experimental results on a dataset of 10 full-body actions show that our system achieves state-of-the-art classification performance without requiring the manual segmentation of training samples, and that congruent visual representations can be retrieved from recognized speech in the absence of visual stimuli. Together, these results show that our hierarchical neural architecture accounts for the development of robust multimodal representations from dynamic audiovisual inputs. "
}
@article{Sardemann20161,
title = "On the accuracy potential of focused plenoptic camera range determination in long distance operation ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "114",
number = "",
pages = "1 - 9",
year = "2016",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616000277",
author = "Hannes Sardemann and Hans-Gerd Maas",
keywords = "Plenoptic camera",
keywords = "Light field",
keywords = "Range image",
keywords = "Accuracy ",
abstract = "Abstract Plenoptic cameras have found increasing interest in optical 3D measurement techniques in recent years. While their basic principle is 100 years old, the development in digital photography, micro-lens fabrication technology and computer hardware has boosted the development and lead to several commercially available ready-to-use cameras. Beyond their popular option of a posteriori image focusing or total focus image generation, their basic ability of generating 3D information from single camera imagery depicts a very beneficial option for certain applications. The paper will first present some fundamentals on the design and history of plenoptic cameras and will describe depth determination from plenoptic camera image data. It will then present an analysis of the depth determination accuracy potential of plenoptic cameras. While most research on plenoptic camera accuracy so far has focused on close range applications, we will focus on mid and long ranges of up to 100 m. This range is especially relevant, if plenoptic cameras are discussed as potential mono-sensorial range imaging devices in (semi-)autonomous cars or in mobile robotics. The results show the expected deterioration of depth measurement accuracy with depth. At depths of 30–100 m, which may be considered typical in autonomous driving, depth errors in the order of 3% (with peaks up to 10–13 m) were obtained from processing small point clusters on an imaged target. Outliers much higher than these values were observed in single point analysis, stressing the necessity of spatial or spatio-temporal filtering of the plenoptic camera depth measurements. Despite these obviously large errors, a plenoptic camera may nevertheless be considered a valid option for the application fields of real-time robotics like autonomous driving or unmanned aerial and underwater vehicles, where the accuracy requirements decrease with distance. "
}
@article{Heylighen20164,
title = "Stigmergy as a universal coordination mechanism I: Definition and components ",
journal = "Cognitive Systems Research ",
volume = "38",
number = "",
pages = "4 - 13",
year = "2016",
note = "Special Issue of Cognitive Systems Research – Human-Human Stigmergy ",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2015.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S1389041715000327",
author = "Francis Heylighen",
keywords = "Stigmergy",
keywords = "Coordination",
keywords = "Actions",
keywords = "Agents",
keywords = "Self-organization",
keywords = "Feedback ",
abstract = "Abstract The concept of stigmergy has been used to analyze self-organizing activities in an ever-widening range of domains, including social insects, robotics, web communities and human society. Yet, it is still poorly understood and as such its full power remains underappreciated. The present paper clarifies the issue by defining stigmergy as a mechanism of indirect coordination in which the trace left by an action in a medium stimulates subsequent actions. It then analyses the fundamental concepts used in the definition: action, agent, medium, trace and coordination. It clarifies how stigmergy enables complex, coordinated activity without any need for planning, control, communication, simultaneous presence, or even mutual awareness. The resulting self-organization is driven by a combination of positive and negative feedbacks, amplifying beneficial developments while suppressing errors. Thus, stigmergy is applicable to a very broad variety of cases, from chemical reactions to bodily coordination and Internet-supported collaboration in Wikipedia. "
}
@article{Bonchis201111588,
title = "Experiments in Autonomous Earth Moving ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11588 - 11593",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.00536",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016454777",
author = "Adrian Bonchis and Nicholas Hillier and Julian Ryde and Elliot Duff and Cedric Pradalier",
keywords = "Autonomous mobile robots",
keywords = "control applications",
keywords = "software tools",
keywords = "scene segmentation ",
abstract = "Abstract This paper presents a technology demonstrator currently under development and describes experiments carried out to date in autonomous bulk material handling using mobile equipment. Our primary platform is a Bobcat \{S185\} skid-steer loader instrumented with an onboard computer, a sensor suite, and a communication link that support various levels of automation, from remote control to supervised autonomy. We present the main system components and discuss the autonomous cleaning of spillage and carryback, common bulk handling task in mining, currently executed exclusively using manually and/or remotely operated loaders. The system architecture is based on Spring, a Robotics Software Framework developed by \{CSIRO\} to support rapid development of new robotic systems, distributed as an Open Source package. "
}
@article{Chagdes20161170,
title = "Limit cycle oscillations in standing human posture ",
journal = "Journal of Biomechanics ",
volume = "49",
number = "7",
pages = "1170 - 1179",
year = "2016",
note = "",
issn = "0021-9290",
doi = "https://doi.org/10.1016/j.jbiomech.2016.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S002192901630269X",
author = "James R. Chagdes and Shirley Rietdyk and Jeffrey M. Haddad and Howard N. Zelaznik and Michael E. Cinelli and Luke T. Denomme and Kaley C. Powers and Arvind Raman",
keywords = "Balance",
keywords = "Model",
keywords = "Time-delay",
keywords = "Bifurcations",
keywords = "Limit cycle",
keywords = "Neuromuscular disease ",
abstract = "Abstract Limit cycle oscillations (LCOs) are a hallmark of dynamic instability in time-delayed and nonlinear systems such as climate change models, biological oscillators, and robotics. Here we study the links between the human neuromuscular system and \{LCOs\} in standing posture. First, we demonstrate through a simple mathematical model that the observation of \{LCOs\} in posture is indicative of excessive neuromuscular time-delay. To test this hypothesis we study \{LCOs\} in the postural sway of individuals with multiple sclerosis and concussed athletes representing two different populations with chronically and acutely increased neuromuscular time-delays. Using a wavelet analysis method we demonstrate that 67% of individuals with multiple sclerosis and 44% of individuals with concussion exhibit intermittent LCOs; 8% of MS-controls, 0% of older adults, and 0% of concussion-controls displayed LCOs. Thus, \{LCOs\} are not only key to understanding postural instability but also may have important applications for the detection of neuromuscular deficiencies. "
}
@article{Nikandrova201525,
title = "Category-based task specific grasping ",
journal = "Robotics and Autonomous Systems ",
volume = "70",
number = "",
pages = "25 - 35",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015000846",
author = "Ekaterina Nikandrova and Ville Kyrki",
keywords = "Category-based grasping",
keywords = "Task-specific grasping",
keywords = "Probabilistic grasping",
keywords = "Shape uncertainty ",
abstract = "Abstract The problem of finding stable grasps has been widely studied in robotics. However, in many applications the resulting grasps should not only be stable but also applicable for a particular task. Task-specific grasps are closely linked to object categories so that objects in a same category can be often used to perform the same task. This paper presents a probabilistic approach for task-specific stable grasping of objects with shape variations inside the category. An optimal grasp is found as a grasp that is maximally likely to be task compatible and stable taking into account shape uncertainty in a probabilistic context. The method requires only partial models of new objects for grasp generation and only few models and example grasps are used during the training stage. The experiments show that the approach can use multiple models to generalize to new objects in that it outperforms grasping based on the closest model. The method is shown to generate stable grasps for new objects belonging to the same class as well as for similar in shape objects of different categories. "
}
@article{Pan2015046,
title = "Efficient Configuration Space Construction and Optimization for Motion Planning ",
journal = "Engineering ",
volume = "1",
number = "1",
pages = "046 - 057",
year = "2015",
note = "Special Section: Robotics ",
issn = "2095-8099",
doi = "https://doi.org/10.15302/J-ENG-2015009",
url = "http://www.sciencedirect.com/science/article/pii/S2095809916300443",
author = "Jia Pan and Dinesh Manocha",
keywords = "configuration space",
keywords = "motion planning",
keywords = "GPU parallel algorithm ",
abstract = "\{ABSTRACT\} The configuration space is a fundamental concept that is widely used in algorithmic robotics. Many applications in robotics, computer-aided design, and related areas can be reduced to computational problems in terms of configuration spaces. In this paper, we survey some of our recent work on solving two important challenges related to configuration spaces: how to efficiently compute an approximate representation of high-dimensional configuration spaces; and how to efficiently perform geometric proximity and motion planning queries in high-dimensional configuration spaces. We present new configuration space construction algorithms based on machine learning and geometric approximation techniques. These algorithms perform collision queries on many configuration samples. The collision query results are used to compute an approximate representation for the configuration space, which quickly converges to the exact configuration space. We also present parallel GPU-based algorithms to accelerate the performance of optimization and search computations in configuration spaces. In particular, we design efficient GPU-based parallel k-nearest neighbor and parallel collision detection algorithms and use these algorithms to accelerate motion planning. "
}
@article{Mcfadyen20161,
title = "A survey of autonomous vision-based See and Avoid for Unmanned Aircraft Systems ",
journal = "Progress in Aerospace Sciences ",
volume = "80",
number = "",
pages = "1 - 17",
year = "2016",
note = "",
issn = "0376-0421",
doi = "https://doi.org/10.1016/j.paerosci.2015.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S0376042115300208",
author = "Aaron Mcfadyen and Luis Mejias",
keywords = "Detect and Avoid",
keywords = "See and Avoid",
keywords = "Unmanned Aircraft Systems",
keywords = "Visual control",
keywords = "Collision avoidance ",
abstract = "Abstract This paper provides a comprehensive review of the vision-based See and Avoid problem for unmanned aircraft. The unique problem environment and associated constraints are detailed, followed by an in-depth analysis of visual sensing limitations. In light of such detection and estimation constraints, relevant human, aircraft and robot collision avoidance concepts are then compared from a decision and control perspective. Remarks on system evaluation and certification are also included to provide a holistic review approach. The intention of this work is to clarify common misconceptions, realistically bound feasible design expectations and offer new research directions. It is hoped that this paper will help us to unify design efforts across the aerospace and robotics communities. "
}
@article{Chavez2017,
title = "Measurements of pCO2 and pH from an autonomous surface vehicle in a coastal upwelling system ",
journal = "Deep Sea Research Part II: Topical Studies in Oceanography ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0967-0645",
doi = "https://doi.org/10.1016/j.dsr2.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S0967064516302338",
author = "Francisco P. Chavez and Jeff Sevadjian and Chris Wahl and Jules Friederich and Gernot E. Friederich",
keywords = "Carbon dioxide",
keywords = "pH",
keywords = "Upwelling",
keywords = "Autonomous surface vehicle",
keywords = "Wave Glider",
keywords = "USA",
keywords = "California",
keywords = "Monterey Bay ",
abstract = "Abstract Anthropogenic input of carbon dioxide (CO2) into the atmosphere and its uptake by the ocean with associated changes in ocean chemistry have created an urgent need to expand coverage of sea surface and atmospheric carbon dioxide observations. Conventional sampling platforms (e.g. ships and moorings) do not provide the spatial and temporal resolution needed to assess the effects of rapidly changing carbon dioxide conditions and are expensive to operate. Through a series of deployments beginning in March 2012, two versions of the Wave Glider autonomous surface vehicles from Liquid Robotics, Inc. have been instrumented with sensors to measure pH, partial pressure of \{CO2\} (pCO2) of the atmosphere and sea surface, and wind speed and direction, from which instantaneous sea-air fluxes of \{CO2\} can be calculated. These deployments, most near Monterey Bay, California, were highly correlated with ΔpCO2 measurements obtained from the Monterey Bay Aquarium Research Institute's (MBARI) long-term mooring station M1, as well as from shipboard observations. In the central California upwelling system with highly variable pCO2 levels, the gliders captured large spatial gradients associated with upwelling fronts. Differences in sea surface pCO2 as large as 470 μatm over &lt; 0.5 km were observed. Unlike traditional ship sampling methods, however, this new generation of sampling platforms is capable of continuous long-term (months) deployments at a fraction of the cost. The vehicles thus have the potential of filling important gaps in present understanding of the effects of global change on ocean chemistry. "
}
@article{RuizSarmiento2015131,
title = "Exploiting semantic knowledge for robot object recognition ",
journal = "Knowledge-Based Systems ",
volume = "86",
number = "",
pages = "131 - 142",
year = "2015",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2015.05.032",
url = "http://www.sciencedirect.com/science/article/pii/S0950705115002191",
author = "Jose-Raul Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Semantic knowledge",
keywords = "Human elicitation",
keywords = "Object recognition",
keywords = "Probabilistic Graphical Models",
keywords = "Autonomous robots ",
abstract = "Abstract This paper presents a novel approach that exploits semantic knowledge to enhance the object recognition capability of autonomous robots. Semantic knowledge is a rich source of information, naturally gathered from humans (elicitation), which can encode both objects’ geometrical/appearance properties and contextual relations. This kind of information can be exploited in a variety of robotics skills, especially for robots performing in human environments. In this paper we propose the use of semantic knowledge to eliminate the need of collecting large datasets for the training stages required in typical recognition approaches. Concretely, semantic knowledge encoded in an ontology is used to synthetically and effortless generate an arbitrary number of training samples for tuning Probabilistic Graphical Models (PGMs). We then employ these \{PGMs\} to classify patches extracted from 3D point clouds gathered from office environments within the UMA-offices dataset, achieving a ∼90% of recognition success, and from office and home scenes within the \{NYU2\} dataset, yielding a success of ∼81% and ∼69.5% respectively. Additionally, a comparison with state-of-the-art recognition methods also based on graphical models has been carried out, revealing that our semantic-based training approach can compete with, and even outperform, those trained with a considerable number of real samples. "
}
@article{Bakambu2006103,
title = "3D \{MAP\} \{BUILDING\} \{FOR\} \{PLANETARY\} \{ROVER\} \{LOCALIZATION\} \{AND\} \{PATH\} \{PLANNING\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "39",
number = "15",
pages = "103 - 108",
year = "2006",
note = "8th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20060906-3-IT-2910.00019",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016384981",
author = "Joseph Nsasi Bakambu and Pierre Allard and Erick Dupuis",
keywords = "mobile robot",
keywords = "autonomous navigation",
keywords = "3D localization",
keywords = "path planning ",
abstract = "Abstract This paper considers the problem of constructing a 3D environment model for space robotics applications. We presented our approach to 3D environment reconstruction from large sparse range data sets. In space robotics applications an accurate and up-to-date model of the environment is very important for variety of reasons. In particular, the model can be used for safe tele-operation, path planning and mapping of points of interest. We propose an on-line reconstruction of the environment using data provided by an on-board 3D range sensor LIDAR. The experiment results demonstrated the effectiveness of our approach in localization, path planning and following scenario on the Mars Yard located at Canadian Space Agency. "
}
@article{Janjai20152356,
title = "Modeling the ratio of photosynthetically active radiation to broadband global solar radiation using ground and satellite-based data in the tropics ",
journal = "Advances in Space Research ",
volume = "56",
number = "11",
pages = "2356 - 2364",
year = "2015",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2015.09.020",
url = "http://www.sciencedirect.com/science/article/pii/S0273117715006626",
author = "S. Janjai and R. Wattan and A. Sripradit",
keywords = "Photosynthetically active radiation",
keywords = "Solar radiation",
keywords = "Ratio",
keywords = "Tropics ",
abstract = "Abstract Data from four stations in Thailand are used to model the ratio of photosynthetically active radiation (PAR) to broadband global solar radiation. The model expresses the ratio of PAR-to-broadband global solar radiation as a function of cloud index, aerosol optical depth, precipitable water, total ozone column and solar zenith angle. Data from the MTSAT-1R and OMI/AURA satellites are used to estimate the cloud index and total ozone column, respectively at each of the four stations, while aerosol optical depth and precipitable water are retrieved from Aerosol Robotic Network (AERONET) sunphotometer measurements, also available at each station. When tested against hourly measurements, the model exhibits a coefficient of variance (R2) equal to or better than 0.96, and root mean square difference (RMSD) in the range of 7.3–7.9% and mean bias difference (MBD) of −4.5% to 3.5%. The model compares favorably with other existing models. "
}
@article{Azharuddin201626,
title = "Particle swarm optimization for maximizing lifetime of wireless sensor networks ",
journal = "Computers & Electrical Engineering ",
volume = "51",
number = "",
pages = "26 - 42",
year = "2016",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0045790616300404",
author = "Md Azharuddin and Prasanta K. Jana",
keywords = "Wireless sensor networks",
keywords = "Routing",
keywords = "Unequal clustering",
keywords = "Network lifetime",
keywords = "Fault tolerance",
keywords = "Particle swarm optimization ",
abstract = "Abstract Particle swarm optimization (PSO) is a popular bio-inspired algorithm which is applied to solve various optimization problems in many areas including machine intelligence, data mining, robotics and computer networks. In this paper, we propose a PSO-based scheme to solve hot spot problem caused by multi-hop communication in a cluster-based wireless sensor network. The scheme consists of routing and clustering algorithms which are shown to be energy efficient. In the routing phase, traffic load over the cluster heads (CHs) is evenly distributed, whereas in the clustering phase, we take care of all the \{CHs\} whose energy is exhausted fast by assigning lesser number of sensor nodes. In addition to this, we also develop a distributed scheme to prevent the \{CHs\} from their quick death which is resulted from complete energy depletion. We perform extensive simulation on the proposed algorithms and compare the results with some existing algorithms to demonstrate its strength. "
}
@article{dApolito201618,
title = "Control of a cost oriented humanoid robot ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "29",
pages = "18 - 23",
year = "2016",
note = "17th \{IFAC\} Conference on International Stability, Technology and Culture \{TECIS\} 2016Durrës, Albania, 26—28 October 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.064",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316324909",
author = "F. dApolito and Xh. Mehmeti and P. Kopacek",
keywords = "Robots",
keywords = "Control",
keywords = "Identification",
keywords = "Cost Orientation ",
abstract = "Abstract: The teen-sized humanoid robot 'Archie' is developed by the Intelligent Handling and Robotics Department (IHRT) at the Technical University of Vienna. The main idea behind “Archie” is to develop a Cost Oriented Humanoid Robot (COHR) to assist humans in their daily life tasks. Currently, the robot consists of 18 degrees of freedom and is able to perform basic human-like walking motions. According to the scope of \{TECIS\} this robot is an excellent example for “Cost Orientation”. Until now the control of the joints was carried out by industrial controllers. These are expensive, heavy and have only limited possibilities for the implementation of advanced control algorithms. Therefore a new hard- and software control concept for the motors and the joints was developed. In order to find appropriate controller parameters the dynamic behavior of the joints is analyzed by means of a nonlinear system identification using a Hammerstein model. The result of the system identification shows that the dynamic behavior of the joints is \{PT1\} element with two nonlinearities, a dead zone and a nonlinear gain. Therefore a “piecewise linear” \{PI\} controller – the gain depends from the velocity – will be implemented on a \{COA\} processor. Finally an outlook on further works will be described. "
}
@article{RoviraMas2008133,
title = "Stereo vision three-dimensional terrain maps for precision agriculture ",
journal = "Computers and Electronics in Agriculture ",
volume = "60",
number = "2",
pages = "133 - 143",
year = "2008",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2007.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S016816990700172X",
author = "Francisco Rovira-Mas and Qin Zhang and John F. Reid",
keywords = "Autonomous navigation",
keywords = "Precision agriculture",
keywords = "Stereo vision",
keywords = "3D map",
keywords = "GPS",
keywords = "IMU",
keywords = "Terrain mapping ",
abstract = "The combined interest in precision agriculture, information technology, and autonomous navigation has led to a growing interest in the generation of 3D maps of mobile equipment surroundings. This article proposes a method to create 3D terrain maps by combining the information captured with a stereo camera, a localization sensor, and an inertial measurement unit, all installed on a mobile equipment platform. The perception engine comprises a compact stereo camera that captures field scenes and generates 3D point clouds, which are transformed to geodetic coordinates and assembled in a global field map. The results showed that stereo perception can provide the level of detail and accuracy needed in the construction of 3D field maps for precision agriculture and field robotics applications. "
}
@article{Galambos201568,
title = "Design, programming and orchestration of heterogeneous manufacturing systems through VR-powered remote collaboration ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "68 - 77",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000738",
author = "Peter Galambos and adam Csapo and Peter Zentay and Istvan Marcell Fulop and Tamas Haidegger and Peter Baranyi and Imre J. Rudas",
keywords = "Virtual reality/augmented reality",
keywords = "Mixed virtual and physical reality",
keywords = "Remote collaboration",
keywords = "Virtual commissioning",
keywords = "Future internet",
keywords = "Cognitive infocommunications ",
abstract = "Abstract Modern manufacturing systems are often composed of a variety of highly customized units and specifically designed manufacturing cells. Optimization of assembly and training of staff requires a series of demo installations and excessive use of costly operational resources. In some cases, components are located at different sites, making the orchestration of the whole system even more difficult. Virtual Reality (VR) collaboration environments offer a solution by enabling high fidelity testing and training of complex manufacturing systems. On the other hand, such platforms are difficult to implement in an engineering perspective, as they are required to provide reliable, standard interfaces towards both robotic components and human operators. The VirCA (Virtual Collaboration Arena) platform is a software framework that supports various means of collaboration through the use of 3D augmented/virtual reality as a communication medium. VirCA offers functions for the high-level interoperability of heterogeneous components in a wide range of domains, spanning from research &amp; development, through remote education to orchestration and management of industrial processes in manufacturing applications. This paper provides an overview of the industrial requirements behind high-fidelity virtual collaboration and demonstrates how the VirCA platform meets these requirements. Use cases are provided to illustrate the usability of the platform. "
}
@article{Araujo2014315,
title = "Desarrollo de un robot movil compacto integrado en el middleware \{ROS\} ",
journal = "Revista Iberoamericana de Automatica e Informatica Industrial \{RIAI\} ",
volume = "11",
number = "3",
pages = "315 - 326",
year = "2014",
note = "",
issn = "1697-7912",
doi = "https://doi.org/10.1016/j.riai.2014.02.009",
url = "http://www.sciencedirect.com/science/article/pii/S1697791214000338",
author = "Andre Araujo and David Portugal and Micael S. Couceiro and Jorge Sales and Rui P. Rocha",
keywords = "ROS",
keywords = "robot movil",
keywords = "sistemas embebidos",
keywords = "diseno",
keywords = "middleware",
keywords = "montaje y test.",
keywords = "ROS",
keywords = "mobile robot",
keywords = "Arduino",
keywords = "embedded system",
keywords = "design",
keywords = "assembling and testing. ",
abstract = "Abstract This paper presents the TraxBot robot and its full integration in the Robotic Operating System (ROS). The TraxBot is a compact mobile robotic platform developed and assembled at the Institute of Systems and Robots (ISR) Coimbra. The goal in this work is to drastically decrease the development time, providing hardware abstraction and intuitive operation modes, allowing researchers to focus in their main research motivations, e.g., search and rescue, multi-robot surveillance or swarm robotics. The potentialities of the TraxBot are described which, combined with the \{ROS\} driver developed, provide several tools for data analysis and easiness of interaction between multiple robots, sensors and tele-operation devices. To validate the approach, diverse experimental tests using real and virtual simulated robots were conducted. "
}
@article{Metzger201677,
title = "Space development and space science together, an historic opportunity ",
journal = "Space Policy ",
volume = "37, Part 2",
number = "",
pages = "77 - 91",
year = "2016",
note = "The use of extraterrestrial resources to facilitate space science and exploration ",
issn = "0265-9646",
doi = "https://doi.org/10.1016/j.spacepol.2016.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0265964616300625",
author = "Philip T. Metzger",
keywords = "Space resources",
keywords = "Space mining",
keywords = "Space industry",
keywords = "Space development",
keywords = "Ethics ",
abstract = "Abstract The national space programs have an historic opportunity to help solve the global-scale economic and environmental problems of Earth while becoming more effective at science through the use of space resources. Space programs will be more cost-effective when they work to establish a supply chain in space, mining and manufacturing then replicating the assets of the supply chain so it grows to larger capacity. This has become achievable because of advances in robotics and artificial intelligence. It is roughly estimated that developing a lunar outpost that relies upon and also develops the supply chain will cost about 1/3 or less of the existing annual budgets of the national space programs. It will require a sustained commitment of several decades to complete, during which time science and exploration become increasingly effective. At the end, this space industry will capable of addressing global-scale challenges including limited resources, clean energy, economic development, and preservation of the environment. Other potential solutions, including nuclear fusion and terrestrial renewable energy sources, do not address the root problem of our limited globe and there are real questions whether they will be inadequate or too late. While industry in space likewise cannot provide perfect assurance, it is uniquely able to solve the root problem, and it gives us an important chance that we should grasp. What makes this such an historic opportunity is that the space-based solution is obtainable as a side-benefit of doing space science and exploration within their existing budgets. Thinking pragmatically, it may take some time for policymakers to agree that setting up a complete supply chain is an achievable goal, so this paper describes a strategy of incremental progress. The most crucial part of this strategy is establishing a water economy by mining on the Moon and asteroids to manufacture rocket propellant. Technologies that support a water economy will play an important role leading toward space development. "
}
@article{Nanni2016142,
title = "Ensemble of different approaches for a reliable person re-identification system ",
journal = "Applied Computing and Informatics ",
volume = "12",
number = "2",
pages = "142 - 153",
year = "2016",
note = "",
issn = "2210-8327",
doi = "https://doi.org/10.1016/j.aci.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S2210832715000046",
author = "Loris Nanni and Matteo Munaro and Stefano Ghidoni and Emanuele Menegatti and Sheryl Brahnam",
keywords = "Person re-identification",
keywords = "Texture descriptors",
keywords = "Ensemble",
keywords = "Color space",
keywords = "Depth map ",
abstract = "Abstract An ensemble of approaches for reliable person re-identification is proposed in this paper. The proposed ensemble is built combining widely used person re-identification systems using different color spaces and some variants of state-of-the-art approaches that are proposed in this paper. Different descriptors are tested, and both texture and color features are extracted from the images; then the different descriptors are compared using different distance measures (e.g., the Euclidean distance, angle, and the Jeffrey distance). To improve performance, a method based on skeleton detection, extracted from the depth map, is also applied when the depth map is available. The proposed ensemble is validated on three widely used datasets (CAVIAR4REID, IAS, and VIPeR), keeping the same parameter set of each approach constant across all tests to avoid overfitting and to demonstrate that the proposed system can be considered a general-purpose person re-identification system. Our experimental results show that the proposed system offers significant improvements over baseline approaches. The source code used for the approaches tested in this paper will be available at https://www.dei.unipd.it/node/2357 and http://robotics.dei.unipd.it/reid/. "
}
@incollection{Adaniya201543,
title = "Chapter 3 - Firefly Algorithm in Telecommunications ",
editor = "Yang, Xin-She and , and Chien, Su Fong and ,  and Ting, Tiew On ",
booktitle = "Bio-Inspired Computation in Telecommunications ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2015",
pages = "43 - 72",
isbn = "978-0-12-801538-4",
doi = "https://doi.org/10.1016/B978-0-12-801538-4.00003-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128015384000033",
author = "Mario H.A.C. Adaniya and Luiz F. Carvalho and Bruno B. Zarpelao and Lucas D.H. Sampaio and Taufik Abrao and Paul Jean E. Jeszensky and Mario Lemes Proenca Jr.",
keywords = "Firefly algorithm",
keywords = "Swarm intelligence",
keywords = "Wireless network",
keywords = "Cooperative network",
keywords = "Resource allocation",
keywords = "Multicarrier systems",
keywords = "Code division multiple access system ",
abstract = "Abstract This chapter discusses the nature-inspired metaheuristic firefly algorithm (FA) applied in telecommunications. \{FA\} has been developed based on the behavior of the fireflies and the light emitted, where the brightest firefly attracts the others in his direction. Besides combining stochastic behavior and a population-based multimodal characteristic, the \{FA\} approach is able to solve optimization problems in different areas of knowledge such as engineering, robotics, combinatorial optimization, and so on. This chapter aims to show the \{FA\} performance in two distinct network optimization problems: traffic characterization and energy-efficient cooperative networks. In the first optimization problem, \{FA\} is applied as a clustering algorithm to create a network traffic pattern called Digital Signature of Network Segment using Flow analysis (DSNSF); in the second, \{FA\} has been applied to the energy-efficiency maximization problem in multicarrier direct sequence code division multiple access (MC-DS/CDMA) cooperative networks. "
}
@article{FernandezMoral2016649,
title = "Scene structure registration for localization and mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "649 - 660",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001979",
author = "Eduardo Fernandez-Moral and Patrick Rives and Vicente Arevalo and Javier Gonzalez-Jimenez",
keywords = "Scene registration",
keywords = "Scene recognition",
keywords = "Localization",
keywords = "Mapping",
keywords = "Planar segmentation ",
abstract = "Abstract Image registration, and more generally scene registration, needs to be solved in mobile robotics for a number of tasks including localization, mapping, object recognition, visual odometry and loop-closure. This paper presents a flexible strategy to register scenes based on its planar structure, which can be used with different sensors that acquire 3D data like LIDAR, time-of-flight cameras, RGB-D sensors and stereo vision. The proposed strategy is based on the segmentation of the planar surfaces from the scene, and its representation using a graph which stores the geometric relationships between neighbouring planar patches. Uncertainty information from the planar patches is exploited in a hierarchical fashion to improve both the robustness and the efficiency of registration. Quick registration is achieved in indoor structured scenarios, offering advantages like a compact representation, and flexibility to adapt to different environments and sensors. Our method is validated with different sensors: a hand-held RGB-D camera and an omnidirectional RGB-D sensor; and for different applications: from visual-range odometry to loop closure and SLAM. "
}
@article{Nad2012224,
title = "Distributed Systems in Control and Navigation of Small Underwater Vehicles ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "224 - 228",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00168",
url = "http://www.sciencedirect.com/science/article/pii/S147466701633614X",
author = "Dula Nad and Nikola Miskovic and Tomislav Lugaric and Zoran Vukic",
keywords = "Distributed systems",
keywords = "low-level control",
keywords = "MOOS",
keywords = "ROS ",
abstract = "Abstract Distributed systems are pervasive in the process industry but less so in underwater robotics. Development of open-source frameworks, targeted at mobile systems, increases applicability of distributed techniques in vehicle control. Most often supervisory control is implemented in a distributed framework while low-level control is kept in the embedded system. This approach allows sharing of sensor data, logging and increased reconfigurability of high level controllers. Meantime, the embedded system offers precise timing and reliable behaviour. Alternatively, the low-level control can be moved into the distributed framework to allow easier reconfiguration and prototyping. In this paper we describe the architecture used for low-level control and analyze its performance in the \{MOOS\} and \{ROS\} distributed frameworks. "
}
@article{Walker2011327,
title = "Computers and Composition 20/20: A Conversation Piece, or What Some Very Smart People Have to Say about the Future ",
journal = "Computers and Composition ",
volume = "28",
number = "4",
pages = "327 - 346",
year = "2011",
note = "Composition 20/20: How the Future of the Web Could Sharpen the Teaching of Writing ",
issn = "8755-4615",
doi = "https://doi.org/10.1016/j.compcom.2011.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S8755461511000703",
author = "Janice R. Walker and Kristine L. Blair and Douglas Eyman and Bill Hart-Davidson and Mike McLeod and Jeff Grabill and Fred Kemp and Mike Palmquist and James P. Purdy and Madeleine Sorapure and Christine Tulley and Victor J. Vitanza",
keywords = "Writing, teaching writing, writing assessment, publishing, robots, mobility, literacy, Web 3.0 ",
abstract = "At the 2011 Computers and Writing Conference, Town Hall speakers were asked to envision the future. This piece extends that conversation, with contributors presenting a range of ideas, often looking backward at our history before gazing into their crystal balls to envision what the future might bring. The pieces included here discuss writing, teaching writing, writing assessment, publishing, robotics, mobility, and other aspects of the field loosely termed computers and composition as it was, is, or may come to be in what we hope will be only the start of an ongoing conversation. "
}
@article{Njaastad201673,
title = "Automatic Touch-Up of Welding Paths Using 3D Vision ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "31",
pages = "73 - 78",
year = "2016",
note = "12th \{IFAC\} Workshop on Intelligent Manufacturing Systems \{IMS\} 2016Austin, Texas, USA, 5—7 December 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.12.164",
url = "http://www.sciencedirect.com/science/article/pii/S240589631632835X",
author = "Eirik B. Njaastad and Olav Egeland",
keywords = "Computer Vision",
keywords = "Flexible Manufacturing Systems",
keywords = "CAD/CAM/CAE ",
abstract = "Abstract: This paper presents a system for automatic robotic welding based on offline programming using \{CAD\} data. The welding paths are corrected before execution with 3D vision where the 3D image is aligned with the \{CAD\} model of the workpiece to be welded. The system is successfully validated in experiments, and the results are presented in the paper. "
}
@article{Ortega201027,
title = "A solution to the Path Planning problem using angle preprocessing ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "1",
pages = "27 - 36",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.07.028",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001183",
author = "Lidia M. Ortega and Antonio J. Rueda and Francisco R. Feito",
keywords = "Plane tessellation",
keywords = "Polar diagram",
keywords = "Visibility ",
abstract = "The Path Planning problem is a common topic for Robotics and Computational Geometry. Many important results have been found to this classic problem, some of them based on plane or space tessellation. The new approach we propose in this paper computes a partition of the plane called the Polar Diagram, using angle properties as criterion of construction. Compared to some other plane partitions as Voronoi Diagrams, this tessellation can be computed much more efficiently for different geometric objects. The polar diagram used as preprocessing can be applied to many geometric problems where the solution can be given by angle processing, such as Visibility or Path Planning problems. "
}
@article{Kuwahara2013289,
title = "Impacts of Space Plug-and-Play Technology on Micro- and Nano-satellites ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "19",
pages = "289 - 294",
year = "2013",
note = "19th \{IFAC\} Symposium on Automatic Control in Aerospace ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130902-5-DE-2040.00109",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015363370",
author = "T. Kuwahara and Y. Tomioka and K. Fukuda and Y. Sakamoto and K. Yoshida and J. Baeckstroem and F. Bruhn",
keywords = "Micro-satellite Earth Observation Space Plug-and-Play Scientific Missions CubeSat ",
abstract = "Abstract The Space Robotics Laboratory of Tohoku University has been investigating application method of Space Plug-and-Play technology for microsatellites together with aAC Microtec AB. The first and second micro-satellites RISING-1/-2 are carrying technology demonstration payloads for this purpose, and the functionality of the former one has been already verified in space environment. Accordingly \{SPA\} technology was applied to the real-life international scientific mission on the third micro-satellite RISESAT. Payload instruments of \{RISESAT\} were converted into \{SPA\} compatible devices. The result of application illustrated that \{SPA\} allows modular, reusable, and rapid system design approach. A CubeSat mission based on \{SPA\} technology where aAC Microtec \{AB\} is involved also successfully demonstrated correct performance in space environment. \{SPA\} technology is revealing its attractive capabilities to micro- and nano-satellites. "
}
@article{Lin2015254,
title = "Computer vision system R&amp;D for \{EAST\} Articulated Maintenance Arm robot ",
journal = "Fusion Engineering and Design ",
volume = "100",
number = "",
pages = "254 - 259",
year = "2015",
note = "",
issn = "0920-3796",
doi = "https://doi.org/10.1016/j.fusengdes.2015.06.017",
url = "http://www.sciencedirect.com/science/article/pii/S0920379615300557",
author = "Linglong Lin and Yuntao Song and Yang Yang and Hansheng Feng and Yong Cheng and Hongtao Pan",
keywords = "EAMA",
keywords = "Maintenance",
keywords = "Computer vision",
keywords = "Pick up",
keywords = "Fragment identification ",
abstract = "Abstract Experimental Advanced Superconducting Tokamak (EAST) is the first full superconducting tokamak device which was constructed at Institute of Plasma Physics Chinese Academy of Sciences (ASIPP). The \{EAST\} Articulated Maintenance Arm (EAMA) robot provides the means of the in-vessel maintenance such as inspection and picking up the fragments of first wall. This paper presents a method to identify and locate the fragments semi-automatically by using the computer vision. The use of computer vision in identification and location faces some difficult challenges such as shadows, poor contrast, low illumination level, less texture and so on. The method developed in this paper enables credible identification of objects with shadows through invariant image and edge detection. The proposed algorithms are validated through our \{ASIPP\} robotics and computer vision platform (ARVP). The results show that the method can provide a 3D pose with reference to robot base so that objects with different shapes and size can be picked up successfully. "
}
@article{Baruch1992399,
title = "Robots in astronomy ",
journal = "Vistas in Astronomy ",
volume = "35, Part 4",
number = "",
pages = "399 - 438",
year = "1992",
note = "",
issn = "0083-6656",
doi = "https://doi.org/10.1016/0083-6656(92)90002-N",
url = "http://www.sciencedirect.com/science/article/pii/008366569290002N",
author = "John E.F. Baruch",
abstract = "This paper follows the growth of robotics and automation in industry and astronomy. It discusses the different purposes for which automation is used in observational astronomy and compares the problems of robot development in industry with the experiences in astronomy. The disillusionment with robotics after the excitement and promise of the sixties is evaluated. Modern ideas of the robot as a personal assistant are developed for application in astronomy. The paper discusses how technology steers our direction of investigations in astronomy, and colours our views of the universe. It is argued that robotics in astronomy will open up whole new areas of investigation that are as likely to be as surprising and exciting as many other new avenues which astronomy has taken. It reviews the most fertile areas for robotic observing and develops an outline design. The necessary technological developments for specific types of observational investigations are detailed. Current programmes of robotic and automated telescopes are listed and the case made for international cooperation to agree formats, interfaces and standards. With standard data formats robotic telescopes can be a world resource that can be addressed by any observer, robotic or human. Standard interfaces will ensure that robotic systems can be broken down into units, particularly software units, that can be made freely available to encourage collaboration. Alternatively new software can be developed to link to standard interfaces by those who wish to improve the systems and compete. The paper concludes with a brief look at the future for robotic systems in astronomy. "
}
@article{Saeedi20141408,
title = "Map merging for multiple robots using Hough peak matching ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "10",
pages = "1408 - 1424",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001134",
author = "Sajad Saeedi and Liam Paull and Michael Trentini and Mae Seto and Howard Li",
keywords = "Simultaneous localization and mapping (SLAM)",
keywords = "Multiple robot",
keywords = "Map merging",
keywords = "Hough space and image entropy ",
abstract = "Abstract Navigation in a GPS-denied environment is an essential requirement for increased robotics autonomy. While this is in some sense solved for a single robot, the next challenge is to design algorithms for a team of robots to be able to map and navigate efficiently. The key requirement for achieving this team autonomy is to provide the robots with a collaborative ability to accurately map an environment. This problem is referred to as cooperative simultaneous localization and mapping (SLAM). In this research, the mapping process is extended to multiple robots with a novel occupancy grid map fusion algorithm. Map fusion is achieved by transforming individual maps into the Hough space where they are represented in an abstract form. Properties of the Hough transform are used to find the common regions in the maps, which are then used to calculate the unknown transformation between the maps. Results are shown from tests performed on benchmark datasets and real-world experiments with multiple robotic platforms. "
}
@article{DiCicco2015309,
title = "Non-parametric calibration for depth sensors ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "309 - 317",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001724",
author = "Maurilio Di Cicco and Luca Iocchi and Giorgio Grisetti",
keywords = "Calibration",
keywords = "Mobile robots",
keywords = "Depth camera ",
abstract = "Abstract \{RGBD\} sensors are commonly used in robotics applications for many purposes, including 3D reconstruction of the environment and mapping. In these tasks, uncalibrated sensors can generate poor quality results. In this paper we propose a quick and easy to use approach to estimate the undistortion function of \{RGBD\} sensors. Our approach does not rely on the knowledge of the sensor model, on the use of a specific calibration pattern or on external \{SLAM\} systems to track the device position. We compute an extensive representation of the undistortion function as well as its statistics and use machine learning methods for approximation of the undistortion function. We validated our approach on datasets acquired from different kinds of \{RGBD\} sensors and using a precise 3D ground truth. We also provide a procedure for evaluating the quality of the calibration using a mobile robot and a 2D laser range finder. The results clearly show the advantages in using sensor data calibrated with the method described in this paper. "
}
@article{Last201748,
title = "Global Commons in the Global Brain ",
journal = "Technological Forecasting and Social Change ",
volume = "114",
number = "",
pages = "48 - 64",
year = "2017",
note = "",
issn = "0040-1625",
doi = "https://doi.org/10.1016/j.techfore.2016.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0040162516301226",
author = "Cadell Last",
keywords = "Global Brain",
keywords = "Futures",
keywords = "Technology",
keywords = "Evolution",
keywords = "Internet",
keywords = "Commons",
keywords = "Politics ",
abstract = "Abstract The next decade (present to ~ 2020–2025) could be characterized by large-scale labour disruption and further acceleration of income and wealth inequality due to the widespread introduction of general-purpose robotics, machine-learning software/artificial intelligence (AI) and their various interconnections within the emerging infrastructure of the ‘Internet of Things’ (IoT). In this paper I argue that such technological changes and their socioeconomic consequences signal the emergence of a global metasystem (i.e. control organization beyond markets and nation-states) and may require a qualitatively new level of political organization to guide a process of self-organization. Consequently, this paper proposes and attempts to develop a conceptual framework with the potential to aid an international political transition towards a ‘post-capitalist’ ‘post-nation state’ global world. This conceptual framework is grounded within sociotechnological theory of the ‘Global Brain’ (GB), which describes a potential future planetary organizational structure founded on distributed and open-ended intelligence; and the socioeconomic theory of the ‘Commons’, which is a paradigm describing distributed modes of organization founded upon principles of democratic management and open access. In the integration of \{GB\} theory and Commons theory this paper ultimately argues that an appropriate international response to the emerging technological revolution should include the creation of networks with both automated and collaborative components that function on ‘Global Commons’ (GC) logic (i.e. beyond both state and market logic). "
}
@article{Pandey2010336,
title = "Extrinsic Calibration of a 3D Laser Scanner and an Omnidirectional Camera ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "16",
pages = "336 - 341",
year = "2010",
note = "7th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100906-3-IT-2019.00059",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016350790",
author = "Gaurav Pandey and James McBride and Silvio Savarese and Ryan Eustice",
keywords = "Sensor Calibration",
keywords = "3D Laser Scanner",
keywords = "Omnidirectional Camera ",
abstract = "Abstract We propose an approach for external calibration of a 3D laser scanner with an omnidirectional camera system. The utility of an accurate calibration is that it allows for precise co-registration between the camera imagery and the 3D point cloud. This association can be used to enhance various state of the art algorithms in computer vision and robotics. The extrinsic calibration technique used here is similar to the calibration of a 2D laser range finder and a single camera as proposed by Zhang (2004), but has been extended to the case where we have a 3D laser scanner and an omnidirectional camera system. The procedure requires a planar checkerboard pattern to be observed simultaneously from the laser scanner and the camera system from a minimum of 3 views. The normal of the planar surface and 3D points lying on the surface constrain the relative position and orientation of the laser scanner and the omnidirectional camera system. These constraints can be used to form a non-linear optimization problem that is solved for the extrinsic calibration parameters and the covariance associated with the estimated parameters. Results are presented for a real world data set collected by a vehicle mounted with a 3D laser scanner and an omnidirectional camera system. "
}
@article{Zheng2016107,
title = "A multi-frame graph matching algorithm for low-bandwidth RGB-D \{SLAM\} ",
journal = "Computer-Aided Design ",
volume = "78",
number = "",
pages = "107 - 117",
year = "2016",
note = "\{SPM\} 2016 ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2016.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S001044851630029X",
author = "Shuai Zheng and Jun Hong and Kang Zhang and Baotong Li and Xin Li",
keywords = "Multi-frame graph matching",
keywords = "Partial matching",
keywords = "Low-bandwidth SLAM",
keywords = "RGB-D reconstruction ",
abstract = "Abstract This paper presents a novel multi-frame graph matching algorithm for reliable partial alignments among point clouds. We use this algorithm to stitch frames for 3D environment reconstruction. The idea is to utilize both descriptor similarity and mutual spatial coherency of features existed in multiple frames to match these frames. The proposed multi-frame matching algorithm can extract coarse correspondence among multiple point clouds more reliably than pairwise matching algorithms, especially when the data are noisy and the overlap is relatively small. When there are insufficient consistent features that appeared in all these frames, our algorithm reduces the number of frames to match to deal with it adaptively. Hence, it is particularly suitable for cost-efficient robotic Simultaneous Localization and Mapping (SLAM). We design a prototype system integrating our matching and reconstruction algorithm on a remotely controlled navigation iRobot, equipped with a Kinect and a Raspberry Pi. Our reconstruction experiments demonstrate the effectiveness of our algorithm and design. "
}
@article{Tarokh201351,
title = "Solving inverse problems by decomposition, classification and simple modeling ",
journal = "Information Sciences ",
volume = "218",
number = "",
pages = "51 - 60",
year = "2013",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2012.07.037",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512005099",
author = "Mahmoud Tarokh",
keywords = "Inverse problems",
keywords = "Classification",
keywords = "Decomposition ",
abstract = "Inverse problems appear in many areas ranging from microwave circuits to environmental studies and to robotics, just to mention a few. In this paper we propose a new approach to solving inverse problems based on decomposition of output space into cells, with the corresponding regions in the input space. Solutions are identified using a clustering method and the relationship between data in an output cell and the corresponding input region is modeled by a simple polynomial. It is shown that the proposed method achieves very high accuracy even with relatively high number of inputs and outputs. It is also extremely fast and is suitable for real-time control, where needed. The method is applied to a highly complex inverse problem in robot kinematics and its performance is demonstrated. "
}
@article{MahdaviHezavehi2017,
title = "A systematic literature review onmethods that handle multiple quality attributes in architecture-based self-adaptive systems ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0950584917302860",
author = "Sara Mahdavi-Hezavehi and Vinicius H.S. Durelli and Danny Weyns and Paris Avgeriou",
abstract = "AbstractContext : Handling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill \{QAs\} of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the \{QAs\} of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods. Objective : In this paper we review the state-of-the-art of architecture-based methods for handling multiple \{QAs\} in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature. Method : We conducted a systematic literature review by performing an automatic search on twenty-eight selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis. Results : Performance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple \{QAs\} mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify \{QAs\} sets are \{QA\} data variables. After \{QA\} data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple \{QAs\} are \{PRISM\} and IBM's autonomic computing toolkit. \{KLAPER\} is the only language that has been specifically developed to deal with quality properties analysis. Conclusions : Our results help researchers to understand the current state of research regarding architecture-based methods for handling multiple \{QAs\} in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple \{QAs\} and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime. "
}
@article{Guenard2012939,
title = "The \{AETOURNOS\} Project: Using a Flock of \{UAVs\} as a Cyber Physical System and Platform for Application-driven Research ",
journal = "Procedia Computer Science ",
volume = "10",
number = "",
pages = "939 - 945",
year = "2012",
note = "\{ANT\} 2012 and MobiWIS 2012 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.06.127",
url = "http://www.sciencedirect.com/science/article/pii/S187705091200484X",
author = "Adrien Guenard and Laurent Ciarletta",
keywords = "Flocking",
keywords = "UAV platform",
keywords = "Cyber Physical Systems",
keywords = "Co-simulation",
keywords = "Sensor and Actuator Networks ",
abstract = "This position paper presents the Airborne Embedded auTonomOUs Robust Network of Objects and Sensors (AE-TOURNOS) platform. We have two main goals: ﬁrstly conducting research in swarming/flocking of UAVs, mixing robotics, wireless sensor and actuator networks, and secondly using this as an application domain and a challenge/demo platform for other researches. After giving an overview of the project context, questions and contributions, we give details about our ﬁrst attempt to implement an autonomous flocking behavior based on a spring-damper model in sim–ulation, combining our ﬁrst physical experiments and developments with the potential hardware. The lessons learned help us build a research and action plan for the year to come. "
}
@article{Ozog2017329,
title = "Mapping underwater ship hulls using a model-assisted bundle adjustment framework ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "329 - 347",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302219",
author = "Paul Ozog and Matthew Johnson-Roberson and Ryan M. Eustice",
keywords = "SLAM",
keywords = "AUVs",
keywords = "Underwater inspection",
keywords = "Mapping",
keywords = "Visualization ",
abstract = "Abstract This paper reports on a model-assisted bundle adjustment (BA) framework in which visually-derived features are fused with an underlying three-dimensional (3D) mesh provided a priori. By using an approach inspired by the expectation–maximization (EM) class of algorithms, we introduce a hidden binary label for each visual feature that indicates if that feature is considered part of the nominal model, or if the feature corresponds to 3D structure that is absent from the model. Therefore, in addition to improved estimates of the feature locations, we can identify visual features that correspond to foreign structure on the ship hull. We show that this framework is a special case of the Gaussian max-mixtures framework, which can be efficiently incorporated into state-of-the-art graph-based simultaneous localization and mapping (SLAM) solvers. In addition, the precision of our bundle adjustment framework allows the identification of structural deviations between 3D structure inferred from bundle-adjusted camera imagery and the prior model. These structural deviations are clustered into shapes, which allow us to fuse camera-derived structure back into the 3D mesh. This augmented model can be used within a 3D photomosaicing pipeline, providing a visually intuitive 3D reconstruction of the ship hull. We evaluate our pipeline using the Bluefin Robotics hovering autonomous underwater vehicle (HAUV) surveying the SS Curtiss, where a 3D mesh derived from computer aided design (CAD) drawings serves as the prior model. In addition to more consistent visual reconstructions, we can update the prior mesh with 3D information corresponding to underwater structure, such as biofouling or manually-placed cylindrical shapes with known dimensions. "
}
@article{Maiolino2017188,
title = "Flexible robot sealant dispensing cell using RGB-D sensor and off-line programming ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "188 - 195",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516302253",
author = "Perla Maiolino and Richard Woolley and David Branson and Panorios Benardos and Atanas Popov and Svetan Ratchev",
keywords = "AOLP",
keywords = "RGB-D sensor",
keywords = "Sealant dispensing ",
abstract = "Abstract In aerospace manufacture the accurate and robust application of sealant is an integral and challenging part of the manufacturing process that is still performed by human operator. Automation of this process is difficult and not cost effective due to the high variability in the parts to operate and also the difficulty associated with programming industrial robotic systems. This work tries to overcome these problems by presenting an \{AOLP\} (Automatic Off-Line Programming) system for sealant dispensing through the integration of the ABB's proprietary \{OLP\} (Off-Line Programming) system RobotStudio with a relatively new RBG-D sensor technology based on structured light and the development of a RobotStudio add-on. The integration of the vision system in the generation of the robot program overcomes the current problems related to \{AOLP\} systems that rely on a known model of the work environment. This enables the ability to dynamically adapt the model according to sensor data, thus coping with environmental and parts variability during operation. Furthermore it exploits the advantages of an \{OLP\} system simplifying the robot programming allowing for faster automation of the process. "
}
@incollection{Clark200171,
title = "Chapter 6 - The future of leisure time ",
editor = "Lockwood, A. and ,  and Medlik, S. ",
booktitle = "Tourism and Hospitality in the 21st Century ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "Oxford",
year = "2001",
pages = "71 - 81",
isbn = "978-0-7506-5627-6",
doi = "https://doi.org/10.1016/B978-0-7506-5627-6.50009-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780750656276500092",
author = "Colin Clark",
abstract = "Seeing the title of this chapter, some of you may remember seminars back in the 1970s that looked forward to an age of leisure for all, supported by information technology and robotics. As we all know it has not worked out like that. Here, I shall try, based on some recent work for the World Tourism Organization (WTO), to outline what is happening to leisure time, why, how it affects tourism and finally take a look at prospects for the future. "
}
@article{Faria2014794,
title = "Knowledge-based reasoning from human grasp demonstrations for robot grasp synthesis ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "794 - 817",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000347",
author = "Diego R. Faria and Pedro Trindade and Jorge Lobo and Jorge Dias",
keywords = "Robot grasp synthesis",
keywords = "Human grasp demonstrations",
keywords = "Object shape representation",
keywords = "Probabilistic inference ",
abstract = "Abstract Humans excel when dealing with everyday manipulation tasks, being able to learn new skills, and to adapt to different complex environments. This results from a lifelong learning, and also observation of other skilled humans. To obtain similar dexterity with robotic hands, cognitive capacity is needed to deal with uncertainty. By extracting relevant multi-sensor information from the environment (objects), knowledge from previous grasping tasks can be generalized to be applied within different contexts. Based on this strategy, we show in this paper that learning from human experiences is a way to accomplish our goal of robot grasp synthesis for unknown objects. In this article we address an artificial system that relies on knowledge from previous human object grasping demonstrations. A learning process is adopted to quantify probabilistic distributions and uncertainty. These distributions are combined with preliminary knowledge towards inference of proper grasps given a point cloud of an unknown object. In this article, we designed a method that comprises a twofold process: object decomposition and grasp synthesis. The decomposition of objects into primitives is used, across which similarities between past observations and new unknown objects can be made. The grasps are associated with the defined object primitives, so that feasible object regions for grasping can be determined. The hand pose relative to the object is computed for the pre-grasp and the selected grasp. We have validated our approach on a real robotic platform—a dexterous robotic hand. Results show that the segmentation of the object into primitives allows to identify the most suitable regions for grasping based on previous learning. The proposed approach provides suitable grasps, better than more time consuming analytical and geometrical approaches, contributing for autonomous grasping. "
}
@article{Seif2016159,
title = "Autonomous Driving in the iCity—HD Maps as a Key Challenge of the Automotive Industry ",
journal = "Engineering ",
volume = "2",
number = "2",
pages = "159 - 162",
year = "2016",
note = "",
issn = "2095-8099",
doi = "https://doi.org/10.1016/J.ENG.2016.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S2095809916309432",
author = "Heiko G. Seif and Xiaolong Hu",
keywords = "Autonomous driving",
keywords = "Traffic infrastructure",
keywords = "iCity",
keywords = "Car-to-X communication",
keywords = "Connected vehicle",
keywords = "HD maps ",
abstract = "\{ABSTRACT\} This article provides in-depth insights into the necessary technologies for automated driving in future cities. State of science is reflected from different perspectives such as in-car computing and data management, road side infrastructure, and cloud solutions. Especially the challenges for the application of \{HD\} maps as core technology for automated driving are depicted in this article. "
}
@article{Loukas201783,
title = "Computation offloading of a vehicle’s continuous intrusion detection workload for energy efficiency and performance ",
journal = "Simulation Modelling Practice and Theory ",
volume = "73",
number = "",
pages = "83 - 94",
year = "2017",
note = "Smart Cities and Internet of Things ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2016.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X16302234",
author = "George Loukas and Yongpil Yoon and Georgia Sakellari and Tuan Vuong and Ryan Heartfield",
keywords = "Computation offloading",
keywords = "Intrusion detection",
keywords = "Energy efficiency",
keywords = "Detection latency",
keywords = "Cyber-physical systems",
keywords = "Vehicular security ",
abstract = "Abstract Computation offloading has been used and studied extensively in relation to mobile devices. That is because their relatively limited processing power and reliance on a battery render the concept of offloading any processing/energy-hungry tasks to a remote server, cloudlet or cloud infrastructure particularly attractive. However, the mobile device’s tasks that are typically offloaded are not time-critical and tend to be one-off. We argue that the concept can be practical also for continuous tasks run on more powerful cyber-physical systems where timeliness is a priority. As case study, we use the process of real-time intrusion detection on a robotic vehicle. Typically, such detection would employ lightweight statistical learning techniques that can run onboard the vehicle without severely affecting its energy consumption. We show that by offloading this task to a remote server, we can utilse approaches of much greater complexity and detection strength based on deep learning. We show both mathematically and experimentally that this allows not only greater detection accuracy, but also significant energy savings, which improve the operational autonomy of the vehicle. In addition, the overall detection latency is reduced in most of our experiments. This can be very important for vehicles and other cyber-physical systems where cyber attacks can directly affect physical safety. In fact, in some cases, the reduction in detection latency thanks to offloading is not only beneficial but necessary. An example is when detection latency onboard the vehicle would be higher than the detection period, and as a result a detection run cannot complete before the next one is scheduled, increasingly delaying consecutive detection decisions. Offloading to a remote server is an effective and energy-efficient solution to this problem too. "
}
@article{Colomina201479,
title = "Unmanned aerial systems for photogrammetry and remote sensing: A review ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "92",
number = "",
pages = "79 - 97",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.02.013",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614000501",
author = "I. Colomina and P. Molina",
keywords = "UAV",
keywords = "Review",
keywords = "Photogrammetry",
keywords = "Remote sensing ",
abstract = "Abstract We discuss the evolution and state-of-the-art of the use of Unmanned Aerial Systems (UAS) in the field of Photogrammetry and Remote Sensing (PaRS). UAS, Remotely-Piloted Aerial Systems, Unmanned Aerial Vehicles or simply, drones are a hot topic comprising a diverse array of aspects including technology, privacy rights, safety and regulations, and even war and peace. Modern photogrammetry and remote sensing identified the potential of UAS-sourced imagery more than thirty years ago. In the last five years, these two sister disciplines have developed technology and methods that challenge the current aeronautical regulatory framework and their own traditional acquisition and processing methods. Navety and ingenuity have combined off-the-shelf, low-cost equipment with sophisticated computer vision, robotics and geomatic engineering. The results are cm-level resolution and accuracy products that can be generated even with cameras costing a few-hundred euros. In this review article, following a brief historic background and regulatory status analysis, we review the recent unmanned aircraft, sensing, navigation, orientation and general data processing developments for \{UAS\} photogrammetry and remote sensing with emphasis on the nano-micro-mini \{UAS\} segment. "
}
@article{Hassan2015129,
title = "Coefficients of an analytical aerosol forcing equation determined with a Monte-Carlo radiation model ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "164",
number = "",
pages = "129 - 136",
year = "2015",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2015.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315002009",
author = "Taufiq Hassan and H. Moosmuller and Chul E. Chung",
keywords = "Aerosol forcing",
keywords = "Radiation model",
keywords = "MACR model",
keywords = "Monte-Carlo",
keywords = "Analytical equation ",
abstract = "Abstract Simple analytical equations for global-average direct aerosol radiative forcing are useful to quickly estimate aerosol forcing changes as function of key atmosphere, surface and aerosol parameters. The surface and atmosphere parameters in these analytical equations are the globally uniform atmospheric transmittance and surface albedo, and have so far been estimated from simplified observations under untested assumptions. In the present study, we take the state-of-the-art analytical equation and write the aerosol forcing as a linear function of the single scattering albedo (SSA) and replace the average upscatter fraction with the asymmetry parameter (ASY). Then we determine the surface and atmosphere parameter values of this equation using the output from the global \{MACR\} (Monte-Carlo Aerosol Cloud Radiation) model, as well as testing the validity of the equation. The \{MACR\} model incorporated spatio-temporally varying observations for surface albedo, cloud optical depth, water vapor, stratosphere column ozone, etc., instead of assuming as in the analytical equation that the atmosphere and surface parameters are globally uniform, and should thus be viewed as providing realistic radiation simulations. The modified analytical equation needs globally uniform aerosol parameters that consist of \{AOD\} (Aerosol Optical Depth), SSA, and ASY. The \{MACR\} model is run here with the same globally uniform aerosol parameters. The \{MACR\} model is also run without cloud to test the cloud effect. In both cloudy and cloud-free runs, the equation fits in the model output well whether \{SSA\} or \{ASY\} varies. This means the equation is an excellent approximation for the atmospheric radiation. On the other hand, the determined parameter values are somewhat realistic for the cloud-free runs but unrealistic for the cloudy runs. The global atmospheric transmittance, one of the determined parameters, is found to be around 0.74 in case of the cloud-free conditions and around 1.03 with cloud. The surface albedo, another determined parameter, is found to be around 0.18 and 0.28 in case of cloud-free and cloudy-sky conditions respectively. Because the cloudy-sky runs yield unrealistic parameter values, we conclude that the equation is more adequate for cloud-free conditions. "
}
@article{Lourenco2017210,
title = "Uncertainty characterization of the orthogonal Procrustes problem with arbitrary covariance matrices ",
journal = "Pattern Recognition ",
volume = "61",
number = "",
pages = "210 - 220",
year = "2017",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.07.037",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316301960",
author = "Pedro Lourenco and Bruno J. Guerreiro and Pedro Batista and Paulo Oliveira and Carlos Silvestre",
keywords = "Weighted Procrustes statistics",
keywords = "Perturbation theory",
keywords = "Uncertainty characterization",
keywords = "Map transformation ",
abstract = "Abstract This paper addresses the weighted orthogonal Procrustes problem of matching stochastically perturbed point clouds, formulated as an optimization problem with a closed-form solution. A novel uncertainty characterization of the solution of this problem is proposed resorting to perturbation theory concepts, which admits arbitrary transformations between point clouds and individual covariance and cross-covariance matrices for the points of each cloud. The method is thoroughly validated through extensive Monte Carlo simulations, and particularly interesting cases where nonlinearities may arise are further analyzed. "
}
@article{Magalhaes201342,
title = "Autonomous Vehicle Navigation in Semi-Structured Urban Environment ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "42 - 47",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00051",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349077",
author = "Andre Chaves Magalhaes and Marcos Prado and Valdir Grassi Jr and Denis Fernando Wolf",
keywords = "autonomous vehicle",
keywords = "lattice planner",
keywords = "autonomous navigation ",
abstract = "Abstract Recent advances in mobile robotic research have contributed to the development of autonomous driving systems for intelligent robotic vehicles. The motion planner is the component of the intelligent system responsible for planning a path that leads the vehicle from its current state to the desired goal state avoiding obstacles in the environment. This paper describes the use of a motion planning method based on lattice state space and anytime dynamic A* applied to our autonomous vehicle for navigation in a semi-structured urban environment. We created a 3D simulation model of our vehicle, implemented the motion planner approach described here and conducted experiments in both simulated and real parking lots. "
}
@article{Mazitov2016305,
title = "Using Bee Algorithm in the Problem of Mapping ",
journal = "Procedia Engineering ",
volume = "149",
number = "",
pages = "305 - 312",
year = "2016",
note = "International Conference on Manufacturing Engineering and Materials, \{ICMEM\} 2016, 6-10 June 2016, Novy Smokovec, Slovakia ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.06.671",
url = "http://www.sciencedirect.com/science/article/pii/S187770581631181X",
author = "Timur Mazitov and Pavol Božek and Andrey Abramov and Yuri Nikitin and Ivan Abramov",
keywords = "SLAM",
keywords = "ICP",
keywords = "swarm algoritms",
keywords = "bee algorithm",
keywords = "location",
keywords = "mapping. ",
abstract = "Abstract Innovative algorithm for solving simultaneous location and mapping problem in unknown environment is considered. The algorithm is based on the comparison of point clouds with bee swarm algorithm. The algorithm obtained was experimentally tested. The algorithm increases the number of calculations in several times as compared to standard methods of minimization (algorithm of gradient descent and others), but the function calculations in random points are similar operations and it enables the efficient application of parallel computations, thus resulting in increased performance. "
}
@article{Vuolo2017202,
title = "Smoothing and gap-filling of high resolution multi-spectral time series: Example of Landsat data ",
journal = "International Journal of Applied Earth Observation and Geoinformation ",
volume = "57",
number = "",
pages = "202 - 213",
year = "2017",
note = "",
issn = "0303-2434",
doi = "https://doi.org/10.1016/j.jag.2016.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S0303243416302100",
author = "Francesco Vuolo and Wai-Tim Ng and Clement Atzberger",
keywords = "Time series",
keywords = "Gap-filling",
keywords = "Filtering ",
abstract = "Abstract This paper introduces a novel methodology for generating 15-day, smoothed and gap-filled time series of high spatial resolution data. The approach is based on templates from high quality observations to fill data gaps that are subsequently filtered. We tested our method for one large contiguous area (Bavaria, Germany) and for nine smaller test sites in different ecoregions of Europe using Landsat data. Overall, our results match the validation dataset to a high degree of accuracy with a mean absolute error (MAE) of 0.01 for visible bands, 0.03 for near-infrared and 0.02 for short-wave-infrared. Occasionally, the reconstructed time series are affected by artefacts due to undetected clouds. Less frequently, larger uncertainties occur as a result of extended periods of missing data. Reliable cloud masks are highly warranted for making full use of time series. "
}
@article{Gao2017,
title = "Are you a human or a humanoid: Predictive user modelling through behavioural analysis of online gameplay data ",
journal = "Advanced Engineering Informatics ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2017.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S1474034616301744",
author = "Chen Gao and Kaiqi Jin and Haifeng Shen and Muhammed Ali Babar",
keywords = "Intelligent agent",
keywords = "Human modelling",
keywords = "MOG",
keywords = "Latency",
keywords = "Jitter",
keywords = "QoE",
keywords = "Humanoid bot",
keywords = "Behavioural analysis",
keywords = "Gameplay data",
keywords = "Predictive user modelling",
keywords = "Regression analysis",
keywords = "Bayesian network ",
abstract = "Abstract Intelligent agents are widely used in robotics, gaming and simulation. A key issue is modelling human behaviours so that intelligent agents can use a human’s behavioural model to imitate them and predict their next moves. In this article, we use Internet-based multiplayer online gaming (MOG) as a case study to present our approach to predictive user modelling through behavioural analysis of online gameplay data. As latency is an inherited bottleneck of the Internet and is likely to remain so into a foreseeable future, a lot of efforts have been made to address the resulting issues. Most of the existing latency handling techniques are based on the assumption that latency is within an acceptable threshold so that they can alleviate or even completely hide its negative impact on players’ quality of experience (QoE) that directly determines consumers’ satisfaction of the provided \{MOG\} services. While this assumption is mostly valid, it is worth noting that a player’s Internet connection latency always fluctuates (known as jitter), possibly to the extent of exceeding a MOG’s designated threshold in which case none of the techniques can handle properly but disconnecting the player from the gameplay session. Forcing a player to quit prematurely simply due to a spike of unusual high latency has a significant negative impact both on the gameplay’s fairness and on the player’s QoE. To improve customer satisfaction of a \{MOG\} service, we propose a more tolerant approach by temporarily substituting a player with a humanoid bot in the event of latency hikes so that the player always remains in the gameplay session. The challenge in this approach is to create a personalised humanoid bot that can imitate the playing pattern of the individual human player being substituted. Our solution is to first extract key variables that have impact on the human player’s decision-makings through behavioural analysis of the player’s historical gameplay data, then model the relationships among these variables, and finally creates the player’s humanoid bot with the model. In this paper, we use a multiplayer online pong game as a case study to explain behavioural variables, modelling techniques, processes, outcomes, and performance studies. "
}
@article{Bibi2017126,
title = "Characterization of absorbing aerosol types using ground and satellites based observations over an urban environment ",
journal = "Atmospheric Environment ",
volume = "150",
number = "",
pages = "126 - 135",
year = "2017",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.11.052",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016309438",
author = "Samina Bibi and Khan Alam and Farrukh Chishtie and Humera Bibi",
keywords = "FMF",
keywords = "AE",
keywords = "AI",
keywords = "AAE",
keywords = "SSA",
keywords = "Absorbing aerosol ",
abstract = "Abstract In this paper, for the first time, an effort has been made to seasonally characterize the absorbing aerosols into different types using ground and satellite based observations. For this purpose, optical properties of aerosol retrieved from \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) and Ozone Monitoring Instrument (OMI) were utilized over Karachi for the period 2012 to 2014. Firstly, \{OMI\} \{AODabs\} was validated with \{AERONET\} \{AODabs\} and found to have a high degree of correlation. Then, based on this validation, characterization was conducted by analyzing aerosol Fine Mode Fraction (FMF), Angstrom Exponent (AE), Absorption Angstrom Exponent (AAE), Single Scattering Albedo (SSA) and Aerosol Index (AI) and their mutual correlation, to identify the absorbing aerosol types and also to examine the variability in seasonal distribution. The absorbing aerosols were characterized into Mostly Black Carbon (BC), Mostly Dust and Mixed \{BC\} &amp; Dust. The results revealed that Mostly \{BC\} aerosols contributed dominantly during winter and postmonsoon whereas, Mostly Dust were dominant during summer and premonsoon. These types of absorbing aerosol were also confirmed with \{MODerate\} resolution Imaging Spectroradiometer (MODIS) and Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) observations. "
}
@article{Lu201683,
title = "Where am I in the dark: Exploring active transfer learning on the use of indoor localization based on thermal imaging ",
journal = "Neurocomputing ",
volume = "173, Part 1",
number = "",
pages = "83 - 92",
year = "2016",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.07.106",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215011261",
author = "Guoyu Lu and Yan Yan and Li Ren and Philip Saponaro and Nicu Sebe and Chandra Kambhamettu",
keywords = "Image-based localization",
keywords = "Active transfer learning",
keywords = "Thermal imaging ",
abstract = "Abstract Indoor localization is one of the key problems in robotics research. Most current localization systems use cellular base stations and Wifi signals, whose localization accuracy is largely dependent on the signal strength and is sensitive to environmental changes. With the development of camera-based technologies, image-based localization may be employed in an indoor environment where the \{GPS\} signal is weak. Most of the existing image-based localization systems are based on color images captured by cameras, but this is only feasible in environments with adequate lighting conditions. In this paper, we introduce an image-based localization system based on thermal imaging to make the system independent of light sources, which are especially useful during emergencies such as a sudden power outage in a building. As thermal images are not obtained as easily as color images, we apply active transfer learning to enrich the thermal image classification learning, where normal \{RGB\} images are treated as the source domain, and thermal images are the target domain. The application of active transfer learning avoids random target training sample selection and chooses the most informative samples in the learning process. Through the proposed active transfer learning, the query thermal images can be accurately used to indicate the location. Experiments show that our system can be efficiently deployed to perform indoor localization in a dark environment. "
}
@article{Hyyti2013248,
title = "Feature Based Modeling and Mapping of Tree Trunks and Natural Terrain Using 3D Laser Scanner Measurement System ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "248 - 255",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00065",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349405",
author = "Heikki Hyyti and Arto Visala",
abstract = "Abstract This paper presents a novel approach to measure tree trunks and to model the ground using a 3D laser scanner. The 3D scanner, self-build using two 2D Sick scanners on a rotating base, measures each scan line approximately at 45° angle towards the ground and the trees. Single scan lines are segmented to find ground and tree returns. 3D point clouds from the surrounding forest are recorded while the measuring vehicle is moving. Sequential scan lines are joined together as the pose changes are reduced from the older buffered measurements. Laser odometry and inertial measurements are used to measure the pose changes. The ground is modeled by fitting a 1m grid to 3D point cloud extracted using a ground return detector. Tree trunks are searched from the 3D point cloud using a histogram approach to segment measurements into separate point clouds for each tree trunk. Tree trunks are modeled using ten circle features one on the other using the extracted point cloud. Instead of using the whole point cloud, mapping is done only for the extracted features and the travelled path to save computation time. Our method can detect nearly all tree trunks and measure them on short ranges of less than 8m with errors less than 4cm in diameter. "
}
@article{MorenoGarcia201650,
title = "Consensus of multiple correspondences between sets of elements ",
journal = "Computer Vision and Image Understanding ",
volume = "142",
number = "",
pages = "50 - 64",
year = "2016",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215001836",
author = "Carlos Francisco Moreno-Garcia and Francesc Serratosa",
keywords = "Consensus",
keywords = "Points’ correspondence",
keywords = "Feature extraction",
keywords = "Linear solver",
keywords = "Hamming distance",
keywords = "Image registration ",
abstract = "Abstract In many pattern recognition and computer vision problems, it is often necessary to compare multiple sets of elements that are completely or partially overlapping and possibly corrupted by noise. Finding a correspondence between elements from the different sets is one of the crucial tasks that several computer vision, robotics or image registration methods have to cope with. The aim of this paper is to find a consensus correspondence between two sets of points, given several initial correspondences between these two sets. We present three different methods: iterative, voting and agglomerative. If the noise randomly affects the original data, we suppose that, while using the deducted correspondence, the process obtains better results than each individual correspondence. The different correspondences between two sets of points are obtained through different feature extractors or matching algorithms. Experimental validation shows the runtime and accuracy for the three methodologies. The agglomerative method obtains the highest accuracy compared to the other consensus methods and also the individual ones, while obtaining an acceptable runtime. "
}
@article{Huang2014497,
title = "Occlusion-aware multi-view reconstruction of articulated objects for manipulation ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "4",
pages = "497 - 505",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013002340",
author = "Xiaoxia Huang and Ian Walker and Stan Birchfield",
keywords = "Articulated reconstruction",
keywords = "3D reconstruction",
keywords = "Procrustes analysis",
keywords = "Locally optimized \{RANSAC\} ",
abstract = "Abstract We present an algorithm called Procrustes-Lo-RANSAC (PLR) to recover complete 3D models of articulated objects. Structure-from-motion techniques are used to capture 3D point cloud models of an object in two different configurations. Procrustes analysis, combined with a locally optimized \{RANSAC\} sampling strategy, facilitates a straightforward geometric approach to recovering the joint axes, as well as classifying them automatically as either revolute or prismatic. With the resulting articulated model, a robotic system is then able to manipulate the object along its joint axes at a specified grasp point in order to exercise its degrees of freedom. Because the models capture all sides of the object, they are occlusion-aware, meaning that the robot has knowledge of parts of the object that are not visible in the current view. Our algorithm does not require prior knowledge of the object, nor does it make any assumptions about the planarity of the object or scene. Experiments with a PUMA 500 robotic arm demonstrate the effectiveness of the approach on a variety of real-world objects containing both revolute and prismatic joints. "
}
@article{Ghoshal2014773,
title = "Robot learns from human teacher through modified kinesthetic teaching ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "1",
pages = "773 - 780",
year = "2014",
note = "3rd International Conference on Advances in Control and Optimization of Dynamical Systems (2014) ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140313-3-IN-3024.00225",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016327422",
author = "D.P. Ghoshal and N. Das and S. Dutta and L. Behera",
keywords = "robot learning",
keywords = "learning by demonstration",
keywords = "kinesthetic teaching",
keywords = "motor skill learning",
keywords = "generalizing movements ",
abstract = "Abstract Teaching new motor tasks to robots through physical interactions is an important goal for both robotics and machine learning. Most monolithic machine learning approaches fail to scale when going beyond basic skills. In this paper we present a simple framework for teaching the robot (to play tennis) through direct physical interaction with a human teacher (i.e. Kinesthetic Teaching). Current popular established method of kinesthetic teaching generally uses a two-stage approach: First, a library of motor primitives is generated through direct physical manipulation of the robot. In second stage, a reinforced learning (“reward” stage) is implemented to dynamically adjust the policy of choosing from motor primitive library. In this paper, we show that by proper modification of the first stage of Kinesthetic Teaching and incorporating the domain experience of the human teacher, we can remove the necessity of the second stage. This approach has multiple advantages: (i) We can make the whole training process much simpler. This would go a long way in making our training algorithm scalable (for much increased number of basic moves, etc). (ii) One potential problem with the “reward” learning phase is that there may be subjective difference of what is a “good” shot from the kinesthetic teaching and from the bystander viewpoint (later in “reward” stage). Even a little difference in this regard will result in a confusing feedback (“reward”), and hence it would be difficult to correctly figure out which library training samples should be reassigned what weight values. Our approach eliminates this problem altogether. "
}
@article{Summan2015189,
title = "Spatial calibration of large volume photogrammetry based metrology systems ",
journal = "Measurement ",
volume = "68",
number = "",
pages = "189 - 200",
year = "2015",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2015.02.054",
url = "http://www.sciencedirect.com/science/article/pii/S0263224115001189",
author = "R. Summan and S.G. Pierce and C.N. Macleod and G. Dobie and T. Gears and W. Lester and P. Pritchett and P. Smyth",
keywords = "Photogrammetry",
keywords = "Calibration",
keywords = "Laser tracker",
keywords = "Accuracy study ",
abstract = "Abstract Photogrammetry systems are used extensively as volumetric measurement tools in a diverse range of applications including gait analysis, robotics and computer generated animation. For precision applications the spatial inaccuracies of these systems are of interest. In this paper, an experimental characterisation of a six camera Vicon \{T160\} photogrammetry system using a high accuracy laser tracker is presented. The study was motivated by empirical observations of the accuracy of the photogrammetry system varying as a function of location within a measurement volume of approximately 100 m3. Error quantification was implemented through simultaneously tracking a target scanned through a sub-volume (27 m3) using both systems. The position of the target was measured at each point of a grid in four planes at different heights. In addition, the effect of the use of passive and active calibration artefacts upon system accuracy was investigated. A convex surface was obtained when considering error as a function of position for a fixed height setting confirming the empirical observations when using either calibration artefact. Average errors of 1.48 mm and 3.95 mm were obtained for the active and passive calibration artefacts respectively. However, it was found that through estimating and applying an unknown scale factor relating measurements, the overall accuracy could be improved with average errors reducing to 0.51 mm and 0.59 mm for the active and passive datasets respectively. The precision in the measurements was found to be less than 10 μm for each axis. "
}
@article{Buttner201693,
title = "Automatic scene parsing for generic object descriptions using shape primitives ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "93 - 112",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002584",
author = "Stefan Buttner and Zoltan-Csaba Marton and Katharina Hertkorn",
keywords = "Sample consensus",
keywords = "Shape primitives",
keywords = "3D models",
keywords = "Task specification ",
abstract = "Abstract Autonomous robots need to generate complete 3D models from a limited range of view when trying to manipulate objects for which no model is known a priori. This can be achieved by detecting symmetrical parts of an object, thus, creating an estimate of the invisible back sides. These symmetrical parts are typically modeled as primitive shapes (cylinders, spheres, cones, etc.), and fitted to noisy sensor data using sample consensus methods. This has the advantage that feasible grasps can be chosen from a precomputed set based on the estimated model, instead of a time-consuming random sampling approach. This article will look at fitting such analytic models to noisy 3D data in the context of robotic manipulation. State of the art methods from the Point Cloud Library (PCL) were extended to include additional relevant shapes (e.g. boxes), constraints (e.g. on size and orientation), and to consider additional information like knowledge about free space or proprioceptive information. A core part of the approach is the development of a scene parsing language, that allows for an easy-to-use pipeline specification during autonomous operation as well as shared-autonomy scenarios. Experiments will be presented based on scenes captured using an Xtion sensor. "
}
@incollection{Jaulin2015219,
title = "7 - Kalman Filter ",
editor = "Jaulin, Luc ",
booktitle = "Mobile Robotics ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2015",
pages = "219 - 294",
isbn = "978-1-78548-048-5",
doi = "https://doi.org/10.1016/B978-1-78548-048-5.50007-3",
url = "http://www.sciencedirect.com/science/article/pii/B9781785480485500073",
author = "Luc Jaulin",
keywords = "Confidence ellipse",
keywords = "Covariance matrices",
keywords = "Gaussian random vectors",
keywords = "Kalman filter",
keywords = "Kalman gain",
keywords = "Kalman smoother",
keywords = "Linear estimation",
keywords = "Nonlinear estimator",
keywords = "Smoothing process",
keywords = "Unbiased orthogonal estimator ",
abstract = "Abstract In Chapters 2 and 3 we have looked at tools for controlling robots in a nonlinear manner. For this purpose, we have assumed that the state vector was completely known. However, this is not the case in practice. This vector must be estimated from sensor measurements. In the case where the only unknown variables are associated with the position of the robot, Chapter 5 gives guidelines to find them. In the more general case, filtering or state observation seeks to reconstruct this state vector as well as possible from all the data measured on the robot throughout time by taking into account the state equations. The aim of this chapter is to show how such reconstruction is performed, within a stochastic context in which the system to observe is assumed to be linear. This is the purpose of the Kalman filter [KAL 60], which will be discussed in this chapter. The Kalman filter is used in numerous mobile robotics applications, even though the robots in question are strongly nonlinear. For such applications, the initial conditions are assumed to be relatively well known in order to allow a reliable linearization. "
}
@article{Takimoto2013239,
title = "3D Reconstruction Using Low Precision Scanner ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "7",
pages = "239 - 244",
year = "2013",
note = "11th \{IFAC\} Workshop on Intelligent Manufacturing Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130522-3-BR-4036.00026",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015356810",
author = "Rogerio Yugo Takimoto and Renato Vogelaar and Edson Kenji Ueda and Andre Kubagawa Sato and Thiago de Castro Martins and Toshiyuki Gotoh and Seiichiro Kagei and Marcos de Sales Guerra Tsuzuki",
keywords = "Computer Vision",
keywords = "Surface Reconstruction",
keywords = "Structured-light cameras",
keywords = "Point Registration",
keywords = "Marching cubes ",
abstract = "The objective of this work is to use low precision laser sensor and create reasonably precise 3D reconstructions. The 3D reconstruction is executed by combining several point clouds obtained from different viewpoints. The proposed method was developed with three main steps: point cloud registration, error compensation and surface reconstruction. The \{ICP\} algorithm is improved to execute the point cloud registration: dynamic distance threshold, weighted distance, rigid body restriction and color information. It is shown that using this improved ICP, the number of point correspondences to evaluate the quadratic error converges to a value. The quadratic error can be determined independently of scene complexity. The point cloud errors are compensated using the consensus surface algorithm with signed distance. The surface is reconstructed using the marching cubes algorithm. Several results are shown to demonstrate the reliability of the proposed method. "
}
@article{Fleck2009141,
title = "Graph cut based panoramic 3D modeling and ground truth comparison with a mobile platform – The Wagele ",
journal = "Image and Vision Computing ",
volume = "27",
number = "1–2",
pages = "141 - 152",
year = "2009",
note = "Canadian Robotic Vision 2005 and 2006 ",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2008.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0262885608001212",
author = "Sven Fleck and Florian Busch and Peter Biber and Wolfgang Straßer",
keywords = "Graph cut",
keywords = "3D model acquisition",
keywords = "3DTV ",
abstract = "Efficient and comfortable acquisition of large 3D scenes is an important topic for many current and future applications in the field of robotics, factory and office visualization, 3DTV and cultural heritage. In this paper we present both an omnidirectional stereo vision approach for 3D modeling based on graph cut techniques and also a new mobile 3D model acquisition platform where it is employed. The platform comprises a panoramic camera and a 2D laser range scanner for self localization by scan matching. 3D models are acquired just by moving the platform around and recording images in regular intervals. Additionally, we concurrently build 3D models using two supplementary laser range scanners. This enables the investigation of the stereo algorithm’s quality by comparing it with the laser scanner based 3D model as ground truth. This offers a more objective point of view on the achieved 3D model quality. "
}
@article{Gaftea2014336,
title = "Socio-economic Major Risks Related to the Information Technology ",
journal = "Procedia Economics and Finance ",
volume = "8",
number = "",
pages = "336 - 345",
year = "2014",
note = "1st International Conference 'Economic Scientific Research - Theoretical, Empirical and Practical Approaches', \{ESPERA\} 2013 ",
issn = "2212-5671",
doi = "https://doi.org/10.1016/S2212-5671(14)00099-9",
url = "http://www.sciencedirect.com/science/article/pii/S2212567114000999",
author = "Viorel Gaftea",
keywords = "cyber security",
keywords = "national impact",
keywords = "major risks ",
abstract = "Abstract Economy underwent a strong transformation in the last decade. Computerization, cybernetics, industrial robotics, communication and management are activities depending by IT.Society is knowledge based on \{IT\} and depending by online. Threats in the online reaches fever. Targets are critical infrastructure, telecommunications, energy, health, government and banking systems. Now there are on the pressure of cyber-attacks by multiple entities. Hackers evolve from “classic” e-mail infiltration or break websites of governmental institutions, to the cyber war as one of the newest and irregular forms of modern conflicts. The Risks are major and affect at nationally level and require preventive actions.Research is directed towards technology development, high level of computer usage and modern solutions for information management, risk control and total computerization of all activities. In social, educationalarea the man isin user position, as target or initiator ofthe own actions but sometimes author of the risk generating actions.IT these generates major risks and required standards, policies, procedures and risk protection, “instruments for systems in public and privatearea and for communicationequipment's using IT”. Todayeconomy is based on all these elements and the evaluation of major risks related to the information technology become main priority. "
}
@article{Mourtzis2014213,
title = "Simulation in Manufacturing: Review and Challenges ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "213 - 229",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.032",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010634",
author = "D. Mourtzis and M. Doukas and D. Bernidaki",
keywords = "Manufacturing",
keywords = "Simulation",
keywords = "Information and Communication Technologies ",
abstract = "Abstract Simulation comprises an indispensable set of technological tools and methods for the successful implementation of digital manufacturing, since it allows for the experimentation and validation of product, process and system design and configuration. Especially in todays’ turbulent manufacturing environment, which is affected by megatrends such as globalisation and ever-increasing requirements for higher degree of product customisation and personalisation, the value of simulation is evident. This keynote paper investigates the major milestones in the evolution of simulation technologies and examines recent industrial and research applications and findings. Based on this review, the identification of gaps in current practices is presented, and future trends and challenges to be met on the field are outlined. The considered simulation methods and tools include CAx, Factory layout design, Material and Information flow design, Manufacturing Networks Design, Manufacturing Systems Planning and Control, Manufacturing Networks Planning and Control, Augmented and Virtual Reality in product and process design, planning and verification (ergonomics, robotics, etc.). The evolution, advances, current practices and future trends of these technologies, industrial applications and research results are discussed in the context of the contemporary manufacturing industry. "
}
@article{Greenhouse20151222,
title = "Breakthrough capability for \{UVOIR\} space astronomy: Reaching the darkest sky ",
journal = "Advances in Space Research ",
volume = "55",
number = "4",
pages = "1222 - 1233",
year = "2015",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2014.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0273117714007108",
author = "Matthew A. Greenhouse and Scott W. Benson and Jacob Englander and Robert D. Falck and Dale J. Fixsen and Jonathan P. Gardner and Jeffrey W. Kruk and Steven R. Oleson and Harley A. Thronson",
keywords = "Solar electric propulsion",
keywords = "Zodiacal light",
keywords = "Space astronomy ",
abstract = "Abstract We describe how availability of new solar electric propulsion (SEP) technology can substantially increase the science capability of space astronomy missions working within the near-UV to far-infrared (UVOIR) spectrum by making dark sky orbits accessible for the first time. We present a proof of concept case study in which \{SEP\} is used to enable a 700 kg Explorer-class observatory payload to reach an orbit beyond where the zodiacal dust limits observatory sensitivity. The resulting scientific performance advantage relative to a Sun–Earth \{L2\} point orbit is presented and discussed. We find that making \{SEP\} available to astrophysics Explorers can enable this small payload program to rival the science performance of much larger long development-time systems. We also present flight dynamics analysis which illustrates that this concept can be extended beyond Explorers to substantially improve the sensitivity performance of heavier (7000 kg) flagship-class astrophysics payloads such as the \{UVOIR\} successor to the James Webb Space Telescope by using high power \{SEP\} that is being developed for the Asteroid Redirect Robotics Mission. "
}
@article{Haselich20131051,
title = "Probabilistic terrain classification in unstructured environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1051 - 1059",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001285",
author = "Marcel Haselich and Marc Arends and Nicolai Wojke and Frank Neuhaus and Dietrich Paulus",
keywords = "Markov random fields",
keywords = "Terrain classification",
keywords = "Sensor fusion ",
abstract = "Autonomous navigation in unstructured environments is a complex task and an active area of research in mobile robotics. Unlike urban areas with lanes, road signs, and maps, the environment around our robot is unknown and unstructured. Such an environment requires careful examination as it is random, continuous, and the number of perceptions and possible actions are infinite. We describe a terrain classification approach for our autonomous robot based on Markov Random Fields (MRFs ) on fused 3D laser and camera image data. Our primary data structure is a 2D grid whose cells carry information extracted from sensor readings. All cells within the grid are classified and their surface is analyzed in regard to negotiability for wheeled robots. Knowledge of our robot’s egomotion allows fusion of previous classification results with current sensor data in order to fill data gaps and regions outside the visibility of the sensors. We estimate egomotion by integrating information of an IMU, \{GPS\} measurements, and wheel odometry in an extended Kalman filter. In our experiments we achieve a recall ratio of about 90% for detecting streets and obstacles. We show that our approach is fast enough to be used on autonomous mobile robots in real time. "
}
@article{Correal20142043,
title = "Automatic expert system for 3D terrain reconstruction based on stereo vision and histogram matching ",
journal = "Expert Systems with Applications ",
volume = "41",
number = "4, Part 2",
pages = "2043 - 2051",
year = "2014",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2013.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0957417413007227",
author = "R. Correal and G. Pajares and J.J. Ruz",
keywords = "Expert system",
keywords = "Terrain reconstruction",
keywords = "Histogram matching",
keywords = "Stereo vision",
keywords = "Image processing ",
abstract = "Abstract This paper proposes an automatic expert system for 3D terrain reconstruction and automatic intensity correction in stereo pairs of images based on histogram matching. Different applications in robotics, particularly those based on autonomous navigation in rough and natural environments, require a high-quality reconstruction of the surface. The stereo vision system is designed with a defined geometry and installed onboard a mobile robot, together with other sensors such as an Inertial Measurement Unit (IMU), necessary for sensor fusion. It is generally assumed the intensities of corresponding points in two images of a stereo pair are equal. However, this assumption is often false, even though they are acquired from a vision system composed of two identical cameras. We have also found this issue in our dataset. Because of the above undesired effects the stereo matching process is significantly affected, as many correspondence algorithms are very sensitive to these deviations in the brightness pattern, resulting in an inaccurate terrain reconstruction. The proposed expert system exploits the human knowledge which is mapped into three modules based on image processing techniques. The first one is intended for correcting intensities of the stereo pair coordinately, adjusting one as a function of the other. The second one is based in computing disparity, obtaining a set of correspondences. The last one computes a reconstruction of the terrain by reprojecting the computed points to 2D and applying a series of geometrical transformations. The performance of this method is verified favorably. "
}
@article{Posner2008901,
title = "Online generation of scene descriptions in urban environments ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "11",
pages = "901 - 914",
year = "2008",
note = "Semantic Knowledge in Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001139",
author = "Ingmar Posner and Derik Schroeter and Paul Newman",
keywords = "Semantic robot maps",
keywords = "Outdoor mapping",
keywords = "Support vector machine ",
abstract = "The ability to extract a rich set of semantic workspace labels from sensor data gathered in complex environments is a fundamental prerequisite to any form of semantic reasoning in mobile robotics. In this paper, we present an online system for the augmentation of maps of outdoor urban environments with such higher-order, semantic labels. The system employs a shallow supervised classification hierarchy to classify scene attributes, consisting of a mixture of 2D/3D geometric and visual scene information, into a range of different workspace classes. The union of classifier responses yields a rich, composite description of the local workspace. We present extensive experimental results, using two large urban data sets collected by our research platform. "
}
@article{Marks201122,
title = "Clearing the heavens, one piece at a time ",
journal = "New Scientist ",
volume = "209",
number = "2799",
pages = "22 - 23",
year = "2011",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(11)60318-7",
url = "http://www.sciencedirect.com/science/article/pii/S0262407911603187",
author = "Paul Marks",
abstract = "As the cloud of space junk shrouding the Earth grows ever denser, the most sophisticated garbage collectors of all time are taking shape "
}
@article{Bibi2016106,
title = "In-depth discrimination of aerosol types using multiple clustering techniques over four locations in Indo-Gangetic plains ",
journal = "Atmospheric Research ",
volume = "181",
number = "",
pages = "106 - 114",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.06.017",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516301703",
author = "Humera Bibi and Khan Alam and Samina Bibi",
keywords = "Aerosol Optical Depth",
keywords = "Angstrom Exponent",
keywords = "Single Scattering Albedo",
keywords = "Refractive Index",
keywords = "Dust",
keywords = "Biomass burning",
keywords = "Urban industrial ",
abstract = "Abstract Discrimination of aerosol types is essential over the Indo-Gangetic plain (IGP) because several aerosol types originate from different sources having different atmospheric impacts. In this paper, we analyzed a seasonal discrimination of aerosol types by multiple clustering techniques using \{AERosol\} \{RObotic\} \{NETwork\} (AERONET) datasets for the period 2007–2013 over Karachi, Lahore, Jaipur and Kanpur. We discriminated the aerosols into three major types; dust, biomass burning and urban/industrial. The discrimination was carried out by analyzing different aerosol optical properties such as Aerosol Optical Depth (AOD), Angstrom Exponent (AE), Extinction Angstrom Exponent (EAE), Abortion Angstrom Exponent (AAE), Single Scattering Albedo (SSA) and Real Refractive Index (RRI) and their interrelationship to investigate the dominant aerosol types and to examine the variation in their seasonal distribution. The results revealed that during summer and pre-monsoon, dust aerosols were dominant while during winter and post-monsoon prevailing aerosols were biomass burning and urban industrial, and the mixed type of aerosols were present in all seasons. These types of aerosol discriminated from \{AERONET\} were in good agreement with \{CALIPSO\} (the Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation) measurement. "
}
@article{Louchet2002335,
title = "Dynamic flies: a new pattern recognition tool applied to stereo sequence processing ",
journal = "Pattern Recognition Letters ",
volume = "23",
number = "1–3",
pages = "335 - 345",
year = "2002",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/S0167-8655(01)00129-5",
url = "http://www.sciencedirect.com/science/article/pii/S0167865501001295",
author = "Jean Louchet and Maud Guyon and Marie-Jeanne Lesot and Amine Boumaza",
keywords = "Artificial evolution",
keywords = "Pattern recognition",
keywords = "Computer vision",
keywords = "Image processing",
keywords = "Parameter space exploration ",
abstract = "The “fly algorithm” is a fast artificial evolution-based technique devised for the exploration of parameter space in pattern recognition applications. In the application described, we evolve a population which constitutes a particle-based three-dimensional representation of the scene. Each individual represents a three-dimensional point in the scene and may be fitted with optional velocity parameters. Evolution is controlled by a fitness function which contains all pixel-level calculations, and uses classical evolutionary operators (sharing, mutation, crossover). The combined individual approach and low complexity fitness function allow fast processing. Test results and an application to mobile robotics are presented. "
}
@article{Knight20041463,
title = "Robot-enhanced fetoscopic surgery ",
journal = "Journal of Pediatric Surgery ",
volume = "39",
number = "10",
pages = "1463 - 1465",
year = "2004",
note = "",
issn = "0022-3468",
doi = "https://doi.org/10.1016/j.jpedsurg.2004.06.012",
url = "http://www.sciencedirect.com/science/article/pii/S0022346804004051",
author = "Colin G. Knight and Attila Lorincz and Anthony Johnson and Kelly Gidell and Rajah Rabah and Michael D. Klein and Scott E. Langenburg",
keywords = "Fetal surgery",
keywords = "robot",
keywords = "fetoscopy",
keywords = "fetendo",
keywords = "Zeus ",
abstract = "Background Fetoscopic surgery carries with it less maternal morbidity than open fetal surgery. Robotic surgery facilitates endoscopic surgery through tremor filtration, motion scaling, indexed movement, articulation, and improved ergonomics. The goal of the authors was to explore using a robotic surgery platform in a fetal animal model. Methods Using the Zeus Robotic Surgery System (Computer Motion, Santa Barbara, CA), fetoscopic surgery in pregnant sheep was performed using a variety of techniques: uterus exteriorized or totally percutaneous and with liquid or gas insufflation. Using the percutaneous technique and gas insufflation, the authors created and sutured fetal skin and fascial defects. The ewes were recovered and killed 2 weeks postoperatively, and autopsies were performed on them and their fetuses. Results In the exteriorized uterus model, instrument movement was unpredictable and fluid leaked. In the fluid environment, clouding of the visual field and difficulty in immobilizing the fetus were major difficulties. In the survival model, 4 of the 6 fetuses survived to autopsy at 2 weeks and showed good healing grossly and histologically. Conclusions The Zeus Robotic Surgery System can be used for fetoscopic surgery in a sheep model. The percutaneous approach with a nitrous oxide environment is the most effective. Advantages of robotic surgery may be applicable in fetoscopic surgery, but further work in a primate model is required. "
}
@article{Moura201767,
title = "Formulation of a Control and Path Planning Approach for a Cab front Cleaning Robot ",
journal = "Procedia \{CIRP\} ",
volume = "59",
number = "",
pages = "67 - 71",
year = "2017",
note = "Proceedings of the 5th International Conference in Through-life Engineering Services Cranfield University, 1st and 2nd November 2016 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309581",
author = "Joao Moura and Mustafa Suphi Erden",
keywords = "Cleaning robot",
keywords = "simultaneous force and position control",
keywords = "operational space formulation. ",
abstract = "Abstract This paper formulates a control and path planning approach for a Cab Front Cleaning Robot. Currently, the operation of cleaning the front part of a train cab is performed manually under challenging conditions. The aim of this work is to formulate a control and path planning solution for the employment of a robot manipulator for such cleaning activity. The proposed solution comprises the study of the interaction between the robotic manipulator and an unknown surface, and consists in using an Operational Space Formulation implementation of simultaneous force and position control. The end-effector trajectory results from projecting a raster scan onto the surface to be cleaned, in real-time, with path adaptation to local surface geometry nuances. This paper also presents a list of criteria to validate future results. "
}
@article{Sommer201648,
title = "Multi-contact haptic exploration and grasping with tactile sensors ",
journal = "Robotics and Autonomous Systems ",
volume = "85",
number = "",
pages = "48 - 61",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016301610",
author = "Nicolas Sommer and Aude Billard",
keywords = "Tactile sensing",
keywords = "Haptic exploration",
keywords = "Multiple contacts",
keywords = "Compliant grasping ",
abstract = "Abstract Haptic exploration has received a great deal of attention of late thanks to the variety of commercially available tactile sensors. While the majority of previous works consider control of a single contact point at a time, we tackle simultaneous control of multiple contact points on several links. In addition, we use information from the existing tactile signals to increase the number of points in contact. We demonstrate the usefulness of this form of control to speed up exploration, scanning and to compliantly grasp unknown objects. Our controller requires to know only the parts of the robot on which it is desirable to make contact and does not need a model of the environment besides the robot itself. We validate the algorithm in a set of experiments using a robotic hand covered with tactile sensors and arm. In a grasping application, the active adaptation of the fingers to the shape of the object ensures that the hand encloses the object with multiple contact points. We show that this improves the robustness of the grasp compared to simple enclosing strategies. When combined with an exploration strategy, our multi-contact approach offers an efficient use of tactile sensors on the whole surface of robotic fingers, and enables the robot to perform a rapid exploration of complex, non convex shapes while maintaining low contact forces. It is robust to variation in the approach angle and to changes in the geometry and orientation of the object. "
}
@article{Tang2017106,
title = "A revisit to decadal change of aerosol optical depth and its impact on global radiation over China ",
journal = "Atmospheric Environment ",
volume = "150",
number = "",
pages = "106 - 115",
year = "2017",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.11.043",
url = "http://www.sciencedirect.com/science/article/pii/S135223101630927X",
author = "Wenjun Tang and Kun Yang and Jun Qin and Xiaolei Niu and Changgui Lin and Xianwen Jing",
keywords = "Global radiation",
keywords = "Aerosol optical depth",
keywords = "Clear-sky",
keywords = "Visibility ",
abstract = "Abstract Global radiation over China decreased between the 1960s and 1990, since when it has remained stable. As the total cloud cover has continued to decrease since the 1960s, variations in aerosols were suggested in previous studies to be the primary cause for variations in global radiation over China. However, the effect of aerosols on global radiation on a decadal scale has not been physically quantified over China. In this study, aerosol optical depth (AOD) data since 1980 are estimated by combining horizontal visibility data at stations in China and \{AOD\} observed by the moderate resolution imaging spectroradiometer (MODIS). It is found that the \{AOD\} exhibits decadal changes, with two decreasing periods (before the end of 1980s and after 2006) and one increasing period (from 1990 to 2006). With the derived AOD, a clear-sky model is then applied to quantify the role of aerosols in the variations in global radiation over China. The results show that aerosol direct effect cannot fully explain the decadal variations in the global radiation over China between 1980 and 2010, though it has a considerable effect on global radiation climatology. There are significant differences between the trends of clear-sky global radiation impacted by aerosols and those of all-sky global radiation impacted by aerosols and clouds, and the correlation coefficient for the comparison is very low. Therefore, the variations in all-sky global radiation over China are likely to be due to changes in cloud properties and to interactions between clouds and aerosols. "
}
@article{Bayat2010503,
title = "\{SLAM\} for an \{AUV\} using vision and an acoustic beacon ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "16",
pages = "503 - 508",
year = "2010",
note = "7th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100906-3-IT-2019.00087",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016351072",
author = "M. Bayat and A. Pedro Aguiar",
keywords = "Underwater Vision",
keywords = "IMU",
keywords = "Extended Kalman Filter",
keywords = "Multiple Model Adaptive Estimator",
keywords = "Simultaneous Localization And Mapping",
keywords = "Pose Estimation ",
abstract = "Abstract The estimation of the position and attitude of an autonomous underwater vehicle (AUV) is a challenging and important problem in marine robotics. It is well known that the underwater environment posses considerable problems, that include i) the fact that there is no \{GPS\} signal, ii) the communication is usually done through acoustic signals, which suffers from faults, delays and low bandwidth, and iii) the use of vision and/or laser is very limited due to poor visibility. In this paper, we combine a multiple set of sensors to address the full state 6DOF pose estimation of an AUV. The problem is formulated assuming that we have partial measurements from an Inertial Measurement Unit (IMU), an acoustic ranging from a single beacon buoy, and a monocular camera attached to the AUV. Using multiple model estimation techniques and the concept of Extended Kalman Filters with Simultaneous Localization and Mapping (EKF-SLAM), we propose an algorithm that integrates the \{AUV\} measurements (that arrive at different sampling-times) and compute in real time an estimate of the position and attitude of the AUV. Simulation results are presented and discussed. "
}
@article{Zhang20161456,
title = "BIM-enabled Modular and Industrialized Construction in China ",
journal = "Procedia Engineering ",
volume = "145",
number = "",
pages = "1456 - 1461",
year = "2016",
note = "\{ICSDEC\} 2016 – Integrating Data Science, Construction and Sustainability ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.04.183",
url = "http://www.sciencedirect.com/science/article/pii/S1877705816301904",
author = "Jinyue Zhang and Yating Long and Siquan Lv and Yunchao Xiang",
keywords = "Modular Construction",
keywords = "Industrialization of Construction",
keywords = "BIM",
keywords = "China ",
abstract = "Abstract Old-fashioned construction methods in China lead to many issues such as low field productivity, unreliable quality, high resource and energy consumption, frequent safety accidents, and significant environmental pollution. The concept of industrialization of construction has been recognized since the 1950's, but was not well developed until recently when the industry came under the pressure of increasing labour costs and the demand for sustainable development. There was a surge of Building Information Modeling (BIM) application in the last few years in China, and the industry has seen the many benefits of virtual design and construction. Integrating \{BIM\} technology into the industrialization of construction is seen as a promising opportunity to improve the performance of modular and industrialized construction. This paper first reviews the history of the industrialization of the Chinese construction industry, and then discusses the recent \{BIM\} adoption in China. The main focus of this paper is using \{BIM\} to support modular design and industrialized construction and installation in China. The use of some advanced hardware tools is also discussed, including the use of 3D laser scanners to collect as-built data and establish a point cloud model for better \{MEP\} system coordination, and the use of a robotic total station for fast installation. "
}
@article{Hopia2015e1,
title = "A patient as a self-manager of their personal data on health and disease with new technology – challenges for nursing education ",
journal = "Nurse Education Today ",
volume = "35",
number = "12",
pages = "e1 - e3",
year = "2015",
note = "",
issn = "0260-6917",
doi = "https://doi.org/10.1016/j.nedt.2015.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S026069171500341X",
author = "Hanna Hopia and Mari Punna and Teemu Laitinen and Eila Latvala",
abstract = "SummaryBackground Digital technologies have transformed nearly every aspect of our lives. However, for many of us, they have not yet improved the way we receive or participate in our health services and disease care. Hostetter et al. (2014) explore in a new multimedia essay the changes occurring with the arrival of new digital tools, from mobile apps and data-driven software solutions to wearable sensors that transmit information to a patient’s team of health care providers. Digitisation will revolutionise health technology to a new extent, as the self-measurement, cloud services, teleconsultation and robotics technologies are being used to get health expenditure under control. In the future, robots will dispense drugs, and treatment routines will utilise cloud services (Biesdorf and Niedermann, 2014; Grain and Sharper, 2013). According to the rationale of the Horizon 2020 (European Commission, 2013b) work programme, personalising health and care has been stated to empower citizens and patients to manage their own health and disease, which can result in more cost-effective healthcare systems by enabling the management of chronic diseases outside institutions, improving health outcomes, and by encouraging healthy citizens to remain so. Solutions should be developed and tested with the use of open innovation platforms, such as large-scale demonstrators for health and service innovation. It is a fact that ICT/new health technology and personal health applications are transforming patients’ self-management in many ways. A huge amount of personal health application solutions are being offered in the marketplace, which engage in activities that promote health, monitoring the symptoms and signs of illness, and managing the impact of illness (European Commission eHealth Action Plan 2012-2020, 2012). The \{WHO\} (2011) has conducted a comprehensive study and published a report on Member States’ use of mHealth (mobile Health) as well as the readiness and barriers to its use. The percentage of countries reporting that they had formally evaluated mHealth initiatives was 12%. Seven per cent of developing countries reported conducting a mHealth evaluation. Mobile technologies have already changed, and they will continue to change the lives of millions around the world. In the WHO’s report, it was estimated that mHealth can revolutionise health and well-being outcomes if implemented strategically and systematically, thereby providing virtually anyone with a mobile phone with health and well-being expertise and knowledge in real-time. In the research reports (European Commission eHealth Action Plan 2012-2020, 2012; Blake, 2013), it was reported that mobile phones as a tool are cost-effective and wide reaching, while they easily target large samples and hard-to-reach groups. Studies show that eHealth as a way to self-monitor and self-manage as well as supportive interventions for clients offers a good possibility to bridge the gap between inpatient and outpatient care. The mobile phone is especially effective in enhancing the therapist-patient bond so that this does not collapse when the client leaves the therapist’s consulting room. Furthermore, eHealth applications can assist the client to cope with everyday situations in an autonomous way while improving the transfer of the abilities acquired by the client in the health care setting to everyday life. The findings of various projects (European Commission eHealth Action Plan 2012-2020, 2012; European Commission, 2012; European Commission, 2013b; Hamalainen, 2013) provide an opportunity for an open discussion regarding the digital health revolution, which will change health care processes and citizens’ applications for health promotion and self-care. "
}
@article{Prankl2013718,
title = "Interactive object modelling based on piecewise planar surface patches ",
journal = "Computer Vision and Image Understanding ",
volume = "117",
number = "6",
pages = "718 - 731",
year = "2013",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S107731421300026X",
author = "Johann Prankl and Michael Zillich and Markus Vincze",
keywords = "Plane detection",
keywords = "Object modelling",
keywords = "Reconstruction",
keywords = "Multiple structure from motion ",
abstract = "Abstract Detecting elements such as planes in 3D is essential to describe objects for applications such as robotics and augmented reality. While plane estimation is well studied, table-top scenes exhibit a large number of planes and methods often lock onto a dominant plane or do not estimate 3D object structure but only homographies of individual planes. In this paper we introduce \{MDL\} to the problem of incrementally detecting multiple planar patches in a scene using tracked interest points in image sequences. Planar patches are reconstructed and stored in a keyframe-based graph structure. In case different motions occur, separate object hypotheses are modelled from currently visible patches and patches seen in previous frames. We evaluate our approach on a standard data set published by the Visual Geometry Group at the University of Oxford [24] and on our own data set containing table-top scenes. Results indicate that our approach significantly improves over the state-of-the-art algorithms. "
}
@article{Huang201532,
title = "Trends in extreme learning machines: A review ",
journal = "Neural Networks ",
volume = "61",
number = "",
pages = "32 - 48",
year = "2015",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2014.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0893608014002214",
author = "Gao Huang and Guang-Bin Huang and Shiji Song and Keyou You",
keywords = "Extreme learning machine",
keywords = "Classification",
keywords = "Clustering",
keywords = "Feature learning",
keywords = "Regression ",
abstract = "Abstract Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of \{ELM\} from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to \{ELM\} which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, \{ELM\} has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, \{ELM\} have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in \{ELM\} together with its future perspectives. "
}
@article{Cutter201628,
title = "Image-based Registration for a Neurosurgical Robot: Comparison Using Iterative Closest Point and Coherent Point Drift Algorithms ",
journal = "Procedia Computer Science ",
volume = "90",
number = "",
pages = "28 - 34",
year = "2016",
note = "20th Conference on Medical Image Understanding and Analysis (MIUA 2016) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S187705091631184X",
author = "Jennifer R. Cutter and Iain B. Styles and Ales Leonardis and Hamid Dehghani",
keywords = "Registration",
keywords = "ICP",
keywords = "CPD",
keywords = "neurosurgery",
keywords = "robot ; ",
abstract = "Abstract Stereotactic neurosurgical robots allow quick, accurate location of small targets within the brain, relying on accurate registration of pre-operative MRI/CT images with patient and robot coordinate systems during surgery. Fiducial markers or a stereotactic frame are used as registration landmarks; the patient's head is fixed in position throughout surgery. An image-based system could be quicker and less invasive, allowing the head to be moved during surgery to give greater ease of access, but would be required to retain a surgical precision of ∼1 mm at the target point. We compare two registration algorithms, iterative closest point (ICP) and coherent point drift (CPD), by registering ideal point clouds taken from \{MRI\} data with re-meshed, noisy and smoothed versions. We find that \{ICP\} generally gives better and more consistent registration accuracy for the region of interest than CPD, with a best \{RMS\} distance of 0.884±0.050 mm between aligned point clouds, as compared to 0.995±0.170 mm or worse for CPD. "
}
@article{Carozza201319,
title = "Error analysis of satellite attitude determination using a vision-based approach ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "83",
number = "",
pages = "19 - 29",
year = "2013",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2013.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0924271613001354",
author = "Ludovico Carozza and Alessandro Bevilacqua",
keywords = "Vision",
keywords = "Image registration",
keywords = "Error analysis",
keywords = "Accuracy analysis",
keywords = "Satellite",
keywords = "Feature tracking ",
abstract = "Abstract Improvements in communication and processing technologies have opened the doors to exploit on-board cameras to compute objects’ spatial attitude using only the visual information from sequences of remote sensed images. The strategies and the algorithmic approach used to extract such information affect the estimation accuracy of the three-axis orientation of the object. This work presents a method for analyzing the most relevant error sources, including numerical ones, possible drift effects and their influence on the overall accuracy, referring to vision-based approaches. The method in particular focuses on the analysis of the image registration algorithm, carried out through on-purpose simulations. The overall accuracy has been assessed on a challenging case study, for which accuracy represents the fundamental requirement. In particular, attitude determination has been analyzed for small satellites, by comparing theoretical findings to metric results from simulations on realistic ground-truth data. Significant laboratory experiments, using a numerical control unit, have further confirmed the outcome. We believe that our analysis approach, as well as our findings in terms of error characterization, can be useful at proof-of-concept design and planning levels, since they emphasize the main sources of error for visual based approaches employed for satellite attitude estimation. Nevertheless, the approach we present is also of general interest for all the affine applicative domains which require an accurate estimation of three-dimensional orientation parameters (i.e., robotics, airborne stabilization). "
}
@article{Hossain20132007,
title = "Texture databases – A comprehensive survey ",
journal = "Pattern Recognition Letters ",
volume = "34",
number = "15",
pages = "2007 - 2022",
year = "2013",
note = "Smart Approaches for Human Action Recognition ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2013.02.009",
url = "http://www.sciencedirect.com/science/article/pii/S0167865513000536",
author = "Shahera Hossain and Seiichi Serikawa",
keywords = "Texture",
keywords = "Database",
keywords = "Dynamic",
keywords = "Vision",
keywords = "Image ",
abstract = "Texture analysis is a very important area in the field of computer vision and related fields. There are a good number of databases developed by different research groups for various texture analysis, in the field of medical analysis, robotics, recognition, analysis, image processing, etc. However, till-to-date, there is no comprehensive works covering the important databases and analyze these in various perspectives. In this paper, we consider this important task so that it becomes helpful for a researcher to choose and evaluate having crucial evaluating aspects in mind. We categorize and critically survey based on many references of the state-of-the-art related to the databases and other texture works. We strongly believe that this elegant survey will be a great contribution for the vision community, especially in the arena of texture analysis. "
}
@article{Rejas2015939,
title = "Environment mapping using a 3D laser scanner for unmanned ground vehicles ",
journal = "Microprocessors and Microsystems ",
volume = "39",
number = "8",
pages = "939 - 949",
year = "2015",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S014193311500157X",
author = "Jose-Ignacio Rejas and Alberto Sanchez and Guillermo Glez-de-Rivera and Manuel Prieto and Javier Garrido",
keywords = "Laser radar",
keywords = "UGV",
keywords = "3D mapping ",
abstract = "Abstract Unmanned ground vehicles need accurate sensors to detect obstacles and map their surroundings. Laser-based distance sensors offers precise results, but 3D off-the-shelf sensors may be too expensive. This paper presents a 3D sensing system using a 2D laser sensor with a rotation system. Point cloud density analyses are presented in order to achieve the optimal rotation speed depending on the vehicle speed, distance to obstacles, etc. The proposed system is able to generate real-time point clouds, detect obstacles and produce maps, with high accuracy and a reasonable price (less than 5, 000 USD). "
}
@article{Andujar201667,
title = "Using depth cameras to extract structural parameters to assess the growth state and yield of cauliflower crops ",
journal = "Computers and Electronics in Agriculture ",
volume = "122",
number = "",
pages = "67 - 73",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2016.01.018",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916000235",
author = "Dionisio Andujar and Angela Ribeiro and Cesar Fernandez-Quintanilla and Jose Dorado",
keywords = "Kinect",
keywords = "Plant structure characterization",
keywords = "Weight estimation",
keywords = "Volume estimation ",
abstract = "Abstract The use of robotic systems for horticultural crops is widely known. However, the use of these systems in cruciferous vegetables remains a challenge. The case of cauliflower crops is of special relevance because it is a hand-harvested crop for which the cutting time is visually chosen. This methodology leads to a yield reduction, as some inflorescences are cut before ripening because the leaves hide their real state of maturity. This work proposes the use of depth cameras instead of visual estimation. Using Kinect Fusion algorithms, depth cameras create a 3D point cloud from the depth video stream and consequently generate solid 3D models, which have been compared to the actual structural parameters of cauliflower plants. The results show good consistency among depth image models and ground truth from the actual structural parameters. In addition, the best time for individual fruit cutting could be detected using these models, which enabled the optimization of harvesting and increased yields. The accuracy of the models deviated from the ground truth by less than 2 cm in diameter/height, whereas the fruit volume estimation showed an error below 0.6% overestimation. Analysis of the structural parameters revealed a significant correlation between estimated and actual values of the volume of plants and fruit weight. These results show the potential of depth cameras to be used as a precise tool in estimating the degree of ripeness during the harvesting of cauliflower and thereby optimizing the crop profitability. "
}
@article{Wettergreen1993171,
title = "Exploring Mount Erebus by walking robot ",
journal = "Robotics and Autonomous Systems ",
volume = "11",
number = "3–4",
pages = "171 - 185",
year = "1993",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/0921-8890(93)90022-5",
url = "http://www.sciencedirect.com/science/article/pii/0921889093900225",
author = "David Wettergreen and Chuck Thorpe and Red Whittaker",
keywords = "Walking",
keywords = "Legged",
keywords = "Autonomous",
keywords = "Robot",
keywords = "Volcanoes ",
abstract = "Dante is a tethered walking robot capable of climbing steep slopes. In 1992 it was created at Carnegie Mellon University and deployed in Antarctica to explore an active volcano, Mount Erebus. The Dante project's robot science objectives were to demonstrate a real exploration mission, rough terrain locomotion, environmental survival, and self-sustained operation in the harsh Antarctic climate. The volcano science objective was to study the unique convecting magma lake inside Mount Erebus' inner crater. The expedition demonstrated the advancing state-of-art in mobile robotics and the future potential of robotic explorers. This paper details our objectives, describes the Dante robot, overviews what happened on the expedition and discusses what did and didn't work. "
}
@article{Bedkowski201478,
title = "Towards terrestrial 3D data registration improved by parallel programming and evaluated with geodetic precision ",
journal = "Automation in Construction ",
volume = "47",
number = "",
pages = "78 - 91",
year = "2014",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2014.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0926580514001642",
author = "Janusz Bedkowski and Karol Majek and Pawel Musialik and Artur Adamek and Dariusz Andrzejewski and Damian Czekaj",
keywords = "Iterative closest point",
keywords = "Data registration",
keywords = "Mobile mapping",
keywords = "CUDA parallel programming",
keywords = "Spatial design support ",
abstract = "Abstract In this paper a quantitative and qualitative evaluation of proposed ICP-based data registration algorithm, improved by parallel programming in \{CUDA\} (compute unified device architecture), is shown. The algorithm was tested on data collected with a 3D terrestrial laser scanner Z + F Imager 5010 mounted on the mobile platform \{PIONNER\} 3AT. Parallel implementation enables data registration on-line, even using a laptop with a standard hardware configuration (graphic card \{NVIDIA\} GeForce 6XX/7XX series). Robustness is assured by the use of CUDA-enhanced fast \{NNS\} (nearest neighbor search) applied for \{ICP\} (iterative closest point) with \{SVD\} (singular value decomposition) solver. The evaluation is based on the reference ground truth data registered with geodetic precision. The geodetic approach extends our previous work and gives an accurate benchmark for the algorithm. The data were collected in an urban area under a demolition scenario in a real environment. We compared four registration strategies concerning data preprocessing, such as subsampling and vegetation removal. The result is the analysis of measured performance and the accuracy of the geometric maps. The system provides accurate metric maps on-line and can be used in several applications such as mobile robotics for construction area modelling or spatial design support. It is a core component for our future work on mobile mapping systems. "
}
@article{Cashmore2015262,
title = "Artificial Intelligence Planning for \{AUV\} Mission Control ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "262 - 267",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.043",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002827",
author = "Michael Cashmore and Maria Fox and Derek Long and Daniele Magazzeni and Bram Ridder",
keywords = "Planning",
keywords = "Persistent Autonomy",
keywords = "Artificial intelligence",
keywords = "Automatic control systems",
keywords = "Autonomous vehicles",
keywords = "Time schedule control",
keywords = "Intelligent knowledge-based systems ",
abstract = "Abstract Autonomous intelligent robotic systems are becoming increasingly important in a wide range of applications. Many of these application contexts are in physical situations out of human reach, so that a robot, or team of robots, must be capable of operating for long periods without human intervention. This requires a strategic planning capability as well as an ability to interpret and adapt to unexpected events. In this paper we describe progress towards developing such a capability in the context of underwater oilfield operations. "
}
@article{Kowadlo2009723,
title = "Improving the robustness of naive physics airflow mapping, using Bayesian reasoning on a multiple hypothesis tree ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "6–7",
pages = "723 - 737",
year = "2009",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.10.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008002029",
author = "Gideon Kowadlo and R. Andrew Russell",
keywords = "Odour localisation",
keywords = "Odor localization",
keywords = "Naive physics",
keywords = "Airflow modelling",
keywords = "Bayesian",
keywords = "Multiple hypothesis ",
abstract = "Previous work on robotic odour localisation in enclosed environments, relying on an airflow model, has faced significant limitations due to the fact that large differences between airflow topologies are predicted for only small variations in a physical map. This is due to uncertainties in the map and approximations in the modelling process. Furthermore, there are uncertainties regarding the flow direction through inlet/outlet ducts. We present a method for dealing with these uncertainties through the generation of multiple airflow hypotheses. As the robot performs odour localisation, airflow in the environment is measured and used to adjust the confidences of the hypotheses using Bayesian inference. The best hypothesis is then selected, which allows the completion of the localisation task. Experimental results show that this method is capable of improving the robustness of odour localisation in the presence of uncertainties, where previously it was incapable. The results further demonstrate the usefulness of naive physics for practical robotics applications. "
}
@article{Gallant20161,
title = "Automated rapid mapping of joint orientations with mobile LiDAR ",
journal = "International Journal of Rock Mechanics and Mining Sciences ",
volume = "90",
number = "",
pages = "1 - 14",
year = "2016",
note = "",
issn = "1365-1609",
doi = "https://doi.org/10.1016/j.ijrmms.2016.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S1365160916301988",
author = "Marc J. Gallant and Joshua A. Marshall",
keywords = "Joint orientation",
keywords = "Mobile",
keywords = "LiDAR",
keywords = "Laser",
keywords = "Discontinuity",
keywords = "Stereonet ",
abstract = "Abstract This paper introduces three-dimensional axis mapping (3DAM), a new method for joint orientation estimation that rapidly collects data from a mobile platform containing a scannerless LiDAR and an inertial measurement unit (IMU). The mobile platform is moved through the environment either as a handheld device or by mounting it to a remotely operated or robotic vehicle. 3DAM is formulated as a global state estimation problem that estimates the orientation of the mobile platform and the joint set orientations by minimizing the uncertainty introduced by the inherently noisy sensors. This requires a dual-parameterization of both the orientation of joint sets and the mobile platform to permit the use of state estimation techniques. 3DAM was field tested in three separate locations and is directly compared to hand measurements and stationary LiDAR. In all experiments, it is shown that 3DAM produces stereonets comparable to other methods, yet does so with lower-cost hardware and significantly reduced effort. "
}
@article{Palleja20101420,
title = "Sensitivity of tree volume measurement to trajectory errors from a terrestrial \{LIDAR\} scanner ",
journal = "Agricultural and Forest Meteorology ",
volume = "150",
number = "11",
pages = "1420 - 1427",
year = "2010",
note = "",
issn = "0168-1923",
doi = "https://doi.org/10.1016/j.agrformet.2010.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S0168192310001942",
author = "T. Palleja and M. Tresanchez and M. Teixido and R. Sanz and J.R. Rosell and J. Palacin",
keywords = "Terrestrial LIDAR",
keywords = "Crop modeling",
keywords = "Dose control ",
abstract = "The use of terrestrial \{LIDARs\} in agriculture enables the measurement of structural parameters of the orchards such as the volume of the trees. The sequence of two-dimensional scans performed with a \{LIDAR\} attached to a tractor can be interpreted as the three-dimensional silhouette of the trees of the grove and used to estimate their volume. In this work, the sensitivity of the tree volume estimates relative to different error sources in the estimated spatial trajectory of the \{LIDAR\} is analyzed. Tests with pear trees have demonstrated that the estimation of the volume is very sensitive to errors in the determination of the distance from the \{LIDAR\} to the center of the trees (with errors up to 30% for an error of 50 mm) and in the determination of the angle of orientation of the \{LIDAR\} (with errors up to 30% for misalignments of 2°). Therefore, any experimental procedure for tree volume estimate based on a motorized terrestrial \{LIDAR\} scanner must include additional devices or procedures to control or estimate and correct these error sources. "
}
@article{GutierrezGomez2015299,
title = "Curve-graph odometry: Orientation-free error parameterisations for loop closure problems ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "299 - 308",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001645",
author = "Daniel Gutierrez-Gomez and J.J. Guerrero",
keywords = "Pose-graph optimisation",
keywords = "Loop closure",
keywords = "SLAM",
keywords = "Robot odometry ",
abstract = "Abstract During incremental odometry estimation in robotics and vision applications, the accumulation of estimation error produces a drift in the trajectory. This drift becomes observable when returning to previously visited areas, where it is possible to correct it by applying loop closing techniques. Ultimately a loop closing process leads to an optimisation problem where new constraints between poses obtained from loop detection are applied to the initial incremental estimate of the trajectory. Typically this optimisation is jointly applied on the position and orientation of each pose of the robot using the state-of-the-art pose graph optimisation scheme on the manifold of the rigid body motions. In this paper we propose to address the loop closure problem using only the positions and thus removing the orientations from the optimisation vector. The novelty in our approach is that, instead of treating trajectory as a set of poses, we look at it as a curve in its pure mathematical meaning. We define an observation function which computes the estimate of one constraint in a local reference frame using only the robot positions. Our proposed method is compared against state-of-the-art pose graph optimisation algorithms in 2 and 3 dimensions. The benefit of eliminating orientations is twofold. First, the objective function in the optimisation does not mix translation and rotation terms, which may have different scales. Second, computational performance can be improved due to the reduction in the state dimension of the nodes of the graph. "
}
@article{Fisch201290,
title = "Learning from others: Exchange of classification rules in intelligent distributed systems ",
journal = "Artificial Intelligence ",
volume = "187–188",
number = "",
pages = "90 - 114",
year = "2012",
note = "",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0004370212000410",
author = "Dominik Fisch and Martin Janicke and Edgar Kalkowski and Bernhard Sick",
keywords = "Classification",
keywords = "Rule exchange",
keywords = "Collaborative learning",
keywords = "Uncertain knowledge",
keywords = "Probabilistic modeling",
keywords = "Collective intelligence",
keywords = "Interestingness ",
abstract = "Learning by an exchange of knowledge and experiences enables humans to act efficiently in a very dynamic environment. Thus, it would be highly desirable to enable intelligent distributed systems to behave in a way which follows that biological archetype. We believe that knowledge exchange will become increasingly important in many application areas such as intrusion detection, driver assistance, or robotics. Constituents of a distributed system such as software agents, cars equipped with smart sensors, or intelligent robots may learn from each other by exchanging knowledge in form of classification rules, for instance. This article proposes techniques for the exchange of classification rules that represent uncertain knowledge. For that purpose, we introduce methods for knowledge acquisition in dynamic environments, for gathering and using meta-knowledge about rules (i.e., experience), and for rule exchange in distributed systems. The methods are based on a probabilistic knowledge modeling approach. We describe the results of two case studies where we show that knowledge exchange (exchange of learned rules) may be superior to information exchange (exchange of raw observations, i.e. samples) and demonstrate that the use of experiences (meta-knowledge concerning the rules) may improve that rule exchange process further. Some possible real application scenarios are sketched briefly and an application in the field of intrusion detection in computer networks is elaborated in more detail. "
}
@article{Kaupp2010444,
title = "Human–robot communication for collaborative decision making — A probabilistic approach ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "5",
pages = "444 - 456",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2010.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889010000400",
author = "Tobias Kaupp and Alexei Makarenko and Hugh Durrant-Whyte",
keywords = "Human–robot communication",
keywords = "Information fusion",
keywords = "Collaborative control",
keywords = "Adjustable autonomy",
keywords = "Semi-autonomous systems ",
abstract = "Humans and robots need to exchange information if the objective is to achieve a task collaboratively. Two questions are considered in this paper: what and when to communicate. To answer these questions, we developed a human–robot communication framework which makes use of common probabilistic robotics representations. The data stored in the representation determines what to communicate, and probabilistic inference mechanisms determine when to communicate. One application domain of the framework is collaborative human–robot decision making: robots use decision theory to select actions based on perceptual information gathered from their sensors and human operators. In this paper, operators are regarded as remotely located, valuable information sources which need to be managed carefully. Robots decide when to query operators using Value-Of-Information theory, i.e. humans are only queried if the expected benefit of their observation exceeds the cost of obtaining it. This can be seen as a mechanism for adjustable autonomy whereby adjustments are triggered at run-time based on the uncertainty in the robots’ beliefs related to their task. This semi-autonomous system is demonstrated using a navigation task and evaluated by a user study. Participants navigated a robot in simulation using the proposed system and via classical teleoperation. Results show that our system has a number of advantages over teleoperation with respect to performance, operator workload, usability, and the users’ perception of the robot. We also show that despite these advantages, teleoperation may still be a preferable driving mode depending on the mission priorities. "
}
@article{Benkhalifa2016206,
title = "Towards climatological study on the characteristics of aerosols in Central Africa and Mediterranean sites ",
journal = "Journal of Atmospheric and Solar-Terrestrial Physics ",
volume = "138–139",
number = "",
pages = "206 - 214",
year = "2016",
note = "",
issn = "1364-6826",
doi = "https://doi.org/10.1016/j.jastp.2016.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S1364682616300104",
author = "Jamel Benkhalifa and Mabrouk Chaabane",
keywords = "Aerosol optical thickness",
keywords = "Angstrom exponent",
keywords = "Aerosol size distribution",
keywords = "Single scattering albedo ",
abstract = "Abstract The atmosphere contains molecules, clouds and aerosols that are sub-millimeter particles having a large variability in size, shape, chemical composition, lifetime and contents. The aerosols concentration depends greatly on the geographical situation, meteorological and environmental conditions, which makes aerosol climatology difficult to assess. Setting up a solar photometer (automatic, autonomous and portable instrument) on a given site allows carrying out the necessary measurements for aerosol characterization. The particle microphysical and optical properties are obtained from photometric measurements. The objective of this study is to analyze the spatial variability of aerosol optical thickness (AOT) in several Mediterranean regions and Central Africa, we considered a set of simultaneous data in the \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) from six sites, two of which are located in Central Africa (Banizoumbou and Zinder Airport) and the rest are Mediterranean sites (Barcelona, Malaga, Lampedusa, and Forth Crete). The results have shown that the physical properties of aerosols are closely linked to the climate nature of the studied site. The optical thickness, single scattering albedo and aerosols size distribution can be due to the aging of the dust aerosol as they are transported over the Mediterranean basin. "
}
@article{Vermote201646,
title = "Preliminary analysis of the performance of the Landsat 8/OLI land surface reflectance product ",
journal = "Remote Sensing of Environment ",
volume = "185",
number = "",
pages = "46 - 56",
year = "2016",
note = "Landsat 8 Science Results ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716301572",
author = "Eric Vermote and Chris Justice and Martin Claverie and Belen Franch",
abstract = "Abstract The surface reflectance, i.e., satellite derived top of atmosphere (TOA) reflectance corrected for the temporally, spatially and spectrally varying scattering and absorbing effects of atmospheric gases and aerosols, is needed to monitor the land surface reliably. For this reason, the surface reflectance, and not \{TOA\} reflectance, is used to generate the greater majority of global land products, for example, from the Moderate Resolution Imaging Spectroradiometer (MODIS) and Visible Infrared Imaging Radiometer Suite (VIIRS) sensors. Even if atmospheric effects are minimized by sensor design, atmospheric effects are still challenging to correct. In particular, the strong impact of aerosols in the visible and near infrared spectral range can be difficult to correct, because they can be highly discrete in space and time (e.g., smoke plumes) and because of the complex scattering and absorbing properties of aerosols that vary spectrally and with aerosol size, shape, chemistry and density. This paper presents the Landsat 8 Operational Land Imager (OLI) atmospheric correction algorithm that has been developed using the Second Simulation of the Satellite Signal in the Solar Spectrum Vectorial (6SV) model, refined to take advantage of the narrow \{OLI\} spectral bands (compared to Thematic Mapper/Enhanced Thematic Mapper (TM/ETM +)), improved radiometric resolution and signal-to-noise. In addition, the algorithm uses the new \{OLI\} Coastal aerosol band (0.433–0.450 μm), which is particularly helpful for retrieving aerosol properties, as it covers shorter wavelengths than the conventional Landsat, \{TM\} and \{ETM\} + blue bands. A cloud and cloud shadow mask has also been developed using the “cirrus” band (1.360–1.390 μm) available on OLI, and the thermal infrared bands from the Thermal Infrared Sensor (TIRS) instrument. The performance of the surface reflectance product from \{OLI\} is analyzed over the Aerosol Robotic Network (AERONET) sites using accurate atmospheric correction (based on in situ measurements of the atmospheric properties), by comparison with the \{MODIS\} Bidirectional Reflectance Distribution Function (BRDF) adjusted surface reflectance product and by comparison of \{OLI\} derived broadband albedo from United States Surface Radiation Budget Network (US SURFRAD) measurements. The results presented clearly show an improvement of Landsat 8 surface reflectance product over the ad-hoc Landsat 5/7 \{LEDAPS\} product. "
}
@article{Li2015260,
title = "How well do satellite \{AOD\} observations represent the spatial and temporal variability of PM2.5 concentration for the United States? ",
journal = "Atmospheric Environment ",
volume = "102",
number = "",
pages = "260 - 273",
year = "2015",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014009583",
author = "Jing Li and Barbara E. Carlson and Andrew A. Lacis",
keywords = "PM2",
keywords = "Aerosol optical depth",
keywords = "Satellite remote sensing",
keywords = "Principal component analysis",
keywords = "Spatial and temporal variability ",
abstract = "Abstract Due to their extensive spatial coverage, satellite Aerosol Optical Depth (AOD) observations have been widely used to estimate and predict surface PM2.5 concentrations. While most previous studies have focused on establishing relationships between collocated, hourly or daily \{AOD\} and PM2.5 measurements, in this study, we instead focus on the comparison of the large-scale spatial and temporal variability between satellite \{AOD\} and PM2.5 using monthly mean measurements. A newly developed spectral analysis technique – Combined Maximum Covariance Analysis (CMCA) is applied to Moderate Resolution Imaging Spectroradiometer (MODIS), Multi-angle Imaging Spectroradiometer (MISR), Sea-viewing Wide Field-of-view Sensor (SeaWiFS) and Ozone Monitoring Instrument (OMI) \{AOD\} datasets and Environmental Protection Agency (EPA) PM2.5 data, in order to extract and compare the dominant modes of variability. Results indicate that \{AOD\} and PM2.5 agree well in terms of interannual variability. An overall decrease is found in both \{AOD\} and PM2.5 across the United States, with the strongest signal over the eastern US. With respect to seasonality, good agreement is found only for Eastern US, while for Central and Western US, \{AOD\} and PM2.5 seasonal cycles are largely different or even reversed. These results are verified using Aerosol Robotic Network (AERONET) \{AOD\} observations and differences between satellite and \{AERONET\} are also examined. \{MODIS\} and \{MISR\} appear to have the best agreement with AERONET. In order to explain the disagreement between \{AOD\} and PM2.5 seasonality, we further use Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) extinction profile data to investigate the effect of two possible contributing factors, namely aerosol vertical distribution and cloud-free sampling. We find that seasonal changes in aerosol vertical distribution, due to the seasonally varying mixing height, is the primary cause for the \{AOD\} and PM2.5 seasonal discrepancy, in particular, the low \{AOD\} but high PM2.5 observed during the winter season for Central and Western US. In addition, cloud-free sampling by passive sensors also induces some bias in \{AOD\} seasonality, especially for the Western US, where the largest seasonal change in cloud fraction is found. The seasonal agreement between low level (below 500 m AGL), all sky \{CALIOP\} \{AOD\} and PM2.5 is significantly better than column \{AOD\} from MODIS, MISR, SeaWiFS and OMI. In particular, the correlation between low level, all sky \{AOD\} and PM2.5 seasonal cycles increases to above 0.7 for Central and Western US, as opposed to near zero or negative correlation for column, clear sky AOD. This result highlights the importance of accounting for the seasonally varying aerosol profiles and cloud-free sampling bias when using column \{AOD\} measurements to infer surface PM2.5 concentrations. "
}
@article{Balint2015129,
title = "Humanly space objects—Perception and connection with the observer ",
journal = "Acta Astronautica ",
volume = "110",
number = "",
pages = "129 - 144",
year = "2015",
note = "Dynamics and Control of Space Systems ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515000144",
author = "Tibor S. Balint and Ashley Hall",
keywords = "Design",
keywords = "Art",
keywords = "Cybernetics",
keywords = "Tacit-knowledge",
keywords = "Perception",
keywords = "Cognition",
keywords = "Affordances ",
abstract = "Abstract Expanding humanity into space is an inevitable step in our quest to explore our world. Yet space exploration is costly, and the awaiting environment challenges us with extreme cold, heat, vacuum and radiation, unlike anything encountered on Earth. Thus, the few pioneers who experience it needed to be well protected throughout their spaceflight. The resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life. Such connections may occur via sensory inputs, namely vision, touch, sound, smell, and taste. This then follows the process of sensing, interpreting, and recognizing familiar patterns, or learning from new experiences. The desire to connect could even transfer to observed objects, if their movements and characteristics trigger the appropriate desires from the observer. When ordered in a familiar way, for example visual stimuli from lights and movements of an object, it may create a perceived real bond with an observer, and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable. These behavior patterns can be designed into an object and performed autonomously in front of an observer, in our case an astronaut. The experience may introduce multiple responses, including communication, connection, empathy, order, and disorder. While emotions are clearly evoked in the observer and may seem one sided, in effect the object itself provides a decoupled bond, connectivity and communication between the observer and the artist-designer of the object. In this paper we will discuss examples from the field of arts and other domains, including robotics, where human perception through object interaction was explored, and investigate the starting point for new innovative design concepts and future prototype designs, that extend these experiences beyond the boundaries of Earth, while taking advantage of remoteness and the zero gravity environment. Through a form of emotional connection and design, these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a co-located observer in spaceflight. We conclude that beyond providing creative expressions for humanly contacts, these experiences may also provide further insights into human perception in spaceflight, and could be tested on the International Space Station, and serve as a stepping-stone towards use on long-duration spaceflight to Mars. "
}
@article{Mendell2004149,
title = "The roles of humans and robots in exploring the solar system ",
journal = "Acta Astronautica ",
volume = "55",
number = "2",
pages = "149 - 155",
year = "2004",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2004.01.052",
url = "http://www.sciencedirect.com/science/article/pii/S0094576504000992",
author = "W.W. Mendell",
abstract = "Historically, advocates of solar system exploration have disagreed over whether program goals could be entirely satisfied by robotic missions. Scientists tend to argue that robotic exploration is most cost-effective. However, the human space program has a great deal of support in the general public, thereby enabling the scientific element of exploration to be larger than it might be as a stand-alone activity. A comprehensive strategy of exploration needs a strong robotic component complementing and supporting human missions. Robots are needed for precursor missions, for crew support on planetary surfaces, and for probing dangerous environments. Robotic field assistants can provide mobility, access to scientific sites, data acquisition, visualization of the environment, precision operations, sample acquisition and analysis, and expertise to human explorers. As long as space exploration depends on public funds, space exploration must include an appropriate mix of human and robotic activity. "
}
@article{Figueroa2013580,
title = "Joint origin identification of articulated robots with marker-based multi-camera optical tracking systems ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "6",
pages = "580 - 592",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000444",
author = "Nadia B. Figueroa and Florian Schmidt and Haider Ali and Nikolaos Mavridis",
keywords = "Joint identification",
keywords = "Marker-based multi-camera optical tracking system",
keywords = "Calibration",
keywords = "Articulated robots ",
abstract = "Abstract Marker-based multi-camera optical tracking systems are being used in the robotics field to track robots for validation, verification, and calibration of their kinematic and dynamic models. These tracking systems estimate the pose of tracking bodies attached to objects within a tracking volume. In this work, we explore the case of tracking the origins of joints of articulated robots when the tracking bodies are mounted on limbs or structures relative to the joints. This configuration leads to an unknown relative pose between the tracking body and the joint origin. The identification of this relative pose is essential for an accurate representation of the kinematic model. We propose an approach for the identification of the origin of joints relative to tracking bodies by using state-of-the-art center of rotation (CoR) and axis of rotation (AoR) estimation methods. The applicability and effectiveness of our approach is demonstrated in two successful case studies: (i) the verification of the upper body kinematics of DLR’s humanoid Rollin’ Justin and (ii) the identification of the kinematic parameters of an \{ST\} Robot arm relative to its environment for the embodiment of a situated conversational assistant. "
}
@article{Li201739,
title = "An integrated approach of reverse engineering aided remanufacturing process for worn components ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "39 - 50",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515301320",
author = "Lingling Li and Congbo Li and Ying Tang and Yanbin Du",
keywords = "Remanufacturing",
keywords = "Reverse engineering",
keywords = "Model reconstruction",
keywords = "Registration",
keywords = "Worn parts ",
abstract = "Abstract The worn mechanical components/parts arrived in the remanufacturing system exhibit highly uncontrolled variabilities in failure conditions as well as structures and shape complexities. With the aid of reverse engineering (RE) technologies, a quick and accurate acquisition of the damaged areas of the worn part is attainable and thereby facilitates remanufacturing operations necessary to bring the parts back to like-new conditions. In this paper, a reverse engineering based approach is proposed to aid the remanufacturing processes of worn parts. The proposed approach integrates 3D surface data collection, nominal model reconstruction, fine registration, extraction of additive/subtractive repair, tool path generation and actual machining process, seeking to improve the reliability and efficiency of manual repair process. For nominal model reconstruction, a Prominent Cross-Section algorithm embedded with curvature constraint is proposed to automatically identify the boundary of the part's damaged area and thereby eliminate the defective point clouds from the reconstruction process. With the nominal reconstruction model and the 3D model of the worn part, a modified \{ICP\} algorithm integrating curvature and distance constraints is proposed to achieve a best-fit position of the two models by automatically identifying and eliminating the unreliable corresponding pairs through iterations. The proposed approach is demonstrated through remanufacturing of two different mechanical components and is approved to be efficient and effective. "
}
@article{Palomer2013286,
title = "A Comparison of \{G2o\} Graph \{SLAM\} and \{EKF\} Pose Based \{SLAM\} with Bathymetry Grids ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "33",
pages = "286 - 291",
year = "2013",
note = "9th \{IFAC\} Conference on Control Applications in Marine Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130918-4-JP-3022.00065",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016461720",
author = "Albert Palomer and Pere Ridao and David Ribas and Angelos Mallios and Guillem Vallicrosa",
abstract = "Abstract This paper address the Simultaneous Localization and Mapping (SLAM) problem of an \{AUV\} using bathymetric maps. The algorithm compounds swath profiles of the seafloor with \{DVL\} navigation(dead-reckoning) to build surface patches (3D point clouds). An initial guess of the location of these point clouds is known a priori by means of the dead-reckoning solution. Whenever there is a significant overlap of two or more point clouds, the corresponding surface patches are registered among themselves using a probabilistic \{ICP\} algorithm. The outcome of the registration procedure is a set of constrains defining the relative position of the overlapping surface patches. Next, these constrains are used to optimize a pose graph using the \{G2o\} optimizer. The results are compared against our prior EKF-pose-based \{SLAM\} solution. Our results suggest that a better performance is achieved using \{EKF\} global optimization with respect to the \{G2o\} graph-SLAM solution. "
}
@article{Phung201111514,
title = "Get Out of the Way – Obstacle Avoidance and Learning by Demonstration for Manipulation ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11514 - 11519",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.01363",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016454650",
author = "A.S. Phung and J. Malzahn and F. Hoffmann and T. Bertram",
keywords = "Robots manipulators",
keywords = "perception and sensing",
keywords = "obstacle avoidance",
keywords = "movement primitives",
keywords = "image processing ",
abstract = "Abstract Humans acquire manipulation skills by trial and error within a few trials, whereas programming a robot to perform the same task requires robotic expertise and effort. This paper presents a robot which learns a movement from demonstrations with the ability to generalize the movement to new goal poses and avoid the collision with obstacles in the workspace. The general movement is represented by dynamic movement primitives (DMP) augmented by potential fields in order to modulate the motion in the presence of obstacles. The approach is validated in experiments with a robotic arm in which dynamic obstacles partially blocking the movement are detected by a Photonic-Mixer-Devices (PMD) camera. "
}
@article{Park201424,
title = "Combined dust detection algorithm by using \{MODIS\} infrared channels over East Asia ",
journal = "Remote Sensing of Environment ",
volume = "141",
number = "",
pages = "24 - 39",
year = "2014",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2013.09.019",
url = "http://www.sciencedirect.com/science/article/pii/S0034425713003568",
author = "Sang Seo Park and Jhoon Kim and Jaehwa Lee and Sukjo Lee and Jeong Soo Kim and Lim Seok Chang and Steve Ou",
keywords = "\{MODerate\} resolution Imaging Spectroradiometer (MODIS)",
keywords = "Dust detection",
keywords = "Dust",
keywords = "East Asia ",
abstract = "Abstract A new dust detection algorithm is developed by combining the results of multiple dust detection methods using \{IR\} channels onboard the \{MODerate\} resolution Imaging Spectroradiometer (MODIS). Brightness Temperature Difference (BTD) between two wavelength channels has been used widely in previous dust detection methods. However, \{BTD\} methods have limitations in identifying the offset values of the \{BTD\} to discriminate clear-sky areas. The current algorithm overcomes the disadvantages of previous dust detection methods by considering the Brightness Temperature Ratio (BTR) values of the dual wavelength channels with 30-day composite, the optical properties of the dust particles, the variability of surface properties, and the cloud contamination. Therefore, the current algorithm shows improvements in detecting the dust loaded region over land during daytime. Finally, the confidence index of the current dust algorithm is shown in 10 × 10 pixels of the \{MODIS\} observations. From January to June, 2006, the results of the current algorithm are within 64 to 81% of those found using the fine mode fraction (FMF) and aerosol index (AI) from the \{MODIS\} and Ozone Monitoring Instrument (OMI). The agreement between the results of the current algorithm and the \{OMI\} \{AI\} over the non-polluted land also ranges from 60 to 67% to avoid errors due to the anthropogenic aerosol. In addition, the developed algorithm shows statistically significant results at four \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) sites in East Asia. "
}
@incollection{Turner201735,
title = "Chapter 4 - Automation of the Molecular Diagnostic Laboratory ",
editor = "Coleman, William B.  and Tsongalis, Gregory J. ",
booktitle = "Diagnostic Molecular Pathology ",
publisher = "Academic Press",
edition = "",
address = "",
year = "2017",
pages = "35 - 46",
isbn = "978-0-12-800886-7",
doi = "https://doi.org/10.1016/B978-0-12-800886-7.00004-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780128008867000042",
author = "S.A. Turner and G.J. Tsongalis",
keywords = "Automation",
keywords = "molecular diagnostics",
keywords = "instrumentation",
keywords = "PCR",
keywords = "NGS ",
abstract = "Abstract The field of molecular diagnostics has evolved at a record pace with the introduction of new technologies and clinical applications. This consistent growth has been augmented by many forms of automation for highly complex tasks. Sample preparation saw the introduction of completely robotic solutions for nucleic acid isolations while changes in the chemistry for the polymerase chain reaction (PCR) made real time and digital droplet \{PCR\} more automated. This chapter focuses on major advances in and introduction of automation that has allowed the molecular diagnostics laboratory to address the growing needs for more molecular testing. "
}
@article{Corsi2007192,
title = "Smart Sensors ",
journal = "Infrared Physics & Technology ",
volume = "49",
number = "3",
pages = "192 - 197",
year = "2007",
note = "Workshop on Advanced Infrared Technology and Applications ",
issn = "1350-4495",
doi = "https://doi.org/10.1016/j.infrared.2006.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S1350449506000739",
author = "C. Corsi",
keywords = "Smart",
keywords = "Infrared",
keywords = "Sensors",
keywords = "Fly-eye",
keywords = "Surveillance",
keywords = "Staring systems",
keywords = "Warning",
keywords = "Collision avoidance ",
abstract = "The term “Smart Sensors” refers to sensors which contain both sensing and signal processing capabilities with objectives ranging from simple viewing to sophisticated remote sensing, surveillance, search/track, weapon guidance, robotics, perceptronics and intelligence applications. Recently this approach is achieving higher goals by a new and revolutionary sensors concept which introduced inside the sensor some of the basic functions of living eyes, such as dynamic stare, non-uniformity compensation, spatial and temporal filtering. New objectives and requirements are presented for this type of new infrared smart sensor systems. This paper is concerned with the front end of \{FPA\} microbolometers processing, namely, the enhancement of target-to-noise ratio by background clutter suppression and the improvement in target detection by “smart” and pattern correlation thresholding. "
}
@article{Putz2016212,
title = "3D Navigation Mesh Generation for Path Planning in Uneven Terrain ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "212 - 217",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.734",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316310102",
author = "Sebastian Putz and Thomas Wiemann and Jochen Sprickerhof and Joachim Hertzberg",
keywords = "Robot Navigation",
keywords = "Path Planning",
keywords = "Surface Reconstruction",
keywords = "Mesh Generation ",
abstract = "Abstract We present a 3D mesh surface navigation system for mobile robots. This system uses a 3D point cloud to reconstruct a triangle mesh of the environment in real time that is enriched with a graph structure to represent local connectivity. This Navigation Mesh is then analyzed for roughness and trafficability and used for online path planning. The presented approach is evaluated with a VolksBot \{XT\} platform in a real life outdoor environment. "
}
@article{Deng2016315,
title = "Incremental image set querying based localization ",
journal = "Neurocomputing ",
volume = "208",
number = "",
pages = "315 - 324",
year = "2016",
note = "SI: BridgingSemantic ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.11.117",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216304738",
author = "Lei Deng and Zhixiang Chen and Baohua Chen and Yueqi Duan and Jie Zhou",
keywords = "Incremental image set localization",
keywords = "Structure-from-motion",
keywords = "Camera set pose estimation ",
abstract = "Abstract Image based localization has been developed for many applications such as mobile localization, auto-navigation, augmented reality and photo tourism. When the querying image is matched against a pre-built 3D feature point cloud, its pose can be estimated for future use. However, when the querying image is distant from the pre-built 3D point cloud, conventional single image-based localization method will fail. To address this problem, we present an incremental image set querying based localization framework. When single image localization fails, the system will incrementally ask the user to input more auxiliary images until the localization is successful and stable. The main idea is that image set, instead of single image, is matched against the pre-built 3D point cloud to meet the challenge. Next the image set is incrementally enlarged and aggregated to form a local 3D model. Compared with single image querying based localization method, the querying 3D model contains more information and geometry constraints which are essential for localization. Experiments have demonstrated the effectiveness and feasibility of the proposed framework. "
}
@article{Miskovic2015125,
title = "\{CADDY\} Project, Year 1: Overview of Technological Developments and Cooperative Behaviours★ ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "125 - 130",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.020",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002591",
author = "Nikola Miskovic and Antonio Pascoal and Marco Bibuli and Massimo Caccia and Jeffrey A. Neasham and Andreas Birk and Murat Egi and Karl Grammer and Alessandro Marroni and Antonio Vasilijevic and Zoran Vukic",
keywords = "Marine systems",
keywords = "Cognitive systems",
keywords = "Autonomous mobile robots",
keywords = "Man/machine interaction ",
abstract = "Abstract”CADDY - Cognitive Autonomous Diving Buddy” is an \{FP7\} project that started in January 2014. Seven partner institutions have joined their efforts towards developing a cognitive underwater robotic system that will help divers during their activities in this hazardous environment. The resulting system will play a threefold role similar to those that a human buddy diver should have: buddy ’’observer”, buddy ”slave”, and buddy ”guide”. This paper gives an outline of the \{CADDY\} project results during the first year of execution. We focus only on the technical developments and cooperative behaviours that have taken place, in order to keep the overview concise and in line with the workshop topics. Special attention is given to the fleet of new and adapted autonomous marine vehicles used in the project, as well as technologies for perceiving the diver. In addition to that, we give a short overview of cooperative robotic behaviours and present initial results with autonomous surface marine vehicles tracking divers. "
}
@article{Leydesdorff1994217,
title = "Tracking areas of strategic importance using scientometric journal mappings ",
journal = "Research Policy ",
volume = "23",
number = "2",
pages = "217 - 229",
year = "1994",
note = "",
issn = "0048-7333",
doi = "https://doi.org/10.1016/0048-7333(94)90054-X",
url = "http://www.sciencedirect.com/science/article/pii/004873339490054X",
author = "Loet Leydesdorff and Susan Cozzens and Peter Van den Besselaar",
abstract = "In science policy, it is often important to track emerging developments: new fields, fast-changing areas that are the focus of special funding efforts, or areas of growth or decline. This article presents methods to produce literature-based indicators for such areas using journal-to-journal citations. Using case studies of AIDS, superconductivity, and oncogenes, we posit that the inclusion of a new journal can be used as an indicator of structural change if the addition indicates the emergence of a new journal category. Using the cases of robotics and artificial intelligence, we illustrate the development of areas chosen for priority funding. Again using artificial intelligence, we demonstrate the importance of constructing even such simple measures of scientific performance as publication counts using dynamic rather than constant journal sets. Change in performance within a subfield can be systematically distinguished from change in the delineations among subfields over time. "
}
@article{Lau20131116,
title = "Efficient grid-based spatial representations for robot navigation in dynamic environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1116 - 1130",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S092188901200142X",
author = "Boris Lau and Christoph Sprunk and Wolfram Burgard",
keywords = "Incremental algorithms",
keywords = "Voronoi diagrams",
keywords = "Distance maps",
keywords = "Configuration space",
keywords = "Collision checking",
keywords = "Robot navigation ",
abstract = "In robotics, grid maps are often used for solving tasks like collision checking, path planning, and localization. Many approaches to these problems use Euclidean distance maps (DMs), generalized Voronoi diagrams (GVDs), or configuration space (c-space) maps. A key challenge for their application in dynamic environments is the efficient update after potential changes due to moving obstacles or when mapping a previously unknown area. To this end, this paper presents novel algorithms that perform incremental updates that only visit cells affected by changes. Furthermore, we propose incremental update algorithms for \{DMs\} and \{GVDs\} in the configuration space of non-circular robots. These approaches can be used to implement highly efficient collision checking and holonomic path planning for these platforms. Our c-space representations benefit from parallelization on multi-core \{CPUs\} and can also be integrated with other state-of-the-art path planners such as rapidly-exploring random trees. In various experiments using real-world data we show that our update strategies for \{DMs\} and \{GVDs\} require substantially less cell visits and computation time compared to previous approaches. Furthermore, we demonstrate that our \{GVD\} algorithm deals better with non-convex structures, such as indoor areas. All our algorithms consider actual Euclidean distances rather than grid steps and are easy to implement. An open source implementation is available online. "
}
@incollection{Bolonkin2005309,
title = "Chapter 17 - Radioisotope Space Sail and Electro-Generator* ",
editor = "Bolonkin, Alexander A. ",
booktitle = "Non-Rocket Space Launch and Flight ",
publisher = "Elsevier Science",
edition = "",
address = "Oxford",
year = "2005",
pages = "309 - 316",
isbn = "978-0-08-044731-5",
doi = "https://doi.org/10.1016/B978-008044731-5/50048-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780080447315500482",
author = "Alexander A. Bolonkin",
abstract = "Publisher Summary Radioisotope sail is a thin film of an alpha-particle-emitting radioisotope deposited on the back of a plastic sail that can provide useful quantities of both propulsion and electrical power to a deep space vehicle. The momentum kick of the emitted alpha particles provides radioisotope sail thrust levels per square meter, comparable to that of a solar sail at 1 astronautic unit (AU). The electrical power generated per 1 m2 is comparable to that obtained from solar cells at 1 AU. Radioisotope sail systems will maintain these propulsion and power levels at distances from the Sun where solar powered systems are ineffective. The propulsion and power levels available from this simple and reliable high-energy-density system would be useful for supplying propulsion and electrical power to a robotic deep space mission to the Oort Cloud or beyond, or to a robotic interstellar flyby or rendezvous probe after its arrival at the target star. "
}
@article{Nguyen201633,
title = "Detection of red and bicoloured apples on tree with an RGB-D camera ",
journal = "Biosystems Engineering ",
volume = "146",
number = "",
pages = "33 - 44",
year = "2016",
note = "Special Issue: Advances in Robotic Agriculture for Crops ",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2016.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S1537511016000088",
author = "Tien Thanh Nguyen and Koenraad Vandevoorde and Niels Wouters and Erdal Kayacan and Josse G. De Baerdemaeker and Wouter Saeys",
keywords = "Computer vision",
keywords = "RGB-D camera",
keywords = "Fruit detection",
keywords = "Harvesting robot ",
abstract = "Recognising and accurately locating fruits on a tree is a critical challenge in developing fruit-by-fruit robotic harvesting. Many researchers have investigated the potential of red, green, blue (RGB) colour imaging for this purpose, but have had limited success due to the occlusion of the target fruits by foliage, branches or other fruits as well as due to the non-uniform and unstructured nature of an orchard environment. Recently, novel, cost-effective camera systems have become available which provide both colour (RGB) and three dimensional (3D) shape information. As these have shown potential for 3D perception for robots operating in unstructured environments, the potential of such an RGB-D camera for the detection and localisation of red and bicoloured apples on tree was investigated in this study. Images were acquired with this camera system in fruit orchards under a light shield blocking direct sunlight, and an algorithm to detect and localise red and bicoloured apples based on colour and shape features was developed. When the algorithm was applied to the data acquired in these orchards, 100% of the fully visible apples and 82% of the partially occluded apples were detected correctly. The location estimation error was below 10 mm in all the coordinate axes of the Cartesian space. This high detection and location accuracy and short processing time (below 1 s for simultaneous detection of 20 apples), makes the developed algorithm suitable for implementation in a robotic harvesting system, and for yield estimation and orchard monitoring. "
}
@article{Yang2017,
title = "Rotational contour signatures for both real-valued and binary feature representations of 3D local shape ",
journal = "Computer Vision and Image Understanding ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2017.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S1077314217300322",
author = "Jiaqi Yang and Qian Zhang and Ke Xian and Yang Xiao and Zhiguo Cao",
keywords = "Local shape descriptor",
keywords = "Rotation",
keywords = "Contour signature",
keywords = "Binary representation",
keywords = "Feature matching ",
abstract = "Abstract This paper presents a rotational contour signatures (RCS) method for both real-valued and binary descriptions of 3D local shape. \{RCS\} comprises several signatures that characterize the 2D contour information derived from 3D-to-2D projection of the local point cloud. The inspiration of our encoding technique comes from that when viewing towards an object, its contour is an effective and robust cue for representing its shape. In order to achieve a comprehensive geometry encoding, the local surface is continually rotated in a predefined local reference frame (LRF) so that multi-view information is obtained. A peculiar trait of our \{RCS\} method is its seamless extension to binary representations to accelerate feature matching and reduce storage consumption. Specifically, we resort to three techniques, i.e., thresholding, quantization and geometrical binary encoding, to generate \{RCS\} binary strings. In contrast to 2D image area, there are quite rare 3D binary descriptors yet in 3D computer vision. We deploy experiments on three standard datasets including shape retrieval, 3D object recognition and 2.5D point cloud view matching scenarios with a rigorous comparison with six state-of-the-art descriptors. The comparative outcomes confirm numerous merits of our \{RCS\} method, e.g., highly discriminative, compact, computational efficient and robust to many nuisances including noise, mesh resolution variation, clutter and occlusion. We also show the versatility of \{RCS\} in matching of both LiDAR and Kinect point clouds. "
}
@article{Prakhya201740,
title = "Low Bit-rate 3D feature descriptors for depth data from Kinect-style sensors ",
journal = "Signal Processing: Image Communication ",
volume = "51",
number = "",
pages = "40 - 49",
year = "2017",
note = "",
issn = "0923-5965",
doi = "https://doi.org/10.1016/j.image.2016.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0923596516301734",
author = "Sai Manoj Prakhya and Weisi Lin and Vijay Chandrasekhar and Bingbing Liu and Jie Lin",
keywords = "3D feature descriptors",
keywords = "Compression",
keywords = "Lattice quantization",
keywords = "3D keypoint matching ",
abstract = "Abstract In applications that require an input point cloud to be matched with a set of database point clouds present on a remote server, it is preferable to compress and transfer 3D feature descriptors online, rather than compressing and transferring the whole input point cloud. This is because the former would require much lesser bandwidth and does not require feature extraction on the server. Existing real valued 3D feature descriptors that offer good keypoint matching performance require higher bandwidth for their transfer over the network. On the other hand, the existing binary 3D feature descriptor requires relatively less bandwidth but offers reduced keypoint matching performance. In this paper, we propose to employ lattice quantization to efficiently compress 3D feature descriptors. These compressed 3D feature descriptors can be directly matched in compressed domain without any need for decompression, hence drastically reducing the memory footprint and computational requirements. We also propose double stage lattice quantization to achieve even more compression in the case of \{SHOT\} 3D feature descriptor. We provide a spectrum of possible bit rates and achievable keypoint matching performance for three state-of-the-art 3D feature descriptors. Experimental evaluation on publicly available benchmark dataset highlights that the compressed 3D feature descriptors require much lesser bandwidth and yet offer good keypoint matching performance. The source code is made publicly available for the benefit of the community. "
}
@article{Wang2015517,
title = "Current status and advancement of cyber-physical systems in manufacturing ",
journal = "Journal of Manufacturing Systems ",
volume = "37, Part 2",
number = "",
pages = "517 - 527",
year = "2015",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2015.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0278612515000400",
author = "Lihui Wang and Martin Torngren and Mauro Onori",
abstract = "Abstract This paper presents the current status and the latest advancement of cyber-physical systems (CPS) in manufacturing. In order to understand \{CPS\} and its future potential in manufacturing, definitions and characteristics of \{CPS\} are explained and compared with cloud manufacturing concept. Research and applications are outlined to highlight the latest advancement in the field. \{CPS\} shows great promise in factories of the future in the areas of future trends as identified at the end of this paper. "
}
@article{Gemignani20161,
title = "Living with robots: Interactive environmental knowledge acquisition ",
journal = "Robotics and Autonomous Systems ",
volume = "78",
number = "",
pages = "1 - 16",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002468",
author = "Guglielmo Gemignani and Roberto Capobianco and Emanuele Bastianelli and Domenico Daniele Bloisi and Luca Iocchi and Daniele Nardi",
keywords = "Semantic mapping",
keywords = "Knowledge representation",
keywords = "Human–robot interaction ",
abstract = "Abstract Robots, in order to properly interact with people and effectively perform the requested tasks, should have a deep and specific knowledge of the environment they live in. Current capabilities of robotic platforms in understanding the surrounding environment and the assigned tasks are limited, despite the recent progress in robotic perception. Moreover, novel improvements in human–robot interaction support the view that robots should be regarded as intelligent agents that can request the help of the user to improve their knowledge and performance. In this paper, we present a novel approach to semantic mapping. Instead of requiring our robots to autonomously learn every possible aspect of the environment, we propose a shift in perspective, allowing non-expert users to shape robot knowledge through human–robot interaction. Thus, we present a fully operational prototype system that is able to incrementally and on-line build a rich and specific representation of the environment. Such a novel representation combines the metric information needed for navigation tasks with the symbolic information that conveys meaning to the elements of the environment and the objects therein. Thanks to such a representation, we are able to exploit multiple \{AI\} techniques to solve spatial referring expressions and support task execution. The proposed approach has been experimentally validated on different kinds of environments, by several users, and on multiple robotic platforms. "
}
@article{Potthast2014148,
title = "A probabilistic framework for next best view estimation in a cluttered environment ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "25",
number = "1",
pages = "148 - 164",
year = "2014",
note = "Visual Understanding and Applications with RGB-D Cameras ",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2013.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S1047320313001387",
author = "Christian Potthast and Gaurav S. Sukhatme",
keywords = "Next best view estimation",
keywords = "Sensor placement",
keywords = "Sensor planning",
keywords = "View planning",
keywords = "Robot exploration",
keywords = "3-D perception",
keywords = "Cluttered environments",
keywords = "Missing points ",
abstract = "Abstract In this article, we present an information gain-based variant of the next best view problem for occluded environment. Our proposed method utilizes a belief model of the unobserved space to estimate the expected information gain of each possible viewpoint. More precise, this belief model allows a more precise estimation of the visibility of occluded space and with that a more accurate prediction of the potential information gain of new viewing positions. We present experimental evaluation on a robotic platform for active data acquisition, however due to the generality of our approach it also applies to a wide variety of 3D reconstruction problems. With the evaluation done in simulation and on a real robotic platform, exploring and acquiring data from different environments we demonstrate the generality and usefulness of our approach for next best view estimation and autonomous data acquisition. "
}
@incollection{Sun2015341,
title = "Chapter 5.1 - The State of the Art in Grasping and Manipulation for Household Service ",
editor = "Xu, Yangsheng and Qian, Huihuan  and Wu, Xinyu ",
booktitle = "Household Service Robotics ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2015",
pages = "341 - 356",
isbn = "978-0-12-800881-2",
doi = "https://doi.org/10.1016/B978-0-12-800881-2.00016-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128008812000165",
author = "Yuandong Sun and Huihuan Qian and Yangsheng Xu",
keywords = "Control",
keywords = "Grasping and manipulation of objects",
keywords = "Planning",
keywords = "Target detection ",
abstract = "Abstract Robotic grasping and manipulation comprise three subtasks, i.e., target detection, planning, and control. The robot first needs to detect the target. Here “detect” means to find (or recognize) the target and locate it. The target could be the object to be manipulated (e.g., electrical plugs) or the destination of the object (electrical sockets). Then the robot approaches the target in an optimized trajectory. In the process of approaching and grasping, the robot should be controlled to perform the task correctly and smoothly. In this chapter, we review the approaches to accomplish these three subtasks, i.e., target detection, planning, and control. "
}
@article{Pire201727,
title = "S-PTAM: Stereo Parallel Tracking and Mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "93",
number = "",
pages = "27 - 42",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302955",
author = "Taihu Pire and Thomas Fischer and Gaston Castro and Pablo De Cristoforis and Javier Civera and Julio Jacobo Berlles",
keywords = "SLAM",
keywords = "Visual SLAM",
keywords = "Stereo SLAM",
keywords = "Stereo vision",
keywords = "Loop closure ",
abstract = "Abstract This paper describes a real-time feature-based stereo \{SLAM\} system that is robust and accurate in a wide variety of conditions – indoors, outdoors, with dynamic objects, changing light conditions, fast robot motions and large-scale loops. Our system follows a parallel-tracking-and-mapping strategy: a tracking thread estimates the camera pose at frame rate; and a mapping thread updates a keyframe-based map at a lower frequency. The stereo constraints of our system allow a robust initialization – avoiding the well-known bootstrapping problem in monocular systems–and the recovery of the real scale. Both aspects are essential for its practical use in real robotic systems that interact with the physical world. In this paper we provide the implementation details, an exhaustive evaluation of the system in public datasets and a comparison of most state-of-the-art feature detectors and descriptors on the presented system. For the benefit of the community, its code for \{ROS\} (Robot Operating System) has been released. "
}
@article{Mufti201216,
title = "Robust estimation of planar surfaces using spatio-temporal \{RANSAC\} for applications in autonomous vehicle navigation ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "1",
pages = "16 - 28",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001606",
author = "Faisal Mufti and Robert Mahony and Jochen Heinzmann",
keywords = "RANSAC",
keywords = "Time-of-flight cameras",
keywords = "Robustness",
keywords = "Navigation",
keywords = "Detection",
keywords = "Ground plane",
keywords = "Segmentation",
keywords = "Obstacle avoidance ",
abstract = "A fundamental problem in autonomous vehicle navigation is the identification of obstacle free space in cluttered and unstructured environments. Features such as walls, people, furniture, doors and stairs, etc are potential hazards. The approach taken in this paper is motivated by the recent development on infra-red time-of-flight cameras that provide video frame rate low resolution depth maps. We propose to exploit the temporal information content provided by the high refresh rate of such cameras to overcome the limitations due to low spatial resolution and high depth uncertainty and aim to provide robust and accurate estimates of planar surfaces in the environment. These surfaces’ estimates are then used to provide statistical tests to identify obstacles and dangers in the environment. Classical 3D spatial \{RANSAC\} is extended to 4D spatio-temporal \{RANSAC\} by developing spatio-temporal models of planar surfaces that incorporate a linear motion model as well as linear environment features. A 4D-vector product is used for hypotheses generation from data that is randomly sampled across both spatial and temporal variations. The algorithm is fully posed in the spatio-temporal representation and there is no need to correlate points or hypothesis between temporal images. The proposed algorithm is computationally fast and robust for estimation of planar surfaces in general and the ground plane in particular. There are potential applications in mobile robotics, autonomous vehicular navigation, and automotive safety systems. The claims of the paper are supported by experimental results obtained from real video data for a time-of-flight range sensor mounted on an automobile navigating in an undercover parking lot. "
}
@article{Stenmark20143056,
title = "Describing constraint-based assembly tasks in unstructured natural language ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "3056 - 3061",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02062",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016420768",
author = "Maj Stenmark and Jacek Malec",
keywords = "Robot programming",
keywords = "natural language",
keywords = "assembly",
keywords = "knowledge-based engineering ",
abstract = "Abstract Task-level industrial robot programming is a mundane, error-prone activity requiring expertise and skill. Since humans easily communicate with natural language (NL), it may be attractive to use speech or text as instruction means for robots. However, there has to be a substantial amount of knowledge in the system to translate the high-level language instructions to executable robot programs. In this paper, the method of Stenmark and Nugues (2013) for natural language programming of robotized assembly tasks is extended. The core idea of the method is to use a generic semantic parser to produce a set of predicate-argument structures from the input sentences. The algorithm presented here facilitates extraction of more complicated, advanced task instructions involving cardinalities, conditionals, parallelism and constraint-bounded programs, besides plain sequences of commands. The bottleneck of this approach is the availability of easily parametrizable robotic skills and functionalities in the system, rather than the natural language understanding by itself. "
}
@article{Holz2015318,
title = "Registration of non-uniform density 3D laser scans for mapping with micro aerial vehicles ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "318 - 330",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.07.021",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001682",
author = "Dirk Holz and Sven Behnke",
keywords = "Mapping",
keywords = "Registration",
keywords = "Micro aerial vehicles",
keywords = "Approximate surface reconstruction",
keywords = "Generalized-ICP ",
abstract = "Abstract Micro aerial vehicles (MAVs) pose specific constraints on onboard sensing, mainly limited payload and limited processing power. For accurate 3D mapping even in GPS-denied environments, we have designed a lightweight 3D laser scanner specifically for the application on MAVs. Similar to other custom-built 3D laser scanners composed of a rotating 2D laser range finder, it exhibits different point densities within and between individual scan lines. When rotated fast, such non-uniform point densities influence neighborhood searches which in turn may negatively affect local feature estimation and scan registration. We present a complete pipeline for 3D mapping including pair-wise registration and global alignment of such non-uniform density 3D point clouds acquired in-flight. For registration, we extend a state-of-the-art registration algorithm to include topological information from approximate surface reconstructions. For global alignment, we use a graph-based approach making use of the same error metric and iteratively refine the complete vehicle trajectory. In experiments, we show that our approach can compensate for the effects caused by different point densities up to very low angular resolutions and that we can build accurate and consistent 3D maps in-flight with a micro aerial vehicle. "
}
@article{Trama200896,
title = "Rapid detection of Atopobium vaginae and association with organisms implicated in bacterial vaginosis ",
journal = "Molecular and Cellular Probes ",
volume = "22",
number = "2",
pages = "96 - 102",
year = "2008",
note = "",
issn = "0890-8508",
doi = "https://doi.org/10.1016/j.mcp.2007.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0890850807000631",
author = "Jason P. Trama and Kristen E. Pascal and Jessica Zimmerman and Matthew J. Self and Eli Mordechai and Martin E. Adelson",
keywords = "Atopobium vaginae",
keywords = "Gardnerella vaginalis",
keywords = "Bacterial vaginosis",
keywords = "Real-time PCR",
keywords = "DNA extraction and \{PCR\} automation ",
abstract = "Atopobium vaginae, a fastidious, anaerobic, Gram-positive cocci-shaped bacterium that generates large quantities of lactic acid, is associated with bacterial vaginosis (BV). Published nucleic acid amplification tests for identifying A. vaginae are directed toward the 16S ribosomal \{DNA\} with suboptimal specificity and require isolation of the organism. Here, sequencing of an A. vaginae genomic library has led to the development of a highly specific and sensitive real-time \{PCR\} test for detection of A. vaginae directly from gynecological cervicovaginal swab samples. The real-time \{PCR\} did not cross-react with \{DNA\} extracted from other members of the Atopobium genus, species with closely related 16S ribosomal DNA, and a panel of 51 other human pathogens. The \{DNA\} extraction and \{PCR\} assembly were amenable to automation using Corbett Robotics X-tractor Gene and CAS-4200N liquid handling systems. The real-time \{PCR\} was used to analyze 96 cervicovaginal swab samples submitted to our clinical laboratory for detection of organisms associated with BV. Of those samples, 28 were positive for A. vaginae. Of the 28 positive samples, 23 were concomitant with Gardnerella vaginalis detection. These results suggest that further clinical study of the relationship of A. vaginae with G. vaginalis and the development of \{BV\} should be performed. "
}
@article{Fischinger2012787,
title = "Shape based Learning for Grasping Novel Objects in Cluttered Scenes ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "787 - 792",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00176",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016337053",
author = "David Fischinger and Markus Vincze",
keywords = "Manipulation tasks",
keywords = "Grasping",
keywords = "Learning algorithms ",
abstract = "Abstract This paper presents a novel approach to clearing a table with a heap of objects. Form, size, position, orientation and constellation of the objects are a priori unknown. Coping with incomplete point cloud data is an additional challenge. There are three key contributions. First, we introduce Height Accumulated Features (HAF) which provide an efficient way of calculating grasp related feature values. The second contribution is an extensible machine learning system for binary classification of grasp hypotheses based on raw point cloud data. Finally, a practical heuristic for selection of the most robust grasp hypothesis is introduced. We evaluate our system in experiments where a robot was required to autonomously clear a table with a heap of unknown objects. Despite the complexity of the scenarios, our system cleared the table each time without human interaction and with a grasp failure rate below three percent. "
}
@article{Delmerico2013841,
title = "Building facade detection, segmentation, and parameter estimation for mobile robot stereo vision ",
journal = "Image and Vision Computing ",
volume = "31",
number = "11",
pages = "841 - 852",
year = "2013",
note = "",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2013.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0262885613001327",
author = "Jeffrey A. Delmerico and Philip David and Jason J. Corso",
keywords = "Stereo vision",
keywords = "Mobile robot perception",
keywords = "Hierarchical Markov random field",
keywords = "Building facade detection",
keywords = "Model-based stereo vision ",
abstract = "Abstract Building facade detection is an important problem in computer vision, with applications in mobile robotics and semantic scene understanding. In particular, mobile platform localization and guidance in urban environments can be enabled with accurate models of the various building facades in a scene. Toward that end, we present a system for detection, segmentation, and parameter estimation of building facades in stereo imagery. The proposed method incorporates multilevel appearance and disparity features in a binary discriminative model, and generates a set of candidate planes by sampling and clustering points from the image with Random Sample Consensus (RANSAC), using local normal estimates derived from Principal Component Analysis (PCA) to inform the planar models. These two models are incorporated into a two-layer Markov Random Field (MRF): an appearance- and disparity-based discriminative classifier at the mid-level, and a geometric model to segment the building pixels into facades at the high-level. By using object-specific stereo features, our discriminative classifier is able to achieve substantially higher accuracy than standard boosting or modeling with only appearance-based features. Furthermore, the results of our \{MRF\} classification indicate a strong improvement in accuracy for the binary building detection problem and the labeled planar surface models provide a good approximation to the ground truth planes. "
}
@article{Kordelas20103833,
title = "Viewpoint independent object recognition in cluttered scenes exploiting ray-triangle intersection and \{SIFT\} algorithms ",
journal = "Pattern Recognition ",
volume = "43",
number = "11",
pages = "3833 - 3845",
year = "2010",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2010.05.030",
url = "http://www.sciencedirect.com/science/article/pii/S003132031000258X",
author = "Georgios Kordelas and Petros Daras",
keywords = "3D object recognition",
keywords = "Distance maps",
keywords = "Ray-triangle intersection",
keywords = "Clutter",
keywords = "Occlusion ",
abstract = "Viewpoint independent recognition of free-form objects and estimation of their exact position are a complex procedure with applications in robotics, artificial intelligence, computer vision and many other scientific fields. In this paper a novel approach is presented that addresses recognition of objects lying in highly cluttered and occluded scenes. The proposed procedure relies on distance maps, which are extracted and stored off-line for each of the 3D objects that might be contained in the scene. During the on-line recognition procedure distance maps are extracted from the scene. Greyscale images, derived from scene's distance maps, are matched with those of the object under recognition by applying similarity measures to the descriptors that are extracted from the images. The similarity is then estimated from image patches, which are defined using the \{SIFT\} descriptor in an appropriate way. After finding the best similarities the position of the object in the scene is estimated. This process is repeated until all objects are successfully recognized. Multiple experiments, which were performed on both 2.5D synthetic and real scenes, proved that the proposed method is robust and highly efficient to a satisfactory degree of occlusion and clutter. "
}
@incollection{Burke20141205,
title = "Chapter 56 - Planetary Exploration Missions ",
editor = "Spohn, Tilman and Breuer, Doris  and Johnson, Torrence V. ",
booktitle = "Encyclopedia of the Solar System (Third Edition) ",
publisher = "Elsevier",
edition = "Third Edition",
address = "Boston",
year = "2014",
pages = "1205 - 1222",
isbn = "978-0-12-415845-0",
doi = "https://doi.org/10.1016/B978-0-12-415845-0.00056-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780124158450000566",
author = "James D. Burke",
keywords = "Lunar",
keywords = "Planetary",
keywords = "Exploration",
keywords = "Missions ",
abstract = "Abstract This chapter briefly reviews lunar and planetary missions that succeeded in returning data in accord with their objectives. The grand adventure of deep-space exploration, robotic and human, began with the flight of Luna 1, Mechta (dream) launched in 1959. By the beginning of 2014, all of the Sun's planets and many moons had been visited by robot spacecraft, and Voyager 1 had reached the heliosphere boundary and was entering interstellar space. "
}
@article{Tariq2015969,
title = "Analysis of optical and physical properties of aerosols during crop residue burning event of October 2010 over Lahore, Pakistan ",
journal = "Atmospheric Pollution Research ",
volume = "6",
number = "6",
pages = "969 - 978",
year = "2015",
note = "",
issn = "1309-1042",
doi = "https://doi.org/10.1016/j.apr.2015.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1309104215000082",
author = "Salman Tariq and Zia ul-Haq and Muhammad Ali",
keywords = "Crop residue burning",
keywords = "AERONET",
keywords = "Aerosol properties",
keywords = "Lahore ",
abstract = "Abstract Aerosols released from biomass burning affect the tropospheric chemistry, radiation budget and cloud processes and hence can cause significant climate modifications. Due to certain economical reasons, the open burning of crop residue has become popular in Pakistan. In the present work we have analyzed the optical and physical properties of aerosols during crop residue burning over Lahore, a central location of Pakistan. The data from ground based Aerosol Robotic Network (AERONET), satellite based \{MODIS\} and \{CALIPSO\} remote sensing instruments have been used for the characterization of aerosols during crop residue burning event of October 2010. The maximum value (2.75) of daily mean \{AOD\} was observed on 20 October 2010 and the next highest value of 2.64 was observed on 19 October 2010, indicating heavy aerosol loading over Lahore on both days due to intense crop residue burning. The fine mode \{AOD\} values ranged from 0.14 to 2.68 (on 20 October 2010) with average value of 0.87 during October 2010 over Lahore. It was found that fine mode aerosols have greater contribution than coarse mode aerosols towards total aerosol burden indicating the presence of fine mode (crop residue burning) aerosols over Lahore. Cluster analysis showed that the mixed aerosols (biomass burning and urban-industrial) were present during the heavy aerosol loading period over Lahore. The highest volume concentration of fine mode occurred on 19 and 20 October 2010 representing the dominance of fine mode aerosols. Due to scattering of incoming solar radiation by intense smoke observed on 19 and 20 October 2010 high values of \{SSA\} (∼0.95) were found. \{HYSPLIT\} model backward trajectories showed that the winds transported aerosols from southeast and northwest directions. "
}
@article{Caruso2017174,
title = "Microsoft Kinect \{V2\} vision system in a manufacturing application ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "174 - 181",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516304082",
author = "L. Caruso and R. Russo and S. Savino",
keywords = "Microsoft kinect",
keywords = "Vision systems",
keywords = "Manufacturing robots ",
abstract = "Abstract In this paper an application for the Kinect \{V2\} sensor is described in the robotic field. The sensor is used as a vision device for detecting position, shape and dimensions of an object on the working space of a robot in order to planning the end effector path. The algorithms used for the recognition of contour and spatial position of planar shapes are described. The technique adopted for the recognition of 3D objects are presented. The first results provided by a prototype of gluing robot for the bonding of leather patches and shoe soles are presented. The results confirm the possibility of using the Kinect \{V2\} sensor as an alternative to the well consolidated 3D measuring devices which are definitely more accurate, but also much more expensive. "
}
@article{Brenner20084,
title = "Coarse orientation of terrestrial laser scans in urban environments ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "63",
number = "1",
pages = "4 - 18",
year = "2008",
note = "Theme Issue: Terrestrial Laser Scanning ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2007.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0924271607000457",
author = "C. Brenner and C. Dold and N. Ripperda",
keywords = "Terrestrial laser scanning",
keywords = "Orientation",
keywords = "Registration",
keywords = "Coarse alignment",
keywords = "Initial values ",
abstract = "The use of terrestrial laser scanners is becoming increasingly popular. For the acquisition of larger scenes, it is usually necessary to align all scans to a common reference frame. While there are methods using direct measurement of the orientation, due to simplicity and costs, mostly artificial targets are used. This works reliably, but usually adds a substantial amount of time to the acquisition process. Methods to align scans using the scan data itself have been known for a long time, however, being iterative, they need good initial values. In this paper, we investigate two different methods targeted at the determination of suitable initial values. The first one is based on a symbolic approach, using corresponding features to compute the orientation. The second one is based on an iterative alignment scheme originally proposed in the robotics domain. To assess the performance of both methods, a set of 20 scans has been acquired systematically along a trajectory in a downtown area. Reference orientations were obtained by a standard procedure using artificial targets. We present the results of both methods regarding convergence and accuracy, and compare their performance. "
}
@article{Chen20161,
title = "Analyzing and visual programming internet of things and autonomous decentralized systems ",
journal = "Simulation Modelling Practice and Theory ",
volume = "65",
number = "",
pages = "1 - 10",
year = "2016",
note = "Analyzing and Visual Programming Internet of Things ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X16301800",
author = "Yinong Chen",
keywords = "Internet of Things",
keywords = "autonomous decentralized system",
keywords = "Visual programming",
keywords = "IoT education ",
abstract = "Abstract The development of Internet of Things, fueled by cloud computing and big data processing from upper level, and by ubiquitous sensory and actuator devices from the lower level, has taken a sharp turn towards integrating the entire information, computing, communication, and control systems. This special issue selected seven papers from the 2015 \{IEEE\} twelfth International Symposium on Autonomous Decentralized Systems (ISADS). These papers cover the latest research on IoT and \{ADS\} based system science and system engineering methods; the wearable sensor network development and applications; and data analysis for security and reliability in IoT and \{ADS\} applications. As an addition to these selected topics, this guest editorial paper also adds IoT education and dissemination aspects to this special issue. As the IoT research and applications expand explosively into all the domains, schools and universities must prepare students to understand and to be able to program the IoT devices. This paper presents a visual programming environment that allows students without programming background to learn the key concepts of computing and IoT devices, and to program IoT devices into different application systems. "
}
@article{Wan2017,
title = "Teaching robots to do object assembly using multi-modal 3D vision ",
journal = "Neurocomputing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.01.077",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217302497",
author = "Weiwei Wan and Feng Lu and Zepei Wu and Kensuke Harada",
keywords = "3D visual detection",
keywords = "Robot manipulation",
keywords = "Motion planning ",
abstract = "Abstract The motivation of this paper is to develop an intelligent robot assembly system using multi-modal vision for next-generation industrial assembly. The system includes two phases where in the first phase human beings demonstrate assembly to robots and in the second phase robots detect objects, plan grasps, and assemble objects following human demonstration using \{AI\} searching. A notorious difficulty to implement such a system is the bad precision of 3D visual detection. This paper presents multi-modal approaches to overcome the difficulty: It uses \{AR\} markers in the teaching phase to detect human operation, and uses point clouds and geometric constraints in the robot execution phase to avoid unexpected occlusion and noises. The paper presents several experiments to examine the precision and correctness of the approaches. It demonstrates the applicability of the approaches by integrating them with graph model-based motion planning, and by executing the results on industrial robots in real-world scenarios. "
}
@article{Beegum2016185,
title = "Simulating aerosols over Arabian Peninsula with CHIMERE: Sensitivity to soil, surface parameters and anthropogenic emission inventories ",
journal = "Atmospheric Environment ",
volume = "128",
number = "",
pages = "185 - 197",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016300188",
author = "S. Naseema Beegum and Imen Gherboudj and Naira Chaouch and Florian Couvidat and Laurent Menut and Hosni Ghedira",
keywords = "CHIMERE",
keywords = "Chemistry transport model",
keywords = "Aerosol optical depth",
keywords = "EDGAR-HTAP emissions",
keywords = "Surface roughness length",
keywords = "Soil erodibility ",
abstract = "Abstract A three dimensional chemistry transport model, CHIMERE, was used to simulate the aerosol optical depths (AOD) over the Arabian Peninsula desert with an offline coupling of Weather Research and Forecasting (WRF) model. The simulations were undertaken with: (i) different horizontal and vertical configurations, (ii) new datasets derived for soil/surface properties, and (iii) EDGAR-HTAP anthropogenic emissions inventories. The model performance evaluations were assessed: (i) qualitatively using \{MODIS\} (Moderate-Resolution Imaging Spectroradiometer) deep blue (DB) \{AOD\} data for the two local dust events of August 6th and 23rd (2013), and (ii) quantitatively using \{AERONET\} (Aerosol Robotic Network) \{AOD\} observations, \{CALIPSO\} (Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation) aerosol extinction profiles, and \{AOD\} simulations from various forecast models. The model results were observed to be highly sensitive to erodibility and aerodynamic surface roughness length. The use of new datasets on soil erodibility, derived from the \{MODIS\} reflectance, and aerodynamic surface roughness length (z0), derived from the ERA-Interim datasets, significantly improved the simulation results. Simulations with the global EDGAR-HTAP anthropogenic emission inventories brought the simulated \{AOD\} values closer to the observations. Performance testing of the adapted model for the Arabian Peninsula domain with improved datasets showed good agreement between \{AERONET\} \{AOD\} measurements and \{CHIMERE\} simulations, where the correlation coefficient (R) is 0.6. Higher values of the correlation coefficients and slopes were observed for the dusty periods compared to the non-dusty periods. "
}
@article{Ananyevskiy2015691,
title = "Control over Internet with timecheck denial gain∗ ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "11",
pages = "691 - 693",
year = "2015",
note = "1st \{IFAC\} Conference onModelling, Identification andControl of Nonlinear SystemsMICNON 2015Saint Petersburg, Russia, 24-26 June 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.09.268",
url = "http://www.sciencedirect.com/science/article/pii/S240589631501349X",
author = "Mikhail S. Ananyevskiy",
keywords = "control over Internet",
keywords = "control with delays",
keywords = "random delays ",
abstract = "Abstract The problem of control over Internet is discussed. It is presented some statistic data of delays obtained from experiments with hardware of Cloud mechatronic laboratory (http://cmlaboratory.com). New algorithm for regulator design is proposed. It consists of remote regulator and local timecheck denial gain. This gain denied control pulse if it comes with too large delay. Some analytic results for a very simple discrete system are presented. "
}
@article{Bohan2017,
title = "Next-Generation Global Biomonitoring: Large-scale, Automated Reconstruction of Ecological Networks ",
journal = "Trends in Ecology & Evolution ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0169-5347",
doi = "https://doi.org/10.1016/j.tree.2017.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169534717300605",
author = "David A. Bohan and Corinne Vacher and Alireza Tamaddoni-Nezhad and Alan Raybould and Alex J. Dumbrell and Guy Woodward",
abstract = "We foresee a new global-scale, ecological approach to biomonitoring emerging within the next decade that can detect ecosystem change accurately, cheaply, and generically. Next-generation sequencing of \{DNA\} sampled from the Earth’s environments would provide data for the relative abundance of operational taxonomic units or ecological functions. Machine-learning methods would then be used to reconstruct the ecological networks of interactions implicit in the raw \{NGS\} data. Ultimately, we envision the development of autonomous samplers that would sample nucleic acids and upload \{NGS\} sequence data to the cloud for network reconstruction. Large numbers of these samplers, in a global array, would allow sensitive automated biomonitoring of the Earth’s major ecosystems at high spatial and temporal resolution, revolutionising our understanding of ecosystem change. "
}
@article{Dirafzoon201779,
title = "A framework for mapping with biobotic insect networks: From local to global maps ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "79 - 96",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S092188901530289X",
author = "Alireza Dirafzoon and Alper Bozkurt and Edgar Lobaton",
keywords = "Topological mapping",
keywords = "Metric estimation",
keywords = "Manifold learning",
keywords = "Cyborg insects",
keywords = "Topological data analysis",
keywords = "Emergency response ",
abstract = "Abstract We present an approach for global exploration and mapping of unknown environments using a swarm of cyborg insects, known as biobots, for emergency response scenarios under minimal sensing and localization constraints. We exploit natural stochastic motion models and controlled locomotion of biobots in conjunction with an aerial leader to explore and map a domain of interest. A sliding window strategy is adopted to construct local maps from coordinate free encounter information of the agents by means of local metric estimation. Robust topological features from these local representations are extracted using topological data analysis and a classification scheme. These maps are then merged into a global map which can be visualized using a graphical representation, that integrates geometric as well as topological features of the environment. Simulation and experimental results with biologically inspired robotic platform are presented to illustrate and verify the correctness of our approach, which provides building blocks for \{SLAM\} with biobotic insects. "
}
@article{Dobkin1985381,
title = "A linear algorithm for determining the separation of convex polyhedra ",
journal = "Journal of Algorithms ",
volume = "6",
number = "3",
pages = "381 - 392",
year = "1985",
note = "",
issn = "0196-6774",
doi = "https://doi.org/10.1016/0196-6774(85)90007-0",
url = "http://www.sciencedirect.com/science/article/pii/0196677485900070",
author = "David P Dobkin and David G Kirkpatrick",
abstract = "The separation of two convex polyhedra is defined to be the minimum distance from a point (not necessarily an extreme point) of one to a point of the other. A linear time algorithm is presented for constructing a pair of points that realize the separation of two convex polyhedra in three dimensions. This algorithm is based on a simple hierarchical description of polyhedra that is of interest in its own right. The result provides a linear algorithm for detecting the intersection of convex polyhedra. Separation and intersection detection algorithms have applications in clustering, the intersection of half-spaces, linear programming, and robotics. "
}
@article{Chen2016350,
title = "Building change detection with RGB-D map generated from \{UAV\} images ",
journal = "Neurocomputing ",
volume = "208",
number = "",
pages = "350 - 364",
year = "2016",
note = "SI: BridgingSemantic ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.11.118",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216304866",
author = "Baohua Chen and Zhixiang Chen and Lei Deng and Yueqi Duan and Jie Zhou",
keywords = "Building change detection",
keywords = "3D reconstruction",
keywords = "Coarse-to-fine registration",
keywords = "UAV aerial image ",
abstract = "Abstract Automatic change detection for urban buildings is very important for disaster assessment, map updating, etc. Height and color information is commonly used for change detection and existing methods use height information from 3D geometry model (e.g. Digital Surface Model, Geographic Information System) and color information from radiometric images captured by satellites or special aircrafts. However, they are either costly for timely change detection or sensitive to large illumination changes. With the rapid development of \{UAV\} technique, capturing the urban building images with high resolution camera at a low altitude becomes easier. In order to utilize these easily acquired aerial images, we propose a novel change detection framework with RGB-D map generated by 3D reconstruction, which can bear the large illumination change. Firstly, an image-based 3D reconstruction is applied to retrieve two point clouds and their related camera poses from two aerial image sets captured at different periods. Then, a RGB-D map could be generated from each 3D model, followed by a coarse-to-fine registration procedure to align the two reconstructed 3D point clouds together. At last, depth difference map and grayscale difference map could be generated from which we can use random forest classification and component connectivity analysis techniques to segment the changed building areas out. Experimental results have illustrated the effectiveness and applicability of the proposed framework. "
}
@article{Woods20061390,
title = "Exploring the design space of robots: Children's perspectives ",
journal = "Interacting with Computers ",
volume = "18",
number = "6",
pages = "1390 - 1418",
year = "2006",
note = "Special Issue: Symbiotic Performance between Humans and Intelligent Systems ",
issn = "0953-5438",
doi = "https://doi.org/10.1016/j.intcom.2006.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S095354380600066X",
author = "Sarah Woods",
keywords = "Robots",
keywords = "Child evaluations",
keywords = "Attitudes",
keywords = "Personality",
keywords = "Emotions",
keywords = "Uncanny valley ",
abstract = "Children's perceptions and evaluations of different robot designs are an important unexplored area within robotics research considering that many robots are specifically designed for children. To examine children's feelings and attitudes towards robots, a large sample of children (N = 159) evaluated 40 robot images by completing a questionnaire for each image, which enquired about robot appearance, robot personality dimensions and robot emotions. Results showed that depending on a robot's appearance children clearly distinguished robots in terms of their intentions (i.e. friendly vs. unfriendly), their capability to understand, and their emotional expression. Results of a principal components analysis of the children's ratings of the robots' personality attributes revealed two dimensions labelled ‘Behavioural Intention’ and ‘Emotional Expression’. Robots were classified according to their scores on these two dimensions and a content analysis of their appearance was conducted in an attempt to identify salient features of different robot personalities. Children judged human-like robots as aggressive, but human–machine robots as friendly. Results on children's perceptions of the robots' behavioural intentions provided tentative empirical support for the Uncanny Valley, hypothesized by (Mori, M., 1970), reflecting a situation where robots are very human-like, but still distinguishable from humans, evoking a feeling of discomfort or repulsion. The paper concludes with a discussion of design implications for robots, and the use of robots in educational contexts. "
}
@incollection{Anwar2017531,
title = "Chapter Eight - Software Development and Application for the Analysis of Cross-Sections ",
editor = "Anwar, Naveed  and Najam, Fawad Ahmed ",
booktitle = "Structural Cross Sections ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2017",
pages = "531 - 564",
isbn = "978-0-12-804443-8",
doi = "https://doi.org/10.1016/B978-0-12-804443-8.00008-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128044438000087",
author = "Naveed Anwar and Fawad Ahmed Najam",
keywords = "Software development",
keywords = "CSiCOL",
keywords = "mobile applications",
keywords = "computer software",
keywords = "CAD/CAE ",
abstract = "Abstract This chapter deals with computer-aided analysis of cross-sections. It provides an overview of various software applications available for cross-section design and analysis. A framework for the development of a general-purpose cross-section analysis software (based on theoretical formulations developed in Chapters 2 and 3) is presented. A brief introduction of \{CSiCOL\} (a comprehensive software package for the analysis and design of reinforced and composite column sections) is also included. This chapter also introduces various new ideas and scopes related to the development of mobile applications for structural analysis on both Android and iOS platforms. Various applications of cloud computing and component-based software engineering in analysis and design of structures are also introduced. "
}
@article{BenlarbiDelai1995239,
title = "Telemetric sensors by microwave interferometry ",
journal = "Sensors and Actuators A: Physical ",
volume = "46",
number = "1–3",
pages = "239 - 243",
year = "1995",
note = "",
issn = "0924-4247",
doi = "https://doi.org/10.1016/0924-4247(94)00897-Q",
url = "http://www.sciencedirect.com/science/article/pii/092442479400897Q",
author = "A. Benlarbi-Delai and J.P. Covillers and Y. Leroy",
keywords = "Anti-collision processes",
keywords = "Localisation",
keywords = "Microwave interferometry",
keywords = "Telemetric sensors ",
abstract = "This paper presents some possibilities offered by a specific microwave sensor called an I-Q demodulator or complex correlator. It is shown that this narrow-band complex correlator is able to provide information about the velocity profile and the position of a monochromatic transmitter which is inside a predefined area; this situation is qualified as cooperative configuration. Nevertheless, this complex correlator can also be used in the situation where only reflected signals are considered — non cooperative configuration — such as in anticollision and level measurement processes. Such sensors can naturally be used in many industrial application fields like robotics, tank gauging and berthing aid. Therefore, to answer industrial requirements, we show in this paper that the necessary compromise between good performance and low cost can be reached. "
}
@article{Thomas1999207,
title = "Are theories of imagery theories of imagination?: An active perception approach to conscious mental content ",
journal = "Cognitive Science ",
volume = "23",
number = "2",
pages = "207 - 245",
year = "1999",
note = "",
issn = "0364-0213",
doi = "https://doi.org/10.1016/S0364-0213(99)00004-X",
url = "http://www.sciencedirect.com/science/article/pii/S036402139900004X",
author = "Nigel J.T Thomas",
abstract = "Can theories of mental imagery, conscious mental contents, developed within cognitive science throw light on the obscure (but culturally very significant) concept of imagination? Three extant views of mental imagery are considered: quasi-pictorial, description, and perceptual activity theories. The first two face serious theoretical and empirical difficulties. The third is (for historically contingent reasons) little known, theoretically underdeveloped, and empirically untried, but has real explanatory potential. It rejects the “traditional” symbolic computational view of mental contents, but is compatible with recent situated cognition and active vision approaches in robotics. This theory is developed and elucidated. Three related key aspects of imagination (non-discursiveness, creativity, and seeing as) raise difficulties for the other theories. Perceptual activity theory presents imagery as non-discursive and relates it closely to seeing as. It is thus well placed to be the basis for a general theory of imagination and its role in creative thought. "
}
@article{Kurazume201725,
title = "Automatic large-scale three dimensional modeling using cooperative multiple robots ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "25 - 42",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300558",
author = "Ryo Kurazume and Souichiro Oshima and Shingo Nagakura and Yongjin Jeong and Yumi Iwashita",
keywords = "Laser measurement",
keywords = "Multiple robots",
keywords = "3D modeling",
keywords = "Automatic sensing planning ",
abstract = "Abstract 3D modeling of real objects by a 3D laser scanner has become popular in many applications, such as reverse engineering of petrochemical plants, civil engineering and construction, and digital preservation of cultural properties. Despite the development of lightweight and high-speed laser scanners, the complicated measurement procedure and long measurement time are still heavy burdens for widespread use of laser scanning. To solve these problems, a robotic 3D scanning system using multiple robots has been proposed. This system, named CPS-SLAM, consists of a parent robot with a 3D laser scanner and child robots with target markers. A large-scale 3D model is acquired by an on-board 3D laser scanner on the parent robot from several positions determined precisely by a localization technique, named the Cooperative Positioning System (CPS), that uses multiple robots. Therefore, this system can build a 3D model without complicated post-processing procedures such as ICP. In addition, this system is an open-loop \{SLAM\} system and a very precise 3D model can be obtained without closed loops. This paper proposes an automatic planning technique for a laser measurement by using CPS-SLAM. Planning a proper scanning strategy depending on a target structure makes it possible to perform laser scanning efficiently and accurately even for a large-scale and complex environment. The proposed technique plans an efficient scanning strategy automatically by taking account of several criteria, such as visibility between robots, error accumulation, and efficient traveling. We conducted computer simulations and outdoor experiments to verify the performance of the proposed technique. "
}
@article{Shi2017130,
title = "Synergy of \{MODIS\} and \{AATSR\} for better retrieval of aerosol optical depth and land surface directional reflectance ",
journal = "Remote Sensing of Environment ",
volume = "195",
number = "",
pages = "130 - 141",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.04.010",
url = "http://www.sciencedirect.com/science/article/pii/S0034425717301608",
author = "Shuaiyi Shi and Tianhai Cheng and Xingfa Gu and Hao Chen and Hong Guo and Ying Wang and Fangwen Bao and Binren Xu and Wannan Wang and Xin Zuo and Can Meng and Xiaochuan Zhang",
keywords = "AATSR",
keywords = "AOD",
keywords = "BRDF",
keywords = "Individual swath retrieval",
keywords = "Gradient optimization method",
keywords = "Remote sensing ",
abstract = "Abstract This paper presents a new algorithm to simultaneously retrieve Aerosol Optical Depth (AOD) and land surface Bidirectional Reflectance Distribution Function (BRDF) from Advanced Along-Track Scanning Radiometer (AATSR) by adopting gradient optimization method. Different from traditional method the approach presented here can perform simultaneous retrieval from each individual \{AATSR\} swath rather than multiple days. A theoretical sensitivity study proves the proposed method is insensitive to the distortion of initial BRDF. The presented algorithm is tested on \{AATSR\} data around four different Aerosol Robotic Network (AERONET) sites representing various types of land surface. Compared with the four selected \{AERONET\} sites' \{AOD\} and BRDF-derived albedo from AERONET-based Surface Reflectance Validation Network (ASRVN) data in corresponding four \{AERONET\} sites, the presented algorithm proves considerable accuracy for various type of land surface with correlation of \{AOD\} ranging from 0.647 to 0.911 and correlation of BRDF-derived albedo ranging from 0.483 to 0.944. The intersensor comparison with Moderate Resolution Imaging Spectroradiometer (MODIS) 3 km \{AOD\} dark target product reveals high coverage rate of the presented method especially in bright surface or nonvegetation area and the correlation between the two sensors reaches up to 0.967. The improved estimation of \{BRDF\} from \{AATSR\} retrieval in \{AERONET\} Beijing site is compared with \{MODIS\} \{MCD43B1\} product. The relative differences in hemispherical albedo calculated from average \{BRDF\} shape function parameters between \{AATSR\} and \{MODIS\} product are 1.33%, 1.52%, 2.60% and 4.28% at 550 nm, 670 nm, 870 nm and 1600 nm respectively. "
}
@article{Sun20131190,
title = "Object detection, shape recovery, and 3D modelling by depth-encoded hough voting ",
journal = "Computer Vision and Image Understanding ",
volume = "117",
number = "9",
pages = "1190 - 1202",
year = "2013",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1077314213000969",
author = "Min Sun and Shyam Sunder Kumar and Gary Bradski and Silvio Savarese",
keywords = "Object recognition",
keywords = "Object detection",
keywords = "Viewpoint estimation",
keywords = "Shape recovery",
keywords = "3D reconstruction",
keywords = "Shape completion",
keywords = "Texture completion ",
abstract = "Abstract Detecting objects, estimating their pose, and recovering their 3D shape are critical problems in many vision and robotics applications. This paper addresses the above needs using a two stages approach. In the first stage, we propose a new method called \{DEHV\} – Depth-Encoded Hough Voting. \{DEHV\} jointly detects objects, infers their categories, estimates their pose, and infers/decodes objects depth maps from either a single image (when no depth maps are available in testing) or a single image augmented with depth map (when this is available in testing). Inspired by the Hough voting scheme introduced in [1], \{DEHV\} incorporates depth information into the process of learning distributions of image features (patches) representing an object category. \{DEHV\} takes advantage of the interplay between the scale of each object patch in the image and its distance (depth) from the corresponding physical patch attached to the 3D object. Once the depth map is given, a full reconstruction is achieved in a second (3D modelling) stage, where modified or state-of-the-art 3D shape and texture completion techniques are used to recover the complete 3D model. Extensive quantitative and qualitative experimental analysis on existing datasets [2–4] and a newly proposed 3D table-top object category dataset shows that our \{DEHV\} scheme obtains competitive detection and pose estimation results. Finally, the quality of 3D modelling in terms of both shape completion and texture completion is evaluated on a 3D modelling dataset containing both in-door and out-door object categories. We demonstrate that our overall algorithm can obtain convincing 3D shape reconstruction from just one single uncalibrated image. "
}
@article{Roca2013128,
title = "Low-cost aerial unit for outdoor inspection of building facades ",
journal = "Automation in Construction ",
volume = "36",
number = "",
pages = "128 - 135",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.08.020",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001477",
author = "D. Roca and S. Laguela and L. Diaz-Vilarino and J. Armesto and P. Arias",
keywords = "UAV",
keywords = "3D modeling",
keywords = "Scanning sensors",
keywords = "Building envelope",
keywords = "Building openings ",
abstract = "Abstract Geometry of buildings is an essential measurement during energy inspections, since it has a great influence in the energy performance of the building. Given the difficult access presented to some areas of the buildings that make impossible their complete geometric characterization with terrestrial devices, Unmanned Aerial Vehicles (UAVs) stand as the solution for the acquisition of data both from facades and roofs. In this paper, the potential of \{UAV\} to building geometric inspection is analyzed by mounting a Kinect sensor for geometric data acquisition in three-dimensions. The resulting point cloud and 3D model are evaluated in order to validate the performance of the complete system. "
}
@article{NorouzzadehRavari201632,
title = "Reconstruction of B-spline curves and surfaces by adaptive group testing ",
journal = "Computer-Aided Design ",
volume = "74",
number = "",
pages = "32 - 44",
year = "2016",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2016.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S001044851600004X",
author = "Alireza Norouzzadeh Ravari and Hamid D. Taghirad",
keywords = "B-spline curve and surface fitting",
keywords = "Akaike Information Criterion",
keywords = "Salient points",
keywords = "Iterative approximation",
keywords = "Group testing ",
abstract = "Abstract Point clouds as measurements of 3D sensors have many applications in various fields such as object modeling, environment mapping and surface representation. Storage and processing of raw point clouds is time consuming and computationally expensive. In addition, their high dimensionality shall be considered, which results in the well known curse of dimensionality. Conventional methods either apply reduction or approximation to the captured point clouds in order to make the data processing tractable. B-spline curves and surfaces can effectively represent 2D data points and 3D point clouds for most applications. Since processing all available data for B-spline curve or surface fitting is not efficient, based on the Group Testing theory an algorithm is developed that finds salient points sequentially. The B-spline curve or surface models are updated by adding a new salient point to the fitting process iteratively until the Akaike Information Criterion (AIC) is met. Also, it has been proved that the proposed method finds a unique solution so as what is defined in the group testing theory. From the experimental results the applicability and performance improvement of the proposed method in relation to some state-of-the-art B-spline curve and surface fitting methods, may be concluded. "
}
@article{Worn2001753,
title = "Computer- and robot-based operation theatre of the future in cranio-facial surgery ",
journal = "International Congress Series ",
volume = "1230",
number = "",
pages = "753 - 759",
year = "2001",
note = "Computer Assisted Radiology and Surgery ",
issn = "0531-5131",
doi = "https://doi.org/10.1016/S0531-5131(01)00127-3",
url = "http://www.sciencedirect.com/science/article/pii/S0531513101001273",
author = "Heinz Worn and Joachim Muhling",
keywords = "Operation theatre",
keywords = "Cranio-facial surgery",
keywords = "3D surface models",
keywords = "Operation planning",
keywords = "Augmented reality",
keywords = "Robot system ",
abstract = "This paper presents an overview of our research in medical high-tech computing and robot-based surgical intervention in cranio facial surgery defining an operation theatre of the future. Our overall goal is to provide improved operation methods and workflows—high-quality, safer and more economical due to shorter operation time and less postoperative treatment. Our operation theatre of the future includes workflow definition as well as high-tech hardware and software systems for pre- and intraoperative steps and the operation room itself. The system's workflow consists of dedicated tasks for image acquisition up to intraoperative application, which jointly integrates to a workflow attending conventional surgical proceeding. Thus, managing highly complex systems like surgical robots or operation planning tools is easy as we follow the surgeon's well-known pre- and intraoperative processes. Modules within the workflow can be categorized by image acquisition, data modeling, operation planning and simulation, and supervision of surgery or intraoperative execution, respectively. The intraoperative setting of the operation theatre of the future involves, e.g. visualization techniques for Virtual and Augmented Reality, heart–lung machine control and the application of surgical robotics. The workflow settings with first-system modules of our operation theatre of the future already showed its potential during the initial clinical evaluation and have been presented at the largest German exhibition for medical systems called \{MEDICA\} in 2000. "
}
@article{RodriguezLizundia201583,
title = "A bellboy robot: Study of the effects of robot behaviour on user engagement and comfort ",
journal = "International Journal of Human-Computer Studies ",
volume = "82",
number = "",
pages = "83 - 95",
year = "2015",
note = "",
issn = "1071-5819",
doi = "https://doi.org/10.1016/j.ijhcs.2015.06.001",
url = "http://www.sciencedirect.com/science/article/pii/S1071581915001032",
author = "Eduardo Rodriguez-Lizundia and Samuel Marcos and Eduardo Zalama and Jaime Gomez-Garcia-Bermejo and Alfonso Gordaliza",
keywords = "Social/service robot",
keywords = "HRI",
keywords = "Proxemics ",
abstract = "Abstract This paper provides the results of various trial experiments in a hotel environment carried out using Sacarino, an interactive bellboy robot. We analysed which aspects of the robot design and behaviour are relevant in terms of user engagement and comfort when interacting with our social robot. The experiments carried out focused on the influence over the proxemics, duration and effectiveness of the interaction, taking into account three dichotomous factors related with the robot design and behaviour: robot embodiment (with/without robotic body), status of the robot (awake/asleep) and who starts communication (robot/user). Results show that users tend to maintain a personal distance when interacting with an embodied robot and that embodiment engages users in maintaining longer interactions. On the other hand, including a greeting model in a robot is useful in terms of engaging users to maintain longer interactions, and that an active-looking robot is more attractive to the participants, producing longer interactions than in the case of a passive-looking robot. "
}
@article{Peng201685,
title = "Semantic Mapping of Orchards* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "85 - 89",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315786",
author = "Cheng Peng and Pravakar Roy and James Luby and Volkan Isler",
keywords = "computer vision",
keywords = "agriculture",
keywords = "image reconstruction",
keywords = "image recognition",
keywords = "object recognition ",
abstract = "Abstract: We present a method to construct a semantic map of an apple orchard using a \{LIDAR\} and a camera rigidly attached to each other. The system is able to capture the map as a standalone sensor which is light-weight and can be mounted on a variety of platforms. At the geometry level, we present a new method to associate image features captured by the camera with 3D points captured by the LIDAR. We then use this method to register 3D point-clouds onto a common frame. We show that our association method yields superior registration performance compared to common methods which work in indoor or urban settings. At the semantic level, the apples are identified as distinct objects. Their locations and diameters are extracted as relevant attributes. As an example, a semantic map of an orchard row is constructed. "
}
@article{Kobayashi20139010,
title = "Corneal regeneration by transplantation of corneal epithelial cell sheets fabricated with automated cell culture system in rabbit model ",
journal = "Biomaterials ",
volume = "34",
number = "36",
pages = "9010 - 9017",
year = "2013",
note = "",
issn = "0142-9612",
doi = "https://doi.org/10.1016/j.biomaterials.2013.07.065",
url = "http://www.sciencedirect.com/science/article/pii/S014296121300879X",
author = "Toyoshige Kobayashi and Kazutoshi Kan and Kohji Nishida and Masayuki Yamato and Teruo Okano",
keywords = "Cell sheet engineering",
keywords = "Automatic cell culture system",
keywords = "Cell cartridge",
keywords = "Corneal epithelial cell",
keywords = "Cell sheet transportation",
keywords = "Cell sheet transplantation ",
abstract = "Abstract We have performed clinical applications of cell sheet-based regenerative medicine with human patients in several fields. In order to achieve the mass production of transplantable cell sheets, we have developed automated cell culture systems. Here, we report an automated robotic system utilizing a cell culture vessel, cell cartridge. The cell cartridge had two rooms for epithelial cells and feeder layer cells separating by porous membrane on which a temperature-responsive polymer was covalently immobilized. After pouring cells into this robotic system, cell seeding, medium change, and microscopic examination during culture were automatically performed according to the computer program. Transplantable corneal epithelial cell sheets were successfully fabricated in cell cartridges with this robotic system. Then, fabricated cell sheets were transplanted onto ocular surfaces of rabbit limbal epithelial stem cell deficiency model after 6-h transportation using a portable homothermal container to keep inner temperature at 36 °C. Within one week after transplantation, normal corneal epithelium was successfully regenerated. This automatic cell culture system would be useful for industrialization of tissue-engineered products for regenerative medicine. "
}
@incollection{Brecher2017321,
title = "Chapter 21 - The Need of Dynamic and Adaptive Data Models for Cyber-Physical Production Systems ",
editor = "Song, Houbing and Rawat, Danda B. and Jeschke, Sabina  and Brecher, Christian ",
booktitle = "Cyber-Physical Systems ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2017",
pages = "321 - 338",
series = "Intelligent Data-Centric Systems",
isbn = "978-0-12-803801-7",
doi = "https://doi.org/10.1016/B978-0-12-803801-7.00021-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128038017000213",
author = "C. Brecher and C. Ecker and W. Herfs and M. Obdenbusch and S. Jeschke and M. Hoffmann and T. Meisen",
keywords = "Cyber-physical production systems",
keywords = "Industrie 4.0",
keywords = "Automation",
keywords = "Industrial communication",
keywords = "Assembly",
keywords = "Condition monitoring",
keywords = "Big data",
keywords = "Product life cycle management",
keywords = "Human-robot interaction ",
abstract = "Abstract Cyber-physical production systems (CPPSs) are the fundamental basis for the realization of the German initiative “Industrie 4.0,” which covers not only the usage of intelligent embedded devices and their interconnectedness, but also models for describing different processes according to the product’s life cycle. This article focuses on challenges regarding the integration of different views on urgent aspects, technologies, and paradigms to formulate one consistent modeling approach. Different use cases then describe the application of modeling and implementation concepts as well as benefits of new possibilities for process control. These are: model-based human-robot interaction for flexible assembly automation, a cloud-based approach for advanced condition monitoring, and product-centered control in the Laboratory for Machine Tools and Production Engineering (WZL)’s Smart Automation Lab. "
}
@article{Zhao201737,
title = "A scientometric review of global \{BIM\} research: Analysis and visualization ",
journal = "Automation in Construction ",
volume = "80",
number = "",
pages = "37 - 47",
year = "2017",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2017.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580517301334",
author = "Xianbo Zhao",
keywords = "Building information modeling",
keywords = "Co-citation",
keywords = "Research trend",
keywords = "Scientometrics",
keywords = "Visualization ",
abstract = "Abstract In the recent years, building information modeling (BIM) has transformed the architecture, engineering, and construction industry, and attracted attentions from both researchers and practitioners. However, few studies have attempted to map the global research on BIM. This study conducts a scientometric review of global \{BIM\} research in 2005–2016, through co-author analysis, co-word analysis and co-citation analysis. A total of 614 bibliographic records from the Web of Science core collection database were analyzed. The results indicated that Charles M. Eastman received the most co-citations and that the most significant development in \{BIM\} research occurred primarily in the USA, South Korea and China. Additionally, \{BIM\} research has primarily focused on the subject categories of engineering, civil engineering and construction &amp; building technology, and the keywords “visualization” and “industry foundation classes (IFC)” received citation bursts in the recent years. Furthermore, 10 co-citation clusters were identified, and the hot topics of \{BIM\} research were: mobile and cloud computing, laser scan, augmented reality, ontology, safety rule and code checking, semantic web technology, and automated generation. This study provides researchers and practitioners with an in-depth understanding of the status quo and trend of the \{BIM\} research in the world. "
}
@article{Barki2009525,
title = "Contributing vertices-based Minkowski sum computation of convex polyhedra ",
journal = "Computer-Aided Design ",
volume = "41",
number = "7",
pages = "525 - 538",
year = "2009",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2009.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0010448509000724",
author = "Hichem Barki and Florence Denis and Florent Dupont",
keywords = "Minkowski sum",
keywords = "Contributing vertices",
keywords = "Slope diagram",
keywords = "Convex hull",
keywords = "Computer-aided design ",
abstract = "Minkowski sum is an important operation. It is used in many domains such as: computer-aided design, robotics, spatial planning, mathematical morphology, and image processing. We propose a novel algorithm, named the Contributing Vertices-based Minkowski Sum (CVMS) algorithm for the computation of the Minkowski sum of convex polyhedra. The \{CVMS\} algorithm allows to easily obtain all the facets of the Minkowski sum polyhedron only by examining the contributing vertices—a concept we introduce in this work, for each input facet. We exploit the concept of contributing vertices to propose the Enhanced and Simplified Slope Diagram-based Minkowski Sum (ESSDMS) algorithm, a slope diagram-based Minkowski sum algorithm sharing some common points with the approach proposed by Wu et al. [Wu Y, Shah J, Davidson J. Improvements to algorithms for computing the Minkowski sum of 3-polytopes. Comput Aided Des. 2003; 35(13): 1181–92]. The \{ESSDMS\} algorithm does not embed input polyhedra on the unit sphere and does not need to perform stereographic projections. Moreover, the use of contributing vertices brings up more simplifications and improves the overall performance. The implementations for the mentioned algorithms are straightforward, use exact number types, produce exact results, and are based on CGAL, the Computational Geometry Algorithms Library. More examples and results of the \{CVMS\} algorithm for several convex polyhedra can be found at http://liris.cnrs.fr/hichem.barki/mksum/CVMS-convex. "
}
@article{Zhang2016281,
title = "Local Surface Geometric Feature for 3D human action recognition ",
journal = "Neurocomputing ",
volume = "208",
number = "",
pages = "281 - 289",
year = "2016",
note = "SI: BridgingSemantic ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.12.122",
url = "http://www.sciencedirect.com/science/article/pii/S092523121630460X",
author = "Erhu Zhang and Wanjun Chen and Zhuomin Zhang and Yan Zhang",
keywords = "Human action recognition",
keywords = "Depth map",
keywords = "Skeleton joint",
keywords = "Local Surface Geometric Feature (LSGF)",
keywords = "Covariance descriptor ",
abstract = "Abstract This paper presents a novel Local Surface Geometric Feature (LSGF) for human action recognition from video sequences captured by a depth camera. The \{LSGF\} is extracted from each skeleton joint in point cloud space to capture the static appearance and pose cues, which includes joint position, normal, and local curvature. A temporal pyramid of covariance matrix is exploited to model both pairwise relations of features instead of features themselves and the temporal evolution. Finally, Fisher vector encoding is imported as a global representation for a video sequence and \{SVM\} classifier is used for classification. In the extensive experiments, we achieve classification results superior to most of previous published results on three public benchmark datasets, i.e., MSR-Action3D, \{MSR\} DailyActivity3D, and \{UTKinect\} Action. "
}
@article{Lee2014442,
title = "Robots in the shipbuilding industry ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "30",
number = "5",
pages = "442 - 450",
year = "2014",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000131",
author = "Donghun Lee",
keywords = "Robot automation",
keywords = "Shipbuilding industry",
keywords = "Self-traveling mechanism",
keywords = "Environment recognition",
keywords = "Launch and recovery system ",
abstract = "Abstract In this paper, details of the uses of various robots in the shipbuilding process are provided, with an emphasis on newer developments and applications. The current state of robot applications will be discussed according to the priority of the shipbuilding process. First, various robots for open structures, such as several types of welding carriages and 6-axis articulated robot manipulators, will be reviewed in terms of their mechanisms and applications. Second, several attempts to design autonomous mobile robotic systems for closed blocks of the double-hulled structure of a ship will be discussed in terms of the performance characteristics of their proposed self-traveling mechanisms. Lastly, all corresponding technologies for overcoming structural complexities in closed blocks as well as future directions of robot automation in the shipbuilding industry are also discussed. "
}
@article{Keller2009967,
title = "Real-time simulation of time-of-flight sensors ",
journal = "Simulation Modelling Practice and Theory ",
volume = "17",
number = "5",
pages = "967 - 978",
year = "2009",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2009.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X09000331",
author = "Maik Keller and Andreas Kolb",
keywords = "Sensor simulation",
keywords = "Time-of-flight",
keywords = "Photonic Mixing Device",
keywords = "Real-time simulation",
keywords = "GPU programming ",
abstract = "Today’s time-of-flight (TOF) sensors measure full-range distance information by estimating the elapsed time between emission and receiving of active light in real-time. Such sensors are inexpensive, compact, and they have a high performance, which especially fits real-time applications, e.g. in the fields of automotive, robotics, 3D imaging, and visualization. The simulation of such sensors is an essential building block for hardware design and application development. Therefore, the simulation data must capture the major sensor characteristics. This paper introduces a simulation approach, which is motivated by physics, for the Photonic Mixing Device (PMD) sensor which is a specific type of time-of-flight sensor. Dynamic motion blurring and resolution artifacts such as flying pixels as well as the typical deviation error are prominent effects of real world systems. Flying pixels arise when an area of inhomogeneous depth is covered by a single PMD-pixel whereas the deviation error is based on the anharmonic properties of the optical signal. The modeling of these artifacts is essential for an authentic simulation approach. We present a detailed comparison between a real PMD-device and the simulation data regarding the sensor characteristics. The proposed algorithms are implemented in a hardware accelerated solution which makes use of the programmability of modern Graphics Processing Units (GPUs). This way, an interactive simulation feedback is provided for applications and further data processing. The simulation takes place in real-time and thus all required control mechanisms are accessible in real-time, too. "
}
@article{Chen20143,
title = "Machine-to-machine communications: Technologies and challenges ",
journal = "Ad Hoc Networks ",
volume = "18",
number = "",
pages = "3 - 23",
year = "2014",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2013.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S1570870513000395",
author = "Kwang-Cheng Chen and Shao-Yu Lien",
keywords = "Machine-to-machine communications",
keywords = "Internet of Things",
keywords = "Cyber–physical systems",
keywords = "Multi-hop networks",
keywords = "Cognitive radio",
keywords = "Spectrum sharing",
keywords = "Swarm communications ",
abstract = "Abstract Machine-to-machine (M2M) communications emerge to autonomously operate to link interactions between Internet cyber world and physical systems. We present the technological scenario of \{M2M\} communications consisting of wireless infrastructure to cloud, and machine swarm of tremendous devices. Related technologies toward practical realization are explored to complete fundamental understanding and engineering knowledge of this new communication and networking technology front. "
}
@article{Pottmann2005751,
title = "Industrial geometry: recent advances and applications in \{CAD\} ",
journal = "Computer-Aided Design ",
volume = "37",
number = "7",
pages = "751 - 766",
year = "2005",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2004.08.013",
url = "http://www.sciencedirect.com/science/article/pii/S0010448504001988",
author = "H. Pottmann and S. Leopoldseder and M. Hofer and T. Steiner and W. Wang",
keywords = "Geometric optimization",
keywords = "Distance function",
keywords = "Curve approximation",
keywords = "Surface approximation",
keywords = "Active contours",
keywords = "Registration",
keywords = "Feature sensitivity",
keywords = "Mathematical morphology ",
abstract = "Industrial Geometry aims at unifying existing and developing new methods and algorithms for a variety of application areas with a strong geometric component. These include CAD, CAM, Geometric Modelling, Robotics, Computer Vision and Image Processing, Computer Graphics and Scientific Visualization. In this paper, Industrial Geometry is illustrated via the fruitful interplay of the areas indicated above in the context of novel solutions of \{CAD\} related, geometric optimization problems involving distance functions: approximation with general B-spline curves and surfaces or with subdivision surfaces, approximation with special surfaces for applications in architecture or manufacturing, approximate conversion from implicit to parametric (NURBS) representation, and registration problems for industrial inspection and 3D model generation from measurement data. Moreover, we describe a ‘feature sensitive’ metric on surfaces, whose definition relies on the concept of an image manifold, introduced into Computer Vision and Image Processing by Kimmel, Malladi and Sochen. This metric is sensitive to features such as smoothed edges, which are characterized by a significant deviation of the two principal curvatures. We illustrate its applications at hand of feature sensitive curve design on surfaces and local neighborhood definition and region growing as an aid in the segmentation process for reverse engineering of geometric objects. "
}
@article{Ghidoni201745,
title = "A multi-viewpoint feature-based re-identification system driven by skeleton keypoints ",
journal = "Robotics and Autonomous Systems ",
volume = "90",
number = "",
pages = "45 - 54",
year = "2017",
note = "Special Issue on New Research Frontiers for Intelligent Autonomous Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305073",
author = "Stefano Ghidoni and Matteo Munaro",
keywords = "People re-identification",
keywords = "People tracking",
keywords = "Body pose estimation",
keywords = "Camera networks",
keywords = "Multi-view skeletal tracker ",
abstract = "Abstract Thanks to the increasing popularity of 3D sensors, robotic vision has experienced huge improvements in a wide range of applications and systems in the last years. Besides the many benefits, this migration caused some incompatibilities with those systems that cannot be based on range sensors, like intelligent video surveillance systems, since the two kinds of sensor data lead to different representations of people and objects. This work goes in the direction of bridging the gap, and presents a novel re-identification system that takes advantage of multiple video flows in order to enhance the performance of a skeletal tracking algorithm, which is in turn exploited for driving the re-identification. A new, geometry-based method for joining together the detections provided by the skeletal tracker from multiple video flows is introduced, which is capable of dealing with many people in the scene, coping with the errors introduced in each view by the skeletal tracker. Such method has a high degree of generality, and can be applied to any kind of body pose estimation algorithm. The system was tested on a public dataset for video surveillance applications, demonstrating the improvements achieved by the multi-viewpoint approach in the accuracy of both body pose estimation and re-identification. The proposed approach was also compared with a skeletal tracking system working on 3D data: the comparison assessed the good performance level of the multi-viewpoint approach. This means that the lack of the rich information provided by 3D sensors can be compensated by the availability of more than one viewpoint. "
}
@article{Feng2013544,
title = "Satellite and surface-based remote sensing of Southeast Asian aerosols and their radiative effects ",
journal = "Atmospheric Research ",
volume = "122",
number = "",
pages = "544 - 554",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.02.018",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512001238",
author = "Nan Feng and Sundar A. Christopher",
keywords = "Southeast Asia",
keywords = "Aerosol radiative effects",
keywords = "Remote sensing ",
abstract = "Using one year (December 2006–November 2007) of the Moderate Resolution Imaging SpectroRadiometer (MODIS), Multi-Angle Imaging SpectroRadiometer (MISR), and Clouds and the Earth's Radiant Energy System (CERES) data sets from NASA's Terra satellite, we assess the spatial and temporal distributions of aerosol properties (Aerosol Optical Depth, Fine Mode Fraction, and Single Scattering albedo) in the Southeast Asian region (SEA, 10°S–25°N, 90°E–150°E). We also provide a quantitative evaluation of regional cloud-free diurnally averaged shortwave aerosol radiative effects (SWARE) at the top of atmosphere (TOA) over both land and ocean. Our results indicate that the diurnally averaged shortwave radiative effects at the \{TOA\} over land and ocean are (− 6.4 ± 1.2 W m− 2) and (− 5.9 ± 1.3 W m− 2) with corresponding 550 nm aerosol optical depths of 0.27 ± 0.24 and 0.12 ± 0.10. Fine aerosol particles (&lt; 0.6 μm) dominate the continental areas during the whole study period, which represents large fractions of biomass burning aerosols and anthropogenic pollutant aerosols. Our results also indicate that the monthly averaged cloud cover fractions over this region are above 60%. Therefore, further sampling of aerosols underneath these cloud layers is needed in future field campaigns. "
}
@article{Marfil201581,
title = "Hierarchical segmentation of range images inside the combinatorial pyramid ",
journal = "Neurocomputing ",
volume = "161",
number = "",
pages = "81 - 88",
year = "2015",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.01.075",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215002118",
author = "R. Marfil and E. Antunez and A. Bandera",
keywords = "Irregular pyramids",
keywords = "RGB-D cameras",
keywords = "Image segmentation ",
abstract = "Abstract RGB-D cameras are not only able to provide color (Red-Green-Blue -RGB-) information from the scene but also a relatively accurate cloud of 3D points. Using information coming from this organized cloud, it is possible to define around each image pixel a small planar patch and obtain its normal vector. Within the framework of the combinatorial pyramid, this paper describes a method to abstract from these normals to parametric surface models. The method works at two consecutive stages. Firstly, normals are hierarchically grouped to divide up the image into superpixels. These superpixels capture small patches on the scene that belong to the same surface. Then, they are merged to segment the scene into simple geometric models. Curvature information and model information are used to divide up the image into planes, cylinders and/or spheres. This paper shows how, in the higher levels of abstraction of the combinatorial pyramid, scenes can be described using these geometric items and their topological relationships. "
}
@article{Paoli2012592,
title = "Large yacht hull measurement by integrating optical scanning with mechanical tracking-based methodologies ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "28",
number = "5",
pages = "592 - 601",
year = "2012",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000221",
author = "Alessandro Paoli and Armando V. Razionale",
keywords = "Shipbuilding",
keywords = "Optical 3D measurement",
keywords = "Mechanical tracking",
keywords = "Laser tracking ",
abstract = "In the shipbuilding industry, the manufacturing of large yacht hulls is a complex process. Metal hulls are traditionally manufactured by welding pre fabricated large steel panels to form the external superstructure. A surface finishing process is then carried out in order to obtain a final target surface having a smooth curvature. The methodologies manly rely on manual processes based on the measurement of the as built hull shape through simple testing instrumentation. Well-experienced workers are required, and a great amount of time is usually wasted, thus affecting the overall shipyard competitiveness. This paper introduces a methodology for automating the measurement process of as built hull yacht shapes. The methodology, which is based on the integration of a robotic system with an optical scanner, provides accurate non contact 3D full field measurements of the hull surface. The placement of the robotic system around the hull shape is determined by a laser total station thus allowing the automatic multi view data registration into a common reference frame. The proposed approach represents the basis for the automation of the whole surface finishing process of large yacht hulls. In this paper, the methodology has been tested by measuring a large broadside area of a 59 m hull assembled within a shipyard. "
}
@incollection{Grand2004323,
title = "Chapter 10 - Wireless 802.11 Hacks ",
editor = "Grand, Joe and Russell, Ryan and Mitnick, Kevin D. and Huang, Andrew “bunnie” and Barken, Lee and Brown, Marcus R. and Haas, Job de and Kaplan, Deborah and Kinstle, Bobby and Owad, Tom  and Yarusso, Albert ",
booktitle = "Hardware Hacking ",
publisher = "Syngress",
edition = "",
address = "Burlington",
year = "2004",
pages = "323 - 347",
isbn = "978-1-932266-83-2",
doi = "https://doi.org/10.1016/B978-193226683-2/50016-8",
url = "http://www.sciencedirect.com/science/article/pii/B9781932266832500168",
author = "Joe Grand and Ryan Russell and Kevin D. Mitnick and Andrew “bunnie” Huang and Lee Barken and Marcus R. Brown and Job de Haas and Deborah Kaplan and Bobby Kinstle and Tom Owad and Albert Yarusso",
abstract = "Publisher Summary This chapter discusses three hardware hacks for wireless networking products. The first hack modifies a D-Link DWL-650 wireless network interface card (NIC) to add an external antenna. Most consumer-grade cards do not provide an external antenna connection. Those that do are generally more expensive. However, the D-Link card can be modified to give it support for an external antenna with relative ease. The second hack explores OpenAP, an open-source Linux distribution from Instant802. The OpenAP software allows reprogramming certain brands of off-the-shelf access points with a fully functioning Linux operating system. The hack uses a U.S. Robotics \{USR\} 2450 AP. The \{USR\} 2450 has a special jumper on the motherboard that, when shorted, will cause the \{AP\} to boot from a static random-access memory (SRAM) card if one is inserted into the \{PCMCIA\} slot. By removing the wireless \{NIC\} from the \{PCMCIA\} slot and replacing it with a preprogrammed \{SRAM\} card containing an OpenAP image file, one can “reflash” the AP's on-board Flash memory. The third hack explores the inner workings of the Dell 1184 Access Point. The Dell 1184 contains an embedded Linux distribution. No special tools or reprogramming is necessary and one can simply Telnet to the device on port 333 and gain complete access. "
}
@article{ElGabry2014456,
title = "Whole-slide imaging: widening the scope of cytopathology ",
journal = "Diagnostic Histopathology ",
volume = "20",
number = "12",
pages = "456 - 461",
year = "2014",
note = "Mini-Symposium: Whole-Slide Imaging in Pathology ",
issn = "1756-2317",
doi = "https://doi.org/10.1016/j.mpdhp.2014.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S1756231714001753",
author = "Ehab A. El-Gabry and Anil V. Parwani and Liron Pantanowitz",
keywords = "cytology",
keywords = "digital pathology",
keywords = "informatics",
keywords = "proficiency testing",
keywords = "telecytology",
keywords = "whole slide imaging",
keywords = "z-stacking ",
abstract = "Abstract Whole slide imaging (WSI) is broadening the scope of cytopathology. Whole slide images are being used for telecytology, quality assurance activities (e.g. proficiency testing) and teaching (e.g. digital teaching sets and online virtual atlases). Progress in \{WSI\} technology that permits high resolution scanning, z-stacking, and hybrid robotic devices has encouraged the use of this imaging modality for cytology practice, education and research. However, widespread adoption in cytology still depends on overcoming barriers unrelated to cytology and challenges directly related to digitizing cytopathology slides. The aim of this article is to review \{WSI\} technology, applications and limitations specific to cytopathology. "
}
@article{Kirton199061,
title = "Canadian space policy ",
journal = "Space Policy ",
volume = "6",
number = "1",
pages = "61 - 71",
year = "1990",
note = "",
issn = "0265-9646",
doi = "https://doi.org/10.1016/0265-9646(90)90008-L",
url = "http://www.sciencedirect.com/science/article/pii/026596469090008L",
author = "John Kirton",
abstract = "Canada's geography made it an early leader in the development of space technology, and generated a civilian-oriented, terrestrially focused space programme with a strong focus on communications and an increasing emphasis on transferring space technology and activity from the government to the private sector. During the 1980s Canada's space programme has strengthened and broadened measurably; its now contains major projects in Earth observation and robotics as well as communications, and has diversified its international partnerships from the \{USA\} to Europe. However, persisting weaknesses in launch capability, space science and military space programmes, and the dependence of all three current major projects (Msat, Radarsat, and the International Space Station's Mobile Servicing System) on the \{USA\} represent potential vulnerabilities which require national investments and expanded international affiliations if they are to be offset. "
}
@article{Wittenberg2016420,
title = "Human-CPS Interaction - requirements and human-machine interaction methods for the Industry 4.0 ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "19",
pages = "420 - 425",
year = "2016",
note = "13th \{IFAC\} Symposium on Analysis, Design, and Evaluation ofHuman-Machine Systems \{HMS\} 2016Kyoto, Japan, 30 August—2 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.602",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316321930",
author = "Carsten Wittenberg",
keywords = "Human-centered design",
keywords = "cyber-physical systems",
keywords = "user requirements",
keywords = "mobile systems",
keywords = "Industry 4.0 ",
abstract = "Abstract Cyber-Physical Systems (CPS) and ideas from the internet of things leaded to the concept of the industry 4.0. The so-called Industry 4.0 implicates techniques like cloud-computing and self-organizing machines. The degree of technological complexity increases. Beside the technological innovation the use context and the tasks for the users will also be changed. In the design phase the engineers have to handle the increased complexity. In the operating phase the operators and also the service and maintenance technicians have to keep the production systems running. This paper discusses the effects of Industry 4.0 and shows the results of the research on mobile applications for supporting service and maintenance technicians under the influence of the CPS/Smart Factories/Industry 4.0. "
}
@article{Kim20096058,
title = "Weekly periodicities of meteorological variables and their possible association with aerosols in Korea ",
journal = "Atmospheric Environment ",
volume = "43",
number = "38",
pages = "6058 - 6065",
year = "2009",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2009.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S1352231009007353",
author = "Byung-Gon Kim and Min-Hyeok Choi and Chang-Hoi Ho",
keywords = "Weekly periodicities",
keywords = "Diurnal temperature range",
keywords = "Meteorological variables",
keywords = "Aerosols",
keywords = "Korea ",
abstract = "The weekly periodicities in meteorological variables and its association with aerosols in Korea are investigated using long-term surface measurements of meteorology (1975–2005) and aerosols (1999–2005). Through an analysis of the annual (and/or seasonal) values averaged over 10 stations, we identified distinct weekly periodicities in the daily minimum temperature (Tmin), diurnal temperature range (DTR), cloud fraction, and solar insolation, although they have different characteristics from each other. The weekly association among variables is discussed in this study. Positive anomalies of the cloud fraction and Tmin and negative anomalies of solar insolation and \{DTR\} are seen for the second half of the week and the reverse for the first half of the week, i.e., more cloudiness and less insolation for Wednesday−Thursday and less cloudiness and more insolation for Monday−Tuesday. Furthermore, seasonal dependence of weekly anomalies shows that the weekly periodicities are enhanced especially in autumn, more than 2–3 times as great as those of the annual mean. The weekly cycles in such variables are most likely driven by changes in cloud fraction, possibly through aerosol–cloud interactions induced by aerosol variations between working weekdays and Sunday, which are clearly identified in \{PM10\} weekly cycles. This study also suggests that the weekly periodicities in meteorological variables are possibly associated with long-range transport of weekly periodicities, as well as aerosol–cloud-precipitation interactions over the region. "
}
@article{Amunts2016574,
title = "The Human Brain Project: Creating a European Research Infrastructure to Decode the Human Brain ",
journal = "Neuron ",
volume = "92",
number = "3",
pages = "574 - 581",
year = "2016",
note = "",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2016.10.046",
url = "http://www.sciencedirect.com/science/article/pii/S0896627316307966",
author = "Katrin Amunts and Christoph Ebell and Jeff Muller and Martin Telefont and Alois Knoll and Thomas Lippert",
abstract = "Decoding the human brain is perhaps the most fascinating scientific challenge in the 21st century. The Human Brain Project (HBP), a 10-year European Flagship, targets the reconstruction of the brain’s multi-scale organization. It uses productive loops of experiments, medical, data, data analytics, and simulation on all levels that will eventually bridge the scales. The \{HBP\} \{IT\} architecture is unique, utilizing cloud-based collaboration and development platforms with databases, workflow systems, petabyte storage, and supercomputers. The \{HBP\} is developing toward a European research infrastructure advancing brain research, medicine, and brain-inspired information technology. "
}
@article{Kim2003871,
title = "Minimum distance between a canal surface and a simple surface ",
journal = "Computer-Aided Design ",
volume = "35",
number = "10",
pages = "871 - 879",
year = "2003",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(02)00123-9",
url = "http://www.sciencedirect.com/science/article/pii/S0010448502001239",
author = "Ku-Jin Kim",
keywords = "Minimum distance",
keywords = "Canal surface",
keywords = "Simple surface",
keywords = "Collision detection",
keywords = "Haptic rendering ",
abstract = "The computation of the minimum distance between two objects is an important problem in the applications such as haptic rendering, CAD/CAM, \{NC\} verification, robotics and computer graphics. This paper presents a method to compute the minimum distance between a canal surface and a simple surface (i.e. a plane, a natural quadric, or a torus) by finding roots of a function of a single parameter. We utilize the fact that the normals at the closest points between two surfaces are collinear. Given the spine curve C(t), tmin≤t≤tmax, and the radius function r(t) for a canal surface, a point on the spine curve C(t∗) uniquely determines a characteristic circle K(t∗) on the surface. Normals to the canal surface at points on K(t∗) form a cone with a vertex C(t∗) and an axis which is parallel to C′(t∗). Then we construct a function of t which expresses the condition that the perpendicular from C(t) to a given simple surface is embedded in the cone of normals to the canal surface at points on K(t). By solving this equation, we find characteristic circles which contain the points of locally minimum distance from the simple surface. Based on these circles, we can compute the minimum distance between given surfaces. "
}
@article{Schmidt2013545,
title = "Contact-less and Programming-less Human-Robot Collaboration ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "545 - 550",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002990",
author = "Bernard Schmidt and Lihui Wang",
keywords = "Collision Avoidance",
keywords = "Human-Robot Collaboration ",
abstract = "Abstract In today's manufacturing environment, safe human-robot collaboration is of paramount importance, to improve efficiency and flexibility. Targeting the safety issue, this paper presents an approach for human-robot collaboration in a shared workplace in close proximity, where real data driven 3D model of a robot and multiple depth images of the workplace are used for monitoring and decision-making to perform a task. The strategy for robot control depends on the current task and the information about the operator's presence and position. A case study of assembly is carried out in a robotic assembly cell with human collaboration. The results show that this approach can be applied in real-world applications such as human-robot collaborative assembly with human operators safeguarded at all time. "
}
@incollection{tagkey200377,
title = "7 - Containment equipment types ",
editor = "Hirst, Nigel and , and Brocklebank, Mike and ,  and Ryder, Martyn ",
booktitle = "Containment Systems ",
publisher = "Gulf Professional Publishing",
edition = "",
address = "Burlington",
year = "2003",
pages = "77 - 119",
isbn = "978-0-7506-7612-0",
doi = "https://doi.org/10.1016/B978-075067612-0/50008-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780750676120500087",
key = "tagkey200377",
abstract = "Publisher Summary This chapter deals with the selection of appropriate equipment and operating systems to implement the containment strategy. Four containment strategies designated as two, three, four, and five for different control devices are discussed. Strategy two in air-flow containment devices do not rely on specific coupling devices but achieve adequate control for low-hazard materials largely as a result of removal of the airborne contaminants in a unidirectional air-stream, provided that the operator follows suitable procedures. Most contained operations (containment strategy three) rely on the ability to transfer materials, components and parts into and out of an isolator or between vessels contained within it without releasing significant quantities of airborne hazardous materials into the environment. Containment Strategy four systems require closed transfer or coupling devices to be used whose connections are made and broken within an isolator. In totally enclosed systems (Containment Strategy five) all operations are carried out by robotics; the operator has no contact at all with the hazardous material but undertakes all required actions by remote control, normally from outside the area or room in which the transfer operation, inside its own isolator, takes place. The main characteristics and applications of the various control devices are also discussed in the chapter. "
}
@article{Paulic2014795,
title = "Reverse Engineering of Parts with Optical Scanning and Additive Manufacturing ",
journal = "Procedia Engineering ",
volume = "69",
number = "",
pages = "795 - 803",
year = "2014",
note = "24th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.03.056",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814003026",
author = "Matej Paulic and Tomaz Irgolic and Joze Balic and Franc Cus and Andrej Cupar and Tomaz Brajlih and Igor Drstvensek",
keywords = "Production engineering",
keywords = "reverse engineering",
keywords = "optical scanning",
keywords = "selective laser sintering ",
abstract = "Abstract This paper presents reverse engineering of car volume button. The purpose of article is to introduce reverse engineering procedure, what we need to do this kind of procedure and how we can remanufacture car's volume button. The purpose of reverse engineering is to manufacture another object based on a physic and existing object for which 3D \{CAD\} is not available. The first we need digital version of object. Because our car's volume button has free formed surfaces we decided to use 3D scanning technology to obtain the point cloud of existing object. With the help of point cloud we can developed 3D \{CAD\} model which will be used for manufacturing of button pair. We used for manufacturing of pair of buttons machine for selective laser sintering Formiga P 100. In the paper are also described costs of making of one pair of buttons and whole workspace. "
}
@article{Christopher20101002,
title = "Satellite and surface-based remote sensing of Saharan dust aerosols ",
journal = "Remote Sensing of Environment ",
volume = "114",
number = "5",
pages = "1002 - 1007",
year = "2010",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2009.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0034425709003630",
author = "Sundar A. Christopher and Thomas A. Jones",
keywords = "Aerosols",
keywords = "Dust",
keywords = "Remote sensing",
keywords = "AERONET",
keywords = "Forcing",
keywords = "MODIS",
keywords = "CERES ",
abstract = "The spatial and temporal characteristics of dust aerosols and their properties are assessed from satellite and ground-based sensors. The spatial distribution of total column aerosol optical depth at 550 nm (AOD) from the Moderate Resolution Imaging SpectroRadiometer (MODIS) coupled with top of atmosphere Clouds and the Earth's Radiant Energy System (CERES) shortwave fluxes are examined from the Terra satellite over the Atlantic Ocean. These data are then compared with \{AOD\} from two Aerosol Robotic Network (AERONET) ground-based sun photometer measurement sites for nearly six years (2000–2005). These two sites include Capo Verde (CV) (16°N, 24°W) near the Saharan dust source region and La Paguera (LP) (18°N, 67°W) that is downwind of the dust source regions. The \{AOD\} is two to three times higher during spring and summer months over \{CV\} when compared to \{LP\} and the surrounding regions. For a unit \{AOD\} value, the instantaneous \{TOA\} shortwave direct radiative effect (DRE) defined as the change in shortwave flux between clear and aerosol skies for \{CV\} and \{LP\} are − 53 and − 68 Wm− 2 respectively. \{DRE\} for \{LP\} is likely more negative due to fall out of larger particles during transport from \{CV\} to LP. However, separating the CERES-derived \{DRE\} by \{MODIS\} aerosol effective radii was difficult. Satellite and ground-based dust aerosol data sets continue to be useful to understand dust processes related to the surface and the atmosphere. "
}
@article{Romano20165,
title = "Experimental determination of short- and long-wave dust radiative effects in the Central Mediterranean and comparison with model results ",
journal = "Atmospheric Research ",
volume = "171",
number = "",
pages = "5 - 20",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.11.019",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515003907",
author = "S. Romano and P. Burlizzi and M.R. Perrone",
keywords = "Desert dust aerosol",
keywords = "Irradiance measurements",
keywords = "Direct radiative forcing",
keywords = "Surface albedo",
keywords = "Land surface temperature ",
abstract = "Abstract Downward and upward irradiance measurements, in the short-wave (SW) and long-wave (LW) spectral range, have been used in combination with simultaneous aerosol optical depths (AODs) to experimentally determine the instantaneous and clear-sky aerosol Direct Radiative Forcing (DRF) at the surface, during a desert dust outbreak which affected the Central Mediterranean from 9 to 13 July 2012. \{AODs\} were retrieved from \{AERONET\} (AErosol \{RObotic\} NETwork) sun/sky photometer measurements collocated in space and time. The importance of downward and upward radiative flux measurements to properly account for both the surface albedo dependence on the solar zenith angle, and the land surface temperature (TLS) has been highlighted. Measured radiative fluxes were in reasonable agreement with the \{CERES\} (Clouds and the Earth's Radiant Energy System) and \{AERONET\} corresponding ones collocated in space and time. \{SW\} and \{LW\} downward fluxes at the surface decreased up to 9% and increased up to 13%, respectively, as a consequence of a factor 5 increase of the \{AOD\} at 675 nm (AOD675). This is due to the cooling and warming effect of desert dust in the \{SW\} and \{LW\} spectral range, respectively. In fact, we have also found that the \{TLS\} increased at a rate of about 250 K per unit increase of the AOD675. The aerosol \{DRF\} at the surface varied from − 8 to − 74 W m− 2 and from + 1.2 to + 9.6 W m− 2 in the \{SW\} and \{LW\} spectral domains, respectively. In particular, we have found that the LW-DRF on average offsets 14% of the related \{SW\} component. It is shown that a two-stream radiative transfer model can reproduce the experimental findings at the surface by replacing the refractive indices typical of dust particles with the ones obtained for a mixture made of dust and soot particles. The dust contamination by anthropogenic particles during its transport to the monitoring site located several hundred kilometers away from the source region was responsible for this last result. We have also found by model simulations that the LW-DRF increased linearly with \{TLS\} both at the surface and at the top of the atmosphere. "
}
@article{SavalCalvo2015572,
title = "Three-dimensional planar model estimation using multi-constraint knowledge based on k-means and \{RANSAC\} ",
journal = "Applied Soft Computing ",
volume = "34",
number = "",
pages = "572 - 586",
year = "2015",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2015.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S1568494615003075",
author = "Marcelo Saval-Calvo and Jorge Azorin-Lopez and Andres Fuster-Guillo and Jose Garcia-Rodriguez",
keywords = "Computer vision",
keywords = "Model extraction",
keywords = "RANSAC multi-plane",
keywords = "Three-dimensional planes ",
abstract = "Abstract Plane model extraction from three-dimensional point clouds is a necessary step in many different applications such as planar object reconstruction, indoor mapping and indoor localization. Different \{RANdom\} \{SAmple\} Consensus (RANSAC)-based methods have been proposed for this purpose in recent years. In this study, we propose a novel method-based on \{RANSAC\} called Multiplane Model Estimation, which can estimate multiple plane models simultaneously from a noisy point cloud using the knowledge extracted from a scene (or an object) in order to reconstruct it accurately. This method comprises two steps: first, it clusters the data into planar faces that preserve some constraints defined by knowledge related to the object (e.g., the angles between faces); and second, the models of the planes are estimated based on these data using a novel multi-constraint RANSAC. We performed experiments in the clustering and \{RANSAC\} stages, which showed that the proposed method performed better than state-of-the-art methods. "
}
@article{Guerra2016404,
title = "On small satellites for oceanography: A survey ",
journal = "Acta Astronautica ",
volume = "127",
number = "",
pages = "404 - 423",
year = "2016",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2016.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515303441",
author = "Andre G.C. Guerra and Frederico Francisco and Jaime Villate and Fernando Aguado Agelet and Orfeu Bertolami and Kanna Rajan",
keywords = "Small satellites",
keywords = "Sensors",
keywords = "Ocean observation ",
abstract = "Abstract The recent explosive growth of small satellite operations driven primarily from an academic or pedagogical need, has demonstrated the viability of commercial-off-the-shelf technologies in space. They have also leveraged and shown the need for development of compatible sensors primarily aimed for Earth observation tasks including monitoring terrestrial domains, communications and engineering tests. However, one domain that these platforms have not yet made substantial inroads into, is in the ocean sciences. Remote sensing has long been within the repertoire of tools for oceanographers to study dynamic large scale physical phenomena, such as gyres and fronts, bio-geochemical process transport, primary productivity and process studies in the coastal ocean. We argue that the time has come for micro and nano-satellites (with mass smaller than 100 kg and 2–3 year development times) designed, built, tested and flown by academic departments, for coordinated observations with robotic assets in situ. We do so primarily by surveying SmallSat missions oriented towards ocean observations in the recent past, and in doing so, we update the current knowledge about what is feasible in the rapidly evolving field of platforms and sensors for this domain. We conclude by proposing a set of candidate ocean observing missions with an emphasis on radar-based observations, with a focus on Synthetic Aperture Radar. "
}
@article{Gomez2012218,
title = "RoboGuideDog: Guiding Blind users Through Physical Environments with Laser Range Scanners ",
journal = "Procedia Computer Science ",
volume = "14",
number = "",
pages = "218 - 225",
year = "2012",
note = "Proceedings of the 4th International Conference on Software Development for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2012) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S1877050912007879",
author = "Javier V. Gomez and Frode Eika Sandnes",
keywords = "guide system: laser range finder",
keywords = "intelligent system",
keywords = "haptic feedback ",
abstract = "In this paper we discuss initial concepts of the development of a fully automatic guide dog system for blind users. The physical scene is scanned using a laser range device, and the three dimensional point cloud measurements are analyzed and transformed into a description of the environment that is communicated to the user via synthetic speech and/or haptic feedback allowing the user to navigate around physical space. "
}
@article{Cadena20101207,
title = "\{SLAM\} in with the Combined Kalman-Information Filter ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "11",
pages = "1207 - 1219",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2010.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S092188901000148X",
author = "C. Cadena and J. Neira",
keywords = "SLAM",
keywords = "Extended Kalman Filter",
keywords = "Extended Information Filter",
keywords = "Data association ",
abstract = "In this paper11 This research has been funded by the Direccion General de Investigacion of Spain under the projects DPI2009-13710 and DPI2009-07130. Preliminary versions of this work were presented in the Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems 2009, St. Louis, MO, USA, October 2009, and in the European Conference on Mobile Robotics 2009, Mlini/Dubrovnik, Croatia, September 2009. we describe the Combined Kalman-Information Filter \{SLAM\} algorithm (CF SLAM), a judicious combination of Extended Kalman (EKF) and Extended Information Filters (EIF) that can be used to execute highly efficient \{SLAM\} in large environments. \{CF\} \{SLAM\} is always more efficient than any other \{EKF\} or \{EIF\} algorithm: filter updates can be executed in as low as O ( log n ) as compared with O ( n 2 ) for Map Joining SLAM, O ( n ) for Divide and Conquer (D&amp;C) SLAM, and the Sparse Local Submap Joining Filter (SLSJF). In the worst cases, updates are executed in O ( n ) for \{CF\} \{SLAM\} as compared with O ( n 2 ) for all others. We also study an often overlooked problem in computationally efficient \{SLAM\} algorithms: data association. In situations in which only uncertain geometrical information is available for data association, \{CF\} \{SLAM\} is as efficient as D&amp;C SLAM, and much more efficient than Map Joining \{SLAM\} or SLSJF. If alternative information is available for data association, such as texture in visual SLAM, \{CF\} \{SLAM\} outperforms all other algorithms. In large scale situations, both algorithms based on Extended Information filters, \{CF\} \{SLAM\} and SLSJF, avoid computing the full covariance matrix and thus require less memory, but still \{CF\} \{SLAM\} is the most computationally efficient. Both simulations and experiments with the Victoria Park dataset, the \{DLR\} dataset, and an experiment using visual stereo are used to illustrate the algorithms’ advantages, also with respect to non filtering alternatives such as iSAM, the Treemap and Tectonic SAM. "
}
@article{He2017132,
title = "Updating highway asset inventory using airborne LiDAR ",
journal = "Measurement ",
volume = "104",
number = "",
pages = "132 - 141",
year = "2017",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2017.03.026",
url = "http://www.sciencedirect.com/science/article/pii/S0263224117301847",
author = "Yi He and Ziqi Song and Zhaocai Liu",
keywords = "Asset management",
keywords = "Highway inventory",
keywords = "Airborne LiDAR",
keywords = "Field experiment",
keywords = "ArcGIS-based workflow ",
abstract = "Abstract Highway assets, including traffic signs and signals, light poles, guardrails, and culverts, are essential components of transportation networks. They guide, warn, and protect drivers and regulate traffic. To manage and maintain the regular operation of the highway system, state departments of transportation (DOTs) need reliable and up-to-date information about the location and condition of highway features. Various techniques have been employed to collect highway inventory data. These techniques range from the simplest manual inventory method to methods that involve advanced technology, such as light detection and ranging (LiDAR). The focus of this paper is to analyze the capability and strengths of airborne LiDAR in highway inventory data collection. A field experiment was conducted to collect airborne LiDAR data, and an ArcGIS-based workflow was proposed to process the data. The results demonstrate the effectiveness of the proposed workflow as well as the feasibility and high efficiency of airborne LiDAR for highway inventory data collection. "
}
@article{Jin201549,
title = "Ceilometer calibration for retrieval of aerosol optical properties ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "153",
number = "",
pages = "49 - 56",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part \{II\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.10.009",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314004257",
author = "Yoshitaka Jin and Kenji Kai and Kei Kawai and Tomohiro Nagai and Tetsu Sakai and Akihiro Yamazaki and Akihiro Uchiyama and Dashdondog Batdorj and Nobuo Sugimoto and Tomoaki Nishizawa",
keywords = "Ceilometer",
keywords = "Lidar",
keywords = "Aerosol",
keywords = "Desert dust ",
abstract = "Abstract Ceilometers are durable compact backscatter lidars widely used to detect cloud base height. They are also useful for measuring aerosols. We introduced a ceilometer (CL51) for observing dust in a source region in Mongolia. For retrieving aerosol profiles with a backscatter lidar, the molecular backscatter signal in the aerosol free heights or system constant of the lidar is required. Although the system constant of the ceilometer is calibrated by the manufacturer, it is not necessarily accurate enough for the aerosol retrieval. We determined a correction factor, which is defined as the ratio of true attenuated backscattering coefficient to the measured attenuated backscattering coefficient, for the \{CL51\} ceilometer using a dual-wavelength Mie-scattering lidar in Tsukuba, Japan before moving the ceilometer to Dalanzadgad, Mongolia. The correction factor determined by minimizing the difference between the ceilometer and lidar backscattering coefficients was approximately 1.2±0.1. Applying the correction to the \{CL51\} signals, the aerosol optical depth (AOD) agreed well with the sky-radiometer \{AOD\} during the observation period (13–17 February 2013) in Tsukuba ( 9 × 10 − 3 of mean square error). After moving the ceilometer to Dalanzadgad, however, the \{AOD\} observed with the \{CL51\} (calibrated by the correction factor determined in Tsukuba) was approximately 60% of the \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) sun photometer AOD. The possible causes of the lower \{AOD\} results are as follows: (1) the limited height range of extinction integration ( &lt; 3 km ); (2) change in the correction factor during the ceilometer transportation or with the window contamination in Mongolia. In both cases, on-site calibrations by dual-wavelength lidar are needed. As an alternative method, we showed that the backward inversion method was useful for retrieving extinction coefficients if the \{AOD\} was larger than 1.5. This retrieval method does not require the system constant and molecular backscatter signals, and can be applied to severe dust and air pollution aerosol cases in East Asia. "
}
@article{Aouina20147604,
title = "3D Modeling with a Moving Tilting Laser Sensor for Indoor Environments ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "7604 - 7609",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00460",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016428119",
author = "A. Aouina and M. Devy and A. Marin Hernandez",
abstract = "Abstract Many works are devoted to 3D modeling of indoor environments from mobile sensors. This function has been performed using multiple robotic platforms, equipped with different types of 3D sensors; many theoretical approaches have been proposed to refine these models, either based on \{SLAM\} algorithms when considering only sparse features, or based of ICP-based methods when a dense model is made from the registration of raw 3D data. This paper presents an approach to build a 3D surfacic model based on planar surfaces, using a tilting \{LRF\} (Laser Range Finder) mounted on the \{PR2\} mobile robot, by the fusion of ribbons (sequence of aligned surfels) extracted from the successive scan lines. These lines are acquired on the fly from the LRF, avoiding a stop and go strategy. The ribbons are aggregated using the robot positions given by a 2D \{SLAM\} process executed independantly and simultaneously; all required information are memorized so that the surfacic model can be corrected when the \{SLAM\} process corrects the robot trajectory after a loop closure. "
}
@article{Bibi2015113,
title = "Intercomparison of MODIS, MISR, OMI, and \{CALIPSO\} aerosol optical depth retrievals for four locations on the Indo-Gangetic plains and validation against \{AERONET\} data ",
journal = "Atmospheric Environment ",
volume = "111",
number = "",
pages = "113 - 126",
year = "2015",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015300169",
author = "Humera Bibi and Khan Alam and Farrukh Chishtie and Samina Bibi and Imran Shahid and Thomas Blaschke",
keywords = "AOD",
keywords = "MODIS",
keywords = "MISR",
keywords = "OMI",
keywords = "CALIPSO",
keywords = "AERONET ",
abstract = "Abstract This study provides an intercomparison of aerosol optical depth (AOD) retrievals from satellite-based Moderate Resolution Imaging Spectroradiometer (MODIS), Multiangle Imaging Spectroradiometer (MISR), Ozone Monitoring Instrument (OMI), and Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) instrumentation over Karachi, Lahore, Jaipur, and Kanpur between 2007 and 2013, with validation against \{AOD\} observations from the ground-based Aerosol Robotic Network (AERONET). Both \{MODIS\} Deep Blue (MODISDB) and \{MODIS\} Standard (MODISSTD) products were compared with the \{AERONET\} products. The MODISSTD–AERONET comparisons revealed a high degree of correlation for the four investigated sites at Karachi, Lahore, Jaipur, and Kanpur, the MODISDB–AERONET comparisons revealed even better correlations, and the MISR–AERONET comparisons also indicated strong correlations, as did the OMI–AERONET comparisons, while the CALIPSO–AERONET comparisons revealed only poor correlations due to the limited number of data points available. We also computed figures for root mean square error (RMSE), mean absolute error (MAE) and root mean bias (RMB). Using \{AERONET\} data to validate MODISSTD, MODISDB, MISR, OMI, and \{CALIPSO\} data revealed that \{MODISSTD\} data was more accurate over vegetated locations than over un-vegetated locations, while \{MISR\} data was more accurate over areas close to the ocean than over other areas. The \{MISR\} instrument performed better than the other instruments over Karachi and Kanpur, while the \{MODISSTD\} \{AOD\} retrievals were better than those from the other instruments over Lahore and Jaipur. We also computed the expected error bounds (EEBs) for both \{MODIS\} retrievals and found that \{MODISSTD\} consistently outperformed \{MODISDB\} in all of the investigated areas. High \{AOD\} values were observed by the MODISSTD, MODISDB, MISR, and \{OMI\} instruments during the summer months (April–August); these ranged from 0.32 to 0.78, possibly due to human activity and biomass burning. In contrast, high \{AOD\} values were observed by the \{CALIPSO\} instrument between September and December, due to high concentrations of smoke and soot aerosols. The variable monthly \{AOD\} figures obtained with different sensors indicate overestimation by MODISSTD, MODISDB, OMI, and \{CALIPSO\} instruments over Karachi, Lahore, Jaipur and Kanpur, relative to the \{AERONET\} data, but underestimation by the \{MISR\} instrument. "
}
@article{Canal201665,
title = "A real-time Human-Robot Interaction system based on gestures for assistive scenarios ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "65 - 77",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - 'Assistive Solutions for Mobility, Communication and HMI' ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S107731421600076X",
author = "Gerard Canal and Sergio Escalera and Cecilio Angulo",
keywords = "Gesture recognition",
keywords = "Human Robot Interaction",
keywords = "Dynamic Time Warping",
keywords = "Pointing location estimation ",
abstract = "Abstract Natural and intuitive human interaction with robotic systems is a key point to develop robots assisting people in an easy and effective way. In this paper, a Human Robot Interaction (HRI) system able to recognize gestures usually employed in human non-verbal communication is introduced, and an in-depth study of its usability is performed. The system deals with dynamic gestures such as waving or nodding which are recognized using a Dynamic Time Warping approach based on gesture specific features computed from depth maps. A static gesture consisting in pointing at an object is also recognized. The pointed location is then estimated in order to detect candidate objects the user may refer to. When the pointed object is unclear for the robot, a disambiguation procedure by means of either a verbal or gestural dialogue is performed. This skill would lead to the robot picking an object in behalf of the user, which could present difficulties to do it by itself. The overall system — which is composed by a \{NAO\} and Wifibot robots, a KinectTM v2 sensor and two laptops — is firstly evaluated in a structured lab setup. Then, a broad set of user tests has been completed, which allows to assess correct performance in terms of recognition rates, easiness of use and response times. "
}
@incollection{Melson2015179,
title = "Chapter 13 - Animals in the Lives of Children ",
editor = "Fine, Aubrey H. ",
booktitle = "Handbook on Animal-Assisted Therapy (Fourth Edition) ",
publisher = "Academic Press",
edition = "Fourth Edition",
address = "San Diego",
year = "2015",
pages = "179 - 194",
isbn = "978-0-12-801292-5",
doi = "https://doi.org/10.1016/B978-0-12-801292-5.00013-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128012925000134",
author = "Gail F. Melson and Aubrey H. Fine",
keywords = "Animal-assisted therapy",
keywords = "Biophilia",
keywords = "Ecological psychology",
keywords = "Relational and self psychologies ",
abstract = "Abstract All therapeutic interventions involving animals rest on a powerful assumption: there is something about animals that powerfully attracts and motivates humans. This assumption becomes especially compelling when children are involved. No matter what facet of human–animal interaction one examines—pet ownership, fascination with wild animals, imaginary animals, robotic pets—children are particularly involved. In this chapter we examine the child–animal connection closely for what it can tell us about the meaning of animals in children’s lives. In turn, this provides an important context for examining animal-assisted therapies and activities for children. "
}
@article{Lee20147104,
title = "New Thinking Paradigm for Maintenance Innovation Design ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "7104 - 7109",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02519",
url = "http://www.sciencedirect.com/science/article/pii/S147466701642731X",
author = "Jay Lee and Maria Holgado and Hung-An Kao and Marco Macchi",
abstract = "Abstract Meanwhile the manufacturing paradigm changes towards predictive manufacturing, the role of maintenance function within manufacturing needs to be refined as a value creation function for achieving more sustainable operations. With the advent of internet of things (IoT), cloud computing, big data, PHM, and cyber-physical systems, e-maintenance necessitates new transformation. These changes are driving a new thinking paradigm for maintenance. This paper introduces new perspectives for maintenance innovation and proposes the value creation paths for maintenance transformation. "
}
@article{Delhaye201748,
title = "The \{MERMOSE\} project: Characterization of particulate matter emissions of a commercial aircraft engine ",
journal = "Journal of Aerosol Science ",
volume = "105",
number = "",
pages = "48 - 63",
year = "2017",
note = "",
issn = "0021-8502",
doi = "https://doi.org/10.1016/j.jaerosci.2016.11.018",
url = "http://www.sciencedirect.com/science/article/pii/S0021850216302233",
author = "David Delhaye and Francois-Xavier Ouf and Daniel Ferry and Ismael K. Ortega and Olivier Penanhoat and Samuel Peillon and Francois Salm and Xavier Vancassel and Cristian Focsa and Cornelia Irimiea and Nadine Harivel and Bruno Perez and Etienne Quinton and Jerôme Yon and Daniel Gaffie",
keywords = "Aircraft engine \{PM\} emission",
keywords = "Soot",
keywords = "Size distributions",
keywords = "Physico-chemical characterization ",
abstract = "Abstract The French national project \{MERMOSE\} gathers the capabilities of seven organizations to better characterize commercial aircraft engine emissions and to better understand their impact on nucleation processes in the atmosphere. In this frame, a measurement campaign has been performed on a Snecma/NPO Saturn SaM146-1S17 turbofan. During this work, we used a complete set of on-line and off-line techniques to measure radial and angular profiles of particulate matter (PM) properties in the engine exhaust hot flow. We studied different engine thrust settings, selected to match the aircraft main operating conditions (idle, climb, take-off, approach and “ground” cruise). The mode of the emitted particles size distribution ranged from 17 nm to 55 nm and was sensitive to the thrust. The sampled \{PM\} showed a complex morphology and were formed by primary nanoparticles of about 15 nm in diameter. They were mainly composed of carbon (with traces of oxygen, sulfur and calcium) and their organic carbon to total carbon ratio (OC/TC) ratio showed a decrease as a function of the maximum thrust from ~80% for 30% thrust setting to ~12% for 100%. "
}
@article{Ros2014707,
title = "Adaptive human–robot interaction in sensorimotor task instruction: From human to robot dance tutors ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "707 - 720",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000499",
author = "Raquel Ros and Ilaria Baroni and Yiannis Demiris",
keywords = "Child–robot interaction",
keywords = "Adaptive behavior",
keywords = "Dance",
keywords = "Involvement measure ",
abstract = "Abstract We explore the potential for humanoid robots to interact with children in a dance activity. In this context, the robot plays the role of an instructor to guide the child through several dance moves to learn a dance phrase. We participated in 30 dance sessions in schools to study human–human interaction between children and a human dance teacher, and to identify the applied methodologies. Based on the strategies observed, both social and task-dependent, we implemented a robotic system capable of autonomously instructing dance sequences to children while displaying basic social cues to engage the child in the task. Experiments were performed in a hospital with the Nao robot interacting with 12 children through multiple encounters, when possible (18 sessions, 236 min). Observational analysis through video recordings and survey evaluations were used to assess the quality of interaction. Moreover, we introduce an involvement measure based on the aggregation of observed behavioral cues to assess the level of interest in the interaction through time. The analysis revealed high levels of involvement, while highlighting the need for further research into social engagement and adaptation with robots over repeated sessions. "
}
@article{Huebner2012367,
title = "BADGr—A toolbox for box-based approximation, decomposition and \{GRasping\} ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "367 - 376",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.021",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001539",
author = "Kai Huebner",
keywords = "Part-based grasping",
keywords = "3D shape approximation",
keywords = "Grasp database generation",
keywords = "Open source software ",
abstract = "In this paper, we conclude our work on shape approximation by box primitives for the goal of simple and efficient grasping. As a main product of our research, we present the \{BADGr\} toolbox for Box-based Approximation, Decomposition and Grasping of objects. The contributions of the work presented here are twofold: in terms of shape approximation, we provide an algorithm for creating a 3D box primitive representation to identify object parts from 3D point clouds. We motivate and evaluate this choice particularly towards the task of grasping. As a contribution in the field of grasping, we further provide a grasp hypothesis generation framework that utilizes the chosen box presentation in a flexible manner. "
}
@article{Wang2016158,
title = "Towards smart factory for industry 4.0: a self-organized multi-agent system with big data based feedback and coordination ",
journal = "Computer Networks ",
volume = "101",
number = "",
pages = "158 - 168",
year = "2016",
note = "Industrial Technologies and Applications for the Internet of Things ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.12.017",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615005046",
author = "Shiyong Wang and Jiafu Wan and Daqiang Zhang and Di Li and Chunhua Zhang",
keywords = "Industry 4.0",
keywords = "Smart factory",
keywords = "Cyber-physical system",
keywords = "Multi-agent system",
keywords = "Deadlock prevention ",
abstract = "Abstract The proliferation of cyber-physical systems introduces the fourth stage of industrialization, commonly known as Industry 4.0. The vertical integration of various components inside a factory to implement a flexible and reconfigurable manufacturing system, i.e., smart factory, is one of the key features of Industry 4.0. In this paper, we present a smart factory framework that incorporates industrial network, cloud, and supervisory control terminals with smart shop-floor objects such as machines, conveyers, and products. Then, we provide a classification of the smart objects into various types of agents and define a coordinator in the cloud. The autonomous decision and distributed cooperation between agents lead to high flexibility. Moreover, this kind of self-organized system leverages the feedback and coordination by the central coordinator in order to achieve high efficiency. Thus, the smart factory is characterized by a self-organized multi-agent system assisted with big data based feedback and coordination. Based on this model, we propose an intelligent negotiation mechanism for agents to cooperate with each other. Furthermore, the study illustrates that complementary strategies can be designed to prevent deadlocks by improving the agents’ decision making and the coordinator's behavior. The simulation results assess the effectiveness of the proposed negotiation mechanism and deadlock prevention strategies. "
}
@article{Glantz200958,
title = "Estimating a relationship between aerosol optical thickness and surface wind speed over the ocean ",
journal = "Atmospheric Research ",
volume = "92",
number = "1",
pages = "58 - 68",
year = "2009",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2008.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169809508002354",
author = "P. Glantz and E.D. Nilsson and W. von Hoyningen-Huene",
keywords = "AOT",
keywords = "Sea salt",
keywords = "Hydroscopic growth",
keywords = "Marine aerosols ",
abstract = "Retrieved aerosol optical thickness (AOT) based on data obtained by the Sea-viewing Wide Field Sensor (SeaWiFS) is combined with surface wind speed, obtained at the European Centre for Medium-Range Weather Forecasts (ECMWF), over the North Pacific for September 2001. In this study a cloud-screening approach is introduced in an attempt to exclude pixels partly or fully covered by clouds. The relatively broad swath width through which the nadir-viewing SeaWiFS scanned over the North Pacific means that the \{AOT\} can be estimated according to a relatively large range of wind speeds for each of the scenes analyzed. The sensitivity in \{AOT\} due to sea salt and hygroscopic growth of the marine aerosols was also investigated. The validation approach is based on previous parameterization in combination with the environmental quantities wind speed, \{RH\} and boundary layer height (BLH), estimated at the ECMWF. In this study a factor of 2 higher \{AOT\} is obtained between the highest wind speed (12 m s− 1) and the lowest wind speed range (0–4 m s− 1) for September 2001 over remote ocean areas. This is supported by the validation of the results. The enhancement in \{AOT\} is explained by a combination of hygroscopic growth of the marine aerosols (~ 40%) and an increase in the sea salt particle mass concentrations (~ 60%), caused by a wind-driven water vapor and sea salt flux respectively. Reasonable agreement (within 1 to 52%) occurs also between satellite-retrieved aerosol optical thickness and \{AOT\} observed at two \{AERONET\} (AErosol \{RObotic\} NETwork) ground-based remote sensing stations. The overall variability is also observed by this comparison. Finally, possible reasons why relatively large standard deviations occur around the mean values of AOT, when all data is taken into consideration in the analyses for September 2001, are discussed. "
}
@article{Ramisa2014246,
title = "Learning RGB-D descriptors of garment parts for informed robot grasping ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "35",
number = "",
pages = "246 - 258",
year = "2014",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2014.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S095219761400147X",
author = "Arnau Ramisa and Guillem Alenya and Francesc Moreno-Noguer and Carme Torras",
keywords = "Computer vision",
keywords = "Pattern recognition",
keywords = "Machine learning",
keywords = "Garment part detection",
keywords = "Classification",
keywords = "Bag of Visual Words ",
abstract = "Abstract Robotic handling of textile objects in household environments is an emerging application that has recently received considerable attention thanks to the development of domestic robots. Most current approaches follow a multiple re-grasp strategy for this purpose, in which clothes are sequentially grasped from different points until one of them yields a desired configuration. In this work we propose a vision-based method, built on the Bag of Visual Words approach, that combines appearance and 3D information to detect parts suitable for grasping in clothes, even when they are highly wrinkled. We also contribute a new, annotated, garment part dataset that can be used for benchmarking classification, part detection, and segmentation algorithms. The dataset is used to evaluate our approach and several state-of-the-art 3D descriptors for the task of garment part detection. Results indicate that appearance is a reliable source of information, but that augmenting it with 3D information can help the method perform better with new clothing items. "
}
@article{Varga20177,
title = "New approaches for cement-based prophylactic augmentation of the osteoporotic proximal femur provide enhanced reinforcement as predicted by non-linear finite element simulations ",
journal = "Clinical Biomechanics ",
volume = "44",
number = "",
pages = "7 - 13",
year = "2017",
note = "",
issn = "0268-0033",
doi = "https://doi.org/10.1016/j.clinbiomech.2017.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0268003317300591",
author = "Peter Varga and Jason A. Inzana and Jakob Schwiedrzik and Philippe K. Zysset and Boyko Gueorguiev and Michael Blauth and Markus Windolf",
keywords = "Prophylactic augmentation",
keywords = "Proximal femur",
keywords = "Femoroplasty",
keywords = "Osteoporosis",
keywords = "Finite element analysis ",
abstract = "AbstractBackground High incidence and increased mortality related to secondary, contralateral proximal femoral fractures may justify invasive prophylactic augmentation that reinforces the osteoporotic proximal femur to reduce fracture risk. Bone cement-based approaches (femoroplasty) may deliver the required strengthening effect; however, the significant variation in the results of previous studies calls for a systematic analysis and optimization of this method. Our hypothesis was that efficient generalized augmentation strategies can be identified via computational optimization. Methods This study investigated, by means of finite element analysis, the effect of cement location and volume on the biomechanical properties of fifteen proximal femora in sideways fall. Novel cement cloud locations were developed using the principles of bone remodeling and compared to the “single central” location that was previously reported to be optimal. Findings The new augmentation strategies provided significantly greater biomechanical benefits compared to the “single central” cement location. Augmenting with approximately 12 ml of cement in the newly identified location achieved increases of 11% in stiffness, 64% in yield force, 156% in yield energy and 59% in maximum force, on average, compared to the non-augmented state. The weaker bones experienced a greater biomechanical benefit from augmentation than stronger bones. The effect of cement volume on the biomechanical properties was approximately linear. Results of the “single central” model showed good agreement with previous experimental studies. Interpretation These findings indicate enhanced potential of cement-based prophylactic augmentation using the newly developed cementing strategy. Future studies should determine the required level of strengthening and confirm these numerical results experimentally. "
}
@article{Tateno2017138,
title = "Large scale and long standing simultaneous reconstruction and segmentation ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "138 - 150",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.05.013",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300662",
author = "Keisuke Tateno and Federico Tombari and Nassir Navab",
keywords = "Dense SLAM",
keywords = "Segmentation",
keywords = "Real-time",
keywords = "Scalable",
keywords = "Long standing",
keywords = "Relocalization",
keywords = "Loop-closure ",
abstract = "Abstract This work proposes a method to segment a 3D point cloud of a scene while simultaneously reconstructing it via Simultaneous Localization And Mapping (SLAM). The proposed method incrementally merges segments obtained from each input depth image in an unified global model leveraging the camera pose estimated via SLAM. Differently from other approaches, our method is able to yield segmentation of scenes reconstructed from multiple views in real-time and with a complexity that does not depend on the size of the global model. Moreover, we endow our system with two additional contributions: a loop closure approach and a failure recovery and re-localization approach, both specifically designed so to enforce global consistency between merged segments, thus making our system suitable for large scale and long standing reconstruction and segmentation. We validate our proposal against the state of the art in terms of computational efficiency and accuracy on several benchmark datasets, as well as by showing how our method enables real-time reconstruction and segmentation of diverse real indoor environments. "
}
@article{Jackson2016274,
title = "Digital Manufacturing and Flexible Assembly Technologies for Reconfigurable Aerospace Production Systems ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "274 - 279",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.054",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116308046",
author = "Keith Jackson and Konstantinos Efthymiou and John Borton",
keywords = "Aerospace",
keywords = "Manufacturing",
keywords = "Reconfiguration",
keywords = "Digital Manufacturing",
keywords = "M4 ",
abstract = "Abstract Reconfigurability is an important aspect of modern manufacturing systems as it facilitates the seamless introduction of new products to production and the adaptation to demand volatility. Advanced manufacturing technologies broadly used in automotive industry have limited application for typical \{UK\} aerospace manufacturing, as they require production volume and repetition of operations to deliver value. This paper discusses a framework of key technologies ranging from digital manufacturing concepts to flexible fixturing that enable reconfigurability in aerospace manufacturing systems. Initially, the overall architecture of the framework is presented illustrating the key components such as a cloud based data storage mechanism, an intelligent multi-product assembly station, kitting boxes embedded with sensors, a manufacturing network management portal and a decision support tool that combines data analytics and discrete event simulation. Afterwards, the main functionalities and technologies of the components are described and finally an industrial application scenario for the proposed framework is presented. "
}
@article{Mussa2009272,
title = "Atmospheric Monitoring for the Pierre Auger Observatory ",
journal = "Nuclear Physics B - Proceedings Supplements ",
volume = "190",
number = "",
pages = "272 - 277",
year = "2009",
note = "Proceedings of the Cosmic Ray International Seminars ",
issn = "0920-5632",
doi = "https://doi.org/10.1016/j.nuclphysbps.2009.03.099",
url = "http://www.sciencedirect.com/science/article/pii/S0920563209003387",
author = "R. Mussa",
abstract = "The monitoring of atmospheric transparency plays a key role in the reconstruction of ultra high energy cosmic rays with the air fluorescence technique. A review of the instruments (LIDARs, Central Laser Facility, Aerosol Phase Function Monitor) for the detection and characterization of cloud and aerosol parameters in the Pierre Auger Observatory is given. "
}
@article{Mayburd201159,
title = "A possibility of miniaturized fusion and fission hybrid reaction core with positive fusion yield ",
journal = "Nuclear Engineering and Design ",
volume = "241",
number = "1",
pages = "59 - 66",
year = "2011",
note = "",
issn = "0029-5493",
doi = "https://doi.org/10.1016/j.nucengdes.2010.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S002954931000693X",
author = "Anatoly Mayburd",
abstract = "A novel fission–fusion hybrid reactor was proposed, comprising saturating of a fissile actinide core with a mix of deuterium–tritium hydrogen isotopes (U–D–T target), similarly to Hyperion design. Movement of massive, highly charged and short-range fissile fragments was assumed to produce transfer of energy to deuterons at the distances below collision impact parameter for electrons, when the latter are already deflected. The overall bulk of energy transfer was still assumed to be directed to electrons, being argued to experience secondary interactions in dense metallic matrix at a short distance (∼3 × 10−13 m) from the projectile. The resulting energy dissipation occurs as a continuous shockwave front (as opposed to discrete transfer in environments of lesser densities) producing compression ahead of the projectile and impacting local values of density. The continuity at short distances from the projectile justified hydrodynamic analogy and application of Taylor–Sedov's shockwave theory. At higher local densities in a bow-wave, the probability of high-energy deuteron acceleration was shown to increase in proportion to compression. The transient non-equilibrium equivalents of pressure and temperature may support fusion in the region with volume V over hot zone life-time τ. Both parameters were compared for the U–D–T and benchmark system (accelerator driven deuteron implantation in a non-actinide hydride target) in a dimensionless and hypothesis-free form, canceling the complexities of the mechanism. Based on the dimensionless theoretical prediction, ∼1–2 fusion 14 MeV neutrons per fission are expected to be produced, accompanied by 1–2 photoneutrons and leading to a significantly decreased critical mass. If confirmed experimentally, the proposed system could produce ∼10–20% of its energy output as controlled fusion, be of compact and economical design, environmentally friendly, lead to significant miniaturization of reactor core compatible with high rate of heat exchange. Novel technological applications in robotics, propulsion, sea bed exploration and as a robust energy source were proposed. "
}
@article{Wang2016237,
title = "An effective multivariate time series classification approach using echo state network and adaptive differential evolution algorithm ",
journal = "Expert Systems with Applications ",
volume = "43",
number = "",
pages = "237 - 249",
year = "2016",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.08.055",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415006120",
author = "Lin Wang and Zhigang Wang and Shan Liu",
keywords = "Multivariate time series classification",
keywords = "Recurrent neural network",
keywords = "Adaptive differential evolution algorithm ",
abstract = "Abstract The multivariate time series (MTS) classification is a very difficult process because of the complexity of the \{MTS\} data type. Among all the methods to resolve this problem, the attribute–value representation classification approaches are the most popular. Despite their proven effectiveness of these however, these approaches are time consuming, sensitive to noise, or prone to damage of inner data properties as well as capable of producing undesirable accuracy. In this paper, we propose a new approach (CADE) for \{MTS\} classification that utilizes recurrent neural network (RNN) and adaptive differential evolution (ADE) algorithm. The approach can effectively overcome specific shortcomings of the attribute–value representation approaches. The principle of this approach adheres to three steps. First, an \{RNN\} is used to project the training \{MTS\} samples into different state clouds (samples in the same class are projected into a state cloud). Second, classifiers from these state clouds are induced for different classes. Third, the final \{MTS\} classifiers are obtained using \{ADE\} for parameter optimization. This approach makes full use of the network state space of a given \{RNN\} to induce classifiers rather than to train the network. Experimental results performed on 18 data sets demonstrate the accuracy and robustness of the proposed approach for \{MTS\} classification. As a new and universal approach, \{CADE\} can be very effective and stable for handling a variety of complex classification problems. "
}
@article{Wang2015918,
title = "Performance Evaluation of Automatically Generated \{BIM\} from Laser Scanner Data for Sustainability Analyses ",
journal = "Procedia Engineering ",
volume = "118",
number = "",
pages = "918 - 925",
year = "2015",
note = "Defining the future of sustainability and resilience in design, engineering and construction ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.08.531",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815021864",
author = "Chao Wang and Yong K. Cho",
keywords = "Laser scanning",
keywords = "Energy efficiency",
keywords = "As-is BIM",
keywords = "Decision support ; ",
abstract = "Abstract Existing buildings now represent the greatest opportunity to improve building energy efficiency. Building performance analysis is becoming increasingly important because decision makers can have a better visualization of their building's performance and quickly make the solution for improving building energy efficiency and reducing environmental impacts. Nowadays, building information models (BIMs) have been widely created during the design phase of new buildings, and it can be easily imported to third party software to conduct various analyses. However, a \{BIM\} is not always available for all existing buildings. Even if a \{BIM\} is available during the design and construction phases, it is very challenging to keep updating it while a building is aged. A manual process to create or update a \{BIM\} is very time consuming and labor intensive. A laser scanning technology has been a popular tool to create as-is BIM. However it still needs labor-intensive manual processes to create a \{BIM\} out of point clouds. This paper introduces automatic as-is simplified \{BIM\} creation from point clouds for energy simulations. A framework of decision support system that can assist decision makers on retrofits for existing buildings is introduced as well. A case study on a residential house was tested in this study to validate the proposed framework, and the technical feasibility of the developed system was positively demonstrated. "
}
@incollection{Kai2002367,
title = "11 - Data Structure in Rapid Prototyping and Manufacturing ",
editor = "Leondes, Cornelius T. ",
booktitle = "Database and Data Communication Network Systems ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2002",
pages = "367 - 416",
isbn = "978-0-12-443895-8",
doi = "https://doi.org/10.1016/B978-012443895-8/50013-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780124438958500131",
author = "Chua Chee Kai and Jacob Gan and Du Zhaohui and Tong Mei",
abstract = "Publisher Summary The efficient management of geometric information, such as points, curves, or polyhedrons, is of significant importance in many engineering applications such as computer-aided design (CAD), computer-aided manufacturing (CAM), robotics, and rapid prototyping and manufacturing (RP&amp;M). A good representation scheme maps the original data objects into a set of objects to facilitate efficient storage and computation. A data structure is the form of organization imposed on the collection of those data elements. It is defined by specifying what kind of elements it contains, and stating the rules of how to store the elements and how to retrieve them when needed. Data structures may be classified into linear and nonlinear types. Linear structures are those elements that have a sequential relationship. It occupies a special place in the study of data structures because the addressing of storage locations in a computer is nearly always linear, so the set of memory storage locations in the machine itself constitutes a linear structure. Nonlinear data structures are of varied sorts. One category important to the software designer is that of hierarchical structures, in which each element is itself a data structure. A good data structure is vital to the reliability and efficiency of a program or software. "
}
@article{Yang2017175,
title = "TOLDI: An effective and robust approach for 3D local shape description ",
journal = "Pattern Recognition ",
volume = "65",
number = "",
pages = "175 - 187",
year = "2017",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.11.019",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316303776",
author = "Jiaqi Yang and Qian Zhang and Yang Xiao and Zhiguo Cao",
keywords = "Local reference frame",
keywords = "Local feature descriptor",
keywords = "Shape retrieval",
keywords = "Object recognition",
keywords = "3D registration ",
abstract = "Abstract Feature description for the 3D local shape in the presence of noise, varying mesh resolutions, clutter and occlusion is a quite challenging task in 3D computer vision. This paper tackles the problem by proposing a new local reference frame (LRF) together with a novel triple orthogonal local depth images (TOLDI) representation, forming the \{TOLDI\} method for local shape description. Compared with previous methods, \{TOLDI\} manages to perform efficient, distinctive and robust description for the 3D local surface simultaneously under various feature matching contexts. The proposed \{LRF\} differs from many prior ones in its calculation of the z-axis and x-axis, the z-axis is calculated using the normal of the keypoint and the x-axis is computed by aggregating the weighted projection vectors of the radius neighbors. \{TOLDI\} feature descriptors are then obtained by concatenating three local depth images (LDI) captured from three orthogonal view planes in the \{LRF\} into feature vectors. The performance of our \{TOLDI\} approach is rigorously evaluated on several public datasets, which contain three major surface matching scenarios, namely shape retrieval, object recognition and 3D registration. Experimental results and comparisons with the state-of-the-arts validate the effectiveness, robustness, high efficiency, and overall superiority of our method. Our method is also applied to aligning 3D object and indoor scene point clouds obtained by different devices (i.e., LiDAR and Kinect), the accurate outcomes further confirm the effectiveness of our method. "
}
@article{He2017150,
title = "\{MODIS\} 3 km and 10 km aerosol optical depth for China: Evaluation and comparison ",
journal = "Atmospheric Environment ",
volume = "153",
number = "",
pages = "150 - 162",
year = "2017",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2017.01.023",
url = "http://www.sciencedirect.com/science/article/pii/S1352231017300225",
author = "Qingqing He and Ming Zhang and Bo Huang and Xuelian Tong",
keywords = "MODIS",
keywords = "AERONET",
keywords = "Aerosol optical depth",
keywords = "Validation",
keywords = "Spatiotemporal comparison",
keywords = "China ",
abstract = "Abstract The recently released Moderate Resolution Imaging Spectrometer (MODIS) Collection 6 introduced a fine scale aerosol optical depth (AOD) distribution, the 3 km product, which is expected to perform well in analyzing aerosols and identifying local air pollution, especially in the severely polluted atmosphere of China. However, few detailed evaluations of regional variations have been conducted. In this paper, we evaluate \{MODIS\} 3 km and 10 km \{AOD\} products for China against ground-based measurements and compare their performance with respect to spatial and temporal variations. The ground validations indicate that the two products are generally correlated well to ground-based observations. Spatially, the 3 km product slightly outperform the 10 km product in well-developed areas of southern China. Temporally, both products perform worse during spring and summer. Atmospheric clouds and underlying surface are two key factors that influence the accuracy and number of retrievals for both products. The comparison analysis reveals the newly introduced \{AOD\} product clearly shows good relationships with the coarse resolution retrievals in spatial and temporal variation but significant differences regarding details. The 3 km \{AOD\} product provides better aerosol gradients, more retrievals in bare areas of western China and some spikes of diurnal variation in cloudy days. Seasonal comparisons show the 3 km \{AOD\} product is higher than the 10 km product in all seasons, especially during spring and summer. Although the 3 km product for China generally performs slightly worse than the 10 km product, the added information of the \{MODIS\} 3 km \{AOD\} product shows potential for studying local aerosol characterization, and may facilitate studies of air pollution. "
}
@article{Wu20031181,
title = "Improvements to algorithms for computing the Minkowski sum of 3-polytopes ",
journal = "Computer-Aided Design ",
volume = "35",
number = "13",
pages = "1181 - 1192",
year = "2003",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(03)00023-X",
url = "http://www.sciencedirect.com/science/article/pii/S001044850300023X",
author = "Yanyan Wu and Jami J. Shah and Joseph K. Davidson",
keywords = "Geometric algorithms",
keywords = "Minkowski sum",
keywords = "Convex hull",
keywords = "Polytopes",
keywords = "Math modeling of geometric variations ",
abstract = "A Minkowski sum is a geometric operation that is equivalent either to the vector additions of all points in two operands or to the sweeping of one operand around the profile of the other without changing the relative orientation. Applications of Minkowski sums are found in computer graphics, robotics, spatial planning, and CAD. This paper presents two algorithms for computing Minkowski sum of convex polyhedron in three space (3-polytopes). Both algorithms are improvements on current ones found in the literature. One is based on convex hulls and the other on slope diagrams. The original convex hull based Minkowski algorithm is costly, while the original slope diagram based algorithms require the operation of stereographic projection from 3D to 2D for merging the slope diagrams of the two operands. Implementation of stereographic projection is complicated which increases the computation time and reduces the accuracy of the geometric information that is needed for constructing the resultant solid. This paper reports on improvements that have been made to these two algorithms and their implementation. These improvements include using vector operations to find the interrelations between points, arcs and regions on a unit sphere for the slope diagram algorithm, and addition of a pre-sorting procedure before constructing convex hull for convex hull based Minkowski sum algorithm. With these improvements, the computation time and complexity for both algorithms have been reduced significantly, and the computational accuracy of the slope diagram algorithm has been improved. This paper also compares these two algorithms to each other and to their original counterparts. The potential for extending these algorithms to higher dimensions is briefly discussed. "
}
@incollection{Bellouin201540,
title = "\{AEROSOLS\} | Climatology of Tropospheric Aerosols ",
editor = "North, Gerald R. and Pyle, John  and Zhang, Fuqing ",
booktitle = "Encyclopedia of Atmospheric Sciences (Second Edition) ",
publisher = "Academic Press",
edition = "Second Edition",
address = "Oxford",
year = "2015",
pages = "40 - 47",
isbn = "978-0-12-382225-3",
doi = "https://doi.org/10.1016/B978-0-12-382225-3.00051-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780123822253000517",
author = "N. Bellouin and J. Haywood",
keywords = "Aerosols",
keywords = "Mineral dust",
keywords = "Particles",
keywords = "Particulate matter",
keywords = "Sea-salt",
keywords = "Sulfate ",
abstract = "Synopsis Aerosols are solid or liquid particles either directly emitted into the atmosphere or converted from gaseous precursors. Both natural processes and human activities generate aerosols. They affect visibility, air quality, formation of clouds, and the energy budget of the Earth. Aerosols remain in the troposphere for up to 2 weeks, where they experience chemical transformation and long-range transport. "
}
@article{Xia201472,
title = "A critical assessment of direct radiative effects of different aerosol types on surface global radiation and its components ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "149",
number = "",
pages = "72 - 80",
year = "2014",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.07.020",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003264",
author = "Xiangao Xia",
keywords = "Aerosol",
keywords = "Direct radiative effect",
keywords = "Aerosol type ",
abstract = "Abstract A critical assessment of direct radiative effects of different aerosol types on surface global, direct and diffuse radiation is presented. The analysis is based on measurements of aerosol optical properties and surface solar radiation (SSR) of cloud-free days at the Baseline Surface Radiation Network (BSRN) and Aerosol Robotic Network station (AERONET) of Xianghe over the North China Plain between October 2004 and May 2012. Six aerosol types are classified based on aerosol size and absorption from the \{AERONET\} retrieval products, including two coarse-mode dominated aerosol types: dust (DU: fine mode fraction (FMF)&lt;0.4) and polluted dust (PD: \{FMF\} within 0.4–0.7) and four fine-mode dominated aerosol types (FMF&gt;0.7) but with different single scattering albedo (SSA): highly absorbing (HA: SSA&lt;0.85), moderately absorbing (MA: \{SSA\} within 0.85–0.90), slightly absorbing (SA: \{SSA\} within 0.90–0.95) and very weakly absorbing (WA: SSA&gt;0.95). Dramatic differences in aerosol direct radiative effect (ADRE) on global \{SSR\} and its components between the six aerosol types have been revealed. \{ADRE\} efficiency on global \{SSR\} for solar zenight angle (SZA) between 55° and 65° ranges from −106 W m−2 for \{WA\} to −181 W m−2 for HA. The minimum \{ADRE\} efficiency on diffuse \{SSR\} is derived for \{HA\} aerosols, being 113 W m−2 that is about half of that by DU, the maximum value of six aerosol types. \{ADRE\} efficiency on global \{SSR\} by \{DU\} and \{PD\} (−141 to −150 W m−2 for \{SZA\} between 55° and 65°) is comparable to that by MA, although 100 W m−2 more direct \{SSR\} is extincted by \{DU\} and \{PD\} than by MA. \{DU\} and \{PD\} induce more diffuse \{SSR\} than \{MA\} that offsets larger reduction of direct \{SSR\} by \{DU\} and PD. Implications of the results to related researches are detailed discussed. The results are derived from aerosol and radiation data in the North China Plain, however the method can be used to any other stations with similar measurements. "
}
@incollection{Guenther1997383,
title = "Neural Models for Flexible Control of Redundant Systems ",
editor = "Pietro Morasso and Vittorio Sanguineti",
booktitle = "Self-Organization, Computational Maps, and Motor Control",
publisher = "North-Holland",
year = "1997",
volume = "119",
pages = "383 - 421",
series = "Advances in Psychology ",
issn = "0166-4115",
doi = "https://doi.org/10.1016/S0166-4115(97)80014-3",
url = "http://www.sciencedirect.com/science/article/pii/S0166411597800143",
author = "Frank H. Guenther and Daniele Micci Barreca",
abstract = "Abstract This chapter discusses the explanation of a class of human motor equivalence competencies put forth by the \{DIVA\} and \{DIRECT\} models of motor skill acquisition and performance. It is suggested that experimental data indicating approximate postural invariance for reaches do not imply that the motor system is utilizing postural targets. Instead, an inverse kinematics transformation utilizing a directional mapping with a “postural relaxation” component is shown to be consistent with these data while also providing motor equivalent capabilities not possessed by models that use postural targets. This transformation is related to robotics techniques utilizing a Jacobian pseudoinverse and to the motor control models of Cruse and colleagues. A self-organizing neural network architecture that learns such a directional mapping is presented, including simulations verifying its ability to explain the approximate postural invariance seen in the experimental data. Side effects of the model’s learning process suggest two sources that may contribute to the gentle curvature seen in human reaches: a bias toward movements along the long axis of the manipulability ellipsoid, and a tendency toward more comfortable postures. "
}
@article{Munaro2016525,
title = "OpenPTrack: Open source multi-camera calibration and people tracking for RGB-D camera networks ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "525 - 538",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002304",
author = "Matteo Munaro and Filippo Basso and Emanuele Menegatti",
keywords = "OpenPTrack",
keywords = "People tracking",
keywords = "RGB-D",
keywords = "Open source",
keywords = "Multi-camera",
keywords = "Network calibration",
keywords = "Human–robot interaction",
keywords = "Microsoft Kinect",
keywords = "Mesa SwissRanger",
keywords = "Stereo ",
abstract = "Abstract OpenPTrack is an open source software for multi-camera calibration and people tracking in RGB-D camera networks. It allows to track people in big volumes at sensor frame rate and currently supports a heterogeneous set of 3D sensors. In this work, we describe its user-friendly calibration procedure, which consists of simple steps with real-time feedback that allow to obtain accurate results in estimating the camera poses that are then used for tracking people. On top of a calibration based on moving a checkerboard within the tracking space and on a global optimization of cameras and checkerboards poses, a novel procedure which aligns people detections coming from all sensors in a x - y - t i m e space is used for refining camera poses. While people detection is executed locally, in the machines connected to each sensor, tracking is performed by a single node which takes into account detections from all over the network. Here we detail how a cascade of algorithms working on depth point clouds and color, infrared and disparity images is used to perform people detection from different types of sensors and in any indoor light condition. We present experiments showing that a considerable improvement can be obtained with the proposed calibration refinement procedure that exploits people detections and we compare Kinect v1, Kinect v2 and Mesa \{SR4500\} performance for people tracking applications. OpenPTrack is based on the Robot Operating System and the Point Cloud Library and has already been adopted in networks composed of up to ten imagers for interactive arts, education, culture and human–robot interaction applications. "
}
@article{Piqueux2015332,
title = "Enumeration of Mars years and seasons since the beginning of telescopic exploration ",
journal = "Icarus ",
volume = "251",
number = "",
pages = "332 - 338",
year = "2015",
note = "Dynamic Mars ",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0019103514006940",
author = "Sylvain Piqueux and Shane Byrne and Hugh H. Kieffer and Timothy N. Titus and Candice J. Hansen",
keywords = "Mars",
keywords = "Mars, polar caps",
keywords = "Mars, atmosphere",
keywords = "Mars, climate ",
abstract = "Abstract A clarification for the enumeration of Mars years prior to 1955 is presented, along with a table providing the Julian Dates associated with Ls = 0° for Mars years −183 (beginning of the telescopic study of Mars) to 100. A practical algorithm for computing Ls as a function of the Julian Date is provided. No new science results are presented. "
}
@article{Mishra2012205,
title = "Synergistic analyses of optical and microphysical properties of agricultural crop residue burning aerosols over the Indo-Gangetic Basin (IGB) ",
journal = "Atmospheric Environment ",
volume = "57",
number = "",
pages = "205 - 218",
year = "2012",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2012.04.025",
url = "http://www.sciencedirect.com/science/article/pii/S135223101200355X",
author = "Amit Kumar Mishra and Takashi Shibata",
keywords = "Agriculture crop residue burning",
keywords = "MODIS",
keywords = "CALIOP",
keywords = "PARASOL",
keywords = "Pyro-convection",
keywords = "Regional transport",
keywords = "Absorption Angstrom Exponent (AAE)",
keywords = "Black carbon (BC) ",
abstract = "Agriculture crop residue burning is one of the important sources of trace gas emissions and aerosol loading over the Indo-Gangetic Basin (IGB). The present study deals with the spatial variability including the vertical structure of optical and microphysical properties of aerosols, during the crop residue burning season (October and November) of 2009 over the IGB. Increased number of fire counts observed by \{MODIS\} (MODerate resolution Imaging Spectroradiometer) that is associated with high aerosol optical depth (MODIS-AOD &gt; 0.7) and enhanced tropospheric columnar \{NO2\} concentrations observed by \{OMI\} (Ozone Monitoring Instrument), suggests agriculture crop residue burning as a main source of aerosol loading over the \{IGB\} during October and November. \{PARASOL\} (Polarization and Anisotropy of Reflectances for Atmospheric Science coupled with Observations from a Lidar) observations show an increase in fine mode \{AOD\} (at 865 nm) from October (0.1–0.2) to November (0.2–0.3) over the IGB, which is well corroborated with \{MODIS\} observations. \{CALIOP\} (Cloud-Aerosol Lidar with Orthogonal Polarization) data shows the elevated aerosol plume (4.0–4.5 km) over the north-west \{IGB\} (associated with burning activities) that could have been caused by positive buoyancy through pyro-convection. However, large concentrations of aerosol were found below 1.0 km altitude. The averaged vertical structure of crop residue burning aerosols shows an exponential decrease with altitude (mean scale height ∼1.44 ± 0.20 km). Aerosol optical and microphysical properties coupled with backward air trajectories analyses at Kanpur indicated regional transport of biomass burning aerosols in a downwind direction from north-west \{IGB\} to south-east IGB. Aerosol classification, using \{AERONET\} (AErosol \{RObotic\} NETwork)-derived absorption properties coupled with size parameter (2006–2010) showed clear seasonal dependency of aerosol types which revealed the presence of biomass burning aerosols only during the crop residue burning season. The findings of this study will be further used for quantification of the properties of atmospheric brown clouds and their effects on global climate change. "
}
@article{Frisoli2013404,
title = "A new bounded jerk on-line trajectory planning for mimicking human movements in robot-aided neurorehabilitation ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "4",
pages = "404 - 415",
year = "2013",
note = "Models and Technologies for Multi-modal Skill Training ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001492",
author = "A. Frisoli and C. Loconsole and R. Bartalucci and M. Bergamasco",
keywords = "Trajectory planning",
keywords = "Exoskeleton",
keywords = "Stroke rehabilitation",
keywords = "Minimum jerk model ",
abstract = "In this paper we propose a new on-line control strategy that can generate motion primitives mimicking human movement for robot assistance in stroke neurorehabilitation. The proposed strategy, with respect to other methods, allows the generation of bounded jerk trajectories characterized by inter-joint synchronization, e.g. joint variables complete the same percentage of their trajectories at each instant of time. The algorithm can on-line automatically identify, localize and track target objects to be reached, and adapt the level of assistance to be provided to the patient, so that the robot assistance is provided to let the patient operate in a real world setting, where he/she can reach and grasp common everyday life objects, To evaluate the performance of the proposed algorithm, its implementation was derived to control the movement of an upper limb robotic exoskeleton, the L-Exos, and an experimental evaluation was conducted in a group of healthy subjects to assess the plausibility of generated trajectories in terms of similarity with human motion. "
}
@incollection{Mona2016161,
title = "Chapter 9 - Lidar Observations of Volcanic Particles ",
editor = "Mackie, Shona and Cashman, Katharine and Ricketts, Hugo and Rust, Alison  and Watson, Matt ",
booktitle = "Volcanic Ash ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "161 - 173",
isbn = "978-0-08-100405-0",
doi = "https://doi.org/10.1016/B978-0-08-100405-0.00014-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780081004050000148",
author = "L. Mona and F. Marenco",
keywords = "Aerosol lidar",
keywords = "Lidar ratio",
keywords = "Particle depolarization",
keywords = "Sun photometer",
keywords = "Volcanic ash ",
abstract = "Abstract Lidar is a powerful tool for monitoring the dispersion of volcanic clouds in the atmosphere. In particular, the lidar technique provides the geometrical properties (top, base, and thickness) for each aerosol layer, the optical properties (extinction, backscatter, and optical depth), and information on the aerosol type, and in some cases, when supported by co-located sun photometer, information on microphysical properties. Lidar instruments can be used at different locations: close to a volcano for monitoring mainly the injection height, or in the far range, where they can provide data on the atmospheric dispersion of the volcanic cloud. Both types of information are useful for the validation of satellite data and the evaluation of dispersion models. The value of the information available from lidars can be amplified with the establishment of ground-based networks. Coordinated lidar ground-based observations can, for instance, be integrated with satellite data for providing the space–time evolution of a volcanic event to Volcanic Ash Advisory Centers (VAACs). Near real-time data could eventually also be used for assimilation in dispersion models and continue to improve the operational forecasts. Volcanic plumes can also be mapped with airborne lidar, adding an additional spatial dimension to the observations; moreover, airborne platforms provide an opportunity to combine lidar observations with passive remote sensing instruments on the same platform, as well as the in situ measurement of particle microphysical properties. "
}
@article{Kazala2015231,
title = "Wireless Network for Mobile Robot Applications ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "24",
pages = "231 - 236",
year = "2015",
note = "16th \{IFAC\} Conference on Technology, Culture and International Stability \{TECIS\} 2015Sozopol, Bulgaria, 24–27 September 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.12.088",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315027123",
author = "R. Kazala and A. Taneva and M. Petrov and St. Penkov",
keywords = "networks",
keywords = "IoT",
keywords = "Ethernet",
keywords = "MQTT protocol",
keywords = "mobile robots ",
abstract = "Abstract The paper presents a concept of wireless network for data exchange between mobile robot nodes. It could be used for monitoring and control applications. Each node is equipped with sensors and communication hardware. The so called nodes can collect data from sensors and send to central one. This can be a host computer connected to a cloud network. It is known as Wireless Sensor Network (WSN). The main goal is to find a way to reduce energy consumption and computing power of robot nodes. The solution is based on choosing proper communication protocols. The article presents description of standards and networks. In the developed solution \{MQ\} Telemetry Transport (MQTT) for data exchange was used. The communication organization between networked nodes is given. As a part of system verification the messages between nodes and central system were exchanged. The advantages of presented network are also included. "
}
@article{Yan20111489,
title = "Comparison of \{CERES\} surface radiation fluxes with surface observations over Loess Plateau ",
journal = "Remote Sensing of Environment ",
volume = "115",
number = "6",
pages = "1489 - 1500",
year = "2011",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2011.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0034425711000514",
author = "Hongru Yan and Jianping Huang and Patrick Minnis and Tianhe Wang and Jianrong Bi",
keywords = "surface radiative fluxes",
keywords = "CERES/SSF",
keywords = "validation ",
abstract = "Surface energy budget is an important factor in weather and climate processes. To estimate the errors in satellite-retrieved surface radiation budget over the interior of China, instantaneous-footprint surface radiation fluxes from the Terra/Aqua \{FLASHFlux\} \{SSF\} product are compared with the measurements taken at the Semi-Arid Climate and Environment Observatory of Lanzhou University (SACOL) from July 2008 to March 2010. Validation is performed separately for different conditions: clear-sky and cloudy-sky, daytime and nighttime for four seasons. Differences between the \{FLASHFlux\} \{CERES\} shortwave radiation flux and surface measurements have larger standard deviations in cloudy-sky conditions than in clear-sky conditions, indicating that cloud contamination increases uncertainty in the retrieval algorithm. Upward shortwave radiation flux (USW) is overestimated in cloudy conditions suggesting that the cloud parameters and surface scene type in the retrieval process are not optimal for northwestern China. The \{CERES\} downward longwave radiation fluxes (DLW) accurately follow the variation of surface measurements during daytime, but are slightly underestimated during nighttime due to the coarse sounding profile and undetected low clouds at nighttime. The \{CERES\} upwelling longwave radiation fluxes (ULW) are strongly underestimated during daytime but are slightly underestimated during nighttime regardless of cloud coverage. This large bias could be caused by an underestimate of surface skin temperature and/or surface emissivity, or spatial inhomogeneity around the site. Generally, except for diurnal ULW, other components of the surface radiative fluxes obtained from \{CERES\} \{SSF\} datasets are close to meeting the accuracy requirements for climate research. "
}
@article{Mei2016,
title = "Retrieval of aerosol optical properties using \{MERIS\} observations: Algorithm and some first results ",
journal = "Remote Sensing of Environment ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.11.015",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716304606",
author = "Linlu Mei and Vladimir Rozanov and Marco Vountas and John P. Burrows and Robert C. Levy and Wolfhardt Lotz",
keywords = "AOT",
keywords = "MERIS",
keywords = "Retrieval ",
abstract = "Abstract The \{MEdium\} Resolution Imaging Spectrometer (MERIS) instrument on board European Space Agency (ESA) Envisat made measurements from 2002 to 2012. Although \{MERIS\} was limited in spectral coverage, accurate Aerosol Optical Thickness (AOT) from \{MERIS\} data are retrieved by using appropriate additional information. We introduce a new \{AOT\} retrieval algorithm for \{MERIS\} over land surfaces, referred to as eXtensible Bremen \{AErosol\} Retrieval (XBAER). \{XBAER\} is similar to the “dark-target” (DT) retrieval algorithm used for Moderate-resolution Imaging Spectroradiometer (MODIS), in that it uses a lookup table (LUT) to match to satellite-observed reflectance and derive the AOT. Instead of a global parameterization of surface spectral reflectance, \{XBAER\} uses a set of spectral coefficients to prescribe surface properties. In this manner, \{XBAER\} is not limited to dark surfaces (vegetation) and retrieves \{AOT\} over bright surface (desert, semiarid, and urban areas). Preliminary validation of the MERIS-derived \{AOT\} and the ground-based Aerosol Robotic Network (AERONET) measurements yield good agreement, the resulting regression equation is y = (0.92x ± 0.07) + (0.05 ± 0.01) and Pearson correlation coefficient of R = 0.78. Global monthly means of \{AOT\} have been compared from XBAER, \{MODIS\} and other satellite-derived datasets. "
}
@article{RuizSarmiento2017257,
title = "Building Multiversal Semantic Maps for Mobile Robot Operation ",
journal = "Knowledge-Based Systems ",
volume = "119",
number = "",
pages = "257 - 272",
year = "2017",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2016.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S0950705116305184",
author = "Jose-Raul Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Semantic maps",
keywords = "Mobile robots",
keywords = "Symbol grounding",
keywords = "Conditional random fields",
keywords = "Ontologies",
keywords = "Uncertainty handling ",
abstract = "Abstract Semantic maps augment metric-topological maps with meta-information, i.e. l semantic knowledge aimed at the planning and execution of high-level robotic tasks. Semantic knowledge typically encodes human-like concepts, like types of objects and rooms, which are connected to sensory data when symbolic representations of percepts from the robot workspace are grounded to those concepts. Such a symbol grounding is usually carried out by algorithms that individually categorize each symbol and provide a crispy outcome – a symbol is either a member of a category or not. Such approach is valid for a variety of tasks, but it fails at: (i) dealing with the uncertainty inherent to the grounding process, and (ii) jointly exploiting the contextual relations among concepts (e.g. microwaves are usually in kitchens). This work provides a solution for probabilistic symbol grounding that overcomes these limitations. Concretely, we rely on Conditional Random Fields (CRFs) to model and exploit contextual relations, and to provide measurements about the uncertainty coming from the possible groundings in the form of beliefs (e.g. an object can be categorized (grounded) as a microwave or as a nightstand with beliefs 0.6 and 0.4, respectively). Our solution is integrated into a novel semantic map representation called Multiversal Semantic Map ( M v S m a p ), which keeps the sets of different groundings, or universes, as instances of ontologies annotated with the obtained beliefs for their posterior exploitation. The suitability of our proposal has been proven with the Robot@Home dataset, a repository that contains challenging multi-modal sensory information gathered by a mobile robot in home environments. "
}
@article{Han2017,
title = "A fast propagation scheme for approximate geodesic paths ",
journal = "Graphical Models ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1524-0703",
doi = "https://doi.org/10.1016/j.gmod.2017.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S1524070317300115",
author = "Xiaoguang Han and Hongchuan Yu and Yizhou Yu and Jianjun Zhang",
keywords = "Discrete geodesic computation",
keywords = "Continuous Dijkstra strategy",
keywords = "Fast Path Propagation ",
abstract = "Abstract Geodesic paths on surfaces are indispensable in many research and industrial areas, including architectural and aircraft design, human body animation, robotic path planning, terrain navigation, and reverse engineering. 3D models in these applications are typically large and complex. It is challenging for existing geodesic path algorithms to process large-scale models with millions of vertices. In this paper, we focus on the single-source geodesic path problem, and present a novel framework for efficient and approximate geodesic path computation over triangle meshes. The algorithm finds and propagates paths based on a continuous Dijkstra strategy with a two-stage approach to compute a path for each propagating step. Starting from an initial path for each step, its shape is firstly optimized by solving a sparse linear system and then the output floating path is projected to the surface to obtain the refined one for further propagation. We have extensively evaluated our algorithms on a number of 3D models and also compared their performance against existing algorithms. Such evaluation and comparisons indicate our algorithm is fast and produces acceptable accuracy. "
}
@article{Srinivasan2012358,
title = "A survey of sensory data boundary estimation, covering and tracking techniques using collaborating sensors ",
journal = "Pervasive and Mobile Computing ",
volume = "8",
number = "3",
pages = "358 - 375",
year = "2012",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2012.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1574119212000430",
author = "Sumana Srinivasan and Subhasri Dattagupta and Purushottam Kulkarni and Krithi Ramamritham",
keywords = "Boundary estimation",
keywords = "Boundary tracking",
keywords = "Boundary covering",
keywords = "Wireless sensor networks",
keywords = "Mobile sensors",
keywords = "Contour covering",
keywords = "Contour estimation ",
abstract = "Boundary estimation and tracking have important applications in the areas of environmental monitoring and disaster management. A boundary separates two regions of interest in a phenomenon. It can be visualized as an edge if there is a sharp change in the field value between the two regions or alternatively, as a contour with a field value f = τ separating two regions with field values f &gt; τ and f &lt; τ . Examples include contours/boundaries of hazardous concentration in a pollutant spill, frontal boundary of a forest fire, isotherms, isohalines etc. Recent advances in the area of embedded sensor devices and robotics have led to deployments of networks of sensors capable of sensing, computing, communication and mobility. They are used to estimate the boundaries of interest in physical phenomena, monitor or track them over time and also in some cases, mitigate the spatial spread of the phenomena. Since these sensors work autonomously in the environment, minimizing the energy consumed while maximizing the accuracy of estimation or tracking is the main challenge for algorithms for boundary estimation and tracking. Several algorithms with these objectives have been proposed in the literature. In this work, we focus on the algorithms that estimate and cover boundaries found in the sensory data in a field and not the topological boundary of the sensor network per se, which is beyond the scope of this paper. Here, our objective is to provide a comprehensive survey of the algorithms for boundary estimation and tracking by providing a taxonomy based on two broad categories — (i) Boundary estimation and tracking, where the sensors estimate the boundary without physically covering the boundary and (ii) Boundary covering — where the sensors not only predict the location and estimate the entire boundary but also physically cover the boundary by surrounding and bounding it. We further classify the techniques based on (a) sensing capabilities —in situ, range or remote sensing (b) movement capabilities — static or mobile sensors and (c) boundary type — static or dynamic and (d) type of estimation — field estimation where the entire field is sampled to search for contours and localized estimation where sampling is done near the boundary and (e) different types of mobility models in the case of mobile sensors. We believe that such a survey has not been performed before. By capturing and classifying the current state-of-the-art and identifying open research problems, we hope to ignite interest and stimulate efforts towards promising solutions for real-world boundary estimation and tracking problems. "
}
@article{Ali2016173,
title = "Mobile device power models for energy efficient dynamic offloading at runtime ",
journal = "Journal of Systems and Software ",
volume = "113",
number = "",
pages = "173 - 187",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.11.042",
url = "http://www.sciencedirect.com/science/article/pii/S0164121215002666",
author = "Farhan Azmat Ali and Pieter Simoens and Tim Verbelen and Piet Demeester and Bart Dhoedt",
keywords = "Power model",
keywords = "Energy consumption",
keywords = "Energy-aware dynamic offloading ",
abstract = "Abstract Spectacular advances in hardware and software technologies have resulted in powerful mobile devices, equipped with advanced processing, storage and network capabilities. Therefore, using resource-intensive applications has become a commodity in many contexts. However, the rapid evolution in hardware and software capabilities has not been paralleled by a similar advance in battery technology. A potential avenue to cope with the device energy resource limitation is to offload computational tasks to cloud infrastructure in the network. In order to offload tasks in an energy-aware manner, we present a detailed model of mobile device energy consumption, addressing the main power consuming subsystems, including CPU, display unit, wireless network interface and memory. Applying this model allows to estimate the power consumed by the application when executed locally, remotely or hybridly (i.e. partly on the device and partly in the cloud infrastructure). Offloading parts of the application can subsequently be decided at runtime based on these energy consumption estimates, also taking into account the power consumed by the device-to-cloud communication over the wireless network. The dynamic offloading has been validated with computational and communication intensive applications. Results show that 18–55% energy gains on the mobile device can be achieved, depending on different conditions. "
}
@article{Anderson199991,
title = "Roadmap to a star ",
journal = "Acta Astronautica ",
volume = "44",
number = "2–4",
pages = "91 - 97",
year = "1999",
note = "Missions to the Outer Solar System and Beyond ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(99)00033-8",
url = "http://www.sciencedirect.com/science/article/pii/S0094576599000338",
author = "John L. Anderson",
abstract = "\{NASA\} is currently constructing an Interstellar Roadmap that will outline a progressive series of phased technology efforts over several decades that would enable new science beyond the solar system, leading to and culminating in robotics exploration of nearby stars. The Roadmap is structured around a decadal progression of science missions and enabling technologies in which each decadal cycle has an intrinsic value in itself. The Roadmap serves at least 5 functions: 1) it lays the foundation for the development of a broad new strategic thrust of space exploration and development; 2) it outlines a long term progressive program for which each phase has an intrinsic value and can be argued independently of a Star Mission itself; 3) it defines a phased approach that would culminate in a large- scale breakthrough beamed energy capability that would have broad planetary and terrestrial applicability; 4) it describes an endeavor that could provide the technological basis of a U.S. economic engine for the first half of the 21st century; and 5) it provides a focus and a structure around which new government/industry economic relationships may be established. This paper outlines the process for constructing the Roadmap which is due to be completed in Fall 1998. It also poses questions raised by a mission of such scale and suggests some of the strategic value of such a Roadmap. "
}
@article{vanDonkelaar20116225,
title = "Satellite-based estimates of ground-level fine particulate matter during extreme events: A case study of the Moscow fires in 2010 ",
journal = "Atmospheric Environment ",
volume = "45",
number = "34",
pages = "6225 - 6232",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.07.068",
url = "http://www.sciencedirect.com/science/article/pii/S135223101100851X",
author = "Aaron van Donkelaar and Randall V. Martin and Robert C. Levy and Arlindo M. da Silva and Michal Krzyzanowski and Natalia E. Chubarova and Eugenia Semutnikova and Aaron J. Cohen",
keywords = "MODIS",
keywords = "PM2.5",
keywords = "Moscow wildfires",
keywords = "Aerosol optical depth ",
abstract = "We estimate fine particulate matter (PM2.5) concentrations daily using \{MODIS\} satellite observations of aerosol optical depth (AOD) for a major biomass burning event around Moscow during summer 2010. Evaluation of \{MODIS\} \{AOD\} with the Moscow \{AERONET\} site supports a MODIS-AOD error estimate of ±(0.05 + 0.2 × AOD) for this event. However, since the smoke was often thick (AOD &gt; 4.0) and spatially variable, the standard \{MODIS\} algorithm incorrectly identifies some aerosol as cloud. We test relaxed cloud screening criteria that increase \{MODIS\} coverage by 21% and find excellent agreement with coincident operational retrievals (r2 = 0.994, slope = 1.01) with no evidence of false aerosol detection. We relate the resultant \{MODIS\} \{AOD\} to PM2.5 using aerosol vertical profiles from the GEOS-Chem chemical transport model. Our estimates are in good agreement with PM2.5 values estimated from in-situ \{PM10\} (r2 = 0.85, slope = 1.06), and we find that the relationship between \{AOD\} and PM2.5 is insensitive to uncertainties in biomass burning emissions. The satellite-derived and in-situ values both indicate that peak daily mean concentrations of approximately 600 μg m−3 occurred on August 7, 2010 in the Moscow region of the Russian Federation. We estimate that exposure to air pollution from the Moscow wildfires may have caused hundreds of excess deaths. "
}
@article{Marco2013205,
title = "Notes on a Robust Plane Detection Approach in 3D. ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "205 - 210",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00014",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349338",
author = "Tommaso De Marco and Cosimo Distante and Giovanni Indiveri",
keywords = "Computer vision",
keywords = "Robust estimation",
keywords = "Entropy",
keywords = "Cameras",
keywords = "Parameter estimation ",
abstract = "Abstract This paper addresses the issue of plane detection in 3 dimensional (3D) range images. The identification of planar structures is a crucial task in many visual-aided autonomous robotic applications. The proposed method consists in implementing, in cascade, two algorithms: Random Sample and Consensus (RANSAC) and the more recent Least Entropy-like Estimator (LEL), a nonlinear prediction error estimator that minimizes a cost function inspired by the definition of Gibbs entropy. \{LEL\} estimators allow to improve \{RANSAC\} performances while maintaining its robustness; kernel density estimation is used to classify data into inliers and outliers. The method has been experimentally applied to 3D images acquired by a Time-Of-Flight camera and compared with a stand alone \{RANSAC\} solution. The proposed solution does not require an accurate estimation of the noise variance or outlier scale. This is of fundamental practical importance as the outlier scale, while severely influencing standard RANSAC, is usually unknown a priori and hard to estimate. "
}
@article{Kelley2014426,
title = "Establishing a new era of submarine volcanic observatories: Cabling Axial Seamount and the Endeavour Segment of the Juan de Fuca Ridge ",
journal = "Marine Geology ",
volume = "352",
number = "",
pages = "426 - 450",
year = "2014",
note = "50th Anniversary Special Issue ",
issn = "0025-3227",
doi = "https://doi.org/10.1016/j.margeo.2014.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S0025322714000723",
author = "Deborah S. Kelley and John R. Delaney and S. Kim Juniper",
keywords = "submarine volcanoes",
keywords = "hydrothermal vents",
keywords = "Juan de Fuca Ridge",
keywords = "Endeavour Segment",
keywords = "Axial Seamount",
keywords = "cabled observatories ",
abstract = "Abstract At least 70% of the volcanism on Earth occurs along the 65,000 km network of mid-ocean ridge (MOR) spreading centers. Within these dynamic environments, the highest fluxes of heat, chemicals, and biological material from the lithosphere to the hydrosphere occur during volcanic eruptions. However, because underwater volcanoes are difficult and expensive to access, researchers are rarely, if ever, in the right place at the right time to characterize these events. Therefore, our knowledge is limited about the linkages among hydrothermal, chemical and biological processes during seafloor formation and crustal evolution. To make significant advancements in understanding the evolution of \{MOR\} environments, the United States and Canada have invested in the first plate-scale submarine cabled observatory linked through the global Internet. Spanning the Juan de Fuca tectonic plate, these two networks include &gt; 1700 km of cable and 14 subsea terminals that provide 8–10 kW power and 10 Gbs communications to hundreds of instruments on the seafloor and throughout the overlying water column — resulting in a 24/7/365 presence in the oceans. Data and imagery are available in real- to near-real time. The initial experimental sites for monitoring volcanic processes include the \{MOR\} volcanoes called Axial Seamount and the Endeavour Segment that are located on the Juan de Fuca Ridge. Axial, a hot-spot influenced seamount, is the most robust volcano along the ridge rising nearly 1400 m above the surrounding seafloor and it has erupted twice in the last 15 years. In contrast, the Endeavour Segment is characterized by more subdued topography with a well defined axial rift and it hosts one of the most intensely venting hydrothermal systems known. A non-eruptive spreading event lasting 6 years was documented at Endeavour between 1999 and 2005. Hydrothermal venting intensity, chemistry, and temperature, as well as associated biological communities at both sites were significantly perturbed by the magmatic and intrusive events. This paper presents the similarities and differences between the Axial and Endeavour volcanic systems and identifies reasons why they are ideal candidates for comparative studies. The U.S. has made a 25-year commitment for sustained observations using the cabled infrastructure. The highly expandable nature of submarine optical networking will allow for the future addition of novel experiments that utilize ever evolving advancements in computer sciences, robotics, genomics and sensor miniaturization. Comprehensive modeling of the myriad processes involved will continue to assimilate and integrate growing databases yielding a new understanding of integrated processes that create the seafloor in the global ocean basins. "
}
@article{Wan2016721,
title = "Error-tolerant manipulation by caging ",
journal = "Signal Processing ",
volume = "120",
number = "",
pages = "721 - 730",
year = "2016",
note = "",
issn = "0165-1684",
doi = "https://doi.org/10.1016/j.sigpro.2014.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0165168414005684",
author = "Weiwei Wan and Feng Lu and Rui Fukui",
keywords = "Caging",
keywords = "Grasping",
keywords = "Robot finger ",
abstract = "Abstract This paper delivers a preliminary attempt to find the optimized caging positions for a three-finger robotic hand designed for home-use logistical environments. The main idea behind optimizing caging positions falls in that optimal caging can afford largest margins to stop target objects from escaping into infinity. By employing the advantages of largest margins, optimal caging grasp can be robust enough to endure dramatic perception noises or errors and low sensing resolutions. This paper optimizes object grasping towards caging. Specifically, our algorithm utilizes Genetic Algorithm (GA) to accelerate the searching procedure and evaluate a fitness of the \{GA\} population by examining a combination of max–min, which corresponds to intersections of neighbour fingers’ \{CC\} space margins, and least inter-finger distance for optimization. Simulation results show that the manipulation strategy proposed in this paper could in the worse case coordinate with sensors whose resolution are less than one pixel per centimeter. "
}
@article{Tang2012306,
title = "Formalization of workflows for extracting bridge surveying goals from laser-scanned data ",
journal = "Automation in Construction ",
volume = "22",
number = "",
pages = "306 - 319",
year = "2012",
note = "Planning Future Cities-Selected papers from the 2010 eCAADe Conference ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511001671",
author = "Pingbo Tang and Burcu Akinci",
keywords = "Surveying goal",
keywords = "Inspection automation",
keywords = "Scientific workflow",
keywords = "Geometric data collection",
keywords = "Geometric assessment",
keywords = "Information retrieval",
keywords = "Laser scanning",
keywords = "Bridge inspection",
keywords = "3D data processing ",
abstract = "Laser scanners enable bridge inspectors to collect dense 3D point clouds, which capture detailed geometries of bridges. While these data sets contain rich geometric information, they bring unique challenges related to geometric information retrieval. This paper describes a case study to show the necessity and potential value of automating the manual data processing workflows being executed for extracting geometric data items (surveying goals) from 3D point clouds, and presents an approach for formalizing these workflows to enable such automation. We analyzed manual procedures of taking measurements on 3D point clouds and as-built models for obtaining bridge inspection related surveying goals, synthesized and categorized all data processing operations into nine generic operations. These nine categories of operations can be formalized using &lt; operator, inputs, output, parameters, constraints&gt; tuples. Using these tuples, we formalized an operation library and workflow construction mechanisms for enabling inspectors to semi-automatically construct executable workflows. This formalism also incorporates several mechanisms for facilitating extensions to the existing operation library to accommodate additional surveying goals that have not been covered. The developed approach is validated for its generality to support workflows needed for all surveying goals required by the National Bridge Inventory (NBI) program, and for its extensibility to support workflows needed to support a variety of other surveying goals identified in the Architecture/Engineering/Construction domain. "
}
@article{Russell201482,
title = "Human-Like Robot Sensing Mediated by Body Heat ",
journal = "Journal of Bionic Engineering ",
volume = "11",
number = "1",
pages = "82 - 89",
year = "2014",
note = "",
issn = "1672-6529",
doi = "https://doi.org/10.1016/S1672-6529(14)60022-6",
url = "http://www.sciencedirect.com/science/article/pii/S1672652914600226",
author = "R. Andrew Russell",
keywords = "sensing volatile chemicals",
keywords = "sensing airflow",
keywords = "human body heat",
keywords = "biomimetic robots ",
abstract = "Abstract This paper presents a novel robotic sensor system that can monitor volatile chemicals and airflow. The system is modelled on characteristics of the human body that are thought to have a significant influence on the human odour and airflow senses. In particular, the effect of buoyant airflow due to body heat acts to gather volatile chemicals over large areas of the human body and carry them to the nose. It is postulated that this effect increases the receptive area for human olfaction. In addition, the interaction between rising air heated by the body and external airflow produces a temperature distribution about head height that can be used to infer airflow direction and magnitude. A heated sensor system was constructed to investigate these effects and the resulting sensor was mounted on a mobile robot. The design of the sensor system is described. Results are presented which demonstrate its ability to measure airflow direction and detect chemical signals over a wider receptive field compared with an unheated sensor. "
}
@article{Kelly2007197,
title = "\{AN\} \{EXPERIMENTAL\} \{STUDY\} \{OF\} \{AERIAL\} \{STEREO\} \{VISUAL\} \{ODOMETRY\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "197 - 202",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00036",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346614",
author = "Jonathan Kelly and Gaurav S. Sukhatme",
keywords = "Gaussian distributions",
keywords = "mobile robots",
keywords = "position estimation",
keywords = "stereo vision",
keywords = "unmanned aerial vehicles ",
abstract = "Abstract Unmanned aerial vehicles normally rely on \{GPS\} to provide pose information for navigation. In this work, we examine stereo visual odometry (SVO) as an alternative pose estimation method for situations in which \{GPS\} in unavailable. \{SVO\} is an incremental procedure that determines ego-motion by identifying and tracking visual landmarks in the environment, using cameras mounted on-board the vehicle. We present experiments demonstrating how \{SVO\} performance varies with camera pointing angle, for a robotic helicopter platform. Our results show that an oblique camera pointing angle produces better motion estimates than a nadir view angle, and that reliable navigation over distances of more than 200 meters is possible using visual information alone. "
}
@article{Sayer2012177,
title = "Use of MODIS-derived surface reflectance data in the ORAC-AATSR aerosol retrieval algorithm: Impact of differences between sensor spectral response functions ",
journal = "Remote Sensing of Environment ",
volume = "116",
number = "",
pages = "177 - 188",
year = "2012",
note = "Advanced Along Track Scanning Radiometer(AATSR) Special Issue ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2011.02.029",
url = "http://www.sciencedirect.com/science/article/pii/S0034425711002203",
author = "Andrew M. Sayer and Gareth E. Thomas and Roy G. Grainger and Elisa Carboni and Caroline Poulsen and Richard Siddans",
keywords = "Aerosol",
keywords = "AATSR",
keywords = "BRDF",
keywords = "MODIS",
keywords = "Optimal estimation",
keywords = "ORAC",
keywords = "Retrieval",
keywords = "Surface albedo ",
abstract = "The aerosol component of the Oxford-Rutherford Appleton Laboratory (RAL) Aerosol and Clouds (ORAC) retrieval scheme for the Advanced Along-Track Scanning Radiometer (AATSR) uses data derived from the Moderate Resolution Imaging Spectroradiometer (MODIS) to constrain the brightness of the surface. However, the spectral response functions of the channels used (centred near 550 nm, 660 nm, 870 nm, and 1.6 μm) do not exactly match between the two sensors. It is shown that failure to account for differences between the instruments' spectral response functions leads to errors of typically 0.001–0.01 in spectral surface albedo, and distinct biases, dependent on wavelength and surface type. A technique based on singular value decomposition (SVD) is used to reduce these random errors by an average of 35% at 670 nm and over 60% at the other wavelengths used. The technique reduces the biases so that they are negligible. In principle, the method can be extended to any combination of sensors. The SVD-based scheme is applied to \{AATSR\} data from the month of July 2008 and found to increase the number of successful aerosol retrievals, the speed of retrieval convergence, and improve the level of consistency between the measurements and the retrieved state. Additionally, retrieved aerosol optical depth at 550 nm shows an improvement in correspondence when compared to Aerosol Robotic Network (AERONET) data. "
}
@article{So20131237,
title = "3DComplete: Efficient completeness inspection using a 2.5D color scanner ",
journal = "Computers in Industry ",
volume = "64",
number = "9",
pages = "1237 - 1252",
year = "2013",
note = "Special Issue: 3D Imaging in Industry ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2013.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S0166361513000675",
author = "Edmond Wai Yan So and Matteo Munaro and Stefano Michieletto and Stefano Tonello and Emanuele Menegatti",
keywords = "Completeness inspection",
keywords = "Laser triangulation",
keywords = "Image and range data fusion",
keywords = "3D reconstruction ",
abstract = "Abstract In this paper, we present a low-cost and highly configurable quality inspection system capable of capturing 2.5D color data, created using off-the-shelf machine vision components, open-source software libraries, and a combination of standard and novel algorithms for 2.5D data processing. The system uses laser triangulation to capture 3D depth, in parallel with a color camera and a line light projector to capture color texture, which are then combined into a color 2.5D model in real-time. Using many examples of completeness inspection tasks that are extremely difficult to solve with current 2D-based methods, we demonstrate how the 2.5D images and point clouds generated by our system can be used to solve these complex tasks effectively and efficiently. Our system is currently being integrated into a real production environment, showing that completeness inspection incorporating 3D technology can be readily achieved in a short time at low costs. "
}
@article{Martins201535,
title = "Proto-object categorisation and local gist vision using low-level spatial features ",
journal = "Biosystems ",
volume = "135",
number = "",
pages = "35 - 49",
year = "2015",
note = "",
issn = "0303-2647",
doi = "https://doi.org/10.1016/j.biosystems.2015.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0303264715000945",
author = "Jaime A. Martins and J.M.F. Rodrigues and J.M.H. du Buf",
keywords = "Disparity",
keywords = "3D",
keywords = "Stereo vision",
keywords = "Colour",
keywords = "Population coding",
keywords = "Learning",
keywords = "Biological model",
keywords = "Figure-ground",
keywords = "Segregation",
keywords = "Object",
keywords = "Categorisation",
keywords = "Verification",
keywords = "Neural network",
keywords = "Visual cortex ",
abstract = "Abstract Object categorisation is a research area with significant challenges, especially in conditions with bad lighting, occlusions, different poses and similar objects. This makes systems that rely on precise information unable to perform efficiently, like a robotic arm that needs to know which objects it can reach. We propose a biologically inspired object detection and categorisation framework that relies on robust low-level object shape. Using only edge conspicuity and disparity features for scene figure-ground segregation and object categorisation, a trained neural network classifier can quickly categorise broad object families and consequently bootstrap a low-level scene gist system. We argue that similar processing is possibly located in the parietal pathway leading to the \{LIP\} cortex and, via areas V5/MT and MST, providing useful information to the superior colliculus for eye and head control. "
}
@article{Lee20163,
title = "RGB-D camera based wearable navigation system for the visually impaired ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "3 - 20",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - 'Assistive Solutions for Mobility, Communication and HMI' ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.019",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300248",
author = "Young Hoon Lee and Gerard Medioni",
keywords = "Wearable navigation system",
keywords = "Visual SLAM",
keywords = "Assistive technologies for the visually impaired ",
abstract = "Abstract In this paper, a novel wearable RGB-D camera based indoor navigation system for the visually impaired is presented. The system guides the visually impaired user from one location to another location without a prior map or \{GPS\} information. Accurate real-time egomotion estimation, mapping, and path planning in the presence of obstacles are essential for such a system. We perform real-time 6-DOF egomotion estimation using sparse visual features, dense point clouds, and the ground plane to reduce drift from a head-mounted RGB-D camera. The system also builds 2D probabilistic occupancy grid map for efficient traversability analysis which is a basis for dynamic path planning and obstacle avoidance. The system can store and reload maps generated by the system while traveling and continually expand the coverage area of navigation. Next, the shortest path between the start location to destination is generated. The system generates a safe and efficient way point based on the traversability analysis result and the shortest path and updates the way point while a user is constantly moving. Appropriate cues are generated and delivered to a tactile feedback system to guide the visually impaired user to the way point. The proposed wearable system prototype is composed of multiple modules including a head-mounted RGB-D camera, standard laptop that runs a navigation software, smart phone user interface, and haptic feedback vest. The proposed system achieves real-time navigation performance at 28.6Hz in average on a laptop, and helps the visually impaired extends the range of their activities and improve the orientation and mobility performance in a cluttered environment. We have evaluated the performance of the proposed system in mapping and localization with blind-folded and the visually impaired subjects. The mobility experiment results show that navigation in indoor environments with the proposed system avoids collisions successfully and improves mobility performance of the user compared to conventional and state-of-the-art mobility aid devices. "
}
@article{Xia201312,
title = "Climatological aspects of aerosol optical properties in North China Plain based on ground and satellite remote-sensing data ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "127",
number = "",
pages = "12 - 23",
year = "2013",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2013.06.024",
url = "http://www.sciencedirect.com/science/article/pii/S0022407313002781",
author = "Xiangao Xia and Hongbin Chen and Philippe Goloub and Xuemei Zong and Wenxing Zhang and Pucai Wang",
keywords = "Aerosol optical properties",
keywords = "AERONET",
keywords = "MODIS",
keywords = "CALIOP",
keywords = "NCP ",
abstract = "Abstract Aerosol data from the Aerosol Robotic Network (AERONET), Moderate Resolution Imaging Spectroradiometer (MODIS), and Cloud–Aerosol Lidar with Orthogonal Polarization (CALIOP) recorded during the new millennium were used to investigate the spatio-temporal variation of aerosol optical properties in the North China Plain (114–120°E; 34.5–41°N). The external linear mixing of both fine and coarse mode components dominated variations of the refractive index and the single scattering albedo ( ω ) in spring and winter when the fine mode fraction (FMF) was &lt;0.6–0.7. The effective radius of fine mode component increased rapidly with \{FMF\} in every season when \{FMF\} exceeded ∼0.6–0.7, and thereby when ω increased significantly. With the exception of dust cases, aerosols resembled the mixed category in every season except summer; summer aerosols resembled the industry/urban category. The aerosol layer height was observed to be 2–3 km in summer; however, aerosols were trapped below 1–2 km in fall and winter. Aerosol optical depth (AOD) retrieved by the \{MODIS\} was in good agreement with the \{AERONET\} \{AOD\} (R&gt;0.80). The \{MODIS\} tended to overestimate \{AOD\} in spring and summer. This feature was most prominent at 660 nm; therefore, \{MODIS\} angstrom exponents were poorly derived. A strong correlation (R&gt;0.7) between the \{AERONET\} \{AODs\} in Beijing and the \{MODIS\} level 2.0 pixel \{AODs\} persisted for a large and strongly anisotropic area of ∼17,000 km2 in winter to ∼100,000 km2 in fall, indicating that the aerosol pollution is regional in nature. A decreasing trend was derived for the \{AERONET\} and \{MODIS\} \{AOD\} data, although no trends were significant. Further understanding of the seasonal variations of aerosol optical properties in this polluted region would help to improve satellite aerosol retrieval and to promote regional climate change research. "
}
@article{Eizicovits201698,
title = "Integration of perception capabilities in gripper design using graspability maps ",
journal = "Biosystems Engineering ",
volume = "146",
number = "",
pages = "98 - 113",
year = "2016",
note = "Special Issue: Advances in Robotic Agriculture for Crops ",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015001956",
author = "Danny Eizicovits and Bart van Tuijl and Sigal Berman and Yael Edan",
keywords = "Gripper design",
keywords = "Grasping",
keywords = "Sensing",
keywords = "Sweet-pepper harvesting",
keywords = "Agricultural robots ",
abstract = "Agricultural environments impose high demands on robotic grippers since the objects to be grasped (e.g., fruit) suffer from inherent uncertainties in size, shape, weight, and texture, are typically highly sensitive to excessive force, and tend to be partly or fully occluded. This paper presents a methodology for evaluating the influence of perception capabilities on grasping and on gripper design using graspability maps. Graspability maps are spatial representations of grasp quality grades from wrist poses (position and orientation) about an object and are generated using simulation. A new module was developed to enable the insertion of object pose errors for testing the effects of perception inaccuracies on grasping. The methodology was implemented for comparing two grippers (Fin-Ray and Lip-type) for harvesting two sweet-pepper cultivars. A 3D model of each gripper was constructed and suitable grasp quality measures were developed and validated in a physical environment. Task and gripper-specific grasp quality measures were developed for each implementation. Sensitivity analyses included varying pepper dimensions and perception inaccuracies. These were followed by analyses of the influence of gripper design parameters on grasp capabilities. Results indicate that the Lip-type gripper is less sensitive to inaccuracies in object orientation, while both grippers are similarly sensitive to inaccuracies in object position. Specific perception system demands and design recommendations are given for each gripper, and cultivar. The results illustrate the importance of integrating perception analysis in the gripper design phase and the utility of the graspability simulation tool for design analysis. "
}
@article{Marion2001275,
title = "Calculation of solar radiation using a methodology with worldwide potential ",
journal = "Solar Energy ",
volume = "71",
number = "4",
pages = "275 - 283",
year = "2001",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/S0038-092X(01)00044-5",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X01000445",
author = "W. Marion and R. George",
abstract = "Surface meteorological observations from the \{DATSAV2\} database provide the capability to use the \{METSTAT\} (meteorological/statistical) model to calculate hourly values of direct normal, diffuse horizontal, and global horizontal solar radiation for locations throughout the world. Opaque cloud cover, a key input parameter to the \{METSTAT\} model, is derived from the \{DATSAV2\} layered cloud cover information. Resulting multiyear data sets include solar radiation and other meteorological data such as dry bulb temperature, dew point temperature, wind speed, and atmospheric pressure. Data filling procedures ensure that the multiyear data sets are serially complete. A minor revision to \{METSTAT\} improved solar radiation estimates for conditions of high cloud amounts and low ceiling heights. The methodology was applied to regions of Southern Africa and Saudi Arabia. "
}
@article{Cazacu201557,
title = "\{AERONET\} data investigation of the aerosol mixtures over Iasi area, One-year time scale overview ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "153",
number = "",
pages = "57 - 64",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part \{II\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003756",
author = "Mihai Marius Cazacu and Adrian Timofte and Florin Unga and Bogdan Albina and Silviu Gurlui",
keywords = "AERONET",
keywords = "Meteorological data",
keywords = "Tropospheric aerosols",
keywords = "Optical-properties",
keywords = "Saharan dust",
keywords = "Atmospheric models ",
abstract = "Abstract In order to analyze the troposphere dynamics under particular conditions in North-East region of Romania, various types of aerosols chemical compositions have been studied using complementary techniques. Thus, the seasonal trends of aerosols and its external influences have been studied using aerosol optical properties retrieved from Aerosol Robotic Network (AERONET). Complementary studies were taken into account by using several meteorological factors, computational models and meteorological data. Moreover, this paper presents optical properties analysis of different types of aerosols and the seasonal variability of them in one year of measurements. The major categories of aerosol types are evidenced, such as urban/industrial aerosol, biomass burning and mineral dust. "
}
@incollection{Bedkowski2011591,
title = "26 - Using the \{NVIDIA\} \{CUDA\} programme to develop cognitive supervision of multi robot systems ",
editor = "Baudoin, Y. and ,  and Habib, Maki K. ",
booktitle = "Using Robots in Hazardous Environments ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2011",
pages = "591 - 598",
isbn = "978-1-84569-786-0",
doi = "https://doi.org/10.1533/9780857090201.5.591",
url = "http://www.sciencedirect.com/science/article/pii/B9781845697860500265",
author = "J. Bedkowski and A. Masłowski",
keywords = "mobile robot control",
keywords = "supervision ",
abstract = "Abstract: This chapter describes the \{CUDA\} application in the cognitive theory-based approach to multi mobile robot control. The model of the cognitive supervisor and its main role in the robotic system is described. The new capabilities derived from the usage of \{GPU\} architecture give an opportunity for real time computation in 3D map building. The idea of real time 3D map reconstruction and analysis by autonomous navigation module is also shown. The need for supervision of the navigation module is presented. The experiments based on simulated and real environment prove the advantage of cognitive supervision. Furthermore the \{CUDA\} application shows new capabilities for robotic applications. The robot’s task can be achieved quickly and the environmental map can be stored and reconstructed with high precision. The robot can be navigated autonomously in a complex and unstructured environment even from an onboard \{PC\} or remotely, therefore the approach supports the autonomous tele-operation of a remotely controlled robot by the robot assistant. Thus, any problems in communication with the base station can be partially managed. "
}
@article{Vucina20141018,
title = "Classification of 3D shape deviation using feature recognition operating on parameterization control points ",
journal = "Computers in Industry ",
volume = "65",
number = "6",
pages = "1018 - 1031",
year = "2014",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514000797",
author = "Damir Vucina and Milan curkovic and Tonci Novkovic",
keywords = "B-spline surfaces",
keywords = "Shape deviation",
keywords = "3D parameterization",
keywords = "Feature detection",
keywords = "Classification",
keywords = "Wind turbine blades ",
abstract = "Abstract A numerically efficient expert system for evaluation of 3D shape based on features extracted from the parameterization control points data-set is developed. Reference shapes are stored and periodically compared with current shapes at the level of windowed control-point data grids for the purpose of detection of 3D shape deviation. Classification heuristics for the respective types of deviations which operate on the control point sets rather than the original raw point clouds are developed based on operations of windowing, coordinate transformation, filtering and singular value decomposition (SVD)/principal component analysis (PCA). The methodology is demonstrated with the cases of detecting and computationally recognizing local impact damage and cavities, narrow gaps or fatigue cracks and wear-based surface deterioration on a wind turbine blade. "
}
@article{Kim2014176,
title = "Improvement of aerosol optical depth retrieval over Hong Kong from a geostationary meteorological satellite using critical reflectance with background optical depth correction ",
journal = "Remote Sensing of Environment ",
volume = "142",
number = "",
pages = "176 - 187",
year = "2014",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2013.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0034425713004379",
author = "Mijin Kim and Jhoon Kim and Man Sing Wong and Jongmin Yoon and Jaehwa Lee and Dong Wu and P.W. Chan and Janet E. Nichol and Chu-Yong Chung and Mi-Lim Ou",
keywords = "Remote sensing",
keywords = "Algorithm",
keywords = "Aerosol optical depth",
keywords = "Critical reflectance",
keywords = "Background aerosol optical depth",
keywords = "Geostationary ",
abstract = "Abstract Despite continuous efforts to retrieve aerosol optical depth (AOD) using a conventional 5-channel meteorological imager in geostationary orbit, the accuracy in urban areas has been poorer than other areas primarily due to complex urban surface properties and mixed aerosol types from different emission sources. The two largest error sources in aerosol retrieval have been aerosol type selection and surface reflectance. In selecting the aerosol type from a single visible channel, the season-dependent aerosol optical properties were adopted from long-term measurements of Aerosol Robotic Network (AERONET) sun-photometers. With the aerosol optical properties obtained from the \{AERONET\} inversion data, look-up tables were calculated by using a radiative transfer code: the Second Simulation of the Satellite Signal in the Solar Spectrum (6S). Surface reflectance was estimated using the clear sky composite method, a widely used technique for geostationary retrievals. Over East Asia, the \{AOD\} retrieved from the Meteorological Imager showed good agreement, although the values were affected by cloud contamination errors. However, the conventional retrieval of the \{AOD\} over Hong Kong was largely underestimated due to the lack of information on the aerosol type and surface properties. To detect spatial and temporal variation of aerosol type over the area, the critical reflectance method, a technique to retrieve single scattering albedo (SSA), was applied. Additionally, the background aerosol effect was corrected to improve the accuracy of the surface reflectance over Hong Kong. The \{AOD\} retrieved from a modified algorithm was compared to the collocated data measured by \{AERONET\} in Hong Kong. The comparison showed that the new aerosol type selection using the critical reflectance and the corrected surface reflectance significantly improved the accuracy of \{AODs\} in Hong Kong areas, with a correlation coefficient increase from 0.65 to 0.76 and a regression line change from τMI [basic algorithm] = 0.41τAERONET + 0.16 to τMI [new algorithm] = 0.70τAERONET + 0.01. "
}
@article{Turk20179,
title = "Home robot helps to keep you on your toes ",
journal = "New Scientist ",
volume = "233",
number = "3108",
pages = "9 - ",
year = "2017",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(17)30058-1",
url = "http://www.sciencedirect.com/science/article/pii/S0262407917300581",
abstract="",
author = "Victoria Turk"
}
@article{Beveridge20163824,
title = "Relationship between increased in vivo meniscal loads and abnormal tibiofemoral surface alignment in \{ACL\} deficient sheep is varied ",
journal = "Journal of Biomechanics ",
volume = "49",
number = "16",
pages = "3824 - 3832",
year = "2016",
note = "",
issn = "0021-9290",
doi = "https://doi.org/10.1016/j.jbiomech.2016.10.017",
url = "http://www.sciencedirect.com/science/article/pii/S0021929016311071",
author = "Jillian E. Beveridge and Mohammad Atarod and Bryan J. Heard and Etienne E.J. O’Brien and Cyril B. Frank and Nigel G. Shrive",
keywords = "Surface interactions",
keywords = "ACL",
keywords = "Meniscus",
keywords = "Osteoarthritis",
keywords = "Sheep ",
abstract = "Abstract The aim of this study was to quantify how abnormal dynamic tibiofemoral surface alignment affects the load bearing function of menisci in vivo. Using a sheep model of \{ACL\} deficiency, we tested the hypothesis that increased in vivo meniscal loads correlate with greater tibiofemoral surface alignment abnormality. Stifle kinematics were recorded using a bone-mounted instrumented spatial linkage in four sheep before, and at four and twenty weeks (w) after \{ACL\} transection. A parallel robotic manipulator was used to quantify stifle kinetics by reproducing each animal׳s in vivo kinematics and measuring tissue loads during gait. Meniscal resultant loads were estimated from the change in joint reaction force after sequentially removing load-bearing tissues. Tibiofemoral subchondral surfaces were then traced and modeled using thin plate splines. Proximity disturbance is a surface interaction measure used to quantify dynamic tibiofemoral surface alignment abnormality. \{ACL\} transection increased meniscal loads by 30–145% at 20w post-ACL transection, whereas the degree of dynamic tibiofemoral subchondral surface alignment varied between sheep. Positive and significant correlations between increased meniscal loads and proximity disturbance values &gt;10 mm were observed (R2=0.04–0.57; p≤0.05). Our results suggest that the proximity disturbance measure reflects abnormal meniscal loads following \{ACL\} injury; however given the range of \{R2\} values, perturbations in dynamic tibiofemoral subchondral surface alignment do not explain abnormal joint kinetics entirely, and point to the presence of other dynamic compensatory mechanisms that may have a significant bearing on in vivo joint function and long-term joint health. "
}
@article{Scardapane201742,
title = "A framework for parallel and distributed training of neural networks ",
journal = "Neural Networks ",
volume = "91",
number = "",
pages = "42 - 54",
year = "2017",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0893608017300849",
author = "Simone Scardapane and Paolo Di Lorenzo",
keywords = "Neural network",
keywords = "Distributed learning",
keywords = "Parallel computing",
keywords = "Networks ",
abstract = "Abstract The aim of this paper is to develop a general framework for training neural networks (NNs) in a distributed environment, where training data is partitioned over a set of agents that communicate with each other through a sparse, possibly time-varying, connectivity pattern. In such distributed scenario, the training problem can be formulated as the (regularized) optimization of a non-convex social cost function, given by the sum of local (non-convex) costs, where each agent contributes with a single error term defined with respect to its local dataset. To devise a flexible and efficient solution, we customize a recently proposed framework for non-convex optimization over networks, which hinges on a (primal) convexification–decomposition technique to handle non-convexity, and a dynamic consensus procedure to diffuse information among the agents. Several typical choices for the training criterion (e.g., squared loss, cross entropy, etc.) and regularization (e.g.,  ℓ 2 norm, sparsity inducing penalties, etc.) are included in the framework and explored along the paper. Convergence to a stationary solution of the social non-convex problem is guaranteed under mild assumptions. Additionally, we show a principled way allowing each agent to exploit a possible multi-core architecture (e.g., a local cloud) in order to parallelize its local optimization step, resulting in strategies that are both distributed (across the agents) and parallel (inside each agent) in nature. A comprehensive set of experimental results validate the proposed approach. "
}
@article{Domek201439,
title = "Timing Belt Gear Design for Mechatronics System ",
journal = "Procedia Engineering ",
volume = "96",
number = "",
pages = "39 - 43",
year = "2014",
note = "Modelling of Mechanical and Mechatronic Systems ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.12.095",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814031464",
author = "Grzegorz Domek and Marian Dudziak and Andrzej Kołodziej",
keywords = "Axially symmetric",
keywords = "Taper bushings",
keywords = "Mechanical gears ",
abstract = "Abstract The development of measurement techniques allows for a new approach to the design of machines. One can use 3D scanning systems and multi-axis computer numerical control (CNC) machines as coordinate measuring machines (CMM). The obtained cloud of measuring points allows to enter more variables into the geometrical product specification (GPS) and hence it allows to get a new method for assessing the tolerances. These situtation refers to axisymmetric elements that have an impact on operation of number of mechanisms. The application of coordinate measuring machines allowed for a new approach to the quality of belt pulley mounitng. Conditions of the contact surface area and allowable manufacturing errors, the actual position of the rotation axis of shaft hole and many other parameters can be defined during the manufacturing stage. "
}
@article{Favorskaya2014851,
title = "Distributed System for Crossroads Traffic Surveillance with Prediction of Incidents ",
journal = "Procedia Computer Science ",
volume = "35",
number = "",
pages = "851 - 860",
year = "2014",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.08.252",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914012174",
author = "Margarita Favorskaya and Euvgenii Kazmiruk and Aleksei Popov",
keywords = "Kalman filter",
keywords = "clustering",
keywords = "particle filter",
keywords = "motion estimation",
keywords = "motion prediction ",
abstract = "Abstract The development of traffic surveillance systems is one of the crucial tasks in intelligent urban surveillance. The visual tracking techniques become more complex with a high computational cost. At the same time, they provide the wide possibilities for motion estimation and prediction in cluttered video sequences. Our contribution is a reasonable application of fast motion estimation with additional using of the clustering procedure. Then the Kalman filter is applied for vehicles’ motion analysis, and the particle filter is used for analysis of pedestrians’ behavior assuming that pedestrians are the weakly predictable objects on the crossroads. Also the distributed surveillance system based on the cloud and fog technologies was designed to process large volumes of video information provided from several IP-cameras in a real-time mode, when six full frames per s are transmitted. "
}
@article{Gunther201290,
title = "Hybrid Reasoning in Perception: A Case Study ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "90 - 95",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00180",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016335935",
author = "Martin Gunther and Joachim Hertzberg and Masoumeh Mansouri and Federico Pecora and Alessandro Saffiotti",
keywords = "hybrid reasoning",
keywords = "temporal reasoning",
keywords = "description logics",
keywords = "fuzzy logic",
keywords = "constraint satisfaction problems",
keywords = "knowledge representation",
keywords = "knowledge-based systems",
keywords = "autonomous mobile robots",
keywords = "artificial intelligence ",
abstract = "Abstract Robots operating in a complex human-inhabited environment need to represent and reason about different kinds of knowledge, including ontological, spatial, causal, temporal and resource knowledge. Often, these reasoning tasks are not mutually independent, but need to be integrated with each other. Integrated reasoning is especially important when dealing with knowledge derived from perception, which may be intrinsically incomplete or ambiguous. For instance, the non-observable property that a dish has been used and should therefore be washed can be inferred from the observable properties that it was full before and that it is empty now. In this paper, we present a hybrid reasoning framework which allows to easily integrate different kinds of reasoners. We demonstrate the suitability of our approach by integrating two kinds of reasoners, for ontological reasoning and for temporal reasoning, and using them to recognize temporally and ontologically defined object properties in point cloud data captured using an RGB-D camera. "
}
@article{Carabali2017,
title = "Aerosol climatology over the Mexico City basin: Characterization of optical properties ",
journal = "Atmospheric Research ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2017.04.035",
url = "http://www.sciencedirect.com/science/article/pii/S0169809517304829",
author = "Giovanni Carabali and Hector Raul Estevez and Mauro Valdes-Barron and Roberto Bonifaz-Alfonzo and David Riveros-Rosas and Victor Manuel Velasco-Herrera and Felipe Adrian Vazquez-Galvez",
keywords = "Mexico City",
keywords = "Aerosols",
keywords = "Climatology",
keywords = "AOD",
keywords = "angstrom exponent",
keywords = "Single Scattering Albedo (SSA) ",
abstract = "Abstract Climatology of Aerosol Optical Depth (AOD), Single Scattering Albedo (SSA), and aerosol particle-size distribution were analyzed using a 15-year (1999–2014) dataset from \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) observations over the Mexico City (MC) basin. The atmosphere over this site is dominated by two main aerosol types, represented by urban/industrial pollution and biomass-burning particles. Due to the specific meteorological conditions within the basin, seasons are usually classified into three as follows: Dry Winter (DW) (November–February); Dry Spring (DS) (March–April), and the \{RAiny\} season (RA) (May–October), which are mentioned throughout this article. Using a \{CIMEL\} sun photometer, we conducted continuous observations over the \{MC\} urban area from January 1999 to December 2014. Aerosol Optical Depth (AOD), angstrom exponent (α440–870), Single Scattering Albedo (SSA), and aerosol particle-size distribution were derived from the observational data. The overall mean \{AOD500\} during the 1999–2014 period was 0.34 ± 0.07. The monthly mean \{AOD\} reached a maximal value of 0.49 in May and a minimal value of 0.27 in February and March. The average α440–870 value for the period studied was 1.50 ± 0.16. The monthly average of α440–870 reached a minimal value of 1.32 in August and a maximal value of 1.61 in May. Average \{SSA\} at 440 nm was 0.89 throughout the observation period, indicating that aerosols over Mexico City are composed mainly of absorptive particles. Concentrations of fine- and coarse-mode aerosols over \{MC\} were highest in \{DS\} season compared with other seasons, especially for particles with radii measuring between 0.1 and 0.2 μm. Results from the Spectral De-convolution Algorithm (SDA) show that fine-mode aerosols dominated \{AOD\} variability in MC. In the final part of this article, we present a classification of aerosols in \{MC\} by using the graphical method proposed by Gobbi et al. (2007), which is based on the combined analysis of α and its spectral curvature δα. "
}
@article{Bradley201557,
title = "The Internet of Things – The future or the end of mechatronics ",
journal = "Mechatronics ",
volume = "27",
number = "",
pages = "57 - 74",
year = "2015",
note = "",
issn = "0957-4158",
doi = "https://doi.org/10.1016/j.mechatronics.2015.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0957415815000215",
author = "David Bradley and David Russell and Ian Ferguson and John Isaacs and Allan MacLeod and Roger White",
keywords = "Internet of Things",
keywords = "Mechatronics",
keywords = "Design",
keywords = "Education",
keywords = "System security",
keywords = "Participatory systems ",
abstract = "Abstract The advent and increasing implementation of user configured and user oriented systems structured around the use of cloud configured information and the Internet of Things is presenting a new range and class of challenges to the underlying concepts of integration and transfer of functionality around which mechatronics is structured. It is suggested that the ways in which system designers and educators in particular respond to and manage these changes and challenges is going to have a significant impact on the way in which both the Internet of Things and mechatronics develop over time. The paper places the relationship between the Internet of Things and mechatronics into perspective and considers the issues and challenges facing systems designers and implementers in relation to managing the dynamics of the changes required. "
}
@article{HuckinsIII2000523,
title = "Exploring the solar system — A current overview — ",
journal = "Acta Astronautica ",
volume = "47",
number = "2–9",
pages = "523 - 533",
year = "2000",
note = "Space an Integral Part of the Information Age ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(00)00091-6",
url = "http://www.sciencedirect.com/science/article/pii/S0094576500000916",
author = "Dr.Earle K. Huckins III and Charles Elachi and Mr.Dan V. Woods",
abstract = "This paper examines the history of robotic exploration of the solar system from the initial flights to present day. Analysis demonstrates how flight rate and spacecraft mass have varied in the programs of the major space faring countries. The paper also demonstrates how the faster, better, cheaper approach has significantly increased scientific productivity and program resiliency to failures. "
}
@article{Antanas201475,
title = "There are plenty of places like home: Using relational representations in hierarchies for distance-based image understanding ",
journal = "Neurocomputing ",
volume = "123",
number = "",
pages = "75 - 85",
year = "2014",
note = "Contains Special issue articles: Advances in Pattern Recognition Applications and Methods ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2012.10.037",
url = "http://www.sciencedirect.com/science/article/pii/S0925231213003688",
author = "Laura Antanas and Martijn van Otterlo and Jose Oramas Mogrovejo and Tinne Tuytelaars and Luc De Raedt",
keywords = "Relational representations",
keywords = "Relational instance-based learning",
keywords = "Hierarchical image understanding ",
abstract = "Abstract Understanding images in terms of logical and hierarchical structures is crucial for many semantic tasks, including image retrieval, scene understanding and robotic vision. This paper combines robust feature extraction, qualitative spatial relations, relational instance-based learning and compositional hierarchies in one framework. For each layer in the hierarchy, qualitative spatial structures in images are detected, classified and then employed one layer up the hierarchy to obtain higher-level semantic structures. We apply a four-layer hierarchy to street view images and subsequently detect corners, windows, doors, and individual houses. "
}
@article{Wolfert201769,
title = "Big Data in Smart Farming – A review ",
journal = "Agricultural Systems ",
volume = "153",
number = "",
pages = "69 - 80",
year = "2017",
note = "",
issn = "0308-521X",
doi = "https://doi.org/10.1016/j.agsy.2017.01.023",
url = "http://www.sciencedirect.com/science/article/pii/S0308521X16303754",
author = "Sjaak Wolfert and Lan Ge and Cor Verdouw and Marc-Jeroen Bogaardt",
keywords = "Agriculture",
keywords = "Data",
keywords = "Information and communication technology",
keywords = "Data infrastructure",
keywords = "Governance",
keywords = "Business modelling ",
abstract = "Abstract Smart Farming is a development that emphasizes the use of information and communication technology in the cyber-physical farm management cycle. New technologies such as the Internet of Things and Cloud Computing are expected to leverage this development and introduce more robots and artificial intelligence in farming. This is encompassed by the phenomenon of Big Data, massive volumes of data with a wide variety that can be captured, analysed and used for decision-making. This review aims to gain insight into the state-of-the-art of Big Data applications in Smart Farming and identify the related socio-economic challenges to be addressed. Following a structured approach, a conceptual framework for analysis was developed that can also be used for future studies on this topic. The review shows that the scope of Big Data applications in Smart Farming goes beyond primary production; it is influencing the entire food supply chain. Big data are being used to provide predictive insights in farming operations, drive real-time operational decisions, and redesign business processes for game-changing business models. Several authors therefore suggest that Big Data will cause major shifts in roles and power relations among different players in current food supply chain networks. The landscape of stakeholders exhibits an interesting game between powerful tech companies, venture capitalists and often small start-ups and new entrants. At the same time there are several public institutions that publish open data, under the condition that the privacy of persons must be guaranteed. The future of Smart Farming may unravel in a continuum of two extreme scenarios: 1) closed, proprietary systems in which the farmer is part of a highly integrated food supply chain or 2) open, collaborative systems in which the farmer and every other stakeholder in the chain network is flexible in choosing business partners as well for the technology as for the food production side. The further development of data and application infrastructures (platforms and standards) and their institutional embedment will play a crucial role in the battle between these scenarios. From a socio-economic perspective, the authors propose to give research priority to organizational issues concerning governance issues and suitable business models for data sharing in different supply chain scenarios. "
}
@article{Zimmermann20161,
title = "High-throughput downstream process development for cell-based products using aqueous two-phase systems ",
journal = "Journal of Chromatography A ",
volume = "1464",
number = "",
pages = "1 - 11",
year = "2016",
note = "",
issn = "0021-9673",
doi = "https://doi.org/10.1016/j.chroma.2016.08.025",
url = "http://www.sciencedirect.com/science/article/pii/S0021967316310871",
author = "Sarah Zimmermann and Sarah Gretzinger and Marie-Luise Schwab and Christian Scheeder and Philipp K. Zimmermann and Stefan A. Oelmeier and Eric Gottwald and Are Bogsnes and Mattias Hansson and Arne Staby and Jurgen Hubbuch",
keywords = "High throughput screening (HTS)",
keywords = "Downstream processing of cell-based products",
keywords = "Label-free cell separation",
keywords = "Aqueous two-phase systems (ATPS)",
keywords = "High-throughput flow cytometry ",
abstract = "Abstract As the clinical development of cell-based therapeutics has evolved immensely within the past years, downstream processing strategies become more relevant than ever. Aqueous two-phase systems (ATPS) enable the label-free, scalable, and cost-effective separation of cells, making them a promising tool for downstream processing of cell-based therapeutics. Here, we report the development of an automated robotic screening that enables high-throughput cell partitioning analysis in ATPS. We demonstrate that this setup enables fast and systematic investigation of factors influencing cell partitioning. Moreover, we examined and optimized separation conditions for the differentiable promyelocytic cell line HL-60 and used a counter-current distribution-model to investigate optimal separation conditions for a multi-stage purification process. Finally, we show that the separation of CD11b-positive and CD11b-negative HL-60 cells is possible after partial DMSO-mediated differentiation towards the granulocytic lineage. The modeling data indicate that complete peak separation is possible with 30 transfers, and &gt;93% of CD11b-positive HL-60 cells can be recovered with &gt;99% purity. The here described screening platform facilitates faster, cheaper, and more directed downstream process development for cell-based therapeutics and presents a powerful tool for translational research. "
}
@article{Jin201559,
title = "Significance and Challenges of Big Data Research ",
journal = "Big Data Research ",
volume = "2",
number = "2",
pages = "59 - 64",
year = "2015",
note = "Visions on Big Data ",
issn = "2214-5796",
doi = "https://doi.org/10.1016/j.bdr.2015.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S2214579615000076",
author = "Xiaolong Jin and Benjamin W. Wah and Xueqi Cheng and Yuanzhuo Wang",
keywords = "Big data",
keywords = "Data complexity",
keywords = "Computational complexity",
keywords = "System complexity ",
abstract = "Abstract In recent years, the rapid development of Internet, Internet of Things, and Cloud Computing have led to the explosive growth of data in almost every industry and business area. Big data has rapidly developed into a hot topic that attracts extensive attention from academia, industry, and governments around the world. In this position paper, we first briefly introduce the concept of big data, including its definition, features, and value. We then identify from different perspectives the significance and opportunities that big data brings to us. Next, we present representative big data initiatives all over the world. We describe the grand challenges (namely, data complexity, computational complexity, and system complexity), as well as possible solutions to address these challenges. Finally, we conclude the paper by presenting several suggestions on carrying out big data projects. "
}
@article{Scharnagl201665,
title = "New Hardware-in-the-Loop Testing Concept for Small Satellite Formation Control Based on Mobile Robot Platforms ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "65 - 70",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.127",
url = "http://www.sciencedirect.com/science/article/pii/S240589631632571X",
author = "Julian Scharnagl and Klaus Schilling",
keywords = "Satellite formation flying",
keywords = "testbed concept",
keywords = "automatic testing",
keywords = "formation control",
keywords = "spacecraft autonomy",
keywords = "systems concept ",
abstract = "Abstract: This paper presents a new concept for hardware-in-the-loop testing of formation flying control of small satellites. Instead of commonly used mobile units based on air cushion principle moving on a frictionless surface, units based on wheeled mobile robots are proposed. Recent formation flying missions as well as presumable future applications are used to derive requirements for formation control algorithms and to justify according test demands. Common concepts of formation control testbeds are presented by examples and analyzed with respect to their value for evaluating the derived control needs, especially with respect to small satellites. Their assets and drawbacks are outlined. In order to complement the drawbacks the new testbed concept is derived. Its benefits, especially scalability, long-term and high-precision simulations, are depicted. Last, a combination of the mobile robot based testbed concept with stationary robotic manipulators with 6 degrees of freedom is proposed to add 3D out-of-plane motion for particular satellites and thus enabling 3D formation scenarios. "
}
@article{Luo2015264,
title = "Improved aerosol retrieval algorithm using Landsat images and its application for \{PM10\} monitoring over urban areas ",
journal = "Atmospheric Research ",
volume = "153",
number = "",
pages = "264 - 275",
year = "2015",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2014.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0169809514003536",
author = "Nana Luo and Man Sing Wong and Wenji Zhao and Xing Yan and Fei Xiao",
keywords = "AERONET",
keywords = "Aerosol retrieval",
keywords = "Landsat image",
keywords = "PM10 concentrations ",
abstract = "Abstract Aerosol retrieval using \{MODerate\} resolution Imaging Spectroradiometer (MODIS) has been well researched over the past decade. However, the application is limited to global- and regional-scale studies, which may not be applicable for urban areas due to its low spatial resolution. To overcome the limitation, this paper proposed an improved aerosol retrieval algorithm for Landsat images (ImAero-Landsat) at spatial resolution of 30 m. This ImAero-Landsat algorithm has been improved in the following two aspects: (i) it does not require a comprehensive look up table and thus it is more efficient in \{AOT\} retrieval; and (ii) it can be operated in both bright and dark surfaces. The derived aerosol optical thickness (AOT) images were validated with \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) measurements as well as \{MODIS\} \{MOD04\} \{AOT\} products. Small root mean square errors (RMSEs) of 0.11 and 0.14 and mean absolute difference (MAD) of 0.07 and 0.11 between ImAero-Landsat AOT, with \{MODIS\} \{MOD04\} and \{AERONET\} products were observed. By correlating with ground based \{PM10\} concentrations, the ImAero-Landsat method outperforms (r2 = 0.32) than \{MOD04\} \{AOT\} products (r2 = 0.23). In addition, the accuracy of estimating \{PM10\} can be improved to r2 = 0.55 when the derived \{AOT\} was integrated with meteorological parameters. The accuracy is similar to the results derived from \{AERONET\} \{AOT\} (r2 = 0.62). This study offers a simple and accurate method to investigate aerosol optical thickness at detailed city-scale. Environmental authorities may use the derived methods for deriving aerosol distribution maps and pinpointing the sources of pollutants in urban areas. "
}
@article{Li201735,
title = "Modeling of path planning and needle steering with path tracking in anatomical soft tissues for minimally invasive surgery ",
journal = "Medical Engineering & Physics ",
volume = "41",
number = "",
pages = "35 - 45",
year = "2017",
note = "",
issn = "1350-4533",
doi = "https://doi.org/10.1016/j.medengphy.2017.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S1350453317300073",
author = "Pan Li and Shan Jiang and Dong Liang and Zhiyong Yang and Yan Yu and Wei Wang",
keywords = "Minimally invasive surgery",
keywords = "Steerable needle",
keywords = "Path planning",
keywords = "Needle steering",
keywords = "Duty-cycled spinning",
keywords = "Path tracking",
keywords = "Soft tissue ",
abstract = "Abstract Steerable needles can potentially improve the effectiveness of diagnostic and therapeutic procedures, such as biopsy and cancer treatment, by increasing the targeting accuracy and reaching previously inaccessible targets. A discrete potential field algorithm based on three dimensional (3D) anatomical structures is proposed in this paper to plan the needle path in minimally invasive surgery. A 3D kinematic model of needle steering is formulated using Lie group theory. Model parameters are fitted using experimental data acquired via a 2-degree of freedom robotic device and an ultrasound imaging device. To execute the paths with variable curvatures, the model is incorporated with duty cycled spinning. Empirical formula between needle curvature and duty cycled factor is obtained through insertion experiments. To improve the targeting accuracy, a path tracking algorithm is developed by correcting for the heading error and cross-track error of the needle tip. The targeting error of the simulation is 0.29 mm. We experimentally evaluate the path tracking model and it achieves an average targeting error of 1.15 ± 0.56 mm in 3D environments with anatomical obstacles. The results of simulation are in agreement with steering experiments, showing that the discrete potential field algorithm and path tracking model have the potential to improve targeting accuracy and advance the therapeutic and diagnostic procedures. "
}
@article{GarrickBethell2007627,
title = "Global scale lunar sample return using projectiles launched from a low-flying spacecraft ",
journal = "Advances in Space Research ",
volume = "39",
number = "4",
pages = "627 - 635",
year = "2007",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2006.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S0273117706005783",
author = "Ian Garrick-Bethell and Erwan Mazarico and Wesley Andres Watters",
keywords = "Moon",
keywords = "Impactor",
keywords = "Sample return",
keywords = "Ejecta ",
abstract = "Since the Moon has no atmosphere it is possible to fly over the surface at very low altitudes without experiencing drag forces. If a spacecraft flying at a low altitude were to fire a projectile into the lunar surface, a second trailing spacecraft could capture material from the resulting cloud of ejecta. This procedure could be repeated over many sites on the Moon with a fresh collector for each location. Eventually, the collector spacecraft would seal its cargo in a reentry vehicle and return to Earth with the samples. Compared with a robotic lander, the advantage of this architecture is the ability to sample locations over the entire Moon, wherever the topography will permit such maneuvers. Our crater ejecta models show that 1–10 g of material can be collected from the ejecta curtain of a 2 m radius crater at an altitude of 150 m, assuming a collector surface area of 1 square meter. We studied numerous means of creating these craters and developed two scenarios: a reduced velocity explosive excavator (EE), and a higher velocity impact excavator (IE). "
}
@article{Hamledari201778,
title = "Automated computer vision-based detection of components of under-construction indoor partitions ",
journal = "Automation in Construction ",
volume = "74",
number = "",
pages = "78 - 94",
year = "2017",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.11.009",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516304046",
author = "Hesam Hamledari and Brenda McCabe and Shakiba Davari",
keywords = "Computer vision",
keywords = "Interior construction",
keywords = "Machine learning",
keywords = "Image processing",
keywords = "Digital images",
keywords = "Indoors ",
abstract = "Abstract This paper presents a computer vision-based algorithm that automatically detects the components of an interior partition and infers its current state using 2D digital images. The algorithm relies on four integrated shape and color-based modules, which detect studs, insulation, electrical outlets, and three states for drywall sheets (installed, plastered, and painted). Based on the results of the four modules, images are classified into five states. The proposed method was validated using three image databases of indoor construction sites captured by a quadcopter (a type of unmanned aerial vehicle), a smartphone, and collected from publically available sources on the internet. The method's high accuracy rates, its fast performance, and applicability to different contexts such as automated robotic inspection are indicative of its promising performance. The visual detection results can potentially provide situational awareness for construction trades, provide future progress tracking systems with information on actual state, and help leverage the use of image processing at indoor sites. "
}
@article{Marov199432,
title = "Scientific and technical strategies for planetary exploration ",
journal = "Space Policy ",
volume = "10",
number = "1",
pages = "32 - 44",
year = "1994",
note = "",
issn = "0265-9646",
doi = "https://doi.org/10.1016/0265-9646(94)90038-8",
url = "http://www.sciencedirect.com/science/article/pii/0265964694900388",
author = "Mikhail Ya. Marov",
abstract = "Dramatic changes in the world political situation have encouraged collaboration between the main spacefaring, and other nations, in furthering progress in space endeavours. General strategic concepts must balance scientific/ technology/cost rationales while still preserving political and ambitious issues. This paper advocates optimizing the information from low-cost robotic missions to outer and inner planets when discussing ambitious robotic and manned flights to Mars. The author also articulates three additional points: first, the necessity of establishing the degree to which a human rather than a robotic presence is an absolute requirement for the most effective study of a planet; second, is the time ripe for a manned mission to Mars considering existing political/economic/technological constraints?; and third, that such a costly project is justified only if nations pool their resources and combine interests through effective international cooperation. "
}
@article{Bohg2010362,
title = "Learning grasping points with shape context ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "4",
pages = "362 - 377",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001699",
author = "Jeannette Bohg and Danica Kragic",
keywords = "Grasping",
keywords = "Shape context",
keywords = "Affordances",
keywords = "SVM ",
abstract = "This paper presents work on vision based robotic grasping. The proposed method adopts a learning framework where prototypical grasping points are learnt from several examples and then used on novel objects. For representation purposes, we apply the concept of shape context and for learning we use a supervised learning approach in which the classifier is trained with labelled synthetic images. We evaluate and compare the performance of linear and non-linear classifiers. Our results show that a combination of a descriptor based on shape context with a non-linear classification algorithm leads to a stable detection of grasping points for a variety of objects. "
}
@article{Yang2017169,
title = "Modern software cybernetics: New trends ",
journal = "Journal of Systems and Software ",
volume = "124",
number = "",
pages = "169 - 186",
year = "2017",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.08.095",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216301595",
author = "Hongji Yang and Feng Chen and Suleiman Aliyu",
keywords = "Software cybernetics",
keywords = "Control engineering",
keywords = "Software engineering",
keywords = "Computer science",
keywords = "Artificial intelligence ",
abstract = "Abstract Software cybernetics research is to apply a variety of techniques from cybernetics research to software engineering research. For more than fifteen years since 2001, there has been a dramatic increase in work relating to software cybernetics. From cybernetics viewpoint, the work is mainly on the first-order level, namely, the software under observation and control. Beyond the first-order cybernetics, the software, developers/users, and running environments influence each other and thus create feedback to form more complicated systems. We classify software cybernetics as Software Cybernetics I based on the first-order cybernetics, and as Software Cybernetics \{II\} based on the higher order cybernetics. This paper provides a review of the literature on software cybernetics, particularly focusing on the transition from Software Cybernetics I to Software Cybernetics II. The results of the survey indicate that some new research areas such as Internet of Things, big data, cloud computing, cyber-physical systems, and even creative computing are related to Software Cybernetics II. The paper identifies the relationships between the techniques of Software Cybernetics \{II\} applied and the new research areas to which they have been applied, formulates research problems and challenges of software cybernetics with the application of principles of Phase \{II\} of software cybernetics; identifies and highlights new research trends of software cybernetic for further research. "
}
@article{Mazanek2015163,
title = "Asteroid Redirect Mission concept: A bold approach for utilizing space resources ",
journal = "Acta Astronautica ",
volume = "117",
number = "",
pages = "163 - 171",
year = "2015",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.06.018",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515002635",
author = "Daniel D. Mazanek and Raymond G. Merrill and John R. Brophy and Robert P. Mueller",
keywords = "Asteroid resources",
keywords = "In-situ resource utilization (ISRU)",
keywords = "Solar electric propulsion",
keywords = "Asteroid Redirect Mission",
keywords = "Space exploration",
keywords = "Settlement of space ",
abstract = "Abstract The utilization of natural resources from asteroids is an idea that is older than the Space Age. The technologies are now available to transform this endeavor from an idea into reality. The Asteroid Redirect Mission (ARM) is a mission concept which includes the goal of robotically returning a small Near-Earth Asteroid (NEA) or a multi-ton boulder from a large \{NEA\} to cislunar space in the mid-2020s using an advanced Solar Electric Propulsion (SEP) vehicle and currently available technologies. The paradigm shift enabled by the \{ARM\} concept would allow in-situ resource utilization (ISRU) to be used at the human mission departure location (i.e., cislunar space) versus exclusively at the deep-space mission destination. This approach drastically reduces the barriers associated with utilizing \{ISRU\} for human deep-space missions. The successful testing of \{ISRU\} techniques and associated equipment could enable large-scale commercial \{ISRU\} operations to become a reality and enable a future space-based economy utilizing processed asteroidal materials. This paper provides an overview of the \{ARM\} concept and discusses the mission objectives, key technologies, and capabilities associated with the mission, as well as how the \{ARM\} and associated operations would benefit humanity׳s quest for the exploration and settlement of space. "
}
@article{Olano20141283,
title = "The Influence of Sky Conditions on the Standardized Calibration of Pyranometers and on the Measurement of Global Solar Irradiation ",
journal = "Energy Procedia ",
volume = "57",
number = "",
pages = "1283 - 1292",
year = "2014",
note = "2013 \{ISES\} Solar World Congress ",
issn = "1876-6102",
doi = "https://doi.org/10.1016/j.egypro.2014.10.118",
url = "http://www.sciencedirect.com/science/article/pii/S1876610214014854",
author = "Xabier Olano and Fabienne Sallaberry and Alberto Garcia de Jalon",
keywords = "Calibration",
keywords = "Pyranometer",
keywords = "Irradiance measurement",
keywords = "Standard Procedure ",
abstract = "Abstract Global solar irradiance measurement is used for applications such as verifying satellite measurements, studying the distribution and variation of the received radiation or estimating the energy yield of solar plants. This measurement is directly influenced by the reference calibration coefficient of the field pyranometer used. The radiometer calibration laboratory of \{CENER\} is accredited by \{ENAC\} (Spanish National Accreditation Body) since 2010 according to \{ISO\} 9847:1992 for the calibration of field pyranometers via comparison to a reference pyranometer. The accreditation's scope covers calibrations “type Ia” (outdoor horizontal calibrations for meteorological and resource measurements, part 5.2.2, annex B.2). For the outdoor calibration, the methodology takes different sky conditions into account: stable cloudless sky conditions, unstable sky conditions with some clouds or cloudy sky conditions. The classification criteria described by the standard have been enhanced by \{CENER\} for an easier application, establishing additional radiometric conditions, especially for unstable sky conditions with some clouds. Detailed criteria are based on CENER's experience in solar collector testing and on the experimental \{CENER\} \{BSRN\} station (Baseline Surface Radiation Network) measurements and total sky camera images. During laboratory activity, several calibration coefficient results have been analyzed in order to validate the three methodologies regarding the before mentioned sky conditions. The calibration coefficient can be slightly different depending on the sky conditions and the calibration methodology; therefore global solar irradiation measurements can differ too. The influence of this dependency has been evaluated in order to estimate the monthly and yearly global solar irradiation. "
}
@article{Sahbani2012326,
title = "An overview of 3D object grasp synthesis algorithms ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "326 - 336",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001485",
author = "A. Sahbani and S. El-Khoury and P. Bidaud",
keywords = "Grasp synthesis",
keywords = "Force-closure",
keywords = "Learning by demonstration",
keywords = "Task modeling ",
abstract = "This overview presents computational algorithms for generating 3D object grasps with autonomous multi-fingered robotic hands. Robotic grasping has been an active research subject for decades, and a great deal of effort has been spent on grasp synthesis algorithms. Existing papers focus on reviewing the mechanics of grasping and the finger–object contact interactions Bicchi and Kumar (2000) [12] or robot hand design and their control Al-Gallaf et al. (1993) [70]. Robot grasp synthesis algorithms have been reviewed in Shimoga (1996) [71], but since then an important progress has been made toward applying learning techniques to the grasping problem. This overview focuses on analytical as well as empirical grasp synthesis approaches. "
}
@article{Dearden2014355,
title = "Manipulation planning using learned symbolic state abstractions ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "3",
pages = "355 - 365",
year = "2014",
note = "Advances in Autonomous Robotics — Selected extended papers of the joint 2012 \{TAROS\} Conference and the \{FIRA\} RoboWorld Congress, Bristol, \{UK\} ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001905",
author = "Richard Dearden and Chris Burbridge",
keywords = "Intelligent robots",
keywords = "Supervised learning",
keywords = "Automatic planning",
keywords = "Symbolic reasoning ",
abstract = "Abstract We present an approach for planning robotic manipulation tasks that uses a learned mapping between geometric states and logical predicates. Manipulation planning, because it requires task-level and geometric reasoning, requires such a mapping to convert between the two. Consider a robot tasked with putting several cups on a tray. The robot needs to find positions for all the objects, and may need to nest one cup inside another to get them all on the tray. This requires translating back and forth between symbolic states that the planner uses, such as stacked (cup1,cup2), and geometric states representing the positions and poses of the objects. We learn the mapping from labelled examples, and importantly learn a representation that can be used in both the forward (from geometric to symbolic) and reverse directions. This enables us to build symbolic representations of scenes the robot observes, but also to translate a desired symbolic state from a plan into a geometric state that the robot can achieve through manipulation. We also show how such a mapping can be used for efficient manipulation planning: the planner first plans symbolically, then applies the mapping to generate geometric positions that are then sent to a path planner. "
}
@article{Crawford20123,
title = "Back to the Moon: The scientific rationale for resuming lunar surface exploration ",
journal = "Planetary and Space Science ",
volume = "74",
number = "1",
pages = "3 - 14",
year = "2012",
note = "Scientific Preparations For Lunar Exploration ",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2012.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0032063312001444",
author = "I.A. Crawford and M. Anand and C.S. Cockell and H. Falcke and D.A. Green and R. Jaumann and M.A. Wieczorek",
keywords = "Moon",
keywords = "Lunar science",
keywords = "Lunar geology",
keywords = "Lunar geophysics",
keywords = "Lunar astronomy",
keywords = "Space exploration",
keywords = "Astrobiology",
keywords = "Space life sciences",
keywords = "Space medicine ",
abstract = "The lunar geological record has much to tell us about the earliest history of the Solar System, the origin and evolution of the Earth–Moon system, the geological evolution of rocky planets, and the near-Earth cosmic environment throughout Solar System history. In addition, the lunar surface offers outstanding opportunities for research in astronomy, astrobiology, fundamental physics, life sciences and human physiology and medicine. This paper provides an interdisciplinary review of outstanding lunar science objectives in all of these different areas. It is concluded that addressing them satisfactorily will require an end to the 40-year hiatus of lunar surface exploration, and the placing of new scientific instruments on, and the return of additional samples from, the surface of the Moon. Some of these objectives can be achieved robotically (e.g., through targeted sample return, the deployment of geophysical networks, and the placing of antennas on the lunar surface to form radio telescopes). However, in the longer term, most of these scientific objectives would benefit significantly from renewed human operations on the lunar surface. For these reasons it is highly desirable that current plans for renewed robotic surface exploration of the Moon are developed in the context of a future human lunar exploration programme, such as that proposed by the recently formulated Global Exploration Roadmap. "
}
@article{Johnson1999165,
title = "The cause and consequences of a satellite fragmentation: A case study ",
journal = "Advances in Space Research ",
volume = "23",
number = "1",
pages = "165 - 173",
year = "1999",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/S0273-1177(98)00243-9",
url = "http://www.sciencedirect.com/science/article/pii/S0273117798002439",
author = "N.L. Johnson",
abstract = "The fragmentation of a Pegasus Hydrazine Auxiliary Propulsion System upper stage on 3 June 1996 stands as the worst satellite breakup on record in terms of cataloged orbital debris. In addition to the more than 700 debris large enough to be tracked (approximately 10 cm in diameter or greater) in the 200 km by 2,000 km orbital regime by the U.S. Space Surveillance Network, a debris population of up to 300,000 objects larger than 4 mm appears to have been generated, based upon special radar observations. The debris cloud presented an immediate threat to many resident space objects, such as the Hubble Space Telescope, which resided in an orbit just 25 km below the breakup altitude. Special analyses were required to ensure the safety of the STS-82 Hubble Space Telescope servicing mission in February 1997. This paper describes the activities undertaken at the National Aeronautics and Space Administration Lyndon B. Johnson Space Center to characterize the near-term and far-term hazard of the debris cloud to manned and robotic spacecraft and to investigate the probable cause of the accident. The role of composite materials in the vehicle may have led to the creation of a much larger number of debris than would have been expected from a more conventional upper stage. To avoid a repetition of the incident, the Hydrazine Auxiliary Propulsion System upper stage was modified before its next launch, and additional passivation measures were adopted. This fragmentation event represents a textbook case for the hazards posed by satellite breakups and how fragmentation potential can be reduced without significantly affecting the capability of the vehicle. "
}
@article{Pahlevan2017289,
title = "Landsat 8 remote sensing reflectance (Rrs) products: Evaluations, intercomparisons, and enhancements ",
journal = "Remote Sensing of Environment ",
volume = "190",
number = "",
pages = "289 - 301",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.12.030",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716305090",
author = "Nima Pahlevan and John R. Schott and Bryan A. Franz and Giuseppe Zibordi and Brian Markham and Sean Bailey and Crystal B. Schaaf and Michael Ondrusek and Steven Greb and Christopher M. Strait",
keywords = "Landsat 8",
keywords = "Aquatic science",
keywords = "Ocean color",
keywords = "Atmospheric correction",
keywords = "Calibration",
keywords = "Coastal/inland waters ",
abstract = "Abstract The Operational Land Imager (OLI) onboard Landsat-8 is generating high-quality aquatic science products, the most critical of which is the remote sensing reflectance (Rrs), defined as the ratio of water-leaving radiance to the total downwelling irradiance just above water. The quality of the Rrs products has not, however, been extensively assessed. This manuscript provides a comprehensive evaluation of Level-1B, i.e., top of atmosphere reflectance, and Rrs products available from \{OLI\} imagery under near-ideal atmospheric conditions in moderately turbid waters. The procedure includes a) evaluations of the Rrs products at sites included in the Ocean Color component of the Aerosol Robotic Network (AERONET-OC), b) intercomparisons and cross-calibrations against other ocean color products, and c) optimizations of vicarious calibration gains across the entire \{OLI\} observing swath. Results indicate that the near-infrared and shortwave infrared (NIR-SWIR) band combinations yield the most robust and stable Rrs retrievals in moderately turbid waters. Intercomparisons against products derived from the Visible Infrared Imaging Radiometer Suite (VIIRS) and the Moderate Resolution Imaging Spectroradiometer onboard the Aqua platform (MODISA) indicate slight across-track non-uniformities (&lt; 1%) associated with \{OLI\} scenes in the blue bands. In both product domains (TOA and Rrs), on average, the \{OLI\} products were found larger in radiometric responses in the blue channels. Following the implementation of updated vicarious calibration gains and accounting for across-track non-uniformities, matchup analyses using independent in-situ validation data confirmed improvements in Rrs products. These findings further support high-fidelity OLI-derived aquatic science products in terms of both demonstrating a robust atmospheric correction method and providing consistent products across OLI's imaging swath. "
}
@article{Seo2011954,
title = "Task planner design for an automated excavation system ",
journal = "Automation in Construction ",
volume = "20",
number = "7",
pages = "954 - 966",
year = "2011",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000409",
author = "Jongwon Seo and Seungsoo Lee and Jeonghwan Kim and Sung-Keun Kim",
keywords = "Automation",
keywords = "Earthwork",
keywords = "Intelligent excavation system",
keywords = "Task planning system ",
abstract = "An automated excavation system, which is a robotic excavator with site modeling capability, is being developed by a Korean research consortium in order to improve the productivity, quality, and safety of conventional earthwork. This paper presents the excavation task planner devised to incorporate the intelligence of a construction planner and a skillful operator into the robotic control mechanism of the automated excavation system. The excavation task planner aims to generate an optimal excavation plan based on 3D models of the work environment and the excavator updated by various cognitive technologies. The structure of the task planner was designed in harmony with the sensing and the control schemes of the automated excavation system. The algorithms used to partition the work area and to generate the excavator path were developed as the critical components of the task planner. The suggested design of the excavation task planner focused on the functions required to utilize the automated excavator at actual construction sites. Case studies showed that the task planner was able to generate effective work plans that could be fed into the automated excavation system. "
}
@article{Kwok2014678,
title = "Volumetric template fitting for human body reconstruction from incomplete data ",
journal = "Journal of Manufacturing Systems ",
volume = "33",
number = "4",
pages = "678 - 689",
year = "2014",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2014.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0278612514000624",
author = "Tsz-Ho Kwok and Kwok-Yun Yeung and Charlie C.L. Wang",
keywords = "Template fitting",
keywords = "Volumetric mesh",
keywords = "Incomplete data",
keywords = "Human body reconstruction",
keywords = "RGB-D camera ",
abstract = "Abstract In this paper, we present a method for reconstructing 3D human body from incomplete data, which are point clouds captured by inexpensive RGB-D cameras. Making use of the volumetric mesh in a template, the fitting process is robust. This method produces high quality fitting results on incomplete data, which are hard to be offered by the surface fitting based methods. The method is formulated as an optimization procedure, so that the results of volumetric fitting rely on the quality of initial shape (i.e., the shape of template). In order to find a good initial shape, we develop a template selection algorithm to choose a template in an iterative manner by using the statistical models of human bodies. Experimental results show that our method can successfully reconstruct human body with good quality to be used in design and manufacturing applications. "
}
@article{Alletto2017274,
title = "Video registration in egocentric vision under day and night illumination changes ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "274 - 283",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S107731421630145X",
author = "Stefano Alletto and Giuseppe Serra and Rita Cucchiara",
keywords = "Video registration",
keywords = "Egocentric vision",
keywords = "Visual matching ",
abstract = "Abstract With the spread of wearable devices and head mounted cameras, a wide range of application requiring precise user localization is now possible. In this paper we propose to treat the problem of obtaining the user position with respect to a known environment as a video registration problem. Video registration, i.e. the task of aligning an input video sequence to a pre-built 3D model, relies on a matching process of local keypoints extracted on the query sequence to a 3D point cloud. The overall registration performance is strictly tied to the actual quality of this 2D-3D matching, and can degrade if environmental conditions such as steep changes in lighting like the ones between day and night occur. To effectively register an egocentric video sequence under these conditions, we propose to tackle the source of the problem: the matching process. To overcome the shortcomings of standard matching techniques, we introduce a novel embedding space that allows us to obtain robust matches by jointly taking into account local descriptors, their spatial arrangement and their temporal robustness. The proposal is evaluated using unconstrained egocentric video sequences both in terms of matching quality and resulting registration performance using different 3D models of historical landmarks. The results show that the proposed method can outperform state of the art registration algorithms, in particular when dealing with the challenges of night and day sequences. "
}
@article{Alvim2017,
title = "Aerosol distribution over Brazil with ECHAM-HAM and CAM5-MAM3 simulations and its comparison with ground-based and satellite data ",
journal = "Atmospheric Pollution Research ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1309-1042",
doi = "https://doi.org/10.1016/j.apr.2017.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S1309104216302197",
author = "Debora Souza Alvim and Jayant Pendharkar and Vinicius Buscioli Capistrano and Ariane Frassoni and Diego Pereira Enore and Otacilio Leandro de Menezes Neto and Enver Ramirez Gutierrez and Ayantika Dey Choudhury and Paulo Yoshio Kubota and Josiane da Silva and Sergio Machado Correa and Paulo Nobre and Silvio Nilo Figueroa",
keywords = "Aerosol optical depth",
keywords = "Climate change",
keywords = "Model assessment",
keywords = "Aerosol Brazil",
keywords = "ECHAM-HAM and CAM5-MAM3 models ",
abstract = "Abstract The accurate representation of the impacts of natural and anthropogenic aerosols in the climate system presents a challenge in General Circulation Models. This paper analyzes the performance of the aerosol component of two Atmospheric General Circulation Models (AGCM): the Europe Centre Hamburg Model - Hamburg Aerosol Model (ECHAM-HAM), and the Community Atmosphere Model - Modal Aerosol Model (CAM5-MAM3) and their comparison with aerosol observations. We analyzed the spatial distribution of aerosols over Brazil represented in terms of the aerosol optical depth (AOD) simulated by these models. The model results are compared to measurements from Aerosol Robotic Network (AERONET) ground station, and satellite observations provided by the Moderate Resolution Imaging Spectroradiometer (MODIS). While both the models provide \{AODs\} at 550 nm, only \{HAM\} provides the Angstrom exponent that is compared with \{AERONET\} measurements. The comparison between the model simulations and the satellite observations of \{AOD\} show that the models can reproduce the spatial and temporal distributions, however models underestimate \{AOD\} for the four cities and for almost every South American continent during all seasons. During the dry season, characterized by intense biomass burning, CAM5-MAM3 shows inconsistent, but comparatively better results that ECHAM-HAM, with negative biases over Northern and Northeastern regions of Brazil. The Angstrom parameter is reasonably reproduced by ECHAM-HAM, except for Cuiaba, indicating that the particle size distribution is correctly represented in most cities. "
}
@article{Barbero20091265,
title = "The recovery of design intent in reverse engineering problems ",
journal = "Computers & Industrial Engineering ",
volume = "56",
number = "4",
pages = "1265 - 1275",
year = "2009",
note = "",
issn = "0360-8352",
doi = "https://doi.org/10.1016/j.cie.2008.07.023",
url = "http://www.sciencedirect.com/science/article/pii/S0360835208001617",
author = "Basilio Ramos Barbero",
keywords = "Reverse engineering",
keywords = "Design recovery",
keywords = "Constraints",
keywords = "Parametric approximation",
keywords = "Design intent ",
abstract = "This article presents a method of reverse engineering applied to the particular case of a cam in order to recover the form and dimensions of the design of the original piece, which take into account: design intent, general knowledge of the problem, different geometric and dimensional restrictions, and the digitized point cloud. Rather than by employing complex mathematical algorithms, a fit is achieved by drawing a parametric outline that complies with the design intent, and by adjusting the different parameters through successive approximations using commercial \{CAD\} software commands. "
}
@article{Castelli2014603,
title = "The HelioMont method for assessing solar irradiance over complex terrain: Validation and improvements ",
journal = "Remote Sensing of Environment ",
volume = "152",
number = "",
pages = "603 - 613",
year = "2014",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2014.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0034425714002673",
author = "M. Castelli and R. Stockli and D. Zardi and A. Tetzlaff and J.E. Wagner and G. Belluardo and M. Zebisch and M. Petitta",
keywords = "Solar surface irradiance",
keywords = "Diffuse radiation",
keywords = "Aerosols",
keywords = "Radiative transfer modeling",
keywords = "Remote sensing ",
abstract = "Abstract This study evaluates the suitability of the method HelioMont, developed by MeteoSwiss, for estimating solar radiation from geostationary satellite data over the Alpine region. The algorithm accounts for the influence of topography, clouds, snow cover and the atmosphere on incoming solar radiation. The main error sources are investigated for both direct and diffuse solar radiation components by comparison with ground-based measurement taken at three sites, namely Bolzano (IT), Davos (CH) and Payerne (CH), encompassing different topographic conditions. The comparison shows that the method provides high accuracy of the yearly cycle: the Mean Absolute Bias (MAB) is below 5 W m− 2 at the lowland station Payerne and below 12 W m− 2 at the other two mountainous stations for the monthly averages of global and diffuse radiation. For diffuse radiation the \{MAB\} is in the range 11–15 W m− 2 for daily means and 34–40 W m− 2 for hourly means. It is found that the largest errors in diffuse and direct radiation components on shorter time scales occur during summer and for cloud-free days. In both Bolzano and Davos the errors for daily-mean diffuse radiation can exceed 50 W m− 2 under such conditions. As HelioMont uses monthly climatological values of atmospheric aerosol characteristics, the effects of this approximation are investigated by simulating clear-sky solar radiation with the radiative transfer model (RTM) libRadtran using instantaneous aerosol measurements. Both ground-based and satellite-based data on aerosol optical properties and water vapor column amount are evaluated. When using daily atmospheric input the estimation of the hourly averages improves significantly and the mean error is reduced to 10–20 W m− 2. These results suggest the need for a more detailed characterization of the local-scale clear-sky atmospheric conditions for modeling solar radiation on daily and hourly time scales. "
}
@article{Zhang20152095,
title = "Integrated Ontologies in Support of Factory Systems Design ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "2095 - 2102",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.398",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315006370",
author = "J. Zhang and K. Agyapong-Kodua",
keywords = "Product (P)-Process (P) and Resource (R) ontologies",
keywords = "Semantic Technologies",
keywords = "Factory systems",
keywords = "Digital Factory ",
abstract = "Abstract Digital factory modelling based on virtual design and simulation has emerged as part of the mainstream activities geared towards reducing product design cycle. Some basic industrial systems are currently integrated via semantic modelling technologies so that products matching processes and resource requirements are integrated to fulfil customer demands. Despite these achievements, product design is still dependent on the knowledge of designers and do not benefit from existing process and resource knowledge, which are in separate domains. This paper therefore presents an integration method based on semantic technologies and \{PPR\} ontologies to enable the reuse of known and unknown knowledge. The method relies on the use of cloud manufacturing to improve the efficiency of responsesgenerated by querying the \{PPR\} ontology. "
}
@article{Faria2012247,
title = "A Probabilistic Framework to Detect Suitable Grasping Regions on Objects ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "247 - 252",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00090",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336187",
author = "Diego R. Faria and Ricardo Martins and Jorge Lobo and Jorge Dias",
keywords = "Human demonstration",
keywords = "object representation",
keywords = "probabilistic framework",
keywords = "grasping ",
abstract = "Abstract This work relies on a probabilistic framework to search for suitable grasping regions on objects. In this approach, the object model is acquired based on occupancy grid representation that deals with the sensor uncertainty allowing later the decomposition of the object global shape into components. Through mixture distribution-based representation we achieve the object segmentation where the outputs are the point cloud clustering. Each object component is matched to a geometrical primitive. The advantage of representing object components into geometrical primitives is due to the simplification and approximation of the shape that facilitates the search for suitable object region for grasping given a context. Human demonstrations of predefined grasp are recorded and then overlaid on the object surface given by the probabilistic volumetric map to find the contact points of stable grasps. By observing the human choice during the object grasping, we perform the learning phase. Bayesian theory is used to identify a potential object region for grasping in a specific context when the artificial system faces a new object that is taken as a familiar object due to the primitives approximation into known components. "
}
@article{Francesconi2012539,
title = "Effects of high-speed impacts on \{CFRP\} plates for space applications ",
journal = "Advances in Space Research ",
volume = "50",
number = "5",
pages = "539 - 548",
year = "2012",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2012.05.012",
url = "http://www.sciencedirect.com/science/article/pii/S0273117712003225",
author = "A. Francesconi and C. Giacomuzzo and S. Kibe and Y. Nagao and M. Higashide",
keywords = "Polymer-matrix composites (PMCs)",
keywords = "Carbon fibre",
keywords = "Impact behaviour",
keywords = "Ballistic limit ",
abstract = "In the framework of a collaboration between the Center of Studies and Activities for Space of the University of Padova (CISAS-UPD) and the Japan Aerospace Exploration Agency (JAXA), 45 hypervelocity impact experiments were realised on Carbon Fibre Reinforced Plastic samples (CFRP) having nominal thickness of 2.3, 3.5 and 4.3 mm. The impact tests were made with aluminium spheres of 0.8, 1.5, 1.9, 2.3 and 2.9 mm, at velocities between 2 and 5 km/s. After a preliminary post-impact inspection of the targets, ballistic limit equations were developed using a new procedure which permits to estimate the uncertainty in the failure predictions starting from the measurement of the projectile entry crater. Then, in case of sample perforation and consequent ejection of fragments, high-speed shadowgraphs of the debris cloud were analysed to qualitatively describe the evolution of the impact damage, together with its basic features. "
}
@article{Lee201431,
title = "Improved volcanic ash detection based on a hybrid reverse absorption technique ",
journal = "Atmospheric Research ",
volume = "143",
number = "",
pages = "31 - 42",
year = "2014",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2014.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S0169809514000210",
author = "Kwon Ho Lee and Man Sing Wong and Sung-Rae Chung and Eunha Sohn",
keywords = "Volcanic ash",
keywords = "Reverse absorption",
keywords = "Hybrid algorithm",
keywords = "MODIS",
keywords = "Brightness temperature ",
abstract = "Abstract A noble volcanic ash (VA) detection method based on a hybrid reverse absorption technique was successfully applied in the analysis of major volcanic eruptions that occurred in Russia, Iceland, Chile, Italy, and Japan by using the MODerate-resolution Imaging Spectroradiometer (MODIS) observation data. Sensitivity studies using radiative-transfer simulations by using various environmental parameters such as ash loadings, sizes, layer heights, and surface emissions, revealed that \{VA\} effects on brightness temperatures (BT) can reach up to 40 K. The advantage of the hybrid algorithm is its ability to detect distinct \{VA\} pixels during the day and night from satellite observations. The results showed that the hybrid algorithm can minimize the false detection of \{VA\} pixels, while well-known reverse absorption methods show abundant false \{VA\} pixels over bright surfaces and cloud formations. Further, the time-and-space distribution of the \{VA\} pixels is in good agreement with the data pertaining to operational aerosol products obtained from the scanning imaging absorption spectrometer for atmospheric cartography (SCIAMACHY) instrument on board ESA's Envisat and the cloud-aerosol Lidar and infrared pathfinder satellite observations (CALIPSO). This novel algorithm is expected to provide a fine spatial and temporal resolution of \{VA\} monitoring from high spectral or geostationary satellite observation data. "
}
@article{Arena201537,
title = "Modelling the insect Mushroom Bodies: Application to sequence learning ",
journal = "Neural Networks ",
volume = "67",
number = "",
pages = "37 - 53",
year = "2015",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2015.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0893608015000623",
author = "Paolo Arena and Marco Cali and Luca Patane and Agnese Portera and Roland Strauss",
keywords = "Neuroscience",
keywords = "Insect brain",
keywords = "Insect Mushroom Bodies",
keywords = "Spiking neurons",
keywords = "Learning",
keywords = "Neural model",
keywords = "Context ",
abstract = "Abstract Learning and reproducing temporal sequences is a fundamental ability used by living beings to adapt behaviour repertoire to environmental constraints. This paper is focused on the description of a model based on spiking neurons, able to learn and autonomously generate a sequence of events. The neural architecture is inspired by the insect Mushroom Bodies (MBs) that are a crucial centre for multimodal sensory integration and behaviour modulation. The sequence learning capability coexists, within the insect brain computational model, with all the other features already addressed like attention, expectation, learning classification and others. This is a clear example that a unique neural structure is able to cope concurrently with a plethora of behaviours. Simulation results and robotic experiments are reported and discussed. "
}
@article{Reid2013403,
title = "Observing and understanding the Southeast Asian aerosol system by remote sensing: An initial review and analysis for the Seven Southeast Asian Studies (7SEAS) program ",
journal = "Atmospheric Research ",
volume = "122",
number = "",
pages = "403 - 468",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512001809",
author = "Jeffrey S. Reid and Edward J. Hyer and Randall S. Johnson and Brent N. Holben and Robert J. Yokelson and Jianglong Zhang and James R. Campbell and Sundar A. Christopher and Larry Di Girolamo and Louis Giglio and Robert E. Holz and Courtney Kearney and Jukka Miettinen and Elizabeth A. Reid and F. Joseph Turk and Jun Wang and Peng Xian and Guangyu Zhao and Rajasekhar Balasubramanian and Boon Ning Chew and Serm Janjai and Nofel Lagrosas and Puji Lestari and Neng-Huei Lin and Mastura Mahmud and Anh X. Nguyen and Bethany Norris and Nguyen T.K. Oanh and Min Oo and Santo V. Salinas and E. Judd Welton and Soo Chin Liew",
keywords = "Southeast Asia",
keywords = "Maritime Continent",
keywords = "Meteorology",
keywords = "Aerosol",
keywords = "Remote Sensing",
keywords = "Biomass Burning",
keywords = "Air Pollution ",
abstract = "Southeast Asia (SEA) hosts one of the most complex aerosol systems in the world, with convoluted meteorological scales, sharp geographic and socioeconomic features, high biological productivity, mixtures of a wide range of atmospheric pollutants, and likely a significant susceptibility to global climate change. This physical complexity of \{SEA\} is coupled with one of the world's most challenging environments for both in situ and remote sensing observation. The 7-Southeast Asian Studies (7SEAS) program was formed to facilitate interdisciplinary research into the integrated \{SEA\} aerosol environment via grass roots style collaboration. In support of the early 7SEAS program and the affiliated Southeast Asia Composition, Cloud, Climate Coupling Regional Study (SEAC4RS), this review was created to outline the network of connections linking aerosol particles in \{SEA\} with meteorology, climate and the total earth system. In this review, we focus on and repeatedly link back to our primary data source: satellite aerosol remote sensing and associated observability issues. We begin with a brief rationale for the program, outlining key aerosol impacts and, comparing their magnitudes to the relative uncertainty of observations. We then discuss aspects of SEA's physical, socio-economic and biological geography relevant to meteorology and observability issues associated with clouds and precipitation. We show that not only does \{SEA\} pose significant observability challenges for aerosol particles, but for clouds and precipitation as well. With the fundamentals of the environment outlined, we explore SEA's most studied aerosol issue: biomass burning. We summarize research on bulk aerosol properties for SEA, including a short synopsis of recent \{AERONET\} observations. We describe long range transport patterns. Finally, considerable attention is paid to satellite aerosol observability issues, with a face value comparison of common aerosol products in the region including passive and active aerosol products as well as fluxes. We show that satellite data products diverge greatly due to a host of known artifacts. These artifacts have important implications for how research is conducted, and care must be taken when using satellite products to study aerosol problems. The paper ends with a discussion of how the community can approach this complex and important environment. "
}
@incollection{Combs201557,
title = "Chapter 7 - Disruptive Technologies Affecting Education and Their Implications for Curricular Redesign ",
editor = "Wartman, Steven A. ",
booktitle = "The Transformation of Academic Health Centers ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2015",
pages = "57 - 68",
isbn = "978-0-12-800762-4",
doi = "https://doi.org/10.1016/B978-0-12-800762-4.00007-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128007624000074",
author = "C. Donald Combs and Bertalan Mesko",
keywords = "Competency based education",
keywords = "Digital technologies",
keywords = "Disruptive innovation",
keywords = "Medical and health professions education",
keywords = "Personalization",
keywords = "Social media",
keywords = "Social networks ",
abstract = "Abstract This chapter discusses the impact of disruptive technologies on education, health care, and health professions education. There are six major categories of digital advances that have begun to disrupt the model of current health care—the cell phone, personal computers, the internet, smart digital devices, gene sequencing, and social networks. There is, within these categories, an amazing array of technologies that need to be incorporated into medical and health professions education programs. The characteristics of curricula that are successful in the future will, we believe, be based on business models that embrace the participatory, democratic culture emerging from ubiquitous digital devices and social networks; that take advantage of big data and cloud computing to increase the customization and personalization of educational programs; and that achieve balance between the constant connectivity afforded by digital devices and the need for offline reflection. "
}
@article{Vinayak|Ramani2016143,
title = "Extracting hand grasp and motion for intent expression in mid-air shape deformation: A concrete and iterative exploration through a virtual pottery application ",
journal = "Computers & Graphics ",
volume = "55",
number = "",
pages = "143 - 156",
year = "2016",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2015.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S009784931500179X",
author = "Vinayak and Karthik Ramani",
keywords = "Mid-air gestures",
keywords = "Depth sensor",
keywords = "Virtual pottery",
keywords = "Shape deformation",
keywords = "Hand grasp ",
abstract = "Abstract We describe the iterative design and evaluation of a geometric interaction technique for bare-hand mid-air virtual pottery. We model the shaping of a pot as a gradual and progressive convergence of the pot-profile to the shape of the user׳s hand represented as a point-cloud (PCL). Our pottery-inspired application served as a platform for systematically revealing how users use their hands to express the intent of deformation during a pot shaping process. Our approach involved three stages: (a) clutching by proximal-attraction, (b) shaping by proximal-attraction, and (c) shaping by grasp+motion. The design and implementation of each stage was informed by user evaluations of the previous stage. Our work evidently demonstrates that it is possible to enable users to express their intent for shape deformation without the need for a fixed set of gestures for clutching and deforming a shape. We found that the expressive capability of hand articulation can be effectively harnessed for controllable shaping by organizing the deformation process in broad classes of intended operations such as pulling, pushing, and fairing. After minimal practice with the pottery application, users could figure out their own strategy for reaching, grasping, and deforming the pot. Users particularly enjoyed using day-to-day physical objects as tools for shaping pots. "
}
@article{Yan201631,
title = "A new method of satellite-based haze aerosol monitoring over the North China Plain and a comparison with \{MODIS\} Collection 6 aerosol products ",
journal = "Atmospheric Research ",
volume = "171",
number = "",
pages = "31 - 40",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515003932",
author = "Xing Yan and Wenzhong Shi and Nana Luo and Wenji Zhao",
keywords = "Haze",
keywords = "Aerosol optical thickness",
keywords = "Retrieval algorithm",
keywords = "Modis ",
abstract = "Abstract With worldwide urbanization, hazy weather has been increasingly frequent, especially in the North China Plain. However, haze aerosol monitoring remains a challenge. In this paper, \{MODerate\} resolution Imaging Spectroradiometer (MODIS) measurements were used to develop an enhanced haze aerosol retrieval algorithm (EHARA). This method can work not only on hazy days but also on normal weather days. Based on 12-year (2002–2014) Aerosol Robotic Network (AERONET) aerosol property data, empirical single scattering albedo (SSA) and asymmetry factor (AF) values were chosen to assist haze aerosol retrieval. For validation, \{EHARA\} aerosol optical thickness (AOT) values, along with \{MODIS\} Collection 6 (C6) dark-pixel and deep blue aerosol products, were compared with \{AERONET\} data. The results show that the \{EHARA\} can achieve greater \{AOT\} spatial coverage under hazy conditions with a high accuracy (73% within error range) and work a higher resolution (1-km). Additionally, this paper presents a comprehensive discussion of the differences between and limitations of the \{EHARA\} and the \{MODIS\} \{C6\} \{DT\} land algorithms. "
}
@article{ElHajj2016202,
title = "Soil moisture retrieval over irrigated grassland using X-band \{SAR\} data ",
journal = "Remote Sensing of Environment ",
volume = "176",
number = "",
pages = "202 - 218",
year = "2016",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.01.027",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716300281",
author = "Mohammad El Hajj and Nicolas Baghdadi and Mehrez Zribi and Gilles Belaud and Bruno Cheviron and Dominique Courault and Francois Charron",
keywords = "grassland",
keywords = "TerraSAR-X",
keywords = "COSMO-SkyMED",
keywords = "neural networks",
keywords = "inversion",
keywords = "soil moisture",
keywords = "vegetation indices ",
abstract = "Abstract The aim of this study was to develop an inversion approach to estimate surface soil moisture from X-band \{SAR\} data over irrigated grassland areas. This approach simulates a coupling scenario between Synthetic Aperture Radar (SAR) and optical images through the Water Cloud Model (WCM). A time series of \{SAR\} (TerraSAR-X and COSMO-SkyMed) and optical (SPOT 4/5 and \{LANDSAT\} 7/8) images were acquired over an irrigated grassland region in southeastern France. An inversion technique based on multi-layer perceptron neural networks (NNs) was used to invert the Water Cloud Model (WCM) for soil moisture estimation. Three inversion configurations based on \{SAR\} and optical images were defined: (1) \{HH\} polarization, (2) \{HV\} polarization, and (3) both \{HH\} and \{HV\} polarizations, all with one vegetation descriptor derived from optical data. The investigated vegetation descriptors were the Normalized Difference Vegetation Index “NDVI”, Leaf Area Index “LAI”, Fraction of Absorbed Photosynthetically Active Radiation “FAPAR”, and the Fractional vegetation \{COVER\} “FCOVER”. These vegetation descriptors were derived from optical images. For the three inversion configurations, the \{NNs\} were trained and validated using a noisy synthetic dataset generated by the \{WCM\} for a wide range of soil moisture and vegetation descriptor values. The trained \{NNs\} were then validated from a real dataset composed of X-band \{SAR\} backscattering coefficients and vegetation descriptor derived from optical images. The use of X-band \{SAR\} measurements in \{HH\} polarization (in addition to one vegetation descriptor derived from optical images) yields more precise results on soil moisture (Mv) estimates. In the case of \{NDVI\} derived from optical images as the vegetation descriptor, the Root Mean Square Error on Mv estimates was 3.6 Vol.% for \{NDVI\} values between 0.45 and 0.75, and 6.1 Vol.% for \{NDVI\} between 0.75 and 0.90. Similar results were obtained regardless of the other vegetation descriptor used. "
}
@article{Karimi2017223,
title = "Semi-supervised classification in stratified spaces by considering non-interior points using Laplacian behavior ",
journal = "Neurocomputing ",
volume = "239",
number = "",
pages = "223 - 231",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217302898",
author = "Zohre Karimi and Saeed Shiry Ghidary",
keywords = "Manifold",
keywords = "Semi-supervised",
keywords = "Laplacian",
keywords = "Stratified space ",
abstract = "Abstract Manifold-based semi-supervised classifiers have attracted increasing interest in recent years. However, they suffer from over learning of locality and cannot be applied to the point cloud sampled from a stratified space. This problem is resolved in this paper by using the fact that the smoothness assumption must be satisfied with the interior points of the manifolds and may be violated in the non-interior points. Distinction of interior and non-interior points is based on the behavior of graph Laplacian in the ϵ -neighborhood of the intersection points. First, this property was generalized to \{KNN\} graph representing the stratified space and then a new algorithm was proposed that penalizes the smoothness on the non-interior points of the manifolds by modifying the edge weights of the graph. Compared to some recent multi-manifold semi-supervised classifiers, the proposed method does not require neither knowing the dimensions of the manifolds nor large amount of unlabeled points to estimate the underling manifolds and does not assume similar properties for neighbors of all data points. Some experiments have been conducted in order to show that it improves the classification accuracy on a number of artificial and real benchmark data sets. "
}
@article{Breitkreuz20071377,
title = "A case study to prepare for the utilization of aerosol forecasts in solar energy industries ",
journal = "Solar Energy ",
volume = "81",
number = "11",
pages = "1377 - 1385",
year = "2007",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2007.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X07000278",
author = "H. Breitkreuz and M. Schroedter-Homscheidt and T. Holzer-Popp",
keywords = "Irradiance forecast",
keywords = "Aerosols",
keywords = "Direct and diffuse irradiance",
keywords = "Air quality modelling ",
abstract = "Precise aerosol information is indispensable in providing accurate clear sky irradiance forecasts, which is a very important aspect in solar facility management as well as in solar and conventional power load prediction. In order to demonstrate the need of detailed aerosol information, direct irradiance derived from Aerosol Robotic Network (AERONET) ground based measurements of aerosol optical depth (AOD) was compared in a case study over Europe to irradiance calculated using a standard aerosol scenario. The analysis shows an underestimation of measurement-derived direct irradiance by the scenario-derived direct irradiance for locations in Northern Europe and an overestimation for the Mediterranean region. Forecasted \{AOD\} of the European Dispersion and Deposition Model (EURAD) system was validated against ground based \{AERONET\} clear sky \{AOD\} measurements for the same test period of February 15th to 22nd, 2004. For the time period analyzed, the modelled \{AOD\} forecasts of the \{EURAD\} system slightly underestimate ground based \{AERONET\} measurements. To quantify the effects of varying \{AOD\} forecast quality in their impact on the application in solar energy industry, measured and forecasted \{AOD\} were used to calculate and compare direct, diffuse, and global irradiance. All other influencing variables (mainly clouds and water vapour) are assumed to be modelled and measured correctly for this analysis which is dedicated to the specific error introduced by aerosol forecasting. The underestimated \{AOD\} results in a mean overestimation of direct irradiance of +28 W/m2 (+12%), whereas diffuse irradiance is generally underestimated (−19 W/m2 or −14%). Mean global irradiance values where direct and diffuse irradiance errors compensate each other are very well represented (on average +9 W/m2 or +2%). "
}
@article{Rambani201450,
title = "Computer assisted navigation in orthopaedics and trauma surgery ",
journal = "Orthopaedics and Trauma ",
volume = "28",
number = "1",
pages = "50 - 57",
year = "2014",
note = "",
issn = "1877-1327",
doi = "https://doi.org/10.1016/j.mporth.2014.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S1877132714000037",
author = "Rohit Rambani and Mathew Varghese",
keywords = "computer",
keywords = "navigation",
keywords = "orthopaedic applications ",
abstract = "Abstract Computer assisted navigation was initially introduced into neurosurgical practice, and then orthopaedic spinal surgery, in the 1990's. It has gained momentum in recent years, finding applications in multiple branches of orthopaedic surgery including hip and knee arthroplasty, sports injuries, trauma, spinal surgery and bone tumour surgery. The technology provides the surgeon with real-time information regarding the position of surgical instruments and implants in relation to the skeleton and has the potential to improve surgical accuracy and outcome. Computer assisted navigation systems can be active, employing robotic surgeons, or passive where the surgeon remains in total control but computer software aids in the procedure. Computer assisted navigation has the potential to help surgeons perform procedures more accurately, with a view to improving outcome. This article reviews the multiple applications, limitations, and advantages of computer assisted navigation in orthopaedics in the operating theatre and beyond. "
}
@article{Yang2016,
title = "Modern Software Cybernetics: Trends with New Cybernetics ",
journal = "Journal of Systems and Software ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.05.044",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216300656",
author = "Hongji Yang and Feng Chen and Suleiman Aliyu",
keywords = "Software Cybernetics",
keywords = "New Cybernetics",
keywords = "Control Engineering",
keywords = "Software Engineering",
keywords = "Computer Science",
keywords = "Artificial Intelligence ",
abstract = "Abstract Software cybernetics research is to apply a variety of techniques from cybernetics research to software engineering research. For more than fifteen years since 2001, there has been a dramatic increase in work on software cybernetics. From cybernetics viewpoint, the work is mainly on the first-order level, namely, the software under observation and control. Beyond the first-order cybernetics, the software, developers/users, and running environments influence each other and thus create feedback to form a more complicated system. We classify software cybernetics as classical software cybernetics based on the first-order cybernetics, and as modern software cybernetics based on the higher order cybernetics (new cybernetics). This paper provides a review of literature on software cybernetics, especially focuses on the transition from classical software cybernetics to modern software cybernetics. The results of the survey indicate that some new research areas such as Internet of Things, big data, cloud computing, cyber-physical systems, and even creative computing are related to modern software cybernetics. The paper identifies the relationships between the techniques of new cybernetics applied and the new research areas to which they have been applied; formulates research problems and challenges of software cybernetics with the application of principles of new cybernetics; identifies and highlights new research trends of modern software cybernetic for further research. "
}
@article{Swaid20153657,
title = "Bringing Computational Thinking to \{STEM\} Education ",
journal = "Procedia Manufacturing ",
volume = "3",
number = "",
pages = "3657 - 3662",
year = "2015",
note = "6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, \{AHFE\} 2015 ",
issn = "2351-9789",
doi = "https://doi.org/10.1016/j.promfg.2015.07.761",
url = "http://www.sciencedirect.com/science/article/pii/S2351978915007623",
author = "Samar I. Swaid",
keywords = "Computational thinking",
keywords = "STEM",
keywords = "Computational science",
keywords = "HBCU",
keywords = "Cyberinfrastructure ",
abstract = "Abstract Today, as advanced technologies and cloud computing tools emerge, it is imperative that such innovations are sustained with knowledge and skill set among \{STEM\} educators and practitioners. In this paper, the author reports on a project, HBCU-UP II, that works on bringing Computational Thinking to Science, Technology, Engineering, and Mathematics (STEM) disciplines. A Computational-Thinking based strategy is adopted to enforce thinking computationally in \{STEM\} gate-keeping courses. The paper presents framework, implementation and outcomes. This on-going project contributes to efforts to establish computational thinking as a universally applicable attitude that is meshed within \{STEM\} conversations, education, and curricula. This paper will be particularly useful for researchers interested in Computational Thinking and its applications in \{STEM\} education, in particular and higher education in general "
}
@article{SmithJr200463,
title = "Robotically assisted laparoscopic prostatectomy: An assessment of its contemporary role in the surgical management of localized prostate cancer ",
journal = "The American Journal of Surgery ",
volume = "188",
number = "4, Supplement 1",
pages = "63 - 67",
year = "2004",
note = "",
issn = "0002-9610",
doi = "https://doi.org/10.1016/j.amjsurg.2004.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S000296100400323X",
author = "Joseph A. Smith Jr.",
abstract = "Radical prostatectomy has maintained a cardinal role in the treatment of localized carcinoma of the prostate. The combination of refinements in surgical technique and better definition of the anatomy have decreased the morbidity from surgery. Nonetheless, concerns about treatment-related side effects remain the primary limitation of surgical therapy for prostate cancer. Laparoscopic prostatectomy, with or without robotic assistance, is playing an increasing role in surgical treatment of prostate cancer. However, the minimally invasive aspect of laparoscopy may have less relevance for radical prostatectomy because the open surgical procedure requires a limited infraumbilical incision. In the present series comparing robotically assisted laparoscopic prostatectomy with open radical retropubic prostatectomy, no difference was seen in postoperative pain, length of stay, or requirement for blood replacement. However, the most important outcome measures are tumor control, continence, and sexual potency. The outstanding visibility and precision afforded by the robotic approach may offer advantages in each of these areas. "
}
@incollection{tagkey2007xix,
title = "List of Acronyms ",
editor = "Renato Baudo, Gianni Tartari and Elisa Vuillermoz",
booktitle = "Mountains Witnesses of Global Changes Research in the Himalaya and Karakoram: Share-Asia Project",
publisher = "Elsevier",
year = "2007",
volume = "10",
pages = "xix - xxvii",
series = "Developments in Earth Surface Processes ",
issn = "0928-2025",
doi = "https://doi.org/10.1016/S0928-2025(06)10040-1",
url = "http://www.sciencedirect.com/science/article/pii/S0928202506100401",
key = "tagkey2007xix",
abstract = "Publisher Summary This chapter lists the acronyms that are found in the volume Mountains, Witnesses of Global Changes, Volume 20, which is a part of the book series Developments in Earth Surface Processes. These acronyms include \{AAR\} (Accumulation area ratio), \{ABC\} (Atmospheric Brown Clouds Project), \{DTM\} (Digital terrain models), and others. "
}
@article{Wen201468,
title = "Hand gesture guided robot-assisted surgery based on a direct augmented reality interface ",
journal = "Computer Methods and Programs in Biomedicine ",
volume = "116",
number = "2",
pages = "68 - 80",
year = "2014",
note = "New methods of human-robot interaction in medical practice ",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2013.12.018",
url = "http://www.sciencedirect.com/science/article/pii/S0169260713004082",
author = "Rong Wen and Wei-Liang Tay and Binh P. Nguyen and Chin-Boon Chng and Chee-Kong Chui",
keywords = "Human–robot cooperation",
keywords = "Augmented reality",
keywords = "Augmented interaction",
keywords = "Visual guidance",
keywords = "Image-guided surgery",
keywords = "Projector-camera system ",
abstract = "Abstract Radiofrequency (RF) ablation is a good alternative to hepatic resection for treatment of liver tumors. However, accurate needle insertion requires precise hand-eye coordination and is also affected by the difficulty of \{RF\} needle navigation. This paper proposes a cooperative surgical robot system, guided by hand gestures and supported by an augmented reality (AR)-based surgical field, for robot-assisted percutaneous treatment. It establishes a robot-assisted natural \{AR\} guidance mechanism that incorporates the advantages of the following three aspects: \{AR\} visual guidance information, surgeon's experiences and accuracy of robotic surgery. A projector-based \{AR\} environment is directly overlaid on a patient to display preoperative and intraoperative information, while a mobile surgical robot system implements specified \{RF\} needle insertion plans. Natural hand gestures are used as an intuitive and robust method to interact with both the \{AR\} system and surgical robot. The proposed system was evaluated on a mannequin model. Experimental results demonstrated that hand gesture guidance was able to effectively guide the surgical robot, and the robot-assisted implementation was found to improve the accuracy of needle insertion. This human–robot cooperative mechanism is a promising approach for precise transcutaneous ablation therapy. "
}
@article{Xiao2015104,
title = "Retrieval of dust storm aerosols using an integrated Neural Network model ",
journal = "Computers & Geosciences ",
volume = "85, Part B",
number = "",
pages = "104 - 114",
year = "2015",
note = "Statistical learning in geoscience modelling: Novel algorithms and challenging case studies ",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2015.02.016",
url = "http://www.sciencedirect.com/science/article/pii/S0098300415000485",
author = "Fei Xiao and Man Sing Wong and Kwon Ho Lee and James R. Campbell and Yu-kai Shea",
keywords = "Dust storms",
keywords = "Integrated modeling",
keywords = "Neural Network",
keywords = "Reverse absorption",
keywords = "Satellite imagery",
keywords = "Trajectory model ",
abstract = "Abstract Dust storms are known to have adverse effects on public health. Atmospheric dust loading is also one of the major uncertainties in global climatic modeling as it is known to have a significant impact on the radiation budget and atmospheric stability. This study develops an integrated model for dust storm detection and retrieval based on the combination of geostationary satellite images and forward trajectory model. The proposed model consists of three components: (i) a Neural Network (NN) model for near real-time detection of dust storms; (ii) a \{NN\} model for dust Aerosol Optical Thickness (AOT) retrieval; and (iii) the Hybrid Single Particle Lagrangian Integrated Trajectory (HYSPLIT) model to analyze the transports of dust storms. These three components are combined using an event-driven active geo-processing workflow technique. The \{NN\} models were trained for the dust detection and validated using sunphotometer measurements from the \{AErosol\} \{RObotic\} \{NETwork\} (AERONET). The \{HYSPLIT\} model was applied in the regions with high probabilities of dust locations, and simulated the transport pathways of dust storms. This newly automated hybrid method can be used to give advance near real-time warning of dust storms, for both environmental authorities and public. The proposed methodology can be applied on early warning of adverse air quality conditions, and prediction of low visibility associated with dust storm events for port and airport authorities. "
}
@article{Yan201787,
title = "An improved algorithm for retrieving the fine-mode fraction of aerosol optical thickness, part 1: Algorithm development ",
journal = "Remote Sensing of Environment ",
volume = "192",
number = "",
pages = "87 - 97",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0034425717300561",
author = "Xing Yan and Zhanqing Li and Wenzhong Shi and Nana Luo and Taixia Wu and Wenji Zhao",
keywords = "Aerosol fine-mode fraction",
keywords = "MODIS",
keywords = "AOT",
keywords = "PM2.5 ",
abstract = "Abstract The fine-mode fraction (FMF) can be a useful tool to separate natural aerosols from man-made aerosols and to assist in estimating surface concentrations of particulate matter with a diameter &lt; 2.5 μm. A LookUp Table-based Spectral Deconvolution Algorithm (LUT-SDA) was developed here for satellite-based applications using data such as \{MODerate\} resolution Imaging Spectroradiometer (MODIS) measurements. This method was validated against ground-based \{FMF\} retrievals from the Aerosol Robotic Network (AERONET). The LUT-SDA was then applied to two MODIS-retrieved aerosol optical thickness (AOT) products for the period of December 2013 to July 2015: the \{MODIS\} Collection 6 (C6) Dark Target (DT) \{AOT\} product and the simplified high-resolution \{MODIS\} Aerosol Retrieval Algorithm (SARA) \{AOT\} product. In comparison with the \{MODIS\} \{C6\} \{FMF\} product in three study areas (Beijing, Hong Kong, and Osaka), \{FMFs\} estimated by the LUT-SDA agreed more closely with those retrieved from the \{AERONET\} with a very low bias. Eighty percent of the \{FMF\} values fell within the expected error range of ± 0.4. The root mean square error (RMSE) was 0.168 with few anomalous values, whereas the \{RMSE\} for the \{MODIS\} \{FMF\} was 0.340 with more anomalous values. The LUT-SDA \{FMF\} estimated using \{SARA\} \{AOT\} data conveys more detailed information on urban pollution than that from \{MODIS\} \{C6\} \{DT\} \{AOT\} data. As a demonstration, the seasonally-averaged spatial distribution of the \{FMF\} in Beijing was obtained from the LUT-SDA applied to \{SARA\} \{AOT\} data and compared with that of the AERONET-retrieved FMF. Their seasonal trends agreed well. "
}
@article{Asvadi2016299,
title = "3D Lidar-based static and moving obstacle detection in driving environments: An approach based on voxels and multi-region ground planes ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "299 - 311",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300483",
author = "Alireza Asvadi and Cristiano Premebida and Paulo Peixoto and Urbano Nunes",
keywords = "\{LIDAR\} perception",
keywords = "Scene understanding",
keywords = "3D representation",
keywords = "Obstacle detection ",
abstract = "Abstract Artificial perception, in the context of autonomous driving, is the process by which an intelligent system translates sensory data into an effective model of the environment surrounding a vehicle. In this paper, and considering data from a 3D-LIDAR mounted onboard an intelligent vehicle, a 3D perception system based on voxels and planes is proposed for ground modeling and obstacle detection in urban environments. The system, which incorporates time-dependent data, is composed of two main modules: (i) an effective ground surface estimation using a piecewise plane fitting algorithm and RANSAC-method, and (ii) a voxel-grid model for static and moving obstacles detection using discriminative analysis and ego-motion information. This perception system has direct application in safety systems for intelligent vehicles, particularly in collision avoidance and vulnerable road users detection, namely pedestrians and cyclists. Experiments, using point-cloud data from a Velodyne \{LIDAR\} and localization data from an Inertial Navigation System were conducted for both a quantitative and a qualitative assessment of the static/moving obstacle detection module and for the surface estimation approach. Reported results, from experiments using the \{KITTI\} database, demonstrate the applicability and efficiency of the proposed approach in urban scenarios. "
}
@article{Fahlgren201593,
title = "Lights, camera, action: high-throughput plant phenotyping is ready for a close-up ",
journal = "Current Opinion in Plant Biology ",
volume = "24",
number = "",
pages = "93 - 99",
year = "2015",
note = "",
issn = "1369-5266",
doi = "https://doi.org/10.1016/j.pbi.2015.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S1369526615000266",
author = "Noah Fahlgren and Malia A Gehan and Ivan Baxter",
abstract = "Anticipated population growth, shifting demographics, and environmental variability over the next century are expected to threaten global food security. In the face of these challenges, crop yield for food and fuel must be maintained and improved using fewer input resources. In recent years, genetic tools for profiling crop germplasm has benefited from rapid advances in \{DNA\} sequencing, and now similar advances are needed to improve the throughput of plant phenotyping. We highlight recent developments in high-throughput plant phenotyping using robotic-assisted imaging platforms and computer vision-assisted analysis tools. "
}
@article{Barfoot2011101,
title = "Pose estimation using linearized rotations and quaternion algebra ",
journal = "Acta Astronautica ",
volume = "68",
number = "1–2",
pages = "101 - 112",
year = "2011",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2010.06.049",
url = "http://www.sciencedirect.com/science/article/pii/S0094576510002407",
author = "Timothy Barfoot and James R. Forbes and Paul T. Furgale",
keywords = "Pose estimation",
keywords = "Linearized rotations",
keywords = "Quaternion algebra ",
abstract = "In this paper we revisit the topic of how to formulate error terms for estimation problems that involve rotational state variables. We present a first-principles linearization approach that yields multiplicative error terms for unit-length quaternion representations of rotations, as well as for canonical rotation matrices. Quaternion algebra is employed throughout our derivations. We show the utility of our approach through two examples: (i) linearizing a sun sensor measurement error term, and (ii) weighted-least-squares point-cloud alignment. "
}
@article{AntonanzasTorres2016122,
title = "Impact of atmospheric components on solar clear-sky models at different elevation: Case study Canary Islands ",
journal = "Energy Conversion and Management ",
volume = "109",
number = "",
pages = "122 - 129",
year = "2016",
note = "",
issn = "0196-8904",
doi = "https://doi.org/10.1016/j.enconman.2015.11.067",
url = "http://www.sciencedirect.com/science/article/pii/S0196890415010870",
author = "F. Antonanzas-Torres and J. Antonanzas and R. Urraca and M. Alia-Martinez and F.J. Martinez-de-Pison",
keywords = "REST2",
keywords = "ESRA",
keywords = "SOLIS",
keywords = "Clear-sky solar irradiance",
keywords = "High altitude ",
abstract = "Abstract The estimation of clear-sky solar irradiance via clear-sky models depends on reliable values of aerosol optical depth, water vapor and ozone content. These atmospheric variables are rarely on-site measured and are generally provided as gridded estimates in very low spatial resolution (1°). The high spatial variability of atmospheric variables within the grid resolution (pixel) leads to important errors in those areas with great atmospheric variability, such as in mountainous regions. In this paper, the performance of three clear-sky solar irradiance models was evaluated in a site with especially great elevation range, the Izana station from the Baseline Surface Radiation Network (Tenerife, Canary Islands) located at a high elevation (2373 m) and just 14 km from the ocean. Aerosols data were obtained from measurements from the Aerosol Robotic Network (AERONET) at the same site. The evaluation was also compared with global horizontal irradiance estimations with clear-sky models in the Guimar station, located at a lower elevation (156 m) and only 11.5 km away from Izana. Results showed a strong influence of elevation on solar radiation estimation under clear-sky conditions. "
}
@article{Rosen1989281,
title = "The characterization and modelling of the diffuse radiance distribution under partly cloudy skies ",
journal = "Solar Energy ",
volume = "43",
number = "5",
pages = "281 - 290",
year = "1989",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/0038-092X(89)90115-1",
url = "http://www.sciencedirect.com/science/article/pii/0038092X89901151",
author = "M.A. Rosen and F.C. Hooper and A.P. Brunger",
abstract = "Results are presented of a detailed analysis of a large set of sky radiance measurements taken in 1982 by an automated robot system built and operated at the University of Toronto, which takes narrow field-of-view sky radiance measurements with a precision and frequency adequate for most analysis and modelling purposes. The analysis of these data has confirmed the supposition that clouds strongly affect the distribution of the diffuse radiance, and has shown that the spatial distribution of the radiance for skies categorized according to cloud type and amount is statistically influenced in an orderly manner by the presence of the clouds. It was observed that the distribution across the sky of the time mean values of the diffuse radiance exhibits circumsolar and horizon brightening, the degree of which depends primarily on cloud type and amount, and on solar zenith angle. Trends were identified in the changes in the sky radiance distributions corresponding to variations in solar zenith angle, cloud amount and cloud group. The measured data appeared to be generally compatible with a model of the form of the Three-Component Continuous Distribution (TCCD) model introduced by Hooper and Brunger, and it was concluded that successful descriptors of the sky radiance could be developed based on that model, or on similar formulations. "
}
@article{Isa2012480,
title = "Secure System Architecture for Wide Area Surveillance Using Security, Trust and Privacy (STP) Framework ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "480 - 485",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.201",
url = "http://www.sciencedirect.com/science/article/pii/S187770581202601X",
author = "Mohd Anuar Mat Isa and Habibah Hashim and Jamalul-lail Ab Manan and Ramlan Mahmod and Mohd Saufy Rohmad and Abdul Hafiz Hamzah and Meor Mohd Azreen Meor Hamzah and Lucyantie Mazalan and Hanunah Othman and Lukman Adnan",
keywords = "Trusted Computing",
keywords = "Surveillance",
keywords = "Heartbeat",
keywords = "Security",
keywords = "Trust",
keywords = "Privacy",
keywords = "STP",
keywords = "TPM",
keywords = "AMT",
keywords = "Attestation",
keywords = "Secure System",
keywords = "Sensor",
keywords = "Beacon",
keywords = "Energy",
keywords = "Power ",
abstract = "Mobile computing emerged in the market for the past few years to provide solution for various platforms that range from smart phone, tablet, laptop, desktop computer, server to virtual computing systems such as cloud computing. The design approach and development of solutions for mobile computing continues to evolve in fulfilling the needs of diverse applications that run on various platforms. Recently, a new framework was introduced to provide a unified approach to resolve Security, Trust and Privacy (STP) enhancement on these platforms. This new framework emerged to enable a better way of dealing with security, trust and privacy conflicting aspects in pervasive environment such as mobile computing. This framework will be useful for system architects, engineers, designers and developers that are still struggling to create a secure, trustworthy, and privacy preserved environment to create confidence amongst users to do business transactions and collaborations especially in a more challenging environment such as cloud computing. In this paper, we discuss and propose new Secure System Architecture for strengthening surveillance activities in Wide Area using a combination of Trusted Computing (TC) via mutual attestation process to ensure integrity of components of the system, and Surveillance System. We further propose using Intel \{AMT\} chip that will generate a heartbeat pulse and transmit the signal through network interface to detect any possible physical intrusion. A failure to provide this pulse within a given time frame will trigger an action by the trusted security system for further analysis such as thievery detection. "
}
@article{Getuli2016542,
title = "A BIM-based Construction Supply Chain Framework for Monitoring Progress and Coordination of Site Activities ",
journal = "Procedia Engineering ",
volume = "164",
number = "",
pages = "542 - 549",
year = "2016",
note = "Selected papers from Creative Construction Conference 2016 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.11.656",
url = "http://www.sciencedirect.com/science/article/pii/S1877705816339972",
author = "Vito Getuli and Silvia Mastrolembo Ventura and Pietro Capone and Angelo L.C. Ciribini",
keywords = "building information modeling",
keywords = "field BIM",
keywords = "monitoring system",
keywords = "site management and control",
keywords = "supply chain management ",
abstract = "Abstract In spite of the growing implementation of Computer-aided technologies and Building Information Modeling (BIM) in \{AEC\} industry, building activities in construction sites are ineffectively monitored even now. Current formats of reporting and communicating the construction progress (e.g., textual progress reports, progress lines, and photographs) may not properly and quickly communicate the construction progress. In the proposed research the capability to communicate progress information right away and to share an Interactive Building Model (IBModel) are identified as the key components for successful management of the site and the supply chain network. This is carried out establishing the involved actors (Owner, Site Director, Site Safety Coordinator, Construction Companies and Suppliers) and setting them several options for the information management and visualization within the \{BIM\} environment. The monitoring system comes from the integration of the building and construction site model bestowing the visualization of site conditions on a set of graphical parametric rules, such as: chromatic visualization of building components referred to objects’ completion percentage; thematic views, automatically extracted and updated, representing the real site conditions; and so forth. The monitoring system, supported by the BIM-based visualization model and managed in a Cloud computing seems to be one of the right directions for improving safety condition on one hand and site productivity and control on the other one. "
}
@article{Holz20141282,
title = "Approximate triangulation and region growing for efficient segmentation and smoothing of range images ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "9",
pages = "1282 - 1293",
year = "2014",
note = "Intelligent Autonomous Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000578",
author = "Dirk Holz and Sven Behnke",
keywords = "Scene understanding",
keywords = "Range image segmentation",
keywords = "Approximate triangulation",
keywords = "Multilateral smoothing ",
abstract = "Abstract Decomposing sensory measurements into coherent parts is a fundamental prerequisite for scene understanding that is required for solving complex tasks, e.g., in the field of mobile manipulation. In this article, we describe methods for efficient segmentation of range images and organized point clouds. In order to achieve real-time performance in complex environments, we focus our approach on simple but robust solutions. We present a fast approach to surface reconstruction in range images and organized point clouds by means of approximate polygonal meshing. The obtained local surface information and neighborhoods are then used to (1) smooth the underlying measurements, and (2) segment the image into planar regions and other geometric primitives. A comparative evaluation using publicly available data sets shows that our approach achieves state-of-the-art performance while being significantly faster than other methods. "
}
@article{Cazorla20082739,
title = "Using a Sky Imager for aerosol characterization ",
journal = "Atmospheric Environment ",
volume = "42",
number = "11",
pages = "2739 - 2745",
year = "2008",
note = "Vienna Visibility Conference 2006 ",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2007.06.016",
url = "http://www.sciencedirect.com/science/article/pii/S1352231007005808",
author = "A. Cazorla and F.J. Olmo and L. Alados-Arboledas",
keywords = "Sky imagery",
keywords = "Sky radiance",
keywords = "Aerosol optical depth",
keywords = "Neural networks",
keywords = "Radial basis networks ",
abstract = "The All-Sky Imager developed by the Atmospheric Physics Group has been tested for aerosol characterization. Different neural network-based models calculate the aerosol optical depth (AOD) for two wavelengths and the angstrom turbidity parameter α using as input parameters data extracted from the principal plane of sky images from the All-Sky Imager. The models use data from a \{CIMEL\} \{CE318\} radiometer for training and validation. The deviations between model and reference values are in the range of uncertainties assigned to Aerosol Robotic Network (AERONET) network. "
}
@article{Haghighi201615,
title = "Method for automating digital fixture-setups that are optimal for machining castings to minimize scrap ",
journal = "Journal of Manufacturing Systems ",
volume = "40, Part 2",
number = "",
pages = "15 - 24",
year = "2016",
note = "SI:Challenges in Smart Manufacturing ",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2016.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0278612516300176",
author = "Payam Haghighi and Satchit Ramnath and Nathan Kalish and Jiten V. Shah and Jami J. Shah and Joseph K. Davidson",
keywords = "Automation",
keywords = "Fixture adjustments",
keywords = "Casting",
keywords = "Machining",
keywords = "Manufacturing ",
abstract = "Abstract The motivation for this paper is to describe a method for lowering the cost of finishing large castings that have machined surfaces for attaching other components. Considerable time is required to set-up each cast part on a machine-tool, sometimes taking longer than the machining itself, and errors in set-up can result in scrapping expensive parts or attempts to salvage them by rework. Although the focus of the paper is to demonstrate a new technology and software for set-up prior to the machining of iron/aluminum/steel sand castings, the same technology also is applicable to large welded assemblies on which finished machining occurs. In this paper, we outline a method, currently being implemented, that can predictively, and off-line, identify the adjustments needed to position and orient each part in its fixture before machining operations begin so that, after machining, all finished features will lie in their tolerance zones. Computer models first simulate all the to-be-machined (TBM) surfaces and any contact points with the fixture by feature-fitting point clouds taken from selective scanning of the raw casting. The locations of these features are compared with their locations on the \{CAD\} model of the part. Then, by using the T-Map model for tolerances, all possible locations of the part in its machining fixture are identified so that all \{TBM\} faces lie in their tolerance-zones. An optimum location may then be chosen. "
}
@article{Ulas201111602,
title = "A 3D Scan Matching Method Based On Multi-Layered Normal Distribution Transform ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11602 - 11607",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.02865",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016454790",
author = "Cihan Ulas and Hakan Temeltas",
abstract = "Abstract Scan matching plays a significant role for 3D simultaneously localization and mapping (SLAM). Before applying the \{SLAM\} methods, two 3D data which belong to highly correlated scene has to be registered by finding the correct transformation. In this paper, we introduce a multi-layered (ML) extension of 3D Normal Distribution Transform based scan matching. In this method, point cloud is subdivided into 8n equally sized cells, where n stands for the level of layer. Unlike the NDT, the score function is described as the Mahalanobis distance. In addition, Newton and Levenberg-Marquardt methods are used to optimize the score function. The proposed method is compared with original NDT, and the optimization methods are discussed. Finally, the performance evaluation is given for experimentally obtained datasets. The approximation provides much faster and long distance measurement capabilities than ordinary NDT. "
}
@article{Yin201465,
title = "Development and calibration of an integrated 3D scanning system for high-accuracy large-scale metrology ",
journal = "Measurement ",
volume = "54",
number = "",
pages = "65 - 76",
year = "2014",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2014.04.009",
url = "http://www.sciencedirect.com/science/article/pii/S0263224114001675",
author = "Shibin Yin and Yongjie Ren and Yin Guo and Jigui Zhu and Shourui Yang and Shenghua Ye",
keywords = "3D scanning",
keywords = "Large-scale metrology",
keywords = "Industrial robot",
keywords = "Enhanced hand–eye calibration ",
abstract = "Abstract Quality control in advanced manufacturing requires automated and high-accuracy large-scale 3D measurement. This paper proposes a high-accuracy, low-cost 3D scanning system by integrating industrial robot with precise linear rail and laser sensor. The measuring principle and system construction of the integrated system are introduced in detail. A mathematical model is established for mapping the change of the laser sensor frame while it scans along the linear rail and a sphere-based algorithm for rail orientation calibration is introduced. Subsequently, taking the robot positioning error into consideration, an enhanced hand–eye calibration method is proposed to determine the relationship between robot end-effector and rail scanning frame. Validation experiments were performed, a maximum distance error of 0.071 mm was detected within the rail range and a mean/maximum distance error of 0.309/0.604 mm was detected in the robot volume. A large-scale scanning instance also shows that integrated robotic scanning system features high-efficiency and high-accuracy. "
}
@article{Li20161,
title = "Large eddy simulation of unsteady shedding behavior in cavitating flows with time-average validation ",
journal = "Ocean Engineering ",
volume = "125",
number = "",
pages = "1 - 11",
year = "2016",
note = "",
issn = "0029-8018",
doi = "https://doi.org/10.1016/j.oceaneng.2016.07.065",
url = "http://www.sciencedirect.com/science/article/pii/S0029801816303109",
author = "Linmin Li and Baokuan Li and Zhiqiang Hu and Yang Lin and Sherman C.P. Cheung",
keywords = "Unsteady cavitating flows",
keywords = "Large eddy simulation",
keywords = "Time-average method",
keywords = "Periodic shedding ",
abstract = "Abstract Cavitation always leads to complex gas–liquid interactions and turbulence structures with multi-scale eddies and vortices. It usually involves cavity growth, break-off and collapse processes; posing great challenges in modeling. This paper focuses on modeling instantaneous cavitating flows using the large eddy simulation (LES) and validating the predictions against experimental data using the time-average method. The volume of fluid (VOF) model was adopted to describe phase equations and coupled with the Schnerr–Sauer cavitation model for describing the evaporation-condensation mass transfer. Simulations were performed to predict the unsteady cavitating flows of both the cylinder and Clark-Y hydrofoil configurations. Firstly, the mechanisms of cavity shedding, vapor cloud forming and collapsing were well revealed. The time-averaged pressure distribution and cavity length around the cylinder were in good agreement with experimental data. Moreover, the periodic cavity shedding and pressure fluctuation around the Clark-Y hydrofoil were also predicted. Different cavity patterns were clearly identified in a typical cycle, and the effect of cavity pattern on hydrodynamic forces was investigated. The computational results of cavity patterns, velocity profiles, drag and lift coefficients were compared with experimental results and good agreements were obtained. The present work provides a valid numerical modeling framework for various cavitating flows. "
}
@article{Luo201690,
title = "Vision-based extraction of spatial information in grape clusters for harvesting robots ",
journal = "Biosystems Engineering ",
volume = "151",
number = "",
pages = "90 - 104",
year = "2016",
note = "",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2016.08.026",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015303901",
author = "Lufeng Luo and Yunchao Tang and Xiangjun Zou and Min Ye and Wenxian Feng and Guoqing Li",
keywords = "Binocular stereo vision",
keywords = "Grape cluster",
keywords = "Bounding volume",
keywords = "Cutting point",
keywords = "Harvesting robots ",
abstract = "Grapes are likely to have collisions and be damaged by manipulations when harvesting grape clusters. To conduct an undamaged robotic harvesting, this paper focuses mainly on locating the spatial coordinates of the cutting points on a peduncle of grape clusters for the end-effector and determining the bounding volume of the grape clusters for the motion planner of the manipulator. A method for acquiring spatial information from grape clusters is presented based on binocular stereo vision. This method includes four steps: (1) calibrating the binocular cameras and rectifying the images, (2) detecting the cutting points on the peduncle and the centres of the grape berries, (3) extracting three-dimensional spatial coordinates of the points detected in step 2, and (4) calculating the bounding volume of the grape clusters. A total of 300 images were captured in the vineyard and were tested to validate the method for the cutting point detection, and the success rate was approximately 87%. The accuracy of the localisation of the cutting points was determined under outdoor conditions, and the accuracy in the Z and X directions was 12 mm and 9 mm, respectively. The acquired bounding volume of the grape cluster was compared with manual measurements, and errors in the height and maximum diameter were less than 17 mm and 19 mm, respectively. The elapsed time of the whole algorithm was less than 0.7 s. The demonstrated performance of this developed method indicated that it could be used on harvesting robots. "
}
@article{Erol201613,
title = "Tangible Industry 4.0: A Scenario-Based Approach to Learning for the Future of Production ",
journal = "Procedia \{CIRP\} ",
volume = "54",
number = "",
pages = "13 - 18",
year = "2016",
note = "6th \{CIRP\} Conference on Learning Factories ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.03.162",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116301500",
author = "Selim Erol and Andreas Jager and Philipp Hold and Karl Ott and Wilfried Sihn",
keywords = "Industry 4.0",
keywords = "smart manufacturing",
keywords = "learning factory",
keywords = "scenario-based learning ",
abstract = "Abstract Industry is currently undergoing a transformation towards full digitalization and intelligentization of manufacturing processes. Visionary but quite realistic concepts such as the Internet of Things, Industrial Internet, Cloud-based Manufacturing and Smart Manufacturing are drivers of the so called Fourth Industrial Revolution which is commonly referred to as Industry 4.0. Although a common agreement exists on the necessity for technological advancement of production technologies and business models in the sense of Industry 4.0, a major obstacle lies in the perceived complexity and abstractness which partly hinders its quick transformation into industrial practice. To overcome these burdens, we suggest a Scenario-based Industry 4.0 Learning Factory concept that we are currently planning to implement in Austria's first Industry 4.0 Pilot Factory. The concept is built upon a tentative competency model for Industry 4.0 and the use of scenarios for problem-oriented learning of future production engineering. "
}
@article{Schmidt2014711,
title = "Depth camera based collision avoidance via active robot control ",
journal = "Journal of Manufacturing Systems ",
volume = "33",
number = "4",
pages = "711 - 718",
year = "2014",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2014.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0278612514000417",
author = "Bernard Schmidt and Lihui Wang",
keywords = "Depth camera",
keywords = "Monitoring",
keywords = "Collision avoidance",
keywords = "Human–robot collaboration ",
abstract = "Abstract A new type of depth cameras can improve the effectiveness of safety monitoring in human–robot collaborative environment. Especially on today's manufacturing shop floors, safe human–robot collaboration is of paramount importance for enhanced work efficiency, flexibility, and overall productivity. Within this context, this paper presents a depth camera based approach for cost-effective real-time safety monitoring of a human–robot collaborative assembly cell. The approach is further demonstrated in adaptive robot control. Stationary and known objects are first removed from the scene for efficient detection of obstacles in a monitored area. The collision detection is processed between a virtual model driven by real sensors, and 3D point cloud data of obstacles to allow different safety scenarios. The results show that this approach can be applied to real-time work cell monitoring. "
}
@article{Schlenoff20131159,
title = "Ubiquitous robots (UBIROBOTS) workshop at the \{UBICOMP\} 2012 conference ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1159 - 1161",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.018",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000808",
abstract="",
author = "Craig Schlenoff and Abdelghani Chibani and Edson Prestes and Yacine Amirat"
}
@incollection{Gudivada20163,
title = "Chapter 1 - Cognitive Computing: Concepts, Architectures, Systems, and Applications ",
editor = "Venkat N. Gudivada, Vijay V. Raghavan, Venu Govindaraju and C.R. Rao",
booktitle = "Cognitive Computing: Theory and Applications",
publisher = "Elsevier",
year = "2016",
volume = "35",
pages = "3 - 38",
series = "Handbook of Statistics ",
issn = "0169-7161",
doi = "https://doi.org/10.1016/bs.host.2016.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169716116300451",
author = "V.N. Gudivada",
keywords = "Cognitive computing",
keywords = "Cognitive architectures",
keywords = "Cognitive models",
keywords = "Cognitive systems",
keywords = "Cognitive applications",
keywords = "Cognitive computing systems",
keywords = "Data science ",
abstract = "Abstract Cognitive computing is an emerging field ushered in by the synergistic confluence of cognitive science, data science, and an array of computing technologies. Cognitive science theories provide frameworks to describe various models of human cognition including how information is represented and processed by the brain. Data science provides processes and systems to extract knowledge from both structured and unstructured data. Cognitive computing employs the computing discipline's theories, methods, and tools to model human cognition. The recent advances in data science and computing disciplines—neuromorphic processors, big data, predictive modeling, machine learning, natural language understanding, and cloud computing—are accelerating advances in cognitive science and cognitive computing. The overarching goal of this chapter is to provide an interdisciplinary introduction to cognitive computing. The focus is on breadth to provide a unified view of the discipline. The chapter begins with an overview of cognitive science, data science, and cognitive computing. The principal technology enablers of cognitive computing are presented next. An overview of three major categories of cognitive architectures is presented, which is followed by a description of cognitive computing systems and their applications. Trends and future research directions in cognitive computing are discussed. The chapter concludes by listing various cognitive computing resources. "
}
@article{Shean2016101,
title = "An automated, open-source pipeline for mass production of digital elevation models (DEMs) from very-high-resolution commercial stereo satellite imagery ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "116",
number = "",
pages = "101 - 117",
year = "2016",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.03.012",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616300107",
author = "David E. Shean and Oleg Alexandrov and Zachary M. Moratto and Benjamin E. Smith and Ian R. Joughin and Claire Porter and Paul Morin",
keywords = "WorldView",
keywords = "Photogrammetry",
keywords = "Stereo reconstruction",
keywords = "Topography",
keywords = "Cryosphere",
keywords = "Ice sheet ",
abstract = "Abstract We adapted the automated, open source \{NASA\} Ames Stereo Pipeline (ASP) to generate digital elevation models (DEMs) and orthoimages from very-high-resolution (VHR) commercial imagery of the Earth. These modifications include support for rigorous and rational polynomial coefficient (RPC) sensor models, sensor geometry correction, bundle adjustment, point cloud co-registration, and significant improvements to the \{ASP\} code base. We outline a processing workflow for ∼0.5 m ground sample distance (GSD) DigitalGlobe WorldView-1 and WorldView-2 along-track stereo image data, with an overview of \{ASP\} capabilities, an evaluation of \{ASP\} correlator options, benchmark test results, and two case studies of \{DEM\} accuracy. Output \{DEM\} products are posted at ∼2 m with direct geolocation accuracy of &lt;5.0 m CE90/LE90. An automated iterative closest-point (ICP) co-registration tool reduces absolute vertical and horizontal error to &lt;0.5 m where appropriate ground-control data are available, with observed standard deviation of ∼0.1–0.5 m for overlapping, co-registered \{DEMs\} (n = 14, 17). While \{ASP\} can be used to process individual stereo pairs on a local workstation, the methods presented here were developed for large-scale batch processing in a high-performance computing environment. We are leveraging these resources to produce dense time series and regional mosaics for the Earth’s polar regions. "
}
@article{Nahangi2016147,
title = "Skeleton-based discrepancy feedback for automated realignment of industrial assemblies ",
journal = "Automation in Construction ",
volume = "61",
number = "",
pages = "147 - 161",
year = "2016",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515002198",
author = "Mohammad Nahangi and Carl T. Haas",
keywords = "Discrepancy",
keywords = "Realignment",
keywords = "As-built modeling",
keywords = "Skeletonization",
keywords = "Industrial assemblies",
keywords = "Pipe spools",
keywords = "3D imaging",
keywords = "Laser scanning ",
abstract = "Abstract Automated and timely detection, characterization, and quantification of fabrication discrepancies and errors are fundamental problems in construction engineering. Despite the fact that the precision of manufacturing machines is continually improving, there are inevitable discrepancies between the designed and built assemblies because of construction realities. Such non-compliant assemblies should be detected early, and the required corrective actions should be planned accordingly. This paper presents an algorithm for automated quantification of discrepancies for components of assemblies. Rather than using dense point clouds, the geometric skeleton (wireframe) of assemblies is extracted for further manipulation, once the as-built status is captured using the appropriate method. The extracted skeletons, which abstractly represent the designed and built states, are registered using a constrained iterative closest point (ICP) algorithm. In order to identify the points making up each straight segment, the skeletons are clustered, and a straight line is fit to each resulting cluster. The corresponding segments in both states are then compared and investigated for quantifying the incurred discrepancy in the form of a rigid transformation. Experimental results show that the accuracy and speed of the new framework are superior to a previously developed method (3D sliding cube). "
}
@article{Marton2013754,
title = "Ensembles of strong learners for multi-cue classification ",
journal = "Pattern Recognition Letters ",
volume = "34",
number = "7",
pages = "754 - 761",
year = "2013",
note = "Scene Understanding and Behaviour Analysis ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2012.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0167865512002334",
author = "Zoltan-Csaba Marton and Florian Seidel and Ferenc Balint-Benczedi and Michael Beetz",
keywords = "Strong learner",
keywords = "Ensemble",
keywords = "Multi-modal",
keywords = "Object recognition ",
abstract = "Real world heterogeneous scenes contain objects of a large variety of forms, surfaces, colors and textures, thus multi-modal approaches are needed to deal with their challenges. A promising method of combining various sources of information are ensemble methods which allow on the fly integration of classification modules, specific to a single sensor modality, into a classification process. These modular and extensible approaches have the advantage that they do not require that a single method copes with every eventuality, but combine existing specialized methods to overcome their weaknesses. In addition, the rapid growth of the perception field means that comparing, evaluating, sharing and combining the available approaches becomes increasingly relevant. In this article we describe a novel training strategy for ensembles of strong learners that not only outperform the best member but also the best classifier trained on the concatenation of features. The method was evaluated using a large \{RGBD\} dataset containing Kinect scans of 300 objects and special use-cases are presented that highlight how ensemble learning can be used to improve classification results. "
}
@article{Chu201667,
title = "Quantifying organic aerosol single scattering albedo over the tropical biomass burning regions ",
journal = "Atmospheric Environment ",
volume = "147",
number = "",
pages = "67 - 78",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.09.069",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016307889",
author = "Jung-Eun Chu and Kyung-Ja Ha",
keywords = "Aerosol light absorption",
keywords = "Brown carbon",
keywords = "Organic aerosol",
keywords = "Sulfate",
keywords = "Nitrate ",
abstract = "Abstract Despite growing evidence of light-absorbing organic aerosols (OAs), their contribution to the Earth's radiative budget is still poorly understood. In this study we derived a new empirical relationship that binds \{OA\} single scattering albedo (SSA), which is the ratio of light scattering to extinction, with sulfate + nitrate aerosol optical depth (AOD) and applied this method to estimate \{OA\} \{SSA\} over the tropical biomass burning regions. This method includes division of the attribution of black carbon (BC) and \{OA\} absorption aerosol optical depths from the Aerosol Robotic Network (AERONET) observation and determination of the fine-mode ratio of sea-salt and dust \{AODs\} from several atmospheric chemistry models. Our best estimate of \{OA\} \{SSA\} over the tropical biomass burning regions is 0.91 at 550 nm. Uncertainties associated with observations and models permit a value range of 0.82–0.93. Furthermore, by using the estimated \{OA\} \{SSA\} and comprehensive observations including AERONET, Moderate Resolution Imaging Spectroradiometer (MODIS) and Multi-angle Imaging Spectroradiometer (MISR), we examined the first global estimate of sulfate + nitrate \{AOD\} through a semi-observational approach. The global mean sulfate + nitrate \{AOD\} of 0.017 is in the lower range of the values obtained from 21 models participated in AeroCom phase II. The results imply that most aerosol models as well as climate models, which commonly use \{OA\} \{SSA\} of 0.96–1.0, have so far ignored light absorption by \{OAs\} and have overestimated light scattering by sulfate + nitrate aerosols. This indicates that the actual aerosol direct radiative forcing should be less negative than currently believed. "
}
@article{Rahmani2017,
title = "Exploiting smart e-Health gateways at the edge of healthcare Internet-of-Things: A fog computing approach ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302121",
author = "Amir M. Rahmani and Tuan Nguyen Gia and Behailu Negash and Arman Anzanpour and Iman Azimi and Mingzhe Jiang and Pasi Liljeberg",
keywords = "Internet of Things",
keywords = "Healthcare",
keywords = "Edge/Fog computing",
keywords = "Mobility",
keywords = "Smart hospital",
keywords = "Home care",
keywords = "Smart gateway",
keywords = "Sensor network ",
abstract = "Abstract Current developments in \{ICTs\} such as in Internet-of-Things (IoT) and Cyber–Physical Systems (CPS) allow us to develop healthcare solutions with more intelligent and prediction capabilities both for daily life (home/office) and in-hospitals. In most of IoT-based healthcare systems, especially at smart homes or hospitals, a bridging point (i.e., gateway) is needed between sensor infrastructure network and the Internet. The gateway at the edge of the network often just performs basic functions such as translating between the protocols used in the Internet and sensor networks. These gateways have beneficial knowledge and constructive control over both the sensor network and the data to be transmitted through the Internet. In this paper, we exploit the strategic position of such gateways at the edge of the network to offer several higher-level services such as local storage, real-time local data processing, embedded data mining, etc., presenting thus a Smart e-Health Gateway. We then propose to exploit the concept of Fog Computing in Healthcare IoT systems by forming a Geo-distributed intermediary layer of intelligence between sensor nodes and Cloud. By taking responsibility for handling some burdens of the sensor network and a remote healthcare center, our Fog-assisted system architecture can cope with many challenges in ubiquitous healthcare systems such as mobility, energy efficiency, scalability, and reliability issues. A successful implementation of Smart e-Health Gateways can enable massive deployment of ubiquitous health monitoring systems especially in clinical environments. We also present a prototype of a Smart e-Health Gateway called UT-GATE where some of the discussed higher-level features have been implemented. We also implement an IoT-based Early Warning Score (EWS) health monitoring to practically show the efficiency and relevance of our system on addressing a medical case study. Our proof-of-concept design demonstrates an IoT-based health monitoring system with enhanced overall system intelligence, energy efficiency, mobility, performance, interoperability, security, and reliability. "
}
@article{Esmaeilian201679,
title = "The evolution and future of manufacturing: A review ",
journal = "Journal of Manufacturing Systems ",
volume = "39",
number = "",
pages = "79 - 100",
year = "2016",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0278612516300024",
author = "Behzad Esmaeilian and Sara Behdad and Ben Wang",
keywords = "Advanced manufacturing",
keywords = "Data analytics in manufacturing",
keywords = "Sustainable manufacturing",
keywords = "Design for manufacturing",
keywords = "Remanufacturing ",
abstract = "Abstract Manufacturing is continuously evolving from concept development to methods and tools available for the production of goods for use or sale. Traditionally, manufacturing refers to an industrial production process through which raw materials are transformed into finished products to be sold in the market. However, these days manufacturing is considered to be an integrated concept at all levels from machines to production systems to an entire business level operation. Although there have been considerable developments in manufacturing technologies and processes, the actual scope and elements of manufacturing systems are complex and not adequately defined. This paper provides a review of both the tangible and intangible elements of manufacturing systems and presents a state-of-the-art survey of published work. It studies the evolution of research in manufacturing starting from past and current trends to future developments. How manufacturing systems have been classified is also presented. Through this extensive survey of the literature, future directions of this changing field are suggested. "
}
@article{Mizrahi201576,
title = "Detection of critical points of multivariate piecewise polynomial systems ",
journal = "Computer Aided Geometric Design ",
volume = "40",
number = "",
pages = "76 - 87",
year = "2015",
note = "",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2015.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0167839615001193",
author = "Jonathan Mizrahi and Gershon Elber",
keywords = "Critical points",
keywords = "Subdivision solvers",
keywords = "B-spline basis functions",
keywords = "Singular points ",
abstract = "Abstract We propose a general scheme for detecting critical locations (of dimension zero) of piecewise polynomial multivariate equation systems. Our approach generalizes previously known methods for locating tangency events or self-intersections, in contexts such as surface–surface intersection (SSI) problems and the problem of tracing implicit plane curves. Given the algebraic constraints of the original problem, we formulate additional constraints, seeking locations where the differential matrix of the original problem has a non-maximal rank. This makes the method independent of a specific geometric application, as well as of dimensionality. Within the framework of subdivision based solvers, test results are demonstrated for non-linear systems with three and four unknowns. "
}
@article{Harati2007475,
title = "\{FAST\} \{RANGE\} \{IMAGE\} \{SEGMENTATION\} \{FOR\} \{INDOOR\} 3D-SLAM ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "475 - 480",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00081",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016347061",
author = "Ahad Harati and Stefan Gachter and Roland Siegwart",
abstract = "Abstract Real-time 3D localization and mapping is eventually needed in many service robotic applications. Toward a light and practical \{SLAM\} algorithm, we focus on feature extraction via segmentation of range images. Using horizontal and vertical traces of the range matrix, 2D observed polygons are considered for calculation of a one-dimensional measure of direction, called Bearing Angle (BA). \{BA\} is the incident angle between the laser beam and edges of the observed polygon by the scanner in the selected direction. Based on this measure, two different approaches to range image segmentation, region- and edge-based, are proposed and evaluated through a set of standard analysis. It is experimentally shown that for navigation applications, edge based approaches are more efficient. Extensive tests on real robots prove BA-based segmentation is successful for SLAM. "
}
@article{Liu201480,
title = "Wildland fire emissions, carbon, and climate: Wildfire–climate interactions ",
journal = "Forest Ecology and Management ",
volume = "317",
number = "",
pages = "80 - 96",
year = "2014",
note = "Wildland fire emissions, carbon, and climate: Science overview and knowledge needs ",
issn = "0378-1127",
doi = "https://doi.org/10.1016/j.foreco.2013.02.020",
url = "http://www.sciencedirect.com/science/article/pii/S037811271300114X",
author = "Yongqiang Liu and Scott Goodrick and Warren Heilman",
keywords = "Wildfire",
keywords = "Emission",
keywords = "Radiative forcing",
keywords = "Feedback to climate",
keywords = "Future fire projection ",
abstract = "Increasing wildfire activity in recent decades, partially related to extended droughts, along with concern over potential impacts of future climate change on fire activity has resulted in increased attention on fire–climate interactions. Findings from studies published in recent years have remarkably increased our understanding of fire–climate interactions and improved our capacity to delineate probable future climate change and impacts. Fires are projected to increase in many regions of the globe under a changing climate due to the greenhouse effect. Burned areas in the western \{US\} could increase by more than 50% by the middle of this century. Increased fire activity is not simply an outcome of the changing climate, but also a participant in the change. Smoke particles reduce overall solar radiation absorbed by the Earth’s atmosphere during individual fire events and fire seasons, leading to regional climate effects including reduction in surface temperature, suppression of cloud and precipitation, and enhancement of climate anomalies such as droughts. Black carbon (BC) in smoke particles displays some different radiation and climate effects by warming the middle and lower atmosphere, leading to a more stable atmosphere. \{BC\} also plays a key role in the smoke-snow feedback mechanism. Fire emissions of CO2, on the other hand, are an important atmospheric \{CO2\} source and contribute substantially to the global greenhouse effect. Future studies should generate a global picture of all aspects of radiative forcing by smoke particles. Better knowledge is needed in space and time variability of smoke particles, evolution of smoke optical properties, estimation of smoke plume height and vertical profiles and their impacts on locations of warming layers, stability structure, clouds and smoke transport, quantification of \{BC\} emission factors and optical properties from different forest fuels, and BC’s individual and combined roles with organic carbon. Finally, understanding the short- and long-term greenhouse effect of fire \{CO2\} emissions, increased capacity to project future fire trends (especially mega-fires), with consideration of climate–fuel–human interactions, and improved fire weather and climate prediction skills (including exploring the SST-fire relations) remain central knowledge needs. "
}
@article{Mocanu2015100,
title = "Factored four way conditional restricted Boltzmann machines for activity recognition ",
journal = "Pattern Recognition Letters ",
volume = "66",
number = "",
pages = "100 - 108",
year = "2015",
note = "Pattern Recognition in Human Computer Interaction ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2015.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S0167865515000379",
author = "Decebal Constantin Mocanu and Haitham Bou Ammar and Dietwig Lowet and Kurt Driessens and Antonio Liotta and Gerhard Weiss and Karl Tuyls",
keywords = "Activity recognition",
keywords = "Deep learning",
keywords = "Restricted Boltzmann machines ",
abstract = "Abstract This paper introduces a new learning algorithm for human activity recognition capable of simultaneous regression and classification. Building upon conditional restricted Boltzmann machines (CRBMs), Factored four way conditional restricted Boltzmann machines (FFW-CRBMs) incorporate a new label layer and four-way interactions among the neurons from the different layers. The additional layer gives the classification nodes a similar strong multiplicative effect compared to the other layers, and avoids that the classification neurons are overwhelmed by the (much larger set of) other neurons. This makes FFW-CRBMs capable of performing activity recognition, prediction and self auto evaluation of classification within one unified framework. As a second contribution, sequential Markov chain contrastive divergence (SMcCD) is introduced. \{SMcCD\} modifies Contrastive Divergence to compensate for the extra complexity of FFW-CRBMs during training. Two sets of experiments one on benchmark datasets and one a robotic platform for smart companions show the effectiveness of FFW-CRBMs. "
}
@article{Bolton201541,
title = "From minefields to minespace: An archeology of the changing architecture of autonomous killing in \{US\} Army field manuals on landmines, booby traps and \{IEDs\} ",
journal = "Political Geography ",
volume = "46",
number = "",
pages = "41 - 53",
year = "2015",
note = "",
issn = "0962-6298",
doi = "https://doi.org/10.1016/j.polgeo.2014.11.002",
url = "http://www.sciencedirect.com/science/article/pii/S0962629814001218",
author = "Matthew Bolton",
keywords = "Landmines",
keywords = "IEDs",
keywords = "Drones",
keywords = "Killer robots",
keywords = "Architecture",
keywords = "War",
keywords = "Disarmament",
keywords = "Battlespace",
keywords = "Critical security studies ",
abstract = "Abstract Since WWI, militaries and armed groups have used remote and autonomous explosive traps – landmines, booby traps and improvised explosive devices (IEDs) – as a kind of deadly architecture to reengineer terrain inhospitable. Until recently, minefields remained analog, static, and fixed. But technological development and changes in the nature of war have made remote and autonomous violence increasingly mobile, dynamic, and robotic and, rather than being contained in a bounded Cartesian plane, diffused through the very spaces and flows that sustain civilian life. Such “unmanned” weapons are increasingly able to navigate, communicate with each other, identify targets and even kill with minimal human involvement. Mirroring broader changes in the spatial configurations of war, the architectural form of remote and autonomous killing is thus shifting from the two-dimensional minefield to multi-dimensional minespace. This poses challenges to those engaged in humanitarian efforts to demilitarize space. To illustrate these changes, the paper draws on Derek Gregory's notion of “Everywhere War” and engages in a discursive “archeology” of the minefield as described by \{US\} Army mine, booby trap and \{IED\} warfare field manuals. "
}
@article{SchulzeMakuch2002675,
title = "Search parameters for the remote detection of extraterrestrial life ",
journal = "Planetary and Space Science ",
volume = "50",
number = "7–8",
pages = "675 - 683",
year = "2002",
note = "Exobiology: the search for extraterrestrial life and prebiotic ch emistry ",
issn = "0032-0633",
doi = "https://doi.org/10.1016/S0032-0633(01)00121-0",
url = "http://www.sciencedirect.com/science/article/pii/S0032063301001210",
author = "Dirk Schulze-Makuch and Louis N. Irwin and Huade Guan",
abstract = "Direct consequences of biological activity (biosignatures) and alterations of the geological environment due to biological processes (geosignatures) are currently known only for the planet Earth. However, geoindicators remotely detectable by robotic technology have revealed a number of sites in the solar system where conditions compatible with the support of life may exist. By focusing on a search for energy gradients, complex chemistry, liquids that may act as solvents, atmospheres, and indicators of geological differentiation, robotic exploration of the solar system and beyond should lead to fruitful targets in the search for extraterrestrial life. An analysis of all major solar system bodies for these parameters suggests that Mars, Titan, and the Galilean satellites should be given the highest priority in the search for extraterrestrial life in our solar system. Extending them to other bodies in the solar system, however, draws attention to Io, Triton, Titania, Enceladus, and Iapetus, among others, as worthy of greater attention. "
}
@article{Sakr201644,
title = "Towards a Comprehensive Data Analytics Framework for Smart Healthcare Services ",
journal = "Big Data Research ",
volume = "4",
number = "",
pages = "44 - 58",
year = "2016",
note = "",
issn = "2214-5796",
doi = "https://doi.org/10.1016/j.bdr.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S221457961530023X",
author = "Sherif Sakr and Amal Elgammal",
abstract = "Abstract With the increasing volumes of information gathered via patient monitoring systems, physicians have been put on increasing pressure for making sophisticated analytical decisions that exploit the various types of data that is being gathered per patient. This phenomenon of continuously growing datasets is arising and gaining momentum in several application domains to what is now recognized in the business community as the Big Data challenge. In this article, we define and discuss some of the major challenges in the healthcare systems which can be effectively tackled by the recent advancement in \{ICT\} technologies. In particular, we focus on sensing technologies, cloud of computing, internet-of-things and big data analytics systems as emerging technologies which are made possible by the remarkable progress in various aspects including network communication speed, computational capabilities and data storage capacities that provide various advantages and characteristics that can contribute towards improving the efficiency and effectiveness of healthcare services. In addition, we describe the architectural components of our proposed framework, SmartHealth, for big data analytics services and describe its various applications in the healthcare domain. "
}
@article{Silva20142628,
title = "New Trends in Manufacturing: Converging to Service and Intelligent Systems ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "2628 - 2633",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02823",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016420069",
author = "Jose Reinaldo Silva",
keywords = "manufacturing design",
keywords = "service design",
keywords = "manufacturing service",
keywords = "AI planning ",
abstract = "Abstract Manufacturing processes and models have been influenced by the linear approach, called Fordism, for almost a century, since the first automated devices and discrete control systems were introduced. At the same time, new ideas to organize manufacturing process have appeared that question the absolute dominance of gain in scale. More recently, new criteria invaded the scenario of manufacturing where quality led manufacturing process to a phase based on accurate supply chain and surrounded by ubiquitous computer and robotic devices. A very precise manufacturing processes can now be designed and implemented in almost all sectors of industry, where special sub-processes can be delivered by other players. In this new scenario, a new paradigm for manufacturing design emerged, based on a set of very specialized services that could be arranged to provide new creative and sustainable processes. In this paper we go into this new paradigm for manufacturing (process) design comparing it with the classic approach that relies on layers classified as production plant, control (software oriented) and supervisory. "
}
@article{Jablkowski201717,
title = "Evolutionary planning of virtualized cyber-physical compute and control clusters ",
journal = "Journal of Systems Architecture ",
volume = "73",
number = "",
pages = "17 - 27",
year = "2017",
note = "Special Issue on Reliable Software Technologies for Dependable Distributed Systems ",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2016.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S138376211630193X",
author = "Boguslaw Jablkowski and Ulrich Thomas Gabor and Olaf Spinczyk",
keywords = "Cyber-physical systems",
keywords = "Virtual machines",
keywords = "Real-time guarantees",
keywords = "Evolutionary algorithms",
keywords = "Formal performance analysis ",
abstract = "Abstract Virtualization technology has the potential to notably advance the automation process in the domain of cyber-physical systems (CPS). It can improve both dependability and availability as well as significantly reduce the procurement, operation and maintenance costs of such systems. However, in the context of virtualization, research has put the most emphasis on topics of hardware utilization and fault-tolerance. There is little literature on how to model, integrate and consolidate a \{CPS\} by means of virtualization. In this paper we present a methodology for planning safe and efficient virtualized cyber-physical compute and control clusters – execution platforms for time-constrained virtual machines (VMs) that encapsulate \{CPS\} applications. We discuss the used methods, describe the corresponding models and the required system architecture. In contrast to typical resource allocation problems from other domains (e.g. cloud computing), in this case, the planning process must take real-time requirements of applications into account. In order to achieve this, we combine evolutionary algorithms with formal system performance analysis – in particular algorithms considered in classical scheduling theory. Such an approach allows not only to optimally dimension the compute and control clusters, but also provides strict guarantees regarding the timing predictability of the integrated CPS. Further, the embedment of a formal performance analysis technique notably eases the modeling of a system. As a consequence, the modeling process is fast, flexible and accessible not only to experts but also to system designers as they do not have to struggle with complex and time consuming mathematical formulations. Finally, our approach also provides answers to several practical questions that arise when integrating a \{CPS\} by means of virtualization. "
}
@article{FernandezPeruchena2015425,
title = "A comparison of one-minute probability density distributions of global horizontal solar irradiance conditioned to the optical air mass and hourly averages in different climate zones ",
journal = "Solar Energy ",
volume = "112",
number = "",
pages = "425 - 436",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2014.11.030",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X1400574X",
author = "Carlos M. Fernandez-Peruchena and Ana Bernardos",
keywords = "Solar energy",
keywords = "Optical air mass",
keywords = "High frequency solar radiation",
keywords = "Clearness index",
keywords = "Climate zones",
keywords = "Aerosol optical depth ",
abstract = "Abstract In this study, one-minute global horizontal solar irradiance distributions conditioned to the optical air mass, m, and hourly average of global horizontal solar irradiance were studied at sites in five different climate regions. For this purpose, the clearness index, kt, which accounts for the atmospheric transmittance, has been used. These distributions are fitted by functions based on the Boltzmann statistic. The one-minute distributions of kt conditioned to m found are either unimodal or bimodal, depending on the location and the value of m. These distributions are different for each of the locations analyzed. The one-minute distributions of kt conditioned to their hourly value (kth) are unimodal, and are in turn different at each of the locations analyzed. The one-minute kt distributions conditioned to both m and kth analyzed are also unimodal. These distributions were found to be the same (Kolmogorov–Smirnov test, p &gt; 0.05) at different sites in 5% of the cases compared, the majority of which show very cloudy sky conditions and decrease monotonically at clearer-sky conditions. These results point to the importance of local distribution and type of clouds in one-minute solar irradiance distributions, and highlight the role of local atmospheric clear sky transparency in differentiating these distributions. "
}
@article{Chen2007202,
title = "Ground-based measurements of aerosol optical properties and radiative forcing in North China ",
journal = "China Particuology ",
volume = "5",
number = "3",
pages = "202 - 205",
year = "2007",
note = "",
issn = "1672-2515",
doi = "https://doi.org/10.1016/j.cpart.2007.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S1672251507000486",
author = "Hongbin Chen and Xiangao Xia and Pucai Wang and Wenxing Zhang",
keywords = "Aerosol",
keywords = "Optical properties",
keywords = "Radiative forcing ",
abstract = "In order to gain an insight into the aerosol properties and their climatic effect over the continental source regions of China, it is of significance to carry out long-term ground-based measurements of aerosol optical properties and radiative forcing. A couple of temporary and permanent Aerosol Robotic Network (AERONET) sites and three comprehensive radiative sites were established in China as a result of international cooperation in recent years. Heavy aerosol loading and significant temporal and spatial variation over North China are revealed by the \{AERONET\} data. Aerosol-induced reductions in surface radiation budget are examined on the basis of collocated observations by sun photometers and pyranometers. "
}
@article{Pan2017197,
title = "An improved spectral optimization algorithm for atmospheric correction over turbid coastal waters: A case study from the Changjiang (Yangtze) estuary and the adjacent coast ",
journal = "Remote Sensing of Environment ",
volume = "191",
number = "",
pages = "197 - 214",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S0034425717300147",
author = "Yanqun Pan and Fang Shen and Wouter Verhoef",
keywords = "Ocean color",
keywords = "Atmospheric correction",
keywords = "GOCI",
keywords = "MERIS",
keywords = "Turbid coastal waters ",
abstract = "Abstract Remote sensing-based retrieval of the concentrations of water components relies largely on the accuracy of the atmospheric correction. Although a variety of atmospheric correction algorithms have been developed for turbid waters, the water-leaving reflectance is still underestimated in extremely turbid waters, such as in the Changjiang (Yangtze) estuary and the adjacent coast. To address this issue, this paper proposes an improved algorithm that is based on a spectral optimization algorithm (ESOA) with a coupled water-atmosphere model. The model combines an aerosol model that is constructed from Aerosol Robotic Network (AERONET) observation data and a simple semi-empirical radiative transfer (SERT) model (Shen et al. 2010) for water component retrieval. Four unknown parameters are involved in the coupled model: the relative humidity (RH), fine-mode fraction (FMF), aerosol optical thickness in the near-infrared (NIR) wavelength τa(λ0) and suspended particulate matter (SPM) concentration (Cspm). These parameters are estimated by a global optimization approach that is based on a genetic algorithm (GA) without any initial inputs. Validation results of the atmospherically corrected remote sensing reflectance Rrs(λ) from matchups between Geostationary Ocean Color Imager (GOCI) data and in situ data show that the algorithm has satisfactory accuracy. The root mean square error (RMSE) and the absolute percentage difference (APD) are 0.0089 and 35.12, respectively. By contrast, the Rrs(λ) values retrieved from the same matchups using the \{GOCI\} data processing system (GDPS) have higher \{RMSE\} and \{APD\} of 0.0104 and 69.15, respectively. The \{ESOA\} method can be implemented conveniently within the open source code of SeaDAS (v7.1) as an alternative and operational tool for atmospheric correction of ocean color data, including GOCI, \{MERIS\} and MODIS, over highly turbid estuarine and coastal regions, such as the Yangtze estuary, the Hangzhou Bay and most of the coastal ocean in Eastern China. "
}
@article{Xuehe2016104,
title = "\{GPU\} based real-time \{SLAM\} of six-legged robot ",
journal = "Microprocessors and Microsystems ",
volume = "47, Part A",
number = "",
pages = "104 - 111",
year = "2016",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.10.008",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001635",
author = "Zhang Xuehe and Li Ge and Liu Gangfeng and Zhao Jie and Hou ZhenXiu",
keywords = "Feature detection",
keywords = "Graphics processing unit (GPU)",
keywords = "Parallel Processing",
keywords = "SLAM ",
abstract = "Abstract Vision and \{AHRS\} (attitude and heading reference system) sensors fusion strategy is prevalent in recent years for the legged robot's \{SLAM\} (Simultaneous Localization and Mapping), due to its low cost and effectiveness in the global positioning system. In this paper, a new adaptive estimation algorithm is proposed to achieve the robot \{SLAM\} by fusing binocular vision and \{AHRS\} sensors. A novel acceleration algorithm for \{SIFT\} implementation based on Compute Unified Device Architecture (CUDA) is presented to detect the matching feature points in 2D images. All the steps of \{SIFT\} were specifically distributed and implemented by \{CPU\} or GPU, according to the step's characteristics to make full use of computational resources. The registration of the 3D feature point cloud is performed by using the iterative closest point (ICP) algorithm. Our GPU-based \{SIFT\} implementation can run at the speed of 30 frames per second (fps) on most images with 900 × 750 resolution in the test. Compared to other methods, our algorithm is simple to implement and suitable for parallel processing. It can be easily integrated into mobile robot’s tasks like navigation or object tracking, which need the real-time localization information. Experiments results showed that in the unknown indoor environments, the proposed algorithm`s operation is stable and the positioning accuracy is high. "
}
@article{Tian2016383,
title = "The bright star survey telescope for the planetary transit survey in Antarctica ",
journal = "Science Bulletin ",
volume = "61",
number = "5",
pages = "383 - 390",
year = "2016",
note = "",
issn = "2095-9273",
doi = "https://doi.org/10.1007/s11434-016-1015-0",
url = "http://www.sciencedirect.com/science/article/pii/S2095927316301773",
author = "Qiguo Tian and Peng Jiang and Fujia Du and Jian Wang and Zhengyang Li and Xiaoyan Li and Zhiyong Zhang and Haiping Lu and Xiangyan Yuan and Huigen Liu and Hui Zhang and Luming Sun and Liang Chang and Jianguo Wang and Shaohua Zhang and Tuo Ji and Xiheng Shi and Jie Chen and Guangyu Zhang and Minghao Jia and Jiajing Liu and Junyan Zhou and Xiang Pan and Shucheng Dong and Fengxin Jiang and Hongfei Zhang and Jilin Zhou and Lifan Wang and Hongyan Zhou",
keywords = "Instrumentation",
keywords = "Exoplanet",
keywords = "Photometry",
keywords = "Antarctic Site ",
abstract = "Abstract Transiting extrasolar planets (exoplanets), especially those orbiting bright stars, are desired for study of the diversity of planetary compositions, internal structures and atmospheres beyond our solar system. Dome A at Antarctica is a promising site for planetary transit surveys, where the continuous darkness and the large clear-sky fraction in the winter months greatly enhance the detection efficiency. The Chinese Small Telescope \{ARray\} and the Antarctic Survey Telescopes are the first facilities that have been operated at Dome A for use in exoplanet surveys. To increase the sky coverage, a low-temperature-resistant wide-field robotic telescope, named the bright star survey telescope (BSST), has been developed to join the ongoing planetary transit survey in Antarctica. The \{BSST\} has an aperture size of 300 mm and is equipped with a large-frame 4K × 4K \{CCD\} camera to receive starlight from a 3.°4 × 3.°4 field of view. The \{BSST\} was operated at Lijiang observatory in April and May 2015 for a test run. Photometric precision of 3.5 mmag was achieved for stars with V ~11 mag using 75 s exposures. The transiting events of two Jupiter-size exoplanets, HAT-P-3b and HAT-P-12b, were observed on May 10 and May 20, 2015, respectively. "
}
@article{Massie2013373,
title = "\{HITRAN\} 2012 refractive indices ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "130",
number = "",
pages = "373 - 380",
year = "2013",
note = "\{HITRAN2012\} special issue ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2013.06.022",
url = "http://www.sciencedirect.com/science/article/pii/S0022407313002768",
author = "S.T. Massie and M. Hervig",
keywords = "Refractive indices",
keywords = "Absorptive indices",
keywords = "Computer program ",
abstract = "Abstract The \{HITRAN\} 2012 compilation of the real and imaginary refractive indices of the materials in aerosols and cloud particles is reviewed. Additions to \{HITRAN\} 2012 focus upon materials that are absorptive (i.e. minerals, burning vegetation, brown carbon, desert dust, and volcanic ash). The HITRAN-RI program, created to facilitate usage of the indices, is discussed. The HITRAN-RI program inter-compares the indices of different data sets and calculates optical properties (i.e. extinction, scattering, absorption, single scattering albedo, backscattering, and asymmetry parameter) for user specified size distributions and particle types. The instructional component of HITRAN-RI introduces the user to Mie calculations for spheres and coated spheres, and applies various mixing rules by which one calculates the effective indices of a multi-component particle. "
}
@article{Mingas2012190,
title = "An \{FPGA\} implementation of the SMG-SLAM algorithm ",
journal = "Microprocessors and Microsystems ",
volume = "36",
number = "3",
pages = "190 - 204",
year = "2012",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2011.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0141933111001244",
author = "Grigorios Mingas and Emmanouil Tsardoulias and Loukas Petrou",
keywords = "Field programmable gate array",
keywords = "Simultaneous localization and mapping",
keywords = "Genetic algorithm",
keywords = "Scan-matching",
keywords = "Co-design ",
abstract = "One of the main tasks of a mobile robot in an unknown environment is to build and update a map of the environment and simultaneously determine its location within this map. This problem is referred to as the simultaneous localization and mapping (SLAM) problem. The article introduces scan-matching genetic \{SLAM\} (SMG-SLAM), a novel \{SLAM\} algorithm. It is based on a genetic algorithm that uses scan-matching for gene fitness evaluation. The main scope of the article is to present a hardware implementation of SMG-SLAM using an field programmable gate array (FPGA). The architecture of the system is described and it is shown that it is up to 14.83 times faster compared to the software algorithm without significant loss in accuracy. The proposed implementation can be used as part of a larger system, providing efficient \{SLAM\} for autonomous robotic applications. "
}
@article{Nogler2004123,
title = "Primary stability of a robodoc® implanted anatomical stem versus manual implantation ",
journal = "Clinical Biomechanics ",
volume = "19",
number = "2",
pages = "123 - 129",
year = "2004",
note = "",
issn = "0268-0033",
doi = "https://doi.org/10.1016/j.clinbiomech.2003.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S0268003303002225",
author = "Michael Nogler and Anne Polikeit and Cornelius Wimmer and Andreas Bruckner and Stephen J Ferguson and Martin Krismer",
keywords = "Total hip replacement",
keywords = "robodoc®",
keywords = "Computer-assisted orthopaedic surgery (CAOS)",
keywords = "Primary stability ",
abstract = "Objective. To assess the initial stability of anatomical stems implanted in manually broached femoral cavities compared with that assessed in cavities milled with the robodoc® system. Design. The bone-prosthesis interface motion was measured in matched pairs of cadaveric femora to assess the initial stability of anatomical stems implanted with two different implantation techniques. Background. The high costs of surgical robots and the increased perioperative efforts associated with their use can only be justified if measurable benefits for patients can be achieved. Increased initial stability of the stem as an early indicator for better bone ongrowth would be such a benefit. Methods. Seven pairs of fresh frozen human cadaveric femora were used. One femur of each pair was randomly assigned to receive the robotic milling method; the other femur underwent manual broaching by an experienced surgeon. Initial micromotions of the anatomical stems were measured during simulated gait cycles with loads of ⩽1500 N, and both groups underwent matched-pair analysis. Results. High motion of the prostheses was found for both implantation techniques Conclusions. The robodoc® system did not enhance the primary stability of the anatomical prosthesis compared with the manual broaching method.Relevance The initial stability of a femoral prosthesis may be an indicator of bone ongrowth and improved long-term fixation. Objective outcome measurements are needed to determine the effectiveness of the robotic milling method in achieving initial stability of implanted anatomic femoral stems. "
}
@article{Zhang201589,
title = "Factorization of view-object manifolds for joint object recognition and pose estimation ",
journal = "Computer Vision and Image Understanding ",
volume = "139",
number = "",
pages = "89 - 103",
year = "2015",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215000715",
author = "Haopeng Zhang and Tarek El-Gaaly and Ahmed Elgammal and Zhiguo Jiang",
keywords = "Homeomorphic manifold analysis",
keywords = "Object categorization",
keywords = "Object recognition",
keywords = "Instance recognition",
keywords = "Pose estimation ",
abstract = "Abstract Due to large variations in shape, appearance, and viewing conditions, object recognition is a key precursory challenge in the fields of object manipulation and robotic/AI visual reasoning in general. Recognizing object categories, particular instances of objects and viewpoints/poses of objects are three critical subproblems robots must solve in order to accurately grasp/manipulate objects and reason about their environments. Multi-view images of the same object lie on intrinsic low-dimensional manifolds in descriptor spaces (e.g. visual/depth descriptor spaces). These object manifolds share the same topology despite being geometrically different. Each object manifold can be represented as a deformed version of a unified manifold. The object manifolds can thus be parameterized by its homeomorphic mapping/reconstruction from the unified manifold. In this work, we develop a novel framework to jointly solve the three challenging recognition sub-problems, by explicitly modeling the deformations of object manifolds and factorizing it in a view-invariant space for recognition. We perform extensive experiments on several challenging datasets and achieve state-of-the-art results. "
}
@article{Pelayo20134,
title = "Magnitude Sensitive Competitive Learning ",
journal = "Neurocomputing ",
volume = "112",
number = "",
pages = "4 - 18",
year = "2013",
note = "Advances in artificial neural networks, machine learning, and computational intelligenceSelected papers from the 20th European Symposium on Artificial Neural Networks (ESANN 2012) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2012.11.039",
url = "http://www.sciencedirect.com/science/article/pii/S0925231213001562",
author = "Enrique Pelayo and David Buldain and Carlos Orrite",
keywords = "Competitive learning",
keywords = "Neural Networks",
keywords = "Vector quantization",
keywords = "Surface modelling",
keywords = "Color quantization",
keywords = "Interpolation ",
abstract = "This paper presents a new neural method for unsupervised learning denoted as Magnitude Sensitive Competitive Learning (MSCL), which has the property of distributing the unit centroids following any magnitude calculated from the unit parameters or the input data inside its Voronoi region. This controlled behavior permits it to outperform standard Competitive Learning algorithms that only tend to concentrate neurons according to the input data density, when other kind of data information processing is desired. Some examples applying different target functions show the \{MSCL\} possibilities in several applications as data-series interpolation, surface modelling from 3D point clouds and color quantization (CQ). "
}
@article{Hernandez201561,
title = "Near laser-scan quality 3-D face reconstruction from a low-quality depth stream ",
journal = "Image and Vision Computing ",
volume = "36",
number = "",
pages = "61 - 69",
year = "2015",
note = "",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2014.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0262885615000165",
author = "Matthias Hernandez and Jongmoo Choi and Gerard Medioni",
keywords = "Kinect",
keywords = "3D reconstruction",
keywords = "Face modeling ",
abstract = "Abstract We propose a method to produce near laser-scan quality 3-D face models of a freely moving user with a low-cost, low resolution range sensor in real-time. Our approach does not require any prior knowledge about the geometry of a face and can produce faithful geometric models of any star-shaped object. We use a cylindrical representation, which enables us to efficiently process the 3-D mesh by applying 2-D filters. We use the first frame as a reference and incrementally build the model by registering each subsequent cloud of 3-D points to the reference using the \{ICP\} (Iterative Closest Point) algorithm implemented on a \{GPU\} (Graphics Processing Unit). The registered point clouds are merged into a single image through a cylindrical representation. The noise from the sensor and from the pose estimation error is removed with a temporal integration and a spatial smoothing of the successively incremented model. To validate our approach, we quantitatively compare our model to laser scans, and show comparable accuracy.11 This paper extends the method presented in [15]. "
}

