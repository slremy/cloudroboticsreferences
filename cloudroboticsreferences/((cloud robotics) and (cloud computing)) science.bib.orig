@article{Wang2017116,
title = "Ubiquitous manufacturing system based on Cloud: A robotics application ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "116 - 125",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300345",
author = "Xi Vincent Wang and Lihui Wang and Abdullah Mohammed and Mohammad Givehchi",
keywords = "Ubiquitous manufacturing",
keywords = "Cloud manufacturing",
keywords = "Interoperability",
keywords = "Cloud robotics ",
abstract = "Abstract Modern manufacturing industry calls for a new generation of production system with better interoperability and new business models. As a novel information technology, Cloud provides new service models and business opportunities for manufacturing industry. In this research, recent Cloud manufacturing and Cloud robotics approaches are reviewed. Function block-based integration mechanisms are developed to integrate various types of manufacturing facilities. A Cloud-based manufacturing system is developed to support ubiquitous manufacturing, which provides a service pool maintaining physical facilities in terms of manufacturing services. The proposed framework and mechanisms are evaluated by both machining and robotics applications. In practice, it is possible to establish an integrated manufacturing environment across multiple levels with the support of manufacturing Cloud and function blocks. It provides a flexible architecture as well as ubiquitous and integrated methodologies for the Cloud manufacturing system. "
}
@article{Du2016,
title = "Robot Cloud: Bridging the power of robotics and cloud computing ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16000042",
author = "Zhihui Du and Ligang He and Yinong Chen and Yu Xiao and Peng Gao and Tongzhou Wang",
keywords = "Service-oriented architecture (SOA)",
keywords = "Cloud computing",
keywords = "Robotics",
keywords = "Robot Cloud",
keywords = "Robot as a Service (RaaS) ",
abstract = "Abstract Cloud computing is shaping the cyber world and evolves as a key computing and service platform for sharing resources including platforms, software applications and everything in the form of services. This is known “X as a Service”. Although it brings our age unparalleled computing ability and economic benefits, the application of cloud computing is still limited currently in the cyberspace due to the cloud services can only reside in cloud instead of our daily life environment. In fact, there are still a plethora of physical position based on-site service demands that cloud computing could help little due to the “cyber limitation”. In this paper, we aim to integrate the cyber world and the physical world by bringing up the idea of “Robot Cloud” to bridge the power of robotics and cloud computing. To make it possible, we design a novel Robot Cloud stack to support our idea and adopt the service-oriented architecture (SOA) to make the functional modules in the Robot Cloud more flexible, extensible and reusable. Then we develop a prototype of Robot Cloud using the popular Google App Engine to demonstrate our design method. Finally, we conduct the simulation experiments with a “robot show” application scenario to evaluate our scheduling policy and identify the effect of different request distributions and robot center solutions. "
}
@article{Xu2017370,
title = "Energy Condition Perception and Big Data Analysis for Industrial Cloud Robotics ",
journal = "Procedia \{CIRP\} ",
volume = "61",
number = "",
pages = "370 - 375",
year = "2017",
note = "The 24th \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.164",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116313245",
author = "Wei Xu and Quan Liu and Wenjun Xu and Zude Zhou and Duc Truong Pham and Ping Lou and Qingsong Ai and Xiaomei Zhang and Jiwei Hu",
keywords = "Industrial cloud robotics",
keywords = "energy-efficient manufacturing",
keywords = "distributed perception",
keywords = "big data analysis ",
abstract = "Abstract Industrial cloud robotics (ICRs), which is proposed to integrate the distributed industrial robots (IRs) resources to provide \{ICRs\} services at any place, has been attracted great attention due to the characteristics of convenient access, cheaper computing cost, more convenient network resources, etc. Meanwhile, in manufacturing industry, the energy-efficient issue, which means minimize the amount of energy resources to achieve a given output level in manufacturing process, is also gradually paid great attention by academia, industry and government. Currently, \{ICRs\} plays a crucial role in production. The implementation of energy-efficient manufacturing for \{ICRs\} will significantly decrease the energy consumption on the premise of normal production process, and also have remarkable effect on energy-saving and emission-reduction in manufacturing industry. In this context, the energy condition perception and big data analysis of \{ICRs\} are the essential procedure to achieve the aforementioned goals. A novel system architecture which mainly focuses on distributed energy condition perception and big data analysis for \{ICRs\} is built. Based on the perceptive data of \{ICRs\} related to energy consumption, a big data analysis model combined with the manufacturing status of \{ICRs\} is proposed, and the relationship between the big data and the analysis model is presented. Through the data analysis model, we can analyze the energy consumption fluctuation characteristic of \{ICRs\} operating state, count the energy consumption of the product related to different production phases, predict the health status of ICRs, as well as the trend of energy consumption associated with their operations. A case study is implemented to demonstrate the effectiveness of the proposed system and approaches. "
}
@article{Smara201774,
title = "Acceptance Test for Fault Detection in Component-based Cloud Computing and Systems ",
journal = "Future Generation Computer Systems ",
volume = "70",
number = "",
pages = "74 - 93",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302151",
author = "Mounya Smara and Makhlouf Aliouat and Al-Sakib Khan Pathan and Zibouda Aliouat",
keywords = "Fault detection",
keywords = "Component-based Cloud Computing",
keywords = "Recovery blocks",
keywords = "Acceptance Test",
keywords = "BIP framework ",
abstract = "Abstract Fault Detection is considered as one of the main challenges in large-scale dynamic environments and thus, for maintaining the reliability requirements of Cloud and Mobile Cloud systems. Most of the popular existing techniques for fault detection applied on the Cloud Computing environment in general, are based on system-monitoring despite the extreme difficulty of keeping track of all machines with their huge number in Cloud systems. In this paper, we propose a Fault Detection framework for the Component-based Cloud Computing by using Recovery Blocks’ Acceptance Test. This framework aims to construct Fail-Silent Cloud modules which have the ability of Self-Fault detection. In this, the detection process of transient hardware faults, software faults, and response-time failures is performed locally on each computing machine in the Cloud system. Background of the research issue, our mechanism, thorough analysis, and appropriate case study are presented. The efficiency and practicality of the proposed framework are proved by Safety verification using the model-checker. "
}
@article{JafarnejadGhomi2017,
title = "Load-balancing Algorithms in Cloud Computing: A Survey ",
journal = "Journal of Network and Computer Applications ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2017.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S1084804517301480",
author = "Einollah Jafarnejad Ghomi and Amir Masoud Rahmani and Nooruldeen Nasih Qader",
keywords = "Cloud Computing",
keywords = "Load Balancing",
keywords = "Task Scheduling",
keywords = "Hadoop MapReduce ",
abstract = "Abstract Cloud computing is a modern paradigm to provide services through the Internet. Load balancing is a key aspect of cloud computing and avoids the situation in which some nodes become overloaded while the others are idle or have little work to do. Load balancing can improve the Quality of Service (QoS) metrics, including response time, cost, throughput, performance and resource utilization. In this paper, we study the literature on the task scheduling and load-balancing algorithms and present a new classification of such algorithms, for example, Hadoop MapReduce load balancing category, Natural Phenomena-based load balancing category, Agent-based load balancing category, General load balancing category, application-oriented category, network-aware category, and workflow specific category. Furthermore, we provide a review in each of these seven categories. Also. We provide insights into the identification of open issues and guidelines for future research. "
}
@article{doNascimento201648,
title = "A Platform for Cloud Robotics* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "48 - 53",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.124",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325629",
author = "Amadeu do Nascimento and Eleri Cardozo and Ricardo S. Souza and Eliane G. Guimarães",
keywords = "Telerobotics",
keywords = "robot programming",
keywords = "mobile robots",
keywords = "telematics",
keywords = "cloud robotics ",
abstract = "Abstract: This paper presents the evolution of a software platform for supporting experimentation in mobile robotics as part of teaching and researching activities. Starting with Web-based laboratories (WebLabs) in the early 2000s the platform kept evolving according to the networking and distributed computing trends since then. In addition to the physical resources managed by the platform, the platform now is able to manage a pool of virtual machines as resources for experimentation. This new class of resources brings the processing power as required by many modern mobile robotics applications. Virtual machines can be widespread on a cluster of processors, on a private cloud computing infrastructure, or on a public cloud computing service. Like any other resource managed by the platform the access to the virtual machines is subjected to user authentication and authorization. A mechanism of user authentication and authorization based on federated identities (single-sign-on) allows the sharing resources maintained by different administrative domains. The paper emphasizes the current stage of the platform and a case study in mobile robotics localization. Localization, as many other mobile robotics algorithms, can employ parallelism at the cluster and cloud levels in order to improve speed, reliability, and scaling. "
}
@article{Qureshi2014220,
title = "Five Traits of Performance Enhancement Using Cloud Robotics: A Survey ",
journal = "Procedia Computer Science ",
volume = "37",
number = "",
pages = "220 - 227",
year = "2014",
note = "The 5th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2014)/ The 4th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2014)/ Affiliated Workshops ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.08.033",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914009983",
author = "Basit Qureshi and Anis Koubâa",
keywords = "Cloud Computing",
keywords = "Cloud Robotics",
keywords = "Big Data",
keywords = "Networked Robots",
keywords = "Autonomous Systems. ",
abstract = "Abstract Recently, robots and automation systems have been at the front of research with the majority of systems still operating indepen- dently using onboard computation, memory manipulation and communication. With improvements in communication technology and the increasing availability of network, new approaches where robot and automation processing is performed remotely with access to large scale datasets, support a range of functions. Cloud Robotics supplements performance enhancement of robotics and autonomous systems by providing a global infrastructure in innovative ways. This paper summarizes recent research into five traits of Cloud Robotics for performance enhancement in robotics and autonomous systems: 1) Remote Brain, 2) Big Data and Shared Knowledge-base, 3) Collective Learning, 4) Intelligence and Behavior, and 5) Cloud architectures. Towards the end, in this survey, we present future directions for research in cloud robotics. "
}
@article{Tsardoulias2017157,
title = "Towards an integrated robotics architecture for social inclusion – The \{RAPP\} paradigm ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "157 - 173",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716300535",
author = "Emmanouil G. Tsardoulias and Athanassios M. Kintsakis and Konstantinos Panayiotou and Aristeidis G. Thallas and Sofia E. Reppou and George G. Karagiannis and Miren Iturburu and Stratos Arampatzis and Cezary Zielinski and Vincent Prunet and Fotis E. Psomopoulos and Andreas L. Symeonidis and Pericles A. Mitkas",
keywords = "Robotic applications",
keywords = "Cloud robotics",
keywords = "Robotic architectures",
keywords = "Assistance robotics",
keywords = "Social robotics ",
abstract = "Abstract Scientific breakthroughs have led to an increase in life expectancy, to the point where senior citizens comprise an ever increasing percentage of the general population. In this direction, the \{EU\} funded \{RAPP\} project “Robotic Applications for Delivering Smart User Empowering Applications” introduces socially interactive robots that will not only physically assist, but also serve as a companion to senior citizens. The proposed \{RAPP\} framework has been designed aiming towards a cloud-based integrated approach that enables robotic devices to seamlessly deploy robotic applications, relieving the actual robots from computational burdens. The Robotic Applications (RApps) developed according to the \{RAPP\} paradigm will empower consumer social robots, allowing them to adapt to versatile situations and materialize complex behaviors and scenarios. The \{RAPP\} pilot cases involve the development of \{RApps\} for the \{NAO\} humanoid robot and the ANG-MED rollator targeting senior citizens that (a) are technology illiterate, (b) have been diagnosed with mild cognitive impairment or (c) are in the process of hip fracture rehabilitation. Initial results establish the robustness of \{RAPP\} in addressing the needs of end users and developers, as well as its contribution in significantly increasing the quality of life of senior citizens. "
}
@article{Abd2016,
title = "An effective approach for managing power consumption in cloud computing infrastructure ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316303830",
author = "Sura Khalil Abd and S.A.R Al-Haddad and Fazirulhisyam Hashim and Azizol B.H.J. Abdullah and Salman Yussof",
keywords = "Cloud computing",
keywords = "DNA-based fuzzy genetic",
keywords = "DFGA",
keywords = "Energy consumption",
keywords = "Resource utilization",
keywords = "VM consolidation",
keywords = "VM migration ",
abstract = "Abstract Cloud computing offers a dynamic provisioning of server capabilities as a scalable virtualized service. Big datacenters which deliver cloud computing services consume a lot of power. This results in high operational cost and large carbon emission. One way to lower power consumption without affecting the cloud services quality is to consolidate resources for reducing power. In this paper, we introduce a DNA-based Fuzzy Genetic Algorithm (DFGA) that employs DNA-based scheduling strategies to reduce power consumption in cloud datacenters. It is a power-aware architecture for managing power consumption in the cloud computing infrastructure. We also identify the performances metrics that are needed to evaluate the proposed work performance. The experimental results show that \{DFGA\} reduced power consumption when comparing with other algorithms. Our proposed work deals with real time task which is not static, and concentrates on the dynamic users since they are involved in cloud. "
}
@article{Tchernykh2016,
title = "Towards understanding uncertainty in cloud computing with risks of confidentiality, integrity, and availability ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.11.011",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316303878",
author = "Andrei Tchernykh and Uwe Schwiegelsohn and El-ghazali Talbi and Mikhail Babenko",
keywords = "Cloud computing",
keywords = "Uncertainty",
keywords = "Resource provisioning",
keywords = "Optimization",
keywords = "Scheduling",
keywords = "Reliability",
keywords = "Privacy ",
abstract = "Abstract An extensive research has led to a general understanding of uncertainty issues in different fields ranging from computational biology to decision making in economics. However, a study of uncertainty on large scale computing systems and cloud computing systems is limited. Most of works examine uncertainty phenomena in users’ perceptions of the qualities, intentions and actions of cloud providers. In this paper, we discuss the role of uncertainty in the resource and service provisioning, privacy, etc. especially, in the presence of the risks of confidentiality, integrity, and availability. We review sources of uncertainty, and fundamental approaches for scheduling under uncertainty. We also discuss potentials of these approaches, and address methods for mitigating the risks of confidentiality, integrity, and availability associated with the loss of information, denial of access for a long time, and information leakage. "
}
@article{AbuSharkh201678,
title = "Building a cloud on earth: A study of cloud computing data center simulators ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "78 - 96",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.06.037",
url = "http://www.sciencedirect.com/science/article/pii/S138912861630216X",
author = "Mohamed Abu Sharkh and Ali Kanso and Abdallah Shami and Peter Öhlén",
keywords = "Cloud computing",
keywords = "Cloud simulators",
keywords = "Scalability",
keywords = "Data centers",
keywords = "Virtualization",
keywords = "Network and systems monitoring and measurements ",
abstract = "Abstract As cloud computing technologies finalize their transformation into the standard technologies for businesses of all sizes, they face more scrutiny than ever. Clients are expecting the benefits of turning infrastructure, platform and network into services payable per use without tolerating any service hiccups caused by performance bottlenecks or overprovision. This puts cloud providers under pressure to deliver data center management solutions and deployment plans in minimal time and with failure allowance close to none. Any comprehensive solution evaluation could gain much from the use of cloud simulators. Cloud simulators have the advantage of practicality over both mathematical proofs and real testbeds. They support any amount of heterogeneous use cases demanded by the cloud provider. Despite being a relatively new concept, multiple cloud simulators were developed. However, they are still in the phase of adapting to the scenarios, objectives and characteristics of the cloud. This paper examines a selected set of the current cloud simulators in terms of vision, features, and architecture. Strong points and limitations are discussed. Moreover, this paper presents a framework for cloud simulator design that can serve as an elaborate design checklist. A discussion of the open research challenges concludes the paper. "
}
@article{Chen2017144,
title = "A nonlinearly normalized back propagation network and cloud computing approach for determining cycle time allowance during wafer fabrication ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "144 - 156",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S073658451500143X",
author = "Toly Chen and Yi-Chi Wang",
keywords = "Internal due date assignment",
keywords = "Allowance determination",
keywords = "Upper bound",
keywords = "Wafer fabrication",
keywords = "Back propagation network ",
abstract = "Abstract This study investigated the determination of the allowance that must be added to the cycle time estimate, which is a critical concern when assigning internal due dates. Because no method for estimating cycle times is completely accurate, producing such estimates remains problematic but has rarely been addressed in the literature. A large allowance postpones the internal due date, diminishing company appeal when a factory manager negotiates with a customer. Therefore, in this study, a nonlinear approach was proposed to normalize the cycle times. After estimating the cycle time of a job by using a back propagation network, the allowance added to the cycle time can be effectively reduced through the collaboration of several computing clouds. Theoretical properties of the proposed method were validated, and a case from a wafer fabrication factory was used to evaluate the effectiveness of the proposed method in comparison with various existing methods. According to the experimental results, the proposed method facilitated establishing tight upper bounds on the cycle times. The proposed method was proven to be very effective. "
}
@article{Xia20165,
title = "Closed-loop design evolution of engineering system using condition monitoring through internet of things and cloud computing ",
journal = "Computer Networks ",
volume = "101",
number = "",
pages = "5 - 18",
year = "2016",
note = "Industrial Technologies and Applications for the Internet of Things ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615005034",
author = "Min Xia and Teng Li and Yunfei Zhang and Clarence W. de Silva",
keywords = "Engineering system design",
keywords = "Design evolution",
keywords = "Multi-domain modeling",
keywords = "Machine condition monitoring",
keywords = "Internet of things",
keywords = "Cloud computing ",
abstract = "Abstract Flexibility of a manufacturing system is quite important and advantageous in modern industry, which function in a competitive environment where market diversity and the need for customized product are growing. Key machinery in a manufacturing system should be reliable, flexible, intelligent, less complex, and cost effective. To achieve these goals, the design methodologies for engineering systems should be revisited and improved. In particular, continuous or on-demand design improvements have to be incorporated rapidly and effectively in order to address new design requirements or resolve potential weaknesses of the original design. Design of an engineering system, which is typically a multi-domain system, can become complicated due to its complex structure and possible dynamic coupling between domains. An integrated and concurrent approach should be considered in the design process, in particular in the conceptual and detailed design phases. In the context of multi-domain design, attention has been given recently to such subjects as multi-criteria decision making, multi-domain modeling, evolutionary computing, and genetic programing. More recently, machine condition monitoring has been considered for integration into a scheme of design evolution even though many challenges exist for this to become a reality such as lack of systematic approaches and the existence of technical barriers in massive condition data acquisition, transmission, storage and mining. Recently, the internet of things (IoT) and cloud computing (CC) are being developed quickly and they offer new opportunities for evolutionary design for such tasks as data acquisition, storage and processing. In this paper, a framework for the closed-loop design evolution of engineering systems is proposed in order to achieve continuous design improvement for an engineering system through the use of a machine condition monitoring system assisted by IoT and CC. New design requirements or the detection of design weaknesses of an existing engineering system can be addressed through the proposed framework. A design knowledge base that is constructed by integrating design expertise from domain experts, on-line process information from condition monitoring and other design information from various sources is proposed to realize and supervise the design process so as to achieve increased efficiency, design speed, and effectiveness. The framework developed in this paper is illustrated by using a case study of design evolution of an industrial manufacturing system. "
}
@article{Pop201679,
title = "ARMCO: Advanced topics in resource management for ubiquitous cloud computing: An adaptive approach ",
journal = "Future Generation Computer Systems ",
volume = "54",
number = "",
pages = "79 - 81",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15002484",
author = "Florin Pop and Maria Potop-Butucaru",
keywords = "Resource management",
keywords = "Task scheduling",
keywords = "Adaptive methods",
keywords = "Cloud computing",
keywords = "Ubiquitous systems ",
abstract = "Abstract Cloud Computing can be seen as one of the latest major evolution in computing offering unlimited possibility to use \{ICT\} in various domains: business, smart cities, medicine, environmental computing, mobile systems, design and implementation of cyber-infrastructures. The recent expansion of Cloud Systems has led to adapting resource management solutions for large number of wide distributed and heterogeneous datacenters. The adaptive methods used in this context are oriented on: self-stabilizing, self-organizing and autonomic systems; dynamic, adaptive and machine learning based distributed algorithms; fault tolerance, reliability, availability of distributed systems. The pay-per-use economic model of Cloud Computing comes with a new challenge: maximizing the profit for service providers, minimizing the total cost for customers and being friendly with the environment. This special issue presents advances in virtual machine assignment and placement, multi-objective and multi-constraints job scheduling, resource management in federated Clouds and in heterogeneous environments, dynamic topology for data distribution, workflow performance improvement, energy efficiency techniques and assurance of Service Level Agreements. "
}
@article{Casas2016,
title = "A balanced scheduler with data reuse and replication for scientific workflows in cloud computing systems ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X1500388X",
author = "Israel Casas and Javid Taheri and Rajiv Ranjan and Lizhe Wang and Albert Y. Zomaya",
keywords = "Cloud computing",
keywords = "Scientific workflow",
keywords = "Scheduling",
keywords = "Virtual machine",
keywords = "Data-intensive computing",
keywords = "Big data ",
abstract = "Abstract Cloud computing provides substantial opportunities to researchers who demand pay-as-you-go computing systems. Although cloud provider (e.g., Amazon Web Services) and application provider (e.g., biologists, physicists, and online gaming companies) both have specific performance requirements (e.g. application response time), it is the cloud scheduler’s responsibility to map the application to underlying cloud resources. This article presents a Balanced and file Reuse–Replication Scheduling (BaRRS) algorithm for cloud computing environments to optimally schedule scientific application workflows. BaRRS splits scientific workflows into multiple sub-workflows to balance system utilization via parallelization. It also exploits data reuse and replication techniques to optimize the amount of data that needs to be transferred among tasks at run-time. BaRRS analyzes the key application features (e.g., task execution times, dependency patterns and file sizes) of scientific workflows for adapting existing data reuse and replication techniques to cloud systems. Further, BaRRS performs a trade-off analysis to select the optimal solution based on two optimization constraints: execution time and monetary cost of running scientific workflows. BaRRS is compared with a state-of-the-art scheduling approach; experiments prove its superior performance. Experiments include four well known scientific workflows with different dependency patterns and data file sizes. Results were promising and also highlighted most critical factors affecting execution of scientific applications on clouds. "
}
@article{Dogmus2015100,
title = "RehabRobo-Onto: Design, development and maintenance of a rehabilitation robotics ontology on the cloud ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "100 - 109",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000714",
author = "Zeynep Dogmus and Esra Erdem and Volkan Patoglu",
keywords = "Rehabilitation robotics",
keywords = "Ontologies",
keywords = "Knowledge representation ",
abstract = "Abstract Representing the available information about rehabilitation robots in a structured form, as an ontology, facilitates access to various kinds of information about the existing robots, and thus it is important both from the point of view of rehabilitation robotics and from the point of view of physical medicine. Rehabilitation robotics researchers can learn various properties of the existing robots and access to the related publications to further improve the state-of-the-art. Physical medicine experts can find information about rehabilitation robots and related publications (possibly including results of clinical studies) to better identify the right robot for a particular therapy or patient population. Therefore, considering also the advantages of ontologies and ontological reasoning, such as interoperability of various heterogeneous knowledge resources (e.g., patient databases or disease ontologies), such an ontology provides the underlying mechanisms for translational physical medicine, from bench-to-bed and back, and personalized rehabilitation robotics. With these motivations, the first formal rehabilitation robotics ontology, called RehabRobo-Onto, is designed and developed, collaborating with experts in robotics and in physical medicine. A web based software (called RehabRobo-Query) with an easy-to-use intelligent user-interface is also built. RehabRobo-Query allows robot designers to add/modify information about their rehabilitation robots to/from RehabRobo-Onto. The ontology system consisting of RehabRobo-Onto and RehabRobo-Query is made available on the cloud, utilizing Amazon Web services, to provide a reliable environment for access, development and maintenance of RehabRobo-Onto by rehabilitation robot designers and physical medicine experts around the world. "
}
@article{Chaâri2016260,
title = "Cyber-physical systems clouds: A survey ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "260 - 278",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S1389128616302699",
author = "Rihab Chaâri and Fatma Ellouze and Anis Koubâa and Basit Qureshi and Nuno Pereira and Habib Youssef and Eduardo Tovar",
keywords = "Cloud computing",
keywords = "Cloud robotics",
keywords = "Cloud sensors",
keywords = "Vehicular cloud networks ",
abstract = "Abstract Cyber-Physical Systems (CPSs) represent systems where computations are tightly coupled with the physical world, meaning that physical data is the core component that drives computation. Industrial automation systems, wireless sensor networks, mobile robots and vehicular networks are just a sample of cyber-physical systems. Typically, \{CPSs\} have limited computation and storage capabilities due to their tiny size and being embedded into larger systems. With the emergence of cloud computing and the Internet-of-Things (IoT), there are several new opportunities for these \{CPSs\} to extend their capabilities by taking advantage of the cloud resources in different ways. In this survey paper, we present an overview of research efforts on the integration of cyber-physical systems with cloud computing and categorize them into three areas: (1) remote brain, (2) big data manipulation, (3) and virtualization. In particular, we focus on three major \{CPSs\} namely mobile robots, wireless sensor networks and vehicular networks. "
}
@article{Jelinek2015193,
title = "Practical Aspects of Total Least Squares Vectorization of Point Clouds in Mobile Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "4",
pages = "193 - 198",
year = "2015",
note = "13th \{IFAC\} and \{IEEE\} Conference on Programmable Devices and Embedded SystemsPDES 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.07.031",
url = "http://www.sciencedirect.com/science/article/pii/S240589631500806X",
author = "Ales Jelinek",
keywords = "Robot",
keywords = "point cloud",
keywords = "vectorization",
keywords = "least squares",
keywords = "localization and mapping ",
abstract = "Abstract Fast and reliable point cloud processing is a challenging task, especially when online running of the implementation on a mobile robot is required. This paper summarizes generally usable optimization techniques (hardware dependent implementation details are not covered) for vectorization of the point cloud using the least squares approach. Formulas for efficient implementation, methodology of tuning of the control variables, posprocessing for result reliability, as well as illustrative examples are all covered in the text. The discussed suggestions were experimentally proofed to give increased performance (in terms of speed and quality of approximation) with respect to basic implementation. "
}
@article{Spinnewyn201714,
title = "Resilient application placement for geo-distributed cloud networks ",
journal = "Journal of Network and Computer Applications ",
volume = "85",
number = "",
pages = "14 - 31",
year = "2017",
note = "Intelligent Systems for Heterogeneous Networks ",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2016.12.015",
url = "http://www.sciencedirect.com/science/article/pii/S1084804516303149",
author = "Bart Spinnewyn and Ruben Mennes and Juan Felipe Botero and Steven Latré",
keywords = "Cloud computing",
keywords = "Quality of service",
keywords = "Application placement",
keywords = "Reliability ",
abstract = "Abstract The strong uptake of cloud computing has led to an important increase of mission-critical applications being placed on cloud environments. Those applications often require high levels of availability coupled with guarantees on a minimum level of throughput and a maximum level of response time. To achieve the lowest response time possible, clouds are more and more decentralized, leading to a heterogeneous network of micro clouds positioned on the edge of the network and possibly interconnected by best-effort links. This heterogeneous environment introduces important challenges for the management of these clouds as the heterogeneity results in an increased failure probability. In this paper, we address these challenges by providing a resilient placement of mission-critical applications on geo-distributed clouds. We present an exact solution to the problem, which is complemented by two heuristics: a near-optimal distributed genetic meta-heuristic and a scalable centralized heuristic based on subgraph isomorphism detection. A detailed performance evaluation shows that, with the newly proposed heuristic based on subgraph isomorphism detection, we can double the amount of applications satisfying availability requirements, in cloud environments comprising over 100 nodes, while keeping the time required to calculate the solution under 20 s. "
}
@article{Razzaghzadeh201712,
title = "Probabilistic modeling to achieve load balancing in Expert Clouds ",
journal = "Ad Hoc Networks ",
volume = "59",
number = "",
pages = "12 - 23",
year = "2017",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S157087051730001X",
author = "Shiva Razzaghzadeh and Ahmad Habibizad Navin and Amir Masoud Rahmani and Mehdi Hosseinzadeh",
keywords = "Expert Cloud",
keywords = "Human resource",
keywords = "Cloud computing",
keywords = "Load balancing",
keywords = "Poisson distribution",
keywords = "Quality of service ",
abstract = "Abstract Expert Cloud as a new class of Cloud computing systems enables its users to request the skill, knowledge and expertise of people without any information of their location by employing Internet infrastructures and Cloud computing concepts. Effective load balancing in a heterogeneous distributed environment such as Cloud is important. Since the differences in the human resource (HRs) capabilities and the variety of users' requests causes that some \{HRs\} are overloaded and some others are idle. The task allocation to the \{HR\} based on the announced requirements by the user may cause the imbalanced load distribution among \{HRs\} as well. Hence resource management and scheduling are among the important cases to achieve load balancing. Using static and dynamic algorithms, the ant colony, and the method based on searching tree all are among the methods to achieve load balancing. This paper presents a new method in order to distribute the dynamic load based on distributed queues aware of service quality in the Cloud environment. In this method, we utilize the colorful ants as a ranking for making distinction among the \{HRs\} capabilities. In this paper, we perform the mapping among the tasks and \{HRs\} using allocating a label to each HR. We model the load balancing and mapping process based on Poisson and exponential distribution. This model allows us to allocate each task to the \{HR\} which is able to execute it with maximum power using the distributed queues aware of the service quality. Simulation results show that the expert Cloud can reduce the execution and tardiness time and improve \{HR\} utilization. The cost of using resources as an effective factor in load balancing is also observed. "
}
@article{Subirats201570,
title = "Assessing and forecasting energy efficiency on Cloud computing platforms ",
journal = "Future Generation Computer Systems ",
volume = "45",
number = "",
pages = "70 - 94",
year = "2015",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2014.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X14002428",
author = "Josep Subirats and Jordi Guitart",
keywords = "Cloud computing",
keywords = "Energy efficiency",
keywords = "Ecological efficiency",
keywords = "Forecasting",
keywords = "Green computing",
keywords = "IaaS provider ",
abstract = "Abstract IaaS providers have become interested in optimising their infrastructure energy efficiency. To do so, their \{VM\} placement algorithms need to know the current and future energy efficiency at different levels (Virtual Machine, node, infrastructure and service levels) and for potential actions such as service deployment or \{VM\} deployment, migration or cancellation. This publication provides a mathematical formulation for the previous aspects, as well as the design of a \{CPU\} utilisation estimator used to calculate the aforementioned forecasts. The correct adjustment of the estimators’ configuration parameters has been proved to lead to considerable precision improvements. When running Web workloads, estimators focused on noise filtering provide the best precision even if they react slowly to changes, whereas reactive predictors are desirable for batch workloads. Furthermore, the precision when running batch workloads partially depends on each execution. Finally, it has been observed that the forecasts precision degradation as such forecasts are performed for a longer time period in the future is smaller when running web workloads. "
}
@article{ShahdiPashaki20151140,
title = "Group technology-based model and cuckoo optimization algorithm for resource allocation in cloud computing ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "1140 - 1145",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.237",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315004760",
author = "S. Shahdi-Pashaki and Ehsan Teymourian and Vahid Kayvanfar and GH.M. Komaki and A. Sajadi",
keywords = "Cloud computing",
keywords = "Group technology",
keywords = "Virtual machine",
keywords = "Cuckoo optimization algorithm ",
abstract = "Abstract The control of operational costs is one of the main goals of resource management problem in cloud computing (CC). This paper presents a new mathematical model based on group technology (GT) to map the virtual machines (VMs) to workflows in order to control some costs (e.g. transfer costs, penalty costs and server cost) when the \{VMs\} are running. \{GT\} is a well-known manufacturing technique in industrial environments which can control some measures (e.g. part movements, resource utilization). In large size problems a cuckoo optimization algorithm (COA) is proposed. To test the effectiveness of our approaches, we first generate a set of problems randomly and then compare the model and \{COA\} with a well-known algorithm in literature called Round robin (RR). Analyzing the computational results proves that our approaches give better performance than RR. "
}
@article{Qureshi201690,
title = "Performance of a Low Cost Hadoop Cluster for Image Analysis in Cloud Robotics Environment ",
journal = "Procedia Computer Science ",
volume = "82",
number = "",
pages = "90 - 98",
year = "2016",
note = "4th Symposium on Data Mining Applications, SDMA2016, 30 March 2016, Riyadh, Saudi Arabia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916300278",
author = "Basit Qureshi and Yasir Javed and Anis Koubâa and Mohamed-Foued Sriti and Maram Alajlan",
keywords = "UAVs",
keywords = "HIPI",
keywords = "Hadoop cluster",
keywords = "Image analysis",
keywords = "Distributed processing",
keywords = "Embedded systems ",
abstract = "Abstract With the emergence of cloud robotics, the cloud computing paradigm becomes increasingly attractive to robotics, where the cloud acts as the remote brain of low-cost robots, such as commodity drones. The idea is to offload heavy computations, like image processing, from the robot to the cloud; process it in short time (near real-time) and send back commands to the robot. This paper investigates the performance of a back-end cloud computing framework in deploying robotics-like applications (i.e. image analysis and processing) using low-cost Hadoop clusters. The design of a low-cost mini-data center built with readily available commodity 32-bit \{ARM\} boards, i.e. Raspberry Pi 2 Model B, is presented. Furthermore, the performance of RPi-based clusters is extensively tested with different types of data including text, text/image and image, and a comparative analysis against Hadoop cluster running on virtual machines is presented. The Hadoop Image Processing Interface (HIPI) Library was used and also configured to optimally utilize the Pi Cluster resources for improved performance. Results show that the \{RPi\} Hadoop cluster lags in performance when compared to Hadoop cluster running on virtual machines, the low cost and small form factor makes it ideal for remote Image analysis in surveillance / disaster recovery scenarios where \{UAVs\} can transmit image streams to the Cluster for remote processing. "
}
@article{Mezgár2014657,
title = "The challenge of networked enterprises for cloud computing interoperability ",
journal = "Computers in Industry ",
volume = "65",
number = "4",
pages = "657 - 674",
year = "2014",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514000335",
author = "István Mezgár and Ursula Rauschecker",
keywords = "Cloud computing",
keywords = "Networked enterprise",
keywords = "Interoperability",
keywords = "Manufacturing",
keywords = "Standardization ",
abstract = "Abstract Manufacturing enterprises have to organize themselves into effective system architectures forming different types of Networked Enterprises (NE) to match fast changing market demands. Cloud Computing (CC) is an important up to date computing concept for NE, as it offers significant financial and technical advantages beside high-level collaboration possibilities. As cloud computing is a new concept the solutions for handling interoperability, portability, security, privacy and standardization challenges have not been solved fully yet. The paper introduces the main characteristics of future Internet-based enterprises and the different \{CC\} models. An overview is given on interoperability and actual standardization issues in \{CC\} environments. A taxonomy on possible connecting forms of networked enterprises and cloud-based \{IT\} systems with reference on interoperability is introduced, parallel presenting four use cases as well. Finally, an example of connecting cloud and \{NE\} is presented as an effective application of cloud computing in manufacturing industry. "
}
@incollection{Chaulya2016351,
title = "Chapter 7 - Application of Cloud Computing Technology in Mining Industry ",
editor = "Chaulya, S.K.  and Prasad, G.M. ",
booktitle = "Sensing and Monitoring Technologies for Mines and Hazardous Areas ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "351 - 396",
isbn = "978-0-12-803194-0",
doi = "https://doi.org/10.1016/B978-0-12-803194-0.00007-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128031940000076",
author = "S.K. Chaulya and G.M. Prasad",
keywords = "Cloud system",
keywords = "Mine automation",
keywords = "Safety management",
keywords = "Asset management",
keywords = "Knowledge sharing ",
abstract = "Abstract A cloud computing system, which is the latest version of computing models available, has practically revolutionized the information technology. It distinguishes itself from other computing paradigms due to its unique characteristics, such as the ability to handle massive data, the power of virtualization, scalability, elasticity, agility, resource pooling capability, and dependable security. Moreover, it is very cost effective and can be useful for individual as well as industries. The mining industry, which is facing several challenges of varied complexities, can reap the benefits of this technology in different areas such as mine automation, knowledge sharing, process improvement, safety management, equipment condition monitoring, environmental impact assessment and management, environmental modeling, tracking of miners and moveable mining machinery, asset management, efficiency improvement in all facets of mining activities, and remote operations. Cloud computing technology, which within its short term of only few years has already shown potential for turning to be a major driver of growth for several industries, can help by enhancing production, increasing safety and bringing economic benefits to mining industry. "
}
@article{Goodarzi2014320,
title = "Cloud Computing Security by Integrating Classical Encryption ",
journal = "Procedia Computer Science ",
volume = "42",
number = "",
pages = "320 - 326",
year = "2014",
note = "Medical and Rehabilitation Robotics and Instrumentation (MRRI2013) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.11.069",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914015075",
author = "Koorosh Goodarzi and Abbas karimi",
keywords = "cryptographic algorithms",
keywords = "cloud computing",
keywords = "classical and modern cryptographic algorithms ",
abstract = "Abstract Cloud calculation provides sharing of the spread sources and the services related to the organizations or websites users. As cloud computing of distributed resource is shared in an open environment, the security is the biggest problem in software development. On one hand user controls data and process on his own computer and on the other hand, data services provided by the company and the vendor are kept in the cloud so that the user does not know where to store the data and has no control over it. In this paper, we try a hybrid methodology of modern and classic cryptographic algorithms for providing data security in a cloud environment. "
}
@article{GhobaeiArani2017,
title = "An autonomic resource provisioning approach for service-based cloud applications: A hybrid approach ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.022",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302327",
author = "Mostafa Ghobaei-Arani and Sam Jabbehdari and Mohammad Ali Pourmina",
keywords = "Cloud computing",
keywords = "Cloud services",
keywords = "Resource provisioning",
keywords = "Autonomic computing",
keywords = "Reinforcement learning ",
abstract = "Abstract In cloud computing environment, resources can be dynamically provisioned on deman for cloud services The amount of the resources to be provisioned is determined during runtime according to the workload changes. Deciding the right amount of resources required to run the cloud services is not trivial, and it depends on the current workload of the cloud services. Therefore, it is necessary to predict the future demands to automatically provision resources in order to deal with fluctuating demands of the cloud services. In this paper, we propose a hybrid resource provisioning approach for cloud services that is based on a combination of the concept of the autonomic computing and the reinforcement learning (RL). Also, we present a framework for autonomic resource provisioning which is inspired by the cloud layer model. Finally, we evaluate the effectiveness of our approach under two real world workload traces. The experimental results show that the proposed approach reduces the total cost by up to 50%, and increases the resource utilization by up to 12% compared with the other approaches. "
}
@article{LD20132292,
title = "Honey bee behavior inspired load balancing of tasks in cloud computing environments ",
journal = "Applied Soft Computing ",
volume = "13",
number = "5",
pages = "2292 - 2303",
year = "2013",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2013.01.025",
url = "http://www.sciencedirect.com/science/article/pii/S1568494613000446",
author = "Dhinesh Babu L.D. and P. Venkata Krishna",
keywords = "Load balancing",
keywords = "Cloud computing",
keywords = "Priorities of tasks",
keywords = "Honey bee behavior",
keywords = "Performance evaluation ",
abstract = "Scheduling of tasks in cloud computing is an NP-hard optimization problem. Load balancing of non-preemptive independent tasks on virtual machines (VMs) is an important aspect of task scheduling in clouds. Whenever certain \{VMs\} are overloaded and remaining \{VMs\} are under loaded with tasks for processing, the load has to be balanced to achieve optimal machine utilization. In this paper, we propose an algorithm named honey bee behavior inspired load balancing (HBB-LB), which aims to achieve well balanced load across virtual machines for maximizing the throughput. The proposed algorithm also balances the priorities of tasks on the machines in such a way that the amount of waiting time of the tasks in the queue is minimal. We have compared the proposed algorithm with existing load balancing and scheduling algorithms. The experimental results show that the algorithm is effective when compared with existing algorithms. Our approach illustrates that there is a significant improvement in average execution time and reduction in waiting time of tasks on queue. "
}
@article{Amoretti2013767,
title = "Efficient autonomic cloud computing using online discrete event simulation ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "73",
number = "6",
pages = "767 - 776",
year = "2013",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2013.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0743731513000336",
author = "Michele Amoretti and Francesco Zanichelli and Gianni Conte",
keywords = "Cloud management",
keywords = "Autonomic computing",
keywords = "Discrete event simulation ",
abstract = "Abstract Interest is growing in open source tools that let organizations build IaaS clouds using their own internal infrastructures, alone or in conjunction with external ones. A key component in such private/hybrid clouds is virtual infrastructure management, i.e., the dynamic orchestration of virtual machines, based on the understanding and prediction of performance at scale, with uncertain workloads and frequent node failures. Part of the research community is trying to solve this and other IaaS problems looking to Autonomic Computing techniques, that can provide, for example, better management of energy consumption, quality of service (QoS), and unpredictable system behaviors. In this context, we first recall the main features of the \{NAM\} framework devoted to the design of distributed autonomic systems. Then we illustrate the organization and policies of a NAM-based Workload Manager, focusing on one of its components, the Capacity Planner. We show that, when it is not possible to obtain optimal energy-aware plans analytically, sub-optimal plans can be autonomically obtained using online discrete event simulation. Specifically, the proposed approach allows to cope with a broader range of working conditions and types of workloads. "
}
@article{Yu201518,
title = "Ant colony optimization applied to web service compositions in cloud computing ",
journal = "Computers & Electrical Engineering ",
volume = "41",
number = "",
pages = "18 - 27",
year = "2015",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2014.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0045790614003139",
author = "Qiang Yu and Ling Chen and Bin Li",
keywords = "Service composition",
keywords = "Multi-cloud base",
keywords = "Cloud combination",
keywords = "Ant colony optimization ",
abstract = "Abstract Rapid developments in cloud computing technology mean that many different web services are now published and available in cloud data centers. There has recently been an increasing amount of interest in web service composition, because it is important in practical applications. However, most traditional service composition methods can only find service composition sequences in a single cloud, and cannot consider a multi-cloud service base. It is challenging to efficiently find a composition across multiple clouds, because it involves service compositions and combinatorial optimization. In this paper, we present a greedy algorithm called Greedy-WSC and an ant colony optimization based algorithm called ACO-WSC, which attempt to select cloud combinations that are feasible and use the minimum number of clouds. Our experimental results show that the proposed ant colony optimization method can effectively and efficiently find cloud combinations with a minimal number of clouds. "
}
@article{Dermaku201364,
title = "Reducing of the latency between the client and server using Heuristic Partitioning Approaches on Cloud Computing Architecture ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "8",
pages = "64 - 68",
year = "2013",
note = "15th \{IFAC\} Workshop on International Stability, Technology, and Culture ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130606-3-XK-4037.00034",
url = "http://www.sciencedirect.com/science/article/pii/S147466701634215X",
author = "A. Dermaku and N. Demaku and Xh. Bajrami",
keywords = "Cloud",
keywords = "Computing",
keywords = "Middleware",
keywords = "Client-Server",
keywords = "Hypergraph",
keywords = "Partitioning ",
abstract = "Abstract Cloud computing has become a significant trend in recent years and is a widely speeding among industry that are ready for noticeable deployments in coming years. Because cloud computing addresses a key difficulties surrounding large scale data processing, and because there are many difficulties that current technology is facing with there is a need to find ways improving the services to the client by introducing new techniques for upgrading the service. One of the ways is to improve the latency between the two points of communications (nodes). In this paper we proposed a new model that minimizes the time needed to transfer data from the cloud using heuristic algorithms (approaches). These approaches find the optimal path between different servers or routers, where servers presents nodes on the communications graph. The client-server architecture model presented in this paper will help users to access the cloud and to retrieve the data and application faster by funding the optimal route "
}
@article{Merrick201738,
title = "Value systems for developmental cognitive robotics: A survey ",
journal = "Cognitive Systems Research ",
volume = "41",
number = "",
pages = "38 - 55",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S1389041716301280",
author = "Kathryn Merrick",
keywords = "Robotics",
keywords = "Cognition",
keywords = "Developmental systems",
keywords = "Value systems",
keywords = "Intrinsic motivation ",
abstract = "Abstract This paper surveys value systems for developmental cognitive robotics. A value system permits a biological brain to increase the likelihood of neural responses to selected external phenomena. Many machine learning algorithms capture the essence of this learning process. However, computational value systems aim not only to support learning, but also autonomous attention focus to direct learning. This combination of unsupervised attention focus and learning aims to address the grand challenge of autonomous mental development for machines. This survey examines existing value systems for developmental cognitive robotics in this context. We examine the definitions of value used—including recent pioneering work in intrinsic motivation as value—as well as initialisation strategies for innate values, update strategies for acquired value and the data structures used for storing value. We examine the extent to which existing value systems support attention focus, learning and prediction in an unsupervised setting. The types of robots and applications in which these value systems are used are also examined, as well as the ways that these applications are evaluated. Finally, we study the strengths and limitations of current value systems for developmental cognitive robots and conclude with a set of research challenges for this field. "
}
@article{Valilai2013110,
title = "A collaborative and integrated platform to support distributed manufacturing system using a service-oriented approach based on cloud computing paradigm ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "110 - 127",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000932",
author = "Omid Fatahi Valilai and Mahmoud Houshmand",
keywords = "\{STEP\} standard",
keywords = "Modularity",
keywords = "XML",
keywords = "Distributed product development",
keywords = "Cloud computing",
keywords = "Service-oriented manufacturing",
keywords = "Collaborative product development ",
abstract = "Today's manufacturing enterprises struggle to adopt cost-effective manufacturing systems. Overview of the recent manufacturing enterprises shows that successful global manufacturing enterprises have distributed their manufacturing capabilities over the globe. The successes of global manufacturing enterprises depend upon the entire worldwide integration of their product development processes and manufacturing operations that are distributed over the globe. Distributed manufacturing agents' collaboration and manufacturing data integrity play a major role in global manufacturing enterprises' success. There are number of works, conducted to enable the distributed manufacturing agents to collaborate with each other. To achieve the manufacturing data integrity through manufacturing processes, numbers of solutions have been proposed which one of the successful solutions is to use \{ISO\} 10303 (STEP) standard. However, adopting this standard one can recognize antonym effects of integration and collaboration approaches that weaken both integration and collaboration capabilities of manufacturing agents. In our latest work, we had developed an integrated and collaborative manufacturing platform named LAYMOD. Albeit the platform in question was through enough to be applied in various collaborative and integrated \{CAx\} systems, its embedded structure hampers its application for collaboration in distributed manufacturing systems. To achieve an integrated and collaborative platform for distributed manufacturing agents, this paper proposes a service-oriented approach. This approach is originated from cloud computing paradigm known as one of the technologies which enables a major transformation in manufacturing industry. Also, to maintain the product data integration based on the \{STEP\} standard, a new service-oriented approach is proposed. This approach is in parallel to the new capability of the \{STEP\} standard for supporting \{XML\} data structures. The result is a new platform named XMLAYMOD. \{XMLAYMOD\} is able to support distributed manufacturing collaboration and data integration based on the \{STEP\} standard. The different aspects of this platform to fulfill the requirements of distributed collaboration and also to overcome the lacks of the \{STEP\} standard are discussed through a brief case study. "
}
@article{Chen2017133,
title = "Development of a cloud-based factory simulation system for enabling ubiquitous factory simulation ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "133 - 143",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300084",
author = "Toly Chen and Min-Chi Chiu",
keywords = "Cloud manufacturing",
keywords = "Factory simulation",
keywords = "Cloud-based simulation",
keywords = "Ubiquitous manufacturing ",
abstract = "Abstract This study investigated several problems related to the implementation of cloud-based factory simulation. First, the differences between cloud-based factory simulation and parallel and distributed factory simulation were discussed. Individually managed, resource heterogeneity, uneven load partitioning, and potential business opportunities were found to be the novel characteristics that discriminate cloud-based factory simulation from parallel and distributed factory simulation. The problems in existing cloud-based factory simulation systems are discussed. An experimental cloud-based factory simulation system was developed and used for simulating a mobile lift table factory. "
}
@article{Toffetti2017165,
title = "Self-managing cloud-native applications: Design, implementation, and experience ",
journal = "Future Generation Computer Systems ",
volume = "72",
number = "",
pages = "165 - 179",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302977",
author = "Giovanni Toffetti and Sandro Brunner and Martin Blöchlinger and Josef Spillner and Thomas Michael Bohnert",
keywords = "Micro services",
keywords = "Cloud-native applications",
keywords = "Container-based applications",
keywords = "Distributed systems",
keywords = "Auto-scaling",
keywords = "Health-management ",
abstract = "Abstract Running applications in the cloud efficiently requires much more than deploying software in virtual machines. Cloud applications have to be continuously managed: (1) to adjust their resources to the incoming load and (2) to face transient failures replicating and restarting components to provide resiliency on unreliable infrastructure. Continuous management monitors application and infrastructural metrics to provide automated and responsive reactions to failures (health management) and changing environmental conditions (auto-scaling) minimizing human intervention. In the current practice, management functionalities are provided as infrastructural or third party services. In both cases they are external to the application deployment. We claim that this approach has intrinsic limits, namely that separating management functionalities from the application prevents them from naturally scaling with the application and requires additional management code and human intervention. Moreover, using infrastructure provider services for management functionalities results in vendor lock-in effectively preventing cloud applications to adapt and run on the most effective cloud for the job. In this paper we discuss the main characteristics of cloud native applications, propose a novel architecture that enables scalable and resilient self-managing applications in the cloud, and relate on our experience in porting a legacy application to the cloud applying cloud-native principles. "
}
@article{Xu201275,
title = "From cloud computing to cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "28",
number = "1",
pages = "75 - 86",
year = "2012",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2011.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584511000949",
author = "Xun Xu",
keywords = "Cloud computing",
keywords = "Cloud manufacturing",
keywords = "Service-oriented business model ",
abstract = "Cloud computing is changing the way industries and enterprises do their businesses in that dynamically scalable and virtualized resources are provided as a service over the Internet. This model creates a brand new opportunity for enterprises. In this paper, some of the essential features of cloud computing are briefly discussed with regard to the end-users, enterprises that use the cloud as a platform, and cloud providers themselves. Cloud computing is emerging as one of the major enablers for the manufacturing industry; it can transform the traditional manufacturing business model, help it to align product innovation with business strategy, and create intelligent factory networks that encourage effective collaboration. Two types of cloud computing adoptions in the manufacturing sector have been suggested, manufacturing with direct adoption of cloud computing technologies and cloud manufacturing—the manufacturing version of cloud computing. Cloud computing has been in some of key areas of manufacturing such as IT, pay-as-you-go business models, production scaling up and down per demand, and flexibility in deploying and customizing solutions. In cloud manufacturing, distributed resources are encapsulated into cloud services and managed in a centralized way. Clients can use cloud services according to their requirements. Cloud users can request services ranging from product design, manufacturing, testing, management, and all other stages of a product life cycle. "
}
@article{Hassan201748,
title = "A multimedia healthcare data sharing approach through cloud-based body area network ",
journal = "Future Generation Computer Systems ",
volume = "66",
number = "",
pages = "48 - 58",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15004070",
author = "Mohammad Mehedi Hassan and Kai Lin and Xuejun Yue and Jiafu Wan",
keywords = "Wireless body area network",
keywords = "Media healthcare",
keywords = "Data sharing",
keywords = "Cloud computing",
keywords = "Network architecture ",
abstract = "Abstract Wireless Body Area Network (WBAN), as a dramatic platform for pervasive computing and communication, has been widely applied in healthcare domains. Since the patient-related data in the form of text, image, voice, etc. is significant in the process of healthcare services, efficiently managing these media data from various \{WBAN\} is vital for various applications. Recently, Cloud-assisted \{WBAN\} has become popular that can supply massive computing, flexible storage and various software services to WBAN. Still, there are some challenging issues exist in this platform to deliver and share the huge media healthcare data to remote terminals timely with guaranteed QoS support. In the paper, we propose an efficient network model that combines \{WBAN\} and Cloud for valid data sharing. The proposed network architecture is designed as four layers: perception layer, network layer, cloud computing layer, and application layer. In the network, the integration of TCP/IP and Zigbee in the coordinator devices is utilized. Consequently, \{WBAN\} coordinators can compatibility inter-operate with various local networks such as WiFi and \{LTE\} network to support high mobility of users. Besides, we integrate Content Centric Networking (CCN) with our proposed architecture to improve the ability of the \{WBAN\} coordinator. Thus, it can support uninterrupted media healthcare content delivery. In addition, adaptive streaming technique was also utilized to reduce packet loss. Various simulations were conducted using \{OPNET\} simulator to show the feasibility of the proposed architecture in terms of transmitting a huge amount of media healthcare data in real-time under traditional IP-based network. "
}
@article{Li2017209,
title = "Novel availability and integrity verification protocol for \{ISMAC\} system under cloud environment ",
journal = "Computers & Electrical Engineering ",
volume = "57",
number = "",
pages = "209 - 219",
year = "2017",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2016.11.002",
url = "http://www.sciencedirect.com/science/article/pii/S0045790616307017",
author = "Jun Li",
keywords = "Cloud computing",
keywords = "Protocol verification",
keywords = "Data center",
keywords = "Security and storage",
keywords = "Numerical simulation ",
abstract = "Abstract The Novel Availability and Integrity Verification Protocol (NAIVP) is a novel technique for indicating the global availability and general integrity that is supported by data that has been stored in the cloud. There are several schemes that have been designed which rely on the Vandermonde-based Reed-Solomon Code. This is necessary to ensure that the data has good availability. Researchers have proposed the homomorphic distributed verification protocol for guaranteeing the security of data storage in the cloud and pseudorandom data is used by the token pre-computation to determine whether the stored data is correct. However, there is very little integrity in the security provided for the data. The proposed \{NAIVP\} overcomes the difficulties faced by this previously published protocol. It can offer robust assurance of the availability and integrity of information stored in the cloud using fractional dynamic data sustenance through verifiability. The experimental result proves effectiveness and robustness of the proposed methodology. "
}
@article{Liu20173,
title = "Workload-based multi-task scheduling in cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "3 - 20",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516303210",
author = "Yongkui Liu and Xun Xu and Lin Zhang and Long Wang and Ray Y. Zhong",
keywords = "Cloud manufacturing",
keywords = "Multi-task scheduling",
keywords = "Task workload ",
abstract = "Abstract Cloud manufacturing is an emerging service-oriented business model that integrates distributed manufacturing resources, transforms them into manufacturing services, and manages the services centrally. Cloud manufacturing allows multiple users to request services at the same time by submitting their requirement tasks to a cloud manufacturing platform. The centralized management and operation of manufacturing services enable cloud manufacturing to deal with multiple manufacturing tasks in parallel. An important issue with cloud manufacturing is therefore how to optimally schedule multiple manufacturing tasks to achieve better performance of a cloud manufacturing system. Task workload provides an important basis for task scheduling in cloud manufacturing. Based on this idea, we present a cloud manufacturing multi-task scheduling model that incorporates task workload modelling and a number of other essential ingredients regarding services such as service efficiency coefficient and service quantity. Then we investigate the effects of different workload-based task scheduling methods on system performance such as total completion time and service utilization. Scenarios with or without time constraints are separately investigated in detail. Results from simulation experiments indicate that scheduling larger workload tasks with a higher priority can shorten the makespan and increase service utilization without decreasing task fulfilment quality when there is no time constraint. When time constraint is involved, the above strategy enables more tasks to be successfully fulfilled within the time constraint, and task fulfilment quality also does not deteriorate. "
}
@article{Hao2017168,
title = "The role of wearable devices in meeting the needs of cloud manufacturing: A case study ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "168 - 179",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515001131",
author = "Yuqiuge Hao and Petri Helo",
keywords = "Cloud manufacturing",
keywords = "Internet of users",
keywords = "Value co-creation",
keywords = "Wearable technology",
keywords = "Augmented reality ",
abstract = "Abstract Cloud manufacturing is a service-oriented, customer-centric and demand-driven process with well-established industrial automation. Even though, it does not necessarily mean the absence of human beings. Due to products and their corresponding manufacturing processes becoming increasingly complex, operators' daily working lives are also becoming more difficult. Enhanced human–machine interaction is one of the core areas for the success of the next generation of manufacturing. However, the current research only focuses on the automation and flexibility features of cloud manufacturing, the interaction between human and machine and the value co-creation among operators is missing. Therefore, a new method is needed for operators to support their work, with the objective of reducing the time and cost of machine control and maintenance. This paper describes a practical demonstration that uses the technologies of the Internet of things (IoT), wearable technologies, augmented reality, and cloud storage to support operators' activities and communication in discrete factories. This case study exhibits the capabilities and user experience of smart glasses in a cloud manufacturing environment, and shows that smart glasses help users stay productive and engaged. "
}
@article{Zheng201773,
title = "A system framework for \{OKP\} product planning in a cloud-based design environment ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "73 - 85",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301132",
author = "Pai Zheng and Yuqian Lu and Xun Xu and Sheng Quan Xie",
keywords = "One-of-a-kind production",
keywords = "Product planning",
keywords = "Cloud-based design",
keywords = "Cloud manufacturing",
keywords = "Mass customisation ",
abstract = "Abstract Nowadays, one-of-a-kind (OKP) companies, which generally operate in an 'engineer-to-order' business mode, strive to deliver individualized products with quality to achieve customer satisfaction. Thus, an accurate and prompt analysis of customer requirements (CRs) in the early design stage is critical to its success. However, most \{OKP\} companies are small or medium-sized enterprises (SMEs). Due to the limited resources and low product planning budget, they often cannot obtain abundant \{CR\} information nor can they afford the expense of complicated planning process. To address these issues, a system framework is proposed in support of \{OKP\} product planning process in a cloud-based design (CBD) environment. The challenges and future market niches of \{OKP\} companies are presented. The comparison of typical distributed systems shows that CBD, which utilizes advanced information technologies and business model, has advantages in providing sufficient resources, decreasing product development time span for \{OKP\} companies in a cost-efficient way. This article describes the proposed system architecture, the business interaction process and the information communication among customers, designers and marketing analysts at the product planning stage. To validate the proposed framework, a prototype system module MyProduct is under development in the \{CBD\} environment with an illustrative example. "
}
@article{Serafin201791,
title = "Using extended measurements and scene merging for efficient and robust point cloud registration ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "91 - 106",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302712",
author = "Jacopo Serafin and Giorgio Grisetti",
keywords = "Pose tracking",
keywords = "Point cloud registration",
keywords = "Iterative closest point (ICP) ",
abstract = "Abstract Point cloud registration is a fundamental building block of many robotic applications. In this paper we describe a system to solve the registration problem, that builds on top of our previous work (Serafin and Grisetti (2015)), and that represents an extension to the well known Iterative Closest Point (ICP) algorithm. Our approach combines recent achievements on optimization by using an extended point representation (Serafin and Grisetti (2014)) that captures the surface characteristics around the points. Thanks to an effective strategy to search for correspondences, our method can operate on-line and cope with measurements gathered with an heterogeneous set of range and depth sensors. By using an efficient map-merging procedure our approach can quickly update the tracked scene and handle dynamic aspects. We also introduce an approximated variant of our method that runs at twice the speed of our full implementation. Experiments performed on a large publicly available benchmarking dataset show that our approach performs better with respect to other state-of-the art methods. In most of the tests considered, our algorithm has been able to obtain a translational and rotational relative error of respectively ∼ 1 cm and ∼ 1 ° . "
}
@article{Badawi201759,
title = "Mobile cloud-based physical activity advisory system using biofeedback sensors ",
journal = "Future Generation Computer Systems ",
volume = "66",
number = "",
pages = "59 - 70",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15003428",
author = "Hawazin Faiz Badawi and Haiwei Dong and Abdulmotaleb El Saddik",
keywords = "Physical activity",
keywords = "Advisory system",
keywords = "Cloud computing",
keywords = "Wellbeing",
keywords = "Biofeedback",
keywords = "Environmental context ",
abstract = "Abstract Physical inactivity has gained a wide attention due to its negative influence on human wellness. Physical activity advisory systems consider a promising solution for this phenomenon. In this paper, we propose a mobile cloud-based physical activity advisory system utilizing biofeedback sensors and environmental context data based on calories expenditure from performing various activities by tracking user’s physical movements. To evaluate the proposed system, we conducted in total a three-month experiment on six users. For each user, we tracked the amount of burnt calories from the physical movements for a two-week period. During the first week, the system did not send any advice, while during the second week, the system was advising the user on activities to perform. The compared results of the two weeks collected data (without and with advice) reflect the positive effect of the proposed system on participants’ physical activity level. The system motivates them to reach or exceed the recommended number of calories to be burned daily. "
}
@article{Liu2017,
title = "Cyber-physical manufacturing cloud: Architecture, virtualization, communication, and testbed ",
journal = "Journal of Manufacturing Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0278612517300432",
author = "Xiaoqing F. Liu and Md Rakib Shahriar and S.M. Nahian Al Sunny and Ming C. Leu and Liwen Hu",
keywords = "Cloud manufacturing",
keywords = "Cyber-physical systems",
keywords = "Service-oriented architecture",
keywords = "MTConnect ",
abstract = "Abstract Cyber-physical systems are integrations of computation, networking, and physical processes and they are increasingly finding applications in manufacturing. Cloud manufacturing integrates cloud computing and service-oriented technologies with manufacturing processes and provides manufacturing services in manufacturing clouds. A cyber physical system for manufacturing is not a manufacturing cloud if it does not use virtualization technique in cloud computing and service oriented architecture in service computing. On the other hand, a manufacturing cloud is not cyber physical system if it does not have components for direct interactions with machine tools and other physical devices. In this paper, a new paradigm of Cyber-Physical Manufacturing Cloud (CPMC) is introduced to bridge gaps among cloud computing, cyber physical systems, and manufacturing. A \{CPMC\} allows direct operations and monitoring of machine tools in a manufacturing cloud over the Internet. A scalable and service-oriented layered architecture of \{CPMC\} is developed. It allows publication and subscription of manufacturing web services and cross-platform applications in CPMC. A virtualization method of manufacturing resources in \{CPMC\} is presented. In addition, communication mechanisms between the layers of the \{CPMC\} using communication protocols such as MTConnect, TCP/IP, and \{REST\} are discussed. A \{CPMC\} testbed is developed and implemented based on the proposed architecture. The testbed is fully operational in two geographically distributed sites. The developed testbed is evaluated using several manufacturing scenarios. Its testing results demonstrate that it can monitor and execute manufacturing operations remotely over the Internet efficiently in a manufacturing cloud. "
}
@article{Tao201734,
title = "SDMSim: A manufacturing service supply–demand matching simulator under cloud environment ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "34 - 46",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516302605",
author = "Fei Tao and Jiangfeng Cheng and Ying Cheng and Shixin Gu and Tianyu Zheng and Hao Yang",
keywords = "Manufacturing service",
keywords = "Supply–demand matching (SDM)",
keywords = "Service-oriented manufacturing (SoM)",
keywords = "Simulator",
keywords = "Hypernetwork",
keywords = "Cloud manufacturing ",
abstract = "Abstract Nowadays, with the introduction and application of new information technologies in manufacturing, various advanced manufacturing modes and national strategies have been put forward and paid more and more attention, such as Industry 4.0, Industrial Internet, Cyber-Physical System or Cyber Manufacturing, Made in China 2025, Internet Plus Manufacturing, Cloud Manufacturing, etc. For these modes and strategies, how to realize the effective and intelligent supply–demand matching (SDM) of various manufacturing resources and capabilities (MR&amp;C) in the form of service is one of the common issues and aims. In order to provide a uniformed research platform for related researchers both in academic and industry, the concept of manufacturing service \{SDM\} simulator (SDMSim) is proposed in this paper. A hypernetwork based architecture for the simulator is designed, as well as its seven key functions and subsystems, including manufacturing service management, manufacturing task management, manufacturing service \{SDM\} hypernetwork, manufacturing service \{SDM\} problem formulation and configuration, matching and scheduling algorithms/strategies selection and design, statistical analysis, and visualization. It illustrates that \{SDMSim\} has the potential to serve the users of manufacturing service provider, manufacturing service consumer, manufacturing service operator in the field of SoM, as well as the related researchers. "
}
@article{Ma20151279,
title = "LTE-based humanoid robotics system ",
journal = "Microprocessors and Microsystems ",
volume = "39",
number = "8",
pages = "1279 - 1284",
year = "2015",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001179",
author = "Yujun Ma and Chi Harold Liu and Musaed Alhussein and Yin Zhang and Min Chen",
keywords = "LTE",
keywords = "Robot",
keywords = "Cloud computing ",
abstract = "Abstract Although the robots integrated with communication module can provide various functions, there is intrinsic limitation because of the instable wireless connection, restricted bandwidth and limited coverage of network. Fortunately, assisted by \{LTE\} (Long Term Evolution) techniques, the robots can be deployed more widely to support bandwidth-intensive applications. Hence, this paper proposes a LTE-based robotics system integrated with cloud computing to enhance the capability of data transmissions and intelligence for providing higher quality and more friendly services. Furthermore, we develop a robot with emotional recognition and feedback for improving Quality of Service (QoS) and Quality of Experience (QoE), and design a testbed for verifying system’s feasibility and performance. "
}
@article{Cura201739,
title = "A scalable and multi-purpose point cloud server (PCS) for easier and faster point cloud data management and processing ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "127",
number = "",
pages = "39 - 56",
year = "2017",
note = "Geospatial Week 2015 ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.06.012",
url = "http://www.sciencedirect.com/science/article/pii/S092427161630123X",
author = "Rémi Cura and Julien Perret and Nicolas Paparoditis",
keywords = "RDBMS",
keywords = "Point cloud management",
keywords = "Point cloud generalisation",
keywords = "Patch",
keywords = "Meta-data",
keywords = "Point cloud server ",
abstract = "Abstract In addition to more traditional geographical data such as images (rasters) and vectors, point cloud data are becoming increasingly available. Such data are appreciated for their precision and true three-Dimensional (3D) nature. However, managing point clouds can be difficult due to scaling problems and specificities of this data type. Several methods exist but are usually fairly specialised and solve only one aspect of the management problem. In this work, we propose a comprehensive and efficient point cloud management system based on a database server that works on groups of points (patches) rather than individual points. This system is specifically designed to cover the basic needs of point cloud users: fast loading, compressed storage, powerful patch and point filtering, easy data access and exporting, and integrated processing. Moreover, the proposed system fully integrates metadata (like sensor position) and can conjointly use point clouds with other geospatial data, such as images, vectors, topology and other point clouds. Point cloud (parallel) processing can be done in-base with fast prototyping capabilities. Lastly, the system is built on open source technologies; therefore it can be easily extended and customised. We test the proposed system with several billion points obtained from Lidar (aerial and terrestrial) and stereo-vision. We demonstrate loading speeds in the ∼50 million pts/h per process range, transparent-for-user and greater than 2 to 4:1 compression ratio, patch filtering in the 0.1 to 1 s range, and output in the 0.1 million pts/s per process range, along with classical processing methods, such as object detection. "
}
@article{Chen201634,
title = "A cloud-based system framework for performing online viewing, storage, and analysis on big data of massive \{BIMs\} ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "34 - 48",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516300413",
author = "Hung-Ming Chen and Kai-Chuan Chang and Tsung-Hsi Lin",
keywords = "Cloud computing",
keywords = "Building information model",
keywords = "Big data analysis",
keywords = "Web3D",
keywords = "Bigtable",
keywords = "MapReduce ",
abstract = "Abstract This paper presents a cloud-based system framework based on Bigtable and MapReduce as the data storage and processing paradigms for providing a web-based service for viewing, storing, and analyzing massive building information models (BIMs). Cloud and Web 3D technologies were utilized to develop a \{BIM\} data center that can handle the big data of massive \{BIMs\} using multiple servers in a distributed manner and can be accessed by multiple users to concurrently submit and view \{BIMs\} online in 3D. Traditional \{BIM\} include only static information such as the geometric parameters, physical properties, and spatial relations for modeling a physical space. In this study, \{BIM\} was extended to dynamic BIM, which includes dynamic data such as historical records from the monitoring of the facility environment and usage. Owing to this extension, a dynamic \{BIM\} became a parametric model, which can be used to simulate user behaviors. On the client side, this study applied WebGL in the web interface development to achieve the display of \{BIMs\} in 3D on browsers. Users can access the services via various online devices anytime and anywhere to view the 3D model online. On the server side, this study used Apache Hadoop, which can utilize multiple servers to provide mass storage spaces in a distributed manner with Bigtable-like structured storage, to establish the \{BIM\} data center. A schema for storing the big data of massive dynamic \{BIMs\} in Bigtables was proposed. MapReduce, a Hadoop component for the parallel processing of large data sets, was utilized to process big data from dynamic BIMs. A big data analysis framework to effectively retrieve and calculate required information from dynamic \{BIMs\} in the data center for various applications by MapReduce distributed computing was proposed this study. We provide principle and architecture of the proposed framework along with its experimental assessment. The results confirmed that scalable and reliable management of massive \{BIMs\} can be achieved using the proposed framework. "
}
@article{Gravina2016,
title = "Cloud-based Activity-aaService cyber–physical framework for human activity monitoring in mobility ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16303016",
author = "Raffaele Gravina and Congcong Ma and Pasquale Pace and Gianluca Aloi and Wilma Russo and Wenfeng Li and Giancarlo Fortino",
keywords = "Cloud computing",
keywords = "Activity monitoring",
keywords = "Wearable sensors",
keywords = "Programming framework",
keywords = "Software as a service ",
abstract = "Abstract This paper proposes Activity as a Service (Activity-aaService), a full-fledged cyber–physical framework to support community, on-line and off-line human activity recognition and monitoring in mobility. Activity-aaService is able to address the current lack of Cloud-Assisted Body Area Networks platforms and applications supporting monitoring and analysis of human activity for single individuals and communities. Activity-aaService is built atop the BodyCloud platform so enabling efficient BSN-based sensor data collection and local processing (Body-side), high performance computing of collected sensor data and data storing on the Cloud (Cloud-side), workflow-based programming of data analysis (Analyst-side), and advanced visualization of results (Viewer-side). Specifically, it provides specific, powerful and flexible programming abstractions for the rapid prototyping of efficient human activity-oriented applications. The effectiveness of the proposed framework has been demonstrated through the development of several prototypes related to physical activity monitoring, step counting, physical energy estimation, automatic fall detection, and smart wheelchair support. Finally, performance evaluation of the proposed framework at the Body-side of the activity classification has been carried out by analyzing processing load, data transmission time, \{CPU\} usage, memory footprint, and battery consumption using four heterogeneous mobile devices representing low, medium and high performance mobile platforms. "
}
@article{Casas2016,
title = "GA-ETI: An enhanced genetic algorithm for the scheduling of scientific workflows in cloud environments ",
journal = "Journal of Computational Science ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316301399",
author = "Israel Casas and Javid Taheri and Rajiv Ranjan and Lizhe Wang and Albert Y. Zomaya",
keywords = "Cloud computing",
keywords = "Scientific workflow",
keywords = "Scheduling algorithms",
keywords = "Genetic algorithm",
keywords = "Virtual machine ",
abstract = "Abstract Over recent years, cloud computing has become one of the main sources of computer power to run scientific experiments. To cope with these demands, cloud providers need to efficiently match applications with computing resources to maintain an acceptable level of customer satisfaction. A correct match or scheduling of scientific workflows relies on the ability to fully analyze applications prior to execution, analyze characteristics of available computing resources, provide users with several scheduling configurations, and guide users to select the optimal configuration to execute workflows. To date, different schedulers have been proposed to execute complex applications on cloud environments; nevertheless, none exists, to the best of our knowledge, to provide all the aforementioned features. GA-ETI, the scheduler proposed in this work, is designed to address all aforementioned concerns by providing several efficient solutions (in a Pareto Front fashion) to run scientific workflows on cloud resources. Flexibility of optimization procedure of GA-ETI allows it to easily adapt to different types of scientific workflows and produce schedules that effectively exploit/consider the relationship between jobs and their required data. GA-ETI acts as an interface between cloud user and cloud provider in receiving an application, analyzing it, and distributing its tasks among selected resources. GA-ETI differs from the majority of proposed schedulers because it can adapt to the size of both jobs and virtual machines, it includes a monetary cost model (from a public cloud), and it considers complex interdependencies among tasks. We test GA-ETI with five well-known benchmarks with different computing and data transfer demands in our VMware-vSphere private cloud. Through experimentation, GA-ETI has been proved to reduce makespan of executing workflows between 11% and 85% when compared to three up-do-date scheduling algorithms without increasing the monetary cost. GA-ETI opens the way to develop a top-layer-scheduler for a workflow manager system to provide a complex analysis and include different optimizing objectives. "
}
@article{Pandey2017,
title = "Exploiting the untapped potential of mobile distributed computing via approximation ",
journal = "Pervasive and Mobile Computing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2017.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S1574119217300494",
author = "Parul Pandey and Dario Pompili",
keywords = "Mobile device clouds",
keywords = "Approximate computing",
keywords = "Mobile perception application",
keywords = "Workflows",
keywords = "Object recognition ",
abstract = "Abstract Mobile computing is one of the largest untapped reservoirs in today’s pervasive computing world as it has the potential to enable a variety of in-situ, real-time applications. Yet, this computing paradigm suffers when the available resources–such as energy in the network, \{CPU\} cycles, memory, I/O data rate–are limited. In this article, the new paradigm of approximate computing is proposed to harness such potential and to enable real-time computation-intensive mobile applications in resource-limited and uncertain environments. A reduction in time and energy consumed by an application is obtained via approximate computing by decreasing the amount of computation needed; such improvement, however, comes with the potential loss in accuracy. Hence, a Mobile Distributed Computing framework, is introduced to determine offline the ‘approximable’ tasks in an application and a light-weight online algorithm is devised to select the approximate version of the tasks in an application during run time. The effectiveness of the proposed approach is validated through extensive simulation and testbed experiments by comparing approximate versus exact-computation performance. "
}
@article{Riazuelo2014401,
title = "C2TAM: A Cloud framework for cooperative tracking and mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "4",
pages = "401 - 413",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013002248",
author = "L. Riazuelo and Javier Civera and J.M.M. Montiel",
keywords = "SLAM",
keywords = "Visual SLAM",
keywords = "Cloud SLAM",
keywords = "Cloud Robotics",
keywords = "Cloud Computing ",
abstract = "Abstract The Simultaneous Localization And Mapping by an autonomous mobile robot–known by its acronym SLAM–is a computationally demanding process for medium and large-scale scenarios, in spite of the progress both in the algorithmic and hardware sides. As a consequence, a robot with \{SLAM\} capabilities has to be equipped with the latest computers whose weight and power consumption might limit its autonomy. This paper describes a visual \{SLAM\} system based on a distributed framework where the expensive map optimization and storage is allocated as a service in the Cloud, while a light camera tracking client runs on a local computer. The robot onboard computers are freed from most of the computation, the only extra requirement being an internet connection. The data flow from and to the Cloud is low enough to be supported by a standard wireless connection. The experimental section is focused on showing real-time performance for single-robot and cooperative \{SLAM\} using an \{RGBD\} camera. The system provides the interface to a map database where: (1) a map can be built and stored, (2) stored maps can be reused by other robots, (3) a robot can fuse its map online with a map already in the database, and (4) several robots can estimate individual maps and fuse them together if an overlap is detected. "
}
@article{Carstensen2016560,
title = "Condition Monitoring and Cloud-based Energy Analysis for Autonomous Mobile Manipulation - Smart Factory Concept with \{LUHbots\} ",
journal = "Procedia Technology ",
volume = "26",
number = "",
pages = "560 - 569",
year = "2016",
note = "3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2016.08.070",
url = "http://www.sciencedirect.com/science/article/pii/S2212017316304170",
author = "Jan Carstensen and Torben Carstensen and Malte Pabst and Fabian Schulz and Jan Friederichs and Simon Aden and Daniel Kaczor and Jens Kotlarski and Tobias Ortmaier",
keywords = "Mobile Robotics",
keywords = "Condition Monitoring",
keywords = "Cloud-based Energy Analysis",
keywords = "Logistic Handling ",
abstract = "Abstract In this paper, a smart factory concept for autonomous mobile robots is presented. The main purpose is to increase productivity of the transport in machine-floor. It is based on advanced methods for failure handling and prevention, leading to increased robustness, less downtime and less effort in maintenance [1], [2]. Therefore, condition data and states of the robot are collected by Robot Operation System (ROS) and transferred to a factory hub (server). The collected data, e.g. voltages, currents, set points, velocities and accelerations are used to identify important system parameters, e.g. moving masses and friction parameters to enable the proposed smart factory concept. Further aim is to let the factory hub control a group of mobile robots using a self-organizing algorithm for different tasks. Due to the increasing customization of products causing smaller lot sizes [3], manufacturers of mobile robotic production systems have developed a diversity of flexible robots [4], [5], [6], [7], [8]. Mobile robots inside the production line allow for collecting and evaluation of system-inherent data e.g. handling and transportation time, wheel friction, workpieces mass, center of gravity and energy consumption during trajectory execution. In general, mobile robots are electrically driven. Hence, an estimation of the battery state is essential in order to automatically plan charging cycles and to organize and optimize the cooperation behavior of a group of mobile robots. In this proposed approach, mobile robots are equipped with a measurement system and connected via Bluetooth to a factory hub, providing monitoring, analyzing and planning tools. The battery states of all robots are considered in the process planning. The robots are based on the \{KUKA\} youBot, equipped with a soft gripper and a RealSense camera. A condition monitoring system measures the energy consumption of all components and transfers the information to the factory hub. The state of charge limits the number of executable operations. Therefore, in a first step the power consumption of all individual consumers is captured, e.g. EC-Maxxon base motors, PC, gripper, camera and five-axis arm. Experimental results show, that the youBot requires 46 W in standstill plus the drive power depending on the movement. Here, the results for mobile manipulation in industrial scenarios during preparation for the RoboCup@Work 2016 will be presented. The transfer of raw measurement data to the hub is shown, as well as the proposed algorithms allowing for range prediction and optimized set point generation. The concept provides excellent capability in data collection, analysis of existing production and production planning. "
}
@article{MattaGómez2014305,
title = "Multi-robot data mapping simulation by using microsoft robotics developer studio ",
journal = "Simulation Modelling Practice and Theory ",
volume = "49",
number = "",
pages = "305 - 319",
year = "2014",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2014.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X14001543",
author = "Antonio Matta-Gómez and Jaime Del Cerro and Antonio Barrientos",
keywords = "Service Oriented Computing (SOC)",
keywords = "Multi-robot systems",
keywords = "Data mapping",
keywords = "Robotics frameworks",
keywords = "Microsoft robotics developer studio ",
abstract = "Abstract This document summarizes the goals achieved in the development of a data mapping application, for a multi-robot system, implemented as a service with the guidelines found in the Service Oriented Computing paradigm (SOC). The obtained service generates both local and global maps in the reconstruction of a virtual scenario: the local maps represent the surrounding area around each one of the mobile robots, and the global one the totality of the scenario where the robots move. The information of the global map is continuously updated by merging the data coming from the local maps by using a novel approach: each one of the maps manages a confidence level value that defines which of the data coming from the maps is worthy of being updated into the global one. This technique is not present in related work. The Microsoft Robotics Developer Studio framework was chosen for its implementation because of the advantages that this tool offers in the management of concurrent and distributed processes, typically found in both a robotics platform and in a multi-robot system. "
}
@article{Hung2017174,
title = "Development of a novel cloud-based multi-tenant model creation service for automatic virtual metrology ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "44",
number = "",
pages = "174 - 189",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301077",
author = "Min-Hsiung Hung and Yu-Yung Li and Yu-Chuan Lin and Chun-Fan Wei and Haw-Ching Yang and Fan-Tien Cheng",
keywords = "Automatic virtual metrology (AVM)",
keywords = "Multi-tenant",
keywords = "Cloud-based model creation service",
keywords = "VM model",
keywords = "CNC machine tool",
keywords = "Machining of wheel rim ",
abstract = "Abstract \{AVM\} (Automatic Virtual Metrology) is the highest-level technology for \{VM\} (Virtual Metrology) applications from the perspective of automation. Its various automatic capabilities could facilitate fast factory-wide deployment and operations of \{VM\} systems. \{AVM\} systems have been successfully applied to the semiconductor, TFT-LCD, solar-cell, and machining industries for on-line monitoring the production quality of workpieces. However, in its past industrial applications, the model creation (MC) functionality of the existing \{AVM\} system encountered several limitations, such as being a standalone application and confined to be used in situ in a factory, no support for multiuser model creation, wasting computing resources, etc., which could diminish the applicability of the existing \{AVM\} system in current global and distributed manufacturing environments. Thus, this paper is dedicated to tackling the problem of how to systematically and effectively overcome MC-related limitations of the existing \{AVM\} system so that it can robustly support multiple users across factories to create their \{VM\} models simultaneously in distributed manufacturing settings. By leveraging the advantages of cloud computing and several \{IT\} technologies (including virtualization software, XML, Web Service, Multi-tenancy technique, and HTML5), this paper proposes a novel cloud-based multi-tenant model creation service (i.e., CMMCS) for AVM. The proposed \{CMMCS\} contains a cloud-based system architecture, functional frameworks of its key components, several functional mechanisms, and HTML5-based Web GUIs. Testing results in an industrial case study that creates \{VM\} models using the \{CMMCS\} for \{CNC\} machine tools in machining wheel rims of automobiles in a factory in Taiwan demonstrate that the \{CMMCS\} can allow multiple users from different tenants to simultaneously create their \{VM\} models, while enabling the \{MC\} cloud services to be more robust for processing \{MC\} requests, having higher CPU-usage rates in the underlying virtual machines, and achieving better cross-platform usage, compared to the original \{MC\} functionality. This paper has provided a feasible solution to systematically and effectively remedying the MC-related limitations of the existing \{AVM\} system. The existing VM-related literature mainly focused on the development of \{VM\} models. To our knowledge, no papers have coped with issues addressed in this paper by leveraging cloud computing. The results of this paper can be a useful reference for industrial practitioners to construct \{AVM\} systems which support multi-tenant or multiuser model creation. "
}
@article{Holder2016383,
title = "Robotics and law: Key legal and regulatory implications of the robotics age (Part I of II) ",
journal = "Computer Law & Security Review ",
volume = "32",
number = "3",
pages = "383 - 402",
year = "2016",
note = "",
issn = "0267-3649",
doi = "https://doi.org/10.1016/j.clsr.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0267364916300358",
author = "Chris Holder and Vikram Khurana and Faye Harrison and Louisa Jacobs",
keywords = "Robots and law",
keywords = "Autonomous vehicles and law",
keywords = "Healthcare robots and law",
keywords = "Data protection issues in robotics",
keywords = "Intellectual property issues in robotics",
keywords = "Consumer protection issues in robotics",
keywords = "Robotics and commercial contracting ",
abstract = "Abstract In this edition, we explore some of the legal, regulatory and ethical implications of robots and robotic systems and applications. We begin by giving our view of why this emerging technology will become increasingly prevalent and why it is important that lawyers and regulators play an important role in its development. We go on to address the key legal, regulatory and ethical issues in respect of specific types of robotics, including automated vehicles and healthcare robots. We also focus on the impact that robotics will have on core legal practice areas, including data protection, intellectual property, consumer protection and commercial contracting. Our objective is to identify the key legal and regulatory implications of robotics, and to start a dialogue about how our existing legal framework might need to adapt and change to meet the demands of the robotics age. In the next edition, we will continue our focus on key legal issues in respect of different types of robotics and core legal practice areas relevant to the discussion. "
}
@article{Chibani20131162,
title = "Ubiquitous robotics: Recent challenges and future trends ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1162 - 1172",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000572",
author = "Abdelghani Chibani and Yacine Amirat and Samer Mohammed and Eric Matson and Norihiro Hagita and Marcos Barreto",
keywords = "Ubiquitous robots",
keywords = "Networked robots",
keywords = "Ambient intelligence",
keywords = "Cloud robotics ",
abstract = "Abstract Ambient intelligence, ubiquitous and networked robots, and cloud robotics are new research hot topics that have started to gain popularity among the robotics community. They enable robots to acquire richer functionalities and open the way for the composition of a variety of robotic services with three functions: semantic perception, reasoning and actuation. Ubiquitous robots (ubirobots) overcome the limitations of stand-alone robots by integrating them with web services and ambient intelligence technologies. The overlap that exists now between ubirobots and ambient intelligence makes their integration worthwhile. It targets to create a hybrid physical–digital space rich with a myriad of proactive intelligent services that enhance the quality and the way of our living and working. Furthermore, the emergence of cloud computing initiates the massive use of a new generation of ubirobots that enrich their cognitive capabilities and share their knowledge by connecting themselves to cloud infrastructures. The future of ubirobots will certainly be open to an unlimited space of applications such as physical and virtual companions assisting people in their daily living, ubirobots that are able to co-work alongside people and cooperate with them in the same environment, and physical and virtual autonomic guards that are able to protect people, monitor their security and safety, and rescue them in indoor and outdoor spaces. This paper introduces the recent challenges and future trends on these topics. "
}
@article{Rausch201733,
title = "Kinematics chain based dimensional variation analysis of construction assemblies using building information models and 3D point clouds ",
journal = "Automation in Construction ",
volume = "75",
number = "",
pages = "33 - 44",
year = "2017",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516304733",
author = "Christopher Rausch and Mohammad Nahangi and Carl Haas and Jeffrey West",
keywords = "Dimensional variability",
keywords = "Kinematics chains",
keywords = "Robotics",
keywords = "Laser scanning",
keywords = "Building information model",
keywords = "Tolerance",
keywords = "Discrepancy and deviation ",
abstract = "Abstract As modern methods of construction progressively incorporate more facets of manufacturing, design optimization tools used in manufacturing can be adopted into construction to solve complex challenges. The specification and control of dimensions and geometry of construction assemblies is one such challenge that can be solved using tools from manufacturing. Even with building information models (BIM) to assist with clash detection for identifying potential dimensional problems, or the use of tolerances to control critical features in an assembly, dimensional variability is still a complex challenge to address in construction. This paper explores the use of a dimensional variation analysis (DVA), which is a design optimization tool from the manufacturing industry. This paper presents a \{DVA\} approach which is based on kinematics theory in robotics to define the assembly equation (how components are dimensionally related to each other). A case study is used to validate the proposed framework through two distinct approaches: (1) an as-designed (model-based) \{DVA\} and (2) an as-built (laser-based) DVA. Comparison of these two methods resulted in a percent difference less than 1% which demonstrates the reliability of using the model-based method for designing critical construction components. "
}
@article{Hallawi20171,
title = "Multi-Capacity Combinatorial Ordering \{GA\} in Application to Cloud resources allocation and efficient virtual machines consolidation ",
journal = "Future Generation Computer Systems ",
volume = "69",
number = "",
pages = "1 - 10",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16304630",
author = "Huda Hallawi and Jörn Mehnen and Hongmei He",
keywords = "Cloud resources allocation",
keywords = "Cloud resources provisioning",
keywords = "Virtual machines consolidation",
keywords = "Vector bin packing",
keywords = "Genetic algorithm ",
abstract = "Abstract This paper describes a novel approach making use of genetic algorithms to find optimal solutions for multi-dimensional vector bin packing problems with the goal to improve cloud resource allocation and Virtual Machines (VMs) consolidation. Two algorithms, namely Combinatorial Ordering First-Fit Genetic Algorithm (COFFGA) and Combinatorial Ordering Next Fit Genetic Algorithm (CONFGA) have been developed for that and combined. The proposed hybrid algorithm targets to minimise the total number of running servers and resources wastage per server. The solutions obtained by the new algorithms are compared with latest solutions from literature. The results show that the proposed algorithm \{COFFGA\} outperforms other previous multi-dimension vector bin packing heuristics such as Permutation Pack (PP), First Fit (FF) and First Fit Decreasing (FFD) by 4%, 34%, and 39%, respectively. It also achieved better performance than the existing genetic algorithm for multi-capacity resources virtual machine consolidation (RGGA) in terms of performance and robustness. A thorough explanation for the improved performance of the newly proposed algorithm is given. "
}
@article{Mateo20131239,
title = "Scalable Adaptive Group Communication for Collaboration Framework of Cloud-enabled Robots ",
journal = "Procedia Computer Science ",
volume = "22",
number = "",
pages = "1239 - 1248",
year = "2013",
note = "17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - \{KES2013\} ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2013.09.211",
url = "http://www.sciencedirect.com/science/article/pii/S1877050913010041",
author = "Romeo Mark A. Mateo",
keywords = "Cloud computing",
keywords = "Cloud robotics",
keywords = "Group communications ",
abstract = "Abstract Recently, researchers have been exploring the idea of robots that rely on cloud-computing infrastructure to take advantage of processing power and access vast amounts of data. This approach allows a robot to delegate compute-intensive tasks like image recognition, graphical mapping systems and etc. However, the efficient information sharing of cloud-enabled robots is not addressed which is necessary in disseminating real time information. In this paper, a collaboration framework is presented which is designed for information sharing of cloud-enabled robots. Based on attributes, cloud-enabled robots form logical groups to perform information sharing through the Internet. To provide a faster way of disseminating messages, a scalable adaptive group communication (SAGC) is proposed. The logical groups are processed using fuzzy system to employ scalable grouping, and then, the logical links are adjusted by a node link weight function based on Brownian agent to direct the queries to robots with relevant information. The performance evaluation showed that the \{SAGC\} had the fastest response to queries compared to other group communication methods. "
}
@article{Yang201756,
title = "Cognitive-affective regulation process for micro-expressions based on Gaussian cloud distribution ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "2",
number = "1",
pages = "56 - 61",
year = "2017",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2016.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S246823221630107X",
author = "Xiujun Yang and Lun Xie and Jing Han and Zhiliang Wang",
keywords = "Micro-expression",
keywords = "Cognitive-affective regulation",
keywords = "Gaussian cloud distribution",
keywords = "Transferring probability",
keywords = "Emotional intensity ",
abstract = "Abstract In this paper, we explore the process of emotional state transition. And the process is impacted by emotional state of interaction objects. First of all, the cognitive reasoning process and the micro-expressions recognition is the basis of affective computing adjustment process. Secondly, the threshold function and attenuation function are proposed to quantify the emotional changes. In the actual environment, the emotional state of the robot and external stimulus are also quantified as the transferring probability. Finally, the Gaussian cloud distribution is introduced to the Gross model to calculate the emotional transitional probabilities. The experimental results show that the model in human–computer interaction can effectively regulate the emotional states, and can significantly improve the humanoid and intelligent ability of the robot. This model is consistent with experimental and emulational significance of the psychology, and allows the robot to get rid of the mechanical emotional transfer process. "
}
@article{Fylaktopoulos2017,
title = "A distributed modular platform for the development of cloud based applications ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.035",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302716",
author = "G. Fylaktopoulos and M. Skolarikis and I. Papadopoulos and G. Goumas and A. Sotiropoulos and I. Maglogiannis",
keywords = "Cloud based development",
keywords = "Model Driven Development",
keywords = "Cloud Integrated Development Environment ",
abstract = "Abstract In this paper we describe the \{CIRANO\} platform, a modular Integrated Development Environment (IDE) for cloud based applications. The proposed platform is built to support Model Driven Development (MDD) and team collaboration, facilitating the rapid development of advanced applications in the cloud. The paper presents at a first stage the state of the art in the field of cloud \{IDEs\} and describes the design, implementation and technical details of the \{CIRANO\} platform. The main features of the proposed platform are presented in two case studies concerning the development of an application from scratch and porting of an existing application. The paper discusses the findings in comparison with existing tools and proposes extensions of the platform as future work. "
}
@article{Li2017192,
title = "Multi-year ground-based observations of aerosol-cloud interactions in the Mid-Atlantic of the United States ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "188",
number = "",
pages = "192 - 199",
year = "2017",
note = "Advances in Atmospheric Light Scattering: Theory and Remote Sensing Techniques ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315303198",
author = "Siwei Li and Everette Joseph and Qilong Min and Bangsheng Yin",
keywords = "Aerosols",
keywords = "Aerosol-cloud interaction",
keywords = "Cloud droplet effective radius",
keywords = "Cloud optical depth",
keywords = "Fine particles ",
abstract = "Abstract The U.S. Mid-Atlantic region experiences a wide variability of aerosol loading and frequent episodes of elevated anthropogenic aerosol loading associated with urban pollution conditions during summer months. In this study, multi-year ground-based observations (2006 to 2010) of aerosol and cloud properties from passive, active and in situ measurements at an atmospheric measurement field station in the Baltimore–Washington corridor operated by Howard University were analyzed to examine aerosol indirect effect on single-layer warm clouds including cloud optical depth (COD), liquid water path (LWP), cloud droplet effective radius (Re) and cloud droplet number concentration (Nd) in this region. A greater occurrence of polluted episodes and cloud cases with smaller Re (&lt;7 µm) were found during the polluted year summers (2006, 2007 and 2008) than the clean year summers (2009 and 2010). The measurements of aerosol particulate matter with aerodynamic diameter≤2.5 µm (PM2.5) were used to represent the aerosol loading under cloudy conditions. Significant negative relationships between cloud droplet Re and PM2.5 were observed. Cloud cases were separated into clean and polluted groups based on the value of PM2.5. The cloud droplet Re was found proportional to \{LWP\} under clean conditions but weakly dependent on \{LWP\} under polluted conditions. The Nd was proportional to \{LWP\} under polluted condition but weakly dependent on \{LWP\} under clean conditions. Moreover, the effects of increasing fine aerosol particles on modifying cloud microphysical properties were found more significant under large \{LWP\} than small \{LWP\} in this region. "
}
@article{Saab201538,
title = "Partial mobile application offloading to the cloud for energy-efficiency with security measures ",
journal = "Sustainable Computing: Informatics and Systems ",
volume = "8",
number = "",
pages = "38 - 46",
year = "2015",
note = "Special Issue on Computing for a Greener Water/Energy/Emissions Nexus; edited by Carol J. Miller.andSpecial Issue on Green Mobile Cloud Computing (Green MCC); edited by Danielo G. Gomes, Rafael Tolosana-Calasanz, and Nazim Agoulmine. ",
issn = "2210-5379",
doi = "https://doi.org/10.1016/j.suscom.2015.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S2210537915000396",
author = "Salwa Adriana Saab and Farah Saab and Ayman Kayssi and Ali Chehab and Imad H. Elhajj",
keywords = "Offloading",
keywords = "Mobile cloud computing",
keywords = "Free sequence protocol",
keywords = "Energy efficiency",
keywords = "Power consumption ",
abstract = "Abstract Mobile applications are becoming computationally intensive nowadays due to the increasing convenience, reliance on, and sophistication of smartphones. Nevertheless, battery lifetime remains a major obstacle that prohibits the large-scale adoption of such apps. Mobile cloud computing is a promising solution whereby apps are partially processed in the cloud to minimize the overall energy consumption of smartphones. However, this will not necessarily save energy if there is no systematic mechanism to evaluate the effect of offloading an app onto the cloud. In this paper, we present a mathematical model that represents this energy consumption optimization problem. We propose an algorithm to dynamically solve the problem while taking security measures into account. We also propose the free sequence protocol (FSP) that allows for the dynamic execution of apps according to their call graph. Our experimental setup consists of an Android smartphone and a Java server in the cloud. The results demonstrate that our approach saves battery lifetime and enhances performance. They also show the effects of workload amount, network type, computation cost, security operations, signal strength, and call graph structure on the optimized overall energy consumption. "
}
@article{Schlechtendahl201789,
title = "Extended study of network capability for cloud based control systems ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "43",
number = "",
pages = "89 - 95",
year = "2017",
note = "Special Issue: Extended Papers Selected from \{FAIM\} 2014 ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515001246",
author = "Jan Schlechtendahl and Felix Kretschmer and Zhiqian Sang and Armin Lechler and Xun Xu",
keywords = "Cloud based manufacturing",
keywords = "Cyber physical system",
keywords = "Realtime communication ",
abstract = "Abstract Current control systems are limited from a technical viewpoint in areas such as scalability, start-up and reconfiguration time and computational complexity for algorithms. These limitations call for a new concept for control systems to address current and future requirements. It has been suggested that the physical location of the control system be moved from that of the machine to a cloud, i.e. control system as a service (CSaaS). In this way, the control system becomes scalable and can handle highly complex computational tasks while keeping the process know-hows. Utilizing capabilities of modern Wide Area Network (WAN) and Local Area Network (LAN) the control system can be connected with the rest of the machine, e.g. drives, sensors, devices and HMI. This approach, however, presents new challenges, i.e. the requirement for integration of network, cloud computing and control system expertize. This paper will focus on the requirements of the communication for a cloud based control system. "
}
@article{Shukla2016508,
title = "Application of robotics in offshore oil and gas industry— A review Part \{II\} ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "508 - 524",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002018",
author = "Amit Shukla and Hamad Karki",
keywords = "Robotics",
keywords = "Automation",
keywords = "Underwater manipulator",
keywords = "Underwater welding",
keywords = "Production structure",
keywords = "NDT",
keywords = "ROV",
keywords = "AUV",
keywords = "WSN",
keywords = "Oil spill ",
abstract = "Abstract Demands for oil and gas are increasing with urbanization and industrialization of the world’s increasing population. Giant oil fields are declining in their production worldwide and this situation is creating need for search of new conventional and non-conventional fossil reserves. With steep depletion of major onshore and shallow-water-offshore oil fields new search of fossil fuel is moving towards deep-water and ultra-deep water offshore fields. Obviously new reserves are located in extreme, hostile and hard-to-reach environmental conditions. Exploration, development and production of oil from such difficult offshore fields have many serious challenges to health, safety and environment (HSE) therefore, require sophisticated technological innovations to support increasing energy demand. Biggest oil spill accidents in explosion of Deepwater Horizon offshore oil platform are burning example of such challenges which human society cannot risk to repeat. Therefore, development of advance drilling system, more accurate and intelligent inspection mechanism, faster responsive system in cases of unfortunate incidence and efficient damage control system is need of the safer future. Successful implementation of robotics, in space and manufacturing industry, is an critical example of how robotic assistance and automation is the only option for safe and cost-effective production of oil in foreseeable future. Teleoperation of unmanned drilling and production platforms, remote operated vehicles (ROVs), autonomous underwater vehicles (AUVs), under-water welding, welding robots for double hulled ships and under-water manipulator are such key robotic technologies which have facilitated smooth transition of offshore rigs from shallow waters to ultra-deep waters in modern time. Considering the sensitivity of product and difficulty of environment, most of these technologies fall under semi-autonomous category, where human operator is in loop for providing cognitive assistance to the overall operation for safe execution. This paper summarizes the key robotic technologies currently used in offshore oil and gas facilities. "
}
@article{Ayari201617,
title = "A semantic approach for enhancing assistive services in ubiquitous robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "17 - 27",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.10.022",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003121",
author = "Naouel Ayari and Abdelghani Chibani and Yacine Amirat and Eric Matson",
keywords = "Intelligent assistive services",
keywords = "Ubiquitous robotics",
keywords = "Multi-agents",
keywords = "Ontologies",
keywords = "Symbolic modeling and reasoning ",
abstract = "Abstract The Ambient Intelligence (AmI) technologies have the potential to create intelligent environments with new generation of assistive services, enhanced with ubiquitous robots. These environments have the ability to be anticipatory, responsive and intelligent providers of assistive services anytime and anywhere. These services can assist frail persons effectively in their daily tasks. One of the main challenging research problems in assistive robotics is to endow ubiquitous robots with ability to pro-actively taking on some tasks to help humans in performing complex activities, by participating with them just as other humans do, in normal societies or organizations. In this paper, we propose a collective intelligence framework based on narrative reasoning and natural language processing. In the proposed approach, we propose a hybrid model that bridges together the Narrative Knowledge Representation Language (NKRL), from natural language processing field, and the \{HARMS\} (Humans, software Agents, Robots, Machines and Sensors) model, from multi-agent systems engineering field. This model is able to (i) drive the dialogues between humans, robots and smart devices, (ii) understand a complex situation, and (iii) trigger reactive actions, in the ubiquitous environment, according to given contexts. Two scenarios dedicated to the assistance of a frail person in a smart home equipped with a companion robot and smart objects are implemented and discussed for validation purposes of the proposed framework. "
}
@article{Zehe2015157,
title = "\{SEMSim\} Cloud Service: Large-scale urban systems simulation in the cloud ",
journal = "Simulation Modelling Practice and Theory ",
volume = "58, Part 2",
number = "",
pages = "157 - 171",
year = "2015",
note = "Special issue on Cloud Simulation ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X15000805",
author = "Daniel Zehe and Alois Knoll and Wentong Cai and Heiko Aydt",
keywords = "Simulation",
keywords = "Cloud-based simulation",
keywords = "Performance evaluation",
keywords = "Urban systems simulations",
keywords = "High performance computing",
keywords = "Traffic simulation",
keywords = "Agent-based simulation ",
abstract = "Abstract Large-scale urban systems simulations are complex and with a large number of active simulation entities the computational workload is extensive. Workstation computers have only limited capabilities of delivering results for large-scale simulations. This leads to the problem that many researchers and engineers have to either reduce the scope of their experiments or fail to execute as many experiments as they would like in a given time frame. The use of high-performance computing (HPC) infrastructure offers a solution to the problem. Users of such simulations are often domain experts with no or little experience with \{HPC\} environments. In addition users do not necessarily have access to an HPC. In this paper we propose an architecture for a cloud-based urban systems simulation platform which specifically aims at making large-scale simulations available to typical users. The proposed architecture also addresses the issue of data confidentiality. In addition we describe the Scalable Electro-Mobility Simulation (SEMSim) Cloud Service that implements the proposed architecture. "
}
@article{Choe20141130,
title = "Online urban object recognition in point clouds using consecutive point information for urban robotic missions ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1130 - 1152",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000815",
author = "Yungeun Choe and Seunguk Ahn and Myung Jin Chung",
keywords = "Urban object recognition",
keywords = "Online",
keywords = "Generative model",
keywords = "LIDAR",
keywords = "Point cloud",
keywords = "Urban environment ",
abstract = "Abstract Urban object recognition is the ability to categorize ambient objects into several classes and it plays an important role in various urban robotic missions, such as surveillance, rescue, and SLAM. However, there were several difficulties when previous studies on urban object recognition in point clouds were adopted for robotic missions: offline-batch processing, deterministic results in classification, and necessity of many training examples. The aim of this paper is to propose an urban object recognition algorithm for urban robotic missions with useful properties: online processing, classification results with probabilistic outputs, and training with a few examples based on a generative model. To achieve this, the proposed algorithm utilizes the consecutive point information (CPI) of a 2D \{LIDAR\} sensor. This additional information was useful for designing an online algorithm consisting of segmentation and classification. Experimental results show that the proposed algorithm using \{CPI\} enhances the applicability of urban object recognition for various urban robotic missions. "
}
@article{Huang201530,
title = "Development of cloud-based automatic virtual metrology system for semiconductor industry ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "34",
number = "",
pages = "30 - 43",
year = "2015",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000186",
author = "Hsien-Cheng Huang and Yu-Chuan Lin and Min-Hsiung Hung and Chia-Chun Tu and Fan-Tien Cheng",
keywords = "Automatic virtual metrology (AVM)",
keywords = "Factory-wide deployment",
keywords = "Cloud computing",
keywords = "Virtualization",
keywords = "Production quality prediction of wafer",
keywords = "Cloud-based \{AVM\} system ",
abstract = "Abstract Automatic virtual metrology (AVM) is the highest-level technology for virtual metrology (VM) applications from the perspective of automation, which could facilitate fast factory-wide deployment of \{VM\} systems. However, the existing \{AVM\} system suffered several limitations during its practical deployment and operation in a fab for semiconductor manufacturing. In this paper, by leveraging the advantages of cloud computing, we propose an approach of building cloud-based \{AVM\} systems, which can effectively resolve these limitations. First, a cloud-based architecture is designed based on a private cloud to virtualize all servers of the \{AVM\} system for resolving the limitations of using physical servers, such as incurring high hardware cost, occupying a lot of shop-floor space, and needing complex efforts in managing \{VM\} servers. Then, three automatic functional mechanisms (i.e., automatic-deployment mechanism, automatic-scaling mechanism, and automatic-serving mechanism) are developed in an extra server (i.e., the virtual machine administrator server) to automate the deployment of \{VM\} servers, to automatically scale out/in the number of \{VM\} servers on demand, and to automatically dispatch \{VM\} servers to serve the requested \{VM\} tasks in parallel. Such an architecture design could significantly reduce the efforts of migrating the original \{AVM\} system to the cloud. Integrated testing results show that the proposed cloud-based \{AVM\} system could successfully overcome the limitations of the existing \{AVM\} system, while demonstrating a significant performance improvement over the existing \{AVM\} system in predicting the production quality of wafers. Most existing VM-related literature focused on the development of the \{VM\} models. To our knowledge, no papers have coped with the issues of plant-wide deployment and operation of \{VM\} systems by using cloud computing. This paper could be a useful reference for industrial practitioners to construct cloud-based \{AVM\} systems. "
}
@article{Newhall201753,
title = "Pervasive parallel and distributed computing in a liberal arts college curriculum ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "105",
number = "",
pages = "53 - 62",
year = "2017",
note = "Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing ",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2017.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0743731517300114",
author = "Tia Newhall and Andrew Danner and Kevin C. Webb",
keywords = "\{CS\} curriculum",
keywords = "Parallel and distributed computing ",
abstract = "Abstract We present a model for incorporating parallel and distributed computing (PDC) throughout an undergraduate \{CS\} curriculum. Our curriculum is designed to introduce students early to parallel and distributed computing topics and to expose students to these topics repeatedly in the context of a wide variety of \{CS\} courses. The key to our approach is the development of a required intermediate-level course that serves as an introduction to computer systems and parallel computing. It serves as a requirement for every \{CS\} major and minor and is a prerequisite to upper-level courses that expand on parallel and distributed computing topics in different contexts. With the addition of this new course, we are able to easily make room in upper-level courses to add and expand parallel and distributed computing topics. The goal of our curricular design is to ensure that every graduating \{CS\} major has exposure to parallel and distributed computing, with both a breadth and depth of coverage. Our curriculum is particularly designed for the constraints of a small liberal arts college, however, much of its ideas and its design are applicable to any undergraduate \{CS\} curriculum. "
}
@article{Chao201546,
title = "Cloud E-learning for Mechatronics: \{CLEM\} ",
journal = "Future Generation Computer Systems ",
volume = "48",
number = "",
pages = "46 - 59",
year = "2015",
note = "Special Section: Business and Industry Specific Cloud ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2014.10.033",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X14002271",
author = "Kuo-Ming Chao and Anne E. James and Antonios G. Nanos and Jen-Hsiang Chen and Sergiu-Dan Stan and Ionut Muntean and Giorgio Figliolini and Pierluigi Rea and Chedli B. Bouzgarrou and Pavel Vitliemov and Joshua Cooper and Jürgen van Capelle",
keywords = "Cloud computing",
keywords = "Mechatronics",
keywords = "E-learning",
keywords = "Remote virtual laboratories",
keywords = "Community",
keywords = "Ecosystem ",
abstract = "Abstract This paper describes results of the \{CLEM\} project, Cloud E-learning for Mechatronics. \{CLEM\} is an example of a domain-specific cloud that is especially tuned to the needs of \{VET\} (Vocational, Education and Training) teachers. An interesting development has been the creation of remote laboratories in the cloud. Learners can access such laboratories to support their practical learning of mechatronics without the need to set up laboratories at their own institutions. The cloud infrastructure enables multiple laboratories to come together virtually to create an ecosystem for educators and learners. From such a system, educators can pick and mix materials to create suitable courses for their students and the learners can experience different types of devices and laboratories through the cloud. The paper provides an overview of this new cloud-based e-learning approach and presents the results. The paper explains how the use of cloud computing has enabled the development of a new method, showing how a holistic e-learning experience can be obtained through use of static, dynamic and interactive material together with facilities for collaboration and innovation. "
}
@article{Donoso2017147,
title = "How do \{ICP\} variants perform when used for scan matching terrain point clouds? ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "147 - 161",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016301282",
author = "F.A. Donoso and K.J. Austin and P.R. McAree",
keywords = "Iterative closest point",
keywords = "Terrain mapping",
keywords = "Point cloud registration algorithms ",
abstract = "Abstract Many variants of the Iterative Closest Point (ICP) algorithm have been proposed for registering point clouds. This paper explores the performance of 20,736 \{ICP\} variants applied to the registration of point clouds for the purpose of terrain mapping, using data obtained from a mobile platform. The methodology of the study has involved taking sequences of 100 consecutive scans at three distinct scenes along the route of a mining haul truck operating in a typical surface mining environment. The scan sequences were obtained at 20 Hz from a Velodyne HDL-64E mounted on the truck. The aim is to understand how well the \{ICP\} variants perform in consolidating these scans into sub-maps. Variants are compared against three metrics: accuracy, precision, and relative computational cost. The main finding of the paper is that none of the variants is simultaneously accurate, precise, and fast to compute, across all three scenes. The best performing variants employed strategies that filtered the data sets, used local surface geometry in the form normals, and used the distance between points in one point cloud to a corresponding surface from a reference point cloud as a measure of the fit between two point clouds. The significance of this work is that it: (i) provides guidance in the construction of \{ICP\} variants for terrain mapping; and (ii) identifies the significant limitations of existing \{ICP\} variants for this application. "
}
@article{Manfredi2016120,
title = "Autonomous Apartment Exploration, Modelling and Segmentation for Service Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "120 - 125",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.719",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316309958",
author = "Guido Manfredi and Sandra Devin and Michel Devy and Daniel Sidobre",
keywords = "Autonomous",
keywords = "Exploration",
keywords = "Modeling",
keywords = "Segmentation",
keywords = "Service Robotics ",
abstract = "Abstract This work proposes a full pipeline for a robot to explore, model and segment an apartment from a 2-D map. Viewpoints are found offline and then visited by the robot to create a 3-D model of the environment. This model is segmented in order to find the various rooms and how they are linked (windows, doors, walls) yielding a topological map. Moreover areas of interest are also segmented, in this case furniture’s planar surfaces. The method is validated on a realistic three rooms apartment. Results show that, despite occlusion, autonomous exploration and modeling covers 95% of the apartment. For the segmentation part, 1 link out of 14 is wrongly classified while all the existing areas of interest are found. "
}
@article{Chen2017347,
title = "Operation Mode Study in Cloud Manufacturing Ecosystem ",
journal = "Procedia \{CIRP\} ",
volume = "61",
number = "",
pages = "347 - 352",
year = "2017",
note = "The 24th \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.154",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116313142",
author = "Shengkai Chen and Shuiliang Fang and Tao Peng and Renzhong Tang",
keywords = "Cloud manufacturing ecosystem",
keywords = "decision-making",
keywords = "operation mode",
keywords = "ecosystem evolution",
keywords = "agent-based simulation ",
abstract = "Abstract With cloud manufacturing and its shared big-data, the life-cycle management of the massive distributed manufacturing resources can be considered as an ecosystem, in which every entity makes their own decisions depend on the enriched information, which will affect the life cycle of the resources and the overall industry states. In this paper, an original operation mode with three extensions are proposed to describe the life cycle vicissitude of each resource. An agent-based model was designed to simulate the ecosystem modes from the very beginning, and the results show that the ecosystem has: 1) shorter job queue length and lower resource idle rate with incubation mode; 2) a little shorter job queue length and fewer amount of registered resource with outsourcing mode; 3) the fewest amount of registered resource but a little higher resource idle rate with metabolism mode. "
}
@article{JafariNavimipour201565,
title = "Behavioral modeling and automated verification of a Cloud-based framework to share the knowledge and skills of human resources ",
journal = "Computers in Industry ",
volume = "68",
number = "",
pages = "65 - 77",
year = "2015",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514002127",
author = "Nima Jafari Navimipour and Ahmad Habibizad Navin and Amir Masoud Rahmani and Mehdi Hosseinzadeh",
keywords = "Expert Cloud",
keywords = "Cloud computing",
keywords = "Model checking",
keywords = "System verification",
keywords = "Virtualization",
keywords = "Human knowledge ",
abstract = "Abstract Expert Cloud as a new class of Cloud computing systems by employing the Internet infrastructures and Cloud computing concepts enables its users to request the skill, knowledge and expertise of human resources without any information about their location. It makes the communication between the \{HRs\} more efficient, reduces the cost of service, increases the variety of knowledge and information, facilitates employment of the \{HR\} in organizations, decreases customer response time and improves the service delivery methods. However, one facet that is still being less cared and that may introduce potential errors and faults regards the architectural problems and components analysis of Expert Cloud. Therefore, in this paper, we verify and check the specification, composition and architecture of the Expert Cloud via NuSMV model checker, Argo \{UML\} and Rebeca Verifier tools. The approach extracts the checking properties in the form of \{LTL\} and \{CTL\} formulas of control behaviors and automatically verifies the properties in operational behaviors. Also, experimental results indicate that the system is reachable, fair and deadlock-free. "
}
@article{Cerroni201516,
title = "Cross-layer resource orchestration for cloud service delivery: A seamless \{SDN\} approach ",
journal = "Computer Networks ",
volume = "87",
number = "",
pages = "16 - 32",
year = "2015",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615001644",
author = "Walter Cerroni and Molka Gharbaoui and Barbara Martini and Aldo Campi and Piero Castoldi and Franco Callegati",
keywords = "Cloud computing",
keywords = "Software-defined networking",
keywords = "Service-oriented networks",
keywords = "Resource orchestration",
keywords = "Anycast service model ",
abstract = "Abstract One of the main challenges of cloud-based service provisioning is to deploy a coordinated control of both application- and network-layer resources in order to provide adaptive service data delivery and adequate user service experiences. In this work we propose a signaling framework architecture for cross-layer resource orchestration, where service awareness provided by session control is effectively combined with the flexibility of software-defined network control. Following a hands-on approach, the proposed solution takes advantage of existing and commonly deployed technologies aiming at an incremental deployment of the software-defined control mechanisms for the purpose of cross-functional service orchestration. The signaling framework is presented and validated through experimental activities carried out on a test-bed reproducing a realistic cloud-based service scenario. Results are compared against an analytical model that allows to investigate and quantify the sensitivity of the cloud-based service performance to the most relevant system parameters. The study demonstrates that a critical role is played by the limitations of the response time of real devices such as commercial routers, and highlights how orchestration functions can mitigate the effect of such limitations while addressing scalability of the overall system. "
}
@article{Vallecillos2016198,
title = "A cloud service for \{COTS\} component-based architectures ",
journal = "Computer Standards & Interfaces ",
volume = "48",
number = "",
pages = "198 - 216",
year = "2016",
note = "Special Issue on Information System in Distributed Environment ",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2015.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0920548915001415",
author = "Jesús Vallecillos and Javier Criado and Nicolás Padilla and Luis Iribarne",
keywords = "Cloud service",
keywords = "Software architectures",
keywords = "Component-based systems",
keywords = "COTS ",
abstract = "Abstract Software architecture management, especially in component-based web user interfaces is important to enhance their run-time accessibility, dynamics and management. The cloud offers some excellent mechanisms for this kind of systems, since software can be managed remotely, easy availability of the resources is ensured and mass storage is possible. This article presents an infrastructure solution, based on the use of web services and cloud computing, for managing COTS-based architectures. "
}
@incollection{Dastjerdi201661,
title = "Chapter 4 - Fog Computing: principles, architectures, and applications ",
editor = "Buyya, Rajkumar  and Dastjerdi, Amir Vahid ",
booktitle = "Internet of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2016",
pages = "61 - 75",
isbn = "978-0-12-805395-9",
doi = "https://doi.org/10.1016/B978-0-12-805395-9.00004-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053959000046",
author = "A.V. Dastjerdi and H. Gupta and R.N. Calheiros and S.K. Ghosh and R. Buyya",
keywords = "Internet of Things",
keywords = "IoT",
keywords = "Web of Things",
keywords = "Cloud of Things",
keywords = "Fog Computing",
keywords = "IoT applications",
keywords = "Edge Computing ",
abstract = "Abstract The Internet of Everything (IoE) solutions gradually bring every object online, and processing data in a centralized cloud does not scale to requirements of such an environment. This is because there are applications such as health monitoring and emergency response that require low latency, so delay caused by transferring data to the cloud and then back to the application can seriously impact the performance. To this end, Fog computing has emerged, where cloud computing is extended to the edge of the network to decrease the latency and network congestion. Fog computing is a paradigm for managing a highly distributed and possibly virtualized environment that provides compute and network services between sensors and cloud data centers. This chapter provides a background and motivations regarding the emergence of Fog computing, and defines its key characteristics. In addition, a reference architecture for Fog computing is presented, and recent related development and applications are discussed. "
}
@article{Dirican2015564,
title = "The Impacts of Robotics, Artificial Intelligence On Business and Economics ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "195",
number = "",
pages = "564 - 573",
year = "2015",
note = "World Conference on Technology, Innovation and Entrepreneurship ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2015.06.134",
url = "http://www.sciencedirect.com/science/article/pii/S1877042815036137",
author = "Cüneyt Dirican",
keywords = "Robots",
keywords = "Robotics",
keywords = "Artificial Intelligence",
keywords = "Hologram",
keywords = "Mecatronics",
keywords = "Business",
keywords = "Economics ",
abstract = "Abstract In the Industrial Age that humanity has entered long time ago with steam series has caused to primitive mechanization in production. With the development of internet and mobile technologies, electronics, nano technology, advances in medicine, health and digital applications and so on speed up mechatronics studies nowadays. Last World Economic Forum holds an important place on the agenda of Robotics and Artificial Intelligence and the economists like Roubini, Stiglitz also entered in the discussion of robotics and artificial in intelligence impacts on economics and business. Although Stephen Hawking criticized on the risks in this regard, every day we are witnessing tremendous news and articles in business pages, regarding on these topics and obviously corporate life and professionals can no longer resist to these changes. Changing form of the business terms and work forces, the way of doing business by using new technologies will have serious impacts on the daily business life and deriving from these on countries and on world economics. Many items and headlines such as jobless ratio, Philips Curve, performance, management, \{CRM\} Analytics, customer relationship management, sales, strategic planning, mass production, Purchasing Power Parity, GDP, inflation, money, Central Banks, Banking System, coaching, training, accounting, taxes etc. regarding to business and economics will face serious dangers, hits, change, exposures as well as opportunities and gains with the improvements in Artificial Intelligence and Robotics. One simple example can explain the degree of these impacts: Should we continue to make provisions for severance pay of the company's staff or should we calculate reserve for depreciation / amortization of robots in the company, which side of the balance sheet will be managed by human resources managers or shall we still name human resources ? This conceptual and hypothetical paper is aiming to address and discusses the future of robots, mechatronics and artificial intelligence in different perspectives. "
}
@article{Hernández2015977,
title = "Cloud Configuration Modelling: A Literature Review from an Application Integration Deployment Perspective ",
journal = "Procedia Computer Science ",
volume = "64",
number = "",
pages = "977 - 983",
year = "2015",
note = "Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2015 October 7-9, 2015 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.616",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915027519",
author = "Inma Hernández and Sandro Sawicki and Fabricia Roos-Frantz and Rafael Z. Frantz",
keywords = "Enterprise Application Integration",
keywords = "Optimisation",
keywords = "Cloud-computing",
keywords = "Cloud Service Model",
keywords = "Service Variability. ",
abstract = "Abstract Enterprise Application Integration has played an important role in providing methodologies, techniques and tools to develop integration solutions, aiming at reusing current applications and supporting the new demands that arise from the evolution of business processes in companies. Cloud-computing is part of a new reality in which companies have at their disposal a high-capacity \{IT\} infrastructure at a low-cost, in which integration solutions can be deployed and run. The charging model adopted by cloud-computing providers is based on the amount of computing resources consumed by clients. Such demand of resources can be computed either from the implemented integration solution, or from the conceptual model that describes it. It is desirable that cloud-computing providers supply detailed conceptual models describing the variability of services and restrictions between them. However, this is not the case and providers do not supply the conceptual models of their services. The conceptual model of services is the basis to develop a process and provide supporting tools for the decision-making on the deployment of integration solutions to the cloud. In this paper, we review the literature on cloud configuration modelling, and compare current proposals based on a comparison framework that we have developed. "
}
@incollection{LaurieLau201517,
title = "Chapter 2 - Cybercrime in cloud: Risks and responses in Hong Kong, Singapore ",
editor = "Ko, Ryan  and Choo, Kim-Kwang Raymond ",
booktitle = "The Cloud Security Ecosystem ",
publisher = "Syngress",
edition = "",
address = "Boston",
year = "2015",
pages = "17 - 35",
isbn = "978-0-12-801595-7",
doi = "https://doi.org/10.1016/B978-0-12-801595-7.00002-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780128015957000021",
author = "Yiu Chung Laurie Lau",
keywords = "Cloud computing",
keywords = "Hong Kong",
keywords = "Singapore",
keywords = "Key factors shaping “Response”",
keywords = "Mainlandization",
keywords = "Discussion ",
abstract = "Abstract The popularity and commercialization of the “Internetwork” began in the late 1990s through the interconnection of computer networks using special gateways or routers to transfer packets of electronic data. As with many things in life, Internetwork technology has had both positive and negative effects on society, and Asia has been no exception. One of the negative effects has been a surge in Internet crime. According to a report released by the Gartner Consulting Group, in 2013 smart phone sales exceeded regular phone sales for the first time, with 968 million smart phones sold, representing 54% of the global mobile phone total and an increase of 54% from 2012. The popularity and technology of the mobile Internetwork, especially the smart mobile phone web, has changed the Internetwork landscape through the concept of cloud computing. Cloud computing is distributed computing over a network, using a program or application that can run on many connected computers and in different locations around the globe simultaneously at a reduced cost. This distributed cloud computing presents law enforcement authorities with the unique challenge of policing Internet crime. Cloud computing relies on sharing resources to achieve coherence, and in doing so creates economies of scale for converged infrastructures and shared services. Accordingly, one problem facing the authorities is the presence of trans- and multijurisdictional crimes. In this chapter, I explore this topic in the contexts of Hong Kong and Singapore, as both are key players on the international stage, especially in relation to international finance and information technology. In both locations, infrastructure works to maintain global financial center status. The remainder of this chapter is organized as follows. A brief overview of the development of cloud computing is followed by an examination of cybercrime risks in the cloud. Then, I review how the authorities in Hong Kong and Singapore respond to cybercrime risks and explore the current government policies on cloud computing, particularly in fighting cybercrime. "
}
@article{Gharbaoui2016279,
title = "Cloud and network orchestration in \{SDN\} data centers: Design principles and performance evaluation ",
journal = "Computer Networks ",
volume = "108",
number = "",
pages = "279 - 295",
year = "2016",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2016.08.029",
url = "http://www.sciencedirect.com/science/article/pii/S1389128616302821",
author = "M. Gharbaoui and B. Martini and D. Adami and S. Giordano and P. Castoldi",
keywords = "Cloud",
keywords = "SDN",
keywords = "Orchestration",
keywords = "OpenFlow",
keywords = "Data Center network ",
abstract = "Abstract The oversubscription of Data Center network links and the high volatility of Virtual Machine (VM) deployments call for a flexible and agile control of Data Center networks, coordinated with computing resource control (i.e., cloud resource management). The Software-Defined Network (SDN) paradigm opens up new opportunities to design convergent resource management systems able to address the provisioning of cloud services while meeting dynamically changing traffic demands of running VMs. This paper presents the architectural design of an SDN-based orchestration system which is able to coordinate the provision of composite cloud and network services while assuring computational requirements as well as a better than best effort \{VM\} data delivery. The proposed orchestration system is able to perform \{VM\} allocations also based on estimations of switch/link and server loads as result of the synergistic interwork of the following functions: (i) resource selection and composition functions, (ii) coordinated resource configuration and management functions, (iii) monitoring and registration functions of resource status. A set of resource selection and composition strategies and estimation schemes have been also specified. The orchestration process has been thoroughly evaluated through a comprehensive set of simulations that clearly show an increasing acceptance rate of service requests, an improved utilization of network capabilities while effectively preventing significant degradations of the user experience despite the oversubscription of data center network links. "
}
@article{Golightly201612,
title = "Manufacturing in the cloud: A human factors perspective ",
journal = "International Journal of Industrial Ergonomics ",
volume = "55",
number = "",
pages = "12 - 21",
year = "2016",
note = "",
issn = "0169-8141",
doi = "https://doi.org/10.1016/j.ergon.2016.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0169814116300464",
author = "David Golightly and Sarah Sharples and Harshada Patel and Svetan Ratchev",
keywords = "Cloud manufacturing",
keywords = "Assembly",
keywords = "Production",
keywords = "Collaboration ",
abstract = "Abstract Cloud manufacturing adopts a cloud computing paradigm as the basis for delivering shared, on-demand manufacturing services. The result is customer-centric supply chains that can be configured for cost, quality, speed and customisation. While the technical capabilities required for cloud manufacturing are a current focus, there are many emerging questions relating to the impact, both positive and negative, on the people consuming or supporting cloud manufacturing services. Human factors can have a pivotal role in enabling the success and adoption of cloud manufacturing, while ensuring the safety, well-being and optimum user experience of those involved in a cloud manufacturing environment. This paper presents these issues, structured around groups of users (service providers, application providers and consumers). We also consider the issues of collaboration that are likely to arise from the manufacturing cloud. From this analysis we discuss the central role of human factors as an enabler of cloud manufacturing, and the opportunities that emerge. "
}
@article{Bueno2016264,
title = "Evaluation of point cloud registration using Monte Carlo method ",
journal = "Measurement ",
volume = "92",
number = "",
pages = "264 - 270",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2016.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S0263224116303116",
author = "M. Bueno and H. González-Jorge and J. Martínez-Sánchez and L. Díaz-Vilariño and P. Arias",
keywords = "Point cloud registration",
keywords = "ICP",
keywords = "Monte Carlo",
keywords = "SLAM ",
abstract = "Abstract Supervision and control are one of the most important steps while executing a construction project and their automation remains an area of growing interest. LiDAR systems provide accurate point clouds with geometric information that can help to improve the automation of survey control. Alignment of the point clouds acquired from a number of scan positions is a fundamental issue regarding surveying accuracy and is frequently carried out in two steps: coarse and fine registration. Fine registration can be achieved automatically by means of an Iterative Closest Point (ICP) procedure. This work presents a Monte Carlo based method to quantify the reliability of a coarse registration step that would enable the automation of the alignment. The method consists of verifying the tolerance of a particular \{ICP\} implementation to coarse registration errors. Results show that the \{ICP\} alignment used works fine when coarse registration errors are lower than 18° for rotations and 1 m for translations. These values were similar for four case studies analysed. Quantifying these limits is crucial for operations such as robotic stop &amp; go surveying, where coarse alignment is based on Simultaneous Location and Mapping (SLAM) and fine alignment is achieved through ICP. "
}
@article{Grieco201432,
title = "IoT-aided robotics applications: Technological implications, target domains and open issues ",
journal = "Computer Communications ",
volume = "54",
number = "",
pages = "32 - 47",
year = "2014",
note = "",
issn = "0140-3664",
doi = "https://doi.org/10.1016/j.comcom.2014.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0140366414002783",
author = "L.A. Grieco and A. Rizzo and S. Colucci and S. Sicari and G. Piro and D. Di Paola and G. Boggia",
keywords = "IoT",
keywords = "Robots",
keywords = "Robotics Applications",
keywords = "IoT security",
keywords = "Semantic consensus ",
abstract = "Abstract The ongoing revolution of Internet of Things (IoT), together with the growing diffusion of robots in many activities of every day life, makes IoT-aided robotics applications a tangible reality of our upcoming future. Accordingly, new advanced services, based on the interplay between robots and “things”, are being conceived in assisting humans. Nevertheless, the path to a mature development of IoT-aided robotics applications requires several pivotal issues to be solved, design methodologies to be consolidated, and strong architectural choices to be discussed. This paper discusses technological implications, open issues, and target applications in the IoT-aided robotics domain. In particular, the present contribution is four-folded. First, it provides a solid state of the art on the main topics related to IoT-aided robotics services: communication networks, robotics applications in distributed and pervasive environments, semantic-oriented approaches to consensus, and network security. Second, it highlights the most important research challenges to be faced. Third, it describes the technological tools available nowadays. Fourth, it summarizes lessons learned to foster a joint scientific investigation among research teams with complementary skills. "
}
@article{Kaaouache20151061,
title = "Solving bin Packing Problem with a Hybrid Genetic Algorithm for \{VM\} Placement in Cloud ",
journal = "Procedia Computer Science ",
volume = "60",
number = "",
pages = "1061 - 1069",
year = "2015",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.151",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915022784",
author = "Mohamed Amine Kaaouache and Sadok Bouamama",
keywords = "Genetic algorithms",
keywords = "Bin Packing",
keywords = "Heuristics",
keywords = "Infeasible solutions",
keywords = "Virtual machine placement",
keywords = "Cloud Computing ",
abstract = "Abstract The Bin Packing Problem's purpose (BPP) is to find the minimum number of bins needed to pack a given set of objects of known sizes so that they do not exceed the capacity of each bin. This problem is known to be NP- Hard. In this paper, we propose an hybrid genetic algorithm using \{BFD\} (Best Fit Decreasing) to deal with infeasible solution due to the bin-used representation. Experimental results showed the effectiveness of our approach for infeasible chromosomes thereby improving the quality of the obtained solution. This will give a good result for the virtual machine placement in Cloud to minimize energy since it looks like a BPP. "
}
@article{Cho2015442,
title = "A Framework for Cloud-based Energy Evaluation and Management for Sustainable Decision Support in the Built Environments ",
journal = "Procedia Engineering ",
volume = "118",
number = "",
pages = "442 - 448",
year = "2015",
note = "Defining the future of sustainability and resilience in design, engineering and construction ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.08.445",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815021001",
author = "Yong K. Cho and Haorong Li and JeeWoong Park and Keke Zheng",
keywords = "As-built modeling",
keywords = "cloud computing",
keywords = "Automated Building System",
keywords = "retrofit",
keywords = "energy ",
abstract = "Abstract This paper introduces a framework which can advance traditional building auditing and energy management methods in terms of cost, convenience of automatic and remote data (e.g., 3D geometry and thermal values) collection, system control, and comprehension and dissemination of results using a proposed cloud-based software as a service (CSaaS) system as a decision support tool. The decision support tool can help decision makers improve their buildings by providing reliable and visualized information of the building's energy performance through an easy-to-use interactive virtual evaluation system in a publicly accessible cyberspace. The proposed open decision-support platform is expected to ultimately reduce the public's energy consumption and invigorate the nation's economy by vitalizing sustainable product manufacture and retrofit construction industries. "
}
@article{Aubé201611,
title = "The spectral amplification effect of clouds to the night sky radiance in Madrid ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "181",
number = "",
pages = "11 - 23",
year = "2016",
note = "Using remote sensing to better understand light pollution (Light Pollution Theory Modelling and Measurements 2015) ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.01.032",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315301849",
author = "M. Aubé and M. Kocifaj and J. Zamorano and H.A. Solano Lamphar and A. Sanchez de Miguel",
keywords = "Sky brightness measurements",
keywords = "Cloud amplification factor",
keywords = "Spectrum",
keywords = "Artificial light at night ",
abstract = "Abstract Artificial Light at Night (ALAN) may have various environmental impacts ranging from compromising the visibility of astronomical objects to the perturbation of circadian cycles in animals and humans. In the past much research has been carried out to study the impact of \{ALAN\} on the radiance of the night sky during clear sky conditions. This was mainly justified by the need for a better understanding of the behavior of \{ALAN\} propagation into the environment in order to protect world-class astronomical facilities. More recently, alongside to the threat to the natural starry sky, many issues have emerged from the biological science community. It has been shown that, nearby or inside cities, the presence of cloud cover generally acts as an amplifier for artificial sky radiance while clouds behave as attenuators for remote observers. In this paper we show the spectral behavior of the zenith sky radiance amplification factor exerted by clouds inside a city. We compare in-situ measurements made with the spectrometer SAND-4 with a numerical model applied to the specific geographical context of the Universidad Complutense de Madrid in Spain. "
}
@article{Badescu2016254,
title = "Reconstruction of effective cloud field geometry from series of sunshine number ",
journal = "Atmospheric Research ",
volume = "176–177",
number = "",
pages = "254 - 266",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516300540",
author = "Viorel Badescu and Marius Paulescu and Marek Brabec",
keywords = "Cloud field geometry",
keywords = "Sunshine number",
keywords = "Point cloudiness ",
abstract = "Abstract A new method is proposed for extracting the parameters of effective cloud field models from time series of sunshine number (SSN). Data of \{SSN\} number and point cloudiness during 2009 and 2010 at Timisoara (Romania, South Eastern Europe; temperate continental climate) are used to illustrate the method. Two procedures of fitting the estimated point cloudiness to the observed point cloudiness data are proposed and tested. Seven simple effective cloud field models are analyzed. All models underestimate the point cloudiness. The \{MBE\} ranges between − 0.06 and − 0.23 while \{RMSE\} between 0.15 and 0.38, depending on the month and the duration of the \{SSN\} data averaging interval. The best model is based on a field of clouds of semicircle form. This agrees with previous results obtained in the semi-arid climate of Great South Plains in US. The dynamics of the effective cloud field is reconstructed during all months of 2010 at Timisoara. The time series of effective cloud fields are dominated by semicircle clouds but short episodes of semielliptic clouds, ellipsoid clouds, truncated cone clouds and cuboidal clouds are included in the series. "
}
@article{Buribayeva2015722,
title = "An Autonomous Emergency Warning System Based on Cloud Servers and \{SNS\} ",
journal = "Procedia Computer Science ",
volume = "60",
number = "",
pages = "722 - 729",
year = "2015",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.225",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915023522",
author = "Gulbanu Buribayeva and Taizo Miyachi and Azamat Yeshmukhametov and Yutaro Mikami",
keywords = "cloud computing",
keywords = "autonomous waning",
keywords = "disaster",
keywords = "sensors network",
keywords = "evacuation map ; ",
abstract = "Abstract There are no warning systems for earthquake, fire and gas disasters in Almaty (Kazakhstan). We propose an autonomous emergency warning system that provides useful awareness against unpredictable disasters. The system mainly consists of sensor network, disaster information mapping server, \{SNS\} module, and web server. When the system detects a disaster it distributes real-time warnings with levels of danger and signs of severe damages by the sensor data and \{GPS\} position to residents by both \{SNS\} (twitter) and the Website with Google maps including real-time safety places. We built a prototype system and could confirm the effectiveness of the warning system. "
}
@article{Sharma201663,
title = "Expanded cloud plumes hiding Big Data ecosystem ",
journal = "Future Generation Computer Systems ",
volume = "59",
number = "",
pages = "63 - 92",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16000054",
author = "Sugam Sharma",
keywords = "Cloud",
keywords = "Big Data",
keywords = "Smart Data and Lakes",
keywords = "IoT",
keywords = "XCLOUDX",
keywords = "as-a-Service ",
abstract = "Abstract Today, a paradigm shift is being observed in science, where the focus is gradually shifting away from operation to data, which is greatly influencing the decision making also. The data is being inundated proactively from several sources in various forms; especially social media and in modern data science vocabulary is being recognized as Big Data. Today, Big Data is permeating through the bigger aspect of human life for scientific and commercial dependencies, especially for massive scale data analytics of beyond the exabyte magnitude. As the footprint of Big Data applications is continuously expanding, the reliability on cloud environments is also increasing to obtain appropriate, robust and affordable services to deal with Big Data challenges. Cloud computing avoids any need to locally maintain the overly scaled computing infrastructure that include not only dedicated space, but the expensive hardware and software also. Several data models to process Big Data are already developed and a number of such models are still emerging, potentially relying on heterogeneous underlying storage technologies, including cloud computing. In this paper, we investigate the growing role of cloud computing in Big Data ecosystem. Also, we propose a novel \{XCLOUDX\} {XCloudX, X…X}classification to zoom in to gauge the intuitiveness of the scientific name of the cloud-assisted NoSQL Big Data models and analyze whether \{XCloudX\} always uses cloud computing underneath or vice versa. \{XCloudX\} symbolizes those NoSQL Big Data models that embody the term “cloud” in their name, where X is any alphanumeric variable. The discussion is strengthen by a set of important case studies. Furthermore, we study the emergence of as-a-Service era, motivated by cloud computing drive and explore the new members beyond traditional cloud computing stack, developed in the past couple of years. "
}
@article{RodríguezGarcía2014295,
title = "Creating a semantically-enhanced cloud services environment through ontology evolution ",
journal = "Future Generation Computer Systems ",
volume = "32",
number = "",
pages = "295 - 306",
year = "2014",
note = "Special Section: The Management of Cloud Systems, Special Section: Cyber-Physical Society and Special Section: Special Issue on Exploiting Semantic Technologies with Particularization on Linked Data over Grid and Cloud Architectures ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13001684",
author = "Miguel Ángel Rodríguez-García and Rafael Valencia-García and Francisco García-Sánchez and J. Javier Samper-Zapater",
keywords = "Semantic annotation",
keywords = "Ontology evolution",
keywords = "Cloud computing",
keywords = "Information extraction",
keywords = "Knowledge management",
keywords = "Ontology",
keywords = "Semantic web ",
abstract = "Abstract Currently, the availability of Web resources has grown enormously to the point that whatever a user needs at a given moment can potentially be found on the Internet. These resources are not limited to data items anymore, functionality delivered through some sort of service architectural model is also offered on the Internet. In the last few years, cloud computing has emerged as one of the most popular computing models to provide services over the Internet. However, as the number of available cloud services increases, the problem of service discovery and selection arises. Experience indicates that semantic technologies can provide the basis for enhanced and more precise search processes. In this paper, we present a platform that makes use of semantic technologies and techniques to facilitate the discovery of cloud resources meeting the users’ needs. We propose an architecture that puts together semantic annotation techniques, ontology evolution, term extraction and indexing resources to semantically annotate cloud services, and a semantic search engine that leverages the semantic description of the cloud resources to find them from keyword-based searches. A comprehensive evaluation of the tool in the \{ICT\} domain has produced very promising results and is also presented in this article. "
}
@article{Koutsovasilis2017,
title = "AcHEe: Evaluating Approximate Computing and Heterogeneity for Energy Efficiency ",
journal = "Parallel Computing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-8191",
doi = "https://doi.org/10.1016/j.parco.2017.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167819117300285",
author = "Panos Koutsovasilis and Christos Kalogirou and Christos Konstantas and Manolis Maroudas and Michalis Spyrou and Christos D. Antonopoulos",
keywords = "Benchmark Suite",
keywords = "Heterogeneous Computing",
keywords = "Approximate Computing",
keywords = "Energy efficiency ",
abstract = "Abstract Energy efficiency is lately a major concern for computer engineers, at the levels of both software and hardware. A popular path is the exploitation of heterogeneity and accelerator-based systems, which combine different architectures, each appropriate for specific computational patterns. Approximate computing is another aggressive, yet viable alternative; it minimizes the energy footprint of applications at the expense of output quality. We introduce AcHEe, a set of 12 applications – ranging from real-world applications to kernels – from different domains, exposing a wide range of characteristics, which have been modified to exploit both heterogeneity and approximations. The degree of approximation can be controlled at runtime. The implementation is based on OpenCL and is publicly available. We evaluate these applications on heterogeneous platforms (comprising of \{CPUs\} and GPUs) and quantify the isolated and combined effect of heterogeneous and approximate computing. AcHEe can serve as a benchmark suite, to evaluate current and future computational devices from the perspective of heterogeneity and approximations. At the same time, it can serve as a software platform to evaluate and compare different approximation techniques. "
}
@article{Wu201494,
title = "Cloud-based Manufacturing: Old Wine in New Bottles? ",
journal = "Procedia \{CIRP\} ",
volume = "17",
number = "",
pages = "94 - 99",
year = "2014",
note = "Variety Management in ManufacturingProceedings of the 47th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.01.035",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114002674",
author = "Dazhong Wu and David W. Rosen and Lihui Wang and Dirk Schaefer",
keywords = "cloud-based manufacturing",
keywords = "distributed manufacturing",
keywords = "cloud computing. ",
abstract = "Abstract Cloud-based manufacturing (CBM), also referred to as cloud manufacturing, is a form of decentralized and networked manufacturing evolving from other relevant manufacturing systems such as web- and agent-based manufacturing. An ongoing debate on \{CBM\} in the research community revolves around several aspects such as definitions, key characteristics, computing architectures, programming models, file systems, operational processes, information and communication models, and new business models pertaining to CBM. One question, in particular, has often been raised: Is cloud-based manufacturing a new paradigm, or is it just old wine in new bottles? Based on the discussion of the key characteristics of CBM, the derivation of requirements that an ideal \{CBM\} system should satisfy, and a thorough comparison between \{CBM\} and other relevant manufacturing systems, we provide supporting evidence that allows us to conclude that \{CBM\} is definitely a new paradigm that will revolutionize manufacturing. "
}
@article{Brabec2016136,
title = "A new perspective on the relationship between cloud shade and point cloudiness ",
journal = "Atmospheric Research ",
volume = "172–173",
number = "",
pages = "136 - 146",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S016980951600017X",
author = "Marek Brabec and Viorel Badescu and Marius Paulescu and Alexandru Dumitrescu",
keywords = "Point cloudiness",
keywords = "Cloud shade",
keywords = "Statistical analysis",
keywords = "Semi-parametric modeling ",
abstract = "Abstract Several simple relationships between cloud shade and point cloudiness have been proposed in the last few decades. The present approach is fundamentally different in that it captures some of the hard restrictions dictated by the bounded range (0, 1)of the cloud shade. Three different models are proposed. The main aim is to produce estimates of the whole conditional distribution of the cloud shade for a given point cloudiness value. The beta-inflated model, which takes into account natural physical constraints of the cloud shade, provides the best results. "
}
@article{Sreekanth20162104,
title = "Discussion on linear long-term trends in aerosol and cloud properties over India and its surrounding waters ",
journal = "Advances in Space Research ",
volume = "57",
number = "10",
pages = "2104 - 2114",
year = "2016",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2016.02.015",
url = "http://www.sciencedirect.com/science/article/pii/S0273117716001149",
author = "V. Sreekanth",
keywords = "MODIS",
keywords = "Linear trend",
keywords = "Aerosol Optical Depth",
keywords = "Cloud fraction ",
abstract = "Abstract Spatial and seasonal variations in the linear long-term trend estimates of aerosol and cloud properties over Indian subcontinent and the surrounding oceanic regions of Bay of Bengal (BoB) and Arabian Sea (AS) are studied and discussed utilizing 12 complete years (2003–2014) of Moderate Resolution Imaging Spectroradiometer (MODIS) derived Aerosol and cloud products. Annual Aerosol Optical Depth (AOD) trends (in terms of AOD/year) are found to be positive (upward) over most of the study region with a spatial mean (median) value of ∼0.0065 (0.0064) and exhibited significant spatial and seasonal heterogeneity. Over Indian landmass \{AOD\} trends and their statistical significance decreased towards north along the Indo-Gangetic plains (IGP), for which the probable causes are discussed. Same kind of pattern in \{AOD\} trends has been observed as we move deeper into the oceanic regions of BoB and AS, away from Indian subcontinent. Observed trend patterns are discussed in light of the possible increase in emissions (over Indian landmass) and transported aerosol component, co-variation with trends in meteorological parameters and their possible feedbacks. Trend maps in seasonal \{AOD\} are shown to understand the aerosol build up over the study region under varying meteorological conditions. Seasonal \{AOD\} trend patterns resembled the synoptic scale wind circulation over the study region revealing that the upward trend in aerosol abundance over the adjoining oceanic regions of India is a result of effective transport of increasing emissions over India on to them. No significant trends in cloud properties (over the whole study region) are depicted in concert with that of aerosols, except over few pockets. The study also highlighted the role of large scale atmospheric processes in modulating the shape of the \{AOD\} time series over the regions with significant abundance of natural aerosol component (dust). "
}
@article{VincentWang2013232,
title = "An interoperable solution for Cloud manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "4",
pages = "232 - 247",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2013.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584513000069",
author = "Xi Vincent Wang and Xun W. Xu",
keywords = "Cloud",
keywords = "Cloud computing",
keywords = "Cloud manufacturing",
keywords = "Service-oriented architecture",
keywords = "STEP ",
abstract = "Cloud manufacturing is a new concept extending and adopting the concept of Cloud computing for manufacturing. The aim is to transform manufacturing businesses to a new paradigm in that manufacturing capabilities and resources are componentized, integrated and optimized globally. This study presents an interoperable manufacturing perspective based on Cloud manufacturing. A literature search has been undertaken regarding Cloud architecture and technologies that can assist Cloud manufacturing. Manufacturing resources and capabilities are discussed in terms of Cloud service. A service-oriented, interoperable Cloud manufacturing system is proposed. Service methodologies are developed to support two types of Cloud users, i.e., customer user and enterprise user, along with standardized data models describing Cloud service and relevant features. Two case studies are undertaken to evaluate the proposed system. Cloud technology brings into manufacturing industry with a number of benefits such as openness, cost-efficiency, resource sharing and production scalability. "
}
@article{Aziz2012333,
title = "Potential for Providing Augmented Reality Elements in Special Education via Cloud Computing ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "333 - 339",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.181",
url = "http://www.sciencedirect.com/science/article/pii/S1877705812025672",
author = "Kamarulzaman Ab Aziz and Nor Azlina Ab Aziz and Anuar Mohd Yusof and Avijit Paul",
keywords = "Advance learning tools",
keywords = "attention deficit hyperactivity disorder (ADHD)",
keywords = "special education ",
abstract = "Technology has definitely enhanced the learning process. This is not only true for the main stream education programmes but also in education programmes for students with special needs. This paper observes two technological trends, namely cloud computing and augmented reality within the context of the Malaysian special education delivery. It is recognised that augmented reality offers significant benefits to the learning process. It is also true that the Malaysian government has embarked the establishment of cloud computing sector in the country. This paper draws attention to the synergistic possibility of providing \{AR\} enhanced education for the special needs students in Malaysia via cloud computing. "
}
@article{Chen201642,
title = "Estimating simulation workload in cloud manufacturing using a classifying artificial neural network ensemble approach ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "38",
number = "",
pages = "42 - 51",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000964",
author = "Toly Chen and Yu-Cheng Wang",
keywords = "Cloud manufacturing",
keywords = "Simulation",
keywords = "k-means",
keywords = "Artificial neural network",
keywords = "Ensemble",
keywords = "Workload estimation ",
abstract = "Abstract Cloud manufacturing (CMfg) is an extension of cloud computing in the manufacturing sector. The \{CMfg\} concept of simulating a factory online by using Web services is a topic of interest. To distribute a simulation workload evenly among simulation clouds, a simulation task is typically decomposed into small parts that are simultaneously processed. Therefore, the time required to complete a simulation task must be estimated in advance. However, this topic is seldom discussed. In this paper, a classifying artificial neural network (ANN) ensemble approach is proposed for estimating the required time for a simulation task. In the proposed methodology, simulation tasks are classified using k-means before their simulation times are estimated. Subsequently, for each task category, an \{ANN\} is constructed to estimate the required task time in the category. However, to reduce the impact of \{ANN\} overfitting, the required time for each simulation task is estimated using the \{ANNs\} of all categories, and the estimation results are then weighted and summed. Thus, the \{ANNs\} form an ensemble. In addition to the proposed methodology, six statistical and soft computing methods were applied in real tasks. According to the experimental results, compared with the six existing methods, the proposed methodology reduced the estimation time considerably. In addition, this advantage was statistically significant according to the results of the paired t test. "
}
@article{Namitha2016209,
title = "Point Cloud Mapping Measurements Using Kinect RGB-D Sensor and Kinect Fusion for Visual Odometry ",
journal = "Procedia Computer Science ",
volume = "89",
number = "",
pages = "209 - 212",
year = "2016",
note = "Twelfth International Conference on Communication Networks, \{ICCN\} 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, \{ICDMW\} 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, \{ICISP\} 2016, August 19-21, 2016, Bangalore, India ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.06.044",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916311097",
author = "N. Namitha and S.M. Vaitheeswaran and V.K. Jayasree and M.K. Bharat",
keywords = "Kinect",
keywords = "Kinect Fusion",
keywords = "Odometry",
keywords = "Robotics",
keywords = "Vision. ",
abstract = "Abstract RGB-D camera like Kinect make available \{RGB\} Images along with per-pixel depth information in real time. This paper uses the Kinect Fusion developed by Microsoft Research for the 3D reconstruction of the scene in real time using the MicroKinect Camera and applies it as an aid for Visual Odometry of a Robotic Vehicle where no external reference like \{GPS\} is available. "
}
@article{Prestes20131193,
title = "Towards a core ontology for robotics and automation ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1193 - 1204",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000596",
author = "Edson Prestes and Joel Luis Carbonera and Sandro Rama Fiorini and Vitor A. M. Jorge and Mara Abel and Raj Madhavan and Angela Locoro and Paulo Goncalves and Marcos E. Barreto and Maki Habib and Abdelghani Chibani and Sébastien Gérard and Yacine Amirat and Craig Schlenoff",
keywords = "Ontologies for robotics and automation",
keywords = "Ontology-based standards",
keywords = "Core ontology",
keywords = "Ontology engineering",
keywords = "Semantic interoperability",
keywords = "Knowledge representation ",
abstract = "Abstract In this paper, we present the current results of the newly formed IEEE-RAS Working Group, named Ontologies for Robotics and Automation. In particular, we introduce a core ontology that encompasses a set of terms commonly used in Robotics and Automation along with the methodology we have adopted. Our work uses ISO/FDIS 8373 standard developed by the ISO/TC184/SC2 Working Group as a reference. This standard defines, in natural language, some generic terms which are common in Robotics and Automation such as robot, robotic device, etc. Furthermore, we discuss the ontology development process employed along with the problems and decisions taken. "
}
@article{Kirill2014216,
title = "The Architecture of Robotics Control Software for Heterogeneous Mobile Robots Network ",
journal = "Procedia Engineering ",
volume = "69",
number = "",
pages = "216 - 221",
year = "2014",
note = "24th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.02.224",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814002264",
author = "Kirsanov Kirill",
keywords = "robtics software",
keywords = "robotics control systems",
keywords = "turing-complite protocol",
keywords = "python",
keywords = "dynamic language ",
abstract = "Abstract This paper dwells on the control software architecture of mobile robots from a programmer's perspective. Several approaches to the construction of such systems were considered in the case of popular systems and the author's own designs. The need for such systems has even become increasingly obvious due to the heterogeneous nature of robotics network. The authors had to work with different types of robots, namely Sensorika \{AMUR\} 1-7, Brokk-400 and Festo Robotino XT. Here, heterogeneity refers not only to the network architecture but also to the robots themselves. Particular attention was given to programming theory, organization of a two-level control instruction pipeline, using Turing-complete protocols, and virtualization of input/output ports. "
}
@article{Xiao201538,
title = "Street environment change detection from mobile laser scanning point clouds ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "107",
number = "",
pages = "38 - 49",
year = "2015",
note = "Multitemporal remote sensing data analysis ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001215",
author = "Wen Xiao and Bruno Vallet and Mathieu Brédif and Nicolas Paparoditis",
keywords = "Change detection",
keywords = "Lidar",
keywords = "K-d tree",
keywords = "Occupancy grids",
keywords = "Point-to-triangle distance",
keywords = "Dempster–Shafer theory ",
abstract = "Abstract Mobile laser scanning (MLS) has become a popular technique for road inventory, building modelling, infrastructure management, mobility assessment, etc. Meanwhile, due to the high mobility of \{MLS\} systems, it is easy to revisit interested areas. However, change detection using \{MLS\} data of street environment has seldom been studied. In this paper, an approach that combines occupancy grids and a distance-based method for change detection from \{MLS\} point clouds is proposed. Unlike conventional occupancy grids, our occupancy-based method models space based on scanning rays and local point distributions in 3D without voxelization. A local cylindrical reference frame is presented for the interpolation of occupancy between rays according to the scanning geometry. The Dempster–Shafer theory (DST) is utilized for both intra-data evidence fusion and inter-data consistency assessment. Occupancy of reference point cloud is fused at the location of target points and then the consistency is evaluated directly on the points. A point-to-triangle (PTT) distance-based method is combined to improve the occupancy-based method. Because it is robust to penetrable objects, e.g. vegetation, which cause self-conflicts when modelling occupancy. The combined method tackles irregular point density and occlusion problems, also eliminates false detections on penetrable objects. "
}
@incollection{Chang2014213,
title = "Chapter 13 - Medical Robotics for Cellular and Molecular Imaging ",
editor = "Chen, Xiaoyuan and ,  and Wong, Stephen ",
booktitle = "Cancer Theranostics ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2014",
pages = "213 - 225",
isbn = "978-0-12-407722-5",
doi = "https://doi.org/10.1016/B978-0-12-407722-5.00013-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012407722500013X",
author = "Tou Pin Chang and Guang-Zhong Yang",
keywords = "Cellular",
keywords = "Molecular",
keywords = "Robotics",
keywords = "Imaging",
keywords = "Minimally invasive surgery",
keywords = "MIS",
keywords = "Endoscopy",
keywords = "Cancer therapy",
keywords = "Deformation",
keywords = "Robotic assistance",
keywords = "Clinical applications",
keywords = "Confocal",
keywords = "Endomicroscopy",
keywords = "Neoplasia",
keywords = "Endoluminal",
keywords = "Intra-abdominal ",
abstract = "The quest for providing real-time cellular and molecular characterization during endoscopy and minimally invasive surgery (MIS) has motivated the development of new in vivo, in-situ high-resolution microscopic imaging tools. These techniques have shown promise for cancer therapies with the potential for accurate margin definition during \{MIS\} procedures. However, the practical use of these imaging tools is faced with a number of technical difficulties. These include the handling of in vivo tissue deformation and maintenance of consistent tissue contact and probe movement to ensure large area surveillance. Existing results have shown problems associated with manual handling of these imaging probes during intervention and called for the development of smart surgical instruments or the use of robotic assistance. It is increasingly evident that robotics has now an established foothold in medicine as an enabling technology for MIS. This chapter outlines some of the promising clinical applications of confocal endomicroscopy in neoplasia detection and how robotic technologies can be used in the near future to overcome some of the challenges in endoluminal and intra-abdominal imaging. "
}
@article{vanHenten2013170,
title = "Robotics in protected cultivation ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "18",
pages = "170 - 177",
year = "2013",
note = "4th \{IFAC\} Conference on Modelling and Control in Agriculture, Horticulture and Post Harvest Industry ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130828-2-SF-3019.00070",
url = "http://www.sciencedirect.com/science/article/pii/S147466701534979X",
author = "E.J. van Henten and C.W. Bac and J. Hemming and Y. Edan",
keywords = "protected cultivation",
keywords = "robotics",
keywords = "sensor",
keywords = "sensor fusion",
keywords = "motion planning",
keywords = "artificial intelligence",
keywords = "optimal design",
keywords = "human-robot collaboration ",
abstract = "Abstract This paper reviews robotics for protected cultivation systems. Based on a short description of the greenhouse crop production process, the current state in greenhouse mechanization and the challenges for robotics in protected cultivation are identified. Examples of current greenhouse robotics research are presented. Since the complex working environment constitutes a considerable challenge to robotics, opportunities will be identified to deal with this complexity. Solutions can be found in developing more advanced technology, including multiple sensor approaches, sensor fusion and artificial intelligence concepts and in human-robot collaboration. Alternatively, solutions can be found in modifying the working environment. The paper also pleas for the development of more generic solutions to deal with the small and very scattered markets of robots in protected cultivation. "
}
@article{Mourad201630,
title = "Interoperability as a Key Enabler for Manufacturing in the Cloud ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "30 - 34",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.051",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116308010",
author = "M. Mourad and A. Nassehi and D. Schaefer",
keywords = "Cloud manufacturing",
keywords = "Interoperability",
keywords = "Manufacturing as a service (MaaS) ",
abstract = "Abstract The emerging cloud paradigm has a prominent effect on manufacturing. The move from hardware bound systems to requirements based service provision is enabling the transition to cloud manufacturing. A networked manufacturing service provision system requires vast amounts of information to be exchanged in a non-ambiguous and timely manner to meet production requirements. In this paper, interoperability is identified as a key enabler for cloud manufacturing and a framework for realisation of interoperability across heterogeneous computer aided manufacturing systems is proposed. Using this framework, manufacturing resources can be shared by a large number of clients based on requirements and priorities. "
}
@article{Bosse201556,
title = "Unified Distributed Computing and Co-ordination in Pervasive/Ubiquitous Networks with Mobile Multi-Agent Systems using a Modular and Portable Agent Code Processing Platform ",
journal = "Procedia Computer Science ",
volume = "63",
number = "",
pages = "56 - 64",
year = "2015",
note = "The 6th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2015)/ The 5th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2015)/ Affiliated Workshops ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.312",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915024400",
author = "Stefan Bosse",
keywords = "Sensor Networks",
keywords = "Cloud Computing",
keywords = "Mobile Agents",
keywords = "Heterogeneous Networks",
keywords = "Embedded Systems",
keywords = "Agent Processing Platform ",
abstract = "Abstract A novel and unified approach for reliable distributed and parallel computing using mobile agents is introduced. The agents can be deployed in large scale and hierarchical network environments crossing barriers transparently. The networks can consist of high- and low-resource nodes ranging from generic computers to microchips, and the supported network classes range from body area networks to the Internet including any kind of sensor and ambient network. Agents are represented by mobile program code that can be modified at run-time. The presented approach enables the development of sensor clouds and smart systems of the future integrated in daily use computing environments and the Internet. Agents can migrate between different hardware and software platforms by migrating the program code of the agent, embedding the state and the data of an agent, too. The entire information exchange and coordination of agents with other agents and the environment is performed by using a tuple space database. Beside architecture specific hardware and software implementations of the agent processing platform, there is a JavaScript (JS) implemen- tation layered on the top of a distributed management layer. The \{JS\} platform enables the integration of Multi-agent Systems (MAS) in Internet server and application environments (e.g., \{WEB\} browser). Agents can migrate transparently between hardware-level sensor networks and \{WEB\} browser applications or network servers and vice versa without any transformation required. "
}
@article{Sgorbissa20131665,
title = "Structure-based object representation and classification in mobile robotics through a Microsoft Kinect ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1665 - 1679",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001139",
author = "Antonio Sgorbissa and Damiano Verda",
keywords = "Object classification",
keywords = "Structure-based modelling and recognition",
keywords = "Microsoft Kinect",
keywords = "Mobile robotics ",
abstract = "Abstract A new approach enabling a mobile robot to recognize and classify furniture-like objects composed of assembled parts using a Microsoft Kinect is presented. Starting from considerations about the structure of furniture-like objects, i.e., objects which can play a role in the course of a mobile robot mission, the 3D point cloud returned by the Kinect is first segmented into a set of “almost convex” clusters. Objects are then represented by means of a graph expressing mutual relationships between such clusters. Off-line, snapshots of the same object taken from different positions are processed and merged, in order to produce multiple-view models that are used to populate a database. On-line, as soon as a new object is observed, a run-time window of subsequent snapshots is used to search for a correspondence in the database. Experiments validating the approach with a set of objects (i.e., chairs, tables, but also other robots) are reported and discussed in detail. "
}
@article{Fehr201680,
title = "Covariance based point cloud descriptors for object detection and recognition ",
journal = "Computer Vision and Image Understanding ",
volume = "142",
number = "",
pages = "80 - 93",
year = "2016",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215001368",
author = "Duc Fehr and William J. Beksi and Dimitris Zermas and Nikolaos Papanikolopoulos",
keywords = "RGB-D data",
keywords = "Colored point clouds",
keywords = "Classification",
keywords = "Object recognition ",
abstract = "Abstract Processing 3D point cloud data is of primary interest in many areas of computer vision, including object grasping, robot navigation, and object recognition. The introduction of affordable RGB-D sensors has created a great interest in the computer vision community towards developing efficient algorithms for point cloud processing. Previously, capturing a point cloud required expensive specialized sensors such as lasers or dedicated range imaging devices; now, range data is readily available from low-cost sensors that provide easily extractable point clouds from a depth map. From here, an interesting challenge is to find different objects in the point cloud. Various descriptors have been introduced to match features in a point cloud. Cheap sensors are not necessarily designed to produce precise measurements, which means that the data is not as accurate as a point cloud provided from a laser or a dedicated range finder. Although some feature descriptors have been shown to be successful in recognizing objects from point clouds, there still exists opportunities for improvement. The aim of this paper is to introduce techniques from other fields, such as image processing, into 3D point cloud processing in order to improve rendering, classification, and recognition. Covariances have proven to be a success not only in image processing, but in other domains as well. This work develops the application of covariances in conjunction with 3D point cloud data. "
}
@article{Adamson2016644,
title = "A Cloud Service Control Approach for Distributed and Adaptive Equipment Control in Cloud Environments ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "644 - 649",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.020",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115010999",
author = "Göran Adamson and Magnus Holm and Philip Moore and Lihui Wang",
keywords = "Adaptive control",
keywords = "Adaptive manufacturing",
keywords = "Cloud manufacturing ",
abstract = "Abstract A developing trend within the manufacturing shop-floor domain is the move of manufacturing activities into cloud environments, as scalable, on-demand and pay-per-usage cloud services. This will radically change traditional manufacturing, as borderless, distributed and collaborative manufacturing missions between volatile, best suited groups of partners will impose a multitude of advantages. The evolving Cloud Manufacturing (CM) paradigm will enable this new manufacturing concept, and on-going research has described many of its anticipated core virtues and enabling technologies. However, a major key enabling technology within \{CM\} which has not yet been fully addressed is the dynamic and distributed planning, control and execution of scattered and cooperating shop-floor equipment, completing joint manufacturing tasks. In this paper, the technological perspective for a cloud service-based control approach is described, and how it could be implemented. Existing manufacturing resources, such as soft, hard and capability resources, can be packaged as cloud services, and combined to create different levels of equipment or manufacturing control, ranging from low-level control of single machines or devices (e.g. Robot Control-as-a-Service), up to the execution of high level multi-process manufacturing tasks (e.g. Manufacturing-as-a-Service). A multi-layer control approach, featuring adaptive decision-making for both global and local environmental conditions, is proposed. This is realized through the use of a network of intelligent and distributable decision modules such as event-driven Function Blocks, enabling run-time manufacturing activities to be performed according to actual manufacturing conditions. The control system's integration to the \{CM\} cloud service management functionality is also described. "
}
@article{Rahmani2017,
title = "Exploiting smart e-Health gateways at the edge of healthcare Internet-of-Things: A fog computing approach ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17302121",
author = "Amir M. Rahmani and Tuan Nguyen Gia and Behailu Negash and Arman Anzanpour and Iman Azimi and Mingzhe Jiang and Pasi Liljeberg",
keywords = "Internet of Things",
keywords = "Healthcare",
keywords = "Edge/Fog computing",
keywords = "Mobility",
keywords = "Smart hospital",
keywords = "Home care",
keywords = "Smart gateway",
keywords = "Sensor network ",
abstract = "Abstract Current developments in \{ICTs\} such as in Internet-of-Things (IoT) and Cyber–Physical Systems (CPS) allow us to develop healthcare solutions with more intelligent and prediction capabilities both for daily life (home/office) and in-hospitals. In most of IoT-based healthcare systems, especially at smart homes or hospitals, a bridging point (i.e., gateway) is needed between sensor infrastructure network and the Internet. The gateway at the edge of the network often just performs basic functions such as translating between the protocols used in the Internet and sensor networks. These gateways have beneficial knowledge and constructive control over both the sensor network and the data to be transmitted through the Internet. In this paper, we exploit the strategic position of such gateways at the edge of the network to offer several higher-level services such as local storage, real-time local data processing, embedded data mining, etc., presenting thus a Smart e-Health Gateway. We then propose to exploit the concept of Fog Computing in Healthcare IoT systems by forming a Geo-distributed intermediary layer of intelligence between sensor nodes and Cloud. By taking responsibility for handling some burdens of the sensor network and a remote healthcare center, our Fog-assisted system architecture can cope with many challenges in ubiquitous healthcare systems such as mobility, energy efficiency, scalability, and reliability issues. A successful implementation of Smart e-Health Gateways can enable massive deployment of ubiquitous health monitoring systems especially in clinical environments. We also present a prototype of a Smart e-Health Gateway called UT-GATE where some of the discussed higher-level features have been implemented. We also implement an IoT-based Early Warning Score (EWS) health monitoring to practically show the efficiency and relevance of our system on addressing a medical case study. Our proof-of-concept design demonstrates an IoT-based health monitoring system with enhanced overall system intelligence, energy efficiency, mobility, performance, interoperability, security, and reliability. "
}
@article{Tarchinskaya2013335,
title = "Cloud-based Engineering Design and Manufacturing: State-of-the-Art ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "9",
pages = "335 - 340",
year = "2013",
note = "7th \{IFAC\} Conference on Manufacturing Modelling, Management, and Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130619-3-RU-3018.00632",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016343087",
author = "Ekaterina Tarchinskaya and Victor Taratoukhine and Martin Matzner",
keywords = "Manufacturing",
keywords = "engineering design",
keywords = "cloud computing",
keywords = "agile manufacturing",
keywords = "business processes ",
abstract = "Abstract Cloud-based technologies proliferated in the past few years, while the manufacturing industry moved towards digitization and network. Therefore, cloud-based technologies have been adopted in the development of new generation manufacturing systems which orchestrate different activities, including product design, process and task planning, production, customer service, etc. These new cloud-ingrained technologies have the potential to change the collaboration of product development partners, the processing and sharing of information as well as utilization rates of critical equipment. Cloud-based technologies affect many aspects of manufacturing activities, and they therefore have the power to enable new or change existing business models of the manufacturing industry. Based on the literature review, this paper analyzes the latest requirements, challenges, and trends of the manufacturing industry. It structures the findings in the coherent manner and further hypothesizes how cloud computing may address identified requirements and challenges as well as realize or support new concepts in manufacturing. "
}
@article{Mezgár201111949,
title = "Cloud Computing Technology for Networked Enterprises ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11949 - 11954",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.00702",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016455369",
author = "István Mezgár",
keywords = "Keywords:",
keywords = "Architectures",
keywords = "enterprise integration",
keywords = "interoperability",
keywords = "manufacturing",
keywords = "networks ",
abstract = "Abstract Today manufacturing enterprises have to organize themselves into effective system architectures to match fast changing market demands. These architectures can be realized only by using computer networks in order to co-ordinate the production of the distributed units forming different types of networked enterprises (NE). Cloud Computing (CC) is an important up to date computing technology for Networked Enterprises, as it offers significant financial and technical advantages beside high level collaboration possibilities. The paper introduces the main characteristics of future internet based enterprises and the different \{CC\} models. Additionally the advantages and disadvantages of cloud computing have been summarized giving special focus on interoperability challenges. "
}
@article{Srivathsan2015602,
title = "Health Monitoring System by Prognotive Computing Using Big Data Analytics ",
journal = "Procedia Computer Science ",
volume = "50",
number = "",
pages = "602 - 609",
year = "2015",
note = "Big Data, Cloud and Computing Challenges ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.04.092",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915005931",
author = "M. Srivathsan and K. Yogesh Arjun",
keywords = "Analytics",
keywords = "Big data",
keywords = "Cloud Computing",
keywords = "Cognitive Computing",
keywords = "Fuzzy Logic",
keywords = "MapReduce",
keywords = "Natural Language Processing",
keywords = "Prognition",
keywords = "Prognotive computing",
keywords = "Pseudo-Intelligence",
keywords = "Virtualization ",
abstract = "Abstract Big data is a modern age concept that is used to process large amount of data in various fields ranging from medical, remote sensing, customer service etc., The Medical Sphere is a tangential aspect to every individual's life.Technological advancement in this field has reached a saturation.A break-throughcan be achieved by Prognotive computing. Prognotive Computing is related to big data analytics as the process may require the collection, processing and analysis of extremely large volume of structured and unstructured biomedical data stemming from a wide range of experiments and surveys collected by hospitals, laboratories, pharmaceutical companies or even social media which is implemented by using existing tools for Big Data. The result of prognosis will improve the efficiency in providing better living to people. "
}
@article{Liu20161101,
title = "Detection based object labeling of 3D point cloud for indoor scenes ",
journal = "Neurocomputing ",
volume = "174, Part B",
number = "",
pages = "1101 - 1106",
year = "2016",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215014617",
author = "Wei Liu and Shaozi Li and Donglin Cao and Songzhi Su and Rongrong Ji",
keywords = "Point cloud",
keywords = "Labeling",
keywords = "Object detection",
keywords = "RGB-D ",
abstract = "Abstract While much exciting progress is being made in 3D reconstruction of scenes, object labeling of 3D point cloud for indoor scenes has been left as a challenge issue. How should we explore the reference images of 3D scene, in aid of scene parsing? In this paper, we propose a framework for 3D indoor scenes labeling, based upon object detection on the RGB-D frames of 3D scene. First, the point cloud is segmented into homogeneous segments. Then, we utilize object detectors to assign class probabilities to pixels in every RGB-D frame. After that, the class probabilities are projected into the segments. Finally, we perform accurate inference on a \{MRF\} model over the homogeneous segments, in combination with geometry cues to output the labels. Experiment on the challenging RGB-D Object Dataset demonstrates that our detection based approach produces accurate labeling and improves the robustness of small object detection for indoor scenes. "
}
@article{Brant2015478,
title = "A novel system for cloud-based micro additive manufacturing of metal structures ",
journal = "Journal of Manufacturing Processes ",
volume = "20, Part 3",
number = "",
pages = "478 - 484",
year = "2015",
note = "Additive Manufacturing ",
issn = "1526-6125",
doi = "https://doi.org/10.1016/j.jmapro.2015.06.020",
url = "http://www.sciencedirect.com/science/article/pii/S1526612515000651",
author = "Anne Brant and Murali M. Sundaram",
keywords = "Cloud-manufacturing",
keywords = "Additive manufacturing",
keywords = "Electrochemical deposition ",
abstract = "Abstract Cloud-based computing holds enormous potential for collaboration, cost-saving, streamlining, and versatility of manufacturing. Additive manufacturing, being a computer-based system that can save point-by-point data of parts to be manufactured, can be easily integrated into the cloud. Preliminary work was done to test the cloud-based application of an in-house micro metal additive manufacturing by electrochemical deposition process. The system was linked to commercial cloud and email access for constant real-time communication from any user with a phone, tablet, or personal computer. The process could be started, stopped, altered, and queried remotely via the cloud. Input parameters (i.e.: geometry, tool size) and preliminary design rules (i.e.: current feedback threshold value) were specified. Plots of output performance, time, and current information were communicated back to the user on-demand, as well as stored on the cloud long-term. The cloud could then link input parameters to the history of system performance on such input parameters in a cloud-stored database. An experiment was set up to optimize horizontal deposition parameters based on deposition resolution, and save these values into the cloud for future use, The experiment was successfully executed and demonstrates the advantage of long-term storage, knowledge sharing, and convenience that the cloud offers for the manufacturing realm. "
}
@article{Tapoglou2016661,
title = "Cloud-based Job Dispatching Using Multi-criteria Decision Making ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "661 - 666",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.081",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115011609",
author = "Nikolaos Tapoglou and Jörn Mehnen",
keywords = "Job allocation",
keywords = "Cloud manufacturing",
keywords = "Multi criteria decision making ",
abstract = "Abstract The dynamic nature of modern workshops and the change in availability of manufacturing equipment affects the allocation of manufacturing jobs. In order to cope with these requirements a module that ranks manufacturing equipment and proposes the best fitted machine to perform a specific manufacturing task according to capabilities, availability and suitability is needed. This paper presents such a framework for allocating tasks to manufacturing equipment according to the capabilities, the availability and the running cost of the manufacturing equipment. The decisions are made by using a multi-criteria decision making tool running in a Cloud environment with data being fed through web based protocols. The novelty of the proposed system lies in the fact that the solution is based on a Cloud Manufacturing environment and the selection process is based on the latest information regarding the machine tool data, received through a web interface. The functionality of the module is illustrated through a case study. "
}
@article{Schauer201654,
title = "Performance comparison between state-of-the-art point-cloud based collision detection approaches on the \{CPU\} and \{GPU\} ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "54 - 59",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.125",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325630",
author = "Johannes Schauer and Janusz Bedkowski and Karol Majek and Andreas Nüchter",
keywords = "k-d tree",
keywords = "CUDA",
keywords = "parallel algorithms",
keywords = "3D point clouds",
keywords = "regular grid decompositio ",
abstract = "Abstract: We present two fundamentally different approaches to detect collisions between two point clouds and compare their performance on multiple datasets. A collision between points happens if they are closer to each other than a given threshold radius. One approach utilizes the main \{CPU\} with a k-d tree datastructure to efficiently carry out fixed range searches around points in 3D while the other mainly executes on a \{GPU\} using a regular grid decomposition technique implemented in the \{CUDA\} framework. We will show how massively parallel 3D range searches on a grid based datastructure on a \{GPU\} performs similarly well as a tree based approach on the \{CPU\} with orders of magnitude less parallelization. We also show how each method scales with varying input sizes and how they perform differently well depending on the spatial structure of the input data. "
}
@article{Mourtzis2016655,
title = "A Cloud-based Approach for Maintenance of Machine Tools and Equipment Based on Shop-floor Monitoring ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "655 - 660",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.069",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115011488",
author = "Dimitris Mourtzis and Ekaterini Vlachou and Nikolaos Milas and Nikitas Xanthopoulos",
keywords = "Monitoring",
keywords = "Maintenance",
keywords = "Cloud manufacturing ",
abstract = "Abstract Maintenance and its cost continue, over the years, to draw the attention of production management since the unplanned failures decrease the reliability of the system and also the return of investments. Advanced maintenance techniques that capture and process shop-floor information can reduce costs and increase the sustainability of an enterprise. This paper presents a condition-based preventive maintenance approach integrated into a machine monitoring framework. The latter acquires data from shop-floor machine tools and analyses them through an information fusion technique to support the condition-based preventive maintenance operations. The proposed approach is developed into a software service, deployed on a Cloud environment. The service gathers and processes data, such as their actual processing time and machining time per tool, related to the operation of machine tools and equipment and calculates the expected remaining useful life of components. Moreover, it provides notifications to machine tool operators and maintenance departments, as well as it enables the communication among them using mobile technology. The framework is applied to a case study with data obtained from a machining SME. "
}
@article{Coccoli201797,
title = "The role of big data and cognitive computing in the learning process ",
journal = "Journal of Visual Languages & Computing ",
volume = "38",
number = "",
pages = "97 - 103",
year = "2017",
note = "SI:In honor of Prof \{SK\} Chang ",
issn = "1045-926X",
doi = "https://doi.org/10.1016/j.jvlc.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S1045926X1530046X",
author = "Mauro Coccoli and Paolo Maresca and Lidia Stanganelli",
keywords = "Cognitive computing",
keywords = "Big data",
keywords = "Smart applications",
keywords = "Collaborative systems",
keywords = "Technology enhanced learning",
keywords = "Smart university ",
abstract = "Abstract In this paper, we investigate how the raise of big data and cognitive computing systems is going to redesign the labor market, also impacting on the learning processes. In this respect, we make reference to higher education and we depict a model of a smart university, which relies on the concepts that are at the basis of the novel smart-cities’ development trends. Thus, we regard education as a process so that we can find specific issues to solve to overcome existing criticisms, and provide some suggestions on how to enhance universities’ performances. We highlight inputs, outputs, and dependencies in a block diagram, and we propose a solution built on a new paradigm called smarter-university, in which knowledge grows rapidly, is easy to share, and is regarded as a common heritage of both teachers and students. Among the others, a paramount consequence is that there is a growing demand for competences and skills that recall the so called T-shape model and we observe that this is pushing the education system to include a blend of disciplines in the curriculums of their courses. In this overview, among the wide variety of recent innovations, we focus our attention on cognitive computing systems and on the exploitation of big data, that we expect to further accelerate the refurbishment process of the key components of the knowledge society and universities as well. "
}
@article{Xu2015355,
title = "Cloud asset for urban flood control ",
journal = "Advanced Engineering Informatics ",
volume = "29",
number = "3",
pages = "355 - 365",
year = "2015",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2015.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S147403461500018X",
author = "Gangyan Xu and George Q. Huang and Ji Fang",
keywords = "Cloud asset",
keywords = "Smart object",
keywords = "Cloud-based applications",
keywords = "Mobile agent",
keywords = "Urban flood control ",
abstract = "Abstract The performance of physical assets has become a major determinant success factor for urban flood control. However, managing these assets is always challenging as there are a huge number of diverse assets involved, which are distributed throughout the city, and owned by different agencies. Aiming at improving the management efficiency of these assets, and ensuring their performance, this paper proposes the concept of cloud asset based on cloud computing, mobile agent, and various smart devices. Through hardware integration and software encapsulation, cloud asset could sense its real-time status, adapt to varied working scenarios, be controlled remotely, and shared among agencies. It enables accurate real-time control of every asset, and thus improves the management efficiency and effectiveness. This paper first presents the concept of cloud asset with its technical architecture, and then analyses the software agent model for cloud asset, which is the key enabler to realize \{UPnP\} (Universal Plug and Play) management of assets, and provides mobility and intelligence for them. After that, the framework of cloud asset-enabled workflow management is built, in which cloud asset could be easily found and dynamically invoked by different workflows. Finally, a demonstrative case is provided to verify the effectiveness of cloud asset. "
}
@article{Holtewert2013527,
title = "Virtual Fort Knox Federative, Secure and Cloud-based Platform for Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "527 - 532",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.027",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002965",
author = "Philipp Holtewert and Rolf Wutzke and Joachim Seidelmann and Thomas Bauernhansl",
keywords = "Smart Factory",
keywords = "Cloud",
keywords = "Ubiquitous computing",
keywords = "production system",
keywords = "information management ",
abstract = "Abstract In future the engineer and \{IT\} world will grow together. Networking and linking of information from the physical production and the digital world enable an optimization in manufacturing. Within the research project Virtual Fort Knox at the Fraunhofer \{IPA\} in Germany, a federative, secure and cloud-based platform for distributed service-oriented applications in plant operation is developed. The challenge is to establish a platform for the manufacturing to improve data processing and intelligent, cooperative networking. Data and information have to be saved, read and used on a flexible, simple and scalable way. This paper presents our research work in developing the platform by the description of the transformation process to the networked factory. The main aspects are consistent, integrated security across all components, community cloud for IT-decentralization respectively data, cooperation and competence distribution. "
}
@article{Caglar2015255,
title = "Cloud-hosted simulation-as-a-service for high school \{STEM\} education ",
journal = "Simulation Modelling Practice and Theory ",
volume = "58, Part 2",
number = "",
pages = "255 - 273",
year = "2015",
note = "Special issue on Cloud Simulation ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X1500101X",
author = "Faruk Caglar and Shashank Shekhar and Aniruddha Gokhale and Satabdi Basu and Tazrian Rafi and John Kinnebrew and Gautam Biswas",
keywords = "Cloud",
keywords = "Modeling",
keywords = "Simulation-as-a-service",
keywords = "STEM ",
abstract = "Abstract Despite their advanced status, nations such as the United States of America continue to face a \{STEM\} (science, technology, engineering and mathematics) crisis in their education system. Lack of effective teaching modalities that can leverage real-world examples to stimulate student interest in \{STEM\} concepts are identified as one of the reasons for this crisis. To address these challenges, our research is investigating the use of innovative and attractive modeling and simulation frameworks for concurrent, interactive and collaborative \{STEM\} education where vehicular traffic serves as the real-world example to reify \{STEM\} concepts. Existing traffic-related tools, such as traffic simulators, however, do not provide: (1) intuitive abstractions to construct, refine, and simulate various traffic models that are commensurate to the level of high school students, (2) concurrent and scalable model execution, and (3) collaborative learning environments. On the other hand, although intuitive abstractions such as Google Maps exist, these abstractions do not support semantics for dynamic behavior, which is representative of real-world traffic scenarios. To overcome both these challenges and address the \{STEM\} problem, this paper presents a Cloud-based, Collaborative, and Scaled-up Modeling and Simulation Framework for \{STEM\} Education called C2SuMo. The key contribution of this paper lies in the design and implementation of a cloud-based, elastic modeling and simulation framework that provides an intuitive, model-driven, collaborative, and concurrent visual simulation environment for \{STEM\} education. The paper also reports on insights we gained conducting a user study involving over sixty high school students. "
}
@article{Morariu20121862,
title = "Resource Monitoring in Cloud Platforms with Tivoli Service Automation Management ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "6",
pages = "1862 - 1868",
year = "2012",
note = "14th \{IFAC\} Symposium on Information Control Problems in Manufacturing ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-RO-2023.00439",
url = "http://www.sciencedirect.com/science/article/pii/S147466701633422X",
author = "Octavian Morariu and Theodor Borangiu",
keywords = "Cloud Computing",
keywords = "Metering",
keywords = "Monitoring",
keywords = "IBM CloudBurst",
keywords = "JADE ",
abstract = "Abstract Cloud computing promises a radical new way in design of the \{IT\} systems. Due to advances in virtualization technology in the last decade this paradigm has gained a lot of traction among the \{IT\} managers, offering a new perspective in design and development of the next generation software and hardware applications. One of the most appealing characteristics of cloud computing is the pay-as-you-go model which allows customers to start with a small \{IT\} investment and grow as required, minimizing risks. For cloud providers, in order to be able to sustain this business model it is important to be able to gather and process usage metrics of the resources provided in order to generate accurate invoices for customers. This paper presents the metrics collections used with each cloud offering (IaaS, PaaS and SaaS) and proposes a novel architecture for collecting these metrics using a Multi Agent System platform, together with a Web \{J2EE\} application for real time data visualization and reporting. The solution is built and presented in the context of \{IBM\} CloudBurst 2.1, managed by \{IBM\} Tivoli Service Automation Manager (TSAM) software stack, while virtualization is provided by \{VMware\} \{ESX\} 4.0 hypervisor with \{VMware\} vCenter solution. "
}
@article{Yu20155,
title = "Computer-Integrated Manufacturing, Cyber-Physical Systems and Cloud Manufacturing – Concepts and relationships ",
journal = "Manufacturing Letters ",
volume = "6",
number = "",
pages = "5 - 9",
year = "2015",
note = "",
issn = "2213-8463",
doi = "https://doi.org/10.1016/j.mfglet.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S2213846315000176",
author = "Chunyang Yu and Xun Xu and Yuqian Lu",
keywords = "Cloud Manufacturing",
keywords = "Cyber-Physical Systems",
keywords = "Computer Integrated Manufacturing",
keywords = "Industry 4.0",
keywords = "Internet of Things ",
abstract = "Abstract Computers are deeply entrenched in modern manufacturing systems, giving rise to technologies such as Computer Integrated Manufacturing, Cyber-Physical Systems and most recently Cloud Manufacturing. These technologies have evolved based on existing or similar technologies or manufacturing paradigms. Some misunderstandings exist among these technologies. In spite of similarities, there are sufficient differences among themselves. To start off, the circumstances under which these technologies were incepted and developed are different. There are different methodologies associated with them. Discussions in this paper are made in relationship to Information Technology, Industry and Services. "
}
@article{Tsai20081392,
title = "An ontology-based collaborative service-oriented simulation framework with Microsoft Robotics Studio® ",
journal = "Simulation Modelling Practice and Theory ",
volume = "16",
number = "9",
pages = "1392 - 1414",
year = "2008",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2008.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X08001421",
author = "W.T. Tsai and Xin Sun and Qian Huang and Helen Karatza",
keywords = "Service-oriented computing",
keywords = "Simulation framework",
keywords = "Ontology",
keywords = "Robotics Studio",
keywords = "Model-driven development ",
abstract = "In Service-Oriented Architecture (SOA), the concepts that services can be discovered and application can be composed via service discovery bring great flexibility to application development [Y. Chen, W.T. Tsai, Distributed Service-Oriented Software Development, Kendall/Hunt, 2008, [4]]. Microsoft Robotics Studio (MSRS) is a recent initiative in applying \{SOA\} to embedded systems and one of its key features is its 3-D simulation tool that allows applications to be simulated before deployment. This paper proposes an ontology-based service-oriented simulation framework with \{MSRS\} by adding a set of ontology systems, i.e., service ontology, workflow ontology, entity ontology, and environment ontology. These ontology systems store relevant information useful to compose simulation applications, and items stored also cross reference to each other to facilitate reusability and rapid application composition, This paper then provides a detailed case study on a popular robotic game Sumobot using \{MSRS\} to illustrate the key concepts and how they can support rapid simulation development.1The contents of this paper were developed under a grant from \{US\} Department of Defense and the Fund for the Improvement of Postsecondary Education (FIPSE), \{US\} Department of Education. However, these contents do not necessarily represent the policy of the Department of Education, and you should not assume endorsement by the Federal Government. 1 "
}
@article{Chen2017124,
title = "An intelligent value stream-based approach to collaboration of food traceability cyber physical system by fog computing ",
journal = "Food Control ",
volume = "71",
number = "",
pages = "124 - 136",
year = "2017",
note = "",
issn = "0956-7135",
doi = "https://doi.org/10.1016/j.foodcont.2016.06.042",
url = "http://www.sciencedirect.com/science/article/pii/S0956713516303565",
author = "Rui-Yang Chen",
keywords = "Food traceability system",
keywords = "Cyber physical system",
keywords = "Fog computing",
keywords = "Value stream mapping ",
abstract = "Abstract Good advanced food traceability systems help to minimize unsafe or poor quality products in food supply chain through value-based process. From the emerging technologies forthcoming for industry automation, future advanced food traceability system must consider not only cyber physical system (CPS) and fog computing but also value-added business in food supply chain. Accordingly, this study presents a novel intelligent value stream-based food traceability cyber physical system approach integrated with enterprise architectures, \{EPCglobal\} and value stream mapping method by fog computing network for traceability collaborative efficiency. Furthermore, the proposed intelligent approach explores distributive and central traceable stream mechanism in assessing the most critical traceable events for tracking and tracing process. Successful case study, software system design and implementation demonstrated the performance of the proposed approach. Furthermore, experiment shows the better results obtained after the simulation execution for intelligent predictive algorithm. "
}
@article{Lim201561,
title = "Point cloud modeling using the homogeneous transformation for non-cooperative pose estimation ",
journal = "Acta Astronautica ",
volume = "111",
number = "",
pages = "61 - 76",
year = "2015",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515000429",
author = "Tae W. Lim",
keywords = "Non-cooperative pose estimation",
keywords = "Homogeneous transformation",
keywords = "Point cloud modeling",
keywords = "Flash lidar",
keywords = "Proximity operation ",
abstract = "Abstract A modeling process to simulate point cloud range data that a lidar (light detection and ranging) sensor produces is presented in this paper in order to support the development of non-cooperative pose (relative attitude and position) estimation approaches which will help improve proximity operation capabilities between two adjacent vehicles. The algorithms in the modeling process were based on the homogeneous transformation, which has been employed extensively in robotics and computer graphics, as well as in recently developed pose estimation algorithms. Using a flash lidar in a laboratory testing environment, point cloud data of a test article was simulated and compared against the measured point cloud data. The simulated and measured data sets match closely, validating the modeling process. The modeling capability enables close examination of the characteristics of point cloud images of an object as it undergoes various translational and rotational motions. Relevant characteristics that will be crucial in non-cooperative pose estimation were identified such as shift, shadowing, perspective projection, jagged edges, and differential point cloud density. These characteristics will have to be considered in developing effective non-cooperative pose estimation algorithms. The modeling capability will allow extensive non-cooperative pose estimation performance simulations prior to field testing, saving development cost and providing performance metrics of the pose estimation concepts and algorithms under evaluation. The modeling process also provides “truth” pose of the test objects with respect to the sensor frame so that the pose estimation error can be quantified. "
}
@article{Whelan20153,
title = "Incremental and batch planar simplification of dense point cloud maps ",
journal = "Robotics and Autonomous Systems ",
volume = "69",
number = "",
pages = "3 - 14",
year = "2015",
note = "Selected papers from 6th European Conference on Mobile Robots ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.08.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001961",
author = "T. Whelan and L. Ma and E. Bondarev and P.H.N. de With and J. McDonald",
keywords = "Planar simplification",
keywords = "Point clouds",
keywords = "Mapping",
keywords = "Plane segmentation",
keywords = "Triangulation",
keywords = "Incremental ",
abstract = "Abstract Dense RGB-D \{SLAM\} techniques and high-fidelity \{LIDAR\} scanners are examples from an abundant set of systems capable of providing multi-million point datasets. These datasets quickly become difficult to process due to the sheer volume of data, typically containing significant redundant information, such as the representation of planar surfaces with millions of points. In order to exploit the richness of information provided by dense methods in real-time robotics, techniques are required to reduce the inherent redundancy of the data. In this paper we present a method for incremental planar segmentation of a gradually expanding point cloud map and a method for efficient triangulation and texturing of planar surface segments. Experimental results show that our incremental segmentation method is capable of running in real-time while producing a segmentation faithful to what would be achieved using a batch segmentation method. Our results also show that the proposed planar simplification and triangulation algorithm removes more than 90% of the input planar points, leading to a triangulation with only 10% of the original quantity of triangles per planar segment. Additionally, our texture generation algorithm preserves all colour information contained within planar segments, resulting in a visually appealing and geometrically accurate simplified representation. "
}
@article{Barazzetti201571,
title = "Cloud-to-BIM-to-FEM: Structural simulation with accurate historic \{BIM\} from laser scans ",
journal = "Simulation Modelling Practice and Theory ",
volume = "57",
number = "",
pages = "71 - 87",
year = "2015",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2015.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X15000994",
author = "Luigi Barazzetti and Fabrizio Banfi and Raffaella Brumana and Gaia Gusmeroli and Mattia Previtali and Giuseppe Schiantarelli",
keywords = "BIM",
keywords = "FEM",
keywords = "Interoperability",
keywords = "Point cloud",
keywords = "Structural simulation ",
abstract = "Abstract The complexity of historic constructions, with irregular geometry, inhomogeneous materials, variable morphology, alterations and damages, poses numerous challenges in the digital modeling and simulation of structural performances under different types of actions. Although recent developments in Building Information Modeling have introduced advanced simulation capabilities, the numerical characterization of historic buildings is still a challenging task for the lack of reliable procedures for structural simulation. This paper presents an innovative two-step methodology (Cloud-to-BIM-to-FEM) able to convert a historic \{BIM\} into a finite element model for structural simulation. The generation of the \{BIM\} (Cloud-to-BIM) is carried out with an accurate survey that integrates geometrical aspects, diagnostic analysis based on destructive and non-destructive inspections, material information, element interconnections, and architectural and structural considerations. The \{BIM\} is then turned into a finite element model (BIM-to-FEM) with a geometric rationalization which preserves irregularities and anomalies, such as verticality deviation and variable thickness. After setting material properties, loads, and boundary conditions, the structural simulation is run with a detailed model that respects the uniqueness and authenticity of the historic building, without the typical excessive geometric simplifications of the shape. A real case study is illustrated and discussed to prove that a rigorous Cloud-to-BIM-to-FEM workflow allows the generation of an accurate historic \{BIM\} from a set of laser scanning point clouds. Structural simulation was carried out with a 3D mesh derived from the \{BIM\} in order to take into consideration the geometrical irregularity of a castle. Here, the advantages and disadvantages of the proposed approach are illustrated and discussed. "
}
@article{Drăgoicea20121702,
title = "A Service Science Knowledge Environment in the Cloud ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "6",
pages = "1702 - 1707",
year = "2012",
note = "14th \{IFAC\} Symposium on Information Control Problems in Manufacturing ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-RO-2023.00438",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016333961",
author = "Monica Drăgoicea and Theodor Borangiu",
keywords = "Service Science",
keywords = "service system",
keywords = "value co-creation",
keywords = "ontology",
keywords = "cloud computing ",
abstract = "Abstract This paper emphasize the way in which the co-creation of value can profit from semantic-driven social software, taking into consideration the case of educational services delivered in the cloud. The solution is delivered in the context of the POS-DRU Project no. 57748 “INSEED - Strategic Program Fostering Service Innovation Through Open, Continuous education” and it approaches conception and development of an open, collaborative, interactive environment to gather around universities, industry, governmental agencies and European institutions in order to foster service innovation by means of information / proves / technological transfer of the research results aiming to develop sustainable service systems solutions. In this respect, a specification proposal for a collaborative service process based on co-creation of value between educational service providers and consumers is presented. As a case study, a deployment proposal in the \{IBM\} Cloud environment for the \{INSEED\} project is depicted. "
}
@article{IñigoBlasco2012803,
title = "Robotics software frameworks for multi-agent robotic systems development ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "6",
pages = "803 - 821",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012000322",
author = "Pablo Iñigo-Blasco and Fernando Diaz-del-Rio and M Carmen Romero-Ternero and Daniel Cagigas-Muñiz and Saturnino Vicente-Diaz",
keywords = "Robotics",
keywords = "MAS",
keywords = "Agents",
keywords = "Software frameworks",
keywords = "Middleware",
keywords = "Architecture ",
abstract = "Robotics is an area of research in which the paradigm of Multi-Agent Systems (MAS) can prove to be highly useful. Multi-Agent Systems come in the form of cooperative robots in a team, sensor networks based on mobile robots, and robots in Intelligent Environments, to name but a few. However, the development of Multi-Agent Robotic Systems (MARS) still presents major challenges. Over the past decade, a high number of Robotics Software Frameworks (RSFs) have appeared which propose some solutions to the most recurrent problems in robotics. Some of these frameworks, such as ROS, YARP, OROCOS, ORCA, Open-RTM, and Open-RDK, possess certain characteristics and provide the basic infrastructure necessary for the development of MARS. The contribution of this work is the identification of such characteristics as well as the analysis of these frameworks in comparison with the general-purpose Multi-Agent System Frameworks (MASFs), such as \{JADE\} and Mobile-C. "
}
@article{PuigPey2017162,
title = "Public entities driven robotic innovation in urban areas ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "162 - 172",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016302792",
author = "Ana Puig-Pey and Yolanda Bolea and Antoni Grau and Josep Casanovas",
keywords = "Robotics",
keywords = "Urban challenges",
keywords = "Smart City",
keywords = "Innovative Public Procurement",
keywords = "Public end Users Driven Technological Innovation ",
abstract = "Abstract Cities present new challenges and needs to satisfy and improve lifestyle for their citizens under the concept “Smart City”. In order to achieve this goal in a global manner, new technologies are required as the robotic one. But Public entities unknown the possibilities offered by this technology to get solutions to their needs. In this paper the development of the Innovative Public Procurement instruments is explained, specifically the process \{PDTI\} (Public end Users Driven Technological Innovation) as a driving force of robotic research and development and offering a list of robotic urban challenges proposed by European cities that have participated in such a process. In the next phases of the procedure, this fact will provide novel robotic solutions addressed to public demand that are an example to be followed by other Smart Cities. "
}
@article{Schauer2015440,
title = "Collision detection between point clouds using an efficient k-d tree implementation ",
journal = "Advanced Engineering Informatics ",
volume = "29",
number = "3",
pages = "440 - 458",
year = "2015",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2015.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S1474034615000348",
author = "Johannes Schauer and Andreas Nüchter",
keywords = "Collision detection",
keywords = "Interference detection",
keywords = "k-d tree",
keywords = "Kinematic laser scanning",
keywords = "3D point clouds ",
abstract = "Abstract Context: An important task in civil engineering is the detection of collisions of a 3D model with an environment representation. Existing methods using the structure gauge provide an insufficient measure because the model either rotates or because the trajectory makes tight turns through narrow passages. This is the case in either automotive assembly lines or in narrow train tunnels. Objective: Given two point clouds, one of the environment and one of a model and a trajectory with six degrees of freedom along which the model moves through the environment, find all colliding points of the environment with the model within a certain clearance radius. Method: This paper presents two collision detection (CD) methods called kd-CD and kd-CD-simple and two penetration depth (PD) calculation methods called kd-PD and kd-PD-fast. All four methods are based on searches in a k-d tree representation of the environment. The creation of the k-d tree, its search methods and other features will be explained in the scope of their use to detect collisions and calculate depths of penetration. Results: The algorithms are benchmarked by moving the point cloud of a train wagon with 2.5 million points along the point cloud of a 1144 m long train track through a narrow tunnel with overall 18.92 million points. Points where the wagon collides with the tunnel wall are visually highlighted with their penetration depth. With a safety margin of 5 cm kd-PD-simple finds all colliding points on its trajectory which is sampled into 19,392 positions in 77 s on a standard desktop machine of 1.6 GHz. Conclusion: The presented methods for collision detection and penetration depth calculation are shown to solve problems for which the structure gauge is an insufficient measure. The underlying k-d tree is shown to be an effective data structure for the required look-up operations. "
}
@article{Kerr201723,
title = "Accurate 3D reconstruction of bony surfaces using ultrasonic synthetic aperture techniques for robotic knee arthroplasty ",
journal = "Computerized Medical Imaging and Graphics ",
volume = "58",
number = "",
pages = "23 - 32",
year = "2017",
note = "",
issn = "0895-6111",
doi = "https://doi.org/10.1016/j.compmedimag.2017.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0895611117300204",
author = "William Kerr and Philip Rowe and Stephen Gareth Pierce",
keywords = "Ultrasound",
keywords = "Total focussing method",
keywords = "Synthetic aperture focussing technique",
keywords = "Robotics",
keywords = "3D surface reconstruction",
keywords = "Computer-aided surgery ",
abstract = "Abstract Robotically guided knee arthroplasty systems generally require an individualized, preoperative 3D model of the knee joint. This is typically measured using Computed Tomography (CT) which provides the required accuracy for preoperative surgical intervention planning. Ultrasound imaging presents an attractive alternative to CT, allowing for reductions in cost and the elimination of doses of ionizing radiation, whilst maintaining the accuracy of the 3D model reconstruction of the joint. Traditional phased array ultrasound imaging methods, however, are susceptible to poor resolution and signal to noise ratios (SNR). Alleviating these weaknesses by offering superior focusing power, synthetic aperture methods have been investigated extensively within ultrasonic non-destructive testing. Despite this, they have yet to be fully exploited in medical imaging. In this paper, the ability of a robotic deployed ultrasound imaging system based on synthetic aperture methods to accurately reconstruct bony surfaces is investigated. Employing the Total Focussing Method (TFM) and the Synthetic Aperture Focussing Technique (SAFT), two samples were imaged which were representative of the bones of the knee joint: a human-shaped, composite distal femur and a bovine distal femur. Data were captured using a 5 MHz, 128 element 1D phased array, which was manipulated around the samples using a robotic positioning system. Three dimensional surface reconstructions were then produced and compared with reference models measured using a precision laser scanner. Mean errors of 0.82 mm and 0.88 mm were obtained for the composite and bovine samples, respectively, thus demonstrating the feasibility of the approach to deliver the sub-millimetre accuracy required for the application. "
}
@article{Weber201596,
title = "Automatic registration of unordered point clouds acquired by Kinect sensors using an overlap heuristic ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "102",
number = "",
pages = "96 - 109",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614002895",
author = "T. Weber and R. Hänsch and O. Hellwich",
keywords = "Point cloud fusion",
keywords = "Point cloud registration",
keywords = "Microsoft Kinect ",
abstract = "Abstract This paper proposes and evaluates a pipeline to automatically register point clouds captured by depth sensors like the Microsoft Kinect. The method neither makes assumptions about the view order of the sensors, nor uses any kind of other task-dependent prior knowledge. All point clouds within the input set are aligned in a common, global coordinate system by a successive application of pairwise registration steps. The order of the individual transformations is automatically derived from a global point cloud graph, which uses the overlap of two individual point clouds to establish a weighted link between them. The experiments prove the generality of the proposed approach by applying it to data from a single but moving sensor, multiple Kinects that run simultaneously, as well as laser scanning data. The obtained accuracies in terms of the mean nearest point neighbor distance are below 0.01% of the maximum point distance of the reference data in all cases. "
}
@article{Bidot2017229,
title = "Geometric backtracking for combined task and motion planning in robotic systems ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "229 - 265",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S000437021500051X",
author = "Julien Bidot and Lars Karlsson and Fabien Lagriffoul and Alessandro Saffiotti",
keywords = "Combined task and motion planning",
keywords = "Task planning",
keywords = "Action planning",
keywords = "Path planning",
keywords = "Robotics",
keywords = "Geometric reasoning",
keywords = "Hybrid reasoning",
keywords = "Robot manipulation ",
abstract = "Abstract Planners for real robotic systems should not only reason about abstract actions, but also about aspects related to physical execution such as kinematics and geometry. We present an approach to hybrid task and motion planning, in which state-based forward-chaining task planning is tightly coupled with motion planning and other forms of geometric reasoning. Our approach is centered around the problem of geometric backtracking that arises in hybrid task and motion planning: in order to satisfy the geometric preconditions of the current action, a planner may need to reconsider geometric choices, such as grasps and poses, that were made for previous actions. Geometric backtracking is a necessary condition for completeness, but it may lead to a dramatic computational explosion due to the large size of the space of geometric states. We explore two avenues to deal with this issue: the use of heuristics based on different geometric conditions to guide the search, and the use of geometric constraints to prune the search space. We empirically evaluate these different approaches, and demonstrate that they improve the performance of hybrid task and motion planning. We demonstrate our hybrid planning approach in two domains: a real, humanoid robotic platform, the \{DLR\} Justin robot, performing object manipulation tasks; and a simulated autonomous forklift operating in a warehouse. "
}
@article{Yan201565,
title = "Comparison of CERES-MODIS cloud microphysical properties with surface observations over Loess Plateau ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "153",
number = "",
pages = "65 - 76",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part \{II\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003811",
author = "Hongru Yan and Jianping Huang and Patrick Minnis and Yuhong Yi and Sunny Sun-Mack and Tianhe Wang and Takashi Y. Nakajima",
keywords = "Validation",
keywords = "Cloud microphysical properties",
keywords = "Satellite ",
abstract = "Abstract To enhance the utility of satellite-derived cloud properties for studying the role of clouds in climate change and the hydrological cycle in semi-arid areas, it is necessary to know their uncertainties. This paper estimates the uncertainties of several cloud properties by comparing those derived over the China Loess Plateau from the MODerate-resolution Imaging Spectroradiometer (MODIS) on Terra and Aqua by the Clouds and Earth׳s Radiant Energy System (CERES) with surface observations at the Semi-Arid Climate and Environment Observatory of Lanzhou University (SACOL). The comparisons use data from January 2008 to June 2010 limited to single layer and overcast stratus conditions during daytime. Cloud optical depths (τ) and liquid water paths (LWP) from both Terra and Aqua generally track the variation of the surface counterparts with modest correlation, while cloud effective radius (re) is only weakly correlated with the surface retrievals. The mean differences between Terra and the \{SACOL\} retrievals are −4.7±12.9, 2.1±3.2 μm and 30.2±85.3 g m−2 for τ, re and LWP, respectively. The corresponding differences for Aqua are 2.1±8.4, 1.2±2.9 μm and 47.4±79.6 g m−2, respectively. Possible causes for biases of satellite retrievals are discussed through statistical analysis and case studies. Generally, the CERES-MODIS cloud properties have a bit larger biases over the Loess Plateau than those in previous studies over other locations. "
}
@article{Turek2016234,
title = "Highly scalable Erlang framework for agent-based metaheuristic computing ",
journal = "Journal of Computational Science ",
volume = "17, Part 1",
number = "",
pages = "234 - 248",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2016.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1877750316300242",
author = "Wojciech Turek and Jan Stypka and Daniel Krzywicki and Piotr Anielski and Kamil Pietak and Aleksander Byrski and Marek Kisiel-Dorohinicki",
keywords = "Metaheuristic computing",
keywords = "Concurrent programming",
keywords = "Scalability",
keywords = "Erlang ",
abstract = "Abstract Difficult search and optimization problems, usually solved by metaheuristics, are very often implemented in concurrent and parallel environment, as many metaheuristics (e.g. population- or agent-based) are inherently easy to parallelize. Therefore search for easy-to-use, robust and efficient frameworks dedicated for such computing methods, especially in the era of ubiquitous many and multi-core systems, is very desirable. Indeed, the development of multi-core architectures is incredibly fast and multicore \{CPUs\} can be found nowadays not only in supercomputers, but also in ordinary laptops or even phones. Efficient use of multicore architectures requires applying suitable languages and technologies, like Erlang. Its concurrency model, based on lightweight processes and asynchronous message-passing, seems very well suited for running massively concurrent code on many cores. Most of existing Erlang industrial applications are deployed on computers with up to 24 \{CPU\} cores, and there are hardly any reports on using Erlang on architectures exceeding 32 physical cores. In this paper we present our experiences with developing a concurrent Erlang-based computing platform, scaling computationally-intensive and memory-intensive applications up to 64 cores, using as examples global optimization and urban traffic planning problems. "
}
@article{Wang2015786,
title = "WRCloud: A Novel \{WEEE\} Remanufacturing Cloud System ",
journal = "Procedia \{CIRP\} ",
volume = "29",
number = "",
pages = "786 - 791",
year = "2015",
note = "The 22nd \{CIRP\} Conference on Life Cycle Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.02.011",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115000505",
author = "Xi Vincent Wang and Lihui Wang",
keywords = "Cloud Manufacturing",
keywords = "Cloud Remanufacturing",
keywords = "WEEE",
keywords = "WEEE Recovery",
keywords = "WEEE Recycle ",
abstract = "Abstract Cloud manufacturing is a new manufacturing paradigm that offers manufacturing capabilities in terms of Cloud services. As a specific type of manufacturing, Waste Electrical and Electronic Equipment (WEEE) remanufacturing experiences difficulties in system integration, data exchange and resource management, especially when the products reach the end of lifecycle. Thus it is possible to introduce the Cloud manufacturing paradigm into \{WEEE\} remanufacturing environment, to overcome the obstacles and bottlenecks. In this paper, a novel Cloud-based system is developed to support \{WEEE\} remanufacturing. The \{WEEE\} recycle/recovery capabilities are integrated and deployed as flexible services in the Cloud. Supporting mechanisms and technologies are also developed, which are presented and evaluated via case studies. "
}
@article{Wu2015169,
title = "Tolerance Design and Adjustment of Complex Customized Product Based on Cloud Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "27",
number = "",
pages = "169 - 175",
year = "2015",
note = "13th \{CIRP\} conference on Computer Aided Tolerancing ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.04.061",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115003236",
author = "Zijian Wu and Zhenbo Gao and Yanlong Cao and Xiaoping Ye and Jiangxin Yang",
keywords = "cloud manufacturing",
keywords = "quality loss",
keywords = "manufacturing cost",
keywords = "dynamic tolerance adjustment ",
abstract = "Abstract A local and temporal separated manufacturing becomes possible, which can enhance the economic efficiency of the production. Complex products such as spacecraft, large \{CNC\} Machine, large compressor face challenges in their development process. The cloud manufacturing which is based on the development of cloud computing and Internet of Things system makes the collaborative manufacturing process of complex customized product become rapid intelligent efficient and of low-energy consumption. Cloud Manufacturing is a new manufacturing pattern which organizes the manufacturing resource to provide customers with all kinds of manufacturing services as needed. Customers who have taken part in this kind of manufacturing process could integrate the resource anytime anywhere according to the product requirement. Different from the traditional manufacturing pattern, Cloud manufacturing is multi-selective dynamic and the process may be across the stage. With more resources in the manufacturing process involved, cost of the manufacturing may be increased, so the cloud manufacturing is more suitable for small batch manufacture process of large and complex manufacturing process of customized products. In this article, we put forward a dynamic tolerance design and management framework of complex customized product based on cloud manufacturing. When the product comes into the manufacturing process, the dimension might be overflown of the acceptable zone which had been designed in the engineering phase, therefore we introduce a dynamic control that at every stage of the manufacturing we re-organize the resource based on the real-time information of the manufacturing cloud (in other word, ability of the manufacturing service) and the performance of former service. To ensure the function of the product expressed integrality and assembly process carried out smoothly, we could obtain the target optimal solution of dynamic allocation process of the tolerance on the follow-up process according to the minimum goal of the cost time and quality loss in dynamic adjustment and process stability. "
}
@article{Talhi2015288,
title = "Towards a Cloud Manufacturing systems modeling methodology ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "288 - 293",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.096",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315003353",
author = "A. Talhi and J.C. Huet and V. Fortineau and S. Lamouri",
keywords = "Ontology",
keywords = "Cloud Manufacturing",
keywords = "ASDI",
keywords = "modeling ",
abstract = "Abstract In this study we present an adaptation of \{ASDI\} (Analysis-Specification-Design- Impelmenation) methodology to the Cloud Manufacturing domain. Cloud Manufacturing is an emerging paradigm in which dynamically scalable and virtualized manufacturing resources are provided to the users as services over the Internet. In order to implement a Cloud Manufacturing platform that will map manufacturing users and providers we propose a modeling methodology named ASDI-Onto. It uses ontologies as modeling approaches to model the Cloud Manufacturing domain and introduce the outlines of the future work. "
}
@article{Nurunnabi20151404,
title = "Outlier detection and robust normal-curvature estimation in mobile laser scanning 3D point cloud data ",
journal = "Pattern Recognition ",
volume = "48",
number = "4",
pages = "1404 - 1419",
year = "2015",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2014.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0031320314004312",
author = "Abdul Nurunnabi and Geoff West and David Belton",
keywords = "Feature extraction",
keywords = "Plane fitting",
keywords = "Point cloud denoising",
keywords = "Robust saliency feature",
keywords = "Segmentation",
keywords = "Surface reconstruction ",
abstract = "Abstract This paper proposes two robust statistical techniques for outlier detection and robust saliency features, such as surface normal and curvature, estimation in laser scanning 3D point cloud data. One is based on a robust z-score and the other uses a Mahalanobis type robust distance. The methods couple the ideas of point to plane orthogonal distance and local surface point consistency to get Maximum Consistency with Minimum Distance (MCMD). The methods estimate the best-fit-plane based on most probable outlier free, and most consistent, points set in a local neighbourhood. Then the normal and curvature from the best-fit-plane will be highly robust to noise and outliers. Experiments are performed to show the performance of the algorithms compared to several existing well-known methods (from computer vision, data mining, machine learning and statistics) using synthetic and real laser scanning datasets of complex (planar and non-planar) objects. Results for plane fitting, denoising, sharp feature preserving and segmentation are significantly improved. The algorithms are demonstrated to be significantly faster, more accurate and robust. Quantitatively, for a sample size of 50 with 20% outliers the proposed MCMD_Z is approximately 5, 15 and 98 times faster than the existing methods: uLSIF, \{RANSAC\} and RPCA, respectively. The proposed MCMD_MD method can tolerate 75% clustered outliers, whereas, \{RPCA\} and \{RANSAC\} can only tolerate 47% and 64% outliers, respectively. In terms of outlier detection, for the same dataset, MCMD_Z has an accuracy of 99.72%, 0.4% false positive rate and 0% false negative rate; for RPCA, \{RANSAC\} and uLSIF, the accuracies are 97.05%, 47.06% and 94.54%, respectively, and they have misclassification rates higher than the proposed methods. The new methods have potential for local surface reconstruction, fitting, and other point cloud processing tasks. "
}
@article{Jerbić2015847,
title = "Robot Assisted 3D Point Cloud Object Registration ",
journal = "Procedia Engineering ",
volume = "100",
number = "",
pages = "847 - 852",
year = "2015",
note = "25th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2014 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.01.440",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815004671",
author = "Bojan Jerbić and Filip Šuligoj and Marko Švaco and Bojan Šekoranja",
keywords = "Point cloud data",
keywords = "position estimation",
keywords = "object recognition",
keywords = "machine learning",
keywords = "stereovision ",
abstract = "Abstract In this paper we describe a method for registration of 3D point clouds that represent objects of interest. A stereovision system is used to capture point clouds of a static environment, robot arm and an unknown object. By moving the robot arm in the environment the proposed system defines known occupied zones and is able to identify the robot arm. In order to identify a complete point cloud presentation of the robot gripper it is rotated in front of a stereovision camera and its geometry is captured from different angles. Iterative closest point algorithm is used to determine a rigid transformation between every new robot pose so the original point cloud can be appended with the transformed one. When the robot is holding a new object the registration procedure is repeated and known elements (environment, robot arm and gripper) are removed so that the object can be identified. "
}
@article{AminiSalehi201696,
title = "Stochastic-based robust dynamic resource allocation for independent tasks in a heterogeneous computing system ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "97",
number = "",
pages = "96 - 111",
year = "2016",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2016.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0743731516300739",
author = "Mohsen Amini Salehi and Jay Smith and Anthony A. Maciejewski and Howard Jay Siegel and Edwin K.P. Chong and Jonathan Apodaca and Luis D. Briceño and Timothy Renner and Vladimir Shestak and Joshua Ladd and Andrew Sutton and David Janovy and Sudha Govindasamy and Amin Alqudah and Rinku Dewri and Puneet Prakash",
keywords = "Dynamic resource allocation",
keywords = "Heterogeneous computing",
keywords = "Robustness",
keywords = "Scheduling",
keywords = "Stochastic models ",
abstract = "Abstract Heterogeneous parallel and distributed computing systems frequently must operate in environments where there is uncertainty in system parameters. Robustness can be defined as the degree to which a system can function correctly in the presence of parameter values different from those assumed. In such an environment, the execution time of any given task may fluctuate substantially due to factors such as the content of data to be processed. Determining a resource allocation that is robust against this uncertainty is an important area of research. In this study, we define a stochastic robustness measure to facilitate resource allocation decisions in a dynamic environment where tasks are subject to individual hard deadlines and each task requires some input data to start execution. In this environment, the tasks that cannot meet their deadlines are dropped (i.e., discarded). We define methods to determine the stochastic completion times of tasks in the presence of the task dropping. The stochastic task completion time is used in the definition of the stochastic robustness measure. Based on this stochastic robustness measure, we design novel resource allocation techniques that work in immediate and batch modes, with the goal of maximizing the number of tasks that meet their individual deadlines. We compare the performance of our technique against several well-known approaches taken from the literature and adapted to our environment. Simulation results of this study demonstrate the suitability of our new technique in a dynamic heterogeneous computing system. "
}
@article{Vonásek2012210,
title = "Techniques for Modeling Simulation Environments for Modular Robotics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "2",
pages = "210 - 215",
year = "2012",
note = "7th Vienna International Conference on Mathematical Modelling ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120215-3-AT-3016.00037",
url = "http://www.sciencedirect.com/science/article/pii/S147466701630670X",
author = "Vojtěch Vonásek and Miroslav Kulich and Tomáš Krajník and Martin Saska and Daniel Fišer and Vladimír Petrík and Libor Přeučil",
keywords = "modular robotics",
keywords = "simulation",
keywords = "3D model reconstruction ",
abstract = "Abstract In modular robotics, complex structures can be formed from basic modules to solve tasks which would be difficult for a single robot. The development of techniques for adaptation and evolution of multi-robot organisms is the subject of Symbrion project Levi and Kernbach (2010). In the project, the bio-inspired evolutionary algorithms are massively simulated prior to run them on a real hardware. It is crucial to evolve behaviors of the robots in a simulation, that is close to a real world. Hence, accurate and efficient representation of an environment in the simulation is needed. The robots learn simple motion primitives or complex movement patterns during many runs of the evolution. The learned skills are then used during experiments with a real hardware. In this paper, we present methods for building 3D model of a real arena using a laser rangefinder. The resulting 3D models consist of triangles. They can be constructed in various level of details using state-of-the-art methods for 3D reconstruction. We will show, how the size of the models influences the speed of the simulation. "
}
@article{Iqbal2011871,
title = "Adaptive resource provisioning for read intensive multi-tier applications in the cloud ",
journal = "Future Generation Computer Systems ",
volume = "27",
number = "6",
pages = "871 - 879",
year = "2011",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2010.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X10002098",
author = "Waheed Iqbal and Matthew N. Dailey and David Carrera and Paul Janecek",
keywords = "Cloud computing",
keywords = "Adaptive resource management",
keywords = "Quality of service",
keywords = "Multi-tier applications",
keywords = "Service-Level Agreement",
keywords = "Scalability ",
abstract = "A Service-Level Agreement (SLA) provides surety for specific quality attributes to the consumers of services. However, current \{SLAs\} offered by cloud infrastructure providers do not address response time, which, from the user’s point of view, is the most important quality attribute for Web applications. Satisfying a maximum average response time guarantee for Web applications is difficult for two main reasons: first, traffic patterns are highly dynamic and difficult to predict accurately; second, the complex nature of multi-tier Web applications increases the difficulty of identifying bottlenecks and resolving them automatically. This paper proposes a methodology and presents a working prototype system for automatic detection and resolution of bottlenecks in a multi-tier Web application hosted on a cloud in order to satisfy specific maximum response time requirements. It also proposes a method for identifying and retracting over-provisioned resources in multi-tier cloud-hosted Web applications. We demonstrate the feasibility of the approach in an experimental evaluation with a testbed EUCALYPTUS-based cloud and a synthetic workload. Automatic bottleneck detection and resolution under dynamic resource management has the potential to enable cloud infrastructure providers to provide \{SLAs\} for Web applications that guarantee specific response time requirements while minimizing resource utilization. "
}
@article{Tedeschi201547,
title = "Security Aspects in Cloud Based Condition Monitoring of Machine Tools ",
journal = "Procedia \{CIRP\} ",
volume = "38",
number = "",
pages = "47 - 52",
year = "2015",
note = "Proceedings of the 4th International Conference on Through-life Engineering Services ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.07.046",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115008057",
author = "Stefano Tedeschi and Jörn Mehnen and Nikolaos Tapoglou and Roy Rajkumar",
keywords = "Cloud",
keywords = "Remote Maintenance",
keywords = "Machine Tool",
keywords = "Secure Communications",
keywords = "Remote Monitoring ",
abstract = "Abstract In the modern competitive environments companies must have rapid production systems that are able to deliver parts that satisfy highest quality standards. Companies have also an increased need for advanced machines equipped with the latest technologies in maintenance to avoid any reduction or interruption of production. Eminent therefore is the need to monitor the health status of the manufacturing equipment in real time and thus try to develop diagnostic technologies for machine tools. This paper lays the foundation for the creation of a safe remote monitoring system for machine tools using a Cloud environment for communication between the customer and the maintenance service company. Cloud technology provides a convenient means for accessing maintenance data anywhere in the world accessible through simple devices such as PC, tablets or smartphones. In this context the safety aspects of a Cloud system for remote monitoring of machine tools becomes crucial and is, thus the focus of this paper. "
}
@article{Mizeranschi20161,
title = "MultiGrain/MAPPER: A distributed multiscale computing approach to modeling and simulating gene regulation networks ",
journal = "Future Generation Computer Systems ",
volume = "63",
number = "",
pages = "1 - 14",
year = "2016",
note = "Modeling and Management for Big Data Analytics and Visualization ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16300711",
author = "Alexandru E. Mizeranschi and Martin T. Swain and Raluca Scona and Quentin Fazilleau and Bartosz Bosak and Tomasz Piontek and Piotr Kopta and Paul Thompson and Werner Dubitzky",
keywords = "Gene-regulatory networks",
keywords = "Reverse-engineering of gene-regulation models",
keywords = "Distributed multiscale computing ",
abstract = "Abstract Modeling and simulation of gene-regulatory networks (GRNs) has become an important aspect of modern systems biology investigations into mechanisms underlying gene regulation. A key task in this area is the automated inference or reverse-engineering of dynamic mechanistic \{GRN\} models from gene expression time-course data. Besides a lack of suitable data (in particular multi-condition data from the same system), one of the key challenges of this task is the computational complexity involved. The more genes in the \{GRN\} system and the more parameters a \{GRN\} model has, the higher the computational load. The computational challenge is likely to increase substantially in the near future when we tackle larger \{GRN\} systems. The goal of this study was to develop a distributed computing framework and system for reverse-engineering of \{GRN\} models. We present the resulting software called MultiGrain/MAPPER. This software is based on a new architecture and tools supporting multiscale computing in a distributed computing environment. A key feature of MultiGrain/MAPPER is the realization of \{GRN\} reverse-engineering based on the underlying distributed computing framework and multi-swarm particle swarm optimization. We demonstrate some of the features of MultiGrain/MAPPER and evaluate its performance using both real and artificial gene expression data. "
}
@article{Wang2016377,
title = "ACP-based social computing and parallel intelligence: Societies 5.0 and beyond ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "1",
number = "4",
pages = "377 - 393",
year = "2016",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2016.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S246823221630083X",
author = "Xiao Wang and Lingxi Li and Yong Yuan and Peijun Ye and Fei-Yue Wang",
keywords = "Social computing",
keywords = "Societies 5.0",
keywords = "Parallel intelligence",
keywords = "Knowledge automation",
keywords = "Cyber-physical-social system",
keywords = "Artificial societies",
keywords = "Computational experiments",
keywords = "Parallel execution ",
abstract = "Abstract Social computing, as the technical foundation of future computational smart societies, has the potential to improve the effectiveness of open-source big data usage, systematically integrate a variety of elements including time, human, resources, scenarios, and organizations in the current cyber-physical-social world, and establish a novel social structure with fair information, equal rights, and a flat configuration. Meanwhile, considering the big modeling gap between the model world and the physical world, the concept of parallel intelligence is introduced. With the help of software-defined everything, parallel intelligence bridges the big modeling gap by means of constructing artificial systems where computational experiments can be implemented to verify social policies, economic strategies, and even military operations. Artificial systems play the role of “social laboratories” in which decisions are computed before they are executed in our physical society. Afterwards, decisions with the expected outputs are executed in parallel in both the artificial and physical systems to interactively sense, compute, evaluate and adjust system behaviors in real-time, leading system behaviors in the physical system converging to those proven to be optimal in the artificial ones. Thus, the smart guidance and management for our society can be achieved. "
}
@article{Mourtzis20159,
title = "Cloud-based Integrated Shop-floor Planning and Control of Manufacturing Operations for Mass Customisation ",
journal = "Procedia \{CIRP\} ",
volume = "33",
number = "",
pages = "9 - 16",
year = "2015",
note = "9th \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering - \{CIRP\} \{ICME\} '14 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115006472",
author = "D. Mourtzis and M. Doukas and C. Lalas and N. Papakostas",
keywords = "Production Planning and Control",
keywords = "Mass Customisation",
keywords = "Decision-making",
keywords = "Software as a Service",
keywords = "Cloud Manufacturing ",
abstract = "Abstract The shift of traditional mass producing industries towards mass customisation practices is nowadays evident. However, if not implemented properly, mass customisation can lead to disturbances in material flow and severe reduction in productivity. This paper discusses the design and development of a Cloud-based production planning and control system for discrete manufacturing environments, referred to as i-MRP. The proposed approach takes into consideration capacity constraints, lot sizing and priority control in a ‘bucket-less’ manufacturing environment. The i-MRP system offers simultaneous shop scheduling and material planning, where material and capacity constraints are considered together in a continuous time environment. A number of feasible alternative shop schedules and material plan combinations are formed and are evaluated on the Cloud platform where the i-MRP engine is hosted. The Cloud platform enables mobility, since it is device and location independent, as well as it minimises the cost of \{IT\} infrastructure ownership, which is especially important for SMEs. The performance of the i-MRP system has been studied in an \{SME\} from the textile sector, using real production data. The system demonstrates high performance in cases of short production times, high value inventory and frequent, small deliveries by suppliers. The i-MRP can be easily integrated with legacy \{IT\} systems as an interfaced functional module under the Software as a Service (SaaS) architecture. "
}
@article{Kopacek201636,
title = "Development Trends in Robotics ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "29",
pages = "36 - 41",
year = "2016",
note = "17th \{IFAC\} Conference on International Stability, Technology and Culture \{TECIS\} 2016Durrës, Albania, 26—28 October 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.070",
url = "http://www.sciencedirect.com/science/article/pii/S240589631632506X",
author = "P. Kopacek",
keywords = "Robots",
keywords = "Control",
keywords = "Roboethics",
keywords = "Social aspects ",
abstract = "Abstract: Current developing trends are humanoid robots and robots supporting people in everyday life. Other intensive research areas are cooperative robots, bio inspired robots, ubiquitous robots, cloud robots, modular robots,...... Micro-, Nano-and Femtorobots are in development and Atorobots are knocking on the door. This paper is an “upgrade” from Kopacek (2015) because the field of robotics is dramatically changing. Therefore an overview as well as an outlook on future developments will be given with special emphasis to the demands and relations to TECIS. "
}
@incollection{Colombo201567,
title = "Chapter 4 - Industrial Agents in the Era of Service-Oriented Architectures and Cloud-Based Industrial Infrastructures ",
editor = "Leitão, Paulo  and Karnouskos, Stamatis ",
booktitle = "Industrial Agents ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2015",
pages = "67 - 87",
isbn = "978-0-12-800341-1",
doi = "https://doi.org/10.1016/B978-0-12-800341-1.00004-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780128003411000048",
author = "Armando Walter Colombo and Stamatis Karnouskos and João Marco Mendes and Paulo Leitão",
keywords = "Industrial agents",
keywords = "Service-oriented architecture",
keywords = "Cloud system",
keywords = "Industrial system",
keywords = "Simulation",
keywords = "Cyber-physical system",
keywords = "Collaborative automation ",
abstract = "Abstract The umbrella paradigm underpinning novel collaborative industrial systems is to consider the set of intelligent system units as a conglomerate of distributed, autonomous, intelligent, proactive, fault-tolerant, and reusable units, which operate as a set of cooperating entities. The application of the industrial agents paradigm is well-fit to act as an enabler for mastering such collaborative industrial systems, especially in conjunction with the prevalence of service-oriented architectures and cloud technologies. The overall combination is seen as promising in the effort to unleash the benefit stemming from the utilization of such sophisticated industrial systems. "
}
@article{Richter2014114,
title = "Concepts and techniques for integration, analysis and visualization of massive 3D point clouds ",
journal = "Computers, Environment and Urban Systems ",
volume = "45",
number = "",
pages = "114 - 124",
year = "2014",
note = "",
issn = "0198-9715",
doi = "https://doi.org/10.1016/j.compenvurbsys.2013.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0198971513000653",
author = "Rico Richter and Jürgen Döllner",
keywords = "3D point clouds",
keywords = "System architecture",
keywords = "Classification",
keywords = "Out-of-core",
keywords = "Visualization ",
abstract = "Abstract Remote sensing methods, such as LiDAR and image-based photogrammetry, are established approaches for capturing the physical world. Professional and low-cost scanning devices are capable of generating dense 3D point clouds. Typically, these 3D point clouds are preprocessed by \{GIS\} and are then used as input data in a variety of applications such as urban planning, environmental monitoring, disaster management, and simulation. The availability of area-wide 3D point clouds will drastically increase in the future due to the availability of novel capturing methods (e.g., driver assistance systems) and low-cost scanning devices. Applications, systems, and workflows will therefore face large collections of redundant, up-to-date 3D point clouds and have to cope with massive amounts of data. Hence, approaches are required that will efficiently integrate, update, manage, analyze, and visualize 3D point clouds. In this paper, we define requirements for a system infrastructure that enables the integration of 3D point clouds from heterogeneous capturing devices and different timestamps. Change detection and update strategies for 3D point clouds are presented that reduce storage requirements and offer new insights for analysis purposes. We also present an approach that attributes 3D point clouds with semantic information (e.g., object class category information), which enables more effective data processing, analysis, and visualization. Out-of-core real-time rendering techniques then allow for an interactive exploration of the entire 3D point cloud and the corresponding analysis results. Web-based visualization services are utilized to make 3D point clouds available to a large community. The proposed concepts and techniques are designed to establish 3D point clouds as base datasets, as well as rendering primitives for analysis and visualization tasks, which allow operations to be performed directly on the point data. Finally, we evaluate the presented system, report on its applications, and discuss further research challenges. "
}
@article{Gustin2016470,
title = "Hand gesture recognition from multibeam sonar imagery* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "23",
pages = "470 - 475",
year = "2016",
note = "10th \{IFAC\} Conference on Control Applications in Marine SystemsCAMS 2016Trondheim, Norway, 13—16 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.450",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316320389",
author = "Franka Gustin and Ivor Rendulic and Nikola Miskovic and Zoran Vukic",
keywords = "Multibeam sonar",
keywords = "gesture recognition ",
abstract = "Abstract: Divers perform demanding tasks in a complex and hazardous underwater environment, which prevents them from carrying special devices that may allow them to communicate with their robotic diving buddies. In this world of natural human-robot interaction in the underwater environment, envisioned by the \{FP7\} Cognitive Robotics project CADDY, hand detection and gesture interpretation is a prerequisite. While hand gesture recognition is most often performed with cameras (mono and stereo), their use in the underwater environment is compromised due to water turbidity and lack of sunlight at greater depths. This paper deals with this lack of performance by introducing the concept of using high resolution multibeam sonars (often referred to as acoustic cameras) for diver hand gesture recognition. In order to ensure reliable communication between the diver and the robot, it is of great importance that the classification precision is as high as possible. This paper presents results of hand gesture recognition which is performed by using two approaches: convex hull method and the support vector machine (SVM). A novel approach that fuses the two methods is introduced as a way of increasing the precision of classification. The results obtained on more than 1000 real sonar samples show that the precision using the convex hull method is around 92%, and using the \{SVM\} around 94%, while fusing the two approaches provides around 99% classification precision. "
}
@article{Carlone20118150,
title = "On Registration of Uncertain Three-dimensional Vectors with Application to Robotics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "8150 - 8158",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.01163",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016449190",
author = "Luca Carlone and Basilio Bona",
keywords = "Registration",
keywords = "Optimization",
keywords = "3D Vectors",
keywords = "Robotics",
keywords = "Robot Navigation ",
abstract = "Abstract In this paper we investigate the problem of finding a suitable roto-translation achieving the optimal matching between two uncertain three-dimensional vector sets. State-of-the-art approaches for vector registration are based on strict assumptions on the covariance matrices describing the uncertainty on the vectors, hence they can be too conservative or inaccurate when the actual uncertainty differs from the employed model. After discussing the problem we propose two iterative solutions for matching the 3D vectors, showing that a suitable uncertainty model allows reducing the estimation error while preserving the real-time nature of the computation. We further derive the covariance matrices for such estimates, evaluating their consistency through extensive numerical experiments. The results appear particularly suitable for robotic applications, since the vector sets constitute a natural representation of three-dimensional perception of a robot, interacting with complex non-planar environments. "
}
@article{Cook201222,
title = "Pervasive computing at scale: Transforming the state of the art ",
journal = "Pervasive and Mobile Computing ",
volume = "8",
number = "1",
pages = "22 - 35",
year = "2012",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2011.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S1574119211001416",
author = "Diane J. Cook and Sajal K. Das",
keywords = "Smart environments",
keywords = "Energy harvesting",
keywords = "Cloud computing",
keywords = "Smart phones",
keywords = "Behavior modeling",
keywords = "Internet of things ",
abstract = "The remarkable recent progress in computing power, sensors and embedded devices, smart phones, wireless communications and networking technologies, combined with emerging data mining techniques, cloud computing and social networking paradigms has enabled us to create pervasive computing systems and services with diverse applications and global accessibility. In this paper, we assess the current state of the art of pervasive computing at scale (PeCS) and look ahead to future directions the field can pursue together with challenges it will need to overcome. "
}
@incollection{Nomdedeu2011125,
title = "6 - Sensing capabilities for mobile robotics ",
editor = "Baudoin, Y. and ,  and Habib, Maki K. ",
booktitle = "Using Robots in Hazardous Environments ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2011",
pages = "125 - 146",
isbn = "978-1-84569-786-0",
doi = "https://doi.org/10.1533/9780857090201.2.125",
url = "http://www.sciencedirect.com/science/article/pii/B978184569786050006X",
author = "L. Nomdedeu and J. Sales and R. Marín and E. Cervera and J.S. Aez",
keywords = "\{GUARDIANS\} project",
keywords = "sensing capabilities",
keywords = "localization",
keywords = "mobile robotics",
keywords = "ego-motion",
keywords = "environment perception ",
abstract = "Abstract: This chapter provides an overview of sensing capabilities for the estimation of distances and localization in a team of mobile robot platforms. This work, similar to others in this book, has been carried out in the context of the \{EU\} \{GUARDIANS\} project (Group of Unmanned Assistant Robots Deployed In Aggregative Navigation supported by Scent detection). There is a need for a localization method not only for robot platforms but also for fire fighters. This chapter will present an overview of the current sensing capabilities available, both commercial, and those not yet commercialized. "
}
@article{Pagallo2013501,
title = "Robots in the cloud with privacy: A new threat to data protection? ",
journal = "Computer Law & Security Review ",
volume = "29",
number = "5",
pages = "501 - 508",
year = "2013",
note = "",
issn = "0267-3649",
doi = "https://doi.org/10.1016/j.clsr.2013.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S0267364913001398",
author = "Ugo Pagallo",
keywords = "Data protection",
keywords = "Human-robot interaction",
keywords = "Katz's test",
keywords = "Network-centric applications",
keywords = "Privacy",
keywords = "Privacy by design",
keywords = "Robotics technology ",
abstract = "Abstract The focus of this paper is on the class of robots for personal or domestic use, which are connected to a networked repository on the internet that allows such machines to share the information required for object recognition, navigation and task completion in the real world. The aim is to shed light on how these robots will challenge current rules on data protection and privacy. On one hand, a new generation of network-centric applications could in fact collect data incessantly and in ways that are “out of control,” because such machines are increasingly “autonomous.” On the other hand, it is likely that individual interaction with personal machines, domestic robots, and so forth, will also affect what U.S. common lawyers sum up with the Katz's test as a reasonable “expectation of privacy.” Whilst lawyers continue to liken people's responsibility for the behaviour of robots to the traditional liability for harm provoked by animals, children, or employees, attention should be drawn to the different ways in which humans will treat, train, or manage their robots-in-the-cloud, and how the human–robot interaction may affect the multiple types of information that are appropriate to reveal, share, or transfer, in a given context. "
}
@article{Li2014187,
title = "Observations of residual submicron fine aerosol particles related to cloud and fog processing during a major pollution event in Beijing ",
journal = "Atmospheric Environment ",
volume = "86",
number = "",
pages = "187 - 192",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.12.044",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013009898",
author = "Zhengqiang Li and Tom Eck and Ying Zhang and Yuhuan Zhang and Donghui Li and Li Li and Hua Xu and Weizhen Hou and Yang Lv and Philippe Goloub and Xingfa Gu",
keywords = "Residual size",
keywords = "Submicron fine mode aerosol",
keywords = "Size distribution",
keywords = "Cloud",
keywords = "Fog",
keywords = "Haze ",
abstract = "Abstract Residual aerosols, the particles left behind after droplet evaporation, are important tracers for aerosols processed by cloud and/or fog. Based on ground-based \{CIMEL\} sun–sky radiometer measurements during an extreme winter pollution event in Beijing, we present observations of the decrease of residual aerosol with dissipation of cloud and an unusual case of residual aerosol increase after partial dissipation of fog. This unusual increase might be an important mechanism for the haze growth in polluted regions. The aerosol single scattering albedo is found to increase with the increase of residual aerosol. We also find that residual aerosol dominated cases with significant water content gain can occur in a short time (e.g. one hour) with the increase of aerosol volume size and decrease of particle number. A lognormal residual aerosol size distribution model is proposed based on sun–sky radiometer measurements with center peak radius at 0.44 micron and geometric standard deviation of about 1.49. "
}
@article{Amirat20161,
title = "Assistance and Service Robotics in a Human Environment ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "1 - 3",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.002",
url = "http://www.sciencedirect.com/science/article/pii/S092188901500247X",
author = "Yacine Amirat and David Daney and Samer Mohammed and Anne Spalanzani and Abdelghani Chibani and Olivier Simonin"
}
@article{Hulik201486,
title = "Continuous plane detection in point-cloud data based on 3D Hough Transform ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "25",
number = "1",
pages = "86 - 97",
year = "2014",
note = "Visual Understanding and Applications with RGB-D Cameras ",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2013.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S104732031300062X",
author = "Rostislav Hulik and Michal Spanel and Pavel Smrz and Zdenek Materna",
keywords = "RGB-D sensor",
keywords = "Point cloud",
keywords = "Hough Transform",
keywords = "Plane detection",
keywords = "PCL library",
keywords = "RANSAC",
keywords = "Computer vision",
keywords = "Shape extraction ",
abstract = "Abstract This paper deals with shape extraction from depth images (point clouds) in the context of modern robotic vision systems. It presents various optimizations of the 3D Hough Transform used for plane extraction from point cloud data. Presented enhancements of standard methods address problems related to noisy data, high memory requirements for the parameter space and computational complexity of point accumulations. The realised robust plane detector benefits from a continuous point cloud stream generated by a depth sensor over time. It is used for iterative refinements of the results. The system is compared to a state-of-the-art RANSAC-based plane detector from the Point Cloud Library (PCL). Experimental results show that it overcomes the \{PCL\} alternative in the stability of plane detection and in the number of negative detections. This advantage is crucial for robotic applications, e.g., when a robot approaches a wall, it can be consistently recognized. The paper concludes with a discussion of further promising optimisation that will be implemented as a future step. "
}
@article{Zou20131459,
title = "Iso-parametric tool-path planning for point clouds ",
journal = "Computer-Aided Design ",
volume = "45",
number = "11",
pages = "1459 - 1468",
year = "2013",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2013.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0010448513001255",
author = "Qiang Zou and Jibin Zhao",
keywords = "Tool path",
keywords = "Point cloud",
keywords = "Meshless",
keywords = "Conformal parameterization",
keywords = "Linear interpolation ",
abstract = "Abstract Due to the compute-intensiveness and the lack of robustness of the algorithms for reconstruction of meshes and spline surfaces from point clouds, there is a need for further research in the topic of direct tool-path planning based on point clouds. In this paper, a novel approach for planning iso-parametric tool-path from a point cloud is presented. Since such planning falls into the iso-parametric category, it intrinsically depends on the parameterization of point clouds. Accordingly, a point-based conformal map is employed to build the parameterization. Based on it, formulas of computing path parameters are derived, which are much simpler than the conventional ones. By regularizing parameter domain and on the basis of the previous formulas, boundary conformed tool-path can be generated with forward and side step calculated against specified chord deviation and scallop height, respectively. Experimental results are given to illustrate the effectiveness of the proposed methods. "
}
@article{Bertacchini2017,
title = "Shopping with a robotic companion ",
journal = "Computers in Human Behavior ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2017.02.064",
url = "http://www.sciencedirect.com/science/article/pii/S0747563217301450",
author = "Francesca Bertacchini and Eleonora Bilotta and Pietro Pantano",
keywords = "Social robotics",
keywords = "Human Robot Interaction (HRI)",
keywords = "Emotion and Gesture Recognition",
keywords = "Machine learning",
keywords = "Smart retail settings ",
abstract = "Abstract In this paper, we present a robotic shopping assistant, designed with a cognitive architecture, grounded in machine learning systems, in order to study how the human-robot interaction (HRI) is changing the shopping behavior in smart technological stores. In the software environment of the \{NAO\} robot, connected to the Internet with cloud services, we designed a social-like interaction where the robot carries out actions with the customer. In particular, we focused our design on two main skills the robot has to learn: the first is the ability to acquire social input communicated by relevant clues that humans provide about their emotional state (emotions, emotional speech), or collected in the Social Media (such as, information on the customer's tastes, cultural background, etc.). The second is the skill to express in turn its own emotional state, so that it can affect the customer buying decision, refining in the user the sense of interacting with a human-like companion. By combining social robotics and machine learning systems the potential of robotics to assist people in real life situations will increase, providing a gentle customers' acceptance of advanced technologies. "
}
@article{Luo201799,
title = "Synchronized production and logistics via ubiquitous computing technology ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "99 - 115",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300424",
author = "Hao Luo and Kai Wang and Xiang T.R. Kong and Shaoping Lu and Ting Qu",
keywords = "Ubiquitous manufacturing",
keywords = "Synchronized production and logistics",
keywords = "RFID ",
abstract = "Abstract The integration of manufacturing and logistics has drawn widespread research attentions in recent years. This paper focuses on the Synchronized Production and Logistics (SPL), which is operational level integration. SPL　is defined as synchronizing the processing, moving and storing of raw material, \{WIP\} and finished product within one manufacturing unit by high level information sharing and joint scheduling to achieve synergic decision, execution and overall performance improvement. Through analysing the requirements and challenges in real life industry, the ubiquitous computing is adopted as an enabling technology and an Ubi-SPL (Synchronized Production and Logistics via Ubiquitous Technology) framework is proposed. This framework is consists of four layers, which creates a close decision-execution loop by linking the frontline real time data, user feedback and optimized decision together. A real life case study of applying Ubi-SPL solution in a chemical industry has been conducted. The implementation results show that the proposed Ubi-SPL solution can significantly improve the overall performance in both production and logistics service. "
}
@article{Gedicke2016114,
title = "\{FLAP\} for CAOS: Forward-Looking Active Perception for Clutter-Aware Object Search1 ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "114 - 119",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.718",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316309946",
author = "Thorsten Gedicke and Martin Günther and Joachim Hertzberg",
keywords = "autonomous mobile robots",
keywords = "heuristic searches",
keywords = "knowledge acquisition",
keywords = "path planning",
keywords = "probabilistic models",
keywords = "robot vision",
keywords = "sampling actions",
keywords = "searching systems ",
abstract = "Abstract In this paper, we present a system for autonomous object search and exploration in cluttered environments. The system shortens the average time needed to complete search tasks by continually planning multiple perception actions ahead of time using probabilistic prior knowledge. Useful sensing actions are found using a frontier-based view sampling technique in a continuously built 3D map. We demonstrate the system on real hardware, investigate the planner’s performance in three experiments in simulation, and show that our approach achieves shorter overall run times of search tasks compared to a greedy strategy. "
}
@article{Wu2013564,
title = "Cloud manufacturing: Strategic vision and state-of-the-art ",
journal = "Journal of Manufacturing Systems ",
volume = "32",
number = "4",
pages = "564 - 579",
year = "2013",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2013.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0278612513000411",
author = "Dazhong Wu and Matthew John Greer and David W. Rosen and Dirk Schaefer",
keywords = "Cloud manufacturing (CM)",
keywords = "Distributed systems",
keywords = "Resource sharing",
keywords = "Automation and control ",
abstract = "Abstract Cloud manufacturing, a service oriented, customer centric, demand driven manufacturing model is explored in both its possible future and current states. A unique strategic vision for the field is documented, and the current state of technology is presented from both industry and academic viewpoints. Key commercial implementations are presented, along with the state of research in fields critical to enablement of cloud manufacturing, including but not limited to automation, industrial control systems, service composition, flexibility, business models, and proposed implementation models and architectures. Comparison of the strategic vision and current state leads to suggestions for future work, including research in the areas of high speed, long distance industrial control systems, flexibility enablement, business models, cloud computing applications in manufacturing, and prominent implementation architectures. "
}
@incollection{Gudivada20163,
title = "Chapter 1 - Cognitive Computing: Concepts, Architectures, Systems, and Applications ",
editor = "Venkat N. Gudivada, Vijay V. Raghavan, Venu Govindaraju and C.R. Rao",
booktitle = "Cognitive Computing: Theory and Applications",
publisher = "Elsevier",
year = "2016",
volume = "35",
pages = "3 - 38",
series = "Handbook of Statistics ",
issn = "0169-7161",
doi = "https://doi.org/10.1016/bs.host.2016.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169716116300451",
author = "V.N. Gudivada",
keywords = "Cognitive computing",
keywords = "Cognitive architectures",
keywords = "Cognitive models",
keywords = "Cognitive systems",
keywords = "Cognitive applications",
keywords = "Cognitive computing systems",
keywords = "Data science ",
abstract = "Abstract Cognitive computing is an emerging field ushered in by the synergistic confluence of cognitive science, data science, and an array of computing technologies. Cognitive science theories provide frameworks to describe various models of human cognition including how information is represented and processed by the brain. Data science provides processes and systems to extract knowledge from both structured and unstructured data. Cognitive computing employs the computing discipline's theories, methods, and tools to model human cognition. The recent advances in data science and computing disciplines—neuromorphic processors, big data, predictive modeling, machine learning, natural language understanding, and cloud computing—are accelerating advances in cognitive science and cognitive computing. The overarching goal of this chapter is to provide an interdisciplinary introduction to cognitive computing. The focus is on breadth to provide a unified view of the discipline. The chapter begins with an overview of cognitive science, data science, and cognitive computing. The principal technology enablers of cognitive computing are presented next. An overview of three major categories of cognitive architectures is presented, which is followed by a description of cognitive computing systems and their applications. Trends and future research directions in cognitive computing are discussed. The chapter concludes by listing various cognitive computing resources. "
}
@article{Arka2014114,
title = "Collaborative Compressed I-cloud Medical Image Storage with Decompress Viewer ",
journal = "Procedia Computer Science ",
volume = "42",
number = "",
pages = "114 - 121",
year = "2014",
note = "Medical and Rehabilitation Robotics and Instrumentation (MRRI2013) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.11.041",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914014793",
author = "Israna Hossain Arka and Kalaivani Chellappan",
keywords = "medical imaging",
keywords = "cloud storage",
keywords = "compression",
keywords = "decompression",
keywords = "mobile devices",
keywords = "data security",
keywords = "collaborative. ",
abstract = "Abstract Healthcare collaborative approach is anticipated to be an appropriate solution for disease management structure in the growing global population. Efficient disease management structure needs deep analytical skills in making effective decisions based on medical data. The nature of medical data being huge in size has been categorized as big data. Big data management in a collaborative environment needs multiple technological integrations. In this paper we have proposed an independent cloud based collaborative medical image storage and mobile viewer assisted with effective compression and decompression technique with unique security structure design. The proposed design has considered deep technology exploitation to offer medical image access via mobile devices by considering all the current constraints in terms of storage, image clarity and security. The proposed architecture allows both patient and medical practioners to have a cost effective approach in disease management and treatment process. It also introduces healthcare analysts and practitioners to the advancements in the computing field to effectively handle and make inferences from voluminous and heterogeneous healthcare data. Due to the broad nature of the topic, our primary emphasis will be on introducing healthcare data repositories, challenges, and concepts in data science. Not much focus will be on describing the details of any particular techniques and/or solutions in image compression, security and the medical field in particular other than convenient data access opportunity framework. "
}
@article{Xiao20131641,
title = "Three-dimensional point cloud plane segmentation in both structured and unstructured environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1641 - 1652",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001152",
author = "Junhao Xiao and Jianhua Zhang and Benjamin Adler and Houxiang Zhang and Jianwei Zhang",
keywords = "3D point cloud",
keywords = "Plane segmentation",
keywords = "Region growing ",
abstract = "Abstract This paper focuses on three-dimensional (3D) point cloud plane segmentation. Two complementary strategies are proposed for different environments, i.e., a subwindow-based region growing (SBRG) algorithm for structured environments, and a hybrid region growing (HRG) algorithm for unstructured environments. The point cloud is decomposed into subwindows first, using the points’ neighborhood information when they are scanned by the laser range finder (LRF). Then, the subwindows are classified as planar or nonplanar based on their shape. Afterwards, only planar subwindows are employed in the former algorithm, whereas both kinds of subwindows are used in the latter. In the growing phase, planar subwindows are investigated directly (in both algorithms), while each point in nonplanar subwindows is investigated separately (only in HRG). During region growing, plane parameters are computed incrementally when a subwindow or a point is added to the growing region. This incremental methodology makes the plane segmentation fast. The algorithms have been evaluated using real-world datasets from both structured and unstructured environments. Furthermore, they have been benchmarked against a state-of-the-art point-based region growing (PBRG) algorithm with regard to segmentation speed. According to the results, \{SBRG\} is 4 and 9 times faster than \{PBRG\} when the subwindow size is set to 3×3 and 4×4 respectively; \{HRG\} is 4 times faster than \{PBRG\} when the subwindow size is set to 4×4. Open-source code for this paper is available at https://github.com/junhaoxiao/TAMS-Planar-Surface-Based-Perception.git. "
}
@article{Katsaros20132077,
title = "A service framework for energy-aware monitoring and \{VM\} management in Clouds ",
journal = "Future Generation Computer Systems ",
volume = "29",
number = "8",
pages = "2077 - 2091",
year = "2013",
note = "Including Special sections: Advanced Cloud Monitoring Systems &amp; The fourth \{IEEE\} International Conference on e-Science 2011 — e-Science Applications and Tools &amp; Cluster, Grid, and Cloud Computing ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2012.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X12002269",
author = "Gregory Katsaros and Josep Subirats and J. Oriol Fitó and Jordi Guitart and Pierre Gilet and Daniel Espling",
keywords = "Monitoring",
keywords = "Cloud",
keywords = "Energy efficiency",
keywords = "Energy consumption ",
abstract = "The monitoring of QoS parameters in Services Computing as well as in Clouds has been a functionality provided by all contemporary systems. As the optimization of energy consumption becomes a major concern for system designers and administrators, it can be considered as another QoS metric to be monitored. In this paper, we present a service framework that allows us to monitor the energy consumption of a Cloud infrastructure, calculate its energy efficiency, and evaluate the gathered data in order to put in place an effective virtual machine (VM) management. In that context, a simulation scenario of an eco-driven \{VM\} placement policy resulted in a 14% improvement of the infrastructure’s energy efficiency. In total, the proposed approaches and implementations have been validated against a testbed, producing very promising results regarding the prospect of energy efficiency as an important quality factor in Clouds. "
}
@article{Indelman201563,
title = "Incremental light bundle adjustment for structure from motion and robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "70",
number = "",
pages = "63 - 82",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015000810",
author = "Vadim Indelman and Richard Roberts and Frank Dellaert",
keywords = "Bundle adjustment",
keywords = "SLAM",
keywords = "Vision-aided navigation ",
abstract = "Abstract Bundle adjustment (BA) is essential in many robotics and structure-from-motion applications. In robotics, often a bundle adjustment solution is desired to be available incrementally as new poses and 3D points are observed. Similarly in batch structure from motion, cameras are typically added incrementally to allow good initializations. Current incremental \{BA\} methods quickly become computationally expensive as more camera poses and 3D points are added into the optimization. In this paper we introduce incremental light bundle adjustment (iLBA), an efficient optimization framework that substantially reduces computational complexity compared to incremental bundle adjustment. First, the number of variables in the optimization is reduced by algebraic elimination of observed 3D points, leading to a structureless BA. The resulting cost function is formulated in terms of three-view constraints instead of re-projection errors and only the camera poses are optimized. Second, the optimization problem is represented using graphical models and incremental inference is applied, updating the solution using adaptive partial calculations each time a new camera is incorporated into the optimization. Typically, only a small fraction of the camera poses are recalculated in each optimization step. The 3D points, although not explicitly optimized, can be reconstructed based on the optimized camera poses at any time. We study probabilistic and computational aspects of iLBA and compare its accuracy against incremental \{BA\} and another recent structureless method using real–imagery and synthetic datasets. Results indicate iLBA is 2–10 times faster than incremental BA, depending on number of image observations per frame. "
}
@article{Anil2013507,
title = "Deviation analysis method for the assessment of the quality of the as-is Building Information Models generated from point cloud data ",
journal = "Automation in Construction ",
volume = "35",
number = "",
pages = "507 - 516",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001003",
author = "Engin Burak Anil and Pingbo Tang and Burcu Akinci and Daniel Huber",
keywords = "As-is Building Information Modeling",
keywords = "BIM",
keywords = "Laser scanning",
keywords = "Point clouds",
keywords = "Quality assessment",
keywords = "Quality inspection ",
abstract = "Abstract Generating three-dimensional (3D) as-is Building Information Models (BIMs), representative of the existing conditions of buildings, from point cloud data collected by laser scanners is becoming common practice. However, generation of such models currently is mostly performed manually, and errors can be introduced during data collection, pre-processing, and modeling. This paper presents a method for assessing the quality of as-is \{BIMs\} generated from point cloud data by analyzing the patterns of geometric deviations between the model and the point cloud data. The fundamental assumption is that the point cloud and the as-is \{BIM\} generated from the point cloud should corroborate in the depiction of the components and their spatial attributes. Major geometric deviations between as-is models and point clouds can indicate potential errors introduced during data collection, processing and/or model generation. The research described in this paper provides a taxonomy for patterns of deviations and sources of errors and demonstrates that it is possible to identify the source, magnitude, and nature of errors by analyzing the deviation patterns. The method is validated through a comparison with the currently adopted physical measurement method in a case study. The results show that the deviation analysis method is capable of identifying almost six times more errors with more than 40% time savings compared to the physical measurement method. "
}
@article{Stock2014320,
title = "Cloud-based Platform to Facilitate Access to Manufacturing \{IT\} ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "320 - 328",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.045",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010762",
author = "Daniel Stock and Matthias Stöhr and Ursula Rauschecker and Thomas Bauernhansl",
keywords = "Manufacturing",
keywords = "cloud",
keywords = "software engineering",
keywords = "service orientation",
keywords = "manufacturing \{IT\} ",
abstract = "Abstract Today information technology is one of the main enablers of efficient production due to its ability to support manufacturing planning, execution, and optimization. However, most of the tools that provide these features are extremely complex and require on-site installation, individual configuration, administration, maintenance, etc. In many cases, the costs and efforts involved are too high for small and medium sized enterprises (SMEs) to bear. As a result, such companies are often unable to exploit the full potentials of manufacturing-related software systems. To overcome this problem, an \{IT\} infrastructure has been developed at Fraunhofer \{IPA\} which makes it easier to access manufacturing IT. The associated \{IT\} services, which are also accessible to SMEs, offer features for product tracking, process monitoring and control, etc., and are embedded in a cloud-based infrastructure, configurable to specific factory demands and accessible via apps (e.g. mobile devices). This paper addresses the relevant infrastructure requirements, such as security, equipment integration, \{IT\} service management, workflow management and execution as well as user-specific app configuration. The basic architecture of the developed infrastructure is then discussed on the basis of these. The concept of engineering apps is taken as an example to underline the main benefits of such an infrastructure. "
}
@article{GuerreroRascado2013210,
title = "Retrieval and variability analysis of optically thin cloud optical depths from a Cimel sun-photometer ",
journal = "Atmospheric Research ",
volume = "127",
number = "",
pages = "210 - 220",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512003511",
author = "J.L. Guerrero-Rascado and M.J. Costa and A.M. Silva and F.J. Olmo",
keywords = "Cloud optical depth",
keywords = "Sun-photometer",
keywords = "Optically thin clouds ",
abstract = "In this work we propose a technique to retrieve optical depths for optically thin clouds. This method complements the current performance of \{AERONET\} for optically thick cloud measurements using data eliminated by the cloud-screening algorithm that are not useful to derive aerosol properties, therefore inexpensively increasing the capabilities of the sun-photometers. The proposed method is based on the computation of the apparent cloud optical depths and on a forward scattering correction method that exploits state-of-the-art ice cloud scattering models. This complementary procedure is applied to Cimel sun-photometer measurements performed at the Évora Geophysics Centre (Portugal, 38.6°N, 7.9°W, 293 m asl) included in the \{AERONET\} network in order to obtain a climatology of optical depths for optically thin clouds over middle-latitude continental regions of the southwestern Iberian Peninsula. Main features regarding annual and seasonal variability and the relative changes in the infrared radiative forcing from 2007 to 2010 are also reported and analyzed. "
}
@article{BeserraGomes2013496,
title = "Efficient 3D object recognition using foveated point clouds ",
journal = "Computers & Graphics ",
volume = "37",
number = "5",
pages = "496 - 508",
year = "2013",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2013.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0097849313000459",
author = "Rafael Beserra Gomes and Bruno Marques Ferreira da Silva and Lourena Karin de Medeiros Rocha and Rafael Vidal Aroca and Luiz Carlos Pacheco Rodrigues Velho and Luiz Marcos Garcia Gonçalves",
keywords = "Point cloud",
keywords = "3D object recognition",
keywords = "Moving fovea ",
abstract = "Abstract Recent hardware technologies have enabled acquisition of 3D point clouds from real world scenes in real time. A variety of interactive applications with the 3D world can be developed on top of this new technological scenario. However, a main problem that still remains is that most processing techniques for such 3D point clouds are computationally intensive, requiring optimized approaches to handle such images, especially when real time performance is required. As a possible solution, we propose the use of a 3D moving fovea based on a multiresolution technique that processes parts of the acquired scene using multiple levels of resolution. Such approach can be used to identify objects in point clouds with efficient timing. Experiments show that the use of the moving fovea shows a seven fold performance gain in processing time while keeping 91.6% of true recognition rate in comparison with state-of-the-art 3D object recognition methods. "
}
@article{Santos2013178,
title = "Modeling Saharan desert dust radiative effects on clouds ",
journal = "Atmospheric Research ",
volume = "127",
number = "",
pages = "178 - 194",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512003262",
author = "D. Santos and M.J. Costa and A.M. Silva and R. Salgado",
keywords = "Atmospheric modeling",
keywords = "Cloud and aerosol radiative effects",
keywords = "Global warming",
keywords = "Radiative transfer ",
abstract = "This work aims at studying the Saharan desert dust storm effects on clouds. This is done through the investigation of the possible modifications that mineral desert dust aerosols may exert on clouds, modifying their properties and also through the estimation of the cloud radiative forcing in the presence of this type of aerosols, during strong desert dust events that occurred in the end of May 2006 and in the beginning of September 2007. The assessment of the cloud radiative forcing is made at a regional scale both at the top of the atmosphere (TOA) and at the surface levels. The results are obtained from numerical simulations with a mesoscale atmospheric model (MesoNH) over Portugal area and nearby Atlantic Ocean. From the results obtained it is possible to observe that, for all days under study, a cooling effect is always found both at the \{TOA\} and surface levels. Also, for these two levels and for clouds developing in a dusty atmosphere, a more pronounced cooling effect (more negative cloud radiative forcing values) is found compared with the corresponding cloud radiative forcing values for clouds developing in a dust free atmosphere. "
}
@article{Bore2017139,
title = "Efficient retrieval of arbitrary objects from long-term robot observations ",
journal = "Robotics and Autonomous Systems ",
volume = "91",
number = "",
pages = "139 - 150",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016308466",
author = "Nils Bore and Rares Ambrus and Patric Jensfelt and John Folkesson",
keywords = "Mapping",
keywords = "Mobile robotics",
keywords = "Point cloud",
keywords = "Segmentation",
keywords = "Retrieval ",
abstract = "Abstract We present a novel method for efficient querying and retrieval of arbitrarily shaped objects from large amounts of unstructured 3D point cloud data. Our approach first performs a convex segmentation of the data after which local features are extracted and stored in a feature dictionary. We show that the representation allows efficient and reliable querying of the data. To handle arbitrarily shaped objects, we propose a scheme which allows incremental matching of segments based on similarity to the query object. Further, we adjust the feature metric based on the quality of the query results to improve results in a second round of querying. We perform extensive qualitative and quantitative experiments on two datasets for both segmentation and retrieval, validating the results using ground truth data. Comparison with other state of the art methods further enforces the validity of the proposed method. Finally, we also investigate how the density and distribution of the local features within the point clouds influence the quality of the results. "
}
@article{Ferreira2013366,
title = "Cloudlet Architecture for Dashboard in Cloud and Ubiquitous Manufacturing ",
journal = "Procedia \{CIRP\} ",
volume = "12",
number = "",
pages = "366 - 371",
year = "2013",
note = "Eighth \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.09.063",
url = "http://www.sciencedirect.com/science/article/pii/S221282711300704X",
author = "Luís Ferreira and Goran Putnik and Manuela Cunha and Zlata Putnik and Hélio Castro and Catia Alves and Vaibhav Shah and Maria Leonilde R. Varela",
keywords = "Cloud Manufacturing",
keywords = "Ubiquitous Manufacturing",
keywords = "Pragmatics",
keywords = "User Pragmatics",
keywords = "Interoperability",
keywords = "User Experiencee",
keywords = "Cloudlet ",
abstract = "Abstract The aim of this paper is to present a cloudlet architecture for dashboard in Cloud and Ubiquitous Manufacturing. In practice means that, with Cloud Computing adoption, Manufacturing requires management applications where ubiquity and effectiveness are enabled. If ubiquity and resources scalability, availability and capacity can be well supported by cloud, pragmatics instruments are required to support effectiveness. The architecture here presented shows the integration of enriched existing (cloud) services, as instances of resources, with layers of new services towards direct and synchronous communication between users. These Rich Internet Application (RIA) components, here named cloudlets, integration, follow dashboards organization patterns and will be supported by emergent web3.0 interaction technologies. In fact, the paper proposes a new Presentation Layer to be used in \{UMS\} and (that may be used) in any multi-layer cloud-based web application. "
}
@article{Schwiegelshohn20101104,
title = "Perspectives on grid computing ",
journal = "Future Generation Computer Systems ",
volume = "26",
number = "8",
pages = "1104 - 1115",
year = "2010",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2010.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X10000907",
author = "Uwe Schwiegelshohn and Rosa M. Badia and Marian Bubak and Marco Danelutto and Schahram Dustdar and Fabrizio Gagliardi and Alfred Geiger and Ladislav Hluchy and Dieter Kranzlmüller and Erwin Laure and Thierry Priol and Alexander Reinefeld and Michael Resch and Andreas Reuter and Otto Rienhoff and Thomas Rüter and Peter Sloot and Domenico Talia and Klaus Ullmann and Ramin Yahyapour and Gabriele von Voigt",
keywords = "Grid computing",
keywords = "Virtual research environment",
keywords = "Grid applications",
keywords = "Grid middleware",
keywords = "Cloud computing ",
abstract = "Grid computing has been the subject of many large national and international \{IT\} projects. However, not all goals of these projects have been achieved. In particular, the number of users lags behind the initial forecasts laid out by proponents of grid technologies. This underachievement may have led to claims that the grid concept as a whole is on its way to being replaced by Cloud computing and various X-as-a-Service approaches. In this paper, we try to analyze the current situation and to identify promising directions for future grid development. Although there are shortcomings in current grid systems, we are convinced that the concept as a whole remains valid and can benefit from new developments, including Cloud computing. Furthermore, we strongly believe that some future applications will require the grid approach and that, as a result, further research is required in order to turn this concept into reliable, efficient and user-friendly computing platforms. "
}
@article{Fink2009226,
title = "CYCLOPS: A mobile robotic platform for testing and validating image processing and autonomous navigation algorithms in support of artificial vision prostheses ",
journal = "Computer Methods and Programs in Biomedicine ",
volume = "96",
number = "3",
pages = "226 - 233",
year = "2009",
note = "",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2009.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S0169260709002053",
author = "Wolfgang Fink and Mark A. Tarbell",
keywords = "Artificial vision prostheses",
keywords = "Retinal implants",
keywords = "Image processing",
keywords = "Autonomous navigation",
keywords = "Robotics",
keywords = "Tele-commanding",
keywords = "Self-commanding",
keywords = "Cloud computing",
keywords = "Worldwide accessibility ",
abstract = "While artificial vision prostheses are quickly becoming a reality, actual testing time with visual prosthesis carriers is at a premium. Moreover, it is helpful to have a more realistic functional approximation of a blind subject. Instead of a normal subject with a healthy retina looking at a low-resolution (pixelated) image on a computer monitor or head-mounted display, a more realistic approximation is achieved by employing a subject-independent mobile robotic platform that uses a pixelated view as its sole visual input for navigation purposes. We introduce CYCLOPS: an AWD, remote controllable, mobile robotic platform that serves as a testbed for real-time image processing and autonomous navigation systems for the purpose of enhancing the visual experience afforded by visual prosthesis carriers. Complete with wireless Internet connectivity and a fully articulated digital camera with wireless video link, \{CYCLOPS\} supports both interactive tele-commanding via joystick, and autonomous self-commanding. Due to its onboard computing capabilities and extended battery life, \{CYCLOPS\} can perform complex and numerically intensive calculations, such as image processing and autonomous navigation algorithms, in addition to interfacing to additional sensors. Its Internet connectivity renders \{CYCLOPS\} a worldwide accessible testbed for researchers in the field of artificial vision systems. \{CYCLOPS\} enables subject-independent evaluation and validation of image processing and autonomous navigation systems with respect to the utility and efficiency of supporting and enhancing visual prostheses, while potentially reducing to a necessary minimum the need for valuable testing time with actual visual prosthesis carriers. "
}
@article{Jiang201351,
title = "A numerical study of the effect of different aerosol types on East Asian summer clouds and precipitation ",
journal = "Atmospheric Environment ",
volume = "70",
number = "",
pages = "51 - 63",
year = "2013",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2012.12.039",
url = "http://www.sciencedirect.com/science/article/pii/S135223101300006X",
author = "Yiquan Jiang and Xiaohong Liu and Xiu-Qun Yang and Minghuai Wang",
keywords = "Aerosol",
keywords = "Cloud",
keywords = "Precipitation",
keywords = "Climate",
keywords = "Community Atmospheric Model version 5 ",
abstract = "In this study, the anthropogenic aerosol impact on the summer monsoon clouds and precipitation in East Asia is investigated using the \{NCAR\} Community Atmospheric Model version 5 (CAM5), a state-of-the-art climate model considering aerosol direct, semi-direct and indirect effects. The effects of all anthropogenic aerosols, and anthropogenic black carbon (BC), sulfate, and primary organic matter (POM) are decomposed from different sensitivity simulations. Anthropogenic sulfate and \{POM\} reduce the solar flux reaching the surface directly by scattering the solar radiation, and indirectly by increasing the cloud droplet number concentration and cloud liquid water path over East China. The surface air temperature over land is reduced, and the precipitation in North China is suppressed. Unlike anthropogenic sulfate and POM, anthropogenic \{BC\} does not have a significant effect on the air temperature at the surface, because of the reduction of the cloud liquid water path and the weakening of shortwave cloud forcing by its semi-direct effect. The anthropogenic \{BC\} strengthens the southwesterly wind over South China and leads to stronger deep convection at the 25°N–30°N latitudinal band. The effect of all anthropogenic aerosols on air temperature, clouds, and precipitation is not a linear summation of effects from individual anthropogenic sulfate, \{BC\} and POM. Overall all anthropogenic aerosols suppress the precipitation in North China and enhance the precipitation in South China and adjacent ocean regions. "
}
@article{Meng20132361,
title = "Parameterization of point-cloud freeform surfaces using adaptive sequential learning \{RBFnetworks\} ",
journal = "Pattern Recognition ",
volume = "46",
number = "8",
pages = "2361 - 2375",
year = "2013",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2013.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S003132031300054X",
author = "Qinggang Meng and Baihua Li and Horst Holstein and Yonghuai Liu",
keywords = "Surface parameterization",
keywords = "Point clouds",
keywords = "Adaptive sequential learning ",
abstract = "We propose a self-organizing Radial Basis Function (RBF) neural network method for parameterization of freeform surfaces from larger, noisy and unoriented point clouds. In particular, an adaptive sequential learning algorithm is presented for network construction from a single instance of point set. The adaptive learning allows neurons to be dynamically inserted and fully adjusted (e.g. their locations, widths and weights), according to mapping residuals and data point novelty associated to underlying geometry. Pseudo-neurons, exhibiting very limited contributions, can be removed through a pruning procedure. Additionally, a neighborhood extended Kalman filter (NEKF) was developed to significantly accelerate parameterization. Experimental results show that this adaptive learning enables effective capture of global low-frequency variations while preserving sharp local details, ultimately leading to accurate and compact parameterization, as characterized by a small number of neurons. Parameterization using the proposed \{RBF\} network provides simple, low cost and low storage solutions to many problems such as surface construction, re-sampling, hole filling, multiple level-of-detail meshing and data compression from unstructured and incomplete range data. Performance results are also presented for comparison. "
}
@article{Munaro201342,
title = "3D flow estimation for human action recognition from colored point clouds ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "5",
number = "",
pages = "42 - 51",
year = "2013",
note = "Extended versions of selected papers from the Third Annual Meeting of the \{BICA\} Society (BICA 2012) ",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2013.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X13000431",
author = "Matteo Munaro and Gioia Ballin and Stefano Michieletto and Emanuele Menegatti",
keywords = "Action recognition",
keywords = "3D motion flow",
keywords = "IAS-Lab Action Dataset",
keywords = "Colored point clouds",
keywords = "RGB-D data",
keywords = "Kinect ",
abstract = "Abstract Motion perception and classification are key elements exploited by humans for recognizing actions. The same principles can serve as a basis for building cognitive architectures which can recognize human actions, thus enhancing challenging applications such as human robot interaction, visual surveillance, content-based video analysis and motion capture. In this paper, we propose an autonomous system for real-time human action recognition based on 3D motion flow estimation. We exploit colored point cloud data acquired with a Microsoft Kinect and we summarize the motion information by means of a 3D grid-based descriptor. Finally, temporal sequences of descriptors are classified with the Nearest Neighbor technique. We also present a newly created public dataset for RGB-D human action recognition which contains 15 actions performed by 12 different people. Our overall system is tested on this dataset and on the dataset used in Ballin, Munaro, and Menegatti (2012), showing the effectiveness of the proposed approach in recognizing about 90% of the actions. "
}
@article{Hong20161,
title = "Obstacle-avoiding shortest path derivation in a multicore computing environment ",
journal = "Computers, Environment and Urban Systems ",
volume = "55",
number = "",
pages = "1 - 10",
year = "2016",
note = "",
issn = "0198-9715",
doi = "https://doi.org/10.1016/j.compenvurbsys.2015.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0198971515300235",
author = "Insu Hong and Alan T. Murray and Sergio Rey",
keywords = "Euclidean shortest path",
keywords = "Convex hull",
keywords = "Vector overlay",
keywords = "High performance computing",
keywords = "Parallelization",
keywords = "GIS ",
abstract = "Abstract The best obstacle avoiding path in continuous space, referred to as the Euclidean shortest path, is important for spatial analysis, location modeling and wayfinding tasks. This problem has received much attention in the literature given its practical application, and several solution techniques have been proposed. However, existing approaches are limited in their ability to support real time analysis in big data environments. In this research a multicore computing approach is developed that exploits spatial knowledge through the use of geographic information system functionality to efficiently construct an optimal shortest path. The approach utilizes the notion of a convex hull for iteratively evaluating obstacles and constructing pathways. Further, the approach is capable of incrementally improving bounds, made possible through parallel processing. Wayfinding routes that avoid buildings and other obstacles to travel are derived and discussed. "
}
@article{Kostavelis201586,
title = "Semantic mapping for mobile robotics tasks: A survey ",
journal = "Robotics and Autonomous Systems ",
volume = "66",
number = "",
pages = "86 - 103",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003030",
author = "Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Mobile robots",
keywords = "Semantic map",
keywords = "Topological map",
keywords = "Temporal coherence",
keywords = "Object recognition",
keywords = "Place recognition",
keywords = "Human–robot interaction",
keywords = "Knowledge representation",
keywords = "Planning ",
abstract = "Abstract The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human–robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also made. "
}
@article{Ahmad201616,
title = "Software architectures for robotic systems: A systematic mapping study ",
journal = "Journal of Systems and Software ",
volume = "122",
number = "",
pages = "16 - 39",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.08.039",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216301479",
author = "Aakash Ahmad and Muhammad Ali Babar",
keywords = "Software architecture",
keywords = "Robotic systems",
keywords = "Evidence-based software engineering",
keywords = "Software architecture for robotics",
keywords = "Systematic mapping study ",
abstract = "AbstractContext Several research efforts have been targeted to support architecture centric development and evolution of software for robotic systems for the last two decades. Objective We aimed to systematically identify and classify the existing solutions, research progress and directions that influence architecture-driven modeling, development and evolution of robotic software. Research Method We have used Systematic Mapping Study (SMS) method for identifying and analyzing 56 peer-reviewed papers. Our review has (i) taxonomically classified the existing research and (ii) systematically mapped the solutions, frameworks, notations and evaluation methods to highlight the role of software architecture in robotic systems. Results and Conclusions We have identified eight themes that support architectural solutions to enable (i) operations, (ii) evolution and (iii) development specific activities of robotic software. The research in this area has progressed from object-oriented to component-based and now to service-driven robotics representing different architectural models that emerged overtime. An emerging solution is cloud robotics that exploits the foundations of service-driven architectures to support an interconnected web of robots. The results of this \{SMS\} facilitate knowledge transfer – benefiting researchers and practitioners – focused on exploiting software architecture to model, develop and evolve robotic systems. "
}
@article{Salim201531,
title = "Urban computing in the wild: A survey on large scale participation and citizen engagement with ubiquitous computing, cyber physical systems, and Internet of Things ",
journal = "International Journal of Human-Computer Studies ",
volume = "81",
number = "",
pages = "31 - 48",
year = "2015",
note = "Transdisciplinary Approaches to Urban Computing ",
issn = "1071-5819",
doi = "https://doi.org/10.1016/j.ijhcs.2015.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1071581915000488",
author = "Flora Salim and Usman Haque",
keywords = "Urban computing",
keywords = "Large-scale participation",
keywords = "Cyber-physical systems",
keywords = "Internet of Things",
keywords = "Smartphones",
keywords = "Human in the loop",
keywords = "Public displays",
keywords = "Urban probes",
keywords = "Public spectacle",
keywords = "Urban interventions",
keywords = "Crowdsourcing",
keywords = "Crowdsensing",
keywords = "Ubiquitous computing ",
abstract = "Abstract With today׳s ubiquitous computing technologies, our daily activities are continuously traced by smartphones in our pockets and more of our everyday things are now connected to the Internet. This phenomena is changing the way we live, work, and interact. This creates, not only technological opportunities for smarter cities, but also interactional opportunities for the citizens. However, designing, developing, and deploying urban computing projects in the wild, outside the controlled research environment, is challenging, due to the complexity of the urban context as well as the people who live in it. What are the ways to trigger and increase the public towards active participation or technological uptake in urban computing? How to design and structure participation for urban computing research and technologies in the wild for it to lead to mass participation with its citizens? These are the questions that are investigated in this paper. We present a survey on existing approaches in engaging participations and devising interactions with a range of existing urban computing technologies: smartphones, public displays, cyber physical systems (including those with embedded systems, sensors, and actuators), and Internet of Things. Based on the reviews, we propose a taxonomy for categorising and characterising urban computing technologies and approaches with regards to the level of participation they stimulate, the participation scale they support, the manipulation and effects mode they enable, and the interaction mode and scale they enable. Finally, strategies for structuring and engendering participations and interactions based on our own experience from deploying small to large scale urban computing projects in the wild are presented in this paper. "
}
@article{Riggs2013521,
title = "Disassembly Liaison Graphs Inspired by Word Clouds ",
journal = "Procedia \{CIRP\} ",
volume = "7",
number = "",
pages = "521 - 526",
year = "2013",
note = "Forty Sixth \{CIRP\} Conference on Manufacturing Systems 2013 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.06.026",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113002953",
author = "Robert J. Riggs and S. Jack Hu",
keywords = "Disassembly",
keywords = "liaison graphs",
keywords = "word clouds ",
abstract = "Abstract Liaison or connection graphs depict physical mates between components in a graphical representation but do not incorporate any precedence relations or order of assembly or disassembly of components. For the context of disassembly, we developed a method to graphically show not only the physical mates between components but also the disassembly precedence relations amongst all the components. The transformation of a liaison graph into a weighted liaison graph (WLG) is inspired by the generation of word clouds from the visual design domain where component nodes are weighted and colored to depict disassembly precedence relations. A \{WLG\} allows users to quickly comprehend the order of disassembly and component embeddedness. "
}
@article{Mineo2017,
title = "Introducing a novel mesh following technique for approximation-free robotic tool path trajectories ",
journal = "Journal of Computational Design and Engineering ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "2288-4300",
doi = "https://doi.org/10.1016/j.jcde.2017.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S228843001630135X",
author = "Carmelo Mineo and Stephen Gareth Pierce and Pascual Ian Nicholson and Ian Cooper",
keywords = "Tool path generation",
keywords = "Mesh following technique",
keywords = "Triangular meshes",
keywords = "Robotics",
keywords = "NDT ",
abstract = "Abstract Modern tools for designing and manufacturing of large components with complex geometries allow more flexible production with reduced cycle times. This is achieved through a combination of traditional subtractive approaches and new additive manufacturing processes. The problem of generating optimum tool-paths to perform specific actions (e.g. part manufacturing or inspection) on curved surface samples, through numerical control machinery or robotic manipulators, will be increasingly encountered. Part variability often precludes using original design \{CAD\} data directly for toolpath generation (especially for composite materials), instead surface mapping software is often used to generate tessellated models. However, such models differ from precise analytical models and are often not suitable to be used in current commercially available path-planning software, since they require formats where the geometrical entities are mathematically represented thus introducing approximation errors which propagate into the generated toolpath. This work adopts a fundamentally different approach to such surface mapping and presents a novel Mesh Following Technique (MFT) for the generation of tool-paths directly from tessellated models. The technique does not introduce any approximation and allows smoother and more accurate surface following tool-paths to be generated. The background mathematics to the new \{MFT\} algorithm are introduced and the algorithm is validated by testing through an application example. Comparative metrology experiments were undertaken to assess the tracking performance of the \{MFT\} algorithms, compared to tool-paths generated through commercial software. It is shown that the \{MFT\} tool-paths produced 40% smaller errors and up to 66% lower dispersion around the mean values. "
}
@article{Wang20124034,
title = "Multidimensional particle swarm optimization-based unsupervised planar segmentation algorithm of unorganized point clouds ",
journal = "Pattern Recognition ",
volume = "45",
number = "11",
pages = "4034 - 4043",
year = "2012",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2012.04.023",
url = "http://www.sciencedirect.com/science/article/pii/S0031320312002038",
author = "Lin Wang and Jianfu Cao and Chongzhao Han",
keywords = "Unorganized point clouds",
keywords = "Unsupervised planar segmentation",
keywords = "Multidimensional particle swarm optimization",
keywords = "Objective function ",
abstract = "This paper presents an unsupervised planar segmentation algorithm of unorganized point clouds based on multidimensional (MD) particle swarm optimization (PSO). A robust objective function of the unsupervised planar segmentation is established according to clustering distances of \{PSO\} clustering algorithm and inliers of random sample consensus (RANSAC) method. After that, \{MD\} \{PSO\} algorithm is adopted to optimize the objective function, where the optimal number and positions of the segmented planar patches are sought simultaneously. In order not to get trapped in local optima, a modification strategy of the global best (GB) position of swarm in each dimension is added to the \{MD\} \{PSO\} algorithm. Thus the unsupervised planar segmentation of point clouds is realized. Experimental results demonstrate the high planar segmentation accuracy of the proposed algorithm. "
}
@article{Alves2012417,
title = "Mobile Robot Control Using a Cloud of Particles ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "417 - 422",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00096",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336461",
author = "Jorge Augusto Vasconcelos Alves and Walter Fetter Lages",
keywords = "Mobile robotics",
keywords = "particle filter",
keywords = "nonlinear control",
keywords = "stochastic control",
keywords = "stochastic estimation ",
abstract = "Abstract Common control systems for mobile robots include the use of deterministic control laws together with state estimation approaches and the consideration of the certainty equivalence principle. Recent approaches consider the use of partially observable Markov decision process strategies together with Bayesian estimators. In order to reduce the required processing power and yet allow for multimodal or non-Gaussian distributions, a scheme based on a particle filter and a corresponding cloud of input signals is proposed in this paper. Results are presented and compared to a scheme with extended Kalman filter and the assumption that the certainty equivalence holds. "
}
@article{Cao2017,
title = "A novel relocation method for simultaneous localization and mapping based on deep learning algorithm ",
journal = "Computers & Electrical Engineering ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2017.03.015",
url = "http://www.sciencedirect.com/science/article/pii/S0045790617305943",
author = "Jun Cao and Bi Zeng and Jianqi Liu and Zhenting Zhao and Yongfeng Su",
keywords = "SLAM",
keywords = "Relocation",
keywords = "Deep learning",
keywords = "Cloud robotics",
keywords = "Classification ",
abstract = "Abstract Relocation is one of the most common problems in Simultaneous Localization and Mapping (SLAM). This paper presents a novel relocation method, using unsupervised deep learning algorithm to extract the feature of Light Detection and Ranging (LiDAR) data, and narrows the scope of relocation by classifying these features to reduce the randomness of the relocation. Compared with the other methods which is based on matching the manual feature points, this method avoids some limitations of manual features. We modify the Particle Filter \{SLAM\} (PF-SLAM), and use our relocation method to replace the original method for experimentation. The experimental results demonstrate that this method can be relocation whit high success rate only use a small amount of computational resource in a short time. Training neural network will consume a lot of computing resources, we also propose a cloud computing framework to the implementation of this method for the mobile robot which computational resources are limited. "
}
@article{Saut20141742,
title = "Grasping objects localized from uncertain point cloud data ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "12",
pages = "1742 - 1754",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001389",
author = "Jean-Philippe Saut and Serena Ivaldi and Anis Sahbani and Philippe Bidaud",
keywords = "Robotic grasping",
keywords = "Multi-fingered hand",
keywords = "Inverse kinematics ",
abstract = "Abstract Robotic grasping is very sensitive to how accurate is the pose estimation of the object to grasp. Even a small error in the estimated pose may cause the planned grasp to fail. Several methods for robust grasp planning exploit the object geometry or tactile sensor feedback. However, object pose range estimation introduces specific uncertainties that can also be exploited to choose more robust grasps. We present a grasp planning method that explicitly considers the uncertainties on the visually-estimated object pose. We assume a known shape (e.g. primitive shape or triangle mesh), observed as a–possibly sparse–point cloud. The measured points are usually not uniformly distributed over the surface as the object is seen from a particular viewpoint; additionally this non-uniformity can be the result of heterogeneous textures over the object surface, when using stereo-vision algorithms based on robust feature-point matching. Consequently the pose estimation may be more accurate in some directions and contain unavoidable ambiguities. The proposed grasp planner is based on a particle filter to estimate the object probability distribution as a discrete set. We show that, for grasping, some ambiguities are less unfavorable so the distribution can be used to select robust grasps. Some experiments are presented with the humanoid robot iCub and its stereo cameras. "
}
@article{Chew20116724,
title = "Tropical cirrus cloud contamination in sun photometer data ",
journal = "Atmospheric Environment ",
volume = "45",
number = "37",
pages = "6724 - 6731",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011008375",
author = "Boon Ning Chew and James R. Campbell and Jeffrey S. Reid and David M. Giles and Ellsworth J. Welton and Santo V. Salinas and Soo Chin Liew",
keywords = "AERONET",
keywords = "Aerosol particles",
keywords = "Cirrus clouds",
keywords = "Lidar",
keywords = "MPLNET",
keywords = "Southeast Asia",
keywords = "Sun photometer ",
abstract = "Cirrus clouds are endemic to Southeast Asia and are a source of potential bias in regional passive aerosol remote sensing datasets. Here, performance of the cloud-screening algorithm for the ground-based Aerosol Robotic Network (AERONET) sun photometer data is evaluated for cirrus cloud contamination at Singapore (1.30° N, 103.77° E). Using twelve months of concurrent \{AERONET\} Level 1.5 and 2.0 cloud-screened aerosol optical depth (AOD) data, and collocated Level 1.0 Micro-Pulse Lidar Network (MPLNET) measurements, we investigate the baseline \{AOD\} bias due to cirrus cloud presence. Observations are considered for a primary sample of all data and a secondary sample where \{AERONET\} data are restricted to a zenith viewing angle ≤ 45°. Cirrus clouds are present in zenith-viewing \{MPL\} profiles for 34% and 23% of these samples respectively. Based on approximations of cirrus cloud optical properties necessary to estimate cloud optical depth from the single-channel lidar signal, and assuming partial forward scattering of diffuse light by cirrus clouds into the sun photometer’s field of view, we estimate a range in \{AOD\} bias due to unscreened cloud presence of 0.034 to 0.060 and 0.031 to 0.055 ± 0.01 for the primary and secondary sample respectively. From the analysis of \{AERONET\} \{AOD\} for the angle-limited subset alone, we also derive a positive \{AOD\} bias of 0.034, which is comparable to the lower bounds for the estimated cloud bias reported for our datasets. These findings, which we attribute to the prevalence of cirrus clouds present from regional convection, are higher than previous reports of global \{AOD\} bias in the Moderate Resolution Infrared Spectroradiometer (MODIS) satellite-borne measurements due to residual cirrus cloud presence. "
}
@article{Malekian20171,
title = "Cyber–physical systems and context-aware sensing and computing ",
journal = "Computer Networks ",
volume = "117",
number = "",
pages = "1 - 4",
year = "2017",
note = "Cyber-physical systems and context-aware sensing and computing ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2017.02.012",
url = "http://www.sciencedirect.com/science/article/pii/S1389128617300567",
author = "Reza Malekian and Kui Wu and Gianluca Reali and Ning Ye and Kevin Curran"
}
@article{Alenyà201410,
title = "ToF cameras for active vision in robotics ",
journal = "Sensors and Actuators A: Physical ",
volume = "218",
number = "",
pages = "10 - 22",
year = "2014",
note = "",
issn = "0924-4247",
doi = "https://doi.org/10.1016/j.sna.2014.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0924424714003458",
author = "G. Alenyà and S. Foix and C. Torras",
keywords = "Time-of-Flight cameras",
keywords = "3D perception for manipulation",
keywords = "Depth calibration",
keywords = "Outdoor imaging",
keywords = "Complex-shape objects ",
abstract = "Abstract ToF cameras are now a mature technology that is widely being adopted to provide sensory input to robotic applications. Depending on the nature of the objects to be perceived and the viewing distance, we distinguish two groups of applications: those requiring to capture the whole scene and those centered on an object. It will be demonstrated that it is in this last group of applications, in which the robot has to locate and possibly manipulate an object, where the distinctive characteristics of ToF cameras can be better exploited. After presenting the physical sensor features and the calibration requirements of such cameras, we review some representative works highlighting for each one which of the distinctive ToF characteristics have been more essential. Even if at low resolution, the acquisition of 3D images at frame-rate is one of the most important features, as it enables quick background/foreground segmentation. A common use is in combination with classical color cameras. We present three developed applications, using a mobile robot and a robotic arm, to exemplify with real images some of the stated advantages. "
}
@article{Williams2017313,
title = "Learned Action SLAM: Sharing \{SLAM\} through learned path planning information between heterogeneous robotic platforms ",
journal = "Applied Soft Computing ",
volume = "50",
number = "",
pages = "313 - 326",
year = "2017",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2016.11.036",
url = "http://www.sciencedirect.com/science/article/pii/S1568494616306056",
author = "Henry Williams and Will N. Browne and Dale A. Carnegie",
keywords = "Cognitive robotics",
keywords = "Learning Classifier Systems",
keywords = "Simultaneous localisation and mapping",
keywords = "Navigation ",
abstract = "Abstract Currently when path planning is used in \{SLAM\} it is to benefit \{SLAM\} only, with no mutual benefit for path planning. Furthermore, \{SLAM\} algorithms are generally implemented and modified for individual heterogeneous robotic platforms without autonomous means of sharing navigation information. This limits the ability for robot platforms to share navigation information and can require heterogeneous robot platforms to generate individual maps within the same environment. This paper introduces Learned Action SLAM, which for the first time autonomously combines path-planning with \{SLAM\} such that heterogeneous robots can share learnt knowledge through Learning Classifier Systems (LCS). This is in contrast to Active SLAM, where path-planning is used to benefit \{SLAM\} only. Results from testing LA-SLAM on robots in the real world have shown; promise for use on teams of robots with various sensor morphologies, implications for scaling to associated domains, and ability to share maps taken from less capable to more advanced robots. "
}
@article{Barnfather2016561,
title = "Development and testing of an error compensation algorithm for photogrammetry assisted robotic machining ",
journal = "Measurement ",
volume = "94",
number = "",
pages = "561 - 577",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2016.08.032",
url = "http://www.sciencedirect.com/science/article/pii/S0263224116304936",
author = "J.D. Barnfather and M.J. Goodfellow and T. Abram",
keywords = "Machining",
keywords = "Robotics",
keywords = "Photogrammetry",
keywords = "Compensation",
keywords = "Error ",
abstract = "Abstract Robotic machining of relatively small features on large components potentially offers an opportunity to reduce capital expenditure in various industries. A barrier to this is the inability of robotic machine tools to machine to the tolerances of conventional equipment. This paper proposes and tests a photogrammetry-based metrology assistance algorithm to compensate for robotic machining inaccuracy, as measured in the part, and investigates the associated measurement challenges. The algorithm is executed in a two stage process, whereby the closest point to nominal cutting coordinates on an aligned inspection surface is used for compensation, created a penultimate measured cut. Finally, the finishing program coordinates are compensated to correct under-cuts during the measured cut stage. Conceptual tests using simulated measurement data give confidence that the proposed approach works well. In experiments, a key area for further R&amp;D effort is found to be uneven inspect point coverage, which results in alignment issues and a poor surface finish. Ultimately, direction is given to improve measurement system performance to enable the metrology assistance approach proposed to be implemented and therefore the benefits of “process-to-part” robotic machining to be realised. "
}
@article{Vijaykumar2015223,
title = "Unique Sense: Smart Computing Prototype ",
journal = "Procedia Computer Science ",
volume = "50",
number = "",
pages = "223 - 228",
year = "2015",
note = "Big Data, Cloud and Computing Challenges ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.04.056",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915005578",
author = "S. Vijaykumar and S.G. Saravanakumar and M. Balamurugan",
keywords = "Smart Computing",
keywords = "HPC",
keywords = "Prototype",
keywords = "ARM",
keywords = "Hadoop ",
abstract = "Abstract Unique sense: Smart computing prototype is a part of “unique sense” computing architecture, which delivers alternate solution for today's computing architecture. This computing is one step towards future generation needs, which brings extended support to the ubiquitous environment. This smart computing prototype is the light weight compact architecture which is designed to satisfy all the needs of this society. The proposed solution is based on the hybrid combination of cutting edge technologies and techniques from the various layers. In addition it achieves low cost architecture and eco-friendly to meet all the levels of people's needs. "
}
@article{Natali2011151,
title = "Graph-based representations of point clouds ",
journal = "Graphical Models ",
volume = "73",
number = "5",
pages = "151 - 164",
year = "2011",
note = "",
issn = "1524-0703",
doi = "https://doi.org/10.1016/j.gmod.2011.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S1524070311000099",
author = "Mattia Natali and Silvia Biasotti and Giuseppe Patanè and Bianca Falcidieno",
keywords = "Graph-based representations",
keywords = "Point clouds",
keywords = "Shape abstraction",
keywords = "Shape comparison ",
abstract = "This paper introduces a skeletal representation, called Point Cloud Graph, that generalizes the definition of the Reeb graph to arbitrary point clouds sampled from m-dimensional manifolds embedded in the d-dimensional space. The proposed algorithm is easy to implement and the graph representation yields to an effective abstraction of the data. Finally, we present experimental results on point-sampled surfaces and volumetric data that show the robustness of the Point Cloud Graph to non-uniform point distributions and its usefulness for shape comparison. "
}
@article{Hayati2007180,
title = "\{ADVANCED\} \{ROBOTICS\} \{TECHNOLOGY\} \{INFUSION\} \{TO\} \{THE\} \{NASA\} \{MARS\} \{EXPLORATION\} \{ROVER\} (MER) \{PROJECT\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "180 - 185",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00033",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346584",
author = "Samad Hayati and Arturo Rankin and Won Kim and Patrick Leger and Rebecca Castano and Khaled Ali",
keywords = "Rover",
keywords = "Autonomy",
keywords = "Autonomous Science",
keywords = "Mars",
keywords = "Space Robotics",
keywords = "Instrument placement",
keywords = "Planetary Rovers ",
abstract = "Abstract This paper presents four new technology developments and their infusion into the Mars Exploration Rover (MER) mission. These technologies were not ready for infusion prior to the launch of this mission. Three of these new capabilities are designed to increase the level of autonomy for the operations, i.e., fewer ground-in-the-loop steps for executing commands. One of the new capabilities is designed to intelligently filter rover obtained images and return only those that are very likely to contain useful information. These new capabilities will be used for this and future \{NASA\} planetary missions. "
}
@article{Muliukha2017505,
title = "Network-centric Supervisory Control System for Mobile Robotic Groups ",
journal = "Procedia Computer Science ",
volume = "103",
number = "",
pages = "505 - 510",
year = "2017",
note = "\{XII\} International Symposium Intelligent Systems 2016, \{INTELS\} 2016, 5-7 October 2016, Moscow, Russia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.01.036",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917300376",
author = "Vladimir Muliukha and Alexander Ilyashenko and Leonid Laboshin",
keywords = "network-centric control system",
keywords = "cyber-physical approach",
keywords = "mobile robots",
keywords = "high-performance cloud system. ",
abstract = "Abstract The paper analyzes network-centric control methods for mobile robotic groups. We consider the task of controlling a group of mobile robots, performing reconnaissance for space and terrestrial applications. In the paper each robot is a cyber-physical object consisting of mechatronic part and computer module, which analyzes data from sensors and generates commands. The use of network-centric approach allows separating these two parts, transferring resource-intensive computing tasks in a high-performance hybrid cloud environment. A cloud environment as a single point for processing of all sensory data allows us to use the advantages of centralized control method and to manage the resources of mobile robots more effectively. In this case, each robot keeps the autonomy if there is no communication with the control center. So a key element of such control systems is reliable communication links. In our work we use redundancy and duplication of various communication channels to provide a continuous connection between a mobile robot and control center. "
}
@article{Salibekyan2015977,
title = "A New Approach for Distributed Computing in Embedded Systems ",
journal = "Procedia Engineering ",
volume = "100",
number = "",
pages = "977 - 986",
year = "2015",
note = "25th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2014 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.01.457",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815004841",
author = "Sergey Salibekyan and Peter Panfilov",
keywords = "distributed systems",
keywords = "embedded computing",
keywords = "dataflow computational model",
keywords = "object-attribute architecture",
keywords = "computer system simulation ",
abstract = "Abstract Historically, a typical embedded system has been designed as a control-dominated system using only a state-oriented model, such as FSMs. However, the trend in embedded systems design in recent years has been towards highly distributed architectures with support for concurrency, data and control flow, and scalable distributed computations. This implies that a different approach is necessary. We propose to use some dataflow computational model views to specify embedded systems, because it is a notation that covers the most relevant aspects of distributed computing. In this paper, we introduce a new computational model, known as \{OAA\} (Object-Attribute Architecture) and present the general characteristics of an OA-methodology to support the design and simulation of distributed computing systems. The matrix multiplication algorithm in the object-attribute distributed computing environment has been used to validate our methodology. The preliminary evaluation results show the feasibility of the \{OA\} approach. "
}
@article{Fortino201550,
title = "A framework for collaborative computing and multi-sensor data fusion in body sensor networks ",
journal = "Information Fusion ",
volume = "22",
number = "",
pages = "50 - 70",
year = "2015",
note = "",
issn = "1566-2535",
doi = "https://doi.org/10.1016/j.inffus.2014.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S156625351400044X",
author = "Giancarlo Fortino and Stefano Galzarano and Raffaele Gravina and Wenfeng Li",
keywords = "Body sensor networks",
keywords = "SPINE",
keywords = "Collaborative computing",
keywords = "Multi-sensor data fusion",
keywords = "Emotion detection",
keywords = "Handshake detection ",
abstract = "Abstract Body Sensor Networks (BSNs) have emerged as the most effective technology enabling not only new e-Health methods and systems but also novel applications in human-centered areas such as electronic health care, fitness/welness systems, sport performance monitoring, interactive games, factory workers monitoring, and social physical interaction. Despite their enormous potential, they are currently mostly used only to monitor single individuals. Indeed, \{BSNs\} can proactively interact and collaborate to foster novel \{BSN\} applications centered on collaborative groups of individuals. In this paper, C-SPINE, a framework for Collaborative \{BSNs\} (CBSNs), is proposed. \{CBSNs\} are \{BSNs\} able to collaborate with each other to fulfill a common goal. They can support the development of novel smart wearable systems for cyberphysical pervasive computing environments. Collaboration therefore relies on interaction and synchronization among the \{CBSNs\} and on collaborative distributed computing atop the collaborating CBSNs. Specifically, collaboration is triggered upon \{CBSN\} proximity and relies on service-specific protocols allowing for managing services among the collaborating CBSNs. C-SPINE also natively supports multi-sensor data fusion among \{CBSNs\} to enable joint data analysis such as filtering, time-dependent data integration and classification. To demonstrate its effectiveness, C-SPINE is used to implement e-Shake, a collaborative \{CBSN\} system for the detection of emotions. The system is based on a multi-sensor data fusion schema to perform automatic detection of handshakes between two individuals and capture of possible heart-rate-based emotion reactions due to the individuals’ meeting. "
}
@article{Chan2016257,
title = "Automatic Point Cloud Registration Using a Single Octagonal Lamp Pole ",
journal = "Photogrammetric Engineering & Remote Sensing ",
volume = "82",
number = "4",
pages = "257 - 269",
year = "2016",
note = "",
issn = "0099-1112",
doi = "https://doi.org/10.14358/PERS.82.4.257",
url = "http://www.sciencedirect.com/science/article/pii/S0099111216300817",
author = "Ting On Chan and Derek D. Lichti and David Belton and Hoang Long Nguyen",
abstract = "Abstract Registration is an essential procedure for merging point clouds defined in different coordinate systems associated to different scanner positions and orientations. It is usually the first step before the point clouds are further processed to provide spatial information of a scene to support engineering applications. In this paper, a new automatic registration method based on a novel geometric model of a polygonal object is presented. Since the cross section of the shaft of many lamp poles is octagonal, registration based on an octagonal pyramid model is proposed. The presented method only requires a single, common octagonal lamp pole observed in both point clouds, though actual overlap of the point clouds is not strictly required. It can be performed as long as the model parameters can be estimated by fitting the point observations to the model. Moreover, no user interaction is needed to derive approximate values, so the proposed registration can be completely automated. Three independent datasets captured by two scanners were used to verify the method. The registration accuracies in the horizontal and vertical directions were up to 11.7 mm and 4.4 mm at approximately 62 m and 17 m away from the scanner, respectively. With such high accuracies, the estimated registration parameters can serve as a set of initial parameters for fine registration using algorithm such as the iterative closest point (icp). "
}
@article{Jiang201621,
title = "Enhanced control of a wheelchair-mounted robotic manipulator using 3-D vision and multimodal interaction ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "21 - 31",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - "Assistive Solutions for Mobility, Communication and HMI" ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.015",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300066",
author = "Hairong Jiang and Ting Zhang and Juan P. Wachs and Bradley S. Duerstock",
keywords = "3D vision",
keywords = "Multi-modal interface",
keywords = "Wheelchair mounted robotic manipulator",
keywords = "Assistive robotics ",
abstract = "Abstract This paper presents a multiple-sensors, 3D vision-based, autonomous wheelchair-mounted robotic manipulator (WMRM). Two 3D sensors were employed: one for object recognition, and the other for recognizing body parts (face and hands). The goal is to recognize everyday items and automatically interact with them in an assistive fashion. For example, when a cereal box is recognized, it is grasped, poured in a bowl, and brought to the user. Daily objects (i.e. bowl and hat) were automatically detected and classified using a three-steps procedure: (1) remove background based on 3D information and find the point cloud of each object; (2) extract feature vectors for each segmented object from its 3D point cloud and its color image; and (3) classify feature vectors as objects after applying a nonlinear support vector machine (SVM). To retrieve specific objects, three user interface methods were adopted: voice-based, gesture-based, and hybrid commands. The presented system was tested using two common activities of daily living -- feeding and dressing. The results revealed that an accuracy of 98.96% is achieved for a dataset with twelve daily objects. The experimental results indicated that hybrid (gesture and speech) interaction outperforms any single modal interaction. "
}
@article{Stoyanov20131094,
title = "Comparative evaluation of range sensor accuracy for indoor mobile robotics and automated logistics applications ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1094 - 1105",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001431",
author = "Todor Stoyanov and Rasoul Mojtahedzadeh and Henrik Andreasson and Achim J. Lilienthal",
keywords = "Range sensing",
keywords = "Comparative evaluation",
keywords = "Automated logistics ",
abstract = "3D range sensing is an important topic in robotics, as it is a component in vital autonomous subsystems such as for collision avoidance, mapping and perception. The development of affordable, high frame rate and precise 3D range sensors is thus of considerable interest. Recent advances in sensing technology have produced several novel sensors that attempt to meet these requirements. This work is concerned with the development of a holistic method for accuracy evaluation of the measurements produced by such devices. A method for comparison of range sensor output to a set of reference distance measurements, without using a precise ground truth environment model, is proposed. This article presents an extensive evaluation of three novel depth sensors — the Swiss Ranger SR-4000, Fotonic \{B70\} and Microsoft Kinect. Tests are concentrated on the automated logistics scenario of container unloading. Six different setups of box-, cylinder-, and sack-shaped goods inside a mock-up container are used to collect range measurements. Comparisons are performed against hand-crafted ground truth data, as well as against a reference actuated Laser Range Finder (aLRF) system. Additional test cases in an uncontrolled indoor environment are performed in order to evaluate the sensors’ performance in a challenging, realistic application scenario. "
}
@incollection{Pradilla2016125,
title = "Chapter 7 - Micro Virtual Machines (MicroVMs) for Cloud-assisted Cyber-Physical Systems (CPS) ",
editor = "Buyya, Rajkumar  and Dastjerdi, Amir Vahid ",
booktitle = "Internet of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2016",
pages = "125 - 142",
isbn = "978-0-12-805395-9",
doi = "https://doi.org/10.1016/B978-0-12-805395-9.00007-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053959000071",
author = "J.V. Pradilla and C.E. Palau",
keywords = "Cyber-Physical Systems (CPS)",
keywords = "Internet of Things (IoT)",
keywords = "Sensor Observation Service (SOS)",
keywords = "Micro Virtual Machines (MicroVM)",
keywords = "Sensor Web Enablement (SWE)",
keywords = "eHealth",
keywords = "Precision Agriculture (PA)",
keywords = "domotic ",
abstract = "Abstract Cyber-Physical Systems (CPS) need to adapt to the changing physical world and expand their capabilities dynamically. To meet this need, this chapter proposes a three-tier architecture that integrates: cloud computing, fog computing, and networks of sensors/actuators. It also provides an implementation of the proposed architecture, based on the use of Micro Virtual Machines (MicroVM) and the Sensor Observation Service (SOS), combining the isolation of virtual machines with the standardization of storage and information-exchange under the Sensor Web Enablement (SWE) framework. Subsequently, the proposed architecture is coupled to the Internet of Things (IoT), and three use-cases that can be applied are addressed: eHealth, precision agriculture, and domotics; these three use-cases clarify the benefits of the implementation of the architecture and illustrate the interactions between its composing levels. "
}
@article{Mörwald2016141,
title = "Modeling connected regions in arbitrary planar point clouds by robust B-spline approximation ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "141 - 151",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002948",
author = "Thomas Mörwald and Jonathan Balzer and Markus Vincze",
keywords = "B-spline",
keywords = "Reconstruction",
keywords = "Curve fitting",
keywords = "Boundary fitting",
keywords = "Concave hull",
keywords = "Surface trimming ",
abstract = "Abstract This paper presents an algorithm for robustly approximating the boundary of a domain, latent in a planar set of scattered points, by a B-spline curve. The algorithm is characterized by three key features: First, we propose a distance measure, called the Asymmetric Distance (AD), which allows for handling outliers inside the curve and finding the outer boundary or concave hull by specifying very natural parameters like smoothness and accuracy. Second, we provide a solution to the problem of unknown required degrees of freedom by Error-Adaptive Knot Insertion (EAKI). During the iterations of our re-weighted least-squares formulation, we check for regions of high error on the curve and locally increase the degrees of freedom if necessary. Third, we present a method to handle deep and narrow concavities, called Concavity Filling (CF). The curve is examined for areas of large distances to the closest data points. In these regions, we explicitly strap the curve to internal points to force it to bend inwards and fill the concavity. Compared with the state of the art, our method shows fundamental improvement in terms of robustness and applicability to real-world data. For 3D reconstruction of organized and unorganized point clouds, prevalent in robotic \{RGBD\} perception, we achieve higher robustness compared to state-of-the-art methods and compression rates up to a factor of 300. We have integrated our code into the Point Cloud Library (PCL) and created a tutorial that guides through the steps of the algorithm (see footnote 1). "
}
@article{Cocias2013960,
title = "Generic fitted shapes (GFS): Volumetric object segmentation in service robotics ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "9",
pages = "960 - 972",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.020",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000845",
author = "Tiberiu T. Cocias and Florin Moldoveanu and Sorin M. Grigorescu",
keywords = "Active contours",
keywords = "3D segmentation",
keywords = "3D reconstruction",
keywords = "Robot vision systems",
keywords = "RGB-D sensors ",
abstract = "Abstract In this paper, a simultaneous 3D volumetric segmentation and reconstruction method, based on the so-called Generic Fitted Shapes (GFS) is proposed. The aim of this work is to cope with the lack of volumetric information encountered in visually controlled mobile manipulation systems equipped with stereo or RGB-D cameras. Instead of using primitive volumes, such as cuboids or cylinders, for approximating objects in point clouds, their volumetric structure has been estimated based on fitted generic shapes. The proposed \{GFSs\} can capture the shapes of a broad range of object classes without the need of large a-priori shape databases. The fitting algorithm, which aims at determining the particular geometry of each object of interest, is based on a modified version of the active contours approach extended to the 3D Cartesian space. The proposed volumetric segmentation system produces comprehensive closed object surfaces which can be further used in mobile manipulation scenarios. Within the experimental setup, the proposed technique has been evaluated against two state-of-the-art methods, namely superquadrics and 3D Object Retrieval (3DOR) engines. "
}
@article{Munaro201697,
title = "3D robot perception with Point Cloud Library ",
journal = "Robotics and Autonomous Systems ",
volume = "78",
number = "",
pages = "97 - 99",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.12.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015003176",
author = "Matteo Munaro and Radu B. Rusu and Emanuele Menegatti"
}
@article{daSilva2016108,
title = "A Cloud-based Architecture for the Internet of Things targeting Industrial Devices Remote Monitoring and Control ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "30",
pages = "108 - 113",
year = "2016",
note = "4th \{IFAC\} Symposium on Telematics Applications \{TA\} 2016Porto Alwegre, Brasil, 6—9 November 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.137",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316325885",
author = "Ademir F. da Silva and Ricardo L. Ohta and Marcelo N. dos Santos and Alecio P.D. Binotto",
keywords = "Internet of Things (IoT)",
keywords = "Industry 4.0",
keywords = "Tele-maintenanc ",
abstract = "Abstract: The process of acquiring, analysing and managing data obtained by sensors and actuators in industrial environments can benefit from modern Cloud-based platforms towards a complete implementation of the Industrie 4.0 concept. The analysis of huge data sets produced by these sensors (Big Data) could allow quick and accurate decision making. For example, productivity improvements can be achieved by analysing device performance and degradation for real-time feedback on configuration and optimization. This work proposes a Cloud-based architecture for Internet of Things (IoT) applications to improve the deployment of smart industrial systems based on remote monitoring and control. By using specific technologies available as a service, we demonstrate the proposed architecture on an automated electric induction motor use case. This approach includes layers for sensor network data gathering, data transformation between standard protocols, message queuing, real-time data analysis, reporting for further analysis, and real-time control. Particularly, by using the proposed architecture, we remotely monitored, controlled and processed data produced by sensors and actuators coupled to the motor. Preliminary results indicate this foundation can support predictive methods and management of automated systems in the Industrie 4.0 context. "
}
@article{Remetean2016161,
title = "Philae locating and science support by robotic vision techniques ",
journal = "Acta Astronautica ",
volume = "125",
number = "",
pages = "161 - 173",
year = "2016",
note = "Rosetta and Philae at comet 67P/Churyumov-Gerasimenko ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515004397",
author = "E. Remetean and B. Dolives and F. Souvannavong and T. Germa and JB. Ginestet and A. Torres and T. Mousset",
keywords = "Philae;",
keywords = "Robotics;",
keywords = "Vision ",
abstract = "Abstract The ROLIS, CIVA-P and \{OSIRIS\} instruments on-board the Philae lander and the Rosetta orbiter acquired high-resolution images during the lander׳s descent towards the targeted landing site Agilkia, during its unexpected rebounds and at the final landing site Abydos on comet 67P/Churyumov–Gerasimenko. We, exploited these images, using robotic vision techniques, to locate the first touchdown on the surface of the comet nucleus, to reconstruct the lander׳s 3D trajectory during the descent and at the beginning of the first rebound, and to create local digital terrain models and depth maps of Agilkia and Abydos sites. Using the \{ROLIS\} close-up images we could also determine the actual movements of the lander between the beginning and the end of the First Science Sequence and we propose a new lander׳s bubble movement command meant to increase the probability for a successful drilling during a hypothetical future Long Term Science phase. "
}
@article{Jaklič2015143,
title = "Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century \{AD\} Roman shipwreck near Sutivan on island Brač, Croatia ",
journal = "Journal of Archaeological Science ",
volume = "62",
number = "",
pages = "143 - 152",
year = "2015",
note = "",
issn = "0305-4403",
doi = "https://doi.org/10.1016/j.jas.2015.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0305440315002447",
author = "Aleš Jaklič and Miran Erič and Igor Mihajlović and Žiga Stopinšek and Franc Solina",
keywords = "Multi-image photogrammetry",
keywords = "Under-water archeology",
keywords = "Marble blocks",
keywords = "Segmentation",
keywords = "3D models",
keywords = "Superquadrics ",
abstract = "Abstract Multi-image photogrammetry can in favorable conditions even under water generate large clouds of 3D points which can be used for visualization of sunken heritage. For analysis of under-water archeological sites and comparison of artifacts, more compact shape models must be reconstructed from 3D points, where each object or a part of it is modeled individually. Volumetric models and superquadric models in particular are good candidates for such modeling since automated methods for their reconstruction and segmentation from 3D points exist. For the study case we use an underwater wreck site of a Roman ship from 2nd/3rd century \{AD\} located near Sutivan on island Brač in Croatia. We demonstrate how superquadric models of sarcophagi and other stone blocks can be reconstructed from an unsegmented cloud of 3D points obtained by multi-image photogrammetry. We compare the dimensions of stone objects measured directly on the corresponding 3D point cloud with dimensions of the reconstructed superquadric models and discuss other advantages of these volumetric models. The average difference between point-to-point measurements of stone blocks and the dimensions of the corresponding superquadric model is on the order of few centimeters. "
}
@article{Jiménez2017107,
title = "Visual grasp point localization, classification and state recognition in robotic manipulation of cloth: An overview ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "107 - 125",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016303517",
author = "P. Jiménez",
keywords = "Deformable object manipulation",
keywords = "Robotic vision",
keywords = "Clothing",
keywords = "Cloth state recognition",
keywords = "Garment classification",
keywords = "Grasp point localization ",
abstract = "Abstract Cloth manipulation by robots is gaining popularity among researchers because of its relevance, mainly (but not only) in domestic and assistive robotics. The required science and technologies begin to be ripe for the challenges posed by the manipulation of soft materials, and many contributions have appeared in the last years. This survey provides a systematic review of existing techniques for the basic perceptual tasks of grasp point localization, state estimation and classification of cloth items, from the perspective of their manipulation by robots. This choice is grounded on the fact that any manipulative action requires to instruct the robot where to grasp, and most garment handling activities depend on the correct recognition of the type to which the particular cloth item belongs and its state. The high inter- and intraclass variability of garments, the continuous nature of the possible deformations of cloth and the evident difficulties in predicting their localization and extension on the garment piece are challenges that have encouraged the researchers to provide a plethora of methods to confront such problems, with some promising results. The present review constitutes for the first time an effort in furnishing a structured framework of these works, with the aim of helping future contributors to gain both insight and perspective on the subject. "
}
@article{Kalogerakis2009282,
title = "Extracting lines of curvature from noisy point clouds ",
journal = "Computer-Aided Design ",
volume = "41",
number = "4",
pages = "282 - 292",
year = "2009",
note = "Point-based Computational Techniques ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2008.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448508002273",
author = "Evangelos Kalogerakis and Derek Nowrouzezahrai and Patricio Simari and Karan Singh",
keywords = "Lines of curvature",
keywords = "Robust curvature estimation",
keywords = "Point cloud denoising",
keywords = "Outlier rejection",
keywords = "Quad mesh construction ",
abstract = "We present a robust framework for extracting lines of curvature from point clouds. First, we show a novel approach to denoising the input point cloud using robust statistical estimates of surface normal and curvature which automatically rejects outliers and corrects points by energy minimization. Then the lines of curvature are constructed on the point cloud with controllable density. Our approach is applicable to surfaces of arbitrary genus, with or without boundaries, and is statistically robust to noise and outliers while preserving sharp surface features. We show our approach to be effective over a range of synthetic and real-world input datasets with varying amounts of noise and outliers. The extraction of curvature information can benefit many applications in CAD, computer vision and graphics for point cloud shape analysis, recognition and segmentation. Here, we show the possibility of using the lines of curvature for feature-preserving mesh construction directly from noisy point clouds. "
}
@article{Abayowa201568,
title = "Automatic registration of optical aerial imagery to a LiDAR point cloud for generation of city models ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "106",
number = "",
pages = "68 - 81",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001434",
author = "Bernard O. Abayowa and Alper Yilmaz and Russell C. Hardie",
keywords = "Scene modeling",
keywords = "Aerial imagery",
keywords = "Sensor fusion",
keywords = "LiDAR",
keywords = "3D registration ",
abstract = "Abstract This paper presents a framework for automatic registration of both the optical and 3D structural information extracted from oblique aerial imagery to a Light Detection and Ranging (LiDAR) point cloud without prior knowledge of an initial alignment. The framework employs a coarse to fine strategy in the estimation of the registration parameters. First, a dense 3D point cloud and the associated relative camera parameters are extracted from the optical aerial imagery using a state-of-the-art 3D reconstruction algorithm. Next, a digital surface model (DSM) is generated from both the LiDAR and the optical imagery-derived point clouds. Coarse registration parameters are then computed from salient features extracted from the LiDAR and optical imagery-derived DSMs. The registration parameters are further refined using the iterative closest point (ICP) algorithm to minimize global error between the registered point clouds. The novelty of the proposed approach is in the computation of salient features from the DSMs, and the selection of matching salient features using geometric invariants coupled with Normalized Cross Correlation (NCC) match validation. The feature extraction and matching process enables the automatic estimation of the coarse registration parameters required for initializing the fine registration process. The registration framework is tested on a simulated scene and aerial datasets acquired in real urban environments. Results demonstrates the robustness of the framework for registering optical and 3D structural information extracted from aerial imagery to a LiDAR point cloud, when co-existing initial registration parameters are unavailable. "
}
@article{Hassan20171,
title = "Special Issue on: Design Automation for Embedded Ubiquitous Computing Systems (DAEUCS) ",
journal = "Journal of Systems Architecture ",
volume = "72",
number = "",
pages = "1 - 2",
year = "2017",
note = "Design Automation for Embedded Ubiquitous Computing Systems ",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S1383762117300012",
author = "Houcine Hassan and Laurence T. Yang and Haibo Zhang"
}
@article{Moldovan2017,
title = "Elastic systems: Towards cyber-physical ecosystems of people, processes, and things ",
journal = "Computer Standards & Interfaces ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2017.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S092054891630232X",
author = "Daniel Moldovan and Georgiana Copil and Schahram Dustdar",
keywords = "Elasticity",
keywords = "Cloud",
keywords = "IoT",
keywords = "Human-based computing ",
abstract = "Abstract Pervasive mobility and an exponential increase in the number of connected devices are adding to \{IT\} complexity. Users are bypassing traditional \{IT\} to access cloud-based services. Boundaries between computing systems, people, and things are disappearing. New approaches are required to manage today's and tomorrow's increasingly connected and heterogeneous ecosystems of people, computing processes, and things. We envision future elastic systems driven by business requirements, integrating computing, people, and things in open dynamic ecosystems in which all entities collaborate towards common goals. We introduce elasticity as a means of integrating computing processes, people, and things. We identify the core computing fields enabling future elastic systems: (i) hardware and software reusability, (ii) smart things, (iv) adaptation, and (v) human-based computing. We look at the development of these fields, and identify fundamental properties for building future elastic systems. We further envision a new field of research: Elastic Computing. We identify and discuss challenges to be addressed by this field towards realizing future elastic systems: Are existing programming languages and models sufficient for designing and managing future elastic systems? How important are the interactions between people, computers, and things? Can people and things be monitored and controlled like computing resources? "
}
@article{Feng2015128,
title = "Vision guided autonomous robotic assembly and as-built scanning on unstructured construction sites ",
journal = "Automation in Construction ",
volume = "59",
number = "",
pages = "128 - 138",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S092658051500120X",
author = "Chen Feng and Yong Xiao and Aaron Willette and Wes McGee and Vineet R. Kamat",
keywords = "On-site construction robotics",
keywords = "Autonomous assembly",
keywords = "Pose estimation",
keywords = "As-built 3D modeling ",
abstract = "Abstract Unlike robotics in the manufacturing industry, on-site construction robotics has to consider and address two unique challenges: 1) the rugged, evolving, and unstructured environment of typical work sites; and 2) the reversed spatial relationship between the product and the manipulator, i.e., the manipulator has to travel to and localize itself at the work face, rather than a partially complete product arriving at an anchored manipulator. The presented research designed and implemented algorithms that address these challenges and enable autonomous robotic assembly of freeform modular structures on construction sites. Building on the authors' previous work in computer-vision-based pose estimation, the designed algorithms enable a mobile robotic manipulator to: 1) autonomously identify and grasp prismatic building components (e.g., bricks, blocks) that are typically non-unique and arbitrarily stored on-site; and 2) assemble these components into pre-designed modular structures. The algorithms use a single camera and a visual marker-based metrology to rapidly establish local reference frames and to detect staged building components. Based on the design of the structure being assembled, the algorithms automatically determine the assembly sequence. Furthermore, if a 3D camera is mounted on the manipulator, 3D point clouds can be readily captured and registered into a same reference frame through our marker-based metrology and the manipulator's internal encoders, either after construction to facilitate as-built Building Information Model (BIM) generation, or during construction to document details of the progress. Implemented using a 7-axis \{KUKA\} \{KR100\} robotic manipulator, the presented robotic system has successfully assembled various structures and created as-built 3D point cloud models autonomously, demonstrating the designed algorithms' effectiveness in autonomous on-site construction robotics applications. "
}
@article{Rusu2008927,
title = "Towards 3D Point cloud based object maps for household environments ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "11",
pages = "927 - 941",
year = "2008",
note = "Semantic Knowledge in Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001140",
author = "Radu Bogdan Rusu and Zoltan Csaba Marton and Nico Blodow and Mihai Dolha and Michael Beetz",
keywords = "Environment object model",
keywords = "Point cloud data",
keywords = "Geometrical reasoning ",
abstract = "This article investigates the problem of acquiring 3D object maps of indoor household environments, in particular kitchens. The objects modeled in these maps include cupboards, tables, drawers and shelves, which are of particular importance for a household robotic assistant. Our mapping approach is based on \{PCD\} (point cloud data) representations. Sophisticated interpretation methods operating on these representations eliminate noise and resample the data without deleting the important details, and interpret the improved point clouds in terms of rectangular planes and 3D geometric shapes. We detail the steps of our mapping approach and explain the key techniques that make it work. The novel techniques include statistical analysis, persistent histogram features estimation that allows for a consistent registration, resampling with additional robust fitting techniques, and segmentation of the environment into meaningful regions. "
}
@article{Reina2016114,
title = "Ambient awareness for agricultural robotic vehicles ",
journal = "Biosystems Engineering ",
volume = "146",
number = "",
pages = "114 - 132",
year = "2016",
note = "Special Issue: Advances in Robotic Agriculture for Crops ",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2015.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015001889",
author = "Giulio Reina and Annalisa Milella and Raphaël Rouveure and Michael Nielsen and Rainer Worst and Morten R. Blas",
keywords = "Agricultural robotics",
keywords = "Intelligent vehicles",
keywords = "Safe driving in crop fields",
keywords = "Advanced perception systems",
keywords = "Ambient awareness ",
abstract = "In the last few years, robotic technology has been increasingly employed in agriculture to develop intelligent vehicles that can improve productivity and competitiveness. Accurate and robust environmental perception is a critical requirement to address unsolved issues including safe interaction with field workers and animals, obstacle detection in controlled traffic applications, crop row guidance, surveying for variable rate applications, and situation awareness, in general, towards increased process automation. Given the variety of conditions that may be encountered in the field, no single sensor exists that can guarantee reliable results in every scenario. The development of a multi-sensory perception system to increase the ambient awareness of an agricultural vehicle operating in crop fields is the objective of the Ambient Awareness for Autonomous Agricultural Vehicles (QUAD-AV) project. Different onboard sensor technologies, namely stereovision, LIDAR, radar, and thermography, are considered. Novel methods for their combination are proposed to automatically detect obstacles and discern traversable from non-traversable areas. Experimental results, obtained in agricultural contexts, are presented showing the effectiveness of the proposed methods. "
}
@article{Jiang20093839,
title = "Registration for 3-D point cloud using angular-invariant feature ",
journal = "Neurocomputing ",
volume = "72",
number = "16–18",
pages = "3839 - 3844",
year = "2009",
note = "Financial EngineeringComputational and Ambient Intelligence (IWANN 2007) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2009.05.013",
url = "http://www.sciencedirect.com/science/article/pii/S0925231209001702",
author = "Jun Jiang and Jun Cheng and Xinglin Chen",
keywords = "3-D registration",
keywords = "ICP",
keywords = "Angular invariant",
keywords = "Curvature invariant",
keywords = "3-D point cloud ",
abstract = "This paper proposes an angular-invariant feature for 3-D registration procedure to perform reliable selection of point correspondence. The feature is a k -dimensional vector, and each element within the vector is an angle between the normal vector and one of its k nearest neighbors. The angular feature is invariant to scale and rotation transformation, and is applicable for the surface with small curvature. The feature improves the convergence and error without any assumptions about the initial transformation. Besides, no strict sampling strategy is required. Experiments illustrate that the proposed angular-based algorithm is more effective than iterative closest point (ICP) and the curvature-based algorithm. "
}
@incollection{Partridge2017,
title = "Artificial Intelligence☆ ",
editor = "",
booktitle = "Reference Module in Neuroscience and Biobehavioral Psychology ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2017",
pages = " - ",
isbn = "978-0-12-809324-5",
doi = "https://doi.org/10.1016/B978-0-12-809324-5.02995-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128093245029953",
author = "D. Partridge",
keywords = "AI",
keywords = "Cognitive science",
keywords = "Computational theory of mind",
keywords = "Emergent mind theory",
keywords = "Machine learning",
keywords = "Machine translation",
keywords = "Neural computing",
keywords = "Robotics",
keywords = "Superintelligence",
keywords = "Turing test ",
abstract = "Abstract A broad survey of the full scope of activities aimed at developing computer systems that exhibit various aspects of intelligence—language understanding, vision, learning and robotics. The survey is developed from a basis of programming philosophy, either procedural or declarative (such as logic programming), and deductive versus inductive. This latter class of implementation is explained in terms of neural computing. The survey concludes with philosophical speculation—emergent mind theory versus computational theory of mind, the Turing Test and the notions of superintelligence. "
}
@article{Polewski2015252,
title = "Detection of fallen trees in \{ALS\} point clouds using a Normalized Cut approach trained by simulation ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "105",
number = "",
pages = "252 - 271",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615000271",
author = "Przemyslaw Polewski and Wei Yao and Marco Heurich and Peter Krzystek and Uwe Stilla",
keywords = "Precision forestry",
keywords = "Dead trees",
keywords = "Normalized Cut",
keywords = "LiDAR",
keywords = "Learning",
keywords = "Vegetation mapping ",
abstract = "Abstract Downed dead wood is regarded as an important part of forest ecosystems from an ecological perspective, which drives the need for investigating its spatial distribution. Based on several studies, Airborne Laser Scanning (ALS) has proven to be a valuable remote sensing technique for obtaining such information. This paper describes a unified approach to the detection of fallen trees from \{ALS\} point clouds based on merging short segments into whole stems using the Normalized Cut algorithm. We introduce a new method of defining the segment similarity function for the clustering procedure, where the attribute weights are learned from labeled data. Based on a relationship between Normalized Cut’s similarity function and a class of regression models, we show how to learn the similarity function by training a classifier. Furthermore, we propose using an appearance-based stopping criterion for the graph cut algorithm as an alternative to the standard Normalized Cut threshold approach. We set up a virtual fallen tree generation scheme to simulate complex forest scenarios with multiple overlapping fallen stems. This simulated data is then used as a basis to learn both the similarity function and the stopping criterion for Normalized Cut. We evaluate our approach on 5 plots from the strictly protected mixed mountain forest within the Bavarian Forest National Park using reference data obtained via a manual field inventory. The experimental results show that our method is able to detect up to 90% of fallen stems in plots having 30–40% overstory cover with a correctness exceeding 80%, even in quite complex forest scenes. Moreover, the performance for feature weights trained on simulated data is competitive with the case when the weights are calculated using a grid search on the test data, which indicates that the learned similarity function and stopping criterion can generalize well on new plots. "
}
@article{Azariadis2007832,
title = "Product design using point-cloud surfaces: A recursive subdivision technique for point parameterization ",
journal = "Computers in Industry ",
volume = "58",
number = "8–9",
pages = "832 - 843",
year = "2007",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2007.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361507000528",
author = "Philip Azariadis and Nickolas Sapidis",
keywords = "Point-cloud",
keywords = "Point-set surfaces",
keywords = "Parameterization",
keywords = "Dynamic base surfaces",
keywords = "Point-based modelling ",
abstract = "This paper presents a method for parameterizing three-dimensional (3D) point-clouds using a recursive subdivision approach. The proposed solution adapts ideas from emerging point-based geometric modelling and extends the dynamic base surfaces (DBS) concept in order to improve the accuracy of the produced parameterizations. Using the new approach it is possible to compute parameterizations for point-clouds which may be “thick” or with a varying density. Indicative examples are presented to illustrate the benefits of the proposed method. "
}
@article{Eissa201517,
title = "Validating surface downwelling solar irradiances estimated by the McClear model under cloud-free skies in the United Arab Emirates ",
journal = "Solar Energy ",
volume = "114",
number = "",
pages = "17 - 31",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2015.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X15000316",
author = "Yehia Eissa and Saima Munawwar and Armel Oumbe and Philippe Blanc and Hosni Ghedira and Lucien Wald and Hélène Bru and Dominique Goffe",
keywords = "Aerosols",
keywords = "Atmosphere",
keywords = "MACC",
keywords = "Solar radiation ",
abstract = "Abstract McClear, a fast model based on a radiative transfer solver, exploits the atmospheric properties provided by the EU-funded \{MACC\} project (Monitoring Atmospheric Composition and Climate) to estimate the surface downwelling solar irradiances for cloud-free instances. This article presents the first validation of the McClear model for the specific climate of the United Arab Emirates where skies are frequently cloud-free but turbid. McClear accurately estimates the global horizontal irradiance measured every 10 min at seven sites. The bias ranges from −9 W m−2 (−1% of the mean observed irradiance) to +35 W m−2 (+6%). The root mean square error (RMSE) ranges from 22 W m−2 (4%) to 47 W m−2 (8%) and the coefficient of determination ranges from 0.980 to 0.990. Estimates of the direct irradiance at normal incidence exhibit an underestimation that is attributed to the overestimation of the aerosol optical depth in the \{MACC\} data set and not accounting for the circumsolar radiation in McClear. The corresponding bias ranges from −57 W m−2 (−8%) to +6 W m−2 (+1%). The \{RMSE\} ranges from 62 W m−2 (9%) to 87 W m−2 (13%) and the coefficient of determination ranges from 0.830 to 0.863. When compared to two other models in the literature, McClear is better able to capture the temporal variability of the direct irradiance at normal incidence. The validation results remain comparable for the global horizontal irradiance. "
}
@article{Morell201455,
title = "Geometric 3D point cloud compression ",
journal = "Pattern Recognition Letters ",
volume = "50",
number = "",
pages = "55 - 62",
year = "2014",
note = "Depth Image Analysis ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2014.05.016",
url = "http://www.sciencedirect.com/science/article/pii/S016786551400172X",
author = "Vicente Morell and Sergio Orts and Miguel Cazorla and Jose Garcia-Rodriguez",
keywords = "3D data",
keywords = "Compression",
keywords = "Kinect ",
abstract = "Abstract The use of 3D data in mobile robotics applications provides valuable information about the robot’s environment but usually the huge amount of 3D information is unmanageable by the robot storage and computing capabilities. A data compression is necessary to store and manage this information but preserving as much information as possible. In this paper, we propose a 3D lossy compression system based on plane extraction which represent the points of each scene plane as a Delaunay triangulation and a set of points/area information. The compression system can be customized to achieve different data compression or accuracy ratios. It also supports a color segmentation stage to preserve original scene color information and provides a realistic scene reconstruction. The design of the method provides a fast scene reconstruction useful for further visualization or processing tasks. "
}
@article{Mineo20161,
title = "Robotic path planning for non-destructive testing – A custom \{MATLAB\} toolbox approach ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "37",
number = "",
pages = "1 - 12",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.05.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000666",
author = "Carmelo Mineo and Stephen Gareth Pierce and Pascual Ian Nicholson and Ian Cooper",
keywords = "Robotics",
keywords = "Path-planning",
keywords = "Automated non-destructive inspections ",
abstract = "Abstract The requirement to increase inspection speeds for non-destructive testing (NDT) of composite aerospace parts is common to many manufacturers. The prevalence of complex curved surfaces in the industry provides motivation for the use of 6 axis robots in these inspections. The purpose of this paper is to present work undertaken for the development of a \{KUKA\} robot manipulator based automated \{NDT\} system. A new software solution is presented that enables flexible trajectory planning to be accomplished for the inspection of complex curved surfaces often encountered in engineering production. The techniques and issues associated with conventional manual inspection techniques and automated systems for the inspection of large complex surfaces were reviewed. This approach has directly influenced the development of a \{MATLAB\} toolbox targeted to \{NDT\} automation, capable of complex path planning, obstacle avoidance, and external synchronization between robots and associated external \{NDT\} systems. This paper highlights the advantages of this software over conventional off-line-programming approaches when applied to \{NDT\} measurements. An experimental validation of path trajectory generation, on a large and curved composite aerofoil component, is presented. Comparative metrology experiments were undertaken to evaluate the real path accuracy of the toolbox when inspecting a curved 0.5 m2 and a 1.6 m2 surface using a \{KUKA\} \{KR16\} L6-2 robot. The results have shown that the deviation of the distance between the commanded \{TCPs\} and the feedback positions were within 2.7 mm. The variance of the standoff between the probe and the scanned surfaces was smaller than the variance obtainable via commercial path-planning software. Tool paths were generated directly on the triangular mesh imported from the \{CAD\} models of the inspected components without need for an approximating analytical surface. By implementing full external control of the robotic hardware, it has been possible to synchronise the \{NDT\} data collection with positions at all points along the path, and our approach allows for the future development of additional functionality that is specific to \{NDT\} inspection problems. For the current \{NDT\} application, the deviations from \{CAD\} design and the requirements for both coarse and fine inspections, dependent on measured \{NDT\} data, demand flexibility in path planning beyond what is currently available from existing off-line robot programming software. "
}
@article{Cattani2006310,
title = "Influence of aerosol particles from biomass burning on cloud microphysical properties and radiative forcing ",
journal = "Atmospheric Research ",
volume = "82",
number = "1–2",
pages = "310 - 327",
year = "2006",
note = "14th International Conference on Clouds and Precipitation14th \{ICCP14th\} International Conference on Clouds and Precipitation ",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2005.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169809506000433",
author = "E. Cattani and M.J. Costa and F. Torricella and V. Levizzani and A.M. Silva",
keywords = "Aerosol–cloud interactions",
keywords = "Cloud parameter retrieval",
keywords = "Radiative transfer",
keywords = "Remote sensing ",
abstract = "Aerosol from biomass burning has been shown to strongly modify cloud microphysical properties and cloud lifetime through the so-called “indirect effect.” However, in the case of a lack of wet scavenging, it stays suspended for days to weeks and can be transported to considerable distances within an elevated layer above low-level cloud tops with minimal aerosol–cloud interactions. The observations carried out during the Southern African Regional Science Initiative (SAFARI) 2000 dry season field campaign often revealed the presence of an elevated biomass-burning aerosol layer above a semi-permanent stratiform cloud deck off the southern African coasts. MODerate-resolution Imaging Spectroradiometer (MODIS) cloud products were used to investigate the existence of an aerosol indirect effect on convective clouds. Results are presented documenting cloud effective radius and cloud radiative forcing variations due to the presence of the aerosol during the development of convective clouds. Radiative transfer simulations in the visible (0.8 μm, VIS) and near-infrared (1.6, 2.1 and 3.7 μm, NIR) wavelengths were instrumental in establishing the extent of the influence of a biomass-burning aerosol layer overlying a water cloud sheet on the \{MODIS\} satellite retrieval of cloud parameters, in particular the effective radius and the optical thickness. The radiative transfer simulations suggest that the presence of the aerosol induces a significant underestimation of the cloud optical thickness, whereas an underestimation of the retrieved effective radius is more pronounced in the retrieval that makes use of the 1.6 μm waveband than the 2.1 and 3.7 μm wavebands. The \{MODIS\} cloud products of 3 days of the \{SAFARI\} 2000 campaign were analyzed to determine whether the aerosol induced biases evidenced by the simulations also affect the operational cloud property retrieval. Cloud parameters, in particular the effective radius, are usually employed as indicators of the occurrence of aerosol–cloud interaction according to the “indirect effect.” However, these results highlight some of the difficulties associated with satellite retrievals of cloud properties and show the importance of an accurate sighting of the cloud and aerosol layer top and bottom heights in order to prevent erroneous detections of indirect effects. "
}
@article{Moghaddam2015828,
title = "Manufacturing-as-a-Service—From e-Work and Service-Oriented Architecture to the Cloud Manufacturing Paradigm ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "828 - 833",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.186",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315004255",
author = "Mohsen Moghaddam and José Reinaldo Silva and Shimon Y. Nof",
keywords = "Manufacturing Paradigm",
keywords = "Collaborative Control Theory (CCT)",
keywords = "Service design ",
abstract = "Abstract After consolidation of classic manufacturing line, several alternative arrangements have been experimented and modeled to explore emerging features such as non-linearity, integration, flexibility, and decentralization by the virtue of holonic and agent-based technologies. All this transformation reflects remarkable evolution in manufacturing systems and emergence of a ubiquitous culture introduced by e- Work and supported by Information and Communication Technologies (ICT). Yet, there is a new paradigm shift emerging in manufacturing: the tendency to move from the traditional product- /production-oriented manufacturing to service-oriented manufacturing. Such tendency is being spread in academic work as well as in today's management decisions. This article briefly reviews and analyzes the emerging coalition between collaborative e-Manufacturing and Service-Oriented Architecture (SOA) towards the fonnation of a new manufacturing paradigm composed of a cloud of sendees that enable the notion of Manufacturing-as-a-Service (MaaS). "
}
@article{Reddy201648,
title = "Computing an unevenness field from 3D laser range data to obtain traversable region around a mobile robot ",
journal = "Robotics and Autonomous Systems ",
volume = "84",
number = "",
pages = "48 - 63",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300744",
author = "Satish Kumar Reddy and Prabir K. Pal",
keywords = "Mobile robot",
keywords = "Outdoor navigation",
keywords = "Obstacle detection",
keywords = "Traversability",
keywords = "Velodyne laser scanner ",
abstract = "Abstract We introduce a novel measure of terrain unevenness, which is computed in terms of ranges of neighbouring laser beams of a 3D laser scanner mounted on a mobile robot. The unevenness so computed over all sampled points forms an unevenness field around the robot. We explore the nature of this measure of unevenness through analysis, and arrive at a reasonable policy for setting thresholds on unevenness in order to detect obstacles, and in the process mark out the traversable region around the mobile robot. The traversable region is obtained as a connectivity graph over 180 × 32 cells in about 30 ms time on an Intel i3 processor. This connectivity graph can be potentially used for path planning of the mobile robot. Conceptually and computationally the measure is simple and efficient. It has an added advantage of being robust against small tilts of the sensor during locomotion. It also works well on slopes. Although there are numerous ways of detecting traversable regions in the literature, it is the novelty of the measure and its analysis, which we believe is our contribution through this paper. We demonstrate its usefulness through experimental results and compare its performance with a standard method that uses both height and slope between neighbouring range points to detect obstacles. "
}
@article{Men2014223,
title = "Hue-assisted automatic registration of color point clouds ",
journal = "Journal of Computational Design and Engineering ",
volume = "1",
number = "4",
pages = "223 - 232",
year = "2014",
note = "",
issn = "2288-4300",
doi = "https://doi.org/10.7315/JCDE.2014.022",
url = "http://www.sciencedirect.com/science/article/pii/S2288430014500334",
author = "Hao Men and Kishore Pochiraju",
keywords = "Computational geometry",
keywords = "Mesh processing",
keywords = "Reverse engineering",
keywords = "Building information modeling (BIM)",
keywords = "Computer graphics ",
abstract = "Abstract This paper describes a variant of the extended Gaussian image based registration algorithm for point clouds with surface color information. The method correlates the distributions of surface normals for rotational alignment and grid occupancy for translational alignment with hue filters applied during the construction of surface normal histograms and occupancy grids. In this method, the size of the point cloud is reduced with a hue-based down sampling that is independent of the point sample density or local geometry. Experimental results show that use of the hue filters increases the registration speed and improves the registration accuracy. Coarse rigid transformations determined in this step enable fine alignment with dense, unfiltered point clouds or using Iterative Common Point (ICP) alignment techniques. "
}
@article{Chui2008270,
title = "Direct 5-axis tool-path generation from point cloud input using 3D biarc fitting ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "24",
number = "2",
pages = "270 - 286",
year = "2008",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2006.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584507000038",
author = "K.L. Chui and W.K. Chiu and K.M. Yu",
keywords = "Machining",
keywords = "Reverse engineering",
keywords = "5-Axis tool-path",
keywords = "3D biarc",
keywords = "Point cloud",
keywords = "Triangular mesh ",
abstract = "In reverse engineering, geometrical information of a product is obtained directly from a physical shape by a digitizing device. To fabricate the product, manufacturing information (usually tool-path) must be generated from a \{CAD\} model. The data digitized must be processed and in most cases, a surface model is constructed from them using some of the surface fitting technologies. However, these technologies are usually complicated and the process for constructing a surface patch from a massive digitizing data is time-consuming. To simplify the process for getting tool-path information, a simple algorithm is proposed in this paper. The algorithm is used to generate a 5-axis machining tool-path. Instead of implementing any complicated surface fitting techniques, a direct method is proposed for constructing three-dimensional (3D) triangular mesh from the digitizing data with the mesh points considered as the tool contact locations. Depending on the locations of the points digitized, a decimation procedure is applied such that some of the digitizing data will be filtered out. Then, the tool axis orientations which must be determined in 5-axis tool-path are calculated and the tool center locations are determined accordingly. A 3D biarc fitting technique is applied for all the tool center locations so that a complete 5-axis tool-path is obtained. "
}
@article{Hallsteinsen20122840,
title = "A development framework and methodology for self-adapting applications in ubiquitous computing environments ",
journal = "Journal of Systems and Software ",
volume = "85",
number = "12",
pages = "2840 - 2859",
year = "2012",
note = "Self-Adaptive Systems ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2012.07.052",
url = "http://www.sciencedirect.com/science/article/pii/S0164121212002245",
author = "S. Hallsteinsen and K. Geihs and N. Paspallis and F. Eliassen and G. Horn and J. Lorenzo and A. Mamelli and G.A. Papadopoulos",
keywords = "Adaptive software",
keywords = "Ubiquitous computing",
keywords = "Model-driven development",
keywords = "Middleware",
keywords = "Mobile computing ",
abstract = "Today software is the main enabler of many of the appliances and devices omnipresent in our daily life and important for our well being and work satisfaction. It is expected that the software works as intended, and that the software always and everywhere provides us with the best possible utility. This paper discusses the motivation, technical approach, and innovative results of the \{MUSIC\} project. \{MUSIC\} provides a comprehensive software development framework for applications that operate in ubiquitous and dynamic computing environments and adapt to context changes. Context is understood as any information about the user needs and operating environment which vary dynamically and have an impact on design choices. \{MUSIC\} supports several adaptation mechanisms and offers a model-driven application development approach supported by a sophisticated middleware that facilitates the dynamic and automatic adaptation of applications and services based on a clear separation of business logic, context awareness and adaptation concerns. The main contribution of this paper is a holistic, coherent presentation of the motivation, design, implementation, and evaluation of the \{MUSIC\} development framework and methodology. "
}
@article{Montero201599,
title = "Past, present and future of robotic tunnel inspection ",
journal = "Automation in Construction ",
volume = "59",
number = "",
pages = "99 - 112",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515000229",
author = "R. Montero and J.G. Victores and S. Martínez and A. Jardón and C. Balaguer",
keywords = "Robotics",
keywords = "Automation",
keywords = "Inspection",
keywords = "Maintenance",
keywords = "Tunnels",
keywords = "IAARC ",
abstract = "Abstract Nowadays, the vast majority of the tunnel inspection processes are performed manually by qualified operators. The process is subjective and the operators need to face very uncomfortable and even dangerous conditions such as dust environments, absence of light, or toxic substance exposition. Robotic technology can overcome many of these disadvantages and provide quality inspections collecting different types of data. This paper presents the key aspects of tunnel inspection and a survey of the developed robotic tunnel inspection systems up to date. Additionally, two projects regarding automation of the processes involved and future trends will be discussed. "
}
@article{Song201547,
title = "A comparison study of algorithms for surface normal determination based on point cloud data ",
journal = "Precision Engineering ",
volume = "39",
number = "",
pages = "47 - 55",
year = "2015",
note = "",
issn = "0141-6359",
doi = "https://doi.org/10.1016/j.precisioneng.2014.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S014163591400124X",
author = "Tao Song and Fengfeng(Jeff) Xi and Shuai Guo and Zhifa Ming and Yu Lin",
keywords = "Normal determination",
keywords = "Dynamic sampling method",
keywords = "Measuring error ",
abstract = "Abstract Robot applications in manufacturing of aircraft sheet metal parts require real-time methods for determining the surface normal using a digitized point data set measured by a 3D laser scanner. For this reason, six archived surface normal algorithms are compared. Though using different weights, these methods are all set to determine the surface normal at a given point by averaging the surface normals of the adjacent facets. In this paper, a comparison study is designed with a nearest neighboring method searching for adjacent facets, along with the introduction of a dynamic sampling method to investigate the effect of the resolution of a data set on the accuracy of surface normal determination. Three performance indices are proposed including the total number of final data points, the number of times of up-sampling and the total computing time. Three geometric models are considered including a sphere representing an aircraft cockpit, a cylinder representing a fuselage, and an ellipsoid representing a wing. The laser scanner error is modeled by a log-normal distribution. While all the six methods can generate satisfactory results in error-free case, the simulation results indicate that in error case \{MWE\} (mean weighted equally) and \{MWAAT\} (mean weighted by areas of adjacent triangles) are not favorable while the other four methods exhibit no obvious difference. "
}
@article{Dragone2015269,
title = "A cognitive robotic ecology approach to self-configuring and evolving \{AAL\} systems ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "45",
number = "",
pages = "269 - 280",
year = "2015",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2015.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0952197615001517",
author = "Mauro Dragone and Giuseppe Amato and Davide Bacciu and Stefano Chessa and Sonya Coleman and Maurizio Di Rocco and Claudio Gallicchio and Claudio Gennaro and Hector Lozano and Liam Maguire and Martin McGinnity and Alessio Micheli and Gregory M.P. O׳Hare and Arantxa Renteria and Alessandro Saffiotti and Claudio Vairo and Philip Vance",
keywords = "Robotic ecology",
keywords = "Ambient assisted living",
keywords = "Cognitive robotics",
keywords = "Machine learning",
keywords = "Planning ",
abstract = "Abstract Robotic ecologies are systems made out of several robotic devices, including mobile robots, wireless sensors and effectors embedded in everyday environments, where they cooperate to achieve complex tasks. This paper demonstrates how endowing robotic ecologies with information processing algorithms such as perception, learning, planning, and novelty detection can make these systems able to deliver modular, flexible, manageable and dependable Ambient Assisted Living (AAL) solutions. Specifically, we show how the integrated and self-organising cognitive solutions implemented within the \{EU\} project \{RUBICON\} (Robotic \{UBIquitous\} Cognitive Network) can reduce the need of costly pre-programming and maintenance of robotic ecologies. We illustrate how these solutions can be harnessed to (i) deliver a range of assistive services by coordinating the sensing &amp; acting capabilities of heterogeneous devices, (ii) adapt and tune the overall behaviour of the ecology to the preferences and behaviour of its inhabitants, and also (iii) deal with novel events, due to the occurrence of new user׳s activities and changing user׳s habits. "
}
@article{Lyapustin200712,
title = "Analysis of MODIS–MISR calibration differences using surface albedo around \{AERONET\} sites and cloud reflectance ",
journal = "Remote Sensing of Environment ",
volume = "107",
number = "1–2",
pages = "12 - 21",
year = "2007",
note = "Multi-angle Imaging SpectroRadiometer (MISR) Special IssueMISR Special Issue ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2006.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S0034425706004299",
author = "A. Lyapustin and Y. Wang and R. Kahn and J. Xiong and A. Ignatov and R. Wolfe and A. Wu and B. Holben and C. Bruegge",
keywords = "MODIS",
keywords = "MISR",
keywords = "Calibration",
keywords = "AERONET",
keywords = "Surface albedo",
keywords = "Cloud regression ",
abstract = "\{MODIS\} and \{MISR\} are two Earth Observing System instruments flown onboard the Terra satellite. Their synergistic use could greatly benefit the broad user community by ensuring a global view of the Earth with high-quality products. A necessary condition for data fusion is radiometric calibration agreement between the two instruments. Earlier studies showed about 3% absolute radiometric difference between \{MISR\} and respective \{MODIS\} land bands in the visible and near-IR spectrum, which are also used in aerosol and cloud research. This study compared two surface albedo products derived from \{MODIS\} and \{MISR\} \{L1B\} data using the AERONET-based Surface Reflectance Validation Network (ASRVN). The \{ASRVN\} shows a positive MISR–MODIS albedo bias of + (0.01–0.03). Cross-sensor calibration inconsistencies were identified as a primary cause of the albedo biases. To establish an independent MODIS–MISR calibration link, top-of-atmosphere \{MODIS\} and \{MISR\} reflectances were regressed against each other over liquid water clouds. The empirical regression results have been adjusted for the differences in the respective \{MISR\} and \{MODIS\} spectral responses using radiative transfer simulations. The MISR–MODIS band gain differences for the top-of-atmosphere reflectance estimated with this technique are + 6.0% in the Blue, + 3.3% in the Green, + 2.7% in the Red, and + 0.8% in the \{NIR\} band. Applying the derived values to rescale the \{MODIS\} or \{MISR\} \{L1B\} data is shown to significantly reduce the cross-sensor \{ASRVN\} surface albedo biases. An absolute calibration scale for both sensors could be established based on independent ground-based measurements of the surface albedo at selected \{AERONET\} sites. "
}
@article{Srinivasan2011535,
title = "Visual control of navigation in insects and its relevance for robotics ",
journal = "Current Opinion in Neurobiology ",
volume = "21",
number = "4",
pages = "535 - 543",
year = "2011",
note = "Sensory and motor systems ",
issn = "0959-4388",
doi = "https://doi.org/10.1016/j.conb.2011.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0959438811000882",
author = "Mandyam V Srinivasan",
abstract = "Flying insects display remarkable agility, despite their diminutive eyes and brains. This review describes our growing understanding of how these creatures use visual information to stabilize flight, avoid collisions with objects, regulate flight speed, detect and intercept other flying insects such as mates or prey, navigate to a distant food source, and orchestrate flawless landings. It also outlines the ways in which these insights are now being used to develop novel, biologically inspired strategies for the guidance of autonomous, airborne vehicles. "
}
@article{He2015354,
title = "An efficient registration algorithm based on spin image for LiDAR 3D point cloud models ",
journal = "Neurocomputing ",
volume = "151, Part 1",
number = "",
pages = "354 - 363",
year = "2015",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2014.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0925231214012120",
author = "Yuqing He and Yuangang Mei",
keywords = "3D model registration",
keywords = "Spin image",
keywords = "KD tree ",
abstract = "Abstract Spin image is a good point feature descriptor of the 3D surface and has been used in model registration for many applications from medical image processing to cooperation of multiple robots. However, researches show that current Spin-Image based Registration (SIR) algorithms present disadvantages in computational efficiency and robustness. Thus in this paper, aiming at 3D model acquired from LiDAR sensor, a new \{SIR\} algorithm is proposed to solve these problems. The new algorithm is on the basis of a new-constructed three-dimensional feature space, which, composed of the curvature, the Tsallis entropy of spin image, and the reflection intensity of laser sensor, is combined with the concept of KD-tree to firstly realize the primary key point matching, i.e., to find the Corresponding Point Candidate Set (CPCS). After that, spin-image based corresponding point searching is conducted with respect to each \{CPCS\} to precisely obtain the final corresponding points. The most absorbing advantages of the proposed method are as the following two aspects: on one hand, due to the introduction of the extra features, the fault corresponding relation introduced by spin image based method can be effectively reduced and thus the registration precision and robustness can be improved greatly; on the other hand, the \{CPCS\} obtained using low-dimensional feature space and KD-tree reduces extraordinarily the computational burden due to spin-image based correspondence searching. This greatly improves the computational efficiency of the proposed algorithm. Finally, in order to verify the feasibility and validity of the proposed algorithm, experiments are conducted and the results are analyzed. "
}
@article{Kranjc201738,
title = "ClowdFlows: Online workflows for distributed big data mining ",
journal = "Future Generation Computer Systems ",
volume = "68",
number = "",
pages = "38 - 58",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302709",
author = "Janez Kranjc and Roman Orač and Vid Podpečan and Nada Lavrač and Marko Robnik-Šikonja",
keywords = "Data mining platform",
keywords = "Cloud computing",
keywords = "Scientific workflows",
keywords = "Batch processing",
keywords = "Map-reduce",
keywords = "Big data ",
abstract = "Abstract The paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. The platform, called ClowdFlows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. As a web application, the ClowdFlows platform poses no software requirements and can be used from any modern browser, including mobile devices. The constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. The server-side software of ClowdFlows can be multiplied and distributed to any number of computing nodes. From a developer’s perspective the platform is easy to extend and supports distributed development with packages. The paper focuses on big data processing in the batch and real-time processing mode. Big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. The batch mode and real-time processing mode are demonstrated with practical use cases. Performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. The ability of ClowdFlows to handle big data sets and its nearly perfect linear speedup is demonstrated. "
}
@article{HosseininavehA20141197,
title = "Towards fully automatic reliable 3D acquisition: From designing imaging network to a complete and accurate point cloud ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1197 - 1207",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000670",
author = "Ali Hosseininaveh A. and Ben Sargeant and Tohid Erfani and Stuart Robson and Mark Shortis and Mona Hess and Jan Boehm",
keywords = "Stereo imaging network",
keywords = "Kinect fusion",
keywords = "Multi-view stereo",
keywords = "Automatic 3D acquisition",
keywords = "Inverse kinematics",
keywords = "Particle Swarm Optimization ",
abstract = "Abstract This paper describes a novel system for accurate 3D digitization of complex objects. Its main novelties can be seen in the new approach, which brings together different systems and tools in a unique platform capable of automatically generating an accurate and complete model for an object of interest. This is performed through generating an approximate model of the object, designing a stereo imaging network for the object with this model and capturing the images at the designed postures through exploiting an inverse kinematics method for a non-standard six degree of freedom robot. The images are then used for accurate and dense 3D reconstruction using photogrammetric multi-view stereo method in two modes, including resolving scale with baseline and with control points. The results confirm the feasibility of using Particle Swarm Optimization in solving inverse kinematics for this non-standard robot. The system provides this opportunity to test the effect of incidence angle on imaging network design and shows that the matching algorithms work effectively for incidence angle of 10°. The accuracy of the final point cloud generated with the system was tested in two modes through a comparison with a dataset generated with a close range 3D colour laser scanner. "
}
@article{Rehman20171,
title = "Towards next-generation heterogeneous mobile data stream mining applications: Opportunities, challenges, and future research directions ",
journal = "Journal of Network and Computer Applications ",
volume = "79",
number = "",
pages = "1 - 24",
year = "2017",
note = "",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2016.11.031",
url = "http://www.sciencedirect.com/science/article/pii/S1084804516302995",
author = "Muhammad Habib ur Rehman and Chee Sun Liew and Teh Ying Wah and Muhammad Khurram Khan",
keywords = "Frequent pattern mining",
keywords = "Classification",
keywords = "Clustering",
keywords = "Mobile computing",
keywords = "Cloud computing",
keywords = "Edge computing ",
abstract = "Abstract The convergence of Internet of Things (IoTs), mobile computing, cloud computing, edge computing and big data has brought a paradigm shift in computing technologies. New computing systems, application models, and application areas are emerging to handle the massive growth of streaming data in mobile environments such as smartphones, IoTs, body sensor networks, and wearable devices, to name a few. However, the challenge arises about how and where to process the data streams in order to perform analytic operations and uncover useful knowledge patterns. The mobile data stream mining (MDSM) applications involve a number of operations for, 1) data acquisition from heterogeneous data sources, 2) data preprocessing, 3) data fusion, 4) data mining, and 5) knowledge management. This article presents a thorough review of execution platforms for \{MDSM\} applications. In addition, a detailed taxonomic discussion of heterogeneous \{MDSM\} applications is presented. Moreover, the article presents detailed literature review of methods that are used to handle heterogeneity at application and platform levels. Finally, the gap analysis is articulated and future research directions are presented to develop next-generation \{MDSM\} applications. "
}
@article{Weiss2009982,
title = "Adaptive supervision of moving objects for mobile robotics applications ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "10",
pages = "982 - 995",
year = "2009",
note = "5th International Conference on Computational Intelligence, Robotics and Autonomous Systems (5th CIRAS) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001043",
author = "Norman Weiss",
keywords = "Adaptive computer vision",
keywords = "Image understanding",
keywords = "Autonomous mobile robots",
keywords = "Robot soccer ",
abstract = "One of the main tasks of mobile robotics is vision. Lighting independence, adaptivity and automated learning are still the main issues when it comes to applications. In this article, we present an image understanding system and its methods targeting automatic, lighting-independent and reliable color-based object recognition under real time conditions. Its application test bed is global vision robot soccer (i.e. FIRA MiroSot und RoboCup Small Size leagues) but it has many other applications in color-based supervision of moving objects. Under typical conditions, it learns the objects of recognition automatically, has zero setup time and tolerates environmental changes during run-time. "
}
@article{Elor201490,
title = "“Robot Cloud” gradient climbing with point measurements ",
journal = "Theoretical Computer Science ",
volume = "547",
number = "",
pages = "90 - 103",
year = "2014",
note = "",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2014.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S0304397514004617",
author = "Yotam Elor and Alfred M. Bruckstein",
keywords = "Source-seeking",
keywords = "Point measurement",
keywords = "Gradient",
keywords = "Fume tracking ",
abstract = "Abstract A scalar-field gradient climbing process for a large group of simple, low-capability mobile robotic agents using only point measurements is proposed and analyzed. The agents are assumed to be memoryless and to lack direct communication abilities. Their only implicit form of communication is by sensing the position of the members of the group. The proposed gradient following algorithm is based on a basic gathering algorithm. The gathering algorithm is augmented by controlling the agents' speed as follows: agents that sense a higher value of the field move slower toward the group center than those sensing lower values, thereby causing the swarm to drift in the direction of the underlying field gradient. Furthermore, a random motion component is added to each agent in order to prevent gathering and allow sampling of the scalar field. We prove that in the proposed algorithm, the group is cohesive and indeed follows the gradient of the scalar field. We also discuss an algorithm based on a more restrictive sensing capabilities for the agents. "
}
@article{Sharifzadeh2016301,
title = "Robust Surface Abnormality Detection for a Robotic Inspection System ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "21",
pages = "301 - 308",
year = "2016",
note = "7th \{IFAC\} Symposium on Mechatronic Systems \{MECHATRONICS\} 2016Loughborough University, Leicestershire, UK, 5—8 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.572",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316321620",
author = "Sara Sharifzadeh and Istvan Biro and Niels Lohse and Peter Kinnell",
keywords = "Automatic abnormality detection",
keywords = "Point Cloud analysis",
keywords = "Feature extraction",
keywords = "Feature classification",
keywords = "Adaptive smoothing",
keywords = "surface inspection ",
abstract = "Abstract: The detection of surface abnormalities on large complex parts represents a significant automation challenge. This is particularly true when surfaces are large (multiple square metres) but abnormalities are small (less than one mm square), and the surfaces of interest are not simple flat planes. One possible solution is to use a robot-mounted laser line scanner, which can acquire fast surface measurements from large complex geometries. The problem with this approach is that the collected data may vary in quality, and this makes it difficult to achieve accurate and reliable inspection. In this paper a strategy for abnormality detection on highly curved Aluminum surfaces, using surface data obtained by a robot-mounted laser scanner, is presented. Using the laser scanner, data is collected from surfaces containing abnormalities, in the form of surface dents or bumps, of approximately one millimeter in diameter. To examine the effect of scan conditions on abnormality detection, two different curved test surfaces are used, and in addition the lateral spacing of laser scans was also varied. These variables were considered because they influence the distribution of points, in the point cloud (PC), that represent an abnormality. The proposed analysis consists of three main steps. First, a pre-processing step consisting of a fine smoothing procedure followed by a global noise analysis is carried out. Second, an abnormality classifier is trained based on a set of predefined surface abnormalities. Third, the trained classifier is used on suspicious areas of the surface in a general unsupervised thresholding step. This step saves computational time as it avoids analyzing every surface data point. Experimental results show that, the proposed technique can successfully find all present abnormalities for both training and test sets with minor false positives and no false negatives. "
}
@article{Matsuda2014416,
title = "Configuration of a Production Control System through Cooperation of Software Units Using their Capability Profiles in the Cloud Environment ",
journal = "Procedia \{CIRP\} ",
volume = "17",
number = "",
pages = "416 - 421",
year = "2014",
note = "Variety Management in ManufacturingProceedings of the 47th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.01.044",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114002790",
author = "Michiko Matsuda and Kiminobu Kodama and Satoshi Noguchi and Sakuyuki Onishi and Toshikatsu Asano and Takuya Horikita and Kousuke Komatsubara",
keywords = "manufacturing application system",
keywords = "dynamic configuration",
keywords = "capability profile matching ",
abstract = "Abstract Recent manufacturing systems including application software for production control are required to have high flexibility and fast changeability. In response to this, this paper proposes the development and operation methodology for production control applications which are configured by cooperation of manufacturing software units provided by different vendors using capability profiling technology. In this methodology, a profile matcher uses the manufacturing software capability profile repository to find and select adequate software units by capability profile matching with the required capability profile. The manufacturing software capability profile repository can be organized using a standardized method given by \{ISO\} 16100 to describe capabilities of manufacturing software units in terms of the capability profile. Based on information from the matcher's output, the production control application has been configured by combining selected software units. The application configurator organizes the production control application by plug-and-play of software units which match the capability profile with the requirement. A profile matcher has been implemented. The experimentation that configured an application in a cloud environment that communicates with the equipment on the floor has been successfully done on a commercially available cloud service. This trial shows the potential for the proposed methodology as a solution for a quick and flexible configuration of a production control system. "
}
@article{OuYang2005338,
title = "Determining gouge-free ball-end mills for 3D surface machining from point cloud data ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "21",
number = "4–5",
pages = "338 - 345",
year = "2005",
note = "14th International Conference on Flexible Automation and Intelligent Manufacturing14th International Conference on Flexible Automation and Intelligent Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2004.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584504001164",
author = "Daoshan OuYang and Benjamin A. Van Nest and Hsi-Yung Feng",
keywords = "Tool selection",
keywords = "Ball-end mill",
keywords = "Gouging",
keywords = "Sculptured surface",
keywords = "Point cloud data ",
abstract = "This paper presents an algorithm to automatically determine the optimal size of the ball-end milling tool used for the three-axis finish machining of free-form surfaces directly from discrete coordinate data points. The tool is considered optimal if it is of the largest possible diameter that can access every data point without causing an overcut situation or gouging the other data points. Two well-developed techniques in computational geometry, Voronoi diagram and Delaunay triangulation, are used to establish the geometric relationship among data points from which the information required to determine the optimal tool size is extracted. The result of Delaunay triangulation is a set of tetrahedrons, with the data points as vertices, which define a corresponding set of empty circum-spheres. Each data point is a vertex of several tetrahedrons and the largest of the corresponding circum-spheres represents a valid estimation of the optimal tool size at the point. Since the data points are only a sample of the original 3D surface, accuracy of the estimated tool size can be improved by using the approximated normal vector at the data point. The estimated tool size is evaluated by comparing it to its theoretical value. Extensive simulation tests show that a robust and accurate method of determining the optimal ball-end mill size has been developed. "
}
@article{Möller20131415,
title = "Cleaning robot navigation using panoramic views and particle clouds as landmarks ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1415 - 1439",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001371",
author = "Ralf Möller and Martin Krzykawski and Lorenz Gerstmayr-Hillen and Michael Horst and David Fleer and Janina de Jong",
keywords = "Cleaning robot",
keywords = "Visual navigation",
keywords = "Particle filter",
keywords = "Topological-metrical map ",
abstract = "Abstract The paper describes a visual method for the navigation of autonomous floor-cleaning robots. The method constructs a topological map with metrical information where place nodes are characterized by panoramic images and by particle clouds representing position estimates. Current image and position estimate of the robot are interrelated to landmark images and position estimates stored in the map nodes through a holistic visual homing method which provides bearing and orientation estimates. Based on these estimates, a position estimate of the robot is updated by a particle filter. The robot’s position estimates are used to guide the robot along parallel, meandering lanes and are also assigned to newly created map nodes which later serve as landmarks. Computer simulations and robot experiments confirm that the robot position estimate obtained by this method is sufficiently accurate to keep the robot on parallel lanes, even in the presence of large random and systematic odometry errors. This ensures an efficient cleaning behavior with almost complete coverage of a rectangular area and only small repeated coverage. Furthermore, the topological-metrical map can be used to completely cover rooms or apartments by multiple meander parts. "
}
@article{Kwon200467,
title = "Fitting range data to primitives for rapid local 3D modeling using sparse range point clouds ",
journal = "Automation in Construction ",
volume = "13",
number = "1",
pages = "67 - 81",
year = "2004",
note = "The best of \{ISARC\} 2002 ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2003.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580503000773",
author = "Soon-Wook Kwon and Frederic Bosche and Changwan Kim and Carl T. Haas and Katherine A. Liapi",
keywords = "Sparse range point clouds",
keywords = "3D workspace modeling",
keywords = "Fitting and matching objects",
keywords = "Merging objects ",
abstract = "Techniques to rapidly model local spaces, using 3D range data, can enable implementation of: (1) real-time obstacle avoidance for improved safety, (2) advanced automated equipment control modes, and (3) as-built data acquisition for improved quantity tracking, engineering, and project control systems. The objective of the research reported here was to develop rapid local spatial modeling tools. Algorithms for fitting sparse range point clouds to geometric primitives such as spheres, cylinders, and cuboids have been developed as well as methods for merging primitives into assemblies. Results of experiments are presented and practical usage and limitations are discussed. "
}
@article{Zhang20161,
title = "Smart computing for large scale visual data sensing and processing ",
journal = "Neurocomputing ",
volume = "178",
number = "",
pages = "1 - 2",
year = "2016",
note = "Smart Computing for Large Scale Visual Data Sensing and Processing ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.10.108",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215015854",
author = "Lei Zhang and Pinar Duygulu and Wangmeng Zuo and Shiguang Shan and Alex Hauptmann"
}
@article{Lee2009968,
title = "Visibility-based modelling and control for network-based robotics ",
journal = "Pattern Recognition Letters ",
volume = "30",
number = "11",
pages = "968 - 976",
year = "2009",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2009.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167865509000750",
author = "Sang Il Lee and Byoung In Cho and Jae-Kyu Lee and Seongjin Ahn and Jin Wook Chung",
keywords = "Line-based recognition",
keywords = "Plane sweep",
keywords = "Real plane",
keywords = "Visibility test ",
abstract = "We present an algorithm to model 3D workspace and to understand test scene for navigation or human computer interaction in network-based mobile robot. This was done by line-based modelling and recognition algorithm. Line-based recognition using 3D lines has been tried by many researchers however its reliability still needs improvement due to ambiguity of 3D line feature information from original images. To improve the outcome, we approach firstly to find real planes using the given 3D lines and then to implement recognition process. The methods we use are principle component analysis (PCA), plane sweep, visibility test, and iterative closest point (ICP). During the implementation, we also use 3D map information for localization. We apply this algorithm to real test scene images and to find out our result can be useful to identify doors or walls in indoor environment with better efficiency. "
}
@incollection{Nadkarni2016159,
title = "Chapter 8 - Mobile Technologies and Clinical Computing ",
editor = "Nadkarni, Prakash ",
booktitle = "Clinical Research Computing ",
publisher = "Academic Press",
edition = "",
address = "",
year = "2016",
pages = "159 - 171",
isbn = "978-0-12-803130-8",
doi = "https://doi.org/10.1016/B978-0-12-803130-8.00008-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128031308000087",
author = "Prakash Nadkarni",
keywords = "mobile devices",
keywords = "mobile sensor technologies",
keywords = "patient-entered data",
keywords = "mobile security",
keywords = "mobile device ergonomics ",
abstract = "Abstract This chapter introduces the various types of mobile devices and discusses their users, both historical and recent. An aspect of mobile devices that is only just beginning to be tapped is their rich sensor capability; this makes possible the creation of nontraditional applications that were simply not conceivable with desktops. The use of mobile devices with respect to both patient-entered and provider-entered data are discussed. Finally, the current limitations of these technologies are explored under the following headings: display, keyboard input, voice input, wearable devices, and security. Some of these limitations will always exist due to the limitations of human anatomy and physiology, but others may be eliminated over time. "
}
@article{Elseberg201376,
title = "One billion points in the cloud – an octree for efficient processing of 3D laser scans ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "76",
number = "",
pages = "76 - 88",
year = "2013",
note = "Terrestrial 3D modelling ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612001888",
author = "Jan Elseberg and Dorit Borrmann and Andreas Nüchter",
keywords = "Octree",
keywords = "Tree data structure",
keywords = "Data compression",
keywords = "Frustum culling",
keywords = "Ray casting",
keywords = "RANSAC",
keywords = "Nearest neighbor search ",
abstract = "Automated 3-dimensional modeling pipelines include 3D scanning, registration, data abstraction, and visualization. All steps in such a pipeline require the processing of a massive amount of 3D data, due to the ability of current 3D scanners to sample environments with a high density. The increasing sampling rates make it easy to acquire Billions of spatial data points. This paper presents algorithms and data structures for handling these data. We propose an efficient octree to store and compress 3D data without loss of precision. We demonstrate its usage for an exchange file format, fast point cloud visualization, sped-up 3D scan matching, and shape detection algorithms. We evaluate our approach using typical terrestrial laser scans. "
}
@article{Senin201339,
title = "Point set augmentation through fitting for enhanced \{ICP\} registration of point clouds in multisensor coordinate metrology ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "39 - 52",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000877",
author = "N. Senin and B.M. Colosimo and M. Pacella",
keywords = "Multisensor data fusion",
keywords = "Coordinate metrology",
keywords = "Registration",
keywords = "Measurement error",
keywords = "Iterative Closest Point (ICP)",
keywords = "Model fitting ",
abstract = "In multisensor coordinate metrology scenarios involving the fusion of homogenous data, specifically 3D point clouds like those originated by \{CMMs\} and structured light scanners, the problem of registration, i.e. the proper localization of the clouds in the same coordinate system, is of central importance. For fine registration, known variants of the Iterative Closest Point (ICP) algorithm are commonly adopted; however, no attempt seems to be done to tweak such algorithms to better suit the distinctive multisensor nature of the data. This work investigates an original approach that targets issues which are specific to multisensor coordinate metrology scenarios, such as coexistence of point sets with different densities, different spatial arrangements (e.g. sparse \{CMM\} points vs. gridded sets from light scanners), and different noise levels associated to the point sets depending on the metrological performances of the sensors involved. The proposed approach is based on combining known \{ICP\} variants with novel point set augmentation techniques, where new points are added to existing sets with the purpose of improving registration performance and robustness to measurement error. In particular, augmentation techniques based on advanced fitting solutions promote a paradigm shift for registration, which is not seen as a geometric problem consisting in moving point sets as close as possible to each other, but as a problem where it is not the original points, but the underlying geometries that must be brought together. In this work, promising combinations of \{ICP\} and point augmentation techniques are investigated through the application to virtual scenarios involving synthetic geometries and simulated measurements. Guidelines for approaching registration problems in industrial scenarios involving multisensor data fusion are also provided. "
}
@article{Dodds1988179,
title = "Fuzziness in knowledge-based robotics systems ",
journal = "Fuzzy Sets and Systems ",
volume = "26",
number = "2",
pages = "179 - 193",
year = "1988",
note = "Fuzzy Control ",
issn = "0165-0114",
doi = "https://doi.org/10.1016/0165-0114(88)90207-2",
url = "http://www.sciencedirect.com/science/article/pii/0165011488902072",
author = "David R. Dodds",
keywords = "Knowledge representation",
keywords = "approximate and commonsense reasoning",
keywords = "Robotics ",
abstract = "This paper addresses how fuzziness is employed in a robotics system, for the purposes of object representation, object or feature location and as a means of representing actions performed on objects. Many, perhaps most, robotics systems do not take advantage of either regular data bases nor Solid Geometry data bases. This paper describes a robotic system which would use a multi-modal representation knowledge base (KB). The focus of the present paper is on the use of fuzziness in this robotic system. Keyboard entered natural language phrases would be used by a human user of the robot. The robot system would, in practice, translate these phrases into executable commands and coordinates. There are several points of departure that would be employed and the first of these is the use of ‘fuzzy descriptions’ rather than the conventional binary distinctive feature matrix (such as SHRDLU) or a point cluster approach. A fuzzy descriptor is a generalization of a geometric description of an object from the system's geometric data base. How the fuzzy descriptor works is described. Object or (geometric) feature location is handled by means of extrapolating the object description method. Named concrete or specific coordinate locations, or named abstract locations which involve a range of coordinates, are used to do this; by means of the familiar ‘linguistic variable’ which we all use in everyday speech. Some means whereby this is done is explained. The user of this robotic system may semantically attach linguistic variables to a fuzzy mapping of knowledge base object descriptions. The paper provides some details as to how a robotic system might be operated in an ‘action abstraction’ mode. "
}
@incollection{Fiedler2017299,
title = "Chapter 17 - The Future of Health Technology Management ",
editor = "Fiedler, Beth Ann ",
booktitle = "Managing Medical Devices Within a Regulatory Framework ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2017",
pages = "299 - 314",
isbn = "978-0-12-804179-6",
doi = "https://doi.org/10.1016/B978-0-12-804179-6.00017-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128041796000174",
author = "B.A. Fiedler",
keywords = "Biomaterials",
keywords = "Cloud computing",
keywords = "Consumer technology",
keywords = "Digital health",
keywords = "Evidence-based medicine",
keywords = "HAPIfork",
keywords = "Health technology management (HTM)",
keywords = "Practice-based medicine",
keywords = "Remote patient monitoring (RPM) ",
abstract = "Abstract The dynamic circumstances in the health system, healthcare delivery, and the envelopment of digital health continue to redefine the definition of health technology management (HTM). This chapter reviews traditional \{HTM\} and encapsulates how emerging technologies—remote patient monitoring (RPM), open software interfaces, and biomaterial development, impact the future of HTM. Further, we suggest that \{HTM\} personnel can optimize existing information to address problems with technology transfer and interoperability by becoming more familiar with the business product development process (PDP), the National Library of Medicine’s Universal Medical Language Systems, and opening collaborative channels for funding and subject matter expertise that expedite regulatory approval and reimbursement. "
}
@article{Yoshihara2012422,
title = "Topologically robust B-spline surface reconstruction from point clouds using level set methods and iterative geometric fitting algorithms ",
journal = "Computer Aided Geometric Design ",
volume = "29",
number = "7",
pages = "422 - 434",
year = "2012",
note = "Geometric Modeling and Processing 2012 ",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2012.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S0167839612000337",
author = "Hiroki Yoshihara and Tatsuya Yoshii and Tadahiro Shibutani and Takashi Maekawa",
keywords = "Level set method",
keywords = "Iterative geometric fitting method",
keywords = "B-spline surfaces",
keywords = "Catmull–Clark subdivision surfaces",
keywords = "Quadrilateral mesh ",
abstract = "In this paper, we present a procedure for automatically reconstructing an arbitrary topological surface from an unorganized point data set; this surface will have three representations, namely quadrilateral meshes, Catmull–Clark subdivision surfaces, and B-spline surfaces. Our novel reconstruction method adapts a level set method to capture the topology of the point clouds in a robust manner and then employs an iterative geometric fitting algorithm to generate high-quality Catmull–Clark subdivision surfaces. A quadrilateral mesh is generated by projecting the control net of the resulting Catmull–Clark surface onto its limit surface. Finally, the control net of the Catmull–Clark surface is converted to that of a B-spline surface. The reconstructed models of topologically complex models show the effectiveness of the proposed algorithm. "
}
@article{Wilson201197,
title = "Positive perspectives on cloud security ",
journal = "Information Security Technical Report ",
volume = "16",
number = "3–4",
pages = "97 - 101",
year = "2011",
note = "Cloud Security ",
issn = "1363-4127",
doi = "https://doi.org/10.1016/j.istr.2011.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1363412711000471",
author = "Piers Wilson",
abstract = "The adoption of cloud computing has faced challenges and there are concerns about the risks, the loss of control of data and the assurance of security and access control. This paper aims to show that these should be viewed as requirements which need to be fulfilled, but that the overriding benefits from cloud computing are such that businesses could face real challenges in future if they resist adoption and so the risks need to be, and can be, faced with a more positive outlook given this more balanced view. "
}
@article{Carley201271,
title = "Significant decadal channel change 58–67 years post-dam accounting for uncertainty in topographic change detection between contour maps and point cloud models ",
journal = "Geomorphology ",
volume = "179",
number = "",
pages = "71 - 88",
year = "2012",
note = "",
issn = "0169-555X",
doi = "https://doi.org/10.1016/j.geomorph.2012.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169555X12003819",
author = "Jennifer K. Carley and Gregory B. Pasternack and Joshua R. Wyrick and Jesse R. Barker and Paul M. Bratovich and Duane A. Massa and Gary D. Reedy and Thomas R. Johnson",
keywords = "Channel change",
keywords = "Geomorphic change detection",
keywords = "Uncertainly analysis",
keywords = "Dam impacts",
keywords = "Gravel-bed river",
keywords = "Fluvial geomorphology ",
abstract = "Construction of digital elevation models (DEMs) and the subtraction of \{DEMs\} between different points in time as a method to determine temporal patterns of scour and fill is a highly valuable procedure emerging in geomorphology. These \{DEMs\} of Differences (DoDs) must be assessed for error in order to distinguish actual topographic change from uncertainty and surface error. Current methods include: (1) uniformly excluding all values that fall below a minimum threshold; (2) using a spatially variable approach such as the construction of minimum Level of Detection (LoD) grids; or (3) the creation of a fuzzy inference system. Although spatially variable methods for determining error have been more accurate in excluding noise without discarding large amounts of meaningful data, a challenge remains in performing DoDs against preexisting contour-based maps for which no original point data are available. The goals of this study were to (1) develop a method that overcomes the unknown point density of contour (and other historical) data sets and allows for some assessment of DoD uncertainty on the basis of information on topographic variability, (2) perform comprehensive uncertainty analysis testing to understand the opportunities and constraints associated with this new method, and (3) report and interpret the overall pattern and volume of decadal topographic change for a regulated river 67 years post-dam in light of alternate conjectured mechanisms of post-dam longitudinal profile adjustment. The key feature of the new approach is the introduction of a high-density artificial point grid that samples the topographic variability evident in the available historical data set. The testbed used to develop and assess this new DoD method was the ~ 37.5-km lower Yuba River, California. Historical data consisted of 0.6-m contours from a 1999 survey, while a more detailed point cloud was available for the most recent survey in 2006–2008. To evaluate uncertainty in the method, this study applied seven different uncertainty metrics of varying strictness (t = 1, t = 1.96, uniform 0.3-m exclusion, t = 1 plus uniform 0.3 m exclusion, t = 1 with LoD minimum at 0.3, t = 1.96 plus uniform 0.3-m exclusion, and t = 1.96 with LoD minimum at 0.3) and two different DoD adjustment methods (exclusion and subtraction). A stringent approach involving joint use of the contour half-interval and the spatially distributed LoD grid at a 95% confidence limit excluded 44.3% of the study area from spatial assessment of channel change and volumetric change computation. This preferred approach yielded an estimated 2.518 million m3 of total scour and 2.455 million m3 of total fill in 7–9 years. After considering different mapping epochs, the net annual average export was 17,000 m3 (~ 32,500 tons) to the Feather River and a river-valley sediment yield of 2205 tons/km2/year. This amount is 36% of the post-dam annual yield of gravel and cobble to the upstream reservoir that blocks sediment conveyance into the study domain, suggesting that the lowland system is still highly dynamic 67 years after the dam was built. The scientific significance of this is that the response of rivers to dams can be far more long-lasting and complex, depending on the suite of cumulative societal impacts to rivers. The ability to account for spatially explicit DoD uncertainty (i.e., data retention when uncertainty is low and data removal when uncertainty is high) when comparing historic contour-based and modern point cloud-based \{DEMs\} will allow for more detailed and reliable DoDs and sediment budgets in these cases. "
}
@article{Vähä2013168,
title = "Extending automation of building construction — Survey on potential sensor technologies and robotic applications ",
journal = "Automation in Construction ",
volume = "36",
number = "",
pages = "168 - 178",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001167",
author = "Pentti Vähä and Tapio Heikkilä and Pekka Kilpeläinen and Markku Järviluoma and Ernesto Gambao",
keywords = "Sensor technologies",
keywords = "Building construction automation",
keywords = "Automated data acquisition",
keywords = "Construction robotics",
keywords = "Prefabrication ",
abstract = "Abstract Today, many construction operations have incorporated automated equipment, means, and methods into their regular practises. Although adaption of automation in the building construction sector has been slow, principles of industrial automation are applicable to this domain, both to building construction, civil engineering, and to prefabrication of construction components. Improved sensor technologies and the widening use of the Building Information Modeling (BIM) will offer new possibilities to cover various needs and operations taking place throughout the building life cycle. These can play a key role in future construction automation. This paper provides a survey for potential sensor technologies for building construction automation, highlighting their potential also with contributions from robotics. The paper carries out the survey from the viewpoints of building construction phases. "
}
@article{Babiceanu2016128,
title = "Big Data and virtualization for manufacturing cyber-physical systems: A survey of the current status and future outlook ",
journal = "Computers in Industry ",
volume = "81",
number = "",
pages = "128 - 137",
year = "2016",
note = "Emerging \{ICT\} concepts for smart, safe and sustainable industrial systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0166361516300471",
author = "Radu F. Babiceanu and Remzi Seker",
keywords = "Sensor-based real-time monitoring",
keywords = "Big Data",
keywords = "Internet of things",
keywords = "Cloud computing",
keywords = "Manufacturing cyber-physical systems ",
abstract = "Abstract The recent advances in sensor and communication technologies can provide the foundations for linking the physical manufacturing facility and machine world to the cyber world of Internet applications. The coupled manufacturing cyber-physical system is envisioned to handle the actual operations in the physical world while simultaneously monitor them in the cyber world with the help of advanced data processing and simulation models at both the manufacturing process and system operational levels. Moreover, a sensor-packed manufacturing system in which each process or piece of equipment makes available event and status information, coupled with market research for true advanced Big Data analytics, seem to be the right ingredients for event response selection and operation virtualization. As a drawback, the resulting manufacturing cyber-physical system will be vulnerable to the inevitable cyber-attacks, unfortunately, so common for the software and Internet-based systems. This reality makes cybersecurity penetration within the manufacturing domain a need that goes uncontested across researchers and practitioners. This work provides a review of the current status of virtualization and cloud-based services for manufacturing systems and of the use of Big Data analytics for planning and control of manufacturing operations. Building on already developed cloud business solutions, cloud manufacturing is expected to offer improved enterprise manufacturing and business decision support. Based on the current state-of-the-art cloud manufacturing solutions and Big Data applications, this work also proposes a framework for the development of predictive manufacturing cyber-physical systems that include capabilities for attaching to the Internet of Things, and capabilities for complex event processing and Big Data algorithmic analytics. "
}
@article{Caci20131493,
title = "Robotic and virtual World Programming labs to Stimulate Reasoning and visual-spatial Abilities ",
journal = "Procedia - Social and Behavioral Sciences ",
volume = "93",
number = "",
pages = "1493 - 1497",
year = "2013",
note = "3rd World Conference on Learning, Teaching and Educational Leadership ",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2013.10.070",
url = "http://www.sciencedirect.com/science/article/pii/S1877042813035155",
author = "Barbara Caci and Giuseppe Chiazzese and Antonella D’Amico",
keywords = "Robotics",
keywords = "virtual worlds",
keywords = "visual-spatial working memory",
keywords = "programming learning",
keywords = "playful learning environment. ",
abstract = "Abstract The individuals’ cognitive skills, academic performance and their relationship with programming of robots or virtual learning environment is a topic of particular interest in the area of human-robot interaction. This paper presents a pilot study performed on a group of 36 lower secondary school students involved in a 32-hours laboratory based on the combination of \{LEGO\} Mindstorm \{NXT\} and Microsoft Kodu Game Lab (KGL) and aimed at programming first a robot and further a more complete virtual world based on a narrative-designed scenario. The findings of the research will be discussed in the light of the effectiveness of using robotics and virtual world programming as a meaningful and playful learning environment for improving cognition in children. "
}
@article{Graña20092111,
title = "Two lattice computing approaches for the unsupervised segmentation of hyperspectral images ",
journal = "Neurocomputing ",
volume = "72",
number = "10–12",
pages = "2111 - 2120",
year = "2009",
note = "Lattice Computing and Natural Computing (JCIS 2007) / Neural Networks in Intelligent Systems Designn (ISDA 2007) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2008.06.026",
url = "http://www.sciencedirect.com/science/article/pii/S0925231208005468",
author = "Manuel Graña and Ivan Villaverde and José O. Maldonado and Carmen Hernandez",
keywords = "Hyperspectral images",
keywords = "Endmember induction",
keywords = "Lattice computing",
keywords = "Lattice independence",
keywords = "Auto-associative morphological memories",
keywords = "Lattice associative memories ",
abstract = "Endmembers for the spectral unmixing analysis of hyperspectral images are sets of affinely independent vectors, which define a convex polytope covering the data points that represent the pixel image spectra. Strong lattice independence (SLI) is a property defined in the context of lattice associative memories convergence analysis. Recent results show that \{SLI\} implies affine independence, confirming the value of lattice associative memories for the study of endmember induction algorithms. In fact, \{SLI\} vector sets can be easily deduced from the vectors composing the lattice auto-associative memories (LAM). However, the number of candidate endmembers found by this algorithm is very large, so that some selection algorithm is needed to obtain the full benefits of the approach. In this paper we explore the unsupervised segmentation of hyperspectral images based on the abundance images computed, first, by an endmember selection algorithm and, second, by a previously proposed heuristically defined algorithm. We find their results comparable on a qualitative basis. "
}
@article{Henn201317,
title = "Model driven reconstruction of roofs from sparse \{LIDAR\} point clouds ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "76",
number = "",
pages = "17 - 29",
year = "2013",
note = "Terrestrial 3D modelling ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612002043",
author = "André Henn and Gerhard Gröger and Viktor Stroh and Lutz Plümer",
keywords = "Reconstruction",
keywords = "Building",
keywords = "Data mining",
keywords = "Classification",
keywords = "LIDAR",
keywords = "Three-dimensional ",
abstract = "This article presents a novel, fully automatic method for the reconstruction of three-dimensional building models with prototypical roofs (CityGML LoD2) from \{LIDAR\} data and building footprints. The proposed method derives accurate results from sparse point data sets and is suitable for large area reconstruction. Sparse \{LIDAR\} data are widely available nowadays. Robust estimation methods such as RANSAC/MSAC, are applied to derive best fitting roof models in a model-driven way. For the identification of the most probable roof model, supervised machine learning methods (Support Vector Machines) are used. In contrast to standard approaches (where the best model is selected via \{MDL\} or AIC), supervised classification is able to incorporate additional features enabling a significant improvement in model selection accuracy. "
}
@incollection{Hong201477,
title = "6.04 - Robotic Welding Technology ",
editor = "Hashmi, Saleem and Batalha, Gilmar Ferreira and Tyne, Chester J. Van  and Yilbas, Bekir ",
booktitle = "Comprehensive Materials Processing ",
publisher = "Elsevier",
edition = "",
address = "Oxford",
year = "2014",
pages = "77 - 99",
isbn = "978-0-08-096533-8",
doi = "https://doi.org/10.1016/B978-0-08-096532-1.00604-X",
url = "http://www.sciencedirect.com/science/article/pii/B978008096532100604X",
author = "T.S. Hong and M. Ghobakhloo and W. Khaksar",
keywords = "Arc welding",
keywords = "Automatic welding",
keywords = "Friction stir welding",
keywords = "Robotics",
keywords = "Robot welding",
keywords = "Spot welding",
keywords = "Welding ",
abstract = "Abstract Since the first industrial robots were introduced in the early 1960s, the development of robotized welding has been truly remarkable and is today one of the major application areas for industrial robots. Robot welding is mainly concerned with the use of mechanized programmable tools, known as robots, which completely automate a welding process by both performing the weld and handling the part. Robots are quite versatile and hence have been used for a variety of welding types such as resistance welding and arc welding. This chapter describes the development and progress of robotization in welding over the years and also discusses many advantages and disadvantages of different robotic welding technologies. "
}
@article{Folch2012165,
title = "Validation of the \{FALL3D\} ash dispersion model using observations of the 2010 Eyjafjallajökull volcanic ash clouds ",
journal = "Atmospheric Environment ",
volume = "48",
number = "",
pages = "165 - 183",
year = "2012",
note = "Volcanic ash over Europe during the eruption of Eyjafjallajöekull on Iceland, April-May 2010 ",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.06.072",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011006960",
author = "A. Folch and A. Costa and S. Basart",
keywords = "Volcanic ash dispersion",
keywords = "Numerical model",
keywords = "Model validation",
keywords = "2010 Eyjafjallajökull eruption ",
abstract = "During April–May 2010 volcanic ash clouds from the Icelandic Eyjafjallajökull volcano reached Europe causing an unprecedented disruption of the EUR/NAT region airspace. Civil aviation authorities banned all flight operations because of the threat posed by volcanic ash to modern turbine aircraft. New quantitative airborne ash mass concentration thresholds, still under discussion, were adopted for discerning regions contaminated by ash. This has implications for ash dispersal models routinely used to forecast the evolution of ash clouds. In this new context, quantitative model validation and assessment of the accuracies of current state-of-the-art models is of paramount importance. The passage of volcanic ash clouds over central Europe, a territory hosting a dense network of meteorological and air quality observatories, generated a quantity of observations unusual for volcanic clouds. From the ground, the cloud was observed by aerosol lidars, lidar ceilometers, sun photometers, other remote-sensing instruments and in-situ collectors. From the air, sondes and multiple aircraft measurements also took extremely valuable in-situ and remote-sensing measurements. These measurements constitute an excellent database for model validation. Here we validate the \{FALL3D\} ash dispersal model by comparing model results with ground and airplane-based measurements obtained during the initial 14–23 April 2010 Eyjafjallajökull explosive phase. We run the model at high spatial resolution using as input hourly-averaged observed heights of the eruption column and the total grain size distribution reconstructed from field observations. Model results are then compared against remote ground-based and in-situ aircraft-based measurements, including lidar ceilometers from the German Meteorological Service, aerosol lidars and sun photometers from \{EARLINET\} and \{AERONET\} networks, and flight missions of the German \{DLR\} Falcon aircraft. We find good quantitative agreement, with an error similar to the spread in the observations (however depending on the method used to estimate mass eruption rate) for both airborne and ground mass concentration. Such verification results help us understand and constrain the accuracy and reliability of ash transport models and it is of enormous relevance for designing future operational mitigation strategies at Volcanic Ash Advisory Centers. "
}
@article{Gálvez2012174,
title = "Particle swarm optimization for non-uniform rational B-spline surface reconstruction from clouds of 3D data points ",
journal = "Information Sciences ",
volume = "192",
number = "",
pages = "174 - 192",
year = "2012",
note = "Swarm Intelligence and Its Applications ",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2010.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0020025510005529",
author = "Akemi Gálvez and Andrés Iglesias",
keywords = "Surface reconstruction",
keywords = "Reverse engineering",
keywords = "Surface parameterization",
keywords = "Surface fitting",
keywords = "Particle swarm optimization",
keywords = "NURBS surface ",
abstract = "This work investigates the use of particle swarm optimization (PSO) to recover the shape of a surface from clouds of (either organized or scattered) noisy 3D data points, a challenging problem that appears recurrently in a wide range of applications such as \{CAD\} design, data visualization, virtual reality, medical imaging and movie industries. In this paper, we apply a \{PSO\} approach in order to reconstruct a non-uniform rational B-spline (NURBS) surface of a certain order from a given set of 3D data points. In this case, surface reconstruction consists of two main tasks: (1) surface parameterization and (2) surface fitting. Both tasks are critical but also troublesome, leading to a high-dimensional non-linear optimization problem. Our method allows us to obtain all relevant surface data (i.e., parametric values of data points, knot vectors, control points and their weights) in a shot and no pre-/post-processing is required. Furthermore, it yields very good results even in presence of problematic features, such as multi-branches, high-genus or self-intersections. Seven examples including open, semiclosed, closed, zero-genus, high-genus surfaces and real-world scanned objects, described in free-form, parametric and implicit forms illustrate the good performance of our approach and its superiority over previous approaches in terms of accuracy and generality. "
}
@article{Lauri201615,
title = "Planning for robotic exploration based on forward simulation ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "15 - 31",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015301779",
author = "Mikko Lauri and Risto Ritala",
keywords = "Partially observable Markov decision process",
keywords = "Active sensing",
keywords = "Robotic exploration",
keywords = "Mutual information",
keywords = "Sensor management ",
abstract = "Abstract We address the problem of controlling a mobile robot to explore a partially known environment. The robot’s objective is the maximization of the amount of information collected about the environment. We formulate the problem as a partially observable Markov decision process (POMDP) with an information-theoretic objective function, and solve it applying forward simulation algorithms with an open-loop approximation. We present a new sample-based approximation for mutual information useful in mobile robotics. The approximation can be seamlessly integrated with forward simulation planning algorithms. We investigate the usefulness of \{POMDP\} based planning for exploration, and to alleviate some of its weaknesses propose a combination with frontier based exploration. Experimental results in simulated and real environments show that, depending on the environment, applying \{POMDP\} based planning for exploration can improve performance over frontier exploration. "
}
@article{Hammoudi2012971,
title = "Recovering Occlusion-Free Textured 3D Maps of Urban Facades by a Synergistic Use of Terrestrial Images, 3D Point Clouds and Area-Based Information ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "971 - 980",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.271",
url = "http://www.sciencedirect.com/science/article/pii/S1877705812026719",
author = "Karim Hammoudi and Fadi Dornaika and Bahman Soheilian and Bruno Vallet and John McDonald and Nicolas Paparoditis",
keywords = "Mobile Platform",
keywords = "Optical Sensors",
keywords = "Vision Sensors",
keywords = "Range Sensors",
keywords = "Sensor Fusion",
keywords = "Sensor Data Processing",
keywords = "Terrestrial-based Facade Modeling",
keywords = "Facade Texturing",
keywords = "Virtual Reality ",
abstract = "In this paper we present a practical approach for generating an occlusion-free textured 3D map of urban facades by the synergistic use of terrestrial images, 3D point clouds and area-based information. Particularly in dense urban environments, the high presence of urban objects in front of the facades causes significant difficulties for several stages in computational building modeling. Major challenges lie on the one hand in extracting complete 3D facade quadrilateral delimitations and on the other hand in generating occlusion-free facade textures. For these reasons, we describe a straightforward approach for completing and recovering facade geometry and textures by exploiting the data complementarity of terrestrial multi-source imagery and area-based information. "
}
@article{Jóźwiak201519,
title = "Embedded Computing Technology for Highly-demanding Cyber-physical Systems ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "4",
pages = "19 - 30",
year = "2015",
note = "13th \{IFAC\} and \{IEEE\} Conference on Programmable Devices and Embedded SystemsPDES 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315007776",
author = "Lech Jóźwiak",
keywords = "cyber-physical systems",
keywords = "embedded processors",
keywords = "application-specific processors",
keywords = "multiprocessor system on a chip (MPSoC)",
keywords = "mobile systems",
keywords = "autonomous systems",
keywords = "smart wearables",
keywords = "smart cars",
keywords = "video",
keywords = "image processing",
keywords = "high performance",
keywords = "low energy consumption ",
abstract = "Abstract The recent spectacular progress in the microelectronic, information, communication, material and sensor technologies created a big stimulus towards development of much more sophisticated, coherent and fit to use, smart communicating cyber-physical systems (CPS). The huge and rapidly developing markets of the modern \{CPS\} represent great opportunities for both private enterprises and country economies. However, these opportunities come with a price of unusual systems complexity, as well as, stringent and difficult to satisfy requirements of the modern \{CPS\} applications. Specifically, numerous mobile and autonomous \{CPS\} applications require a. o. a guaranteed (ultra-)high performance or (ultra-)low energy consumption, as well as, a high reliability, safety and security. To adequately address these problems and overcome the related challenges a sophisticated embedded computing and embedded design technologies are needed. After a brief introduction to modern \{CPS\} and consideration of several serious challenges of their design, this paper discusses the embedded computing technology needed for the modern complex and highly-demanding mobile and autonomous CPS. "
}
@article{Dix2016,
title = "Human–computer interaction, foundations and new paradigms ",
journal = "Journal of Visual Languages & Computing ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1045-926X",
doi = "https://doi.org/10.1016/j.jvlc.2016.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S1045926X16300088",
author = "Alan Dix",
keywords = "Human–computer interaction",
keywords = "History, ubiquitous computing",
keywords = "Cloud-computing",
keywords = "Design for solitude",
keywords = "Digital fabrication ",
abstract = "Abstract This paper explores the roots of human–computer interaction as a discipline, the various trends which have marked its development, and some of the current and future challenges for research. Human–computer interaction, like any vocational discipline, sits upon three broad foundations: theoretical principles, professional practice and a community of people. As an interdisciplinary field the theoretical roots of \{HCI\} encompass a number of other disciplines including psychology, computing, ergonomics, and social sciences; however, it also has theoretical and practical challenges of its own. The evolving internal and external context of HCI, computers, have become smaller and less costly; this has led to changes in nature of the users and uses of computers, with corresponding impact on society. The paper explores the current challenges of computers from the cloud to digital fabrication and the need to design for solitude. It suggests that \{HCI\} should not just react to the changes around it, but also shape those changes. "
}
@article{CommitteeonArmyRoboticsandArtificialIntelligence|ManufacturingStudiesBoard|CommissiononEngineeringandTechnicalSystems|NationalResearchCouncil1984191,
title = "Applications of robotics and artificial intelligence to reduce risk and improve effectiveness: A study for the United States Army ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "1",
number = "2",
pages = "191 - 222",
year = "1984",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/0736-5845(84)90007-3",
url = "http://www.sciencedirect.com/science/article/pii/0736584584900073",
author = "Committee on Army Robotics and Artificial Intelligence and Manufacturing Studies Board and Commission on Engineering and Technical Systems and National Research Council"
}
@article{Brun20116382,
title = "Mapping aerosol intrusion in Himalayan valleys using the Moderate Resolution Imaging Spectroradiometer (MODIS) and Cloud–Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) ",
journal = "Atmospheric Environment ",
volume = "45",
number = "35",
pages = "6382 - 6392",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.08.026",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011008466",
author = "Julien Brun and Prabhakar Shrestha and Ana P. Barros",
keywords = "Aerosol",
keywords = "Intrusion",
keywords = "River valley",
keywords = "High resolution",
keywords = "MODIS",
keywords = "CALIPSO",
keywords = "Nepal ",
abstract = "Mapping the spatial and temporal distribution of aerosols along mountain ranges is an important step toward elucidating orographic aerosol–cloud–rainfall interactions. This requires high spatial resolution aerosol observations over complex topography, which are not currently available either from ground-based observing systems or from remote-sensing products. Here, a novel approach is presented that relies on visible channels from \{MODIS\} Rapid Response data at 250 m spatial resolution to extract the daytime aerosol run-up (intrusion length and height) from the Indo-Gangetic Plains to the High Himalaya. Intrusion length and height are determined from the intersection of topography with the MODIS-derived aerosol plume using an adaptive object-classification algorithm. The methodology is demonstrated for a case study of the Arun River in eastern Nepal. Results of run-up extraction are examined along with the Total Attenuated Backscatter (Level 1B at 532 nm) from \{CALIPSO\} to investigate the regional variability of aerosol. During the pre-monsoon season, \{CALIPSO\} nighttime profiles show the presence of a slanted dust layer following the envelope topography. This is consistent with upper level transport of aerosol by north-westerly winds associated with high-frequency dust storms. In the winter, the signal is weaker, and the nighttime elevated aerosol layer is flat and remains below the envelope orography consistent with blocking conditions. For both seasons, the daytime aerosol layer detected from \{MODIS\} observations is always below the ridges. This suggests that in addition to seasonal variability governed by synoptic conditions, there is a distinct diurnal cycle in the North–South transport of aerosol between the Himalayas and the IGP. "
}
@article{Tong2013146,
title = "Evaluation of heterogeneous measurement outlier rejection schemes for robotic planetary surface mapping ",
journal = "Acta Astronautica ",
volume = "88",
number = "",
pages = "146 - 162",
year = "2013",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2012.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094576512003189",
author = "Chi Hay Tong and Timothy D. Barfoot",
keywords = "Surface mapping",
keywords = "Outlier rejection",
keywords = "SLAM",
keywords = "Mobile robotics ",
abstract = "In this paper, we describe the development and evaluation of a core algorithmic component for robust robotic planetary surface mapping. In particular, we consider the issue of outlier measurements when utilizing both odometry and sparse features for laser scan alignment. Due to the heterogeneity of the measurements and the relative scarcity of distinct geometric features in the planetary environment, we have found that the conventional outlier rejection methods in the current literature do not produce satisfactory classifications for accurate mapping performance. In light of these limitations, we develop a new approach capable of addressing these concerns. This includes a family of four outlier classification algorithms, which are incorporated through iterative reclassification into the batch alignment framework to provide robust surface mapping performance. Characterization of these outlier rejection schemes is presented using a combination of simulated data and real-world testing with an indoor rover. "
}
@article{Javidrad2011397,
title = "Contour curve reconstruction from cloud data for rapid prototyping ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "27",
number = "2",
pages = "397 - 404",
year = "2011",
note = "Translational Research – Where Engineering Meets Medicine ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584510001079",
author = "F. Javidrad and A.R. Pourmoayed",
keywords = "Reverse engineering",
keywords = "Contour curve",
keywords = "Rapid prototyping",
keywords = "Interval B-spline ",
abstract = "In this study, a method for generation of sectional contour curves directly from cloud point data is given. This method computes contour curves for rapid prototyping model generation via adaptive slicing, data points reducing and B-spline curve fitting. In this approach, first a cloud point data set is segmented along the component building direction to a number of layers. The points are projected to the mid-plane of the layer to form a 2-dimensional (2D) band of scattered points. These points are then utilized to construct a boundary curve. A number of points are picked up along the band and a B-spline curve is fitted. Then points are selected on the B-spline curve based on its discrete curvature. These are the points used as centers for generation of circles with a user-define radius to capture a piece of the scattered band. The geometric center of the points lying within these circles is treated as a control point for a B-spline curve fitting that represents a boundary contour curve. The advantage of this method is simplicity and insensitivity to common small inaccuracies. Two experimental results are included to demonstrate the effectiveness and applicability of the proposed method. "
}
@article{Li199899,
title = "Uncertainty reasoning based on cloud models in controllers ",
journal = "Computers & Mathematics with Applications ",
volume = "35",
number = "3",
pages = "99 - 123",
year = "1998",
note = "",
issn = "0898-1221",
doi = "https://doi.org/10.1016/S0898-1221(97)00282-4",
url = "http://www.sciencedirect.com/science/article/pii/S0898122197002824",
author = "D. Li and D. Cheung and Xuemei Shi and V. Ng",
keywords = "Uncertainty modeling",
keywords = "Linguistic atom",
keywords = "Compatibility cloud",
keywords = "Virtual cloud",
keywords = "Cloud generator ",
abstract = "The methodology of fuzzy reasoning has been shown to be very useful technology for modeling complex nonlinear systems. However, the most commonly used method for reasoning with fuzzy systems models, the Mamdani-Zadeh paradigm, faces many criticisms, particularly from the probability community. A new mathematical representation of linguistic concepts is presented in this paper. With the new model of normal compatibility clouds and a virtual rule engine, a novel uncertainty reasoning technology is proposed. It not only serves as a foundation of linguistic control, but also integrating fuzziness and randomness in an inseparable way. A case study is given to clean up many doubts raised in the debate between fuzzy theory and probability theory researchers, and to give a good interpretation of the Mamdani-Zadeh operations for the defuzzification strategy as well. The architecture of such a controller shows the advantages in hardware implementations. "
}
@article{Mollaret201678,
title = "A multi-modal perception based assistive robotic system for the elderly ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "78 - 97",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - "Assistive Solutions for Mobility, Communication and HMI" ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216000758",
author = "C. Mollaret and A.A. Mekonnen and F. Lerasle and I. Ferrané and J. Pinquier and B. Boudet and P. Rumeau",
keywords = "Assistive technology",
keywords = "Elderly care",
keywords = "Intention detection",
keywords = "Multi-modal data fusion",
keywords = "Human–robot interaction",
keywords = "Robotic perception ",
abstract = "Abstract In this paper, we present a multi-modal perception based framework to realize a non-intrusive domestic assistive robotic system. It is non-intrusive in that it only starts interaction with a user when it detects the user’s intention to do so. All the robot’s actions are based on multi-modal perceptions which include user detection based on RGB-D data, user’s intention-for-interaction detection with RGB-D and audio data, and communication via user distance mediated speech recognition. The utilization of multi-modal cues in different parts of the robotic activity paves the way to successful robotic runs (94% success rate). Each presented perceptual component is systematically evaluated using appropriate dataset and evaluation metrics. Finally the complete system is fully integrated on the \{PR2\} robotic platform and validated through system sanity check runs and user studies with the help of 17 volunteer elderly participants. "
}
@article{McKee2012455,
title = "Robotic Ecologies for Deep Space Outposts ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "455 - 460",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00183",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336527",
author = "Gerard McKee and Blesson Varghese",
keywords = "robotic ecologies",
keywords = "space robotics",
keywords = "human outposts",
keywords = "networked robotics",
keywords = "self-adaptation",
keywords = "ambient intelligence",
keywords = "multi-agent systems ",
abstract = "Abstract Robotics systems are a recognised part of the human exploration and colonisation of space. Advances in sensor and robotic networks, ambient intelligence and multi-agent systems offer approaches to modelling, implementing and operating robotic ecologies, comprising heterogeneous sets of mobile and embedded robotic devices and sensors, to support space applications, particularly in constructing and maintaining human habitats prior and subsequent to human arrival. This paper proposes a framework for integrating these technologies and techniques. The framework comprises application-level and infrastructure-level components, the former emphasising a model-driven approach supporting cognitive awareness and the latter an autonomic computing approach to self management. The paper provides a first draft of the framework, motivated by a deep space human outpost mission scenario. "
}
@article{Campos2016222,
title = "The Challenges of Cybersecurity Frameworks to Protect Data Required for the Development of Advanced Maintenance ",
journal = "Procedia \{CIRP\} ",
volume = "47",
number = "",
pages = "222 - 227",
year = "2016",
note = "Product-Service Systems across Life Cycle ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.03.059",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116300294",
author = "Jaime Campos and Pankaj Sharma and Erkki Jantunen and David Baglee and Luca Fumagalli",
keywords = "Big data",
keywords = "cloud computing",
keywords = "maintenance engineering",
keywords = "asset management ",
abstract = "Abstract The main objective of the paper is to highlight the important aspects of the data management in condition monitoring and maintenance, especially when the emergent technologies, such as the cloud computing and big data, are to be considered in the maintenance department. In addition, one of the main data management elements highlighted in the current work are the cybersecurity issues which might be one of the biggest obstacles hindering the development of cloud based big data for condition-based maintenance (CBM) purposes. Further, the benefits and current risks of storing a company's data in the cloud are highlighted. The authors discuss as well different data needs in various processes in the area of asset management. In addition, the challenges and issues to be addressed for the optimal use of the company data at the cloud together with the big data approach are addressed. This is seen as an important part in an effort to achieve sustainable information and communication technologies for the industry. "
}
@article{Maté201195,
title = "Book Review ",
journal = "Fuzzy Sets and Systems ",
volume = "177",
number = "1",
pages = "95 - 97",
year = "2011",
note = "Theme:Fuzzy Interval Analysis ",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2011.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S016501141100087X",
author = "Carlos G. Maté"
}
@article{Ratib2011161,
title = "From \{PACS\} to the clouds ",
journal = "European Journal of Radiology ",
volume = "78",
number = "2",
pages = "161 - 162",
year = "2011",
note = "From \{PACS\} to the clouds ",
issn = "0720-048X",
doi = "https://doi.org/10.1016/j.ejrad.2010.12.097",
url = "http://www.sciencedirect.com/science/article/pii/S0720048X11001331",
author = "Osman Ratib"
}
@article{Tang2010829,
title = "Automatic reconstruction of as-built building information models from laser-scanned point clouds: A review of related techniques ",
journal = "Automation in Construction ",
volume = "19",
number = "7",
pages = "829 - 843",
year = "2010",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2010.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580510000907",
author = "Pingbo Tang and Daniel Huber and Burcu Akinci and Robert Lipman and Alan Lytle",
keywords = "Building information models",
keywords = "Building reconstruction",
keywords = "Laser scanners",
keywords = "Object recognition",
keywords = "Geometric modeling",
keywords = "Relationship modeling",
keywords = "Shape representation ",
abstract = "Building information models (BIMs) are maturing as a new paradigm for storing and exchanging knowledge about a facility. \{BIMs\} constructed from a \{CAD\} model do not generally capture details of a facility as it was actually built. Laser scanners can be used to capture dense 3D measurements of a facility's as-built condition and the resulting point cloud can be manually processed to create an as-built \{BIM\} — a time-consuming, subjective, and error-prone process that could benefit significantly from automation. This article surveys techniques developed in civil engineering and computer science that can be utilized to automate the process of creating as-built BIMs. We sub-divide the overall process into three core operations: geometric modeling, object recognition, and object relationship modeling. We survey the state-of-the-art methods for each operation and discuss their potential application to automated as-built \{BIM\} creation. We also outline the main methods used by these algorithms for representing knowledge about shape, identity, and relationships. In addition, we formalize the possible variations of the overall as-built \{BIM\} creation problem and outline performance evaluation measures for comparing as-built \{BIM\} creation algorithms and tracking progress of the field. Finally, we identify and discuss technology gaps that need to be addressed in future research. "
}
@article{Mayachita2013380,
title = "Implementation of Entertaining Robot on \{ROS\} Framework ",
journal = "Procedia Technology ",
volume = "11",
number = "",
pages = "380 - 387",
year = "2013",
note = "4th International Conference on Electrical Engineering and Informatics, \{ICEEI\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.12.206",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313003605",
author = "Inneke Mayachita and Rizka Widyarini and Hadi Rasyid Sono and Adrianto Ravi Ibrahim and Widyawardana Adiprawita",
keywords = "ROS",
keywords = "cloud robotics",
keywords = "interactive",
keywords = "PeopleBot ",
abstract = "Abstract As technologies are continually growing, there should be an option to implement technologies such as robots as entertainer at the tourism places, replacing the old-fashioned clowns and mascots. However, robots with a lot of features need relatively complex data processing. By implementing cloud robotics, all process and data calculation will be done by computers which are separated from the body of the robot. To implement this new robotics system, we use PeopleBot as the main physical platform, three computers, and a tablet. Communication between devices occurs via network and be facilitated by Robot Operating System (ROS) framework. Robot has some features such as Layout, image capture and storage in cloud, navigation, crowd detection, and speech recognition "
}
@article{Sinha20097,
title = "Monitoring the Dispersion of a Contaminant Cloud in an Urban Region by a Swarm of \{UAV\} Sensors ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "22",
pages = "7 - 12",
year = "2009",
note = "1st \{IFAC\} Workshop on Networked Robotics ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20091006-3-US-4006.00002",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015340106",
author = "Arpita Sinha and Antonios Tsourdos and Brian White",
keywords = "Boundary tracking",
keywords = "UAVs path planning",
keywords = "auction mechanism",
keywords = "splinegon ",
abstract = "Abstract In this paper, we develop a mechanism to detect, model and track the shape of a contaminant cloud boundary using air borne sensor swarms. The cloud consists of a transparent gas of nuclear, biological or chemical contaminants and is spreading slowly in an urban environment. A group of UAVs, having the required sensors, are made to fly through the cloud to detect the boundary of the cloud. The shape of the cloud is modeled using splinegon. An observer is designed to track the movement of the cloud. The output of the observer is used in the path planning of the UAVs. The path planning is online, decentralized and considers obstacle avoidance and connectivity maintenance among the UAVs. Simulated experiments are carried out to test the proposed cloud tracking algorithm. "
}
@article{Katsaros2016480,
title = "Estimation and forecasting of ecological efficiency of virtual machines ",
journal = "Future Generation Computer Systems ",
volume = "55",
number = "",
pages = "480 - 494",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15000035",
author = "Gregory Katsaros and Pascal Stichler and Josep Subirats and Jordi Guitart",
keywords = "Ecological efficiency",
keywords = "Cloud computing",
keywords = "Virtual machine",
keywords = "Energy consumption",
keywords = "Monitoring ",
abstract = "Abstract The massive development of the cloud marketplace is leading to an increase in the number of the Data Centers (DCs) globally and eventually to an increase of the \{CO\} 2 related footprint. The calculation of the impact of Virtual Machines (VMs) on the environment is a challenging task, not only due to the technical difficulties but also due to the lack of information from the energy providers. The ecological efficiency of a system captures the relationship between the performance of the system with its environmental footprint. In this paper we present a methodology for the estimation and prediction of the ecological efficiency of \{VMs\} in private cloud infrastructures. We specifically focus on the information management starting from the energy resources in a region, the energy consumption and the performance of the resources and finally the calculation of ecological efficiency of a VM. To this end, we have designed and implemented a framework through which the ecological efficiency of a running \{VM\} can be assessed and the ecological efficiency of a \{VM\} to be deployed can be forecasted. The presented framework is being evaluated through several private cloud scenarios with \{VM\} deployments in hosts located in Germany. "
}
@article{GarcíaLuna2016365,
title = "Towards an artificial vision-robotic system for tomato identification ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "365 - 370",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.067",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316305",
author = "F. García-Luna and A. Morales-Díaz",
keywords = "Artificial vision",
keywords = "fruit detection",
keywords = "fruit localization",
keywords = "robotic system ",
abstract = "Abstract: In the present paper we developed a simple and affordable vision-based robotic system for the identification of the Euclidean position of red spheres that emulate ripe tomatoes. This is done by using a RGB-D sensor in a fixed position, together with a 5 \{DOF\} manipulator. To detect the tomato the sensor considers it as a red blob and then it calculates its center using a point cloud map. The position of the red blob is mapped to the manipulator reference frame using the homogeneous transformation matrix from the camera to the manipulator. The position of the sphere is sent through a micro-controller to drive the manipulator, with the purpose of reaching the sphere’s position. Experimental results of the vision-based robotic system are provided, and the system accuracy obtained in localizing and touching the interest object demonstrate to be highly effective, reaching an accuracy of 10/10 in identification and touching the object in ideal environment. "
}
@article{Tiedemann2016570,
title = "An Automotive Distributed Mobile Sensor Data Collection with Machine Learning Based Data Fusion and Analysis on a Central Backend System ",
journal = "Procedia Technology ",
volume = "26",
number = "",
pages = "570 - 579",
year = "2016",
note = "3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2016.08.071",
url = "http://www.sciencedirect.com/science/article/pii/S2212017316304182",
author = "Tim Tiedemann and Christian Backe and Thomas Vögele and Peter Conradi",
keywords = "Sensor Cloud",
keywords = "Pervasive Computing",
keywords = "Distributed ML",
keywords = "IoT",
keywords = "Big Data ",
abstract = "Abstract One of the most extensive examples for ubiquitous computing today is automotion. The equipment of sensors and independent computing devices in current vehicles is vast if not endless. Furthermore, traffic infrastructure is realized using global and local computing devices. Communication initiated by the car itself (e.g., to an emergency hotline) will be obligatory in some countries soon. And finally, by using a smart phone the driver brings an additional powerful computing device and sensor set to the vehicle. However, all these automotive sensors and computing devices are used just for fixed (and in most cases single) purposes. Data exchange between vehicles or vehicles and infrastructure is rarely done. And dynamic changes like compensating for a broken sensor with available other data, using old sensor equipment for new functions, or improving old driver assistance systems with new sensors is not possible, either. The objective of the collaborative research project Smart Adaptive Data Aggregation (SADA) is to develop technologies that enable linking data from distributed mobile on-board sensors (on vehicles) with data from previously unknown stationary (e.g., infrastructure) or mobile sensors (e.g., other vehicles, smart devices). One focus of the project is the dynamic and fully-automated switching between different sensors or sensor configurations, including the adaptation of data fusion processes. Technically, one important component for some of the \{SADA\} use cases is a central backend system that (1) collects sensor data of the vehicles and/or the infrastructure, (2) fuses these data, and (3) carries out machine learning (ML) based analysis of the data to generate new information for the drivers (sometimes refered to by the term “virtual sensors”). The article gives a short overview of the \{SADA\} project and describes in more detail the concept of the backend system architec- ture, the user interface, and the methods and processes needed for a demonstration use-case. "
}
@article{Arrouk2016302,
title = "CAD-based unified graphical methodology for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "37",
number = "",
pages = "302 - 321",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515000447",
author = "Khaled Assad Arrouk and Belhassen Chedli Bouzgarrou and Grigore Gogu",
keywords = "Planar parallel robotic manipulator (PPRM)",
keywords = "Computer-Aided Design techniques",
keywords = "3D total workspace",
keywords = "Forward kinematic problem (FKP)",
keywords = "Singularity-free trajectory planning ",
abstract = "Abstract \{CAD\} environments provide powerful tools for graphical programming and geometric feature handling. This paper explores this potential for robotics applications by presenting a set of several original approaches for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators (PPRMs). These approaches rely on the use of CAD-based graphical programming enabling rapid resolution and geometric interpretation of the 3D total workspace characteristics. The novelty of the proposed approach resides in the association of an original, unique and natural 3D graphical representation of the end-effector poses and the use of geometric feature handling and graphical solver capabilities within a \{CAD\} environment, for determining the 3D total operational workspace as well as solving the forward kinematic problem (FKP) of PPRMs. The approach consists in considering the mobile platform separately attached to each limb that we disconnect from the rest of the mechanism. The geometric construction of the spaces reachable by the end-effector is performed by using Boolean intersections of the vertex volumes, respectively the vertex surfaces, relative to each limb for 3D total workspace determination, respectively for \{FKP\} resolution. By combining in the same 3D graphical environment several geometric entities associated to the PPRM, such as workspace volume, singularity surface, and the different solutions of the FKP, this approach allows designers, in a user-friendly way, to generate the singularity-free trajectories connecting different assembly modes. The approach presented in this paper is mostly useful for the architectures of 3-DOF parallel robotic manipulators for which an algebraic closed form solution does not exist for the forward kinematic model and the singularity-free trajectory planning between assembly modes is not a trivial task. It is applied for several \{PPRMs\} such as: 3-RPR, 3-RRR, 3-PPR, 3-RRP, 3-PRP, 3-PRR, 3-RRR, and 3-RPR. "
}
@article{Ingrand201710,
title = "Deliberation for autonomous robots: A survey ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "10 - 44",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2014.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0004370214001350",
author = "Félix Ingrand and Malik Ghallab",
keywords = "Robotics",
keywords = "Deliberation",
keywords = "Planning",
keywords = "Acting",
keywords = "Monitoring",
keywords = "Observing",
keywords = "Learning ",
abstract = "Abstract Autonomous robots facing a diversity of open environments and performing a variety of tasks and interactions need explicit deliberation in order to fulfill their missions. Deliberation is meant to endow a robotic system with extended, more adaptable and robust functionalities, as well as reduce its deployment cost. The ambition of this survey is to present a global overview of deliberation functions in robotics and to discuss the state of the art in this area. The following five deliberation functions are identified and analyzed: planning, acting, monitoring, observing, and learning. The paper introduces a global perspective on these deliberation functions and discusses their main characteristics, design choices and constraints. The reviewed contributions are discussed with respect to this perspective. The survey focuses as much as possible on papers with a clear robotics content and with a concern on integrating several deliberation functions. "
}
@article{Berruti2013460,
title = "Performance evaluation of measurement data acquisition mechanisms in a distributed computing environment integrating remote laboratory instrumentation ",
journal = "Future Generation Computer Systems ",
volume = "29",
number = "2",
pages = "460 - 471",
year = "2013",
note = "Special section: Recent advances in e-Science ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2012.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X12001550",
author = "Luca Berruti and Franco Davoli and Sandro Zappatore",
keywords = "Grid-based architecture",
keywords = "Tele-Laboratory platform",
keywords = "Performance evaluation ",
abstract = "The usage of laboratory and measurement instrumentation of any kind, from large complex equipment to networks of sensors that collectively appear as a distributed measurement device, has become of relevant importance in all branches of experimental sciences. Owing to the increasing networking capacity and access ubiquity, this bulk of instrumentation is ever more frequently accessed remotely by users who want to perform experiments, collect and process experimental data, analyze and interpret results. With reference to a remote instrumentation architecture deeply rooted in distributed computing paradigms such as grids and clouds, we evaluate the performance of mechanisms for the collection of data generated by instruments, in order to assess the capabilities of remote instrumentation services. In the presence of instruments generating measurements at high rate, which must be delivered to a multiplicity of users, publish/subscribe dispatching (push) mechanisms are shown to outperform pull-based ones. "
}
@article{Hély201773,
title = "Feasibility study of robotic fibre placement on intersecting multi-axial revolution surfaces ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "73 - 79",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301661",
author = "Clément Hély and Lionel Birglen and Wen-Fang Xie",
keywords = "Automated fibre placement",
keywords = "Path planning",
keywords = "Multi-axial closed surfaces ",
abstract = "Abstract In this paper, the first steps towards using a robotic workcell for the automated fibre placement (AFP) manufacturing of Y-shaped tubes are proposed. The proposed workcell is constituted of a standard serial manipulator holding the fibre placement toolhead combined to a rotary table on which the part where the fibres must be laid out is attached. The investigations carried out in this work explore the feasibility of this setup and more precisely the path planning aspect. To this aim two novel path planning algorithms are presented generalizing the techniques proposed in the literature for open-contoured and cylindrical surfaces. In the first, the maximal geodesic curvature typically allowed in \{AFP\} is disregarded to generate continuous paths with a constant placement angle on the branches without any gaps or overlaps. Subsequently, a second algorithm, taking into account this curvature constraint, is presented. These algorithms were implemented in a software using the MATLAB™ suite. Finally, an algorithm to optimize the motion of the robotic system is presented and simulations are discussed. "
}
@article{HidalgoPeña2013370,
title = "Web-based and Interactive Learning - Recognition Method for a Humanoid Robot ",
journal = "Procedia Technology ",
volume = "7",
number = "",
pages = "370 - 376",
year = "2013",
note = "3rd Iberoamerican Conference on Electronics Engineering and Computer Science, \{CIIECC\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.04.046",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313000479",
author = "Enrique Hidalgo-Peña and Luis F. Marin-Urias and Fernando Montes-Gonzalez and Antonio Marin-Hernandez and Homero Rios-Figueroa",
keywords = "One-class Classification",
keywords = "PCA",
keywords = "Object Recognition",
keywords = "Cloud Robotics",
keywords = "Service Robots ",
abstract = "In this paper an Object Learning and Recognition method for a Humanoid is presented. This method tries to take advantage of the Cloud Resources, since it is based on image web search in order to build training sets for learn about objects appearance. In case of unavailability of Internet access, the robot would ask human to show the object and take the images from its camera. This way, our method aims to be a flexible and natural Human-Robot Interaction framework and to give as much autonomy as possible to the robot. "
}
@incollection{Kaklauskas2016413,
title = "17 - Intelligent decision-support systems and the Internet of Things for the smart built environment ",
editor = "Pacheco-Torgal, Fernando and , and Rasmussen, Erik and , and Granqvist, Claes-Göran and , and Ivanov, Volodymyr and , and Kaklauskas, Arturas and ,  and Makonin, Stephen ",
booktitle = "Start-Up Creation ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2016",
pages = "413 - 449",
isbn = "978-0-08-100546-0",
doi = "https://doi.org/10.1016/B978-0-08-100546-0.00017-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780081005460000170",
author = "A. Kaklauskas and R. Gudauskas",
keywords = "Built environment",
keywords = "Cloud computing",
keywords = "Machine-to-machine",
keywords = "Internet of Things ",
abstract = "Abstract Potential applications of the Internet of Things (IoT) for the built environment are many and various, fitting into almost all activities done by persons, organizations, and the community as a whole. The active use of electronics, software, sensors, and network connectivity has taken off in the built environment, and these physical devices operating in the built environment can send and receive data via the existing Internet infrastructure. This chapter outlines the general theory (the definition, characteristics, components, etc.) and analyses several specific examples and applications of the IoT in the built environment. It proceeds with an analysis of possibilities to integrate intelligent decision support systems with IoT in the built environment. Such instances are not numerous in the world. The chapter also discusses the main trends and the future of IoT in the built environment. It then ends with the IoT start-ups. "
}
@article{Viejo20123158,
title = "A study of a soft computing based method for 3D scenario reconstruction ",
journal = "Applied Soft Computing ",
volume = "12",
number = "10",
pages = "3158 - 3164",
year = "2012",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2012.05.025",
url = "http://www.sciencedirect.com/science/article/pii/S1568494612002803",
author = "Diego Viejo and Jose Garcia-Rodriguez and Miguel Cazorla",
keywords = "Egomotion",
keywords = "GNG",
keywords = "Registration",
keywords = "3D feature extraction ",
abstract = "Several recent works deal with 3D data in mobile robotic problems, e.g., mapping. Data comes from any kind of sensor (time of flight, Kinect or 3D lasers) that provide a huge amount of unorganized 3D data. In this paper we detail an efficient approach to build complete 3D models using a soft computing method, the Growing Neural Gas (GNG). As neural models deal easily with noise, imprecision, uncertainty or partial data, \{GNG\} provides better results than other approaches. The \{GNG\} obtained is then applied to a sequence. We present a comprehensive study on \{GNG\} parameters to ensure the best result at the lowest time cost. From this \{GNG\} structure, we propose to calculate planar patches and thus obtaining a fast method to compute the movement performed by a mobile robot by means of a 3D models registration algorithm. Final results of 3D mapping are also shown. "
}
@article{Santoli1999117,
title = "Hyper-interspersed nano/MEMS-architecture design for new concepts in miniature robotics for space exploration ",
journal = "Acta Astronautica ",
volume = "44",
number = "2–4",
pages = "117 - 122",
year = "1999",
note = "Missions to the Outer Solar System and Beyond ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(99)00037-5",
url = "http://www.sciencedirect.com/science/article/pii/S0094576599000375",
author = "Salvatore Santoli",
abstract = "Launch weight and volume requirements are substantially decreased by reduction of probe size in exploration mission systems, as mass and volume both scale as the third power of system size. Accordingly, the already quite developed \{MEMS\} (Micro Electro Mechanical System) technology, that offers low cost, small, light weight, and increasingly reliable devices through durability and redundancy, is strongly attractive as a near-term technology for significantly reducing the cost to launch and operate space systems. It is shown that the final goal of \{MEMS\} technology, i.e. the merging through solid state microdcvices of the functions of sensing, computation, communication and actuation, can lead to a new, biomimetic kind of miniature robotics, particularly suitable for planetary exploration, through molecular mono- electronics/MEMS integration jointly with a hyper-interspersed architecture made up of autonomous units embodying sensors, information processors and actuators. The problem tackled here concerns the basic design of such miniature robots, from some μm to insect size, featuring finely structured intelligent autonomous parts as smart skins, sensory and manipulating members working on the analogue external reality and communicating with their inner molecular level nondiscrete pseudo-analogue information processing networks. The (mesoscopic network)/MEMS units are shown to embody a quantum mechanical/macroscopic world connection, in which the nondiscrete molecular devices allow the automaton parts to perform very complex, fast information processing operations as metaphores of bionic functions like learning, attention, and decision making under uncertain conditions, this last due to the stochasticity inherent in the quantum network. Flexible architectures instead of von Neumann type rigid architectures in addition to hyper-interspersion of autonomous units can be realized through such nano/MEMS devices, and the μm — cm size of the whole robots and their organs allow dynamic biochemical, possibly reaction - diffusion, spatially separated highly nonlinear systems to be exploited as additional primitive computing devices (e.g. chemical oscillators, dissipative biomolecular distributed systems, planar photoactivated enzyme biosensors). Each interspersed unit can be designed as a multilevel nondiscrete system according to the information processing “rank” to be obtained in simulating the biological nervous system activity. "
}
@article{Liu2008576,
title = "Automatic segmentation of unorganized noisy point clouds based on the Gaussian map ",
journal = "Computer-Aided Design ",
volume = "40",
number = "5",
pages = "576 - 594",
year = "2008",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2008.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448508000419",
author = "Yu Liu and Youlun Xiong",
keywords = "Segmentation",
keywords = "Clustering",
keywords = "Gaussian map",
keywords = "Mean shift",
keywords = "Dimensional analysis ",
abstract = "A nonparametric clustering algorithm, called cell mean shift (CMS), is developed to extract clusters of a set of points on the Gaussian sphere S 2 . It is computationally more efficient than the traditional mean shift (MS). Based on the singular value decomposition, the dimensional analysis is introduced to classify these clusters into point-, curve-, and area-form clusters. Each cluster is the Gaussian image of a set of points which will be examined by a connected search in R 3 . An orientation analysis of the Gaussian map to area-form clusters is applied to identify hyperbolic and elliptical regions. A signed point-to-plane distance function is used to identify points of convex and concave regions. Segmentation results of several real as well as synthetic point clouds, together with complexity analyses, are presented. "
}
@article{Pajarinen2017213,
title = "Robotic manipulation of multiple objects as a \{POMDP\} ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "213 - 228",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215000570",
author = "Joni Pajarinen and Ville Kyrki",
keywords = "POMDP",
keywords = "Planning under uncertainty",
keywords = "Task planning",
keywords = "Manipulation",
keywords = "Unknown objects",
keywords = "Multiple objects",
keywords = "Cluttered environment ",
abstract = "Abstract This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our \{POMDP\} model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online \{POMDP\} method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step \{POMDP\} planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience. "
}
@article{Oksa2015134,
title = "OpenCRP Ecosystem Demonstration Platform ",
journal = "Procedia Computer Science ",
volume = "76",
number = "",
pages = "134 - 138",
year = "2015",
note = "2015 \{IEEE\} International Symposium on Robotics and Intelligent Sensors (IEEE IRIS2015) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.12.323",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915038247",
author = "Petri Oksa and Pekka Loula and Teemu Alapaholuoma",
keywords = "Open-source softwares",
keywords = "mobile robot",
keywords = "cloud computing",
keywords = "ecosystem",
keywords = "PaaS ",
abstract = "Abstract Mobile robots with service-oriented functions are stepping to our lives in hospitals, hospices and industries where robots can help to assist or perform all the arduous working duties. A lot of laborious processes are found that can be automatized, e.g. in hospital medicine delivery and food servery to ward for patients. This paper presents a pilot- and demonstration environment for multiple open-source mobile robots sharing their collected data with each other via a private cloud. The presented platform, OpenCRP, introduces a novel ecosystem based on an open-source software frameworks and robots. "
}
@article{Wang20152603,
title = "Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring ",
journal = "Procedia Computer Science ",
volume = "51",
number = "",
pages = "2603 - 2612",
year = "2015",
note = "International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.05.368",
url = "http://www.sciencedirect.com/science/article/pii/S187705091501176X",
author = "Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson",
keywords = "Bayesian Computational Sensor Networks",
keywords = "Uncertainty",
keywords = "Structural Health Monitoring",
keywords = "Cloud Computing ",
abstract = "Abstract The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments. "
}
@incollection{Baumes2013315,
title = "Chapter 13 - High-Performance Computing for Accelerated Zeolitic Materials Modeling ",
editor = "Rajan, Krishna ",
booktitle = "Informatics for Materials Science and Engineering ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "Oxford",
year = "2013",
pages = "315 - 347",
isbn = "978-0-12-394399-6",
doi = "https://doi.org/10.1016/B978-0-12-394399-6.00013-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780123943996000138",
author = "Laurent A. Baumes and Frederic Kruger and Pierre Collet",
keywords = "Zeolite",
keywords = "Microporous",
keywords = "Modeling",
keywords = "Structure",
keywords = "Performance",
keywords = "Parallelism ",
abstract = "Very recently, the design and understanding of materials synthesis have received considerable attention where modeling approaches are decisive. Here, we focus on the generation of crystalline inorganic frameworks. Despite high-throughput (HT) methods having proved to be useful for the discovery of zeolites, the determination of the new phases’ structure takes up a large part of the entire process. Therefore, we show how graphic processing units (GPUs) can be used in order to speed up this mandatory step. We describe \{GPUs\} and predictive methods for phase determination. Then, we show all the details that allow us to reach a stable and robust solution with benchmark analysis and real applications for zeolites. "
}
@incollection{Gobbi200777,
title = "11 The EV-K2-CNR Pyramid and the \{AERONET\} network (Himalayan atmospheric brown cloud characterization via sunphotometer observations) ",
editor = "Renato Baudo, Gianni Tartari and Elisa Vuillermoz",
booktitle = "Mountains Witnesses of Global Changes Research in the Himalaya and Karakoram: Share-Asia Project",
publisher = "Elsevier",
year = "2007",
volume = "10",
pages = "77 - 82",
series = "Developments in Earth Surface Processes ",
issn = "0928-2025",
doi = "https://doi.org/10.1016/S0928-2025(06)10011-5",
url = "http://www.sciencedirect.com/science/article/pii/S0928202506100115",
author = "Gian Paolo Gobbi and Federico Angelini and Francesca Barnaba and Paolo Bonasoni",
abstract = "A Cimel sunphotometer operating in the framework of the \{AERONET\} project has been installed at the Himalayan Ev-K2-CNR Pyramid (5079 m a.s.l.) in the year 2006, as site Ev-K2-CNR. The observational activity will provide a characterization of the optical and microphysical properties of atmospheric aerosols, in particular of the atmospheric brown cloud (ABC) in the Himalayan region. This paper will describe the Cimel sunphotometer measurement technique, will introduce to the \{AERONET\} programme and will evaluate the contribution of the proposed Ev-K2-CNR \{AERONET\} site to the study of the ABC. "
}
@article{Watanabe20151664,
title = "A Framework to Evaluate the Performance of Disperse Productive System through Sustainability Performance Indicators ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "1664 - 1669",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.325",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315005649",
author = "Edson H. Watanabe and Mauricio F. Blos and Robson M. da Silva and Fabrício Junqueira and Diolino J. Santos Filho and Paulo E. Miyagi",
keywords = "sustainability",
keywords = "performance evaluation",
keywords = "Petri net",
keywords = "framework",
keywords = "disperse productive systems",
keywords = "cloud computing ",
abstract = "Abstract Productive systems (PS) should currently consider the efficient use of resources (such as technological transformation, handling and material transport) besides the dispersed distribution of productive plants and sustainability concepts to allow the adequate use of environmental resources and reduce costs through local facilities. However, in the literature there are not widely accepted criteria to evaluate this class of Sustainable and Dispersed Productive Systems (SDPS). Therefore, this work introduces a framework for \{SDPS\} performance evaluation by extending the system requirements in the ANSI/ISA-95 standard specifications. Petri net (PN) technique and its extension, Production Flow Schema (PFS), are used to systematize the collection of production data and indexes to evaluating the \{SDPS\} performance. Cloud computing technology is also considered to provide resources to access information from SDPS. The presented method allows obtaining and choosing the better indicator for sustainable SDPS. "
}
@article{Mojtahedzadeh201599,
title = "Support relation analysis and decision making for safe robotic manipulation tasks ",
journal = "Robotics and Autonomous Systems ",
volume = "71",
number = "",
pages = "99 - 117",
year = "2015",
note = "Emerging Spatial Competences: From Machine Perception to Sensorimotor Intelligence ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014003145",
author = "Rasoul Mojtahedzadeh and Abdelbaki Bouguerra and Erik Schaffernicht and Achim J. Lilienthal",
keywords = "Scene analysis",
keywords = "Machine learning",
keywords = "Decision making",
keywords = "World models",
keywords = "Robotic manipulation ",
abstract = "Abstract In this article, we describe an approach to address the issue of automatically building and using high-level symbolic representations that capture physical interactions between objects in static configurations. Our work targets robotic manipulation systems where objects need to be safely removed from piles that come in random configurations. We assume that a 3D visual perception module exists so that objects in the piles can be completely or partially detected. Depending on the outcome of the perception, we divide the issue into two sub-issues: (1) all objects in the configuration are detected; (2) only a subset of objects are correctly detected. For the first case, we use notions from geometry and static equilibrium in classical mechanics to automatically analyze and extract act and support relations between pairs of objects. For the second case, we use machine learning techniques to estimate the probability of objects supporting each other. Having the support relations extracted, a decision making process is used to identify which object to remove from the configuration so that an expected minimum cost is optimized. The proposed methods have been extensively tested and validated on data sets generated in simulation and from real world configurations for the scenario of unloading goods from shipping containers. "
}
@article{Badr20152623,
title = "Resilient and Trustworthy Dynamic Data-driven Application Systems (DDDAS) Services for Crisis Management Environments ",
journal = "Procedia Computer Science ",
volume = "51",
number = "",
pages = "2623 - 2637",
year = "2015",
note = "International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.05.370",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915011783",
author = "Youakim Badr and Salim Hariri and Youssif AL-Nashif and Erik Blasch",
keywords = "rDaaS",
keywords = "resilience",
keywords = "cloud computing",
keywords = "service-oriented computing",
keywords = "trust and security ",
abstract = "Abstract Future crisis management systems needresilient and trustworthy infrastructures to quickly develop reliable applications and processes, andensure end-to-end security, trust, and privacy. Due to the multiplicity and diversity of involved actors, volumes of data, and heterogeneity of shared information;crisis management systems tend to be highly vulnerable and subjectto unforeseen incidents. As a result, the dependability of crisis management systems can be at risk. This paper presents a cloud-based resilient and trustworthy infrastructure (known as rDaaS) to quickly develop securecrisis management systems. The rDaaSintegrates the Dynamic Data-DrivenApplication Systems (DDDAS) paradigm into a service-oriented architectureover cloud technology andprovidesa set of resilient DDDAS-As-A Service (rDaaS)components to build secure and trusted adaptable crisis processes. The rDaaSalso ensures resilience and security by obfuscating the execution environment andapplying Behavior Software Encryption and Moving Technique Defense. A simulation environment for a nuclear plant crisis managementcase study is illustrated to build resilient and trusted crisis response processes. "
}
@article{Hanheide2017119,
title = "Robot task planning and explanation in open and uncertain worlds ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "119 - 150",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S000437021500123X",
author = "Marc Hanheide and Moritz Göbelbecker and Graham S. Horn and Andrzej Pronobis and Kristoffer Sjöö and Alper Aydemir and Patric Jensfelt and Charles Gretton and Richard Dearden and Miroslav Janicek and Hendrik Zender and Geert-Jan Kruijff and Nick Hawes and Jeremy L. Wyatt",
keywords = "Open-world planning",
keywords = "Planning under uncertainty",
keywords = "Commonsense knowledge",
keywords = "Mobile robotics",
keywords = "Probabilistic reasoning",
keywords = "Failure explanation",
keywords = "Assumptive planning",
keywords = "Retaskability ",
abstract = "Abstract A long-standing goal of \{AI\} is to enable robots to plan in the face of uncertain and incomplete information, and to handle task failure intelligently. This paper shows how to achieve this. There are two central ideas. The first idea is to organize the robot's knowledge into three layers: instance knowledge at the bottom, commonsense knowledge above that, and diagnostic knowledge on top. Knowledge in a layer above can be used to modify knowledge in the layer(s) below. The second idea is that the robot should represent not just how its actions change the world, but also what it knows or believes. There are two types of knowledge effects the robot's actions can have: epistemic effects (I believe X because I saw it) and assumptions (I'll assume X to be true). By combining the knowledge layers with the models of knowledge effects, we can simultaneously solve several problems in robotics: (i) task planning and execution under uncertainty; (ii) task planning and execution in open worlds; (iii) explaining task failure; (iv) verifying those explanations. The paper describes how the ideas are implemented in a three-layer architecture on a mobile robot platform. The robot implementation was evaluated in five different experiments on object search, mapping, and room categorization. "
}
@article{Musuvathy20111485,
title = "Computing medial axes of generic 3D regions bounded by B-spline surfaces ",
journal = "Computer-Aided Design ",
volume = "43",
number = "11",
pages = "1485 - 1495",
year = "2011",
note = "Solid and Physical Modeling 2011 ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2011.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S0010448511002223",
author = "Suraj Musuvathy and Elaine Cohen and James Damon",
keywords = "Medial axis",
keywords = "B-spline surfaces ",
abstract = "A new approach is presented for computing the interior medial axes of generic regions in R 3 bounded by C ( 4 ) -smooth parametric B-spline surfaces. The generic structure of the 3D medial axis is a set of smooth surfaces along with a singular set consisting of edge curves, branch curves, fin points and six junction points. In this work, the medial axis singular set is first computed directly from the B-spline representation using a collection of robust higher order techniques. Medial axis surfaces are computed as a time trace of the evolving self-intersection set of the boundary under the the eikonal (grassfire) flow, where the bounding surfaces are dynamically offset along the inward normal direction. The eikonal flow results in special transition points that create, modify or annihilate evolving curve fronts of the (self-) intersection set. The transition points are explicitly identified using the B-spline representation. Evolution of the (self-) intersection set is computed by adapting a method for tracking intersection curves of two different surfaces deforming over generalized offset vector fields. The proposed algorithm accurately computes connected surfaces of the medial axis as well its singular set. This presents a complete solution along with accurate topological structure. "
}
@article{Diner2005495,
title = "The value of multiangle measurements for retrieving structurally and radiatively consistent properties of clouds, aerosols, and surfaces ",
journal = "Remote Sensing of Environment ",
volume = "97",
number = "4",
pages = "495 - 518",
year = "2005",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2005.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0034425705001951",
author = "David J. Diner and Bobby H. Braswell and Roger Davies and Nadine Gobron and Jiannan Hu and Yufang Jin and Ralph A. Kahn and Yuri Knyazikhin and Norman Loeb and Jan-Peter Muller and Anne W. Nolin and Bernard Pinty and Crystal B. Schaaf and Gabriela Seiz and Julienne Stroeve",
keywords = "Multiangle remote sensing",
keywords = "Terra",
keywords = "MISR",
keywords = "CERES",
keywords = "ASTER",
keywords = "MODIS ",
abstract = "Passive optical multiangle observations make possible the retrieval of scene structural characteristics that cannot be obtained with, or require fewer underlying assumptions than, single-angle sensors. Retrievable quantities include aerosol amount over a wide variety of surfaces (including bright targets); aerosol microphysical properties such as particle shape; geometrically-derived cloud-top heights and 3-D cloud morphologies; distinctions between polar clouds and ice; and textural measures of sea ice, ice sheets, and vegetation. At the same time, multiangle data are necessary for accurate retrievals of radiative quantities such as surface and top-of-atmosphere albedos, whose magnitudes are governed by structural characteristics of the reflecting media and which involve angular integration over intrinsically anisotropic intensity fields. Measurements of directional radiation streams also provide independent checks on model assumptions conventionally used in satellite retrievals, such as the application of 1-D radiative transfer theory, and provide data required to constrain more sophisticated, 3-D approaches. In this paper, the value of multiangle remote sensing in establishing physical correspondence and self-consistency between scene structural and radiative characteristics is demonstrated using simultaneous observations from instruments aboard NASA's Terra satellite (MISR, CERES, ASTER, and MODIS). Illustrations pertaining to the remote sensing of clouds, aerosols, ice, and vegetation properties are presented. "
}
@article{Azariadis2004607,
title = "Parameterization of clouds of unorganized points using dynamic base surfaces ",
journal = "Computer-Aided Design ",
volume = "36",
number = "7",
pages = "607 - 623",
year = "2004",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(03)00138-6",
url = "http://www.sciencedirect.com/science/article/pii/S0010448503001386",
author = "Phillip N. Azariadis",
keywords = "Parameterization",
keywords = "Reverse engineering",
keywords = "Surface fitting",
keywords = "Base surfaces ",
abstract = "In this paper a new method for parameterizing clouds of unorganized points is presented. The proposed method introduces the notion of dynamic base surfaces (DBS) which are dynamically adapted to the three-dimensional shape implied by the clouds of points. The only assumption regarding the cloud of points is the existence of a boundary defined by a closed path of four curves. The proposed method is based on an iterative procedure where a \{DBS\} is gradually improved approximating more faithfully the fundamental geometry of the cloud of points. Parameterization is achieved by orthogonally projecting the cloud of points onto the DBS. An application of the introduced parameterization method to the well-known surface least-squares fitting is presented which illustrates the effectiveness and the efficiency of the proposed approach. "
}
@article{Azariadis2005109,
title = "Drawing curves onto a cloud of points for point-based modelling ",
journal = "Computer-Aided Design ",
volume = "37",
number = "1",
pages = "109 - 122",
year = "2005",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2004.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0010448504000892",
author = "Phillip N. Azariadis and Nickolas S. Sapidis",
keywords = "Digital curves",
keywords = "Digital surfaces",
keywords = "Point-based representation",
keywords = "Point projection algorithm",
keywords = "Polylines",
keywords = "Smoothing polylines ",
abstract = "Point-based geometric models are gaining popularity in both the computer graphics and \{CAD\} fields. A related design/modelling problem is the focus of the reported research: drawing curves onto digital surfaces represented by clouds of points. The problem is analyzed and solved, and a set of ‘design tools’ are proposed which allow the user/designer to efficiently perform ‘product development’ (alternative name: ‘detail design’) tasks which require efficient processing of a ‘digital surface’. The primary tool is a robust and efficient point projection algorithm combined with a smoothing technique for producing smooth ‘digital curves’ lying onto the cloud surface. The new design tools are tested on a real-life industrial example with very satisfactory results, which are thoroughly presented in the paper. "
}
@article{Sengupta20131206,
title = "Intelligent Platforms for Disease Assessment: Novel Approaches in Functional Echocardiography ",
journal = "JACC: Cardiovascular Imaging ",
volume = "6",
number = "11",
pages = "1206 - 1211",
year = "2013",
note = "",
issn = "1936-878X",
doi = "https://doi.org/10.1016/j.jcmg.2013.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S1936878X13006529",
author = "Partho P. Sengupta",
keywords = "big data",
keywords = "cognitive computing",
keywords = "echocardiography",
keywords = "parametric imaging",
keywords = "robotics ",
abstract = "Accelerating trends in the dynamic digital era (from 2004 onward) has resulted in the emergence of novel parametric imaging tools that allow easy and accurate extraction of quantitative information from cardiac images. This review principally attempts to heighten the awareness of newer emerging paradigms that may advance acquisition, visualization and interpretation of the large functional data sets obtained during cardiac ultrasound imaging. Incorporation of innovative cognitive software that allow advanced pattern recognition and disease forecasting will likely transform the human-machine interface and interpretation process to achieve a more efficient and effective work environment. Novel technologies for automation and big data analytics that are already active in other fields need to be rapidly adapted to the health care environment with new academic-industry collaborations to enrich and accelerate the delivery of newer decision making tools for enhancing patient care. "
}
@article{Chen2013159,
title = "Internet of intelligent things and robot as a service ",
journal = "Simulation Modelling Practice and Theory ",
volume = "34",
number = "",
pages = "159 - 171",
year = "2013",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2012.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X12000469",
author = "Yinong Chen and Hualiang Hu",
keywords = "Internet of Things",
keywords = "Robot as a Service",
keywords = "Decentralized autonomous system",
keywords = "Distributed intelligence",
keywords = "Context-aware computing",
keywords = "Cloud computing ",
abstract = "The development of computing and communication systems has gone through a spiral cycle of centralization and decentralization paradigms. The earliest computer systems are centralized mainframe computers. The paradigm moved to decentralized as networked stations became more dependable, extensible and cost-effective. The decentralized systems have their limitations and inconveniences. The virtualization and cloud computing paradigm creates a centralized system that appears to users to be a centralized system, where computing and communication resources are not in the client computers but in an integrated infrastructure that is accessible anywhere and anytime. Nevertheless, the implementation of the centralized infrastructure is equipped with decentralized and redundant resources, which makes the system more dependable as any component failures can be tolerated internally. The Internet of Things extends the cloud computing concept beyond computing and communication to include everything, particularly, the physical devices. This paper discusses the architectures, interfaces, and behaviors of intelligent devices connected to the cloud computing environment. Robot as a Service is the case study, which has all the key features of Internet of Intelligent Things: autonomous, mobile, sensing, and action taking. The goal is to further extend the centralized cloud computing environment into a decentralized system to complete another cycle of the spiral development. The idea of achieving the goal is through autonomous and intelligent mobile physical services or robots as services to form local pool of intelligent devices and that can make local decisions without communicate with the cloud. "
}
@article{Tenorth2017151,
title = "Representations for robot knowledge in the KnowRob framework ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "151 - 169",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215000843",
author = "Moritz Tenorth and Michael Beetz",
keywords = "Knowledge representation",
keywords = "Autonomous robots",
keywords = "Knowledge-enabled robotics ",
abstract = "Abstract In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in \{AI\} research, and propose to re-consider a \{KR\} system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation. The KnowRob system has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot's performance. "
}
@article{Schneider2014636,
title = "Integrated approach to robotic machining with macro/micro-actuation ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "30",
number = "6",
pages = "636 - 647",
year = "2014",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000271",
author = "Ulrich Schneider and Bjo¨rn Olofsson and Olof So¨rnmo and Manuel Drust and Anders Robertsson and Martin Hägele and Rolf Johansson",
keywords = "Robotic machining",
keywords = "Macro/micro-actuation",
keywords = "Contact operations",
keywords = "Model-based control",
keywords = "Optical tracking ",
abstract = "Abstract A novel integrated approach to high-accuracy machining with industrial robots is presented in this paper. By combining a conventional industrial robot with an external compensation mechanism, a significantly higher bandwidth of the control of the relative position between the tool and the workpiece can be achieved. A model-based feedback controller for the compensation mechanism, as well as a mid-ranging control architecture for the combined system with the robot and the compensation mechanism are developed. The system performance is evaluated in extensive machining experiments, and the workpiece accuracies achieved are quantified and compared to the corresponding results obtained with state-of-the-art approaches to robotic machining. It is shown that the proposed approach to machining offers significantly higher accuracy, up to eight times improvement for milling in steel, where the required process forces, and thus the exhibited position deviations of the robot, are significant. "
}
@article{Erdim2010657,
title = "A comparison of sampling strategies for computing general sweeps ",
journal = "Computer-Aided Design ",
volume = "42",
number = "8",
pages = "657 - 669",
year = "2010",
note = "Application-driven Shape Development ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2009.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0010448509001717",
author = "Hüseyin Erdim and Horea T. Ilieş",
keywords = "Solid sweeping",
keywords = "Boundary evaluation",
keywords = "Space sampling",
keywords = "Marching cubes",
keywords = "Octrees ",
abstract = "Sweeping moving objects has become one of the basic geometric operations used in engineering design, analysis and physical simulation. Despite its relevance, computing the boundary of the set swept by a non-polyhedral moving object is largely an open problem due to well-known theoretical and computational difficulties of the envelopes. We have recently introduced a generic point membership classification (PMC) test for general solid sweeping. Importantly, this \{PMC\} test provides complete geometric information about the set swept by the moving object, including the ability to compute the self-intersections of the sweep itself. In this paper, we compare two recursive strategies for sampling points of the space in which the object moves, and show that the sampling based on a fast marching cubes algorithm possesses the best combination of features in terms of performance and accuracy for the boundary evaluation of general sweeps. Furthermore, we show that the \{PMC\} test can be used as the foundation of a generic sweep boundary evaluator in conjunction with efficient space sampling strategies for solids of arbitrary complexity undergoing affine motions. "
}
@article{DrewsJr20131696,
title = "Novelty detection and segmentation based on Gaussian mixture models: A case study in 3D robotic laser mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "12",
pages = "1696 - 1709",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001115",
author = "Paulo Drews -Jr. and Pedro Núñez and Rui P. Rocha and Mario Campos and Jorge Dias",
keywords = "Novelty detection",
keywords = "Gaussian mixture model",
keywords = "3D robotic mapping ",
abstract = "Abstract This article proposes a framework to detect and segment changes in robotics datasets, using 3D robotic mapping as a case study. The problem is very relevant in several application domains, not necessarily related with mobile robotics, including security, health, industry and military applications. The aim is to identify significant changes by comparing current data with previous data provided by sensors. This feature is extremely challenging because large amounts of noisy data must be processed in a feasible way. The proposed framework deals with novelty detection and segmentation in robotic maps using clusters provided by Gaussian Mixture Models (GMMs). \{GMMs\} provides a feature space that enables data compression and effective processing. Two alternative criteria to detect changes in the \{GMM\} space are compared: a greedy technique based on the Earth Mover’s Distance (EMD); and a structural matching algorithm that fulfills both absolute (global matching) and relative constraints (structural matching). The proposed framework is evaluated with real robotic datasets and compared with other methods known from literature. With this purpose, 3D mapping experiments are carried out with both simulated data and real data from a mobile robot equipped with a 3D range sensor. "
}
@article{Witte2012S359,
title = "PO-0912 A \{PRACTICAL\} \{METHOD\} \{FOR\} \{PROBABILISTIC\} \{PLAN\} \{EVALUATION\} \{IN\} \{HETEROGENEOUS\} TISSUES: \{BEYOND\} \{THE\} \{DOSE\} \{CLOUD\} \{APPROXIMATION\} ",
journal = "Radiotherapy and Oncology ",
volume = "103, Supplement 1",
number = "",
pages = "S359 - S360",
year = "2012",
note = "\{ESTRO\} 31 ",
issn = "0167-8140",
doi = "https://doi.org/10.1016/S0167-8140(12)71245-8",
url = "http://www.sciencedirect.com/science/article/pii/S0167814012712458",
author = "M. Witte and M. Bal and T. Janssen and M. Van Herk"
}
@article{Morales2017355,
title = "Social robotic wheelchair centered on passenger and pedestrian comfort ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "355 - 362",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S092188901630570X",
author = "Yoichi Morales and Takahiro Miyashita and Norihiro Hagita",
keywords = "Human–robot comfortable interaction",
keywords = "Social navigation",
keywords = "Spatial cognition ",
abstract = "Abstract The use of robot technology such as robotic wheelchairs is crucial to provide services for super-aging societies. A social issue in current robotic wheelchairs is the lack of passenger and pedestrian comfort considerations. This paper proposes a balanced navigation model for the passenger and pedestrians in terms of social issues regarding wheelchair navigation. The model considers comfort requirements for the passenger and pedestrians and is used to compute social wheelchair paths. Model validation was performed with human participants in the case of a single passenger and a pedestrian where experimental results show that overall comfort should be considered for computing socially accepted paths. Passengers and pedestrians scored the paths computed by the social planner as more comfortable than state of the art shortest paths. "
}
@article{Fernandes2014372,
title = "CaRINA Intelligent Robotic Car: Architectural design and applications ",
journal = "Journal of Systems Architecture ",
volume = "60",
number = "4",
pages = "372 - 392",
year = "2014",
note = "",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2013.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S1383762113002841",
author = "Leandro C. Fernandes and Jefferson R. Souza and Gustavo Pessin and Patrick Y. Shinzato and Daniel Sales and Caio Mendes and Marcos Prado and Rafael Klaser and André Chaves Magalhães and Alberto Hata and Daniel Pigatto and Kalinka Castelo Branco and Valdir Grassi Jr. and Fernando S. Osorio and Denis F. Wolf",
keywords = "Autonomous vehicle architecture",
keywords = "Embedded system design",
keywords = "Robotic vehicle navigation",
keywords = "Computer vision",
keywords = "Machine learning",
keywords = "Intelligent systems ",
abstract = "Abstract This paper presents the development of two outdoor intelligent vehicles platforms named CaRINA I and CaRINA II, their system architecture, simulation tools, and control modules. It also describes the development of the intelligent control system modules allowing the mobile robots and vehicles to navigate autonomously in controlled urban environments. Research work has been carried out on tele-operation, driver assistance systems, and autonomous navigation using the vehicles as platforms to experiments and validation. Our robotic platforms include mechanical adaptations and the development of an embedded software architecture. This paper addresses the design, sensing, decision making, and acting infrastructure and several experimental tests that have been carried out to evaluate both platforms and proposed algorithms. The main contributions of this work is the proposed architecture, that is modular and flexible, allowing it to be instantiated into different robotic platforms and applications. The communication and security aspects are also investigated. "
}
@article{Lenac2017197,
title = "Fast planar surface 3D \{SLAM\} using \{LIDAR\} ",
journal = "Robotics and Autonomous Systems ",
volume = "92",
number = "",
pages = "197 - 220",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016303475",
author = "Kruno Lenac and Andrej Kitanov and Robert Cupec and Ivan Petrović",
keywords = "Mapping",
keywords = "Pose estimation",
keywords = "Point cloud segmentation",
keywords = "Planar surface registration",
keywords = "Planar map",
keywords = "ESDS filter ",
abstract = "Abstract In this paper we propose a fast 3D pose based \{SLAM\} system that estimates a vehicle’s trajectory by registering sets of planar surface segments, extracted from 36 0 ∘ field of view (FOV) point clouds provided by a 3D LIDAR. Full \{FOV\} and planar representation of the map gives the proposed \{SLAM\} system the capability to map large-scale environments while maintaining fast execution time. For efficient point cloud processing we apply image-based techniques to project it to three two-dimensional images. The \{SLAM\} backend is based on Exactly Sparse Delayed State Filter as a non-iterative way of updating the pose graph and exploiting sparsity of the \{SLAM\} information matrix. Finally, our \{SLAM\} system enables reconstruction of the global map by merging the local planar surface segments in a highly efficient way. The proposed point cloud segmentation and registration method was tested and compared with the several state-of-the-art methods on two publicly available datasets. Complete \{SLAM\} system was also tested in one indoor and one outdoor experiment. The indoor experiment was conducted using a research mobile robot Husky \{A200\} to map our university building and the outdoor experiment was performed on the publicly available dataset provided by the Ford Motor Company, in which a car equipped with a 3D \{LIDAR\} was driven in the downtown Dearborn Michigan. "
}
@article{Günther2017336,
title = "Model-based furniture recognition for building semantic object maps ",
journal = "Artificial Intelligence ",
volume = "247",
number = "",
pages = "336 - 351",
year = "2017",
note = "Special Issue on \{AI\} and Robotics ",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2014.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S000437021400157X",
author = "Martin Günther and Thomas Wiemann and Sven Albrecht and Joachim Hertzberg",
keywords = "Semantic map",
keywords = "Incremental mapping",
keywords = "Closed-loop mapping",
keywords = "Model-based object recognition",
keywords = "3D point cloud",
keywords = "CAD model matching",
keywords = "OWL-DL ontology ",
abstract = "Abstract This paper presents an approach to creating a semantic map of an indoor environment incrementally and in closed loop, based on a series of 3D point clouds captured by a mobile robot using an RGB-D camera. Based on a semantic model about furniture objects (represented in an OWL-DL ontology with rules attached), we generate hypotheses for locations and 6DoF poses of object instances and verify them by matching a geometric model of the object (given as a \{CAD\} model) into the point cloud. The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture. We demonstrate the robustness of our approach against occlusion and aperture limitations of the RGB-D frames, and against differences between the \{CAD\} models and the real objects. We evaluate the complete system on two challenging datasets featuring partial visibility and totaling over 800 frames. The results show complementary strengths and weaknesses of processing each frame directly vs. processing the fully registered scene, which accord with intuitive expectations. "
}
@article{Citak2013268,
title = "Unicompartmental knee arthroplasty: Is robotic technology more accurate than conventional technique? ",
journal = "The Knee ",
volume = "20",
number = "4",
pages = "268 - 271",
year = "2013",
note = "",
issn = "0968-0160",
doi = "https://doi.org/10.1016/j.knee.2012.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0968016012002232",
author = "Mustafa Citak and Eduardo M. Suero and Musa Citak and Nicholas J. Dunbar and Sharon H. Branch and Michael A. Conditt and Scott A. Banks and Andrew D. Pearle",
keywords = "Robotic-assisted",
keywords = "Unicompartmental knee arthroplasty",
keywords = "Navigation",
keywords = "Accuracy ",
abstract = "Background Robotic-assisted unicompartmental knee arthroplasty (UKA) with rigid bone fixation "can significantly improve implant placement and leg alignment. The aim of this cadaveric study was to determine whether the use of robotic systems with dynamic bone tracking would provide more accurate \{UKA\} implant positioning compared to the conventional manual technique. Methods Three-dimensional CT-based preoperative plans were created to determine the desired position and orientation for the tibial and femoral components. For each pair of cadaver knees, \{UKA\} was performed using traditional instrumentation on the left side and using a haptic robotic system on the right side. Postoperative \{CT\} scans were obtained and 3D-to-3D iterative closest point registration was performed. Implant position and orientation were compared to the preoperative plan. Results Surgical \{RMS\} errors for femoral component placement were within 1.9 mm and 3.7° in all directions of the planned implant position for the robotic group, while \{RMS\} errors for the manual group were within 5.4 mm and 10.2°. Average \{RMS\} errors for tibial component placement were within 1.4 mm and 5.0° in all directions for the robotic group; while, for the manual group, \{RMS\} errors were within 5.7 mm and 19.2°. Conclusions \{UKA\} was more precise using a semiactive robotic system with dynamic bone tracking technology compared to the manual technique. "
}
@article{Garboczi2017325,
title = "3D analytical mathematical models of random star-shape particles via a combination of X-ray computed microtomography and spherical harmonic analysis ",
journal = "Advanced Powder Technology ",
volume = "28",
number = "2",
pages = "325 - 339",
year = "2017",
note = "",
issn = "0921-8831",
doi = "https://doi.org/10.1016/j.apt.2016.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921883116302953",
author = "E.J. Garboczi and J.W. Bullard",
keywords = "Particle shape",
keywords = "Spherical harmonics",
keywords = "X-ray computed tomography",
keywords = "Star shape",
keywords = "Shape parameters",
keywords = "Random ",
abstract = "Abstract To compute any physical quantity for a random particle, one needs to know the mathematical shape of the particle. For regular particles like spheres and ellipsoids, the mathematics are straightforward. For random particles, with realistic shapes, mathematically characterizing the shape had not been generally done. But since about the year 2002, a method has been developed that combines X-ray computed tomography and spherical harmonic analysis to give analytical, differentiable mathematical functions for the three-dimensional shape of star-shape particles, which are a wide class of particles covering most industrial particles of interest, ranging from micrometer scale to millimeter scale particles. This review article describes how this is done, in some detail, and then gives examples of applications of this method, including a contact function that is suitable for these random shape particles. The purpose of this article is to make these ideas widely available for the general powder researcher who knows that particle shape is important to his/her applications, and especially for those researchers who are just starting out in their particle science and technology careers. "
}
@article{Cazals2009551,
title = "Computing the arrangement of circles on a sphere, with applications in structural biology ",
journal = "Computational Geometry ",
volume = "42",
number = "6–7",
pages = "551 - 565",
year = "2009",
note = "",
issn = "0925-7721",
doi = "https://doi.org/10.1016/j.comgeo.2008.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0925772108000965",
author = "Frédéric Cazals and Sébastien Loriot",
keywords = "Spheres",
keywords = "Arrangement of circles",
keywords = "Van der Waals models",
keywords = "Docking ",
abstract = "Balls and spheres are the simplest modeling primitives after affine ones, which accounts for their ubiquitousness in Computer Science and Applied Mathematics. Amongst the many applications, we may cite their prevalence when it comes to modeling our ambient 3D space, or to handle molecular shapes using Van der Waals models. If most of the applications developed so far are based upon simple geometric tests between balls, in particular the intersection test, a number of applications would obviously benefit from finer pieces of information. Consider a sphere S 0 and a list of circles on it, each such circle stemming from the intersection between S 0 and another sphere, say S i . Also assume that S i has an accompanying ball B i . This paper develops an integrated framework, based on the generalization of the Bentley–Ottmann algorithm to the spherical setting, to (i) compute the exact arrangement of circles on S 0 (ii) construct in a single pass the half-edge data structure encoding the arrangement induced by the circles (iii) report the covering list of each face of this arrangement, i.e. the list of balls containing it. As an illustration, the covering lists are used as the building block of a geometric optimization algorithm aiming at selecting diverse conformational ensembles for flexible protein–protein docking. "
}
@article{Smirnov2000337,
title = "Cloud-Screening and Quality Control Algorithms for the \{AERONET\} Database ",
journal = "Remote Sensing of Environment ",
volume = "73",
number = "3",
pages = "337 - 349",
year = "2000",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/S0034-4257(00)00109-7",
url = "http://www.sciencedirect.com/science/article/pii/S0034425700001097",
author = "A. Smirnov and B.N. Holben and T.F. Eck and O. Dubovik and I. Slutsker",
abstract = "Automatic globally distributed networks for monitoring aerosol optical depth provide measurements of natural and anthropogenic aerosol loading, which is important in many local and regional studies as well as global change research investigations. The strength of such networks relies on imposing a standardization of measurement and processing, allowing multiyear and large-scale comparisons. The development of the Aerosol Robotic Network (AERONET) for systematic ground-based sunphotometer measurements of aerosol optical depth is an essential and evolving step in this process. The growing database requires the development of a consistent, reproducible, and system-wide cloud-screening procedure. This paper discusses the methodology and justification of the cloud-screening algorithm developed for the \{AERONET\} database. The procedure has been comprehensively tested on experimental data obtained in different geographical and optical conditions. These conditions include biomass burning events in Brazil and Zambia, hazy summer conditions in the Washington \{DC\} area, clean air advected from the Canadian Arctic, and variable cloudy conditions. For various sites our screening algorithm eliminates from ∼20% to 50% of the initial data depending on cloud conditions. Certain shortcomings of the proposed procedure are discussed. "
}
@article{Rieffel2014169,
title = "Private aggregation for presence streams ",
journal = "Future Generation Computer Systems ",
volume = "31",
number = "",
pages = "169 - 181",
year = "2014",
note = "Special Section: Advances in Computer Supported Collaboration: Systems and Technologies ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13001088",
author = "Eleanor G. Rieffel and Jacob T. Biehl and Adam J. Lee and William van Melle",
keywords = "Privacy",
keywords = "Presence systems",
keywords = "Awareness",
keywords = "Access control",
keywords = "Cloud computing",
keywords = "Homomorphic encryption ",
abstract = "Abstract Collaboration technologies must support information sharing between collaborators, but must also take care not to share too much information or share information too widely. Systems that share information without requiring an explicit action by a user to initiate the sharing must be particularly cautious in this respect. Presence systems are an emerging class of applications that support collaboration. Through the use of pervasive sensors, these systems estimate user location, activities, and available communication channels. Because such presence data are sensitive, to achieve wide-spread adoption, sharing models must reflect the privacy and sharing preferences of their users. This paper looks at the role that privacy-preserving aggregation can play in addressing certain user sharing and privacy concerns with respect to presence data. We define conditions to achieve CollaPSE (Collaboration Presence Sharing Encryption) security, in which (i) an individual has full access to her own data, (ii) a third party performs computation on the data without learning anything about the data values, and (iii) people with special privileges called “analysts” can learn statistical information about groups of individuals, but nothing about the individual values contributing to the statistic other than what can be deduced from the statistic. More specifically, analysts can decrypt aggregates without being able to decrypt the individual values contributing to the aggregate. Based in part on studies we carried out that illustrate the need for the conditions encapsulated by CollaPSE security, we designed and implemented a family of CollaPSE protocols. We analyze their security, discuss efficiency tradeoffs, describe extensions, and review more recent privacy-preserving aggregation work. "
}
@incollection{Andress2014277,
title = "Chapter 16 - The Future of Cyber War ",
editor = "Andress, Jason  and Winterfeld, Steve ",
booktitle = "Cyber Warfare (Second Edition) ",
publisher = "Syngress",
edition = "Second Edition",
address = "Boston",
year = "2014",
pages = "277 - 289",
isbn = "978-0-12-416672-1",
doi = "https://doi.org/10.1016/B978-0-12-416672-1.00016-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780124166721000167",
author = "Jason Andress and Steve Winterfeld",
keywords = "Black Swan event",
keywords = "Capability surprise",
keywords = "Cloud computing",
keywords = "Cyber Response Framework",
keywords = "Cyber time ",
abstract = "Abstract When it comes to cyber war, it can be impractical to predict the future. However, this does not mean one should resign all hope and take a “come what may” attitude toward cyber warfare and cybersecurity. A deep understanding and awareness of cyber threats and their prevention and mitigation is crucial if the United States is to maintain leadership in this arena. But before this can occur, leaders must agree on whether a “cyber war” is being waged today, identify associated problems, and determine how to solve them. This closing chapter focuses on the future of cyber war. After setting the stage for their examination of the issue, the authors identify some near-term trends and the most likely and most dangerous courses of action. They round out the chapter with a discussion on new technologies and their inherent problems, and then look at cyber war from an international perspective. "
}
@article{Herrero2017,
title = "Skill based robot programming: Assembly, vision and Workspace Monitoring skill interaction ",
journal = "Neurocomputing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2016.09.133",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217305441",
author = "Héctor Herrero and Amine Abou Moughlbay and Jose Luis Outón and Damien Sallé and Karmele López de Ipiña",
keywords = "Robotics",
keywords = "Flexibility",
keywords = "Skill based programming",
keywords = "State machine",
keywords = "Easy programming",
keywords = "Vision skills",
keywords = "Collaborative robots",
keywords = "Workspace Monitoring ",
abstract = "Abstract The skill based programming eases the robot program generation, its similarity to human behavior allows non expert operators maintaining, adapting or creating robotic applications. The use of skills requires different approaches for the interaction between them, especially for sharing information. The presented approach combines the skill based programming using a state machine for low level robot execution management. With the proposed framework the interaction and communication between skills is improved. The work presented below is focused on the use of vision skills and safe Workspace Monitoring, for addressing a real use case where interaction with robot motions (organized as assembly skills) is required. "
}
@incollection{Havens2016245,
title = "Chapter 11 - Using Thermal Imagers for Animal Ecology ",
editor = "Havens, Kirk J.  and Sharp, Edward J. ",
booktitle = "Thermal Imaging Techniques to Survey and Monitor Animals in the Wild ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2016",
pages = "245 - 314",
isbn = "978-0-12-803384-5",
doi = "https://doi.org/10.1016/B978-0-12-803384-5.00011-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128033845000117",
author = "Kirk J. Havens and Edward J. Sharp",
keywords = "viewing angle",
keywords = "reflectivity",
keywords = "emissivity",
keywords = "survey area",
keywords = "apparent temperature difference",
keywords = "spatial distribution",
keywords = "thermal signatures",
keywords = "heat transfer",
keywords = "atmospheric transmission",
keywords = "animal ecology",
keywords = "detectability",
keywords = "poikilotherms",
keywords = "homotherms",
keywords = "atmospheric effects",
keywords = "solar loading",
keywords = "diurnal cycle",
keywords = "swath width",
keywords = "survey geometry",
keywords = "FOV-footprint",
keywords = "automated detection",
keywords = "robotic vision",
keywords = "panning",
keywords = "water vapor",
keywords = "relative humidity",
keywords = "atmospheric scattering",
keywords = "aerosols",
keywords = "red-cockaded woodpecker",
keywords = "precipitation",
keywords = "cloud cover",
keywords = "shading effects",
keywords = "tree cavities",
keywords = "thermal shadows",
keywords = "background clutter",
keywords = "emissivity",
keywords = "transects",
keywords = "thermal contrast",
keywords = "bedding sites",
keywords = "signature lifetimes ",
abstract = "Abstract A successful session of collecting thermal imagery in the field requires that the survey planning take into account how to best use the factors and techniques that we can control and integrate them with those that we cannot control. This chapter deals with the effects of phenomena that have a dominating influence on the quality of imagery gathered in the field. The effects of the atmosphere, diurnal cycle, and continually changing micrometeorological conditions are beyond our control but must always be included in the planning of a data-gathering effort. In the sections that follow we provide insight on how these continually changing gifts of nature affect thermal images and how to best manage their deleterious side effects on the imagery and at the same time use the advantageous side of these effects to help optimize the detectability. "
}
@article{Chao2013301,
title = "Structure Based Derived Uniform Formula for Siphon, Its Complementary Set and T-characteristic Vectors ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "9",
pages = "301 - 306",
year = "2013",
note = "7th \{IFAC\} Conference on Manufacturing Modelling, Management, and Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130619-3-RU-3018.00549",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016343026",
author = "Dinel Yuh Chao and Yen-Liang Pan and Wei-Hsiang Liao",
keywords = "Petri nets",
keywords = "siphons",
keywords = "supervisory control",
keywords = "cloud computing",
keywords = "flexible manufacturing systems ",
abstract = "Abstract Unmarked siphons in a Petri net modeling concurrent systems such as those in cloud computing induce deadlocks. The number of siphons grows exponentially with the size of a net. This problem can be relieved by computing compound (or strongly dependent) siphons based on basic siphons. A basic (resp. compound) siphon can be synthesized from an elementary (resp. compound called alternating) resource circuit. It however cannot be extended to cases where two elementary circuits intersect at a directed path rather than a single place (i.e., corresponding to a weakly dependent siphon). This paper develops a uniform formula not only for both cases but also valid for the complementary set of siphon and characteristic vectors. We further propose to generalize it to a compound siphon consisting of n basic siphons. This helps simplify the computation and the computer implementation to shorten the program size. Also, the formula is easier to be memorized without consulting the references due to the same underlying physics. "
}
@article{Chan2009640,
title = "Image-guided robotic neurosurgery—an in vitro and in vivo point accuracy evaluation experimental study ",
journal = "Surgical Neurology ",
volume = "71",
number = "6",
pages = "640 - 647",
year = "2009",
note = "",
issn = "0090-3019",
doi = "https://doi.org/10.1016/j.surneu.2008.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0090301908005806",
author = "Frank Chan and Irwan Kassim and Charles Lo and Chi Long Ho and David Low and Beng Ti Ang and Ivan Ng",
keywords = "Stereotactic brain biopsy",
keywords = "Robotic surgery",
keywords = "Image Guided Surgery",
keywords = "Stereotactic neurosurgery ",
abstract = "Background We describe the development of a prototype neurosurgical robotic system called NISS. The aim is to implement a robotic system capable of achieving accurate registration of robotic coordinate systems based on \{CT\} images, so that it can be used in clinical application. This system has been refined with a better level of predictability, reliability, and robustness sufficient for animal trial evaluation in stereotactic biopsy of brain lesions. Methods Point accuracy evaluation of \{NISS\} began with an in vitro study. The in vitro robotic application accuracy result was 0.1 ± 0.05 mm and absolute needle-to-target deviation was 0.3 ± 0.2 mm. An in vivo experiment approach of using steel balls of 1.56-mm-diameter as targets inside the brain of an anaesthetized dog was used to evaluate the performance accuracy of \{NISS\} stereotactic probe placement. Five dogs underwent surgical insertion of steel balls into the brain, and the steel balls were served as targets to be reached by a core needle (1.56-mm-diameter). The experiment was carried out by precise manipulation of the needle to reach the steel ball using frameless stereotactic localization principles. Results A total of 9 needle results were collected from procedures involving 5 dogs. In the first 5 procedures on 3 dogs, the results were less than 1.9 mm, with an average of 1.3 ± 0.5 mm. The remaining 4 procedures on 2 dogs yielded results of less than 0.7 mm, with an average of 0.3 ± 0.2 mm. Conclusion The in vitro and in vivo studies represent the first approach toward evaluating targeting accuracy of a robotic surgery system by using stereotactics biopsy application in a living subject. "
}
@article{Krol2012206,
title = "Elastic Infrastructure for Interactive Data Farming Experiments ",
journal = "Procedia Computer Science ",
volume = "9",
number = "",
pages = "206 - 215",
year = "2012",
note = "Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.04.022",
url = "http://www.sciencedirect.com/science/article/pii/S1877050912001433",
author = "Dariusz Krol and Bartosz Kryza and Michal Wrzeszcz and Lukasz Dutka and Jacek Kitowski",
keywords = "data farming",
keywords = "cloud computing",
keywords = "agent-based simulation",
keywords = "military mission planning ",
abstract = "With the increasing availability of high performance computing power, new possibilities with respect to simulation and analysis become available and feasible. One of such methodologies is data farming, where large amounts of data are generated through simulation of several configurations from large parameter space and then analyzed for patterns. Unfortunately, the availability of versatile data farming systems is very limited and none of existing solutions allows integration with novel Cloud solutions. In this paper, we present our system, which is a flexible solution for running very large Data Farming experiments on both intranet clusters as well as on remote computational resources, including public Clouds. Another important aspect of the presented system is the support of interactive Data Farming experiments with online analysis of partial experiment results and experiment extending capability. Sample application of our system is present on military mission planning support scenario. "
}
@article{Jeyarani2012811,
title = "Design and implementation of adaptive power-aware virtual machine provisioner (APA-VMP) using swarm intelligence ",
journal = "Future Generation Computer Systems ",
volume = "28",
number = "5",
pages = "811 - 821",
year = "2012",
note = "Special Section: Energy efficiency in large-scale distributed systems ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2011.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X11001130",
author = "R. Jeyarani and N. Nagaveni and R. Vasanth Ram",
keywords = "\{VM\} provisioning",
keywords = "Resource dynamics",
keywords = "Cloud computing",
keywords = "Particle Swarm Optimization (PSO)",
keywords = "Dynamic adaptive PSO",
keywords = "Power saving states",
keywords = "Dynamic Voltage Frequency Scaling (DVFS)",
keywords = "Power conservation ",
abstract = "Cloud computing aims at providing dynamic leasing of server capabilities as scalable, virtualized services to end users. Our work focuses on the Infrastructure as a Service (IaaS) model where custom Virtual Machines (VM) are launched in appropriate servers available in a data center. The cloud data center taken into consideration is heterogeneous and large scale in nature. Such a resource pool is basically characterized by high resource dynamics caused by non-linear variation in the availability of processing elements, memory size, storage capacity, bandwidth and power drawn resulting from the sporadic nature of workload. Apart from the said resource dynamics, our proposed work also considers the processor transitions to various sleep states and their corresponding wake up latencies that are inherent in contemporary enterprise servers. The primary objective of the proposed metascheduler is to map efficiently a set of \{VM\} instances onto a set of servers from a highly dynamic resource pool by fulfilling resource requirements of maximum number of workloads. As the cloud data centers are overprovisioned to meet the unexpected workload surges, huge power consumption has become one of the major issues of concern. We have proposed a novel metascheduler called Adaptive Power-Aware Virtual Machine Provisioner (APA-VMP) that schedules the workload in such a way that the total incremental power drawn by the server pool is minimum without compromising the performance objectives. The APA-VMP makes use of swarm intelligence methodology to detect and track the changing optimal target servers for \{VM\} placement very efficiently. The scenario was experimented by novel Self-adaptive Particle Swarm Optimization (SAPSO) for \{VM\} provisioning, which makes best possible use of the power saving states of idle servers and instantaneous workload on the operational servers. It is evident from the results that there is a significant reduction in the power numbers against the existing strategies. "
}
@article{Chromý2013268,
title = "Creating Three-Dimensional Computer Models Using Robotic Manipulator and Laser Scanners ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "28",
pages = "268 - 273",
year = "2013",
note = "12th \{IFAC\} Conference on Programmable Devices and Embedded Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130925-3-CZ-3023.00037",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015373365",
author = "Adam Chromý and Petra Kocmanová and Luděk Žalud",
keywords = "Robotic manipulators",
keywords = "laser scanners",
keywords = "3D models",
keywords = "Epson \{C3\} robotic manipulator ",
abstract = "Abstract This paper presents scanning system providing three-dimensional models. Use of laser scanner mounted on robotic manipulator provides very flexible device capable of building models of both tiny detailed structures and large object. It could be used in many various applications, especially in health care, where it brings lot of advantages comparing to present scanning systems. Mechanical constitution, interfacing approaches and operating principles of this device are described. "
}
@article{Kaipa201617,
title = "Addressing perception uncertainty induced failure modes in robotic bin-picking ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "42",
number = "",
pages = "17 - 38",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515300971",
author = "Krishnanand N. Kaipa and Akshaya S. Kankanhalli-Nagendra and Nithyananda B. Kumbla and Shaurya Shriyam and Srudeep Somnaath Thevendria-Karthic and Jeremy A. Marvel and Satyandra K. Gupta",
abstract = "Abstract We present a comprehensive approach to handle perception uncertainty to reduce failure rates in robotic bin-picking. Our focus is on mixed-bins. We identify the main failure modes at various stages of the bin-picking task and present methods to recover from them. If uncertainty in part detection leads to perception failure, then human intervention is invoked. Our approach estimates the confidence in the part match provided by an automated perception system, which is used to detect perception failures. Human intervention is also invoked if uncertainty in estimated part location and orientation leads to a singulation planning failure. We have developed a user interface that enables remote human interventions when necessary. Finally, if uncertainty in part posture in the gripper leads to failure in placing the part with the desired accuracy, sensor-less fine-positioning moves are used to correct the final placement errors. We have developed a fine-positioning planner with a suite of fine-motion strategies that offer different tradeoffs between completion time and postural accuracy at the destination. We report our observations from system characterization experiments with a dual-armed Baxter robot, equipped with a Ensenso three-dimensional camera, to perform bin-picking on mixed-bins. "
}
@article{Gilbert201675,
title = "Evaluation of Absorbable Hemostatic Powder for Prevention of Lymphoceles Following Robotic Prostatectomy With Lymphadenectomy ",
journal = "Urology ",
volume = "98",
number = "",
pages = "75 - 80",
year = "2016",
note = "",
issn = "0090-4295",
doi = "https://doi.org/10.1016/j.urology.2016.06.071",
url = "http://www.sciencedirect.com/science/article/pii/S0090429516305520",
author = "Daniel R. Gilbert and Jordan Angell and Ronney Abaza",
abstract = "Objective To determine whether lymphoceles can be prevented after robotic prostatectomy with pelvic lymph node dissection (PLND), we performed a prospective randomized study using an absorbable hemostatic agent (Arista AH). The most common complications of \{PLND\} for prostate cancer are related to lymphocele formation, which occur in 30%-50% of patients according to studies that performed screening imaging. Although most are asymptomatic, when intervention is required the cost and morbidity are high. Materials and Methods Of 100 patients enrolled, 88 completed the study. Each patient served as his or her own control, with Arista \{AH\} placed over the field of \{PLND\} on only one side in a randomized fashion as revealed only after bilateral \{PLND\} was completed. All patients underwent screening pelvic computed tomography scan 3 months later, with radiologists blinded to the Arista \{AH\} treated side. A significant lymphocele was defined as a fluid collection 3 cm or greater in any plane. Results The mean lymph node yield was 8.1 nodes. Fourteen lymphoceles were identified. Five occurred on the side where Arista \{AH\} was used vs 9 on untreated sides (5.7% vs 10.2%, P = .248). When they occurred, there was no statistically significant difference in lymphocele size between treated and untreated sides (P = .441). No lymphoceles were symptomatic. Conclusion Although the lymphocele rate with Arista \{AH\} was 5.7% compared with 10.2% without it, this was not a statistically significant difference potentially because the study was underpowered due to an unusually low baseline rate of lymphoceles. A larger study is warranted to determine whether using a hemostatic agent like Arista \{AH\} can prevent lymphoceles. "
}
@article{Thuot201386,
title = "Remote robotic underwater grinding system and modeling for rectification of hydroelectric structures ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "86 - 95",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000889",
author = "Dominique Thuot and Zhaoheng Liu and Henri Champliaud and Julien Beaudry and Pierre-Luc Richard and Michel Blain",
keywords = "Underwater grinding process",
keywords = "Grinding modeling",
keywords = "Material removal rate (MRR)",
keywords = "Water drag effect",
keywords = "Air injector",
keywords = "Robotic grinding ",
abstract = "A submersible grinding robot has been designed to automate the dam gate metallic structure repair process. In order to measure and control the amount of material removed during the process, an empirical approach for modeling the material removal rate (MRR) of the underwater grinding application is proposed and presented in this paper. The objective is to determine the \{MRR\} in terms of the process parameters such as cutting speed and grinding power over a range of variable wheel diameters. Experiments show that water causes drag and a significant loss of power occurs during grinding. An air injector encasing the grinding wheel has been prototyped, and it is shown that power loss can be reduced by up to 80%. A model, based on motor characterization and empirical relations among system and process parameters, is developed for predicting \{MRR\} which will be used for the robotic grinding control system. A validation is carried out through experiments, and confirms the good accuracy of the model for predicting the depth of cut for underwater grinding. A comparative study for dry and underwater grinding is also conducted through experiments and shows that the \{MRR\} is higher for underwater grinding than in dry conditions at low cutting speeds. "
}
@article{Wilson20141901,
title = "The Prevalence of Nodal Upstaging During Robotic Lung Resection in Early Stage Non-Small Cell Lung Cancer ",
journal = "The Annals of Thoracic Surgery ",
volume = "97",
number = "6",
pages = "1901 - 1907",
year = "2014",
note = "",
issn = "0003-4975",
doi = "https://doi.org/10.1016/j.athoracsur.2014.01.064",
url = "http://www.sciencedirect.com/science/article/pii/S0003497514003865",
author = "Jennifer L. Wilson and Brian E. Louie and Robert J. Cerfolio and Bernard J. Park and Eric Vallières and Ralph W. Aye and Ahmed Abdel-Razek and Ayesha Bryant and Alexander S. Farivar",
abstract = "Background Pathologic nodal upstaging can be considered a surrogate for completeness of nodal evaluation and quality of surgery. We sought to determine the rate of nodal upstaging and disease-free and overall survival with a robotic approach in clinical stage I NSCLC. Methods We retrospectively reviewed patients with clinical stage I \{NSCLC\} after robotic lobectomy or segmentectomy at three centers from 2009 to 2012. Data were collected primarily based on Society of Thoracic Surgeons database elements. Results Robotic anatomic lung resection was performed in 302 patients. The majority were right sided (192; 63.6%) and of the upper lobe (192; 63.6%). Most were clinical stage \{IA\} (237; 78.5%). Pathologic nodal upstaging occurred in 33 patients (10.9% [pN1 20, 6.6%; pN2 13, 4.3%]). Hilar (pN1) upstaging occurred in 3.5%, 8.6%, and 10.8%, respectively, for cT1a, cT1b, and cT2a tumors. Comparatively, historic hilar upstage rates of video-assisted thoracoscopic surgery (VATS) versus thoracotomy for cT1a, cT1b, and cT2a were 5.2%, 7.1%, and 5.7%, versus 7.4%, 8.8%, and 11.5%, respectively. Median follow-up was 12.3 months (range, 0 to 49). Forty patients (13.2%) had disease recurrence (local 11, 3.6%; regional 7, 2.3%; distant 22, 7.3%). The 2-year overall survival was 87.6%, and the disease-free survival was 70.2%. Conclusions The rate of nodal upstaging for robotic resection appears to be superior to \{VATS\} and similar to thoracotomy data when analyzed by clinical T stage. Both disease-free and overall survival were comparable to recent \{VATS\} and thoracotomy data. A larger series of matched open, \{VATS\} and robotic approaches is necessary. "
}
@article{Kerr2016165,
title = "Investigation of synthetic aperture methods in ultrasound surface imaging using elementary surface types ",
journal = "Ultrasonics ",
volume = "72",
number = "",
pages = "165 - 176",
year = "2016",
note = "",
issn = "0041-624X",
doi = "https://doi.org/10.1016/j.ultras.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0041624X16301408",
author = "W. Kerr and S.G. Pierce and P. Rowe",
keywords = "Ultrasound imaging",
keywords = "Total Focussing Method",
keywords = "Synthetic Aperture Focussing Method",
keywords = "Full Matrix Capture",
keywords = "Robotics ",
abstract = "Abstract Synthetic aperture imaging methods have been employed widely in recent research in non-destructive testing (NDT), but uptake has been more limited in medical ultrasound imaging. Typically offering superior focussing power over more traditional phased array methods, these techniques have been employed in \{NDT\} applications to locate and characterise small defects within large samples, but have rarely been used to image surfaces. A desire to ultimately employ ultrasonic surface imaging for bone surface geometry measurement prior to surgical intervention motivates this research, and results are presented for initial laboratory trials of a surface reconstruction technique based on global thresholding of ultrasonic 3D point cloud data. In this study, representative geometry artefacts were imaged in the laboratory using two synthetic aperture techniques; the Total Focusing Method (TFM) and the Synthetic Aperture Focusing Technique (SAFT) employing full and narrow synthetic apertures, respectively. Three high precision metallic samples of known geometries (cuboid, sphere and cylinder) which featured a range of elementary surface primitives were imaged using a 5 MHz, 128 element 1D phased array employing both \{SAFT\} and \{TFM\} approaches. The array was manipulated around the samples using a precision robotic positioning system, allowing for repeatable ultrasound derived 3D surface point clouds to be created. A global thresholding technique was then developed that allowed the extraction of the surface profiles, and these were compared with the known geometry samples to provide a quantitative measure of error of 3D surface reconstruction. The mean errors achieved with optimised \{SAFT\} imaging for the cuboidal, spherical and cylindrical samples were 1.3 mm, 2.9 mm and 2.0 mm respectively, while those for \{TFM\} imaging were 3.7 mm, 3.0 mm and 3.1 mm, respectively. These results were contrary to expectations given the higher information content associated with the \{TFM\} images. However, it was established that the reduced error associated with the \{SAFT\} technique was associated with significant reductions in side lobe levels of approximately 24 dB in comparison to \{TFM\} imaging, although this came at the expense of reduced resolution and coverage. "
}
@article{Zhang2011377,
title = "Typical Virtual Appliances: An optimized mechanism for virtual appliances provisioning and management ",
journal = "Journal of Systems and Software ",
volume = "84",
number = "3",
pages = "377 - 387",
year = "2011",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2010.11.925",
url = "http://www.sciencedirect.com/science/article/pii/S0164121210003249",
author = "Tianle Zhang and Zhihui Du and Yinong Chen and Xiang Ji and Xiaoying Wang",
keywords = "Cloud computing",
keywords = "Virtualization",
keywords = "Virtual appliance",
keywords = "Infrastructure as a service ",
abstract = "A computing infrastructure requirement in the cloud computing environment can be specified and composed using virtual appliances, which forms the infrastructure-as-a-service (IaaS). Due to the diversity of user requirements, a large number of virtual appliances may be needed. We propose a mechanism called Typical Virtual Appliances (TVAs), an efficient method for providing virtual appliances. In this paper, we present the concept of \{TVAs\} and formulate it as an optimization problem with given constraints. With analysis of the software download logs of real web sites, we discover that the number of user requirements follows a quadratic polynomial distribution, and the user requirements are clustered in nature. According to this finding, we develop a clustering-based \{TVAs\} generation algorithm, and we show that this algorithm can achieve the optimal result. The clustering algorithm can generate TVAs, which can be transformed to other virtual appliances easily and efficiently. We further design a \{TVA\} Management System (TVAMS) to support this mechanism. The simulation results show that our method can meet most of the user requirements efficiently with low storage overhead. "
}
@article{Gogouvitis2012193,
title = "Workflow management for soft real-time interactive applications in virtualized environments ",
journal = "Future Generation Computer Systems ",
volume = "28",
number = "1",
pages = "193 - 209",
year = "2012",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2011.05.017",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X11000999",
author = "Spyridon Gogouvitis and Kleopatra Konstanteli and Stefan Waldschmidt and George Kousiouris and Gregory Katsaros and Andreas Menychtas and Dimosthenis Kyriazis and Theodora Varvarigou",
keywords = "Workflow management",
keywords = "Quality of service",
keywords = "Cloud computing",
keywords = "Service oriented infrastructures",
keywords = "Soft real-time applications ",
abstract = "Many applications, especially the ones implementing multi-user collaborative environments, fall within the context of soft real-time systems in which only small deviations from timing constraints are allowed. The advancements in distributed computing have made it possible to follow a service oriented approach, taking advantage of the benefits this provides. In this context, applications consist of soft real-time critical application service components that interact with each other to provide the corresponding application functionality, forming application workflows. In this paper we present a new architectural design and implementation of a Workflow Management approach. This approach covers enacting soft real-time application service components according to a workflow description language, synchronizing the application components, monitoring the execution and reacting to events within a distributed virtualized environment. We also demonstrate the operation of the implemented mechanism and evaluate its effectiveness using an application scenario with soft real-time interactivity characteristics, namely Film post-production, under realistic settings. "
}
@incollection{Médini2017151,
title = "Chapter 5 - Building a Web of Things with Avatars: A comprehensive approach for concern management in WoT applications ",
editor = "Sheng, Quan Z. and Qin, Yongrui and Yao, Lina  and Benatallah, Boualem ",
booktitle = "Managing the Web of Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2017",
pages = "151 - 180",
isbn = "978-0-12-809764-9",
doi = "https://doi.org/10.1016/B978-0-12-809764-9.00007-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012809764900007X",
author = "Lionel Médini and Michael Mrissa and El-Mehdi Khalfi and Mehdi Terdjimi and Nicolas Le Sommer and Philippe Capdepuy and Jean-Paul Jamont and Michel Occello and Lionel Touseau",
keywords = "Cyber-physical systems",
keywords = "Distributed robotics",
keywords = "Semantic interoperability disruption–tolerant networks",
keywords = "Contextual adaptation",
keywords = "Multi-agent systems ",
abstract = "Abstract The Web of Things (WoT) relies on Web standards to enable interoperability between physical objects (things) and build applications using them. While most approaches (Cyber-Physical Systems, Internet of Things) require complex domain-driven software design that combines different disciplines such as electronics, networks and computing, we believe that generic solutions are needed to support WoT applications across the variety of things and application domains. To this end, we propose the notion of avatar as a Web-compliant software extension of a thing. Avatars achieve interoperability between things using semantic technologies and expose high-level functionalities as \{RESTful\} resources. They can collaborate with other avatars and form standard-compliant WoT applications that match end-users' needs. We detail the notion of avatar and describe how avatar-based WoT infrastructures can improve the quality of Web of Things applications. We show how their architecture allows avatars to embed advances in different areas, and focus on contributions at different levels: tolerance to network disconnection, contextual adaptation and multi-agent negotiation. "
}
@article{Wermter2009111,
title = "Multimodal communication in animals, humans and robots: An introduction to perspectives in brain-inspired informatics ",
journal = "Neural Networks ",
volume = "22",
number = "2",
pages = "111 - 115",
year = "2009",
note = "What it Means to Communicate ",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2009.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0893608009000069",
author = "S. Wermter and M. Page and M. Knowles and V. Gallese and F. Pulvermüller and J. Taylor",
keywords = "Multimodal communication",
keywords = "Neural networks",
keywords = "Robotics",
keywords = "Brain-inspired computing ",
abstract = "Recent years have seen convergence in research on brain mechanisms and neurocomputational approaches, culminating in the creation of a new generation of robots whose artificial “brains” respect neuroscience principles and whose “cognitive” systems venture into higher cognitive domains such as planning and action sequencing, complex object and concept processing, and language. The present article gives an overview of selected projects in this general multidisciplinary field. The work reviewed centres on research funded by the \{EU\} in the context of the New and Emergent Science and Technology, NEST, funding scheme highlighting the topic “What it means to be human”. Examples of such projects include learning by imitation (Edici project), examining the origin of human rule-based reasoning (Far), studying the neural origins of language (Neurocom), exploring the evolutionary origins of the human mind (Pkb140404), researching into verbal and non-verbal communication (Refcom), using and interpreting signs (Sedsu), characterising human language by structural complexity (Chlasc), and representing abstract concepts (Abstract). Each of the communication-centred research projects revealed individual insights; however, there had been little overall analysis of results and hypotheses. In the Specific Support Action Nestcom, we proposed to analyse some \{NEST\} projects focusing on the central question “What it means to communicate” and to review, understand and integrate the results of previous communication-related research, in order to develop and communicate multimodal experimental hypotheses for investigation by future projects. The present special issue includes a range of papers on the interplay between neuroinformatics, brain science and robotics in the general area of higher cognitive functions and multimodal communication. These papers extend talks given at the \{NESTCOM\} workshops, at \{ICANN\} (http://www.his.sunderland.ac.uk/nestcom/workshop/icann.html) in Porto and at the first meeting of the Federation of the European Societies of Neuropsychology in Edinburgh in 2008 (http://www.his.sunderland.ac.uk/nestcom/workshop/esn.html). We hope that the collection will give a vivid insight into current trends in the field. "
}
@article{Siebert20141,
title = "Mobile 3D mapping for surveying earthwork projects using an Unmanned Aerial Vehicle (UAV) system ",
journal = "Automation in Construction ",
volume = "41",
number = "",
pages = "1 - 14",
year = "2014",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2014.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0926580514000193",
author = "Sebastian Siebert and Jochen Teizer",
keywords = "Global positioning system (GPS)",
keywords = "Laser scanning",
keywords = "Photogrammetry",
keywords = "Robotic total station (RTS)",
keywords = "Robotic total station (RTS)",
keywords = "Airplane and helicopters",
keywords = "Remotely piloted vehicles (RPV)",
keywords = "Unmanned aerial vehicle (UAV) systems (UAS)",
keywords = "3D range point cloud generation and mapping",
keywords = "Autonomous vision-based infrastructure sensing",
keywords = "Efficiency, productivity, and safety in geomatics and surveying ",
abstract = "Abstract Unmanned Aerial Vehicle (UAV) systems as a data acquisition platform and as a measurement instrument are becoming attractive for many surveying applications in civil engineering. Their performance, however, is not well understood for these particular tasks. The scope of the presented work is the performance evaluation of a \{UAV\} system that was built to rapidly and autonomously acquire mobile three-dimensional (3D) mapping data. Details to the components of the \{UAV\} system (hardware and control software) are explained. A novel program for photogrammetric flight planning and its execution for the generation of 3D point clouds from digital mobile images is explained. A performance model for estimating the position error was developed and tested in several realistic construction environments. Test results are presented as they relate to large excavation and earth moving construction sites. The experiences with the developed \{UAV\} system are useful to researchers or practitioners in need for successfully adapting \{UAV\} technology for their application(s). "
}
@article{Tsai2011843,
title = "Machine vision based path planning for a robotic golf club head welding system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "27",
number = "4",
pages = "843 - 849",
year = "2011",
note = "Conference papers of Flexible Automation and Intelligent ManufacturingIntelligent manufacturing and services ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2011.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584511000196",
author = "Ming J. Tsai and Hong-Wen Lee and Nai-Jun Ann",
keywords = "Machine vision",
keywords = "Robotic welding system",
keywords = "Path planning ",
abstract = "A path planning method based on machine vision techniques is constructed for a golf-club head robotic welding system. This system uses 3D machine vision techniques to recognize the weldseam and generates a welding path for the robot. The location of the weldseam is discovered by applying a Sobel mask to the captured data. A Laplace mask is also useful to filter out the noise points due to the scatter light refraction of tack-welding spots. The weldseam is then replenished and smoothed out by a B-spline curve fitting. The task frame of the weldseam is computed by finding the tangent, normal, and bi-normal of the curve. The robotic welding path is obtained by further rotations and translation along the axes of the task frame according to the requirement of the welding attitude. The developed machine vision technique and the mathematic framework pertaining to the generation of a welding task frame can readily be used for various three-dimensional welding tasks. "
}
@article{Chikhaoui2016234,
title = "Kinematics and performance analysis of a novel concentric tube robotic structure with embedded soft micro-actuation ",
journal = "Mechanism and Machine Theory ",
volume = "104",
number = "",
pages = "234 - 254",
year = "2016",
note = "",
issn = "0094-114X",
doi = "https://doi.org/10.1016/j.mechmachtheory.2016.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094114X16301100",
author = "Mohamed Taha Chikhaoui and Kanty Rabenorosoa and Nicolas Andreff",
keywords = "Continuum robot",
keywords = "Kinematics",
keywords = "Holonomy",
keywords = "Redundancy",
keywords = "Soft micro-actuators",
keywords = "Intracorporeal microrobotics ",
abstract = "Abstract Continuum robots have shown astounding abilities to assist surgeons reaching confined spaces in the human body. Thus, accurate control of these manipulators, and particularly concentric tube robots, is required in order to achieve intracorporeal microrobotic interventions. We present hereby an improvement of this kinematic structure based on embedded soft micro-actuators. Two models for single and double direction curvature control are introduced. We demonstrate that kinematics are enhanced with respect to the standard approach in terms of holonomy, actuation redundancy and workspace covering. Further kinematic analysis enables the detection of singular configurations. The number of the end-effector pose occurrences that can be reached in a given volume (one cubic millimeter) are computed as well. Finally, the advantages of the novel structures are proven using performance indices. "
}
@article{Kuss2016545,
title = "Detection of Workpiece Shape Deviations for Tool Path Adaptation in Robotic Deburring Systems ",
journal = "Procedia \{CIRP\} ",
volume = "57",
number = "",
pages = "545 - 550",
year = "2016",
note = "Factories of the Future in the digital environment - Proceedings of the 49th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.094",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116312483",
author = "Alexander Kuss and Manuel Drust and Alexander Verl",
keywords = "Deburring",
keywords = "Industrial Robot System",
keywords = "Shape Deviation",
keywords = "CAD Model ",
abstract = "Abstract Robotic systems have the potential to automate deburring processes along edges of arbitrarily shaped workpieces. The desired robot movement can be realized by proper trajectory planning using the computer-aided design (CAD) model of the manufactured workpiece. A fundamental problem is that geometric shape deviations between the nominal \{CAD\} model and the manufactured parts might be beyond acceptable limits for correct execution of the deburring process. This paper proposes a novel, easy to implement and practical approach to detect shape deviations of workpieces for automatic adaptation of robotic deburring processes. The approach only uses dimensional tolerance specifications of the manufactured part provided by the product design to derive possible variations of the workpiece geometry model. A matching process is performed between point clouds for each of the considered variants and a measured point cloud from the manufactured workpiece using an Iterative Closest Point (ICP) approach. Resulting point distances are used for evaluation of shape similarity between the compared point clouds. Finally, the most similar geometry model is identified for subsequent trajectory planning and workpiece localization. Experimental validation is performed by an industrial robot equipped with a stereo camera for shape sensing and a milling tool for subsequent execution of a deburring process. The results demonstrate the effectiveness and practicality of the proposed approach in industrial applications and an increased deburring quality. "
}
@article{Ramisa2016936,
title = "A 3D descriptor to detect task-oriented grasping points in clothing ",
journal = "Pattern Recognition ",
volume = "60",
number = "",
pages = "936 - 948",
year = "2016",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316301558",
author = "Arnau Ramisa and Guillem Alenyà and Francesc Moreno-Noguer and Carme Torras",
keywords = "3D descriptor",
keywords = "Recognition",
keywords = "Detection",
keywords = "Grasping",
keywords = "Manipulation",
keywords = "Robotics ",
abstract = "Abstract Manipulating textile objects with a robot is a challenging task, especially because the garment perception is difficult due to the endless configurations it can adopt, coupled with a large variety of colors and designs. Most current approaches follow a multiple re-grasp strategy, in which clothes are sequentially grasped from different points until one of them yields a recognizable configuration. In this work we propose a method that combines 3D and appearance information to directly select a suitable grasping point for the task at hand, which in our case consists of hanging a shirt or a polo shirt from a hook. Our method follows a coarse-to-fine approach in which, first, the collar of the garment is detected and, next, a grasping point on the lapel is chosen using a novel 3D descriptor. In contrast to current 3D descriptors, ours can run in real time, even when it needs to be densely computed over the input image. Our central idea is to take advantage of the structured nature of range images that most depth sensors provide and, by exploiting integral imaging, achieve speed-ups of two orders of magnitude with respect to competing approaches, while maintaining performance. This makes it especially adequate for robotic applications as we thoroughly demonstrate in the experimental section. "
}
@article{Wu20031181,
title = "Improvements to algorithms for computing the Minkowski sum of 3-polytopes ",
journal = "Computer-Aided Design ",
volume = "35",
number = "13",
pages = "1181 - 1192",
year = "2003",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(03)00023-X",
url = "http://www.sciencedirect.com/science/article/pii/S001044850300023X",
author = "Yanyan Wu and Jami J. Shah and Joseph K. Davidson",
keywords = "Geometric algorithms",
keywords = "Minkowski sum",
keywords = "Convex hull",
keywords = "Polytopes",
keywords = "Math modeling of geometric variations ",
abstract = "A Minkowski sum is a geometric operation that is equivalent either to the vector additions of all points in two operands or to the sweeping of one operand around the profile of the other without changing the relative orientation. Applications of Minkowski sums are found in computer graphics, robotics, spatial planning, and CAD. This paper presents two algorithms for computing Minkowski sum of convex polyhedron in three space (3-polytopes). Both algorithms are improvements on current ones found in the literature. One is based on convex hulls and the other on slope diagrams. The original convex hull based Minkowski algorithm is costly, while the original slope diagram based algorithms require the operation of stereographic projection from 3D to 2D for merging the slope diagrams of the two operands. Implementation of stereographic projection is complicated which increases the computation time and reduces the accuracy of the geometric information that is needed for constructing the resultant solid. This paper reports on improvements that have been made to these two algorithms and their implementation. These improvements include using vector operations to find the interrelations between points, arcs and regions on a unit sphere for the slope diagram algorithm, and addition of a pre-sorting procedure before constructing convex hull for convex hull based Minkowski sum algorithm. With these improvements, the computation time and complexity for both algorithms have been reduced significantly, and the computational accuracy of the slope diagram algorithm has been improved. This paper also compares these two algorithms to each other and to their original counterparts. The potential for extending these algorithms to higher dimensions is briefly discussed. "
}
@article{Edwards2017391,
title = "Research note: Machinery, manumission, and economic machinations ",
journal = "Journal of Business Research ",
volume = "70",
number = "",
pages = "391 - 394",
year = "2017",
note = "",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2016.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0148296316304994",
author = "David J. Edwards and Erika Pärn and Peter E.D. Love and Hatem El-Gohary",
keywords = "Big data",
keywords = "Computerization",
keywords = "Robotics",
keywords = "Off-highway plant and machinery ",
abstract = "Abstract This research note reports upon advancements in computerization and big data creation within the off-highway plant and machinery sector. A thematic literature review synthesizes a disparate range of research initiatives and industrial developments and highlights specific examples of technological developments. A discussion regarding impact upon future employment concludes that rather than creating mass unemployment, computerization will change the employment horizon and continue to shape the global economic community. Education is quintessentially important to humanity which must master the machine and not become a slave to technology. Future proofing of educational provisions will therefore feature heavily in tomorrow's employment market. This provocative research note advances new ideas and theoretical perspectives that are specifically designed to stimulate academic debate in this novel and rapidly developing area of scientific endeavor. "
}
@article{Underwood201683,
title = "Mapping almond orchard canopy volume, flowers, fruit and yield using lidar and vision sensors ",
journal = "Computers and Electronics in Agriculture ",
volume = "130",
number = "",
pages = "83 - 96",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2016.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916308249",
author = "James P. Underwood and Calvin Hung and Brett Whelan and Salah Sukkarieh",
keywords = "Robotics",
keywords = "Sensing",
keywords = "Machine vision",
keywords = "Lidar",
keywords = "Multi-sensor fusion",
keywords = "Orchard yield mapping ",
abstract = "Abstract This paper present a mobile terrestrial scanning system for almond orchards, that is able to efficiently map flower and fruit distributions and to estimate and predict yield for individual trees. A mobile robotic ground vehicle scans the orchard while logging data from on-board lidar and camera sensors. An automated software pipeline processes the data offline, to produce a 3D map of the orchard and to automatically detect each tree within that map, including correct associations for the same trees seen on prior occasions. Colour images are also associated to each tree, leading to a database of images and canopy models, at different times throughout the season and spanning multiple years. A canopy volume measure is derived from the 3D models, and classification is performed on the images to estimate flower and fruit density. These measures were compared to individual tree harvest weights to assess the relationship to yield. A block of approximately 580 trees was scanned at peak bloom, fruit-set and just before harvest for two subsequent years, with up to 50 trees individually harvested for comparison. Lidar canopy volume had the strongest linear relationship to yield with R 2 = 0.77 for 39 tree samples spanning two years. An additional experiment was performed using hand-held photography and image processing to measure fruit density, which exhibited similar performance ( R 2 = 0.71 ). Flower density measurements were not strongly related to yield, however, the maps show clear differentiation between almond varieties and may be useful for other studies. "
}
@article{Nguyen20162,
title = "A Smart Shoe for building a real-time 3D map ",
journal = "Automation in Construction ",
volume = "71, Part 1",
number = "",
pages = "2 - 12",
year = "2016",
note = "The Special Issue of 32nd International Symposium on Automation and Robotics in Construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516300401",
author = "Luan V. Nguyen and Hung M. La and Jesus Sanchez and Tam Vu",
keywords = "Robotics",
keywords = "3D map",
keywords = "Real-time 3D map algorithms",
keywords = "SLAM ",
abstract = "Abstract Three dimensional (3D) mapping of environments has gained tremendous attention, from academic to industry to military, owing to the ever increasing needs of environmental modeling as well as monitoring. While many highly effective techniques have been reported thus far, a few even turned into commercial products, none has explored the use of wearable sensors to capture human foot motion, gait, and phase for 3D map construction, especially in the Architecture, Engineering, and Construction (AEC) domain. In this work, we propose a smart (and wearable) shoe, called “Smart Shoe”, which integrates multiple laser scanners and an inertial measurement unit (IMU) to build a 3D map of environments in real time. Such a Smart Shoe can be a potential tool for floor plan surveying, construction process monitoring, planning renovations, space usage planning, managing building maintenance and other tasks in the \{AEC\} domain. Besides, this Smart Shoe could assist disabled people (blind people) to navigate and avoid obstacles in the unknown environment. In another case, the shoes may help firefighters quickly model and recognize objects in the firing, dark, and smoky buildings where traditional camera-based approaches might not be applicable. We integrate this shoe with a novel foot localization algorithm that produces a smooth and accurate pose and trajectory of human walking, which is the key enabling technique to minimize data registration errors from laser point cloud. "
}
@article{Xie2016435,
title = "A Fast All-sky Radiation Model for Solar applications (FARMS): Algorithm and performance evaluation ",
journal = "Solar Energy ",
volume = "135",
number = "",
pages = "435 - 445",
year = "2016",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2016.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X16301827",
author = "Yu Xie and Manajit Sengupta and Jimy Dudhia",
keywords = "Solar radiation",
keywords = "Radiative transfer model",
keywords = "Cloud ",
abstract = "Abstract Radiative transfer (RT) models simulating broadband solar radiation have been widely used by atmospheric scientists to model solar resources for various energy applications such as operational forecasting. Due to the complexity of solving the \{RT\} equation, the computation under cloudy conditions can be extremely time consuming though many approximations (e.g. two-stream approach and delta-M truncation scheme) have been utilized. Thus, a more efficient \{RT\} model is crucial for model developers as a new option for approximating solar radiation at the land surface with minimal loss of accuracy. In this study, we developed a fast all-sky radiation model for solar applications (FARMS) using the simplified clear-sky \{RT\} model, REST2, and simulated cloud transmittances and reflectances from Rapid Radiation Transfer Model (RRTM) with a sixteen-stream Discrete Ordinates Radiative Transfer (DISORT). Simulated lookup tables (LUTs) of cloud transmittances and reflectances are created by varying cloud optical thicknesses, cloud particle sizes, and solar zenith angles. Equations with optimized parameters are fitted to the cloud transmittances and reflectances to develop the model. The all-sky solar irradiance at the land surface can then be computed rapidly by combining \{REST2\} with the cloud transmittances and reflectances. This new \{RT\} model is more than 1000 times faster than those currently utilized in solar resource assessment and forecasting since it does not explicitly solve the \{RT\} equation for each individual cloud condition. Our results indicate the accuracy of the fast radiative transfer model is comparable to or better than two-stream approximation in term of computing cloud transmittance and solar radiation. "
}
@incollection{Sturm2017211,
title = "Chapter 16 - The Case for Standards ",
editor = "Sturm, Rick and Pollard, Carol  and Craig, Julie ",
booktitle = "Application Performance Management (APM) in the Digital Enterprise ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2017",
pages = "211 - 235",
isbn = "978-0-12-804018-8",
doi = "https://doi.org/10.1016/B978-0-12-804018-8.00016-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128040188000164",
author = "Rick Sturm and Carol Pollard and Julie Craig",
keywords = "Application description files (ADFs)",
keywords = "Application response measurement (ARM)",
keywords = "Cloud application management for platforms (CAMP)",
keywords = "Cloud auditing data federation (CADF)",
keywords = "Common information model (CIM)",
keywords = "Component description files (CDFs)",
keywords = "Desktop and mobile architecture for system hardware (DASH)",
keywords = "Global description file (GDF)",
keywords = "IEEE 1220",
keywords = "ISO/IEC 16350",
keywords = "ISO/IEC 17023:2011",
keywords = "ISO/IEC 17963:2013",
keywords = "Object identifier (OID)",
keywords = "Organization for advancing open standards for the information society (OASIS)",
keywords = "POSIX 1387.2",
keywords = "System application \{MIB\} (sysApplMIB)",
keywords = "System management architecture for server management (SMASH)",
keywords = "Tivoli application management specification (AMS)",
keywords = "Web services management (WS-MAN) ",
abstract = "As cloud computing models emerge and evolve in a significant way to deliver reliable, automated services across private, hosted and public environments, standards provide a base of consistent, interoperable management across different cloud service implementations. Brad Anderson, Microsoft General Manager, Management and Services Division As every market matures, so evolves the need for standards. \{HP\} sees that the right balance between industry standards and proprietary technologies propels the industry forward, fostering collaboration and innovation. James Mouton, Hewlett–Packard, Chief Technology Officer, Technology Solutions Group It is not only about open standards, but it is about how these standards all play together for the benefit of the customer. Angel Diaz, \{VP\} \{IBM\} Standards, Open Source and Cloud Labs "
}
@article{Barnfather201629,
title = "Photogrammetric measurement process capability for metrology assisted robotic machining ",
journal = "Measurement ",
volume = "78",
number = "",
pages = "29 - 41",
year = "2016",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2015.09.045",
url = "http://www.sciencedirect.com/science/article/pii/S0263224115005126",
author = "J.D. Barnfather and M.J. Goodfellow and T. Abram",
keywords = "Photogrammetry",
keywords = "Performance",
keywords = "Uncertainty",
keywords = "Inspection ",
abstract = "Abstract This paper documents the findings of experiments done to assess the capability of a photogrammetric measurement process for use in a metrology assisted robotic machining application. Capability is judged from the perspective of uncertainty and error across various part geometries over several days. The influence of operator technique on error and point acquisition ability for challenging geometry is also assessed. The process is found to be resistant to short-term error drift when operating in a controlled environment but systematic and random errors are demonstrated to be highly dependent on geometry. Operator influence on capability is found to be minimal when scanning freeform geometry, although this is unlikely for more complex parts. Acquisition of inspection points on cylindrical pockets is found to be a limitation. Technological development opportunities are highlighted in the context of the metrology assistance application considered. Overall, a thorough assessment of the measurement process capability is made and findings provide a quantification of current state, setting a base case for comparing research progress against. "
}
@article{Misimi201684,
title = "\{GRIBBOT\} – Robotic 3D vision-guided harvesting of chicken fillets ",
journal = "Computers and Electronics in Agriculture ",
volume = "121",
number = "",
pages = "84 - 100",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2015.11.021",
url = "http://www.sciencedirect.com/science/article/pii/S0168169915003701",
author = "Ekrem Misimi and Elling Ruud Øye and Aleksander Eilertsen and John Reidar Mathiassen and Olav Berg Åsebø and Tone Gjerstad and Jan Buljo and Øystein Skotheim",
keywords = "Flexible automation",
keywords = "Visual servoing",
keywords = "Robot",
keywords = "Chicken",
keywords = "Harvesting",
keywords = "Gripper ",
abstract = "Abstract In Norway, the final stage of front half chicken harvesting is still a manual operation due to a lack of automated systems that are suitably flexible with regard to production efficiency and raw material utilisation. This paper presents the ‘GRIBBOT’ – a novel 3D vision-guided robotic concept for front half chicken harvesting. It functions using a compliant multifunctional gripper tool that grasps and holds the fillet, scrapes the carcass, and releases the fillet using a downward pulling motion. The gripper has two main components; a beak and a supporting plate. The beak scrapes the fillet down the rib cage of the carcass following a path determined by the anatomical boundary between the meat and the bone of the rib cage. The supporting plate is actuated pneumatically in order to hold the fillet. A computer vision algorithm was developed to process images from an RGB-D camera (Kinect v2) and locate the grasping point in 3D as the initial contact point of the gripper with the chicken carcass for harvesting operation. Calibration of camera and robot was performed so that the grasping point was defined using 3D coordinates within the robot’s base coordinate frame and tool centre point. A feed-forward Look-and-Move control algorithm was used to control the robot arm and generate the motion trajectories, based on the 3D coordinates of the grasping point as calculated from the computer vision algorithm. The results of an experimental proof-of-concept demonstration showed that \{GRIBBOT\} was successful both in scraping the carcass, grasping chicken fillets automatically and in completing the front half fillet harvesting process. It demonstrated a potential for the flexible robotic automation of the chicken fillet harvesting operation. Its commercial application, with further development, can result in automated fillet harvesting, while future research may also lead to optimal raw material utilisation. \{GRIBBOT\} shows that there is potential to automate even the most challenging processing operations currently carried out manually by human operators. "
}
@article{Bao2016265,
title = "Field-based Robotic Phenotyping for Sorghum Biomass Yield Component Traits Characterization Using Stereo Vision ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "265 - 270",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.049",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316123",
author = "Yin Bao and Lie Tang",
keywords = "Field phenotyping",
keywords = "biomass sorghum",
keywords = "plant height",
keywords = "stem diameter",
keywords = "leaf area",
keywords = "vegetation volume",
keywords = "semi-global stereo matching ",
abstract = "Abstract: Sorghum is known as a major potential feedstock for biofuel production. Being able to efficiently discover genetic control of many traits over a large number of genotypes, genome-wide association study (GWAS) has become a powerful tool for studying sorghum biomass yield components. However, automated high-throughput field-based plant phenotyping is now the bottleneck for scaling up such experiments. This paper presents an auto-guidance enabled utility tractor which navigates itself between crop rows with a predefined path while collecting stereo images of sorghum samples from both sides of the vehicle. Three levels of stereo camera heads were instrumented to capture images of plants up to 3 meters tall. The stereo images were processed offline to reconstruct 3D point clouds using Semi-Global Block Matching. A semi-automated software interface was developed to measure stem diameter due to the strict sampling strategy and the complexity of high-density crop canopy. An automated hedge-based feature extraction pipeline was proposed to quantify other variations in plant architecture traits such as plant height, leaf area index (LAI) and vegetation volume index (VVI). The stem diameter measured using the semiautomatic method showed high correlation (0.958) to hand measurement. "
}
@incollection{Kangovi2017247,
title = "8 - Applications of Peering Carrier Ethernet Networks ",
editor = "Kangovi, Sachidananda ",
booktitle = "Peering Carrier Ethernet Networks ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2017",
pages = "247 - 271",
isbn = "978-0-12-805319-5",
doi = "https://doi.org/10.1016/B978-0-12-805319-5.00008-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053195000083",
author = "Sachidananda Kangovi",
keywords = "Application-specific performance objective (APO)",
keywords = "CoS performance objective (CPO)",
keywords = "Cyber-physical systems (CPS)",
keywords = "Internet of things (IoT)",
keywords = "IP backhaul",
keywords = "Mobile backhaul",
keywords = "Performance tier (PT)",
keywords = "Private cloud",
keywords = "Public cloud",
keywords = "Streaming and switched video transport",
keywords = "Virtual reality (VR) ",
abstract = "Abstract This chapter describes the taxonomy of customers and their applications. This taxonomy provides a structure and important insight in understanding applications that customers need, use, and pay for. Customer applications are the primary purpose of Carrier Ethernet networks (CENs) and peering \{CENs\} as well as operations and business support systems (OSS/BSS) which provide very important and necessary foundations on which applications ride. The chapter then presents application-specific performance requirements or objectives compiled by \{MEF\} from variety of sources in public domain. These application-specific performance objectives (APOs) are then mapped to MEF-defined standard CoS performance objectives (CPOs) and performance tiers (PTs). This mapping is crucial to standardizing Carrier Ethernet (CE) services particularly in peering CENs. The mapping is also described in this chapter. The chapter then covers the applicable \{CE\} services including Ethernet-access service for peering \{CENs\} to meet the network functionality needed by customer applications. Examples of network functionality include \{IP\} backhaul, mobile backhaul, streaming and switched video transport, site-to-site connectivity, connection for cloud computing services, and network connectivity for emerging applications such as Internet of things (IoT), cyber-physical systems (CPS), and virtual reality (VR). The chapter next dwells, briefly, on a process to convert information about customer applications and topology into a design for a \{CE\} service based on \{CENs\} and peering CENs. Finally, the chapter provides a transition to next steps needed in further enhancing peering of \{CENs\} to accommodate emerging trends which is covered in some detail in the final chapter of this book. "
}
@article{Triantafyllou2016233,
title = "A geometric approach to robotic unfolding of garments ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "233 - 243",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.025",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002201",
author = "Dimitra Triantafyllou and Ioannis Mariolis and Andreas Kargakos and Sotiris Malassiotis and Nikos Aspragathos",
keywords = "Garment manipulation",
keywords = "Shape analysis",
keywords = "Unfolding ",
abstract = "Abstract This work presents a novel approach to autonomous unfolding of garments by means of a dual arm robotic manipulator. The proposed approach is based on the observation that a garment can be brought to an approximately planar configuration if it is held by two points on its outline. This step facilitates the detection of another set of points that when grasped the garment will naturally unfold. A robust method for successively detecting such boundary points on images of garments hanging from a single point was developed. The manipulated garment is then laid on a flat surface and matched to a set of foldable templates using shape analysis techniques. Using the established correspondences with the template’s landmark points the garment is re-grasped by such two points that it will naturally unfold in a spread out configuration. The adopted framework has been experimentally evaluated using a dual industrial manipulator and a variety of garments. The produced results indicate the feasibility and robustness of the proposed approach. "
}
@article{Mutz2016439,
title = "Large-scale mapping in complex field scenarios using an autonomous car ",
journal = "Expert Systems with Applications ",
volume = "46",
number = "",
pages = "439 - 462",
year = "2016",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.10.045",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415007496",
author = "Filipe Mutz and Lucas P. Veronese and Thiago Oliveira-Santos and Edilson de Aguiar and Fernando A. Auat Cheein and Alberto Ferreira De Souza",
keywords = "Robotics",
keywords = "Autonomous vehicles",
keywords = "SLAM",
keywords = "GraphSLAM",
keywords = "Mapping ",
abstract = "Abstract In this paper, we present an end-to-end framework for precise large-scale mapping with applications in autonomous driving. In special, the problem of mapping complex environments, with features changing from tree-lined streets to urban areas with dense traffic, is studied. The robotic car is equipped with an odometry sensor, a 3D LiDAR Velodyne HDL-32E, a IMU, and a low cost GPS, and the data generated by these sensors are integrated in a pose-based GraphSLAM estimator. A new strategy for identification and correction of odometry data using evolutionary algorithms is presented. This new strategy makes odometry data significantly more consistent with GPS. Loop closures are detected using \{GPS\} data, and GICP, a 3D point cloud registration algorithm, is used to estimate the displacement between the different travels over the same region. After path estimation, 3D LiDAR data is used to build an occupancy grid mapping of the environment. A detailed mathematical description of how occupancy evidence can be calculated from the point clouds is given, and a submapping strategy to handle memory limitations is presented as well. The proposed framework is tested in three real world environments with different sizes, and features: a parking lot, a university beltway, and a city neighborhood. In all cases, satisfactory maps were built, with precise loop closures even when the vehicle traveled long distances between them. "
}
@article{Paz2013337,
title = "Modelling Saharan dust transport into the Mediterranean basin with \{CMAQ\} ",
journal = "Atmospheric Environment ",
volume = "70",
number = "",
pages = "337 - 350",
year = "2013",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2013.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S1352231013000265",
author = "David de la Paz and Michel Vedrenne and Rafael Borge and Julio Lumbreras and Juan Manuel de Andrés and Javier Pérez and Encarnación Rodríguez and Angeliki Karanasiou and Teresa Moreno and Elena Boldo and Cristina Linares",
keywords = "Air quality modelling",
keywords = "Dust transport",
keywords = "Particulate matter",
keywords = "CMAQ",
keywords = "DEM",
keywords = "SERCA",
keywords = "Remote sensing",
keywords = "AOT",
keywords = "Saharan dust ",
abstract = "The need for a better quantification of the influence of Saharan dust transport processes on the air quality modelling in the Mediterranean basin led to the formulation of a dust emission module (DEM) integrated into the Air Quality Risk Assessment System for the Iberian Peninsula (SERCA). This paper is focused on the formulation of \{DEM\} based on the \{GOCART\} aerosol model, along with its integration and execution into the air quality model. It also addresses the testing of the module and its evaluation by contrasting results against satellite products such as \{MODIS\} and \{CALIPSO\} and ground-level observations of aerosol optical thickness (AOT) and concentration levels of \{PM10\} for different periods in July 2007. \{DEM\} was found capable of reproducing the spatial (horizontal and vertical) and temporal profiles of Saharan dust outbreaks into the Mediterranean basin and the Atlantic coast of Africa. Moreover, it was observed that its combination with \{CMAQ\} increased the correlation degree between observed and modelled \{PM10\} concentrations at the selected monitoring locations. \{DEM\} also enhanced \{CMAQ\} capabilities to reproduce observed AOT, although significant underestimations remain. The implementation of CMAQ + DEM succeeded in capturing Saharan dust transport into the Iberian Peninsula, with contributions up to 25 and 14 μg m−3 in 1 h and 24 h average \{PM10\} respectively. The general improvement of total \{PM10\} predictions in Spain are however moderate. The analysis of model performance for the main \{PM\} components points out that remaining \{PM10\} underestimation is due to dust local sources missing in the inventories and misrepresentation of organic aerosol processes, which constitutes the main areas for future improvement of \{CMAQ\} capabilities to simulate particulate matter within SERCA. "
}
@article{Iocchi2015258,
title = "RoboCup@Home: Analysis and results of evolving competitions for domestic and service robots ",
journal = "Artificial Intelligence ",
volume = "229",
number = "",
pages = "258 - 281",
year = "2015",
note = "",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2015.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0004370215001174",
author = "Luca Iocchi and Dirk Holz and Javier Ruiz-del-Solar and Komei Sugiura and Tijn van der Zant",
keywords = "Robotic competitions",
keywords = "Artificial intelligence and robotics",
keywords = "Benchmarking ",
abstract = "Abstract Scientific competitions are becoming more common in many research areas of artificial intelligence and robotics, since they provide a shared testbed for comparing different solutions and enable the exchange of research results. Moreover, they are interesting for general audiences and industries. Currently, many major research areas in artificial intelligence and robotics are organizing multiple-year competitions that are typically associated with scientific conferences. One important aspect of such competitions is that they are organized for many years. This introduces a temporal evolution that is interesting to analyze. However, the problem of evaluating a competition over many years remains unaddressed. We believe that this issue is critical to properly fuel changes over the years and measure the results of these decisions. Therefore, this article focuses on the analysis and the results of evolving competitions. In this article, we present the RoboCup@Home competition, which is the largest worldwide competition for domestic service robots, and evaluate its progress over the past seven years. We show how the definition of a proper scoring system allows for desired functionalities to be related to tasks and how the resulting analysis fuels subsequent changes to achieve general and robust solutions implemented by the teams. Our results show not only the steadily increasing complexity of the tasks that RoboCup@Home robots can solve but also the increased performance for all of the functionalities addressed in the competition. We believe that the methodology used in RoboCup@Home for evaluating competition advances and for stimulating changes can be applied and extended to other robotic competitions as well as to multi-year research projects involving Artificial Intelligence and Robotics. "
}
@article{Yandun2016457,
title = "Classifying Agricultural Terrain for Machinery Traversability Purposes* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "457 - 462",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.083",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316316469",
author = "Francisco J. Yandun and Eduard Gregorio and Marcos Zúñiga and Alexandre Escolá and Joan R. Rosell-Polo and Fernando A. Auat Cheein",
keywords = "Agricultural robotics",
keywords = "terrain classification",
keywords = "terramechanics modelling",
keywords = "pattern recognition ",
abstract = "Abstract: The detection of the type of soil surface where a robotic vehicle is navigating on is an important issue for performing several agricultural tasks. Satisfactory results in activities such as seeding, plowing, fertilizing, among others depend on a correct identification of the vehicle environment, specially its contact interface with the ground. In the this work, the implementation of a supervised image texture classifier to recognize five different classes of typical agricultural soil surfaces is presented and analysed. The sensing device is the Microsoft Kinect for Windows V2, which allows to acquire RGB, \{IR\} and depth data. Only \{IR\} and depth data were used for the processing, since color information becomes unreliable under different illumination conditions. Two data acquisition modes allowed to validate and to apply the system in real operation conditions. The accuracy of the classifier was assessed under different configuration parameters, obtaining up to 93 percent of success rate, in ideal conditions. Real field conditions were simulated by placing the sensor over a moving wagon, obtaining up to 86 percent of success rate, showing in this way the usability of a low cost sensor such as the Kinect \{V2\} for agricultural robotics. "
}
@article{Mahmoudabadi2016135,
title = "Efficient terrestrial laser scan segmentation exploiting data structure ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "119",
number = "",
pages = "135 - 150",
year = "2016",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616301083",
author = "Hamid Mahmoudabadi and Michael J. Olsen and Sinisa Todorovic",
keywords = "Terrestrial laser scanning",
keywords = "Segmentation",
keywords = "High Dynamic Range imaging",
keywords = "Computer vision",
keywords = "Point cloud",
keywords = "Lidar ",
abstract = "Abstract New technologies such as lidar enable the rapid collection of massive datasets to model a 3D scene as a point cloud. However, while hardware technology continues to advance, processing 3D point clouds into informative models remains complex and time consuming. A common approach to increase processing efficiently is to segment the point cloud into smaller sections. This paper proposes a novel approach for point cloud segmentation using computer vision algorithms to analyze panoramic representations of individual laser scans. These panoramas can be quickly created using an inherent neighborhood structure that is established during the scanning process, which scans at fixed angular increments in a cylindrical or spherical coordinate system. In the proposed approach, a selected image segmentation algorithm is applied on several input layers exploiting this angular structure including laser intensity, range, normal vectors, and color information. These segments are then mapped back to the 3D point cloud so that modeling can be completed more efficiently. This approach does not depend on pre-defined mathematical models and consequently setting parameters for them. Unlike common geometrical point cloud segmentation methods, the proposed method employs the colorimetric and intensity data as another source of information. The proposed algorithm is demonstrated on several datasets encompassing variety of scenes and objects. Results show a very high perceptual (visual) level of segmentation and thereby the feasibility of the proposed algorithm. The proposed method is also more efficient compared to Random Sample Consensus (RANSAC), which is a common approach for point cloud segmentation. "
}
@article{Kumar2016975,
title = "Smart Autonomous Gardening Rover with Plant Recognition Using Neural Networks ",
journal = "Procedia Computer Science ",
volume = "93",
number = "",
pages = "975 - 981",
year = "2016",
note = "Proceedings of the 6th International Conference on Advances in Computing and Communications ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.07.289",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916315356",
author = "V. Sathiesh Kumar and I. Gogul and M. Deepan Raj and S.K. Pragadesh and J. Sarathkumar Sebastin",
keywords = "Intelligent agriculture robotics",
keywords = "floriculture",
keywords = "horticulture",
keywords = "arboriculture",
keywords = "plant recognition methods",
keywords = "neural networks",
keywords = "Internet of things ",
abstract = "Abstract Modernization of our environment (pruning trees for constructing tall buildings) results in climatic changes and ecological imbalance. To mitigate the effect, gardening (to plant trees and shrubs) becomes more and more important than just a hobby. Besides, maintenance of a garden is a tedious process and also time-consuming. Often the gardener lacks in knowledge about the requirements of plant (nutrient and the amount of water to be sprayed) to enhance its growth. In this regard, it is necessary to build an autonomous gardening robotic vehicle which automatically identifies and classifies the plant species using feature extraction algorithms (Scale Invariant Feature Transform (SIFT), Speeded-Up Robust Features (SURF), Oriented \{FAST\} and Rotated \{BRIEF\} (ORB)) and neural networks, respectively. It also measures the key parameters for gardening such as temperature, humidity, heat level, wind speed, wind direction and soil moisture. The data acquired from the on-board sensors of the gardening rover are sent to the cloud storage platform on a regular basis. Based on the acquired data and history, future predictions are made to maintain the garden more effectively and efficiently. A website and an android application are developed for monitoring and controlling the rover from a remote area. This system is a combination of new technologies involving an interdisciplinary approach to carry out precision gardening using Internet of Things (IoT). "
}
@article{Lauer2017,
title = "Benchmarking \{CMIP5\} models with a subset of \{ESA\} \{CCI\} Phase 2 data using the \{ESMValTool\} ",
journal = "Remote Sensing of Environment ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S003442571730007X",
author = "Axel Lauer and Veronika Eyring and Mattia Righi and Michael Buchwitz and Pierre Defourny and Martin Evaldsson and Pierre Friedlingstein and Richard de Jeu and Gerrit de Leeuw and Alexander Loew and Christopher J. Merchant and Benjamin Müller and Thomas Popp and Maximilian Reuter and Stein Sandven and Daniel Senftleben and Martin Stengel and Michel Van Roozendael and Sabrina Wenzel and Ulrika Willén",
keywords = "\{ESA\} CCI",
keywords = "CMIP",
keywords = "Earth system models",
keywords = "Climate",
keywords = "Model evaluation",
keywords = "ESMValTool",
keywords = "Sea surface temperature",
keywords = "Sea ice",
keywords = "Clouds",
keywords = "Soil moisture",
keywords = "Land cover",
keywords = "Aerosols",
keywords = "Ozone",
keywords = "Greenhouse gases",
keywords = "CO2 ",
abstract = "Abstract The Coupled Model Intercomparison Project (CMIP) is now moving into its sixth phase and aims at a more routine evaluation of the models as soon as the model output is published to the Earth System Grid Federation (ESGF). To meet this goal the Earth System Model Evaluation Tool (ESMValTool), a community diagnostics and performance metrics tool for the systematic evaluation of Earth system models (ESMs) in CMIP, has been developed and a first version (1.0) released as open source software in 2015. Here, an enhanced version of the \{ESMValTool\} is presented that exploits a subset of Essential Climate Variables (ECVs) from the European Space Agency's Climate Change Initiative (ESA CCI) Phase 2 and this version is used to demonstrate the value of the data for model evaluation. This subset includes consistent, long-term time series of \{ECVs\} obtained from harmonized, reprocessed products from different satellite instruments for sea surface temperature, sea ice, cloud, soil moisture, land cover, aerosol, ozone, and greenhouse gases. The \{ESA\} \{CCI\} data allow extending the calculation of performance metrics as summary statistics for some variables and add an important alternative data set in other cases where observations are already available. The provision of uncertainty estimates on a per grid basis for the \{ESA\} \{CCI\} data sets is used in a new extended version of the Taylor diagram and provides important additional information for a more objective evaluation of the models. In our analysis we place a specific focus on the comparability of model and satellite data both in time and space. The \{ESA\} \{CCI\} data are well suited for an evaluation of results from global climate models across \{ESM\} compartments as well as an analysis of long-term trends, variability and change in the context of a changing climate. The enhanced version of the \{ESMValTool\} is released as open source software and ready to support routine model evaluation in \{CMIP6\} and at individual modeling centers. "
}
@article{Gao20172,
title = "Through Life Analysis for Machine Tools: From Design to Remanufacture ",
journal = "Procedia \{CIRP\} ",
volume = "59",
number = "",
pages = "2 - 7",
year = "2017",
note = "Proceedings of the 5th International Conference in Through-life Engineering Services Cranfield University, 1st and 2nd November 2016 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.09.027",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309611",
author = "Robert X. Gao and Peng Wang",
keywords = "sustainable manufacturing",
keywords = "life cycle analysis",
keywords = "remanufacture",
keywords = "cloud manufacturing ",
abstract = "Abstract Increasing awareness of environmental burden calls for a sensible transition of manufacturing from the traditional mode where products have only one cycle of service life after being produced to a sustainable mode where multiple cycles of service life are enabled through material recovery, reuse, and remanufacture. As both the means for product generation and a product of modern manufacturing processes, machine tools have been increasingly viewed as a critical element for improving through life and consequently, sustainability. This paper examines the life cycles of machine tools and recent advancement in extending their life cycles. A life cycle is defined as starting from the design, proceeding through the stages of manufacturing and usage, and completing by the end of the service life. Modular design techniques that facilitate the manufacture and assembly of machine tools and analytical methods for reliable machine state estimation and remaining service life prediction are presented. Extension beyond completion of the first service life is enabled by recover and recycle of material from worn/broken machines, and redesign methods that reduce the amount of new materials to be used for making the same product in the subsequent re-manufacturing processes to ultimately realize materials reuse. Opportunities and challenges for sustainable manufacturing in the context of cloud manufacturing are also highlighted. "
}
@article{Borangiu2009299,
title = "Flexible 3D Trajectory Teaching and Following for Various Robotic Applications ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "16",
pages = "299 - 304",
year = "2009",
note = "9th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090909-4-JP-2010.00052",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015306522",
author = "Theodor Borangiu and Alexandru Dumitrache and Anamaria Dogar",
keywords = "Robotic manipulators",
keywords = "trajectory learning",
keywords = "laser range finder",
keywords = "robot vision ",
abstract = "Abstract This paper addresses an actual problem regarding complex industrial robot applications. Based on the fact that no \{CAD\} model for the processed parts is available, the application presented here consists in a 3D accurate path following, applicable in various robot tasks. Using a sensor-based 3D path learning procedure available in automatic or manual mode, the 6 d.o.f industrial robot will be able to reproduce in real-time the learned trajectory. Calibration and synchronization aspects are presented, and experimental results are provided and analyzed. "
}
@article{Watson201667,
title = "Enterprise system case using Microsoft Dynamics \{GP\} via DynamicsCloud ",
journal = "Journal of Accounting Education ",
volume = "37",
number = "",
pages = "67 - 92",
year = "2016",
note = "",
issn = "0748-5751",
doi = "https://doi.org/10.1016/j.jaccedu.2016.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0748575116300215",
author = "Marcia Weidenmier Watson and Bonnie K. Klamm and Joann Segovia and Mark W. Lehman",
keywords = "Cloud application",
keywords = "Enterprise system",
keywords = "Microsoft Dynamics \{GP\} ",
abstract = "Abstract This case increases your understanding of enterprise systems by applying course concepts in an active-learning setting. Specifically, you build on previous course knowledge by using Microsoft Dynamics \{GP\} via a cloud provider, DynamicsCloud. Cloud applications allow companies to reduce information technology costs and use one consistent platform across the entire company, whether they have one or many locations across the globe. The case consists of three main parts (i.e., system overview, data collection and storage, and information retrieval) and integrates internal controls and exercises within each part of the case. Upon completion of this case, you will understand the basic functions of an enterprise system. Activities require you to collect and process data in the revenue and purchasing cycles, identify internal controls within the system, and provide useful information for decision making. In addition, you gain hands-on experience using an enterprise system and acquire skills that transfer to other enterprise systems or to upgraded versions of Dynamics GP, which companies can use to support global operations. The case should increase accounting information system knowledge, system navigation skills, and the ability to learn on your own. "
}
@article{Morariu201626,
title = "Redundancy and scalability for virtualized \{MES\} systems with programmable infrastructure ",
journal = "Computers in Industry ",
volume = "81",
number = "",
pages = "26 - 35",
year = "2016",
note = "Emerging \{ICT\} concepts for smart, safe and sustainable industrial systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2015.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0166361515300415",
author = "Octavian Morariu and Theodor Borangiu and Silviu Raileanu and Cristina Morariu",
keywords = "Private cloud",
keywords = "Virtualization",
keywords = "Smart manufacturing",
keywords = "Redundancy",
keywords = "Programmable infrastructure",
keywords = "COBASA",
keywords = "Event driven ",
abstract = "Abstract Virtualization of manufacturing execution system (vMES) workloads offers a set of design and operational advantages to enterprises, the most visible being improved resource utilization and flexibility of the overall solution. This paper explores redundancy and scalability, as other important operational advantages introduced by the use of private clouds for \{MES\} virtualization in the context of the programmable infrastructure (PI) concept. \{PI\} is a new architectural approach in which the computing infrastructure, represented by resources, networks, storage, becomes dynamic and is controlled by the application, in contrast with traditional architectures where the application has to adapt to a static infrastructure. For \{MES\} applications, the adoption of \{PI\} has the potential to add a new layer of flexibility and optimization by allowing quick configuration and re-configuration based on environmental changes, especially in the context of virtualization in private cloud where workloads can be provisioned and de-provisioned in real time. In this context, this paper presents the main redundancy and scalability requirements for the workloads identified in ISA-95.03 based solutions and discusses in detail the strategies to assure the redundancy and scalability requirements of these workloads both individually and at the system level. The main contributions of this paper are therefore the introduction of \{PI\} combined with private cloud virtualization at the \{MES\} layer in order to achieve redundancy and scalability of the control solution. The pilot implementation presented is based on \{PI\} concepts and is realized in practice using \{SOA\} \{BPEL\} and \{IBM\} CloudBurst \{REST\} APIs. The \{MES\} system considered for the pilot implementation adopts a multi-agent vMES architecture having COBASA-type functionality. The experimental results presented in this paper show the system response in a set of failure scenarios, with focus on the reconfiguration time of workloads, and the dynamic response to perturbations in the system. "
}
@article{Jablkowski201717,
title = "Evolutionary planning of virtualized cyber-physical compute and control clusters ",
journal = "Journal of Systems Architecture ",
volume = "73",
number = "",
pages = "17 - 27",
year = "2017",
note = "Special Issue on Reliable Software Technologies for Dependable Distributed Systems ",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2016.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S138376211630193X",
author = "Boguslaw Jablkowski and Ulrich Thomas Gabor and Olaf Spinczyk",
keywords = "Cyber-physical systems",
keywords = "Virtual machines",
keywords = "Real-time guarantees",
keywords = "Evolutionary algorithms",
keywords = "Formal performance analysis ",
abstract = "Abstract Virtualization technology has the potential to notably advance the automation process in the domain of cyber-physical systems (CPS). It can improve both dependability and availability as well as significantly reduce the procurement, operation and maintenance costs of such systems. However, in the context of virtualization, research has put the most emphasis on topics of hardware utilization and fault-tolerance. There is little literature on how to model, integrate and consolidate a \{CPS\} by means of virtualization. In this paper we present a methodology for planning safe and efficient virtualized cyber-physical compute and control clusters – execution platforms for time-constrained virtual machines (VMs) that encapsulate \{CPS\} applications. We discuss the used methods, describe the corresponding models and the required system architecture. In contrast to typical resource allocation problems from other domains (e.g. cloud computing), in this case, the planning process must take real-time requirements of applications into account. In order to achieve this, we combine evolutionary algorithms with formal system performance analysis – in particular algorithms considered in classical scheduling theory. Such an approach allows not only to optimally dimension the compute and control clusters, but also provides strict guarantees regarding the timing predictability of the integrated CPS. Further, the embedment of a formal performance analysis technique notably eases the modeling of a system. As a consequence, the modeling process is fast, flexible and accessible not only to experts but also to system designers as they do not have to struggle with complex and time consuming mathematical formulations. Finally, our approach also provides answers to several practical questions that arise when integrating a \{CPS\} by means of virtualization. "
}
@article{Fischinger201660,
title = "Hobbit, a care robot supporting independent living at home: First prototype and lessons learned ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part A",
number = "",
pages = "60 - 78",
year = "2016",
note = "Assistance and Service Robotics in a Human Environment ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014002140",
author = "David Fischinger and Peter Einramhof and Konstantinos Papoutsakis and Walter Wohlkinger and Peter Mayer and Paul Panek and Stefan Hofmann and Tobias Koertner and Astrid Weiss and Antonis Argyros and Markus Vincze",
keywords = "Social robotics",
keywords = "Robots for elderly",
keywords = "Care robot for independent living ",
abstract = "Abstract One option to address the challenge of demographic transition is to build robots that enable aging in place. Falling has been identified as the most relevant factor to cause a move to a care facility. The Hobbit project combines research from robotics, gerontology, and human–robot interaction to develop a care robot which is capable of fall prevention and detection as well as emergency detection and handling. Moreover, to enable daily interaction with the robot, other functions are added, such as bringing objects, offering reminders, and entertainment. The interaction with the user is based on a multimodal user interface including automatic speech recognition, text-to-speech, gesture recognition, and a graphical touch-based user interface. We performed controlled laboratory user studies with a total of 49 participants (aged 70 plus) in three \{EU\} countries (Austria, Greece, and Sweden). The collected user responses on perceived usability, acceptance, and affordability of the robot demonstrate a positive reception of the robot from its target user group. This article describes the principles and system components for navigation and manipulation in domestic environments, the interaction paradigm and its implementation in a multimodal user interface, the core robot tasks, as well as the results from the user studies, which are also reflected in terms of lessons we learned and we believe are useful to fellow researchers. "
}
@article{Nabil201537,
title = "Soft material modeling for robotic task formulation and control in the muscle separation process ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "32",
number = "",
pages = "37 - 53",
year = "2015",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000787",
author = "Essahbi Nabil and Bouzgarrou Belhassen-Chedli and Gogu Grigore",
keywords = "Robotized anatomical cutting",
keywords = "Soft material dynamical modeling",
keywords = "Dynamic trajectory generation ",
abstract = "Abstract This paper introduces a global approach for the muscle separation process in the meat industry by using a multi-arm robotic system. Process control is based on both physical modeling of soft material and vision perception. Mechanical models appropriate for real-time applications are examined and compared through simulation results. In order to take into account material anisotropy, a new formulation based on mass-spring discretization, is proposed. While geometrical model construction uses \{MRI\} techniques, physical parameters are determined by the use of rheological tests. The cutting model for muscle separation is therefore considered through three approaches based on knife position, pull-off strength and experimental cutting forces. In order to generate robotic cutting tasks, a new algorithm using the curvature estimation of a 3D surface mesh is introduced. This enables the cutting-tool path generation and updating. "
}
@incollection{King20081932,
title = "\{ROBOTIC\} \{ARCHAEOLOGY\} \{ON\} \{THE\} \{DEEP\} \{OCEAN\} \{FLOOR\} ",
editor = "Pearsall, Deborah M. ",
booktitle = "Encyclopedia of Archaeology ",
publisher = "Academic Press",
edition = "",
address = "New York",
year = "2008",
pages = "1932 - 1940",
isbn = "978-0-12-373962-9",
doi = "https://doi.org/10.1016/B978-012373962-9.00434-9",
url = "http://www.sciencedirect.com/science/article/pii/B9780123739629004349",
author = "Thomas F. King",
keywords = "Archaeology",
keywords = "Deep ocean",
keywords = "Ethics",
keywords = "Remotely operated vehicles",
keywords = "Remote sensing",
keywords = "Robotic Shipwreck",
keywords = "Salvage",
keywords = "Submersible",
keywords = "Technology ",
abstract = "Technology developed by the military, the telecommunications industry, and oil and gas interests has been adapted to allow the conduct of high-precision archaeological survey and excavation on the deep ocean floor, hundreds of meters below the surface. Side-scan sonar and other exploration tools can be used to map the distribution of anomalies on the sea bed, which then can be inspected using deep-diving robotic submersibles. Sites of interest, such as shipwrecks, can be excavated using remotely operated vehicles (ROVs) controlled by archaeologists in control ships on the surface. This technology is very expensive to be within the budgets of many museums and academic institutions; it is employed for archaeological purposes by a small number of commercial shipwreck exploration firms. Since these firms typically market some of the material they recover, most mainstream archaeologists have ethical difficulty cooperating with them, but some positive working relationships have been developed. If deep ocean archaeology is to continue, such relationships will probably have to become more common place. "
}
@article{Fang2016367,
title = "A framework for real-time pro-active safety assistance for mobile crane lifting operations ",
journal = "Automation in Construction ",
volume = "72, Part 3",
number = "",
pages = "367 - 379",
year = "2016",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2016.08.025",
url = "http://www.sciencedirect.com/science/article/pii/S0926580516301807",
author = "Yihai Fang and Yong K. Cho and Jingdao Chen",
keywords = "Crane safety",
keywords = "Human error",
keywords = "Real-time",
keywords = "Crane motion capturing",
keywords = "Collision hazard analysis",
keywords = "3D reconstruction",
keywords = "Point cloud ",
abstract = "Abstract Despite many safety considerations addressed in lift pre-planning, the ability to provide real-time safety assistance to crane operators and to mitigate human errors during the lifting operation is missing. This research developed a framework for real-time pro-active safety assistance for mobile crane lifting operations. First, crane poses are reconstructed in real-time based on the critical motions of crane parts captured by a sensor system. Second, as-is lift site conditions are automatically modeled and updated based on point cloud data. Lastly, the risk of colliding the crane parts and lifted load into nearby obstructions is pro-actively analyzed and warnings are provided to the operator through a graphical user interface. A prototype system was developed based on the framework and deployed on a mobile crane. Field test results indicate that the system can accurately reconstruct crane motion in real-time and provide pro-active warnings that allow the operator to make timely decisions to mitigate the risk. "
}
@article{Wang201771,
title = "Pedestrian recognition and tracking using 3D LiDAR for autonomous vehicle ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "71 - 78",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.014",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302633",
author = "Heng Wang and Bin Wang and Bingbing Liu and Xiaoli Meng and Guanghong Yang",
keywords = "Pedestrian recognition and tracking",
keywords = "Point clouds",
keywords = "Hash table",
keywords = "GUI design ",
abstract = "Abstract This paper studies the pedestrian recognition and tracking problem for autonomous vehicles using a 3D LiDAR, a classifier trained by \{SVM\} (Support Vector Machine) is used to recognize pedestrians, the recognition performance is further improved with the aid of tracking results. By comparing positions and velocity directions of pedestrians with curb information, alarms will be generated if pedestrians are detected to be on road or close to curbs. The proposed approach has been verified on an autonomous vehicle platform. "
}
@article{Scardapane201742,
title = "A framework for parallel and distributed training of neural networks ",
journal = "Neural Networks ",
volume = "91",
number = "",
pages = "42 - 54",
year = "2017",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0893608017300849",
author = "Simone Scardapane and Paolo Di Lorenzo",
keywords = "Neural network",
keywords = "Distributed learning",
keywords = "Parallel computing",
keywords = "Networks ",
abstract = "Abstract The aim of this paper is to develop a general framework for training neural networks (NNs) in a distributed environment, where training data is partitioned over a set of agents that communicate with each other through a sparse, possibly time-varying, connectivity pattern. In such distributed scenario, the training problem can be formulated as the (regularized) optimization of a non-convex social cost function, given by the sum of local (non-convex) costs, where each agent contributes with a single error term defined with respect to its local dataset. To devise a flexible and efficient solution, we customize a recently proposed framework for non-convex optimization over networks, which hinges on a (primal) convexification–decomposition technique to handle non-convexity, and a dynamic consensus procedure to diffuse information among the agents. Several typical choices for the training criterion (e.g., squared loss, cross entropy, etc.) and regularization (e.g.,  ℓ 2 norm, sparsity inducing penalties, etc.) are included in the framework and explored along the paper. Convergence to a stationary solution of the social non-convex problem is guaranteed under mild assumptions. Additionally, we show a principled way allowing each agent to exploit a possible multi-core architecture (e.g., a local cloud) in order to parallelize its local optimization step, resulting in strategies that are both distributed (across the agents) and parallel (inside each agent) in nature. A comprehensive set of experimental results validate the proposed approach. "
}
@article{Zamuda201693,
title = "Constrained differential evolution optimization for underwater glider path planning in sub-mesoscale eddy sampling ",
journal = "Applied Soft Computing ",
volume = "42",
number = "",
pages = "93 - 118",
year = "2016",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2016.01.038",
url = "http://www.sciencedirect.com/science/article/pii/S1568494616300266",
author = "Aleš Zamuda and José Daniel Hernández Sosa and Leonhard Adler",
keywords = "Differential evolution",
keywords = "Constraint handling",
keywords = "Underwater robotics",
keywords = "Underwater glider path planning",
keywords = "Sub-mesoscale ocean eddy sampling ",
abstract = "Abstract This paper presents an approach for tackling constrained underwater glider path planning (UGPP), where the feasible path area is defined as a corridor around the border of an ocean eddy. The objective of the glider here is to sample the oceanographic variables more efficiently while keeping a bounded trajectory. Therefore, we propose a solution based on differential evolution (DE) algorithm mechanisms, including in its configuration self-adaptation of control parameters, population size reduction, ϵ-constraint handling with adjustment, and mutation based on elitistic best vector. Different aspects of this \{DE\} configuration are studied for the constrained \{UGPP\} challenge, on a prepared benchmark set comprised of 28 different specialized scenarios. The \{DE\} configurations were tested over a benchmark set over 51 independent runs for each \{DE\} configuration aspect. Comparison and suitability for the combination of these mechanisms is reported, through the per-scenario and aggregated statistical performance differences, including different constraint handling definition strategies, different \{DE\} mutation strategies’ configurations, and population sizing parameterizations. Our proposed solution outranked all other compared algorithms, keeping a trajectory within the limits with 100% success rate in all physically feasible scenarios; on average, it improved the randomly initialized trajectories fitness by roughly 50%, even reaching perfect fitness (all-around, 360-degree eddy corridor sampling) in some scenarios. "
}
@article{Li2017183,
title = "SeeMore: A kinetic parallel computer sculpture for educating broad audiences on parallel computation ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "105",
number = "",
pages = "183 - 199",
year = "2017",
note = "Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing ",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2017.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0743731517300230",
author = "Bo Li and John Mooring and Sam Blanchard and Aditya Johri and Melinda Leko and Kirk W. Cameron",
keywords = "Parallel and distributed computing",
keywords = "Kinetic art",
keywords = "Computer science education ",
abstract = "Abstract We discuss the design, implementation, and evaluation of a 256-node Raspberry-Pi cluster with kinetic properties. Each compute node is attached to a servo mechanism such that movement results from local computation. The result is SeeMore, a kinetic parallel computer sculpture designed to enable visualization of parallel algorithms in an effort to educate broad audiences as to the beauty, complexity, and importance of parallel computation. The algorithms and interfaces were implemented by students from various related courses at \{VA\} Tech. We describe these designs in sufficient detail to enable others to build their own kinetic computing sculptures to augment their experiential learning programs. Our evaluations at exhibitions indicate 63% and 84% of visitors enjoyed interacting with SeeMore while 69% and 87% believed SeeMore has educational value. "
}
@article{Tsai2006134,
title = "Recognition of quadratic surface of revolution using a robotic vision system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "22",
number = "2",
pages = "134 - 143",
year = "2006",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2005.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584505000268",
author = "Ming J. Tsai and Jia H. Hwung and Tien-Fu Lu and Hung-Yao Hsu",
keywords = "Reverse engineering",
keywords = "Robotic vision",
keywords = "Feature recognition",
keywords = "Quadratic surface",
keywords = "Curve fitting",
keywords = "Image process ",
abstract = "Reverse engineering using 3D scanners has been gaining increasing popularity. One challenging task that remains is to recognize the geometric feature from the cloud data scanned. In this study, a robotic vision system is used to recognize quadratic surfaces of revolution on an object. The top-view image of an object is used to detect the surface boundary by loop analysis technique. The boundary of a single surface is extracted according to the 2D loop of that surface. The robot then projects laser lines through the principal axes of the loop to get the sectional curves. The surface is recognized by a curve-fitting method based on the characteristics of these curves. This study provides a simple and faster method to detect the manufacture features on an object that contains quadratic surfaces. The data structure can be output in \{IGES\} format for re-design or rapid manufacture of the object. "
}
@incollection{Kala201611,
title = "2 - Basics of Autonomous Vehicles ",
editor = "Kala, Rahul ",
booktitle = "On-Road Intelligent Vehicles ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2016",
pages = "11 - 35",
isbn = "978-0-12-803729-4",
doi = "https://doi.org/10.1016/B978-0-12-803729-4.00002-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128037294000027",
author = "Rahul Kala",
keywords = "Autonomous vehicles",
keywords = "Control",
keywords = "Intelligent vehicles",
keywords = "Localization",
keywords = "Mobile robotics",
keywords = "Motion planning",
keywords = "Sensing",
keywords = "Vision ",
abstract = "Abstract The technology behind autonomous vehicles is interesting and challenging. The chapter, in a nutshell, discusses the complete technology and shows how autonomous vehicles get the capability to navigate autonomously in traffic scenarios. The hardware of autonomous vehicles, from a computational perspective, consists of sensors including vision cameras, RADARs, ultrasonics and LIDARs, along with an Inertial Measurement Unit and motion encoders to enable the vehicles estimate the position. The vehicles are driven with the help of steering, brake and throttle using the drive-by-wire technology which facilitates driving using computer programmes. The vision systems are responsible for looking at the operational scenario and making inferences, which are used to make the map of the world by a mapping module. The localization module uses the vision and map information to estimate the vehicle's pose. Motion-planning algorithms do all the decision-making including computing trajectories for operation, which are followed by using control algorithms. "
}
@article{Servos2017247,
title = "Multi-Channel Generalized-ICP: A robust framework for multi-channel scan registration ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "247 - 257",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016306790",
author = "James Servos and Steven L. Waslander",
keywords = "Scan registration",
keywords = "RGBD point clouds ",
abstract = "Abstract Current state of the art scan registration algorithms which use only position information often fall victim to correspondence ambiguity and degeneracy in the optimization solutions. Other methods which use additional channels, such as color or intensity, often use only a small fraction of the available information and ignore the underlying structural information of the added channels. The proposed method incorporates the additional channels directly into the scan registration formulation to provide information within the plane of the surface. This is achieved by calculating the uncertainty both along and perpendicular to the local surface at each point and calculating nearest neighbor correspondences in the higher dimensional space. The proposed method reduces instances of degenerate transformation estimates and improves both registration accuracy and convergence rate. The method is tested on the Ford Vision and Lidar dataset using both color and intensity channels, as well as with Microsoft Kinect data from the Freiburg \{RGBD\} Office dataset and data obtained from the University of Waterloo campus. "
}
@article{Hoffmann2014833,
title = "Adaptive robotic tool use under variable grasps ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "833 - 846",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000244",
author = "Heiko Hoffmann and Zhichao Chen and Darren Earl and Derek Mitchell and Behnam Salemi and Jivko Sinapov",
keywords = "Grasping",
keywords = "Manipulation",
keywords = "Computer vision",
keywords = "Tactile sense",
keywords = "Kinematics",
keywords = "Adaptive systems ",
abstract = "Abstract Successful robotic manipulation of human tools will greatly advance robotic collaboration with humans in manufacturing and robotic assistance in human environments, e.g., in hospitals, offices, and homes. In these settings, the robot needs to grasp a tool (e.g., a drill) before using it, rather than rely on the tool being firmly attached to the robot’s end effector. Thus, when using the tool, the robot has to account for the uncertainty in the hand-tool interface, since the grasp will vary between trials. To address this challenge, we propose a new framework in which control-relevant parameters are extracted about the uncertain interface between palm and tool tip. Our approach allows a robot to control position and force at the tool tip using either visual or tactile feedback. In addition, the proposed framework allows a robot to move the tip of a tool along a surface, despite uncertainty about how the tool is held in the hand and uncertainty about the structure of the surface. We demonstrated the feasibility of our new approach on two robotic platforms: the \{DARPA\} \{ARM\} robot operating a hand-held drill and an \{ST\} Robotics \{R17\} robot drawing with a pencil. "
}
@article{RuizSarmiento20158805,
title = "Scene object recognition for mobile robots through Semantic Knowledge and Probabilistic Graphical Models ",
journal = "Expert Systems with Applications ",
volume = "42",
number = "22",
pages = "8805 - 8816",
year = "2015",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.07.033",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415004935",
author = "José-Raúl Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Object recognition",
keywords = "Semantic Knowledge",
keywords = "Probabilistic Graphical Models",
keywords = "Mobile robotics",
keywords = "Expert systems",
keywords = "Autonomous agents ",
abstract = "Abstract Scene object recognition is an essential requirement for intelligent mobile robots. In addition to geometric or appearance features, modern recognition systems strive to incorporate contextual information, normally modelled through Probabilistic Graphical Models (PGMs) or Semantic Knowledge (SK). However, these approaches, separately, show some weaknesses that limit their application, e.g., the exponential complexity of the probabilistic inference over \{PGMs\} or the inability of \{SK\} to handle uncertainty. This paper presents a hybrid PGM-SK system for object recognition that integrates both techniques reducing their individual limitations and gaining in probabilistic inference efficiency, performance robustness, uncertainty handling, and providing coherent results according to domain knowledge codified by a human expert. We support this claim with an extensive experimental evaluation according to both recognition success and time requirements in real scenarios from two datasets (NYU2 and UMA-offices). The yielded figures support the suitability of the hybrid PGM-SK recognition system, and its applicability to mobile robotic agents. "
}
@article{Quintana2016643,
title = "Semantic scan planning for indoor structural elements of buildings ",
journal = "Advanced Engineering Informatics ",
volume = "30",
number = "4",
pages = "643 - 659",
year = "2016",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2016.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S1474034616300453",
author = "B. Quintana and S.A. Prieto and A. Adán and A.S. Vázquez",
keywords = "Large-scale 3D scanning",
keywords = "Automatic 3D acquisition",
keywords = "Dense 3D reconstruction",
keywords = "Next best view in 3D environments",
keywords = "Large point cloud processing ",
abstract = "Abstract The objective of this paper is to propose a new semantic 3D data acquisition method which is focused on sensing data belonging to indoor structural elements of buildings. Our system uses and processes 3D information coming from a 3D laser scanner sensor. The presented approach deals with some essential key issues in the scanning world which are rarely dealt with in papers. These are: the final goal of the scanning process, the hypotheses about the scene, lack of dynamic spaces in the next-best-scan-based solutions and the quality evaluation of the data sensed. Whereas most of the Next Best Scan (NBS) based approaches do not discriminate between data and clutter, we propose a scanning process in which potential structural elements of building indoors are learned as a new scan arrives. Our workspace is not a priori hypothesized, but a dynamic space which is updated as a new scan is added. This allows us to deal with more complex shape scenarios (i.e. concave-shaped spaces). Through the so called Structural Element (SE) membership probability, we introduce the data-quality concept in the scanning process which highly reduces the point cloud to be processed. This system has been tested in inhabited indoors and has yielded promising results. An experimental comparison with three close techniques is presented in an extended and detailed experimental section. The results yielded from our experimental work demonstrate the quality and validity of the proposed method. "
}
@article{Bausch2016583,
title = "3D Printing onto Unknown Uneven Surfaces* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "21",
pages = "583 - 590",
year = "2016",
note = "7th \{IFAC\} Symposium on Mechatronic Systems \{MECHATRONICS\} 2016Loughborough University, Leicestershire, UK, 5—8 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.664",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316322765",
author = "Nils Bausch and David P. Dawkins and Regina Frei and Susanne Klein",
keywords = "3D printing",
keywords = "3D scanning",
keywords = "conformal printing",
keywords = "sensors",
keywords = "robotics",
keywords = "control",
keywords = "mechatronic system ",
abstract = "Abstract: Since its inception, 3D printing has seen a wide area of applications, but a general approach to printing onto unknown objects has not been tackled yet. Nowadays 3D scanning technology can be used for reverse engineering. Multiple axis machines enable the creation of object layers at diferent deposition angles, and printing on uneven surfaces is achieved by conformal printing. In this paper, a new methodology is presented, which combines 3D scanning, multiple axis 3D printing, and conformal printing to create an afordable 3D printing system, which can deposit material onto a priori unknown uneven objects. A prototype system was developed, which can print a frst layer on top of a previously unknown object. The creation of further layers is work in progress. The application areas for such a method could include repairing structures, product customization, printing security features on existing objects, adding functionality by, for example, printing antennas on items, and modifying prosthetics to fit individual patients. "
}
@article{Chen2017126,
title = "Ubiquitous manufacturing: Current practices, challenges, and opportunities ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "126 - 132",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516300175",
author = "Toly Chen and Horng-Ren Tsai",
keywords = "Ubiquitous computing",
keywords = "Ubiquitous manufacturing",
keywords = "Cyberphysical system",
keywords = "Sensor",
keywords = "Industry 4.0 ",
abstract = "Abstract Ubiquitous manufacturing (UM) features a “design anywhere, make anywhere, sell anywhere, and at any time” paradigm that grants factories an unlimited production capacity and permanent manufacturing service availability. However, the research and applications of \{UM\} have been limited thus far to in-factory operations or logistics. For this reason, this study reviews the current practices of UM, discusses the challenges faced by researchers and practitioners, and determines potential opportunities for \{UM\} in the near future. Finally, we conclude that the success of \{UM\} depends on the quality of the manufacturing services deployed, and that \{UM\} is a realizable target for Industry 4.0. "
}
@article{Rocha2014605,
title = "Object recognition and pose estimation for industrial applications: A cascade system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "30",
number = "6",
pages = "605 - 621",
year = "2014",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000313",
author = "Luís F. Rocha and Marcos Ferreira and V. Santos and A. Paulo Moreira",
keywords = "Pattern recognition",
keywords = "Flexible manufacturing",
keywords = "Autonomous systems",
keywords = "Robotics",
keywords = "Spray coating ",
abstract = "Abstract The research work presented in this paper focuses on the development of a 3D object localization and recognition system to be used in robotics conveyor coating lines. These requirements were specified together with enterprises with small production series seeking a full robotic automation of their production line that is characterized by a wide range of products in simultaneous manufacturing. Their production process (for example heat or coating/painting treatments) limits the use of conventional identification systems attached to the object in hand. Furthermore, the mechanical structure of the conveyor introduces geometric inaccuracy in the object positioning. With the correct classification and localization of the object, the robot will be able to autonomously select the right program to execute and to perform coordinate system corrections. A cascade system performed with Support Vector Machine and the Perfect Match (point cloud geometric template matching) algorithms was developed for this purpose achieving 99.5% of accuracy. The entire recognition and pose estimation procedure is performed in a maximum time range of 3 s with standard off the shelf hardware. It is expected that this work contributes to the integration of industrial robots in highly dynamic and specialized production lines. "
}
@article{Viejo2014174,
title = "Combining visual features and Growing Neural Gas networks for robotic 3D \{SLAM\} ",
journal = "Information Sciences ",
volume = "276",
number = "",
pages = "174 - 185",
year = "2014",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.02.053",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514001595",
author = "Diego Viejo and Jose Garcia-Rodriguez and Miguel Cazorla",
keywords = "GNG",
keywords = "SLAM",
keywords = "3D registration ",
abstract = "Abstract The use of 3D data in mobile robotics provides valuable information about the robot’s environment. Traditionally, stereo cameras have been used as a low-cost 3D sensor. However, the lack of precision and texture for some surfaces suggests that the use of other 3D sensors could be more suitable. In this work, we examine the use of two sensors: an infrared \{SR4000\} and a Kinect camera. We use a combination of 3D data obtained by these cameras, along with features obtained from 2D images acquired from these cameras, using a Growing Neural Gas (GNG) network applied to the 3D data. The goal is to obtain a robust egomotion technique. The \{GNG\} network is used to reduce the camera error. To calculate the egomotion, we test two methods for 3D registration. One is based on an iterative closest points algorithm, and the other employs random sample consensus. Finally, a simultaneous localization and mapping method is applied to the complete sequence to reduce the global error. The error from each sensor and the mapping results from the proposed method are examined. "
}
@incollection{Luxton20161,
title = "Chapter 1 - An Introduction to Artificial Intelligence in Behavioral and Mental Health Care ",
editor = "Luxton, David D. ",
booktitle = "Artificial Intelligence in Behavioral and Mental Health Care ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2016",
pages = "1 - 26",
isbn = "978-0-12-420248-1",
doi = "https://doi.org/10.1016/B978-0-12-420248-1.00001-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780124202481000015",
author = "David D. Luxton",
keywords = "Artificial intelligence",
keywords = "behavioral health",
keywords = "mental health",
keywords = "health care",
keywords = "expert systems",
keywords = "virtual reality",
keywords = "robotics",
keywords = "virtual intelligent agents ",
abstract = "Artificial intelligence (AI) technologies and techniques have useful purposes in just about every domain of behavioral and mental health care including clinical decision-making, treatments, assessment, self-care, healthcare management, research and more. This introductory chapter provides an overview of \{AI\} and includes definitions of common terms and concepts to provide a foundation for what is discussed in subsequent chapters. Recent technological innovations are highlighted to demonstrate emerging capabilities and forthcoming opportunities. The benefits of the use of \{AI\} in mental health care are also discussed. "
}
@article{Stefas201610,
title = "Vision-Based \{UAV\} Navigation in Orchards* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "10 - 15",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315646",
author = "Nikolaos Stefas and Haluk Bayram and Volkan Isler",
keywords = "Vision-based navigation",
keywords = "Unmanned Aerial Vehicles",
keywords = "Agricultural Robotics ",
abstract = "Abstract: Unmanned Aerial Vehicles (UAV) are becoming increasingly common in agricultural applications. Currently, they are primarily used to fly over fields in open space. Navigation inside orchard-like environments remains challenging. We study the problem of orchard navigation with cameras on an aerial vehicle. We study both the controller and the vision component. For the vision component, we provide two methods for detecting orchard rows with frontal facing cameras. In the monocular case, we present a pipeline to extract the geometry of tree rows when there is a well defined path structure. In the binocular case, we present a depth-based navigation algorithm to extract the rows. For the controller component, we design a controller that uses both frontal and downward facing cameras and provides reliable performance even on the presence of strong wind disturbances. "
}
@article{Pereira2016326,
title = "Self calibration of multiple \{LIDARs\} and cameras on autonomous vehicles ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "326 - 337",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300173",
author = "Marcelo Pereira and David Silva and Vitor Santos and Paulo Dias",
keywords = "Extrinsic calibration",
keywords = "Point cloud",
keywords = "3D data fitting ",
abstract = "Abstract Autonomous navigation is an important field of research and, given the complexity of real world environments, most of the systems rely on a complex perception system combining multiple sensors on board, which reinforces the concern of sensor calibration. Most calibration methods rely on manual or semi-automatic interactive procedures, but reliable fully automatic methods are still missing. However, if some simple objects could be detected and identified automatically by all the sensors from several points of view, then automatic calibration would be possible on the fly. The idea proposed in this paper is to use a ball in motion in front of a set of uncalibrated sensors allowing them to detect its center along the successive positions. This set of centers generates a point cloud per sensor, which, by using segmentation and fitting techniques, allows the calculation of the rigid body transformation among all pairs of sensors. This paper proposes and describes such a method with results demonstrating its validity. "
}
@article{Carlson2016389,
title = "Robot Station Optimization for Minimizing Dress Pack Problems ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "389 - 394",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.01.022",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116000342",
author = "Johan S. Carlson and Jonas Kressin and Tomas Hermansson and Robert Bohlin and Mathias Sundbäck and Henri Hansson",
keywords = "automation",
keywords = "simulation",
keywords = "motion planning",
keywords = "optimization",
keywords = "robotics and dress packs ",
abstract = "Abstract Problems with robot dress packs are one of the major reasons for online adjustments of robot motions and for down time in robot stations. A factory study showed that many robots wear out more than one dress pack per year. The life length variation was in fact shown considerable, ranging from years to only months. The dress packs consist of attached cables and hoses which typically have significant impact on allowed robot configurations and motions in the station. In this paper, we present novel simulation methods for improving robot configurations and motions during off-line programming and optimization of robot stations. The proposed method is applied to a stud welding station resulting in the elimination of several problems related to the dress packs. "
}
@article{Hassaan201616,
title = "Precision Forestry: Trees Counting in Urban Areas Using Visible Imagery based on an Unmanned Aerial Vehicle ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "16 - 21",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315658",
author = "Omair Hassaan and Ahmad Kamal Nasir and Hubert Roth and M. Fakhir Khan",
keywords = "Precision Forestry",
keywords = "Robotics",
keywords = "Vision",
keywords = "UAV ",
abstract = "Abstract: This research work describes an approach to count trees in an urban environment. Furthermore it addresses the problems involved in detection of trees in aerial imagery. This work can be used to solve the problem of forest degradation and deforestation. Right now forest man labor isn’t efficient enough to detect or prevent this problem. A multi-rotor \{UAV\} equipped with high resolution \{RGB\} camera was used to acquire aerial images and to count number of trees in surveyed area. Various issues involved in the robust implementation of proposed algorithm are discussed. The result of successful implementation of the proposed algorithm on multiple scenarios are also presented and we show that our naive approach is able to achieve ≈ 0.72 accuracy within reasonable amount of time. "
}
@incollection{Salgues2016161,
title = "12 - The Technologies that Could Change Everything ",
editor = "Salgues, Bruno ",
booktitle = "Health Industrialization ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2016",
pages = "161 - 184",
isbn = "978-1-78548-147-5",
doi = "https://doi.org/10.1016/B978-1-78548-147-5.50012-6",
url = "http://www.sciencedirect.com/science/article/pii/B9781785481475500126",
author = "Bruno Salgues",
keywords = "Artificial zeolites",
keywords = "Biometry",
keywords = "Biotechnology",
keywords = "3D printing",
keywords = "Graphene",
keywords = "Information technology",
keywords = "Nanoproducts",
keywords = "Nanosystems",
keywords = "Patient’s data",
keywords = "Robotics ",
abstract = "Abstract: The technologies with the potential to “change everything” have to do with substitution or switching approaches. "
}
@article{Haidegger20131215,
title = "Applied ontologies and standards for service robots ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1215 - 1223",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S092188901300105X",
author = "Tamás Haidegger and Marcos Barreto and Paulo Gonçalves and Maki K. Habib and Sampath Kumar Veera Ragavan and Howard Li and Alberto Vaccarella and Roberta Perrone and Edson Prestes",
keywords = "Service robotics",
keywords = "Robot ontologies",
keywords = "Robot standards",
keywords = "Human–robot interaction ",
abstract = "Abstract Service robotics is an emerging application area for human-centered technologies. The rise of household and personal assistance robots forecasts a human–robot collaborative society. One of the robotics community’s major task is to streamline development trends, work on the harmonization of taxonomies and ontologies, along with the standardization of terms, interfaces and technologies. It is important to keep the scientific progress and public understanding synchronous, through efficient outreach and education. These efforts support the collaboration among research groups, and lead to widely accepted standards, beneficial for both manufacturers and users. This article describes the necessity of developing robotics ontologies and standards focusing on the past and current research efforts. In addition, the paper proposes a roadmap for service robotics ontology development. The \{IEEE\} Robotics &amp; Automation Society is sponsoring the working group Ontologies for Robotics and Automation. The efforts of the Working group are presented here, aiming to connect the cutting edge technology with the users of these services—the general public. "
}
@article{Shao2011181,
title = "Dust cycle: An emerging core theme in Earth system science ",
journal = "Aeolian Research ",
volume = "2",
number = "4",
pages = "181 - 204",
year = "2011",
note = "",
issn = "1875-9637",
doi = "https://doi.org/10.1016/j.aeolia.2011.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S1875963711000085",
author = "Yaping Shao and Karl-Heinz Wyrwoll and Adrian Chappell and Jianping Huang and Zhaohui Lin and Grant H. McTainsh and Masao Mikami and Taichu Y. Tanaka and Xulong Wang and Soonchang Yoon",
keywords = "Dust",
keywords = "Dust cycle",
keywords = "Aeolian processes",
keywords = "Energy cycle",
keywords = "Carbon cycle",
keywords = "Climate change ",
abstract = "The dust cycle is an integral part of the Earth system. Each year, an estimated 2000 Mt dust is emitted into the atmosphere, 75% of which is deposited to the land and 25% to the ocean. The emitted and deposited dust participates in a range physical, chemical and bio-geological processes that interact with the cycles of energy, carbon and water. Dust profoundly affects the energy balance of the Earth system, carries organic material, contributes directly to the carbon cycle and carries iron which is vital to ocean productivity and the ocean-atmosphere \{CO2\} exchange. A deciphering of dust sources, transport and deposition, requires an understanding of the geological controls and climate states – past, present and future. While our knowledge of the dust cycle, its impacts and interactions with the other global-scale bio-geochemical cycles has greatly advanced in the last 30 years, large uncertainties and knowledge gaps still exist. In this review paper, we attempt to provide a benchmark of our present understanding, identify the needs and emphasise the importance of placing the dust issue in the Earth system framework. Our review focuses on (i) the concept of the dust cycle in the context of global biogeochemical cycles; (ii) dust as a climate indicator; (iii) dust modelling; (iv) dust monitoring; and (v) dust parameters. The adoption of a quantitative and global perspective of the dust cycle, underpinned by a deeper understanding of its physical controls, will lead to the reduction of the large uncertainties which presently exist in Earth system models. "
}
@article{Borrmann2015105,
title = "Evaluation of Methods for Robotic Mapping of Cultural Heritage Sites ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "10",
pages = "105 - 110",
year = "2015",
note = "2nd \{IFAC\} Conference on Embedded Systems, Computer Intelligence and Telematics \{CESCIT\} 2015Maribor, Slovenia, 22-24 June 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.08.116",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315009830",
author = "Dorit Borrmann and Robin Hess and Daniel Eck and Hamidreza Houshiar and Andreas Nüchter and Klaus Schilling",
keywords = "laser scanning",
keywords = "3D modeling",
keywords = "multi-sensors ",
abstract = "Abstract In archaeological studies the use of new technologies has moved into focus in the past years creating new challenges such as the processing of the massive amounts of data. In this paper we present steps and processes for smart 3D modelling of environments by use of the mobile robot Irma3D. A robot that is equipped with multiple sensors, most importantly a photo camera and a laser scanner, enables the automation of most of the processes, including data acquisition and registration. The robot was tested in the Würzburg Residence. Methods for automatic 3D color reconstructions of cultural heritage sites are evaluated in this paper. "
}
@article{Sanz20158,
title = "A benchmarking perspective of underwater intervention systems★ ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "8 - 13",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002414",
author = "P.J. Sanz and J. Pérez and J. Sales and A. Peñalver and J.J. Fernández and D. Fornas and R. Marín and J.C. Garcia",
keywords = "Underwater simulator",
keywords = "Benchmarking",
keywords = "Underwater intervention",
keywords = "Robotics ",
abstract = "Abstract This paper presents recent progress concerning benchmarking issues in the underwater robotics manipulation context. After a very intensive 6-years period of work, under several funding research projects, all of them in the aforementioned area, a strong know-how has been developed. As part of this expertise, a new underwater simulation tool has been implemented. This platform enables the integration, simulation, comparative analysis and experimentation on real data and a detailed characterization of the results, using as input a simple web-based user interface. In fact, our previous experience in related research projects has evidenced the necessity of testing, comparing and evaluating different algorithms in similar conditions. So, the similarity between the virtual scenario, where the benchmarking will be performed, and the real one, will determine the quality of the results. In that sense, a methodology is presented which updates the scenario with real information each time a real trial is performed. Benchmarking, a very active robotic area in nowadays, is the underlying problem to solve. In summary, the main functionalities for benchmarking available in the simulation platform will be highlighted, by using some case studies concerning object tracking under visibility changes, object tracking under variable water current and 3D reconstruction subject to different optical conditions. "
}
@article{Li2015229,
title = "Cognitive assisted living ambient system: a survey ",
journal = "Digital Communications and Networks ",
volume = "1",
number = "4",
pages = "229 - 252",
year = "2015",
note = "",
issn = "2352-8648",
doi = "https://doi.org/10.1016/j.dcan.2015.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S2352864815000589",
author = "Ruijiao Li and Bowen Lu and Klaus D. McDonald-Maier",
keywords = "Assitive living",
keywords = "Digital communication",
keywords = "Smart home",
keywords = "Robotics",
keywords = "Sensor network ",
abstract = "Abstract The demographic change towards an aging population is creating a significant impact and introducing drastic challenges to our society. We therefore need to find ways to assist older people to stay independently and prevent social isolation of these population. Information and Communication Technologies (ICT) provide various solutions to help older adults to improve their quality of life, stay healthier, and live independently for a time. Ambient Assisted Living (AAL) is a field to investigate innovative technologies to provide assistance as well as healthcare and rehabilitation to impaired seniors. The paper provides a review of research background and technologies of AAL. "
}
@article{Panetto201647,
title = "New perspectives for the future interoperable enterprise systems ",
journal = "Computers in Industry ",
volume = "79",
number = "",
pages = "47 - 63",
year = "2016",
note = "Special Issue on Future Perspectives On Next Generation Enterprise Information Systems ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2015.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361515300312",
author = "Hervé Panetto and Milan Zdravkovic and Ricardo Jardim-Goncalves and David Romero and J. Cecil and István Mezgár",
keywords = "Context-aware systems",
keywords = "Cloud-based systems",
keywords = "Enterprises as cyber-physical systems",
keywords = "Interoperability assessment",
keywords = "Semantic interoperability",
keywords = "Enterprise integration",
keywords = "Networked collaborative enterprise",
keywords = "Enterprise information systems ",
abstract = "Abstract The rapid changes in today's socio-economic and technological environment in which the enterprises operate necessitate the identification of new requirements that address both theoretical and practical aspects of the Enterprise Information Systems (EIS). Such an evolving environment contributes to both the process and the system complexity which cannot be handled by the traditional architectures. The constant pressure of requirements for more data, more collaboration and more flexibility motivates us to discuss about the concept of Next Generation \{EIS\} (NG EIS) which is federated, omnipresent, model-driven, open, reconfigurable and aware. All these properties imply that the future enterprise system is inherently interoperable. This position paper presents the discussion that spans several research challenges of future interoperable enterprise systems, specialized from the existing general research priorities and directions of \{IFAC\} Technical Committee 5.3,11 \{IFAC\} Technical Committee 5.3 « Enterprise Integration and Networking », http://www.ifac-tc53.org namely: context-aware systems, semantic interoperability, cyber-physical systems, cloud-based systems and interoperability assessment. "
}
@article{AuatCheein2015361,
title = "Real-time approaches for characterization of fully and partially scanned canopies in groves ",
journal = "Computers and Electronics in Agriculture ",
volume = "118",
number = "",
pages = "361 - 371",
year = "2015",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2015.09.017",
url = "http://www.sciencedirect.com/science/article/pii/S0168169915002926",
author = "Fernando A. Auat Cheein and José Guivant and Ricardo Sanz and Alexandre Escolà and Francisco Yandún and Miguel Torres-Torriti and Joan R. Rosell-Polo",
keywords = "Crown volume",
keywords = "LiDAR sensor",
keywords = "Mobile terrestrial laser scanner",
keywords = "Agricultural robotics ",
abstract = "Abstract Efficient information management in orchard characterization leads to more efficient agricultural processes. In this brief, a set of computational geometry methods are presented and evaluated for orchard characterization; in particular, for the estimation of canopy volume and shape in groves and orchards using a LiDAR (Light Detection And Ranging) sensor mounted on an agricultural service unit. The proposed approaches were evaluated and validated in the field, showing they are convergent in the estimation process and that they are able to estimate the crown volume for fully scanned canopies in real time; for partially observed tree crowns, accuracy decreases up to 30% (the worst case). The latter is the major contribution of this brief since it implies that the automated service unit does not need to cover all alley-ways for an accurate modeling of the orchard, thus saving valuable resources. "
}
@article{delaPuente201580,
title = "Feature based graph \{SLAM\} with high level representation using rectangles ",
journal = "Robotics and Autonomous Systems ",
volume = "63, Part 1",
number = "",
pages = "80 - 88",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S092188901400181X",
author = "Paloma de la Puente and Diego Rodriguez-Losada",
keywords = "Mobile robotics",
keywords = "Feature based SLAM",
keywords = "Environment modeling ",
abstract = "Abstract In mobile robotics, feature based maps are very popular for the representation of the environment. Some of the main advantages of these maps are final compactness and expressivity, aspects that make storage easier and simplify higher level reasoning. Most existing approaches, however, stick to low level features such as points, segments and sometimes circles, corners or splines. This paper presents the incorporation of rectangles as higher level features in a feature based graph Simultaneous Localization and Mapping (SLAM) framework for the consideration of the structure of the environment in the mapping process. "
}
@article{BerkerLogoglu2016558,
title = "CoSPAIR: Colored Histograms of Spatial Concentric Surflet-Pairs for 3D object recognition ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "558 - 570",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.027",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002225",
author = "K. Berker Logoglu and Sinan Kalkan and Alptekin Temizel",
keywords = "3D descriptors",
keywords = "3D object recognition",
keywords = "Point clouds",
keywords = "RGB-D ",
abstract = "Abstract Introduction of RGB-D sensors together with the efforts on open-source point-cloud processing tools boosted research in both computer vision and robotics. One of the key areas which have drawn particular attention is object recognition since it is one of the crucial steps for various applications. In this paper, two spatially enhanced local 3D descriptors are proposed for object recognition tasks: Histograms of Spatial Concentric Surflet-Pairs (SPAIR) and Colored \{SPAIR\} (CoSPAIR). The proposed descriptors are compared against the state-of-the-art local 3D descriptors that are available in Point Cloud Library (PCL) and their object recognition performances are evaluated on several publicly available datasets. The experiments demonstrate that the proposed CoSPAIR descriptor outperforms the state-of-the-art descriptors in both category-level and instance-level recognition tasks. The performance gains are observed to be up to 9.9 percentage points for category-level recognition and 16.49 percentage points for instance-level recognition over the second-best performing descriptor. "
}
@article{Oliveira2016312,
title = "Incremental scenario representations for autonomous driving using geometric polygonal primitives ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "312 - 325",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300604",
author = "Miguel Oliveira and Vitor Santos and Angel D. Sappa and Paulo Dias and A. Paulo Moreira",
keywords = "Incremental scene reconstruction",
keywords = "Point clouds",
keywords = "Autonomous vehicles",
keywords = "Polygonal primitives ",
abstract = "Abstract When an autonomous vehicle is traveling through some scenario it receives a continuous stream of sensor data. This sensor data arrives in an asynchronous fashion and often contains overlapping or redundant information. Thus, it is not trivial how a representation of the environment observed by the vehicle can be created and updated over time. This paper presents a novel methodology to compute an incremental 3D representation of a scenario from 3D range measurements. We propose to use macro scale polygonal primitives to model the scenario. This means that the representation of the scene is given as a list of large scale polygons that describe the geometric structure of the environment. Furthermore, we propose mechanisms designed to update the geometric polygonal primitives over time whenever fresh sensor data is collected. Results show that the approach is capable of producing accurate descriptions of the scene, and that it is computationally very efficient when compared to other reconstruction techniques. "
}
@article{Yusuf201515,
title = "Application of acoustic directional data for audio event recognition via HMM/CRF in perimeter surveillance systems ",
journal = "Robotics and Autonomous Systems ",
volume = "72",
number = "",
pages = "15 - 28",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S092188901500086X",
author = "Syed A. Yusuf and David J. Brown and Alan Mackinnon",
keywords = "Robotics",
keywords = "Automation",
keywords = "Hidden Markov models",
keywords = "Conditional Random Fields",
keywords = "Audio event detection",
keywords = "Machine learning",
keywords = "Artificial intelligence ",
abstract = "Abstract Audio event detection (AED) and recognition is a signal processing and analysis domain used in a wide range of applications including surveillance, home automation and behavioral assessment. The field presents numerous challenges to the current state-of-the-art due to its highly nonlinear nature. High false alarm rates (FARs) in such applications particularly limit the capabilities of vision-based perimeter monitoring systems by inducing high operator dependence. On the other hand, conventional fence-based vibration detectors and pressure-driven “taut wires” offer high sensitivity at the cost of a high \{FAR\} due to debris, animals and weather. This work reports an audio event identification methodology implemented as a test-bed system for a surveillance application to reduce FAR, maximize blind-spot coverage and improve audio event classification accuracy. The first phase utilizes a nonlinear autoregressive classifier to locate and classify discrete audio events via an exogenous sound direction variable to improve classifier confidence. The second phase implements a time-series-based system to recognize various audio activity groups from nominal everyday sound events such as traffic and muffled speech. The discretely labeled data is thus trained with \{HMM\} and Conditional Random Field classifiers and reports a substantial improvement in classification accuracies of indoor human activities. "
}
@article{Liang201663,
title = "Terrestrial laser scanning in forest inventories ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "115",
number = "",
pages = "63 - 77",
year = "2016",
note = "Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science' ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616000204",
author = "Xinlian Liang and Ville Kankare and Juha Hyyppä and Yunsheng Wang and Antero Kukko and Henrik Haggrén and Xiaowei Yu and Harri Kaartinen and Anttoni Jaakkola and Fengying Guan and Markus Holopainen and Mikko Vastaranta",
keywords = "Forest inventory",
keywords = "Point cloud",
keywords = "Terrestrial laser scanning",
keywords = "Mobile laser scanning",
keywords = "Personal laser scanning",
keywords = "Image-based point cloud ",
abstract = "Abstract Decision making on forest resources relies on the precise information that is collected using inventory. There are many different kinds of forest inventory techniques that can be applied depending on the goal, scale, resources and the required accuracy. Most of the forest inventories are based on field sample. Therefore, the accuracy of the forest inventories depends on the quality and quantity of the field sample. Conventionally, field sample has been measured using simple tools. When map is required, remote sensing materials are needed. Terrestrial laser scanning (TLS) provides a measurement technique that can acquire millimeter-level of detail from the surrounding area, which allows rapid, automatic and periodical estimates of many important forest inventory attributes. It is expected that \{TLS\} will be operationally used in forest inventories as soon as the appropriate software becomes available, best practices become known and general knowledge of these findings becomes more wide spread. Meanwhile, mobile laser scanning, personal laser scanning, and image-based point clouds became capable of capturing similar terrestrial point cloud data as TLS. This paper reviews the advances of applying \{TLS\} in forest inventories, discusses its properties with reference to other related techniques and discusses the future prospects of this technique. "
}
@article{Guerreiro20141116,
title = "Automatic 2-D LiDAR geometric calibration of installation bias ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1116 - 1129",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000906",
author = "Bruno J. Guerreiro and Carlos Silvestre and Paulo Oliveira",
keywords = "Calibration",
keywords = "Range sensing",
keywords = "Special orthogonal group",
keywords = "Mapping",
keywords = "Aerial robotics ",
abstract = "Abstract This paper proposes two estimation algorithms for the determination of the attitude installation matrix for 2-D light detection and ranging (LiDAR) systems on board unmanned aerial vehicles (UAVs). While a comparative calibration algorithm assumes the existence of a known calibration surface, an automatic calibration algorithm does not require any prior knowledge of the trajectories of the vehicle or the terrain where the calibration mission is performed. The proposed calibration algorithms rely on the minimization of the errors between the measured point cloud and a representation of the known calibration surface or, alternatively, the errors between several acquired point clouds, by comparing each measured point cloud with a surface representation of the others. The resulting optimization problems are addressed using two techniques: (i) nonlinear optimization, where the attitude installation rotation matrix is parameterized by the Z Y X Euler angles, and (ii) optimization on Riemannian manifolds, enabling the estimation of the attitude installation matrix on the group of special orthogonal matrices \{SO\} ( 3 ) . The proposed calibration techniques are extensively validated and compared using both simulated and experimental LiDAR data sets, demonstrating their accuracy and performance. "
}
@article{Mitchell2014567,
title = "Image-Guided Surgery and Emerging Molecular Imaging: Advances to Complement Minimally Invasive Surgery ",
journal = "Urologic Clinics of North America ",
volume = "41",
number = "4",
pages = "567 - 580",
year = "2014",
note = "Advances in Robotic-Assisted Urologic Surgery ",
issn = "0094-0143",
doi = "https://doi.org/10.1016/j.ucl.2014.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094014314000780",
author = "Christopher R. Mitchell and S. Duke Herrell",
keywords = "Image guidance",
keywords = "Robotics",
keywords = "Surgical navigation",
keywords = "Molecular imaging",
keywords = "Urologic surgery "
}
@incollection{Pickering2015645,
title = "Cybernetics ",
editor = "Wright, James D. ",
booktitle = "International Encyclopedia of the Social & Behavioral Sciences (Second Edition) ",
publisher = "Elsevier",
edition = "Second Edition",
address = "Oxford",
year = "2015",
pages = "645 - 650",
isbn = "978-0-08-097087-5",
doi = "https://doi.org/10.1016/B978-0-08-097086-8.85005-9",
url = "http://www.sciencedirect.com/science/article/pii/B9780080970868850059",
author = "Andrew Pickering",
keywords = "Actor-network theory",
keywords = "Agency",
keywords = "Complexity",
keywords = "Counterculture",
keywords = "Cyborgs",
keywords = "Enframing",
keywords = "Interdisciplinarity",
keywords = "Mangle of practice",
keywords = "Modernity",
keywords = "Ontology",
keywords = "Poiesis",
keywords = "Politics",
keywords = "Posthumanism",
keywords = "Robotics",
keywords = "Technocracy",
keywords = "Technologies of the self ",
abstract = "Abstract This article reviews developments in cybernetics from the 1940s to the present, focusing on the most radical threads, those that foreground key questions of agency, performance, and emergence. It explores cybernetic intersections with fields including science and technology studies, brain science, psychiatry and antipsychiatry, biological computing, management, the environment, the arts, architecture, nonmodern spirituality, and the counterculture of the 1960s. It concludes with a discussion of the politics of cybernetics. "
}
@article{Sansoni2014222,
title = "Optoranger: A 3D pattern matching method for bin picking applications ",
journal = "Optics and Lasers in Engineering ",
volume = "54",
number = "",
pages = "222 - 231",
year = "2014",
note = "",
issn = "0143-8166",
doi = "https://doi.org/10.1016/j.optlaseng.2013.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0143816613002303",
author = "Giovanna Sansoni and Paolo Bellandi and Fabio Leoni and Franco Docchio",
keywords = "3D metrology",
keywords = "Bin picking",
keywords = "Robotics",
keywords = "3D matching",
keywords = "3D segmentation ",
abstract = "Abstract This paper presents a new method, based on 3D vision, for the recognition of free-form objects in the presence of clutters and occlusions, ideal for robotic bin picking tasks. The method can be considered as a compromise between complexity and effectiveness. A 3D point cloud representing the scene is generated by a triangulation-based scanning system, where a fast camera acquires a blade projected by a laser source. Image segmentation is based on 2D images, and on the estimation of the distances between point pairs, to search for empty areas. Object recognition is performed using commercial software libraries integrated with custom-developed segmentation algorithms, and a database of model clouds created by means of the same scanning system. Experiments carried out to verify the performance of the method have been designed by randomly placing objects of different types in the Robot work area. The preliminary results demonstrate the excellent ability of the system to perform the bin picking procedure, and the reliability of the method proposed for automatic recognition of identity, position and orientation of the objects. "
}
@article{Schaub20142640,
title = "Autonomous Parking using a Highly Maneuverable Robotic Vehicle ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "2640 - 2645",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00800",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016420082",
author = "Alexander Schaub and Juan Carlos Ramirez de la Cruz and Darius Burschka",
abstract = "Abstract This work presents a novel autonomous parking concept for a four wheel-steerable robotic electric vehicle called \{ROboMObil\} (ROMO). Its extraordinary maneuverability, including rotations and lateral driving, and its capability of autonomous driving is demonstrated in the application of parallel parking. The whole process is described starting with the perception to identify a suitable parking spot in the near environment, planning the maneuver, and executing it autonomously. The proposed parking method is free of assumptions and does not use any information about the environment from an external source. Test results with the real vehicle are presented to show the feasibility of the concept. "
}
@article{Tamas201476,
title = "3D semantic interpretation for robot perception inside office environments ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "32",
number = "",
pages = "76 - 87",
year = "2014",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2014.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0952197614000566",
author = "Levente Tamas and Lucian Cosmin Goron",
keywords = "Robotics",
keywords = "Perception",
keywords = "Segmentation",
keywords = "Registration",
keywords = "Indoor mapping ",
abstract = "Abstract Making sense out of human indoor environments is an essential feature for robots. The paper at hand presents a system for semantic interpretation of our surrounding indoor environments such as offices and kitchens. The perception and the interpretation of the measured data are essential tasks for any intelligent system. There are different techniques for processing 3D point clouds. The majority of them include acquisition, iterative registration, segmentation, or classification stages. We describe a generic pipeline for indoor data processing and semantic information extraction. The proposed pipeline is validated using several data sets collected using different 3D sensing devices. "
}
@article{Mourtzis2016637,
title = "Energy Consumption Estimation for Machining Processes Based on Real-time Shop Floor Monitoring via Wireless Sensor Networks ",
journal = "Procedia \{CIRP\} ",
volume = "57",
number = "",
pages = "637 - 642",
year = "2016",
note = "Factories of the Future in the digital environment - Proceedings of the 49th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.11.110",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116312641",
author = "Dimitris Mourtzis and Ekaterini Vlachou and Nikolaos Milas and George Dimitrakopoulos",
keywords = "Wireless Sensor Network",
keywords = "Monitoring",
keywords = "Cloud manufacturing",
keywords = "CBR ",
abstract = "Abstract The increasing concern about the depletion of the energy repositories places the energy efficiency issues in high priority. In the manufacturing sector, the improvement of energy efficiency is a challenging task due to the complexity of manufacturing systems and the requirements for flexible operation targeting highly customised products. Towards this end, the estimation of the energy consumption of a machining task, and therefore the machining cost, is necessary. This paper presents a machine tool monitoring methodology that integrates sensory systems, a scheduling module, and human operators to perform real-time monitoring on the shop-floor. A monitoring system is designed to capture real-time measurements from sensors attached on machine tools and perform the necessary pre-processing to transmit these measurements to a Cloud server via wireless sensor networks. Furthermore, the input from human operators is utilized to collect the machining parameters. The collected information is fused through an information fusion mechanism to extract meaningful results. The results are stored in a database for the reuse in future tasks by estimating the energy consumption of new cases, through a case-based reasoning approach, prior the job dispatching. Therefore, the machining parameters of the new case can be modified targeting energy consumption reduction. The proposed system is delivered as a Cloud software-as-a-service to realise the philosophy of Cloud manufacturing. "
}
@article{Liu2015110,
title = "Table-top scene analysis using knowledge-supervised \{MCMC\} ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "110 - 123",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000702",
author = "Ziyuan Liu and Dong Chen and Kai M. Wurm and Georg von Wichert",
keywords = "Knowledge representation and reasoning",
keywords = "Robotics",
keywords = "Scene analysis",
keywords = "Abstract models",
keywords = "Semantic modelling ",
abstract = "Abstract In this paper, we propose a probabilistic approach to generate abstract scene graphs from uncertain 6D pose estimates. We focus on generating a semantic understanding of the perceived scenes that well explains the composition of the scene and the inter-object relations. The proposed system is realized by our knowledge-supervised \{MCMC\} sampling technique. We explicitly make use of task-specific context knowledge by encoding this knowledge as descriptive rules in Markov logic networks. We use a probabilistic sensor model to encode the fact that measurements are subject to significant uncertainty. We integrate the measurements with the abstract scene graph in a data driven \{MCMC\} process. Our system is fully probabilistic and links the high-level abstract scene description to uncertain low level measurements. Moreover, false estimates of the object poses and hidden objects of the perceived scenes can be systematically detected using the defined Markov logic knowledge base. The effectiveness of our approach is demonstrated and evaluated in real world experiments. "
}
@article{Takimoto20167,
title = "Rough Surface Wear Analysis Using Image Processing Techniques ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "31",
pages = "7 - 12",
year = "2016",
note = "12th \{IFAC\} Workshop on Intelligent Manufacturing Systems \{IMS\} 2016Austin, Texas, USA, 5—7 December 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.12.153",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316328233",
author = "Rogério Yugo Takimoto and Marcos de Sales Guerra Tsuzuki and Edson Kenji Ueda and André Kubagawa Sato and Thiago de Castro Martins and Tiago Cousseau and Deniol Tanaka and Amilton Sinatora",
keywords = "Point Cloud Registration",
keywords = "Image Processing",
keywords = "Rigid Transform",
keywords = "ICP",
keywords = "SIFT ",
abstract = "Abstract: Due to the great interest of the automotive industry to quickly and systematically evaluate low wear quantities a new approach based on image processing is presented. By comparing the captured rough surface point cloud using optical interferometry before and after wear, the proposed algorithm was able to estimate the amount of volume wear and mass loss. The proposed algorithm has two main steps. In the first step, the 3D point clouds obtained before and after wear are mapped to 2D images, and conventional edge detection algorithms are applied. Keypoints are determined using the \{SIFT\} algorithm on both images (before and after the wear), followed by the use of the \{RANSAC\} algorithm to create a good 2D registration between both 2D images. In the second step an enhanced \{ICP\} algorithm is used to perform a 3D registration. The main advantage of this method is the visualization of the wear geometry provided by the wear topography. The proposed algorithm was tested and the results are presented. "
}
@article{Kocifaj201540,
title = "Unified model of radiance patterns under arbitrary sky conditions ",
journal = "Solar Energy ",
volume = "115",
number = "",
pages = "40 - 51",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2015.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X15000894",
author = "Miroslav Kocifaj",
keywords = "Sky radiance patterns",
keywords = "Stochastic cloud coverage",
keywords = "Aerosols",
keywords = "Light scattering ",
abstract = "Abstract The radiance/luminance patterns that simulate more realistic skies are urgently needed in lighting engineering applications to model daylight availability in exterior and interior spaces. Undoubtedly, the angular behavior of sky radiance/luminance is a key factor determining the daylight conditions in rooms with variable orientations and window sizes. Therefore, much effort is currently expended in search of a universal, scalable daylight model that accepts actual meteorological situations. The natural sky radiances are neither monotonic nor smooth functions of zenith/azimuth angle, primarily due to the presence of broken cloud arrays or single clouds scattered over the whole sky vault. In this paper we show how we have addressed the phenomena and developed a universal sky radiance model for a turbid, cloudy atmosphere. This model accommodates higher scattering orders, aerosol optics, surface albedo, and the statistically relevant contributions of single clouds. The radiance at ground depends on the bulk characteristics of cloud fields, such as spectral optical thickness, spectral reflectance, altitude, positions on the sky, sizes, and shapes. We have shown that single scattering approximation fails to reproduce the radiance in the circumsolar region when clouds block the direct solar beams. The single scattering concept also overestimates reflection by individual clouds. Incorporation of double scattering into a computational model generally makes the radiance patterns smooth and less steep at the edges of clouds as commonly occur in nature. The numerical demonstrations are based on UniSky Simulator (Kocifaj and Fecko, 2014) which allows for modeling of various cloud configurations and is available for public use. "
}
@article{Costa2016113,
title = "Robust 3/6 DoF self-localization system with selective map update for mobile robot platforms ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "113 - 140",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.030",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002250",
author = "Carlos M. Costa and Héber M. Sobreira and Armando J. Sousa and Germano M. Veiga",
keywords = "Self-localization",
keywords = "Simultaneous localization and mapping",
keywords = "Point cloud registration",
keywords = "Geometric feature matching ",
abstract = "Abstract Mobile robot platforms capable of operating safely and accurately in dynamic environments can have a multitude of applications, ranging from simple delivery tasks to advanced assembly operations. These abilities rely heavily on a robust navigation stack, which requires stable and accurate pose estimations within the environment. To solve this problem, a modular localization system suitable for a wide range of mobile robot platforms was developed. By using LIDAR/RGB-D data, the proposed system is capable of achieving 1–2 cm in translation error and 1°–3° degrees in rotation error while requiring only 5–35 ms of processing time (in 3 and 6 DoF respectively). The system was tested in three robot platforms and in several environments with different sensor configurations. It demonstrated high accuracy while performing pose tracking with point cloud registration algorithms and high reliability when estimating the initial pose using feature matching techniques. The system can also build a map of the environment with surface reconstruction and incrementally update it with either the full field of view of the sensor data or only the unknown sections, which allows to reduce the mapping processing time and also gives the possibility to update a \{CAD\} model of the environment without degrading the detail of known static areas due to sensor noise. "
}
@article{Ni20132135,
title = "Vision-based virtual force guidance for tele-robotic system ",
journal = "Computers & Electrical Engineering ",
volume = "39",
number = "7",
pages = "2135 - 2144",
year = "2013",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2013.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0045790613001900",
author = "Tao Ni and Hongyan Zhang and Peng Xu and Hironao Yamada",
abstract = "Abstract In order to improve operator performance and understanding within remote environment, a vision-based virtual forced guidance control methodology for tele-robotic system is presented. The remote operation of the construction robot is achieved by manipulating the graphic robot in a virtual environment. Based on binocular vision, the ground surface is modeled as an elevation map, and the task objects are recognized from video images and reconstructed using the Power Crust algorithm. The virtual guidance forces consisting of a pair of attractive force and repulsive force from the objects and obstacles are used to enhance the multi-task manipulation of the tele-robotic system. "
}
@article{Oliveira2016614,
title = "3D object perception and perceptual learning in the \{RACE\} project ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "614 - 626",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002146",
author = "Miguel Oliveira and Luís Seabra Lopes and Gi Hyun Lim and S. Hamidreza Kasaei and Ana Maria Tomé and Aneesh Chauhan",
keywords = "3D object perception",
keywords = "Point-Cloud Library",
keywords = "Dual memory systems",
keywords = "Open-ended learning",
keywords = "Interactive learning ",
abstract = "Abstract This paper describes a 3D object perception and perceptual learning system developed for a complex artificial cognitive agent working in a restaurant scenario. This system, developed within the scope of the European project RACE, integrates detection, tracking, learning and recognition of tabletop objects. Interaction capabilities were also developed to enable a human user to take the role of instructor and teach new object categories. Thus, the system learns in an incremental and open-ended way from user-mediated experiences. Based on the analysis of memory requirements for storing both semantic and perceptual data, a dual memory approach, comprising a semantic memory and a perceptual memory, was adopted. The perceptual memory is the central data structure of the described perception and learning system. The goal of this paper is twofold: on one hand, we provide a thorough description of the developed system, starting with motivations, cognitive considerations and architecture design, then providing details on the developed modules, and finally presenting a detailed evaluation of the system; on the other hand, we emphasize the crucial importance of the Point Cloud Library (PCL) for developing such system.11 This paper is a revised and extended version of Oliveira et al. (2014). "
}
@article{Morariu201527,
title = "vMES: Virtualization aware manufacturing execution system ",
journal = "Computers in Industry ",
volume = "67",
number = "",
pages = "27 - 37",
year = "2015",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2014.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0166361514001924",
author = "Octavian Morariu and Theodor Borangiu and Silviu Raileanu",
keywords = "MES",
keywords = "Virtualization",
keywords = "Private cloud",
keywords = "Shop floor",
keywords = "Resource allocation",
keywords = "ISA-95 ",
abstract = "Abstract The large scale emergence in the last decade of various cloud solutions, ranging from software-as-a-service (SaaS) based solutions for business process management and implementation to very sophisticated private cloud solutions capable of high performance computing (HPC) and efficient virtualization, constitute the building blocks for engineering the next generation of flexible enterprise systems that can respond with great agility to changes in their environment. These new technologies are adopted at a certain level by manufacturing enterprises in order to advance in a new era of mass customization where flexibility, scalability and agility are the differentiating factors. In this context, this paper introduces the virtualized manufacturing execution system (vMES), an intermediate layer in the manufacturing stack, and discusses the advantages and limitations offered by this approach for manufacturing enterprises. A classification of \{MES\} workloads based on the ISA-95 function model is presented, focusing on the virtualization techniques suitable for each workload, considering the algorithms and technologies used and the virtualization overhead. A pilot vMES implementation using a parallel process for smart resource provisioning and automatic scaling is also presented. The pilot implementation using six Adept robots and one \{IBM\} CloudBurst 2.1 private cloud and an ISA-95 based \{MES\} is described; the virtualization sequence is analyzed in several scenarios of resource workload collocation on physical cloud blades with and without perturbations. "
}
@article{Abar2017,
title = "Agent Based Modelling and Simulation tools: A review of the state-of-art software ",
journal = "Computer Science Review ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1574-0137",
doi = "https://doi.org/10.1016/j.cosrev.2017.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S1574013716301198",
author = "Sameera Abar and Georgios K. Theodoropoulos and Pierre Lemarinier and Gregory M.P. O’Hare",
keywords = "Software agent",
keywords = "Agent Based Modelling and Simulation (ABMS) tools",
keywords = "Multi-agent computing",
keywords = "Modelling complex systems",
keywords = "Swarm intelligence",
keywords = "Artificial life / social science simulations ",
abstract = "Abstract The key intent of this work is to present a comprehensive comparative literature survey of the state-of-art in software agent-based computing technology and its incorporation within the modelling and simulation domain. The original contribution of this survey is two-fold: (1) Present a concise characterization of almost the entire spectrum of agent-based modelling and simulation tools, thereby highlighting the salient features, merits, and shortcomings of such multi-faceted application software; this article covers eighty five agent-based toolkits that may assist the system designers and developers with common tasks, such as constructing agent-based models and portraying the real-time simulation outputs in tabular/graphical formats and visual recordings. (2) Provide a usable reference that aids engineers, researchers, learners and academicians in readily selecting an appropriate agent-based modelling and simulation toolkit for designing and developing their system models and prototypes, cognizant of both their expertise and those requirements of their application domain. In a nutshell, a significant synthesis of Agent Based Modelling and Simulation (ABMS) resources has been performed in this review that stimulates further investigation into this topic. "
}
@article{Ichim2016539,
title = "Semantic parametric body shape estimation from noisy depth sequences ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "539 - 549",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.029",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002249",
author = "Alexandru Eugen Ichim and Federico Tombari",
keywords = "3D body modeling",
keywords = "3D body tracking",
keywords = "Depth data",
keywords = "Point Cloud Library ",
abstract = "Abstract The paper proposes a complete framework for tracking and modeling articulated human bodies from sequences of range maps acquired from off-the-shelf depth cameras. In particular, we propose an original approach for fitting a pre-defined parametric shape model to depth data by exploiting the 3D body pose tracked through a sequence of range maps. To this goal, we make use of multiple types of constraints and cues embedded into a unique cost function, which is then efficiently minimized. Our framework is able to yield compact semantic tags associated to the estimated body shape by leveraging on semantic body modeling from MakeHuman and \{L1\} relaxation, and relies on the tools and algorithms provided by the open source Point Cloud Library (PCL), representing a good integration of the functionalities available therein. "
}
@article{Stein201779,
title = "Interpolation in the eXtended Classifier System: An architectural perspective ",
journal = "Journal of Systems Architecture ",
volume = "75",
number = "",
pages = "79 - 94",
year = "2017",
note = "",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2017.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S138376211730053X",
author = "Anthony Stein and Dominik Rauh and Sven Tomforde and Jörg Hähner",
keywords = "Organic computing",
keywords = "XCS",
keywords = "Genetic algorithm",
keywords = "Action selection regime",
keywords = "Covering",
keywords = "Interpolation component ",
abstract = "Abstract Machine Learning techniques constitute a key factor to make Organic Computing (OC) systems self-adaptive and self-reconfigurable at runtime. \{OC\} systems are therefore equipped with a so-called self-learning property enabling them to react appropriately when the environmental demands change and the system is faced possibly unforeseen situations. The eXtended Classifier System (XCS) is a rule-based evolutionary online learning system that has gained plenty attention in the research field of Genetic-based Machine Learning in general and within the \{OC\} initiative in particular. In this article, the \{XCS\} system is structurally extended to incorporate numerical interpolation. With the presented approaches we pursue the overall goal to overcome the challenge of sparsely distributed samples in the problem space resulting from e.g., non-uniform data distributions. A novel Interpolation Component (IC) is introduced and two architectural integration approaches are discussed. We elaborate on three strategies to integrate interpolated values into various algorithmic steps of XCS. The potential of incorporating interpolation techniques is underpinned by an evaluation on a rather challenging theoretical classification task, called the checkerboard problem. "
}
@incollection{Marinescu201733,
title = "Chapter 2 - Nature-Inspired Algorithms and Systems ",
editor = "Marinescu, Dan C. ",
booktitle = "Complex Systems and Clouds ",
publisher = "Elsevier",
edition = "",
address = "Boston",
year = "2017",
pages = "33 - 63",
series = "Computer Science Reviews and Trends",
isbn = "978-0-12-804041-6",
doi = "https://doi.org/10.1016/B978-0-12-804041-6.00002-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128040416000025",
author = "Dan C. Marinescu",
keywords = "Cellular automata",
keywords = "Epidemic algorithms",
keywords = "Genetic algorithms",
keywords = "Ant colony optimization algorithms",
keywords = "Swarm intelligence",
keywords = "DNA computing",
keywords = "Quantum information processing",
keywords = "P-systems ",
abstract = "Abstract Disciplines such as evolutionary computation, neural computation, artificial immune systems, swarm intelligence, and Ant Colony Optimization (ACO) draw their inspiration from nature for new problem-solving techniques. Cellular automata, epidemic algorithms, genetic algorithms, \{ACO\} algorithms, swarm intelligence, deoxyribonucleic acid (DNA) computing, quantum information processing, and membrane computing are then presented. A discussion of the scope and limitations of nature-inspired algorithms and realistic expectations from \{DNA\} computing and quantum information processing concludes the chapter. "
}
@article{Arbib1989185,
title = "Schemas and neural networks for sixth generation computing invited survey ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "6",
number = "2",
pages = "185 - 216",
year = "1989",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/0743-7315(89)90059-2",
url = "http://www.sciencedirect.com/science/article/pii/0743731589900592",
author = "Michael A. Arbib",
abstract = "The study of animal and human brains suggests overall architectural principles for “sixth generation computers.” Each such machine will comprise a network of more specialized devices, with many of these devices structured as highly parallel arrays of interacting neuron-like, possibly adaptive, components. We stress the interaction between computational neurobiology and neural engineering and note the two grains of analysis of schemas and neural networks, arguing that “schemas will be the programming language of the sixth generation.” After a brief introduction to the variety of neuron models now current, schemas are exemplified in a discussion of high-level vision. The integration of neural network and schema models is brought out in an integrated set of studies, called Rana computatrix, of mechanisms for visuomotor coordination in frog and toad. Whereas many articles on neural networks focus on learning and restrict themselves to a limited class of simple neurons, the present paper emphasizes the “domain-specific” structure of neural networks, as well as emphasizing that technologists have much to learn from the study of neurobiological systems. We close with a brief account of adaptation and the programming of sixth generation computers. "
}
@article{Dorr2017322,
title = "Common errors in reasoning about the future: Three informal fallacies ",
journal = "Technological Forecasting and Social Change ",
volume = "116",
number = "",
pages = "322 - 330",
year = "2017",
note = "",
issn = "0040-1625",
doi = "https://doi.org/10.1016/j.techfore.2016.06.018",
url = "http://www.sciencedirect.com/science/article/pii/S0040162516301275",
author = "Adam Dorr",
keywords = "Technological progress",
keywords = "Accelerating change",
keywords = "Computing",
keywords = "Fallacy",
keywords = "Errors in reasoning ",
abstract = "Abstract The continued exponential growth of the price-performance of computing is likely to effectuate technologies that radically transform both the global economy and the human condition over the course of this century. Conventional visions of the next 50 years fail to realistically account for the full implications of accelerating technological change driven by the exponential growth of computing, and as a result are deeply flawed. These flawed visions are, in part, a consequence of three interrelated errors in reasoning: 1) the linear projection fallacy, 2) the ceteris paribus fallacy, and 3) the arrival fallacy. Each of these informal fallacies is likely a manifestation of shortcomings in our intuitions about complex dynamic systems. Recognizing these errors and identifying when and where they affect our own reasoning is an important first step toward thinking more realistically about the future. "
}
@article{Hu2015343,
title = "G-SHOT: \{GPU\} accelerated 3D local descriptor for surface matching ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "30",
number = "",
pages = "343 - 349",
year = "2015",
note = "",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2015.05.008",
url = "http://www.sciencedirect.com/science/article/pii/S1047320315000875",
author = "Linjia Hu and Saeid Nooshabadi",
keywords = "3D Object local descriptor",
keywords = "Point signature",
keywords = "Surface matching",
keywords = "SHOT",
keywords = "Computer vision",
keywords = "Point cloud library",
keywords = "Parallel algorithm",
keywords = "GPU",
keywords = "Real-time processing",
keywords = "Point cloud ",
abstract = "Abstract Signature of histogram of orientations (SHOT) as a novel 3D object local descriptor can achieves a good balance between descriptiveness and robustness in surface matching. However, its computation workload is much higher than the other 3D local descriptors. This paper investigates the development of suitable massively parallel algorithms on the graphics processing unit (GPU) for computation of high density and large scale 3D object local descriptors through two alternative parallel algorithms; one exact, and one approximate. Both algorithms exhibit outstanding speedup performance. The exact parallel descriptor comes at no cost to the descriptiveness, with a speedup factor of up to 40.70, with respect to the serial \{SHOT\} on the central processing unit (CPU). The approximate version achieves a corresponding speedup factor of up to 54 with minor degradation in descriptiveness. The proposed algorithms are integrated into point cloud library (PCL), a open source project for image and point cloud. "
}
@article{Shabanov201529,
title = "Evaluation of the performance of Suomi \{NPP\} \{VIIRS\} top of canopy vegetation indices over \{AERONET\} sites ",
journal = "Remote Sensing of Environment ",
volume = "162",
number = "",
pages = "29 - 44",
year = "2015",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715000504",
author = "N. Shabanov and M. Vargas and T. Miura and A. Sei and A. Danial",
keywords = "VIIRS",
keywords = "Vegetation indices",
keywords = "AERONET",
keywords = "Match-up",
keywords = "Clouds",
keywords = "Aerosol",
keywords = "Snow ",
abstract = "Abstract The Suomi \{NPP\} \{VIIRS\} Vegetation Index (VI) Environment Data Record (EDR) includes the Top Of the Atmosphere Normalized Difference Vegetation Index (TOA NDVI) and the Top Of the Canopy Enhanced Vegetation Index (TOC EVI). \{TOC\} \{NDVI\} will be included in the \{VI\} \{EDR\} suite for the upcoming JPSS-1 and JPSS-2 missions. Currently, the \{VIIRS\} \{VI\} suite is undergoing extensive Calibration and Validation (Cal/Val) activities to quantify product performance and to provide guidance for algorithm improvement. In this study we utilized \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) based Surface Reflectance (SR) match-up data sets. Match-ups are pairs of \{VIIRS\} \{SR\} and \{SR\} derived from atmospheric correction of \{VIIRS\} \{TOA\} reflectances using \{AERONET\} ground measurements (aerosol and water vapor parameters) and ancillary data. Atmospheric correction is performed with the Second Simulation of a Satellite Signal in the Solar Spectrum (6S) radiative transfer code, the same code used in the operational \{VIIRS\} atmospheric correction. Daily time series January 1, 2013–March 31, 2014 of 101 × 101 pixel window match-up subsets at 375 m \{VIIRS\} Imagery resolution, centered at the selected \{AERONET\} site locations were used. The overall objective of the study was to characterize the performance of the \{VIIRS\} \{TOC\} \{VIs\} (TOC \{EVI\} and \{TOC\} NDVI) over \{AERONET\} sites as a function of accuracy of inputs of atmospheric correction algorithm (aerosol, water vapor and others) and quality control screening (cloud and snow masks). We performed three types of analyses: (1) analysis of overall performance of \{VI\} product over all sites, (2) analysis of time series over select sites representative of vegetation types, and (3) sensitivity analysis of \{VI\} to cloud, aerosols and snow contamination. Over the period of time series average Accuracy, Precision and Uncertainty statistics were 0.009, 0.035, and 0.038, respectively, for \{TOC\} \{NDVI\} and − 0.004, 0.015, and 0.016, respectively, for \{TOC\} EVI. Those statistics were derived based on screening to retain only confidently clear, snow free, non-urban pixels. The reason for the substantial difference in the performance of \{VIs\} is a different sensitivity of \{VIs\} to residual atmospheric contamination. According to our study \{VIIRS\} cloud mask performed reasonably. However, Aerosol Optical Thickness (AOT) was substantially overestimated in the vicinity of clouds, which resulted in overcorrection of \{VIIRS\} visible channels and ultimately overestimation of \{TOC\} NDVI. \{TOC\} EVI, on the other hand, remained largely unaffected, as an atmospherically resistant index. \{TOC\} \{EVI\} was also found to be less sensitive to residual snow contamination. Results of this study indicate the need to develop VI-specific quality control, which effectively screens data based on index sensitivity to atmospheric contamination. Monitoring \{VIIRS\} \{VIs\} over \{AERONET\} sites has been automated with a web-based \{STAR\} \{JPSS\} \{VI\} Monitor. "
}
@article{Theiler2015126,
title = "Globally consistent registration of terrestrial laser scans via graph optimization ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "109",
number = "",
pages = "126 - 138",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0924271615001987",
author = "Pascal Willy Theiler and Jan Dirk Wegner and Konrad Schindler",
keywords = "Point cloud registration",
keywords = "Terrestrial laser scanning",
keywords = "Geometric matching",
keywords = "Global consistency",
keywords = "Loop closure",
keywords = "Energy minimization ",
abstract = "Abstract In this paper we present a framework for the automatic registration of multiple terrestrial laser scans. The proposed method can handle arbitrary point clouds with reasonable pairwise overlap, without knowledge about their initial orientation and without the need for artificial markers or other specific objects. The framework is divided into a coarse and a fine registration part, which each start with pairwise registration and then enforce consistent global alignment across all scans. While we put forward a complete, functional registration system, the novel contribution of the paper lies in the coarse global alignment step. Merging multiple scans into a consistent network creates loops along which the relative transformations must add up. We pose the task of finding a global alignment as picking the best candidates from a set of putative pairwise registrations, such that they satisfy the loop constraints. This yields a discrete optimization problem that can be solved efficiently with modern combinatorial methods. Having found a coarse global alignment in this way, the framework proceeds by pairwise refinement with standard ICP, followed by global refinement to evenly spread the residual errors. The framework was tested on six challenging, real-world datasets. The discrete global alignment step effectively detects, removes and corrects failures of the pairwise registration procedure, finally producing a globally consistent coarse scan network which can be used as initial guess for the highly non-convex refinement. Our overall system reaches success rates close to 100% at acceptable runtimes &lt; 1 h, even in challenging conditions such as scanning in the forest. "
}
@article{Jalili201790,
title = "Indexing Next-Generation Sequencing data ",
journal = "Information Sciences ",
volume = "384",
number = "",
pages = "90 - 109",
year = "2017",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2016.08.085",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516306685",
author = "Vahid Jalili and Matteo Matteucci and Marco Masseroli and Stefano Ceri",
keywords = "Genomic computing",
keywords = "Domain-specific data indexing",
keywords = "Region-based operations and calculus",
keywords = "Data integration ",
abstract = "Abstract Next-Generation Sequencing (NGS), also known as high-throughput sequencing, has opened the possibility of a comprehensive characterization of the genomic and epigenomic landscapes, giving answers to fundamental questions for biological and clinical research, e.g., how DNA-protein interactions and chromatin structure affect gene activity, how cancer develops, how much complex diseases such as diabetes or cancer depend on personal (epi)genomic traits, opening the road to personalized and precision medicine. In this context, our research has focused on sense-making, e.g., discovering how heterogeneous \{DNA\} regions concur to determine particular biological processes or phenotypes. Towards such discovery, characteristic operations to be performed on region data regard identifying co-occurrences of regions, from different biological tests and/or of distinct semantic types, possibly within a certain distance from each others and/or from \{DNA\} regions with known structural or functional properties. In this paper, we present Di3, a 1D Interval Inverted Index, acting as a multi-resolution single-dimension data structure for interval-based data queries. Di3 is defined at data access layer, independent from data layer, business logic layer, and presentation layer; this design makes Di3 adaptable to any underlying persistence technology based on key-value pairs, spanning from classical B+ tree to LevelDB and Apache HBase, and makes Di3 suitable for different business logic and presentation layer scenarios. We demonstrate the effectiveness of Di3 as a general purpose genomic region manipulation tool, with a console-level interface, and as a software component used within MuSERA, a tool for comparative analysis of region data replicates from \{NGS\} ChIP-seq and DNase-seq tests. "
}
@article{Panwar201664,
title = "A survey on 5G: The next generation of mobile communication ",
journal = "Physical Communication ",
volume = "18, Part 2",
number = "",
pages = "64 - 84",
year = "2016",
note = "Special Issue on Radio Access Network Architectures and Resource Management for 5G ",
issn = "1874-4907",
doi = "https://doi.org/10.1016/j.phycom.2015.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S1874490715000531",
author = "Nisha Panwar and Shantanu Sharma and Awadhesh Kumar Singh",
keywords = "Cloud radio access networks",
keywords = "Cognitive radio networks",
keywords = "D2D communication",
keywords = "Dense deployment",
keywords = "Multi-tier heterogeneous network",
keywords = "Tactile Internet ",
abstract = "Abstract The rapidly increasing number of mobile devices, voluminous data, and higher data rate are pushing to rethink the current generation of the cellular mobile communication. The next or fifth generation (5G) cellular networks are expected to meet high-end requirements. The 5G networks are broadly characterized by three unique features: ubiquitous connectivity, extremely low latency, and very high-speed data transfer. The 5G networks would provide novel architectures and technologies beyond state-of-the-art architectures and technologies. In this paper, our intent is to find an answer to the question: “what will be done by 5G and how?” We investigate and discuss serious limitations of the fourth generation (4G) cellular networks and corresponding new features of 5G networks. We identify challenges in 5G networks, new technologies for 5G networks, and present a comparative study of the proposed architectures that can be categorized on the basis of energy-efficiency, network hierarchy, and network types. Interestingly, the implementation issues, e.g., interference, QoS, handoff, security–privacy, channel access, and load balancing, hugely effect the realization of 5G networks. Furthermore, our illustrations highlight the feasibility of these models through an evaluation of existing real-experiments and testbeds. "
}
@article{Stork201282,
title = "Towards a scientific foundation for engineering Cognitive Systems – A European research agenda, its rationale and perspectives ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "1",
number = "",
pages = "82 - 91",
year = "2012",
note = "",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X12000072",
author = "Hans-Georg Stork",
keywords = "Cognitive systems",
keywords = "Bio-inspiration",
keywords = "Robotics",
keywords = "Cognitive robotics",
keywords = "Research agendas",
keywords = "Public funding ",
abstract = "For more than 10 years, beginning in the early 2000s, the European Commission has been supporting targeted research in the fields of Cognitive Systems and Robotics. In this note we discuss the rationale of the underlying research agenda (including its relevance to the \{BICA\} challenge), structure the large set of funded projects, and outline perspectives for future research. "
}
@article{Chotiprayanakul201211,
title = "Human–robot–environment interaction interface for robotic grit-blasting of complex steel bridges ",
journal = "Automation in Construction ",
volume = "27",
number = "",
pages = "11 - 23",
year = "2012",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2012.04.014",
url = "http://www.sciencedirect.com/science/article/pii/S0926580512000702",
author = "P. Chotiprayanakul and D.K. Liu and G. Dissanayake",
keywords = "Steel bridge maintenance",
keywords = "Grit-blasting",
keywords = "Human–robot–environment interaction",
keywords = "Haptic interface ",
abstract = "This paper presents a human-robot-environment interaction (HREI) interface using haptic feedback for a grit-blasting robot operating in close proximity to a complex steel bridge structure. The productivity requirements dictate the need for efficient algorithms for mapping, exploration, and collision-free motion planning. While a large portion of the grit-blasting operation can be automated, a tele-operation is essential to deal with some difficult to access sections such as edges, complex corners, and surfaces which can only be approached through hole. A 3-dimensional virtual force field (3D-VF2) method is developed for capturing the relationship between the robot and its environment. A novel haptic force generation method and a workspace mapping algorithm allow intuitive interaction between the operator and the robot through haptic feedback. The strategies presented are verified in extensive simulations and experiments conducted on a steel bridge with a prototype grit-blasting robot. "
}
@article{Mishchenko2007325,
title = "Past, present, and future of global aerosol climatologies derived from satellite observations: A perspective ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "106",
number = "1–3",
pages = "325 - 347",
year = "2007",
note = "\{IX\} Conference on Electromagnetic and Light Scattering by Non-Spherical Particles ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2007.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0022407307000192",
author = "Michael I. Mishchenko and Igor V. Geogdzhayev and Brian Cairns and Barbara E. Carlson and Jacek Chowdhary and Andrew A. Lacis and Li Liu and William B. Rossow and Larry D. Travis",
keywords = "Tropospheric aerosols",
keywords = "Remote sensing ",
abstract = "A number of passive satellite instruments have been used to develop global climatologies of terrestrial tropospheric aerosols by analyzing the properties of sunlight reflected by the atmosphere–surface system. The outcome of these efforts are several climatologies which all purport to represent the same aerosol characteristics such as optical thickness and size. However, the quantitative differences between these climatologies have been found to far exceed the corresponding individual uncertainty claims. The magnitude of these differences is alarming and necessitates a detailed critical assessment and integrated analysis that would go far beyond simple intercomparisons of various satellite products and comparisons of satellite aerosol optical thickness results with ground-based sun-photometer data. This paper outlines the framework for a global long-term satellite climatology of aerosol properties based on a consistent combination of previous, current, and near-future satellite retrievals. We also discuss potential future strategies for deriving a much improved aerosol climatology from Earth-orbiting satellites. "
}
@article{Monica2016627,
title = "A KinFu based approach for robot spatial attention and view planning ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "627 - 640",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001980",
author = "Riccardo Monica and Jacopo Aleotti and Stefano Caselli",
keywords = "KinectFusion",
keywords = "Point Cloud Library",
keywords = "Robot spatial attention ",
abstract = "Abstract When a user and a robot share the same physical workspace the robot may need to keep an updated 3D representation of the environment. Indeed, robot systems often need to reconstruct relevant parts of the environment where the user executes manipulation tasks. This paper proposes a spatial attention approach for a robot manipulator with an eye-in-hand Kinect range sensor. Salient regions of the environment, where user manipulation actions are more likely to have occurred, are detected by applying a clustering algorithm based on Gaussian Mixture Models applied to the user hand trajectory. A motion capture sensor is used for hand tracking. The robot attentional behavior is driven by a next-best view algorithm that computes the most promising range sensor viewpoints to observe the detected salient regions, where potential changes in the environment have occurred. The environment representation is built upon the \{PCL\} KinFu Large Scale project [1], an open source implementation of KinectFusion. KinFu has been modified to support the execution of the next-best view algorithm directly on the \{GPU\} and to properly manage voxel data. Experiments are reported to illustrate the proposed attention based approach and to show the effectiveness of GPU-based next-best view planning compared to the same algorithm executed on the CPU. "
}
@article{tagkey1986155,
title = "Information and computing recommendations for a course at the secondary school level: A report of the \{AFIPS\} secondary education project committee ",
journal = "Education and Computing ",
volume = "2",
number = "3",
pages = "155 - 183",
year = "1986",
note = "",
issn = "0167-9287",
doi = "https://doi.org/10.1016/S0167-9287(86)91522-0",
url = "http://www.sciencedirect.com/science/article/pii/S0167928786915220",
key = "tagkey1986155"
}
@article{Reina20121377,
title = "Self-learning classification of radar features for scene understanding ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "11",
pages = "1377 - 1388",
year = "2012",
note = "Towards Autonomous Robotic Systems 2011 ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012000462",
author = "Giulio Reina and Annalisa Milella and James Underwood",
keywords = "Field robotics",
keywords = "Radar-based perception",
keywords = "Self-learning classifier ",
abstract = "Autonomous driving is a challenging problem in mobile robotics, particularly when the domain is unstructured, as in an outdoor setting. In addition, field scenarios are often characterized by low visibility as well, due to changes in lighting conditions, weather phenomena including fog, rain, snow and hail, or the presence of dust clouds and smoke. Thus, advanced perception systems are primarily required for an off-road robot to sense and understand its environment recognizing artificial and natural structures, topology, vegetation and paths, while ensuring, at the same time, robustness under compromised visibility. In this paper the use of millimeter-wave radar is proposed as a possible solution for all-weather off-road perception. A self-learning approach is developed to train a classifier for radar image interpretation and autonomous navigation. The proposed classifier features two main stages: an adaptive training stage and a classification stage. During the training stage, the system automatically learns to associate the appearance of radar data with class labels. Then, it makes predictions based on past observations. The training set is continuously updated online using the latest radar readings, thus making it feasible to use the system for long range and long duration navigation, over changing environments. Experimental results, obtained with an unmanned ground vehicle operating in a rural environment, are presented to validate this approach. A quantitative comparison with laser data is also included showing good range accuracy and mapping ability as well. Finally, conclusions are drawn on the utility of millimeter-wave radar as a robotic sensor for persistent and accurate perception in natural scenarios. "
}
@incollection{Marinescu201765,
title = "Chapter 3 - Managing Complexity of Large-Scale Cyber-Physical Systems ",
editor = "Marinescu, Dan C. ",
booktitle = "Complex Systems and Clouds ",
publisher = "Elsevier",
edition = "",
address = "Boston",
year = "2017",
pages = "65 - 112",
series = "Computer Science Reviews and Trends",
isbn = "978-0-12-804041-6",
doi = "https://doi.org/10.1016/B978-0-12-804041-6.00003-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128040416000037",
author = "Dan C. Marinescu",
keywords = "Cyber-physical systems",
keywords = "Autonomic computing",
keywords = "Self-organization",
keywords = "Scalable system organization",
keywords = "Complex networks",
keywords = "Virtualization by aggregation",
keywords = "Coalition formation",
keywords = "Cooperative games ",
abstract = "Abstract Cyber-physical systems are now ubiquitous and their undeniable complexity is caused by a set of factors reviewed in the first sections of the chapter, which also discusses how software has pushed the limits of system composability, as well as challenges specific to large-scale, cyber-physical systems. Autonomic computing and scalable system organizations are the topics of the next sections. The discussion of virtualization by aggregation and coalition formation is followed by a survey of cooperative games for coalition formation. An indepth analysis of a self-organization protocol for very large sensor networks concludes the chapter. "
}
@article{Corti2016584,
title = "A metrological characterization of the Kinect \{V2\} time-of-flight camera ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "584 - 594",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002195",
author = "Andrea Corti and Silvio Giancola and Giacomo Mainetti and Remo Sala",
keywords = "Time-of-flight",
keywords = "Kinect v2",
keywords = "Characterization",
keywords = "Point Cloud Library",
keywords = "GUM",
keywords = "Metrological qualification ",
abstract = "Abstract A metrological characterization process for time-of-flight (TOF) cameras is proposed in this paper and applied to the Microsoft Kinect V2. Based on the Guide to the Expression of Uncertainty in Measurement (GUM), the uncertainty of a three-dimensional (3D) scene reconstruction is analysed. In particular, the random and the systematic components of the uncertainty are evaluated for the single sensor pixel and for the complete depth camera. The manufacturer declares an uncertainty in the measurement of the central pixel of the sensor of about few millimetres (Kinect for Windows Features, 2015), which is considerably better than the first version of the Microsoft Kinect (Chow et al., 2012  [1]). This work points out that performances are highly influenced by measuring conditions and environmental parameters of the scene; actually the 3D point reconstruction uncertainty can vary from 1.5 to tens of millimetres. "
}
@article{Charalampous2015166,
title = "Thorough robot navigation based on \{SVM\} local planning ",
journal = "Robotics and Autonomous Systems ",
volume = "70",
number = "",
pages = "166 - 180",
year = "2015",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015000342",
author = "Konstantinos Charalampous and Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Path planning",
keywords = "SVM",
keywords = "Robot navigation",
keywords = "Point cloud ",
abstract = "Abstract A prerequisite for autonomous robot navigation is the extraction of a path that is both efficient and safe in terms of collision. Towards this end, the paper in hand presents a novel local path planning method, incorporating the support vector machines (SVM) theory. The original \{SVM\} based module exploits a 2D map of points which are considered to be obstacles, so as to culminate in a collision free path. A unique attribute of the proposed \{SVM\} based local path planning algorithm is that it considers the consecutive positions of the global path trajectory, the embodiment of the robot and clusters the obstacles accordingly. Thus, the derived trajectory is a physically constrained path inasmuch as it considers the maximum margin notion of the \{SVM\} theory. Instead of providing a purely theoretical approach for local planning assessed using only artificial data, we integrate our local planner into an autonomous navigation system which is evaluated in real-world scenarios in order to show its efficacy. The latter framework firstly constructs a global 3D metric map of the perceived environment and then it converts it into a 2D map upon which a global path planner unrolls. The global map grows incrementally, by registering the collected point clouds over the robot’s route towards a goal position. Moreover, the navigation is supported by an obstacle detection strategy based on v-disparity images. The system–and, consequently, the presented local path planner–was evaluated in long range outdoors scenarios, navigating successfully within congestive environments. "
}
@article{Brenner2016227,
title = "A Seamless Convergence of the Digital and Physical Factory Aiming in Personalized Product Emergence Process (PPEP) for Smart Products within \{ESB\} Logistics Learning Factory at Reutlingen University ",
journal = "Procedia \{CIRP\} ",
volume = "54",
number = "",
pages = "227 - 232",
year = "2016",
note = "6th \{CIRP\} Conference on Learning Factories ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.06.108",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309672",
author = "Beate Brenner and Vera Hummel",
keywords = "Seamless",
keywords = "digital cloud-based and physical learning factory",
keywords = "personalized product development",
keywords = "3D experience software",
keywords = "collaborative interactive environment",
keywords = "Industrie4.0 principles",
keywords = "SCRUM ",
abstract = "Abstract A seamless convergence of the digital and physical factory aiming in personalized Product Emergence Process (PPEP) for smart products within \{ESB\} Logistics Learning Factory at Reutlingen University. A completely new business model with reference to Industrie4.0 and facilitated by 3D Experience Software in today's networked society in which customers expect immediate responses, delightful experience and simple solutions is one of the mission scenarios in the \{ESB\} Logistics Learning Factory at \{ESB\} Business School (Reutlingen University). The business experience platform provides software solutions for every organization in the company respectively in the factory. An interface with dashboards, project management apps, 3D - design and construction apps with high end visualization, manufacturing and simulation apps as well as intelligence and social network apps in a collaborative interactive environment help the user to learn the creation of a value end to end process for a personalized virtual and later real produced product. Instead of traditional ways of working and a conventional operating factory real workers and robots work semi-intuitive together. Centerpiece in the self-planned interim factory is the smart personalized product, uniquely identifiable and locatable at all times during the production process – a scooter with an individual colored mobile phone – holder for any smart phone produced with a 3D printer in lot size one. Smart products have in the future solutions incorporated internet based services – designed and manufactured - at the costs of mass products. Additionally the scooter is equipped with a retrievable declarative product memory. Monitoring and control is handled by sensor tags and a raspberry positioned on the product. The engineering design and implementation of a changeable production system is guided by a self-execution system that independently find amongst others esplanade workplaces. The imparted competences to students and professionals are project management method SCRUM, customization of workflows by Industrie4.0 principles, the enhancements of products with new personalized intelligent parts, electrical and electronic self-programmed components and the control of access of the product memory information, to plan in a digital engineering environment and set up of the physical factory to produce customer orders. The gained action-orientated experience refers to the chances and requirements for holistic digital and physical systems. "
}
@article{Huxtable201646,
title = "On Servitization of the Manufacturing Industry in the \{UK\} ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "46 - 51",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.042",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116307922",
author = "James Huxtable and Dirk Schaefer",
keywords = "Servitization",
keywords = "Industry 4.0",
keywords = "Big Data",
keywords = "Cloud-Based Design and Manufacturing",
keywords = "Cyber Security",
keywords = "Autonomy ",
abstract = "Abstract For a number of years, an increase in manufacturing-related service activities being provided by third parties rather than “in-house” departments has been observed. This trend appears to be strengthening in the context of the Industry 4.0 landscape. The purpose of this paper is to investigate in what sense and at what rate the domain of manufacturing in the \{UK\} is transitioning into a major service-oriented field and what types of manufacturing-related activities are most/least suitable for future servitization. Hence, the paper addresses the following questions: i) To what extent has Servitization been adopted in the UK? – What impact is Industry 4.0 currently making? ii) What types of services are currently being offered as a result of industry 4.0? iii) What pros/cons/opportunities/threats does Industry 4.0 bring to British Servitization? – What wider economic issues will make an impact? The research summarized in this paper presents an answer to the outlined questions and draws conclusions as to how this field may further develop in future. The main contributions of this research are the closing of a critical gap in literature by investigating the relationships between the two fields of Servitization and Industry 4.0, and the creation of a framework to allow companies to make themselves aware of Industry 4.0-related services, whilst ensuring these new service innovations are offered in-line with their current business model. "
}
@article{Paul2013136,
title = "A novel surface segmentation approach for robotic manipulator-based maintenance operation planning ",
journal = "Automation in Construction ",
volume = "29",
number = "",
pages = "136 - 147",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2012.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0926580512001483",
author = "Gavin Paul and Ngaiming Kwok and Dikai Liu",
keywords = "Surface segmentation",
keywords = "Manipulator trajectory planning",
keywords = "Maintenance operations ",
abstract = "This paper presents a novel approach to segmenting a three-dimensional surface map by considering the task requirements and the movements of an industrial robot manipulator. Maintenance operations, such as abrasive blasting, that are performed by a field robot manipulator can be made more efficient by exploiting surface segmentation. The approach in this paper utilises an aggregate of multiple connectivity graphs, with graph edges defined by task constraints, and graph vertices that correspond to small, maintenance-specific target surfaces, known as Scale-Like Discs (SLDs). The task constraints for maintenance operations are based on the characteristics of neighbouring SLDs. The combined connectivity graphs are analysed to find clusters of vertices, thus segmenting the surface map into groups of related SLDs. Experiments conducted in three typical bridge maintenance environments have shown that the approach can reduce garnet usage by 10%–40% and reduce the manipulator joint movements by up to 35%. "
}
@article{Tresset2013348,
title = "Portrait drawing by Paul the robot ",
journal = "Computers & Graphics ",
volume = "37",
number = "5",
pages = "348 - 363",
year = "2013",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2013.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0097849313000149",
author = "Patrick Tresset and Frederic Fol Leymarie",
keywords = "Fine arts",
keywords = "Media arts",
keywords = "Computer graphics",
keywords = "Non-photorealistic rendering (NPR)",
keywords = "Computer vision",
keywords = "Robotics ",
abstract = "We describe Paul, a robotic installation that produces observational face drawings of people. Paul is a naive drawer: it does not have highlevel knowledge of the structures constitutive of the human face (such as the mouth, nose, eyes) nor the capability of learning expertise based on experience as a human would. However, Paul is able to draw using the equivalent of an artist's stylistic signature based on a number of processes mimicking drawing skills and technique, which together form a drawing cycle. Furthermore, we present here our first efforts in implementing two different versions of visual feedback to permit the robot to iteratively augment and improve a drawing which initially is built from a process of salient lines recovery. The first form of visual feedback we study we refer to as computational as it involves a purely internal (memory-based) representation of regions to render via shading by the robot. The second version we call physical as it involves the use of a camera as an ‘eye’ taking new snapshots of the artefact in progress. This is then analysed to take decisions on where and how to render shading next. A main point we emphasise in this work is the issue of embodiment of graphical systems, in our case in a robotic platform. We present our arguments in favour of such a position for the graphics community to reflect upon. Finally, we emphasise that the drawings produced by Paul have been considered of interest by fine art professionals in recent international art fairs and exhibitions, as well as by the public at large. One drawing is now in the Victoria and Albert museum collection. We identify a number of factors that may account for such perceived qualities of the produced drawings. "
}
@article{Berglund2016697,
title = "On The Trade-off between Data Density and Data Capture Duration in 3D Laser Scanning for Production System Engineering ",
journal = "Procedia \{CIRP\} ",
volume = "41",
number = "",
pages = "697 - 701",
year = "2016",
note = "Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.12.141",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116000366",
author = "Jonatan Berglund and Erik Lindskog and Björn Johansson",
keywords = "3D scanning",
keywords = "Virtual",
keywords = "Production",
keywords = "Point cloud ",
abstract = "Abstract 3D laser scanning is a technology for capture of spatial data in three dimensions. The technology originates from the field of surveying and has since been spread to several other application areas. In the realm of production system engineering, 3D laser scanning is primarily used to verify equipment installation. Lately applications for the 3D scan data are emerging also when it comes to the planning of the installations and the use of the equipment. The motivation for using 3D scan data in the case of planning is primarily to have up-to-date and verified spatial data, including any undocumenter alterations from drawings and models. The process of capturing 3D scan data requires access to an unmoving production system which can be costly, either due to stopping produciton or by accessing it during nights or weekends. The more detailed the data collection is, the more time is required. Therefore there is a need to accurately define and plan the minimum data density requirement. This paper evaluates the effect of data density, and thus data collection duration, in a production system application. Data capture duration is shown to impact the usability of the resulting data. To further understand the trade-off and be able to use it as decision support there needs to be an analysis of the additional time and data storage costs created by increasing the number of scan locations. "
}
@article{Urbanová201577,
title = "Testing photogrammetry-based techniques for three-dimensional surface documentation in forensic pathology ",
journal = "Forensic Science International ",
volume = "250",
number = "",
pages = "77 - 86",
year = "2015",
note = "",
issn = "0379-0738",
doi = "https://doi.org/10.1016/j.forsciint.2015.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0379073815001073",
author = "Petra Urbanová and Petr Hejna and Mikoláš Jurda",
keywords = "Postmortem documentation",
keywords = "Optical surface scanning",
keywords = "Photogrammetry",
keywords = "Point cloud comparison ",
abstract = "Abstract Three-dimensional surface technologies particularly close range photogrammetry and optical surface scanning have recently advanced into affordable, flexible and accurate techniques. Forensic postmortem investigation as performed on a daily basis, however, has not yet fully benefited from their potentials. In the present paper, we tested two approaches to 3D external body documentation – digital camera-based photogrammetry combined with commercial Agisoft PhotoScan® software and stereophotogrammetry-based Vectra H1®, a portable handheld surface scanner. In order to conduct the study three human subjects were selected, a living person, a 25-year-old female, and two forensic cases admitted for postmortem examination at the Department of Forensic Medicine, Hradec Králové, Czech Republic (both 63-year-old males), one dead to traumatic, self-inflicted, injuries (suicide by hanging), the other diagnosed with the heart failure. All three cases were photographed in 360° manner with a Nikon 7000 digital camera and simultaneously documented with the handheld scanner. In addition to having recorded the pre-autopsy phase of the forensic cases, both techniques were employed in various stages of autopsy. The sets of collected digital images (approximately 100 per case) were further processed to generate point clouds and 3D meshes. Final 3D models (a pair per individual) were counted for numbers of points and polygons, then assessed visually and compared quantitatively using \{ICP\} alignment algorithm and a cloud point comparison technique based on closest point to point distances. Both techniques were proven to be easy to handle and equally laborious. While collecting the images at autopsy took around 20 min, the post-processing was much more time-demanding and required up to 10 h of computation time. Moreover, for the full-body scanning the post-processing of the handheld scanner required rather time-consuming manual image alignment. In all instances the applied approaches produced high-resolution photorealistic, real sized or easy to calibrate 3D surface models. Both methods equally failed when the scanned body surface was covered with body hair or reflective moist areas. Still, it can be concluded that single camera close range photogrammetry and optical surface scanning using Vectra \{H1\} scanner represent relatively low-cost solutions which were shown to be beneficial for postmortem body documentation in forensic pathology. "
}
@article{Faria2012396,
title = "Extracting data from human manipulation of objects towards improving autonomous robotic grasping ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "396 - 410",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.020",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001527",
author = "Diego R. Faria and Ricardo Martins and Jorge Lobo and Jorge Dias",
keywords = "Human demonstration",
keywords = "Manipulation task representation",
keywords = "Motion pattern",
keywords = "Probabilistic object representation",
keywords = "Contact points",
keywords = "Stable grasp ",
abstract = "Humans excel in manipulation tasks, a basic skill for our survival and a key feature in our manmade world of artefacts and devices. In this work, we study how humans manipulate simple daily objects, and construct a probabilistic representation model for the tasks and objects useful for autonomous grasping and manipulation by robotic hands. Human demonstrations of predefined object manipulation tasks are recorded from both the human hand and object points of view. The multimodal data acquisition system records human gaze, hand and fingers 6D pose, finger flexure, tactile forces distributed on the inside of the hand, colour images and stereo depth map, and also object 6D pose and object tactile forces using instrumented objects. From the acquired data, relevant features are detected concerning motion patterns, tactile forces and hand-object states. This will enable modelling a class of tasks from sets of repeated demonstrations of the same task, so that a generalised probabilistic representation is derived to be used for task planning in artificial systems. An object centred probabilistic volumetric model is proposed to fuse the multimodal data and map contact regions, gaze, and tactile forces during stable grasps. This model is refined by segmenting the volume into components approximated by superquadrics, and overlaying the contact points used taking into account the task context. Results show that the features extracted are sufficient to distinguish key patterns that characterise each stage of the manipulation tasks, ranging from simple object displacement, where the same grasp is employed during manipulation (homogeneous manipulation) to more complex interactions such as object reorientation, fine positioning, and sequential in-hand rotation (dexterous manipulation). The framework presented retains the relevant data from human demonstrations, concerning both the manipulation and object characteristics, to be used by future grasp planning in artificial systems performing autonomous grasping. "
}
@article{Hiremath201441,
title = "Laser range finder model for autonomous navigation of a robot in a maize field using a particle filter ",
journal = "Computers and Electronics in Agriculture ",
volume = "100",
number = "",
pages = "41 - 50",
year = "2014",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2013.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0168169913002470",
author = "Santosh A. Hiremath and Gerie W.A.M. van der Heijden and Frits K. van Evert and Alfred Stein and Cajo J.F. ter Braak",
keywords = "Probabilistic robotics",
keywords = "Autonomous navigation",
keywords = "Particle filter",
keywords = "Laser range finder ",
abstract = "Abstract Autonomous navigation of robots in an agricultural environment is a difficult task due to the inherent uncertainty in the environment. Many existing agricultural robots use computer vision and other sensors to supplement Global Positioning System (GPS) data when navigating. Vision based methods are sensitive to ambient lighting conditions. This is a major disadvantage in an outdoor environment. The current study presents a novel probabilistic sensor model for a 2D range finder (LIDAR) from first principles. Using this sensor model, a particle filter based navigation algorithm (PF) for autonomous navigation in a maize field was developed. The algorithm was tested in various field conditions with varying plant sizes, different row patterns and at several scanning frequencies. Results showed that the Root Mean Squared Error of the robot heading and lateral deviation were equal to 2.4 degrees and 0.04 m, respectively. It was concluded that the performance of the proposed navigation method is robust in a semi-structured agricultural environment. "
}
@article{Healy201377,
title = "Artificial interfaces (“AI”) in surgery: Historic development, current status and program implementation in the public health sector ",
journal = "Surgical Oncology ",
volume = "22",
number = "2",
pages = "77 - 85",
year = "2013",
note = "",
issn = "0960-7404",
doi = "https://doi.org/10.1016/j.suronc.2012.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S096074041200093X",
author = "Donagh A. Healy and Shane P. Murphy and John P. Burke and John C. Coffey",
keywords = "Robotic colorectal surgery",
keywords = "Da Vinci surgical system",
keywords = "Telepresence",
keywords = "Telerobotics",
keywords = "Robotics ",
abstract = "The past two decades have seen considerable advances in the application of artificial interfaces (AI) in surgery. Several have been developed including \{AESOP\} (Automated Endoscopic System for Optimal Positioning), Zeus and the Da Vinci Surgical System (DVSS). Whilst each has advantages \{DVSS\} is being used increasingly across multiple surgical specialities. These developments generate many challenges in an era where the emphasis is increasingly on safer and cost-effective surgery. Whilst the role of \{DVSS\} is firmly established in urologic and gynaecologic surgery, the role of \{DVSS\} in gastrointestinal surgery is evolving. Recent data indicate that it is at least as oncologically effective, whilst providing numerous benefits (e.g. reduced conversion and complication rates) over traditional laparoscopic approaches. The increasing adoption of AI/DVSS worldwide places institutes and health sectors under increasing pressure to adopt and develop such programs. This article provides (1) an update on the current status of \{AI\} in surgery in general and in colorectal surgery and (2) an appraisal of the cost implications of the establishment and implementation of AI/DVSS–based provisions in the public health sector. The numerous challenges faced generate many opportunities in the implementation of present and future surgical technologies. "
}
@article{Zahawi2015287,
title = "Using lightweight unmanned aerial vehicles to monitor tropical forest recovery ",
journal = "Biological Conservation ",
volume = "186",
number = "",
pages = "287 - 295",
year = "2015",
note = "",
issn = "0006-3207",
doi = "https://doi.org/10.1016/j.biocon.2015.03.031",
url = "http://www.sciencedirect.com/science/article/pii/S0006320715001421",
author = "Rakan A. Zahawi and Jonathan P. Dandois and Karen D. Holl and Dana Nadwodny and J. Leighton Reid and Erle C. Ellis",
keywords = "Canopy structure",
keywords = "Costa Rica",
keywords = "Drone",
keywords = "Ecosynth",
keywords = "Hexacopter",
keywords = "LiDAR",
keywords = "Point cloud model ",
abstract = "Abstract Large areas of tropical lands are being removed from agriculture and restored to address conservation goals. However, monitoring the ecological value of these efforts at the individual land-owner scale is rare, owing largely to issues of cost and accessibility. Traditional field-based measures for assessing forest recovery and habitat quality can be labour intensive and costly. Here we assess whether remote sensing measurements from lightweight unmanned aerial vehicles (UAV) are a cost-effective substitute for traditional field measures. An inexpensive UAV-based remote sensing methodology, “Ecosynth”, was applied to measure forest canopy structure across field plots in a 7–9-yr tropical forest restoration study in southern Costa Rica. Ecosynth methods combine aerial images from consumer-grade digital cameras with computer vision software to generate 3D ‘point cloud’ models of vegetation at high spatial resolutions. Ecosynth canopy structure measurements were compared to field-based measures and their ability to predict the abundance of frugivorous birds; key seed dispersers that are sensitive to canopy structure. Ecosynth canopy height measurements were highly correlated with field-based measurements (R2 ⩾ 0.85), a result comparable in precision to LiDAR-based remote sensing measurements. Ecosynth parameters were also strongly correlated with above-ground biomass (R2 ⩾ 0.81) and percent canopy openness (R2 = 0.82). Correlations were weaker with proportion-based measures such as canopy roughness (R2 = 0.53). Several Ecosynth metrics (e.g., canopy openness and height) predicted frugivore presence and abundance at levels of accuracy similar to those of field-based measurements. Ecosynth \{UAV\} remote-sensing provides an effective alternate methodology to traditional field-based measures of evaluating forest structure and complexity across landscapes. Furthermore, given the volume of data that can be generated in a single flight plan, as well as the ability to use the technology in remote areas, these methods could expand the scope of studies on forest dynamics and recovery when combined with field-based calibration plots. "
}
@article{Gazzarata20151124,
title = "A Standardized \{SOA\} Based Solution to Guarantee the Secure Access to \{EHR\} ",
journal = "Procedia Computer Science ",
volume = "64",
number = "",
pages = "1124 - 1129",
year = "2015",
note = "Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2015 October 7-9, 2015 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.08.582",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915027179",
author = "Giorgia Gazzarata and Roberta Gazzarata and Mauro Giacomini",
keywords = "auditability",
keywords = "access control",
keywords = "interoperability",
keywords = "secure use of cloud for clinical data ",
abstract = "Abstract Continued advances in science and technology and general improvements in environmental and social conditions is extending the population's life expectancy with the consequence that a person can undergo many episodes of healthcare during lifetime. In this context, the Electronic Health Record (EHR) represents a fundamental tool to support treatment continuity, education and research. The economic restrictions in healthcare and the need to increase efficiency in term of cost/effectiveness ration could lead institutional organizations to choose cloud solutions to host the EHR. In this paper, a cloud infrastructure architecture, focus on the \{EHR\} and based on \{SOA\} (Service Oriented Architecture) paradigm, which is able both to completely support technical, semantic and process interoperability, and to guarantee security, is proposed. In order to achieve this goal, the indications and the standards proposed by Healthcare Services Specification Project (HSSP) was adopted. Different situations can be managed by the proposed architecture and are described: the user access to an encrypted resource in EHR, the availability of \{EHR\} content for external Decision Support Systems, the update of \{EHR\} content, the management of semantic of clinical data exchanged among distributed healthcare organizations. Finally, the authors propose a discussion on the proposed solution. "
}
@article{Burian201263,
title = "Unified Storage for Laser Scanner Data* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "7",
pages = "63 - 66",
year = "2012",
note = "11th IFAC,IEEE International Conference on Programmable Devices and Embedded Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120523-3-CZ-3015.00014",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015350631",
author = "F. Burian and L. Zalud and T. Florian and T. Jilek",
keywords = "Robotics",
keywords = "Self-localization",
keywords = "Map building",
keywords = "Laser mapping ",
abstract = "The main goal of this paper is to show a way to resolve interoperability of more different laser proximity scanners into a mapping engine. The idea is to make a software layer with unified data approach to be able to access laser scanner data from different 2D or 3D proximity scanners in unified way. Presented work is a part of project with the aim to make widely accessible data for self-localization algorithms assessment in mobile robotics. All the described algorithms, source code and scanner data will be accessible on project web-page http://www.mapping.uamt.feec.vutbr.cz. "
}
@article{Halbach2013145,
title = "Job planning and supervisory control for automated earthmoving using 3D graphical tools ",
journal = "Automation in Construction ",
volume = "32",
number = "",
pages = "145 - 160",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513000277",
author = "Eric Halbach and Aarne Halme",
keywords = "Earthmoving",
keywords = "Automation",
keywords = "Robotics",
keywords = "Job planning",
keywords = "Supervisory control",
keywords = "Simulation",
keywords = "3D graphics",
keywords = "Wheel loader",
keywords = "Augmented reality ",
abstract = "Abstract Planning tools and algorithms are presented for enabling supervisory control of automated earthmoving performed by a robotic wheel loader. Interactive 3D graphical objects are rendered over a worksite model, and allow a remote human operator to specify high-level plans for pile transfer and area clearing jobs. These are automatically translated into lower-level plans for the machine to follow and are displayed graphically back to the operator, who then mostly monitors work but can intervene in a supervisory capacity. The tools were developed and tested using Matlab, and were able to guide simulated jobs to completion. Outdoor manually-driven tests using snow were also conducted to verify that heightmaps from a 3D laser rangefinder could be used to correctly track progress and generate commands using the same tools and algorithms. Augmented Reality versions of the tools present a concept of how they could be used in real-world applications. "
}
@article{Nurunnabi2014106,
title = "Robust statistical approaches for local planar surface fitting in 3D laser scanning data ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "96",
number = "",
pages = "106 - 122",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614001762",
author = "Abdul Nurunnabi and David Belton and Geoff West",
keywords = "3D modelling",
keywords = "Feature extraction",
keywords = "Normal estimation",
keywords = "Outlier",
keywords = "Plane fitting",
keywords = "Point cloud",
keywords = "Robustness",
keywords = "Segmentation",
keywords = "Surface reconstruction ",
abstract = "Abstract This paper proposes robust methods for local planar surface fitting in 3D laser scanning data. Searching through the literature revealed that many authors frequently used Least Squares (LS) and Principal Component Analysis (PCA) for point cloud processing without any treatment of outliers. It is known that \{LS\} and \{PCA\} are sensitive to outliers and can give inconsistent and misleading estimates. \{RANdom\} \{SAmple\} Consensus (RANSAC) is one of the most well-known robust methods used for model fitting when noise and/or outliers are present. We concentrate on the recently introduced Deterministic Minimum Covariance Determinant estimator and robust PCA, and propose two variants of statistically robust algorithms for fitting planar surfaces to 3D laser scanning point cloud data. The performance of the proposed robust methods is demonstrated by qualitative and quantitative analysis through several synthetic and mobile laser scanning 3D data sets for different applications. Using simulated data, and comparisons with LS, PCA, RANSAC, variants of \{RANSAC\} and other robust statistical methods, we demonstrate that the new algorithms are significantly more efficient, faster, and produce more accurate fits and robust local statistics (e.g. surface normals), necessary for many point cloud processing tasks. Consider one example data set used consisting of 100 points with 20% outliers representing a plane. The proposed methods called DetRD-PCA and DetRPCA, produce bias angles (angle between the fitted planes with and without outliers) of 0.20° and 0.24° respectively, whereas LS, \{PCA\} and \{RANSAC\} produce worse bias angles of 52.49°, 39.55° and 0.79° respectively. In terms of speed, DetRD-PCA takes 0.033 s on average for fitting a plane, which is approximately 6.5, 25.4 and 25.8 times faster than RANSAC, and two other robust statistical methods, respectively. The estimated robust surface normals and curvatures from the new methods have been used for plane fitting, sharp feature preservation and segmentation in 3D point clouds obtained from laser scanners. The results are significantly better and more efficiently computed than those obtained by existing methods. "
}
@article{PerezYus2017192,
title = "Stairs detection with odometry-aided traversal from a wearable RGB-D camera ",
journal = "Computer Vision and Image Understanding ",
volume = "154",
number = "",
pages = "192 - 205",
year = "2017",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.04.007",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300315",
author = "A. Perez-Yus and D. Gutierrez-Gomez and G. Lopez-Nicolas and J.J. Guerrero",
keywords = "Stair detection",
keywords = "Visually impaired",
keywords = "RGB-D",
keywords = "Visual odometry",
keywords = "Wearable computing ",
abstract = "Abstract Stairs are one of the most common structures present in human-made scenarios, but also one of the most dangerous for those with vision problems. In this work we propose a complete method to detect, locate and parametrise stairs with a wearable RGB-D camera. Our algorithm uses the depth data to determine if the horizontal planes in the scene are valid steps of a staircase judging their dimensions and relative positions. As a result we obtain a scaled model of the staircase with the spatial location and orientation with respect to the subject. The visual odometry is also estimated to continuously recover the current position and orientation of the user while moving. This enhances the system giving the ability to come back to previously detected features and providing location awareness of the user during the climb. Simultaneously, the detection of the staircase during the traversal is used to correct the drift of the visual odometry. A comparison of results of the stair detection with other state-of-the-art algorithms was performed using public dataset. Additional experiments have also been carried out, recording our own natural scenes with a chest-mounted RGB-D camera in indoor scenarios. The algorithm is robust enough to work in real-time and even under partial occlusions of the stair. "
}
@article{Francis2014776,
title = "Observations of wind direction by automated analysis of images from Mars and the \{MSL\} rover ",
journal = "Acta Astronautica ",
volume = "94",
number = "2",
pages = "776 - 783",
year = "2014",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2013.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0094576513003548",
author = "Raymond Francis and John Moores and Kenneth McIsaac and David Choi and Gordon Osinski",
keywords = "Computer vision",
keywords = "Normalized cross-correlation",
keywords = "Winds",
keywords = "Clouds",
keywords = "Planetary atmospheres",
keywords = "Mars Science Laboratory ",
abstract = "Abstract Past missions to Mars have revealed the presence of clouds in the atmosphere, visible both from the surface and from orbit. Where atmospheric sounding instrumentation is not available, the motion of such clouds can be used as a proxy for wind observations. Such observations aid in the study of the Martian climate, as well as of mass and moisture transport in the atmosphere. An understanding of the water cycle on Mars has important implications for models of the transport, distribution, and preservation of any biomarkers which might exist from past or present life on the planet. The present work describes an algorithm for automated image analysis, the function of which is to identify clouds in sequences of images of the Martian sky, and to track their movement across frames in the sequence to allow a calculation of the wind vector. The system is currently under development using imagery from previous surface missions, particularly the Phoenix lander, for reference and test. Past work has used these images for manual tracking of clouds and wind estimation; the current effort aims to automate the process to allow faster and more accurate analysis. The work will be finalized with the availability of data from the NavCam imager aboard the Mars Science Laboratory (MSL) rover, now operating on Mars since August 2012. Once tested with the \{MSL\} imagery, the system will be used for regular observations of the wind in the atmosphere near the \{MSL\} landing site. The image-analysis strategy used in the algorithm is presented, and its performance to date in recognizing the types of clouds expected on Mars is described. The tracking performance between frames in the reference data is shown, and the future utility of the system is described. The work is undertaken under a \{NASA\} Participating Scientist project, with support from the Canadian Space Agency. "
}
@article{Mahowald201453,
title = "The size distribution of desert dust aerosols and its impact on the Earth system ",
journal = "Aeolian Research ",
volume = "15",
number = "",
pages = "53 - 71",
year = "2014",
note = "",
issn = "1875-9637",
doi = "https://doi.org/10.1016/j.aeolia.2013.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S1875963713000736",
author = "Natalie Mahowald and Samuel Albani and Jasper F. Kok and Sebastian Engelstaeder and Rachel Scanza and Daniel S. Ward and Mark G. Flanner",
keywords = "Desert dust",
keywords = "Size distribution",
keywords = "Biogeochemistry",
keywords = "Radiative effects",
keywords = "Indirect effects on clouds ",
abstract = "Abstract The global cycle of desert dust aerosols responds strongly to climate and human perturbations, and, in turn, impacts climate and biogeochemistry. Here we focus on desert dust size distributions, how these are characterized, emitted from the surface, evolve in the atmosphere, and impact climate and biogeochemistry. Observations, theory and global model results are synthesized to highlight the evolution and impact of dust sizes. Individual particles sizes are, to a large extent, set by the soil properties and the mobilization process. The lifetime of different particle sizes controls the evolution of the size distribution as the particles move downwind, as larger particles fall out more quickly. The dust size distribution strongly controls the radiative impact of the aerosols, as well as their interactions with clouds. The size of particles controls how far downwind they travel, and thus their ability to impact biogeochemistry downwind of the source region. "
}
@article{Chougule2014212,
title = "Development of patient specific implants for Minimum Invasive Spine Surgeries (MISS) from non-invasive imaging techniques by reverse engineering and additive manufacturing techniques ",
journal = "Procedia Engineering ",
volume = "97",
number = "",
pages = "212 - 219",
year = "2014",
note = ""12th Global Congress on Manufacturing and Management" \{GCMM\} - 2014 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.12.244",
url = "http://www.sciencedirect.com/science/article/pii/S1877705814033037",
author = "V.N. Chougule and A.V. Mulay and B.B. Ahuja",
keywords = "Point Cloud Data",
keywords = "CT scans",
keywords = "Image Processing",
keywords = "threshold",
keywords = "NURBs",
keywords = "free form surface ",
abstract = "Abstract Reverse Engineering and Rapid Prototyping are extensively used technologies by both research and industrial community for rapid developments in various industrial as well as Bio-medical applications. Recent advances in computer technology and Bio-medicines enabled Computer Aided Design (CAD) to find many novel applications in Bio-medical engineering and integration of \{CAD\} and Bio-medical technology is usually referred as Bio-CAD. The major objective of the current research work is to generate an efficient algorithm for generation of free form surface from non-invasive \{CT\} scan images. Minimally Invasive Spine Surgery (MISS) have enabled spinal surgeons to select patients and treat several spinal disorders like degenerative disc disease, herniated disc, fractures, tumors, infections, instability, deformity, etc. with less disruption of muscles, which enables patient towards faster recovery to normal functions, reduces operative blood loss. In this paper, it is proposed to extract point cloud data from stalk of non-invasive \{CT\} scan images by using Image Processing techniques and Reverse Engineering approach. This point cloud data is to be processed for noise reduction, point cloud data segmentation and \{CAD\} model generation. This image-based \{CAD\} modeling approach begins with the acquisition of \{CT\} scan in \{DICOM\} 3.0 format. The point cloud estimation is based on threshold techniques and edge detection method. This point cloud data is used for construction of 3D \{CAD\} model by fitting free form \{NURB\} surface between theses points and then fitting surface between these curve networks by swept blend technique. An efficient and robust algorithm has been developed for generation of curves from unorganized point cloud data. "
}
@article{Popescu201475,
title = "Direct Toolpath Generation Based on Graph Theory for Milling Roughing ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "75 - 80",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.013",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010440",
author = "Daniela Popescu and Florin Popister and Sorin Popescu and Calin Neamtu and Mircia Gurzau",
keywords = "direct toolpath",
keywords = "graph theory",
keywords = "cloud points",
keywords = "roughing ",
abstract = "Abstract The paper presents a tool path generation methodology for roughing operation based on the oriented graph theory. The cutting areas are identified using an original method that is based on a bicolor and binary map. The toolpath is generated using the searching Dijkstra algorithm inside a graph in order to find the single-source shortest path. The method was employed in order to be applied on ordered and/or unordered point clouds. The entire algorithm was implemented into a mathematic calculus solution which allows the import of point clouds and its processing until the final \{NC\} code is generated. "
}
@article{Ntouskos201310,
title = "Saliency prediction in the coherence theory of attention ",
journal = "Biologically Inspired Cognitive Architectures ",
volume = "5",
number = "",
pages = "10 - 28",
year = "2013",
note = "Extended versions of selected papers from the Third Annual Meeting of the \{BICA\} Society (BICA 2012) ",
issn = "2212-683X",
doi = "https://doi.org/10.1016/j.bica.2013.05.012",
url = "http://www.sciencedirect.com/science/article/pii/S2212683X13000479",
author = "Valsamis Ntouskos and Fiora Pirri and Matia Pizzoli and Arnab Sinha and Bruno Cafaro",
keywords = "Visual attention",
keywords = "Saliency prediction",
keywords = "Proto-objects",
keywords = "Visual search",
keywords = "Cognitive robotics",
keywords = "Cognitive vision ",
abstract = "Abstract In the coherence theory of attention, introduced by Rensink, O’Regan, and Clark (2000), a coherence field is defined by a hierarchy of structures supporting the activities taking place across the different stages of visual attention. At the interface between low level and mid-level attention processing stages are the proto-objects; these are generated in parallel and collect features of the scene at specific location and time. These structures fade away if the region is no further attended by attention. We introduce a method to computationally model these structures. Our model is based experimentally on data collected in dynamic 3D environments via the Gaze Machine, a gaze measurement framework. This framework allows to record pupil motion at the required speed and projects the point of regard in the 3D space (Pirri, Pizzoli, &amp; Rudi, 2011; Pizzoli, Rigato, Shabani, &amp; Pirri, 2011). To generate proto-objects the model is extended to vibrating circular membranes whose initial displacement is generated by the features that have been selected by classification. The energy of the vibrating membranes is used to predict saliency in visual search tasks. "
}
@article{SanchezLopez2013416,
title = "A Real-time 3D Pose Based Visual Servoing Implementation for an Autonomous Mobile Robot Manipulator ",
journal = "Procedia Technology ",
volume = "7",
number = "",
pages = "416 - 423",
year = "2013",
note = "3rd Iberoamerican Conference on Electronics Engineering and Computer Science, \{CIIECC\} 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.04.052",
url = "http://www.sciencedirect.com/science/article/pii/S2212017313000534",
author = "Jose R. Sanchez-Lopez and Antonio Marin-Hernandez and Elvia R. Palacios-Hernandez and Homero V. Rios-Figueroa and Luis F. Marin-Urias",
keywords = "Autonomous Mobile Manipulator",
keywords = "Visual Servoing",
keywords = "Robotic Arm Control",
keywords = "Mobile Robotics ",
abstract = "Today, the manipulation of objects by mobile robots is still a challenging task. This task is commonly decomposed on three stages: a) approaching to the objects, b) path planning and trajectory execution of the manipulator arm and finally c) fine tuning and grasping. In this work is presented an implementation of a 3D pose visual servoing for an autonomous mobile manipulator dealing with the last stage of the manipulation task (fine tuning and grasping). The methodology proposed consists of three steps: a) beginning with a fast monocular image segmentation, followed by b) 3D model reconstruction and finally c) pose estimation to feedback fine tuning manipulation control loop. Objects and end-effector are colored in different colors and their models are supposed to be known. Our mobile manipulator prototype consists of a stereo camera under a binocular stand-alone configuration and an anthropomorphic 7DoF arm with a parallel end-effector (gripper). Our methodology runs in real time and is suitable to perform continuous visual servoing. Experimental results are reported. "
}
@article{Bedkowski2009569,
title = "Improvement of the Robotic System for Disaster and Hazardous Threat Management ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "13",
pages = "569 - 574",
year = "2009",
note = "14th \{IFAC\} Conference on Methods and Models in Automation and Robotics ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090819-3-PL-3002.00099",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015305024",
author = "Janusz Bedkowski and Jakub Piszczek and Piotr Kowalski and Andrzej Masłowski",
abstract = "Abstract Following paper shows an improvement of the robotic system (Masłowski, 2004 and 2006) for disaster and hazardous threat management. The system uses two types of robots for investigating the potential risks in unknown environment – teleoperated and fully autonomous mobile platform. The teleoperated robot equipped with video cameras and 5DOF arm is used for hazardous materials detection and neutralization. The improvement is based on the autonomous mobile robot development based on hybrid composition of 3D laser scanners providing 3D feedback to base station. The idea of real time 3D map building is shown. The new idea of the usage given map to the supervision module of the robotics system is presented. "
}
@article{Bai2013594,
title = "Self-organized sorting of heterotypic agents via a chemotaxis paradigm ",
journal = "Science of Computer Programming ",
volume = "78",
number = "5",
pages = "594 - 611",
year = "2013",
note = "Special section: Principles and Practice of Programming in Java 2009/2010 &amp; Special section: Self-Organizing Coordination ",
issn = "0167-6423",
doi = "https://doi.org/10.1016/j.scico.2012.10.007",
url = "http://www.sciencedirect.com/science/article/pii/S016764231200192X",
author = "Linge Bai and Manolya Eyiyurekli and Peter I. Lelkes and David E. Breen",
keywords = "Chemotaxis",
keywords = "Self-organization",
keywords = "Sorting",
keywords = "Agents",
keywords = "Swarm robotics ",
abstract = "Cell sorting is a fundamental phenomenon in morphogenesis, a process that leads to shape formation in living organisms. The sorting of heterotypic cell populations is produced by a variety of inter-cellular actions, e.g. differential chemotactic response, adhesion, rigidity, and motility. Via a process called chemotaxis, living cells respond to chemicals released by other cells into the environment. Inspired by the biological phenomena of chemotaxis and cell sorting in heterotypic cell aggregates, we propose a chemotaxis-based algorithm that sorts self-organizing heterotypic agents. In our algorithm, two types of agents are initially randomly placed in a toroidal environment. Agents emit a chemical signal and interact with nearby agents. Given the appropriate parameters, the two kinds of agents self-organize into a complex aggregate consisting of a single group of one type of agent surrounded by agents of the second type. This paper describes the chemotaxis-based sorting algorithm, the behaviors of our self-organizing heterotypic agents, evaluation of the final aggregates and parametric studies of the algorithm. "
}
@article{Mandow20101239,
title = "Fast range-independent spherical subsampling of 3D laser scanner points and data reduction performance evaluation for scene registration ",
journal = "Pattern Recognition Letters ",
volume = "31",
number = "11",
pages = "1239 - 1250",
year = "2010",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2010.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0167865510000899",
author = "Anthony Mandow and Jorge L. Martínez and Antonio J. Reina and Jesús Morales",
keywords = "3D measurement system",
keywords = "Laser ranging",
keywords = "Point subsampling",
keywords = "Scene registration",
keywords = "Mobile robotics",
keywords = "Point matching ",
abstract = "Three-dimensional laser range-finders are increasingly being incorporated into applications, such as mobile robotics, that require real-time registration of scene data. However, the computational costs of adaptive range-dependent data selection and point cloud matching grow significantly with the number of points. Therefore, fast range-independent subsampling by uniform or random data reduction is usually performed at a preprocessing step. The paper proposes a new range-independent subsampling algorithm that is more effective for the widely used spherical scanning mechanism. As this type of device measures the ranges by composition of two rotations, it samples certain directions with a higher density, which can distort the registration optimization process. The proposed solution uses sensor characteristics to equalize the measure-direction density of the reduced point cloud. The paper also addresses performance assessment of subsampling methods by contributing three benchmark criteria that do not rely on a particular registration technique: one considers the ground truth transformation between two scans, and the other two are based on the analysis of a single scan. The advantages of spherical subsampling are analyzed through a comparison of range-independent methods and a simple range-dependent one with real scans from three representative scenes (urban, natural, and indoors). "
}
@article{Law2014287,
title = "Direct normal irradiance forecasting and its application to concentrated solar thermal output forecasting – A review ",
journal = "Solar Energy ",
volume = "108",
number = "",
pages = "287 - 307",
year = "2014",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2014.07.008",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X14003466",
author = "Edward W. Law and Abhnil A. Prasad and Merlinde Kay and Robert A. Taylor",
keywords = "\{DNI\} forecasting",
keywords = "Numerical weather prediction",
keywords = "Time series analysis",
keywords = "Cloud motion vector",
keywords = "Forecast accuracy",
keywords = "Concentrated solar thermal power ",
abstract = "Abstract Solar irradiance forecasting can reduce the uncertainty of solar power plant output caused by solar irradiance intermittency. Concentrated solar thermal (CST) plants generate electricity from the direct normal irradiance (DNI) component of solar irradiance. Different forecasting methods have been recommended for a range of forecast horizons relevant to electricity generation. High \{DNI\} forecast accuracy is important for achieving accurate forecasts of \{CST\} plant output which are shown to increase \{CST\} plant profitability. This paper reviews the \{DNI\} forecast accuracy of numerical weather prediction models, time series analysis methods, cloud motion vectors, and hybrid methods. The results of the reviewed papers are summarised to identify the best \{DNI\} forecast accuracy for particular forecast horizons. The application of \{DNI\} forecasts to operate \{CST\} plants is also briefly reviewed. This paper found that additional research is required for time series analysis methods to corroborate current results and for satellite-based cloud motion vectors to establish \{DNI\} forecast accuracy. It was also concluded that future research should use the same error metrics to report results to facilitate fair comparison of \{DNI\} forecast accuracy from different studies. In addition, the creation of a common high quality \{DNI\} data set to evaluate all forecasting methods would also help to verify best forecast accuracy. The review of \{DNI\} forecasting for \{CST\} plants found that using accurate 2-day ahead \{DNI\} forecasts can increase revenue and decrease penalty costs. Future research should investigate benefits from using short-term \{DNI\} forecasts from the intra-hour forecast horizon up to the 6-h forecast horizon to determine \{CST\} plant operation. Another aspect to research is to determine whether the benefit of \{DNI\} forecasts for a \{CST\} plant is affected by different regulations in different electricity markets. "
}
@article{Rossi2013139,
title = "Robot trajectory planning by assigning positions and tangential velocities ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "29",
number = "1",
pages = "139 - 156",
year = "2013",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2012.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0736584512000415",
author = "Cesare Rossi and Sergio Savino",
keywords = "Robotics",
keywords = "Robot mechanics",
keywords = "Trajectory planning ",
abstract = "A technique for the robot trajectory planning is proposed. The technique mainly consists in controlling a manipulator by assigning not only the way points on the path but also the geometrical tangent of the desired path shape at each of those points. This is achieved by assigning to the control system not only the joint variables { q i } , but also the vector values { q ̇ i } of the velocities that the joints must have when the end-effector passes through each of those trajectory points. In this way if a path is defined by a same number of points, the proposed technique permits to achieve more accurate paths than those obtained by a traditional point to point technique. Finally, some examples are presented making comparisons on same trajectories assigned by different techniques and also an example of a elaborate surface. "
}
@article{Oh2013311,
title = "Estimation of aerosol direct radiative effects for all-sky conditions from \{CERES\} and \{MODIS\} observations ",
journal = "Journal of Atmospheric and Solar-Terrestrial Physics ",
volume = "102",
number = "",
pages = "311 - 320",
year = "2013",
note = "",
issn = "1364-6826",
doi = "https://doi.org/10.1016/j.jastp.2013.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S1364682613001855",
author = "Hye-Ryun Oh and Yong-Sang Choi and Chang-Hoi Ho and Myeong-Jae Jeong",
keywords = "All-sky aerosol direct radiative effect",
keywords = "Satellite observation",
keywords = "Cloud ",
abstract = "Abstract Satellite observations have shown the global average of the aerosol direct radiative effect (DRE) at the top of the atmosphere to be approximately −5.0 W m−2. Although there is a general consensus on this quantity, it is essentially biased toward clear-sky conditions. To circumvent this limitation, the present study introduces a new method for retrieving the global \{DRE\} of aerosol over the region of 60°S–60°N for all-sky conditions (both clear and cloudy skies). The all-sky \{DRE\} was calculated on a monthly basis by combining the measured \{DRE\} for a clear sky and the simulated \{DRE\} for a cloudy sky in 1°×1° grids. For the measured clear-sky DRE, we employed aerosol, cloud, and radiation fluxes from the Cloud and Earth's Radiant Energy System (CERES) instrument and the Moderate Resolution Imaging Spectroradiometer (MODIS) onboard the Terra satellite for May 2000–December 2005. For the simulated cloudy-sky DRE, we performed radiative transfer modeling with the \{MODIS\} cloud properties in addition to the aerosol optical properties independently estimated in this study that include asymmetry factor and single scattering albedo. The results show that the global mean±standard deviation of \{DRE\} for the all-sky scene is −3.1±1.0 W m−2, which is weaker than that for the clear-sky only. This is in good agreement with the global estimates from previous studies based on different methods. The main advantage of our method is near-real-time estimation of monthly global all-sky \{DRE\} that has physical consistency with the \{CERES\} data. "
}
@article{Elor201259,
title = "A “thermodynamic” approach to multi-robot cooperative localization ",
journal = "Theoretical Computer Science ",
volume = "457",
number = "",
pages = "59 - 75",
year = "2012",
note = "",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2012.06.038",
url = "http://www.sciencedirect.com/science/article/pii/S030439751200655X",
author = "Yotam Elor and Alfred M. Bruckstein",
keywords = "Localization",
keywords = "Cooperative localization",
keywords = "Multi-agent",
keywords = "Multi-robot",
keywords = "Distributed robotics",
keywords = "Odometry",
keywords = "Dead reckoning ",
abstract = "We propose a new approach to the simultaneous cooperative localization of a very large group of simple robots capable of performing dead-reckoning and sensing the relative position of nearby robots. In the last decade, the use of distributed optimal Kalman filters (KF) to address this problem has been studied extensively. In this paper, we propose to use a very simple encounter based averaging process (denoted by EA). The idea behind \{EA\} is the following: every time two robots meet, they simply average their location estimates. We assume that two robots meet whenever they are close enough to allow relative location estimation and communication. At each meeting event, the robots average their location estimations thus reducing the localization error. Naturally, the frequency of the meetings affects the localization quality. The meetings are determined by the robots’ movement pattern. In this work we consider movement patterns which are “well mixing”, i.e. every robot meets other robots and eventually all of the robots frequently. For such a movement pattern, the time course of the expected localization error is derived. We prove that \{EA\} is asymptotically optimal and requires significantly less computation and communication resources than KF. "
}
@article{Newman20101253,
title = "The \{NASA\} robotic conjunction assessment process: Overview and operational experiences ",
journal = "Acta Astronautica ",
volume = "66",
number = "7–8",
pages = "1253 - 1261",
year = "2010",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2009.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S0094576509004913",
author = "Lauri Kraft Newman",
keywords = "Conjunction assessment",
keywords = "Collision avoidance ",
abstract = "Orbital debris poses a significant threat to spacecraft health and safety. Recent events such as China's anti-satellite test and the Breeze-M rocket explosion have led to an even greater awareness and concern in the satellite community. Therefore, the National Aeronautics and Space Administration (NASA) has established requirements that routine conjunction assessment screening shall be performed for all maneuverable spacecraft having perigees &lt;2000 km or within 200 km of geosynchronous altitude. NASA's Goddard Space Flight Center (GSFC) has developed an operational collision risk assessment process to protect NASA's high-value unmanned (robotic) assets that has been in use since January 2005. This paper provides an overview of the \{NASA\} robotic conjunction assessment process, including descriptions of the new tools developed to analyze close approach data and of the risk mitigation strategies employed. In addition, statistical data describing the number of conjunctions experienced are presented. A debris avoidance maneuver performed by Aura in June of 2008 is described in detail to illustrate the process. "
}
@article{Srinivasa201254,
title = "A bio-inspired kinematic controller for obstacle avoidance during reaching tasks with real robots ",
journal = "Neural Networks ",
volume = "35",
number = "",
pages = "54 - 69",
year = "2012",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2012.07.010",
url = "http://www.sciencedirect.com/science/article/pii/S0893608012001906",
author = "Narayan Srinivasa and Rajan Bhattacharyya and Rashmi Sundareswara and Craig Lee and Stephen Grossberg",
keywords = "Learning",
keywords = "Reach",
keywords = "Robotics",
keywords = "Obstacle avoidance",
keywords = "ART",
keywords = "DIRECT",
keywords = "Attentional shroud",
keywords = "Inverse model",
keywords = "Motor control ",
abstract = "This paper describes a redundant robot arm that is capable of learning to reach for targets in space in a self-organized fashion while avoiding obstacles. Self-generated movement commands that activate correlated visual, spatial and motor information are used to learn forward and inverse kinematic control models while moving in obstacle-free space using the Direction-to-Rotation Transform (DIRECT). Unlike prior \{DIRECT\} models, the learning process in this work was realized using an online Fuzzy \{ARTMAP\} learning algorithm. The DIRECT-based kinematic controller is fault tolerant and can handle a wide range of perturbations such as joint locking and the use of tools despite not having experienced them during learning. The \{DIRECT\} model was extended based on a novel reactive obstacle avoidance direction (DIRECT-ROAD) model to enable redundant robots to avoid obstacles in environments with simple obstacle configurations. However, certain configurations of obstacles in the environment prevented the robot from reaching the target with purely reactive obstacle avoidance. To address this complexity, a self-organized process of mental rehearsals of movements was modeled, inspired by human and animal experiments on reaching, to generate plans for movement execution using DIRECT-ROAD in complex environments. These mental rehearsals or plans are self-generated by using the Fuzzy \{ARTMAP\} algorithm to retrieve multiple solutions for reaching each target while accounting for all the obstacles in its environment. The key aspects of the proposed novel controller were illustrated first using simple examples. Experiments were then performed on real robot platforms to demonstrate successful obstacle avoidance during reaching tasks in real-world environments. "
}
@article{Lee201614,
title = "Automatic agent generation for IoT-based smart house simulator ",
journal = "Neurocomputing ",
volume = "209",
number = "",
pages = "14 - 24",
year = "2016",
note = "Advances in Computational Intelligence with Internet of Things ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.04.130",
url = "http://www.sciencedirect.com/science/article/pii/S092523121630580X",
author = "Wonsik Lee and Seoungjae Cho and Phuong Chu and Hoang Vu and Sumi Helal and Wei Song and Young-Sik Jeong and Kyungeun Cho",
keywords = "Virtual environment",
keywords = "Autonomous agent",
keywords = "Ubiquitous computing",
keywords = "GUI tool",
keywords = "Behavior planning ",
abstract = "Abstract In order to evaluate the quality of Internet of Things (IoT) environments in smart houses, large datasets containing interactions between people and ubiquitous environments are essential for hardware and software testing. Both testing and simulation require a substantial amount of time and volunteer resources. Consequently, the ability to simulate these ubiquitous environments has recently increased in importance. In order to create an easy-to-use simulator for designing ubiquitous environments, we propose a simulator and autonomous agent generator that simulates human activity in smart houses. The simulator provides a three-dimensional (3D) graphical user interface (GUI) that enables spatial configuration, along with virtual sensors that simulate actual sensors. In addition, the simulator provides an artificial intelligence agent that automatically interacts with virtual smart houses using a motivation-driven behavior planning method. The virtual sensors are designed to detect the states of the smart house and its living agents. The sensed datasets simulate long-term interaction results for ubiquitous computing researchers, reducing the testing costs associated with smart house architecture evaluation. "
}
@article{Malek2010972,
title = "An architecture-driven software mobility framework ",
journal = "Journal of Systems and Software ",
volume = "83",
number = "6",
pages = "972 - 989",
year = "2010",
note = "Software Architecture and Mobility ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2009.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0164121209002842",
author = "Sam Malek and George Edwards and Yuriy Brun and Hossein Tajalli and Joshua Garcia and Ivo Krka and Nenad Medvidovic and Marija Mikic-Rakic and Gaurav S. Sukhatme",
keywords = "Software architecture",
keywords = "Mobility",
keywords = "Quality of service analysis",
keywords = "Robotics ",
abstract = "Software architecture has been shown to provide an appropriate level of granularity for assessing a software system’s quality attributes (e.g., performance and dependability). Similarly, previous research has adopted an architecture-centric approach to reasoning about and managing the run-time adaptation of software systems. For mobile and pervasive software systems, which are known to be innately dynamic and unpredictable, the ability to assess a system’s quality attributes and manage its dynamic run-time behavior is especially important. In the past, researchers have argued that a software architecture-based approach can be instrumental in facilitating mobile computing. In this paper, we present an integrated architecture-driven framework for modeling, analysis, implementation, deployment, and run-time migration of software systems executing on distributed, mobile, heterogeneous computing platforms. In particular, we describe the framework’s support for dealing with the challenges posed by both logical and physical mobility. We also provide an overview of our experience with applying the framework to a family of distributed mobile robotics systems. This experience has verified our envisioned benefits of the approach, and has helped us to identify several avenues of future work. "
}
@incollection{Höller2014245,
title = "Chapter 11 - Industrial Automation ",
editor = "Höller, Jan and , and Tsiatsis, Vlasios and , and Mulligan, Catherine and , and Karnouskos, Stamatis and , and Avesand, Stefan and ,  and Boyle, David ",
booktitle = "From Machine-To-Machine to the Internet of Things ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2014",
pages = "245 - 253",
isbn = "978-0-12-407684-6",
doi = "https://doi.org/10.1016/B978-0-12-407684-6.00011-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780124076846000115",
author = "Jan Höller and Vlasios Tsiatsis and Catherine Mulligan and Stamatis Karnouskos and Stefan Avesand and David Boyle",
keywords = "Architecture",
keywords = "Cloud",
keywords = "Collaborative Automation Industrial Automation",
keywords = "Control",
keywords = "Cyber-Physical Systems",
keywords = "Factory of the Future",
keywords = "Monitoring",
keywords = "SOA",
keywords = "Web Services ",
abstract = "The industrial systems of the future are complex systems composed of vast numbers of devices interacting with each other and with enterprise systems. Modern technologies such as web services, service-oriented architectures (SOAs), the cloud, etc. make it possible for sophisticated infrastructures to emerge in future factories. We take a closer look at key visionary aspects that are expected to be introduced in the industrial automation domain in the years to come, and the pivotal role of \{M2M\} and IoT. Additionally, we investigate the impact on the collaboration of machines among themselves and with enterprise systems and their services. "
}
@article{HongSeok2014931,
title = "Development of an Inspection System for Defect Detection in Pressed Parts Using Laser Scanned Data ",
journal = "Procedia Engineering ",
volume = "69",
number = "",
pages = "931 - 936",
year = "2014",
note = "24th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2013 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2014.03.072",
url = "http://www.sciencedirect.com/science/article/pii/S187770581400318X",
author = "Park Hong-Seok and Tuladhar Upendra Mani",
keywords = "Inspection system",
keywords = "Pressed parts",
keywords = "Segmentation",
keywords = "Point cloud registration",
keywords = "Iterative closest point",
keywords = "Laser scanner ",
abstract = "Abstract In past few decades several researches have been conducted in the field of 3D parts inspection system. The accuracy level of manufactured parts has been improved remarkably within this period. The use of laser sensors in 3D part measurement process has introduced a significant improvement in data acquisition process regarding time and cost. However for quality control process, due to lack of appropriate technique to process and inspect the scanned point cloud data, high accuracy level could not have been achieved so far. Therefore the industries are still compelled to use same traditional coordinate measuring machines (CMMs) despite of being very slow. In this paper, a robust inspecting technique to detect defects in 3D pressed parts has been proposed. Point cloud data are segmented for the extraction of features. These segmented features are used for shape matching during feature based registration process to localize them with the respective \{CAD\} model and bring into same coordinate frame. A modified Iterative closest point (ICP) algorithm is proposed for the registration process. After the registration has been completed these scanned model and \{CAD\} model are compared to find defects in the manufactured parts. "
}
@article{Kahnert201441,
title = "Review: Model particles in atmospheric optics ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "146",
number = "",
pages = "41 - 58",
year = "2014",
note = "Electromagnetic and Light Scattering by Nonspherical Particles \{XIV\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314000715",
author = "Michael Kahnert and Timo Nousiainen and Hannakaisa Lindqvist",
keywords = "Scattering",
keywords = "Aerosols",
keywords = "Ice clouds",
keywords = "Mineral dust",
keywords = "Black carbon",
keywords = "Cosmic dust",
keywords = "Regolith ",
abstract = "Abstract This review paper provides an overview over model geometries for computing light scattering by small particles. The emphasis is on atmospheric optics, although much of this review will also be relevant to neighbouring fields, in particular to astronomy. Various morphological particle properties are discussed, such as overall nonsphericity, pristine shapes, aggregation, and different forms of inhomogeneity, e.g. porous and compact inhomogeneous morphologies, as well as encapsulated aggregates. Models employed to reproduce the optical properties of complex particles range from strongly simplified to highly realistic and morphologically sophisticated model geometries. Besides reviewing the most recent literature, we discuss the idea behind models of varying degree of complexity with regard to the intended use of the models. Applications range from fundamental studies of light scattering processes to routine applications of particle optics look-up tables in operational modelling systems. "
}
@article{Barfoot2010671,
title = "Field testing of robotic technologies to support ground ice prospecting in martian polygonal terrain ",
journal = "Planetary and Space Science ",
volume = "58",
number = "4",
pages = "671 - 681",
year = "2010",
note = "Exploring other worlds by exploring our own: The role of terrestrial analogue studies in planetary exploration ",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2009.09.021",
url = "http://www.sciencedirect.com/science/article/pii/S0032063309002852",
author = "Timothy D. Barfoot and Paul T. Furgale and Gordon R. Osinski and Nadeem Ghafoor and Kevin K. Williams",
keywords = "Planetary exploration",
keywords = "Ground-penetrating radar",
keywords = "Lidar",
keywords = "Stereo camera",
keywords = "Planetary rover",
keywords = "Analogue studies ",
abstract = "Polygonal terrain, a landform commonly associated with the presence of ground ice, is widespread throughout the high latitudes on Mars. In this paper, we present the results of field testing a potential mission concept for the robotic prospecting of ground ice in polygonal terrain. The focus of the paper is on the key robotic technologies that could be used to implement the concept and the engineering lessons we learned (as opposed to the specific scientific findings of our field tests). In particular, we have found that a lander- or rover-mounted lidar and a rover-borne stereo camera/ground-penetrating radar suite are two important scientific tools that may be used to help pin-point ground ice prior to subsurface sampling. We field tested some aspects of this mission concept on a previously - unstudied polygonal terrain site on Devon Island in the Canadian High Arctic (a common Mars/Moon analogue site) during the summer of 2008. This unique collaboration between technological and scientific communities has led to a deeper understanding of how such a science-driven mission could actually be implemented robotically. "
}
@article{Xue201445,
title = "China Collection 2.0: The aerosol optical depth dataset from the synergetic retrieval of aerosol properties algorithm ",
journal = "Atmospheric Environment ",
volume = "95",
number = "",
pages = "45 - 58",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.06.019",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014004658",
author = "Yong Xue and Xingwei He and Hui Xu and Jie Guang and Jianping Guo and Linlu Mei",
keywords = "Aerosol optical depth",
keywords = "Gas absorption",
keywords = "SRAP",
keywords = "Cloud mask",
keywords = "MODIS",
keywords = "China Collection 2.0 ",
abstract = "Abstract A wide range of data products have been published since the operation of the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor on NASA's \{TERRA\} and \{AQUA\} satellites. Based on DarkTarget and DeepBlue method, \{NASA\} has published Aerosol Optical Depth (AOD) products Collection 5.0 and Collection 5.1 at 10 km spatial resolution. The Collection 6.0 will be published soon with spatial resolution of 3 km. Although validated globally, regional and systematic errors are still found in the MODIS-retrieved \{AOD\} products. This is especially remarkable for bright heterogeneous land surface, such as mainland China. In order to solve the aerosol retrieval problem over heterogeneous bright land surface, the Synergetic Retrieval of Aerosol Properties algorithm (SRAP) has been developed based on the synergetic use of the \{MODIS\} data of \{TERRA\} and \{AQUA\} satellites. Using the \{SRAP\} algorithm, we produced \{AOD\} dataset-China Collection 2.0, dated from August 2002 to August 2012, and compared the \{AOD\} results with \{AErosol\} Robotic \{NETwork\} (AERONET) and Chinese Meteorological Administration Aerosol Remote Sensing Network (CARSNET) measurements. We find that 62% of China Collection 2.0 \{AOD\} values are within an expected error (EE) range of ±(0.05 + 20%) and that 56% are within an \{EE\} range of ±(0.05 + 15%) when compared with AERONET-observed values. For \{CARSNET\} validation, we find that 60% of China Collection 2.0 \{AOD\} values are within an expected error (EE) range of ±(0.05 + 20%) and that 53% are within an \{EE\} range of ±(0.05 + 15%). In addition, we also compare the \{AOD\} results with \{MODIS\} aerosol products, the cross validation shows that the two \{AOD\} have good consistency. Monthly averaged \{AOD\} results show that \{AOD\} is generally high in China's eastern coastal region from March to August, and \{AOD\} is not more than 0.5 in other months. Season averaged results show that the higher values of \{AOD\} are mostly distributed in eastern and southern China. "
}
@article{Yasar201675,
title = "Special Issue: Emerging, Ambient and Ubiquitous Systems 2015 ",
journal = "Future Generation Computer Systems ",
volume = "64",
number = "",
pages = "75 - 77",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302102",
author = "Ansar-Ul-Haque Yasar and Stephane Galland and Elhadi Shakshuki",
keywords = "Emerging systems",
keywords = "Ambient networks",
keywords = "Ubiquitous computing ",
abstract = "Abstract This special issue is based on the best papers from the 6th International Conference on Ambient Systems, Networks and Technologies (ANT), which was held at London, United Kingdom, on 2–5 June 2015. The conference attracted a large number of scientific papers that contributed to the state-of-the-art in the areas of pervasive and ambient information systems. This special issue follows on the same topics published earlier in the journals of Future Generation Computer Systems in 2013, 2014 and 2016 [1–3]. With rapid technological developments, we thought that it would be interesting once more to draw together high-quality work in this field. "
}
@article{Guo2015196,
title = "A novel local surface feature for 3D object recognition under clutter and occlusion ",
journal = "Information Sciences ",
volume = "293",
number = "",
pages = "196 - 213",
year = "2015",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514009219",
author = "Yulan Guo and Ferdous Sohel and Mohammed Bennamoun and Jianwei Wan and Min Lu",
keywords = "Local surface feature",
keywords = "3D object recognition",
keywords = "Point-cloud",
keywords = "Feature description",
keywords = "Clutter",
keywords = "Occlusion ",
abstract = "Abstract This paper presents a highly distinctive local surface feature called the TriSI feature for recognizing 3D objects in the presence of clutter and occlusion. For a feature point, we first construct a unique and repeatable Local Reference Frame (LRF) using the implicit geometrical information of neighboring triangular faces. We then generate three signatures from the three orthogonal coordinate axes of the LRF. These signatures are concatenated and then compressed into a TriSI feature. Finally, we propose an effective 3D object recognition algorithm based on hierarchical feature matching. We tested our TriSI feature on two popular datasets. Rigorous experimental results show that the TriSI feature was highly descriptive and outperformed existing algorithms under all levels of Gaussian noise, Laplacian noise, shot noise, varying mesh resolutions, occlusion, and clutter. Moreover, we tested our TriSI-based 3D object recognition algorithm on four standard datasets. The experimental results show that our algorithm achieved the best overall recognition results on these datasets. "
}
@article{Niemeyer2014152,
title = "Contextual classification of lidar data and building object detection in urban areas ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "87",
number = "",
pages = "152 - 165",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2013.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0924271613002359",
author = "Joachim Niemeyer and Franz Rottensteiner and Uwe Soergel",
keywords = "LIDAR",
keywords = "Point cloud",
keywords = "Classification",
keywords = "Urban",
keywords = "Contextual",
keywords = "Building",
keywords = "Detection ",
abstract = "Abstract In this work we address the task of the contextual classification of an airborne LiDAR point cloud. For that purpose, we integrate a Random Forest classifier into a Conditional Random Field (CRF) framework. It is a flexible approach for obtaining a reliable classification result even in complex urban scenes. In this way, we benefit from the consideration of context on the one hand and from the opportunity to use a large amount of features on the other hand. Considering the interactions in our experiments increases the overall accuracy by 2%, though a larger improvement becomes apparent in the completeness and correctness of some of the seven classes discerned in our experiments. We compare the Random Forest approach to linear models for the computation of unary and pairwise potentials of the CRF, and investigate the relevance of different features for the LiDAR points as well as for the interaction of neighbouring points. In a second step, building objects are detected based on the classified point cloud. For that purpose, the \{CRF\} probabilities for the classes are plugged into a Markov Random Field as unary potentials, in which the pairwise potentials are based on a Potts model. The 2D binary building object masks are extracted and evaluated by the benchmark \{ISPRS\} Test Project on Urban Classification and 3D Building Reconstruction. The evaluation shows that the main buildings (larger than 50 m2) can be detected very reliably with a correctness larger than 96% and a completeness of 100%. "
}
@article{Zhang2013126,
title = "Multiple Vehicle-like Target Tracking Based on the Velodyne LiDAR* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "126 - 131",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00058",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349211",
author = "Liang Zhang and Qingquan Li and Ming Li and Qingzhou Mao and Andreas Nüchter",
keywords = "Multi-Target Tracking",
keywords = "Velodyne Lidar",
keywords = "Multiple Hypothesis Tracking",
keywords = "Dynamic Point Cloud Registration ",
abstract = "Abstract This paper proposes a novel multiple vehicle-like target tracking method based on a Velodyne \{HDL64E\} light detection and ranging (LiDAR) system. The proposed method combines multiple hypothesis tracking (MHT) algorithm with dynamic point cloud registration (DPCR), which is able to solve the multiple vehicle-like target tracking in highly dynamic urban environments without any auxiliary information from \{GPS\} or IMU. Specifically, to track targets consistently, the \{DPCR\} is developed to calculate accurately the pose of the ego-vehicle for the transformation of raw measurements taken in the moving coordinate systems into a static absolute coordinate system; while in turn, \{MHT\} helps to improve the performance of \{DPCR\} by discriminating and removing the dynamic points from the scene. Furthermore, the proposed \{MHT\} method is also able to solve the occlusion problem existing in the point cloud. Experiments on sets of urban environments prove that the presented method is effective and robust, even in highly dynamic environments. "
}
@article{HernándezLópez2012196,
title = "Detecting objects using color and depth segmentation with Kinect sensor ",
journal = "Procedia Technology ",
volume = "3",
number = "",
pages = "196 - 204",
year = "2012",
note = "The 2012 Iberoamerican Conference on Electronics Engineering and Computer Science ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2012.03.021",
url = "http://www.sciencedirect.com/science/article/pii/S2212017312002502",
author = "José-Juan Hernández-López and Ana-Linnet Quintanilla-Olvera and José-Luis López-Ramírez and Francisco-Javier Rangel-Butanda and Mario-Alberto Ibarra-Manzano and Dora-Luz Almanza-Ojeda",
keywords = "Kinect",
keywords = "Object detection",
keywords = "Mobile robotics",
keywords = "Color segmentation",
keywords = "Depth segmentation ",
abstract = "In order to optimize the movements of a robot, every object found in the work environment must not just be identiﬁed, but located in reference to the robot itself. Usually, object segmentation from an image is achieved using color segmentation. This segmentation can be achieved by processing the R, G and B chromatic components. However, this method has the disadvantage of been very sensitive to the changes on lighting. Converting the \{RGB\} image to the CIE-Lab color space avoids the lack of sensitivity by increasing the accuracy of the color segmentation. Unfortunately, if multiple objects of the same color are presented in the scene, is not possible to identify one of these objects using only this color space. Therefore, we need to consider an additional data source, in this case the depth, in order to discriminate objects that are not in the same plane as the object of interest. In this paper, we introduce an algorithm to detect objects, essentially on indoor environments, using CIE-Lab and depth segmentation techniques. We process the color and depth images provided by the Kinect sensor for proposing a visual strategy with real-time performance "
}
@article{Kappler2012411,
title = "Templates for pre-grasp sliding interactions ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "411 - 423",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001473",
author = "Daniel Kappler and Lillian Y. Chang and Nancy S. Pollard and Tamim Asfour and Rüdiger Dillmann",
keywords = "Pre-grasp interaction",
keywords = "Object manipulation",
keywords = "Humanoid robotics",
keywords = "Pushing",
keywords = "Sliding ",
abstract = "In manipulation tasks that require object acquisition, pre-grasp interaction such as sliding adjusts the object in the environment before grasping. This change in object placement can improve grasping success by making desired grasps reachable. However, the additional sliding action prior to grasping introduces more complexity to the motion planning process, since the hand pose relative to the object does not need to remain fixed during the pre-grasp interaction. Furthermore, anthropomorphic hands in humanoid robots have several degrees of freedom that could be utilized to improve the object interaction beyond a fixed grasp shape. We present a framework for synthesizing pre-grasp interactions for high-dimensional anthropomorphic manipulators. The motion planning is tractable because information from pre-grasp manipulation examples reduces the search space to promising hand poses and shapes. In particular, we show the value of organizing the example data according to object category templates. The template information focuses the search based on the object features, resulting in increased success of adapting a template pose and decreased planning time. "
}
@article{Hanly200419,
title = "Robotic abdominal surgery ",
journal = "The American Journal of Surgery ",
volume = "188",
number = "4, Supplement 1",
pages = "19 - 26",
year = "2004",
note = "",
issn = "0002-9610",
doi = "https://doi.org/10.1016/j.amjsurg.2004.08.020",
url = "http://www.sciencedirect.com/science/article/pii/S000296100400371X",
author = "Eric J. Hanly and Mark A. Talamini",
abstract = "As a whole, abdominal surgeons possess excellent videoendoscopic surgical skills. However, the limitations of laparoscopy—such as reduced range of motion and instrument dexterity and 2-dimensional view of the operative field—have inspired even the most accomplished laparoscopists to investigate the potential of surgical robotics to broaden their application of the minimally invasive surgery paradigm. This review discusses data obtained from articles indexed in the \{MEDLINE\} database written in English and mapped to the following key words: “surgical robotics,” “robotic surgery,” “robotics,” “computer-assisted surgery,” “da Vinci,” “Zeus,” “fundoplication,” “morbid obesity,” “hepatectomy,” “pancreatectomy,” “small intestine,” “splenectomy,” “colectomy,” “adrenalectomy,” and “pediatric surgery.” A limited subset of 387 publications was reviewed to determine article relevance to abdominal robotic surgery. Particular emphasis was placed on reports that limited their discussion to human applications and surgical outcomes. Included are comments about the initial 202 robotic abdominal surgery cases performed at Johns Hopkins University Hospital (Baltimore, MD) from August 2000 to January 2004. Surgical robotic systems are being used to apply laparoscopy to the surgical treatment of diseases in virtually every abdominal organ. Procedures demanding superior visualization or requiring complex reconstruction necessitating extensive suturing obtain the greatest benefit from robotics over conventional laparoscopy. Whereas advanced surgical robotic systems offer the promise of a unique combination of advantages over open and conventional laparoscopic approaches, clinical data demonstrating improved outcomes are lacking for robotic surgical applications within the abdomen. Outcomes data for surgical robotics are essential given the exorbitant costs associated with the use of these tools. "
}
@article{Rusu2008844,
title = "Robots in the kitchen: Exploiting ubiquitous sensing and actuation ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "10",
pages = "844 - 856",
year = "2008",
note = "Network Robot Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.06.010",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008000912",
author = "Radu Bogdan Rusu and Brian Gerkey and Michael Beetz",
keywords = "Ubiquitous robotics",
keywords = "Sensor network",
keywords = "Software infrastructure",
keywords = "Reusable code ",
abstract = "Our goal is to develop intelligent service robots that operate in standard human environments, automating common tasks. In pursuit of this goal, we follow the ubiquitous robotics paradigm, in which intelligent perception and control, are combined with ubiquitous computing. By exploiting sensors and effectors in its environment, a robot can perform more complex tasks without becoming overly complex itself. Following this insight, we have developed a service robot that operates autonomously in a sensor-equipped kitchen. The robot learns from demonstration, and performs sophisticated tasks, in concert with the network of devices in its environment. We report on the design, implementation, and usage of this system, which is freely available for use, and improvement by others, in the research community. "
}
@article{Caponetti2011223,
title = "Stochastic automata for outdoor semantic mapping using optimised signal quantisation ",
journal = "Control Engineering Practice ",
volume = "19",
number = "3",
pages = "223 - 233",
year = "2011",
note = "Special Section: \{IFAC\} World Congress Application Paper Prize Papers ",
issn = "0967-0661",
doi = "https://doi.org/10.1016/j.conengprac.2010.11.010",
url = "http://www.sciencedirect.com/science/article/pii/S0967066110002571",
author = "Fabio Caponetti and Morten Rufus Blas and Mogens Blanke",
keywords = "Stochastic automata",
keywords = "Robotics",
keywords = "Classification",
keywords = "Probabilistic models",
keywords = "Quantisation ",
abstract = "Autonomous robots require many types of information to obtain intelligent and safe behaviours. For outdoor operations, semantic mapping is essential and this paper proposes a stochastic automaton to localise the robot within the semantic map. For correct modelling and classification under uncertainty, this paper suggests quantising robotic perceptual features, according to a probabilistic description, and then optimising the quantisation. The proposed method is compared with other state-of-the-art techniques that can assess the confidence of their classification. Data recorded on an autonomous agricultural robot are used for verification and the new method is shown to compare very favourably with existing ones. "
}
@article{FU20141680,
title = "Line Matching Across Views Based on Multiple View Stereo ",
journal = "Acta Automatica Sinica ",
volume = "40",
number = "8",
pages = "1680 - 1689",
year = "2014",
note = "",
issn = "1874-1029",
doi = "https://doi.org/10.1016/S1874-1029(14)60017-3",
url = "http://www.sciencedirect.com/science/article/pii/S1874102914600173",
author = "Kang-Ping FU and Shu-Han SHEN and Zhan-Yi HU",
keywords = "Multi-view line matching",
keywords = "multiple view stereo (MVS)",
keywords = "feature matching",
keywords = "3D point clouds ",
abstract = "Abstract A graph-based multiple view line matching method is proposed based on results of multiple view stereo (MVS) algorithms. With the 3D points and their visibility information provided by MVS, point-line correspondences are firstly established through 3D-to-2D re-projection. Each image line detected in different views is described using a 3D point set as well as a unit vector representing its coarse 3D direction. From such a description, pairwise similarity and consistency are evaluated. Then, a graph is constructed to contain all image lines as nodes. To get a unified node distance measure, a spectral graph analysis method is employed. Finally, a modified \{DBSCAN\} algorithm is introduced to obtain reliable line matches from the graph. Experiments show that our method is more robust and exhibits better accuracy than the existing methods. "
}
@article{Zhou2013107,
title = "Vision-Based Window Estimation for \{MAV\} in Unknown Urban Environments* ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "30",
pages = "107 - 111",
year = "2013",
note = "2nd \{IFAC\} Workshop on Research, Education and Development of Unmanned Aerial Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20131120-3-FR-4045.00026",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015402794",
author = "Shuting Zhou and Gerardo Flores and Rogelio Lozano and Pedro Castillo",
keywords = "Computer vision",
keywords = "Window estimation",
keywords = "Stereo vision",
keywords = "Kinect",
keywords = "Point cloud ",
abstract = "Abstract This paper addresses the issue of window estimation of a micro Air Vehicle (MAV) in unknown urban environments. The \{MAV\} is required to navigate from an initial and outdoor position to a final position inside a building. This paper develops two vision-based methods using the information provided by the onboard vision system. To effectively identify the target and estimate the distance between the camera carrier and target, firstly a stereo camera system is applied. Besides, we propose another approach using point cloud captured by a RGB-D camera. "
}
@incollection{Li2014279,
title = "9 - Evolving academic libraries in the future ",
editor = "Li, LiLi ",
booktitle = "Scholarly Information Discovery in the Networked Academic Learning Environment ",
publisher = "Chandos Publishing",
edition = "",
address = "Oxford",
year = "2014",
pages = "279 - 309",
series = "Chandos Information Professional Series",
isbn = "978-1-84334-763-7",
doi = "https://doi.org/10.1533/9781780634449.4.279",
url = "http://www.sciencedirect.com/science/article/pii/B9781843347637500093",
author = "LiLi Li",
keywords = "Apple iWatch",
keywords = "artificial intelligence",
keywords = "Barnes &amp; Noble",
keywords = "cloud storage",
keywords = "Google Chrome",
keywords = "Google Chromebook",
keywords = "Google Fiber",
keywords = "Google Glass",
keywords = "Google Inside Search",
keywords = "Google Knowledge Graph",
keywords = "IBM Watson",
keywords = "machine translation",
keywords = "wearable computer",
keywords = "XiaoTu ",
abstract = "Abstract: In today’s information society, cutting edge and emerging technologies are greatly impacting information resources and services in academic libraries worldwide. The beginning of the rise of the wearable computer suggests that today’s information society is moving toward the post-PC era. Although the future fate of academic libraries is still debatable, the tragedy predicted by Brian T. Sullivan11. Brian T. Sullivan is an instructional librarian at Alfred University, New York. to happen by 2050 is extremely unlikely. Instead, combined with innovative information technologies, future academic libraries will become more vigorous in our networked academic learning environment. As \{IT\} architecture evolves, so high-speed digital applications and highly intellectual robots will shape new creative and innovative information resources and services in the academic library of the future. "
}
@incollection{Wasklewicz2013130,
title = "3.6 Digital Terrain Modeling ",
editor = "Shroder, John F. ",
booktitle = "Treatise on Geomorphology ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2013",
pages = "130 - 161",
isbn = "978-0-08-088522-3",
doi = "https://doi.org/10.1016/B978-0-12-374739-6.00048-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780123747396000488",
author = "T. Wasklewicz and D.M. Staley and K. Reavis and T. Oguchi",
keywords = "Airborne laser scanning",
keywords = "Cloud segmentation",
keywords = "Decimation",
keywords = "Digital elevation model",
keywords = "Digital terrain model",
keywords = "Filtering",
keywords = "Interferometric synthetic-aperture radar",
keywords = "Light detection and ranging",
keywords = "Point clouds",
keywords = "Terrestrial laser scanning",
keywords = "Terrestrial photogrammetry ",
abstract = "Geomorphologists require quantitative information about the land surface. New sensors can now measure elevation changes at a variety of scales and these data are used to generate digital terrain model (DTM) that accurately characterize topography. A variety of \{DTM\} analytics are used to support a multitude of geomorphological studies. However, there are numerous issues involving representation, sampling, interpolation, and error assessment and correction, which must be addressed before using the elevation data. Data reduction, filtering, and accuracy are key aspects to consider. Knowledge of these issues is critical for terrain analysis and the communication of information derived from a DTM. "
}
@article{Damen201698,
title = "You-Do, I-Learn: Egocentric unsupervised discovery of objects and their modes of interaction towards video-based guidance ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "98 - 112",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - "Assistive Solutions for Mobility, Communication and HMI" ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.02.016",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216000709",
author = "Dima Damen and Teesid Leelasawassuk and Walterio Mayol-Cuevas",
keywords = "Video guidance",
keywords = "Real-time computer vision",
keywords = "Assistive computing",
keywords = "Object discovery",
keywords = "Object usage ",
abstract = "Abstract This paper presents an unsupervised approach towards automatically extracting video-based guidance on object usage, from egocentric video and wearable gaze tracking, collected from multiple users while performing tasks. The approach (i) discovers task relevant objects, (ii) builds a model for each, (iii) distinguishes different ways in which each discovered object has been used and (iv) discovers the dependencies between object interactions. The work investigates using appearance, position, motion and attention, and presents results using each and a combination of relevant features. Moreover, an online scalable approach is presented and is compared to offline results. The paper proposes a method for selecting a suitable video guide to be displayed to a novice user indicating how to use an object, purely triggered by the user’s gaze. The potential assistive mode can also recommend an object to be used next based on the learnt sequence of object interactions. The approach was tested on a variety of daily tasks such as initialising a printer, preparing a coffee and setting up a gym machine. "
}
@article{Aulinas201016,
title = "Submapping \{SLAM\} based on acoustic data from a 6-DOF \{AUV\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "20",
pages = "16 - 21",
year = "2010",
note = "8th \{IFAC\} Conference on Control Applications in Marine Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100915-3-DE-3008.00036",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016334309",
author = "Josep Aulinas and Chee Sing Lee and Joaquim Salvi and Yvan R. Petillot",
keywords = "Autnonomous vehicles",
keywords = "robotics",
keywords = "navigation ",
abstract = "Abstract Autonomous Underwater Vehicles (AUVs) need positioning systems besides the Global Positioning System (GPS), since \{GPS\} does not work in underwater scenarios. Possible solutions are the Simultaneous Localization and Mapping (SLAM) algorithms. \{SLAM\} algorithms aim to build a map while simultaneously localizing the vehicle within this map. However, they offer limited performance when faced with large scale scenarios. For instance, they do not create consistent maps for large areas, mainly because uncertainties increase with the scale of the scenario. In addition, the computational cost increases with the map size. The use of local maps reduces computational cost and improves map consistency. Following this idea, in this paper we propose a new \{SLAM\} approach that uses independent local maps together with a global level stochastic map. The global level contains the relative transformations between local maps. These local maps are updated once a new loop is detected. Local maps that are sharing a high number of features are updated through fusion, maintaining the correlation between landmarks and vehicle. Experimental results on real data obtained from the REMUS-100 \{AUV\} show that our approach is able to obtain large map areas consistently. "
}
@article{Goicoechea2008182,
title = "First robotic monitoring of a lensed quasar: Intrinsic variability of \{SBS\} 0909+532 ",
journal = "New Astronomy ",
volume = "13",
number = "3",
pages = "182 - 193",
year = "2008",
note = "",
issn = "1384-1076",
doi = "https://doi.org/10.1016/j.newast.2007.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S1384107607000875",
author = "L.J. Goicoechea and V.N. Shalyapin and E. Koptelova and R. Gil-Merino and A.P. Zheleznyak and A. Ullán",
keywords = "Gravitational lensing",
keywords = "Galaxies: quasars: general",
keywords = "Galaxies: quasars: individual (SBS 0909+532) ",
abstract = "To go into the details about the variability of the double quasar \{SBS\} 0909+532, we designed a monitoring programme with the 2 m Liverpool Robotic Telescope in the r Sloan filter, spanning 1.5 years from 2005 January to 2006 June. The r-band light curves of the A and B components, several cross-correlation techniques and a large number of simulations (synthetic light curves) lead to a robust delay ΔtBA = −49 ± 6 days (1σ interval) that agrees with our previous results (the B component is leading). Once the time delay and the magnitude offset are known, the magnitude- and time-shifted light curve of image A is subtracted from the light curve of image B. This difference light curve of \{SBS\} 0909+532 is consistent with zero, so any possible extrinsic signal must be very weak, i.e., the observed variability in A and B is basically due to observational noise and intrinsic signal. We then make the combined light curve and analyse its statistical properties (structure functions). The structure function of the intrinsic luminosity is fitted to predictions of simple models of two physical scenarios: accretion disc instabilities and nuclear starbursts. Although, no simple model is able to accurately reproduce the observed trend, symmetric triangular flares in an accretion disc seems to be the best option to account for it. "
}
@article{Li2011324,
title = "Calibration of a multiple axes 3-D laser scanning system consisting of robot, portable laser scanner and turntable ",
journal = "Optik - International Journal for Light and Electron Optics ",
volume = "122",
number = "4",
pages = "324 - 329",
year = "2011",
note = "",
issn = "0030-4026",
doi = "https://doi.org/10.1016/j.ijleo.2010.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0030402610001154",
author = "Jianfeng Li and Ming Chen and Xuebi Jin and Yu Chen and Zhiyong Dai and Zhonghua Ou and Qin Tang",
keywords = "Robotics",
keywords = "Robot vision",
keywords = "Robot \{TCP\} calibration",
keywords = "3-D laser scanner ",
abstract = "A multiple axes 3-D laser scanning system consisting of a portable 3-D laser scanner, a industrial robot and a turntable is demonstrated. By using a criterion sphere, a robot tool center point (TCP) calibration approach is proposed to calibrate the relation between the laser 3-D scanner and the robot end-effector. In this approach, two different translational motions of robot are first made to determine the rotation part, and then at least three different rotational motions are made to determine the translation part. Meanwhile, by using the criterion sphere, a turntable approach is proposed to calibrate the pose of the turntable relative to the robot. In this approach, several rotational angles of turntable and two different heights of the sphere are made to determine the rotational axis of turntable. Experiment is performed on a portable laser scanner mounted on an industrial robot \{ABB\} \{IRB4400\} with a turntable. The experiment results show that the two proposed calibration algorithms are stable and flexible. The application of 3-D measurement is also given to demonstrate the effectiveness and stability of the multiple axes 3-D laser scanning system. "
}
@article{GolparvarFard20111143,
title = "Evaluation of image-based modeling and laser scanning accuracy for emerging automated performance monitoring techniques ",
journal = "Automation in Construction ",
volume = "20",
number = "8",
pages = "1143 - 1155",
year = "2011",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.04.016",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000707",
author = "Mani Golparvar-Fard and Jeffrey Bohn and Jochen Teizer and Silvio Savarese and Feniosky Peña-Mora",
keywords = "Progress monitoring",
keywords = "Image-based modeling",
keywords = "Structure from motion",
keywords = "Laser scanning",
keywords = "Computer aided design",
keywords = "Construction field imagery",
keywords = "Range point clouds",
keywords = "As-built modeling ",
abstract = "Accurate and rapid assessment of the as-built status on any construction site provides the opportunity to understand the current performance of a project easily and quickly. Rapid project assessment further identifies discrepancies between the as-built and as-planned progress, and facilitates decision making on the necessary remedial actions. Currently, manual visual observations and surveying are the most dominant data capturing techniques but they are time-consuming, error-prone, and infrequent, making quick and reliable decision-making difficult. Therefore, research on new approaches that allow automatic recognition of as-built performance and visualization of construction progress is essential. This paper presents and compares two methods for obtaining point cloud models for detection and visualization of as-built status for construction projects: (1) A new method of automated image-based reconstruction and modeling of the as-built project status using unordered daily construction photo collections through analysis of Structure from Motion (SfM); (2) 3D laser scanning and analysis of the as-built dense point cloud models. These approaches provide robust means for recognition of progress, productivity, and quality on a construction site. In this paper, an overview of the newly developed automated image-based reconstruction approach and exclusive features which distinct it from other image-based or conventional photogrammetric techniques is presented. Subsequently the terrestrial laser scanning approach carried out for reconstruction and comparison of as-built scenes is presented. Finally the accuracy and usability of both of these techniques for metric reconstruction, automated production of point cloud models, 3D \{CAD\} shape modeling, and as-built visualizations is evaluated and compared on eight different case studies. It is shown that for precise defect detection or alignment tasks, image-based point cloud models may not be as accurate and dense as laser scanners' point cloud models. Nonetheless image-based point cloud models provide an opportunity to extract as-built semantic information (i.e., progress, productivity, quality and safety) through the content of the images, are easy to use, and do not need add burden on the project management teams by requiring expertise for data collection or analysis. Finally image-based reconstruction automatically provides photo alignment with point cloud models and enables image-based renderings which can remarkably impact automated performance monitoring and as-built visualizations. "
}
@article{Yew201643,
title = "Towards a griddable distributed manufacturing system with augmented reality interfaces ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "39",
number = "",
pages = "43 - 55",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515301605",
author = "A.W.W. Yew and S.K. Ong and A.Y.C. Nee",
keywords = "Augmented reality",
keywords = "Manufacturing grid",
keywords = "Manufacturing system",
keywords = "Smart objects",
keywords = "Ubiquitous computing ",
abstract = "Abstract Rapidly changing demand and mass customization require highly flexible and adaptive manufacturing systems. Manufacturing operations have evolved in order to keep up by organizing themselves into smaller units of specialized production processes that are combined in different ways to create different products. Human workers are integral in the manufacturing systems and they too must be flexible and adaptive. This paper describes an augmented reality manufacturing system that aims to greatly improve the information perception of the different types of workers in a manufacturing facility and to make interaction with manufacturing software natural and efficient. In this approach, traditionally paper-based and computer-based tasks are augmented to the workers’ interactions in the environment. The system is distributed and modular as the different functions of CAD/CAM software are provided by individual physical or virtual objects in the environment or by a combination of them working cooperatively. This modularity allows the individual resources and facilities to be linked via internet onto a manufacturing grid with universally-accessible augmented reality interfaces to their services. "
}
@article{Horváth2015161,
title = "Ubiquitous computer aided design: A broken promise or a Sleeping Beauty? ",
journal = "Computer-Aided Design ",
volume = "59",
number = "",
pages = "161 - 175",
year = "2015",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2014.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0010448514002358",
author = "Imre Horváth and Regine W. Vroom",
keywords = "Ubiquitous computing",
keywords = "Computer aided design",
keywords = "Ubiquitous design enablers",
keywords = "Competing technology exploitation",
keywords = "Ubiquitous \{CAD\} applications ",
abstract = "Abstract As a novel computational approach, ubiquitous computing was emerging at the beginning of the 1980s and has reached a rather mature level by now. It assumes that computing can be available anywhere, anytime and in any context due to technological developments, social demands and calm implementations. Over the years, the opportunities of this computing paradigm have been explored and the benefits have been exploited successfully in many application fields. This survey paper addresses ubiquitous computing from the perspective of enabling computer aided design. The specific objectives of the reported survey are to: (i) give an overall account of the current status of ubiquitous computing and technologies, (ii) cast light on how ubiquitous computing has influenced the development of \{CAD\} systems, tools, and methods, and (iii) critically investigate future development opportunities of ubiquitous computing enabled computer aided design. First, the paper discusses the principles and typical technologies of ubiquitous computing. Then, the development and spectrum of the so-called standard computer aided design tasks are analyzed from a computational point of view. Afterwards, the already implemented design enabling functionalities are discussed and some additional functional possibilities are considered. The literature provides evidence that ubiquitous computing has not managed to revolutionize the methodologies or the systems of computer aided design so far, though many researchers intensively studied the affordances and the application possibilities of ubiquitous technologies. One reason is that ubiquitous computing technologies had in the last two decades to compete with other kinds of computational technologies, such as high-capacity computing, high-speed networking, immersive virtual reality, knowledge ontologies, smart software agents, mobile communication, etc., which had a much stronger influence on the development of computer aided design methods and systems. In combination with the rather conservative and conventionalist industrial practice of \{CAD\} system development and application, this may explain why the ubiquitous computing revolution remained weak in computer aided design. The literature clearly indicates that application of ubiquitous technologies did not lead to radically new functionalities that could have been exploited by the concerned industries. Consequently, it seems to be possible that computer aided design simply steps over the paradigm of ubiquitous computing and expects new functionalities from the emerging new computing paradigms, such as brain–computer interfacing, cyber–physical computing, biological computing, or quantum computing. "
}
@article{Damiani201617,
title = "A type-sound calculus of computational fields ",
journal = "Science of Computer Programming ",
volume = "117",
number = "",
pages = "17 - 44",
year = "2016",
note = "",
issn = "0167-6423",
doi = "https://doi.org/10.1016/j.scico.2015.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167642315003573",
author = "Ferruccio Damiani and Mirko Viroli and Jacob Beal",
keywords = "Computational field",
keywords = "Core calculus",
keywords = "Operational semantics",
keywords = "Spatial computing",
keywords = "Type soundness ",
abstract = "Abstract A number of recent works have investigated the notion of “computational fields” as a means of coordinating systems in distributed, dense and dynamic environments such as pervasive computing, sensor networks, and robot swarms. We introduce a minimal core calculus meant to capture the key ingredients of languages that make use of computational fields: functional composition of fields, functions over fields, evolution of fields over time, construction of fields of values from neighbours, and restriction of a field computation to a sub-region of the network. We formalise a notion of type soundness for the calculus that encompasses the concept of domain alignment, and present a sound static type inference system. This calculus and its type inference system can act as a core for actual implementation of coordination languages and models, as well as to pave the way towards formal analysis of properties concerning expressiveness, self-stabilisation, topology independence, and relationships with the continuous space–time semantics of spatial computations. "
}
@article{Urraca2016539,
title = "Smart baseline models for solar irradiation forecasting ",
journal = "Energy Conversion and Management ",
volume = "108",
number = "",
pages = "539 - 548",
year = "2016",
note = "",
issn = "0196-8904",
doi = "https://doi.org/10.1016/j.enconman.2015.11.033",
url = "http://www.sciencedirect.com/science/article/pii/S0196890415010535",
author = "R. Urraca and J. Antonanzas and M. Alia-Martinez and F.J. Martinez-de-Pison and F. Antonanzas-Torres",
keywords = "Solar forecasting",
keywords = "Intra-daily solar irradiance",
keywords = "Random forests",
keywords = "Soft computing",
keywords = "Persistence models ",
abstract = "Abstract This work presents a kind of smart baseline models for solar irradiation forecasting, as models are only fed with meteorological records and solar-computed values, easy-to-obtain inputs that facilitate their implementation worldwide. Global horizontal irradiation (GHI) is predicted for horizons of 1 h in a site of Southeast Spain. Two types of approaches are undertaken: fixed models, trained just once with a global database, and moving models, where the training database is updated based on the features of the testing sample. The approaches are implemented with two machine learning algorithms, support vector regression (SVR) and random forest (RFs), along with the classic linear regression and kNN. Besides, genetic algorithms (GAs) are used to automate the training process of fixed models, a task traditionally performed based on the experience or the researcher. Significant improvements were obtained over the basic persistence methods with both approaches. In the case of moving models, results proved that the best approach to update the calibration set was by computing the Euclidean distance in the principal components space. Results of both approaches were comparable in terms of \{MAE\} and forecast skill (s), though slightly superior predictions were obtained with the moving SVR, with a forecast skill ranging from 8% to 23% and a testing \{MAE\} ranging from 49 to 64 W / m 2 for the different states of cloudiness. Anyway, both approaches are valid baselines to compare new forecasting models fed with more difficult-to-obtain features, supplementing the classic but naive persistence models. "
}
@article{Precup201575,
title = "An overview on fault diagnosis and nature-inspired optimal control of industrial process applications ",
journal = "Computers in Industry ",
volume = "74",
number = "",
pages = "75 - 94",
year = "2015",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2015.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0166361515000469",
author = "Radu-Emil Precup and Plamen Angelov and Bruno Sielly Jales Costa and Moamar Sayed-Mouchaweh",
keywords = "Data-driven control",
keywords = "Data mining",
keywords = "Evolving soft computing techniques",
keywords = "Fault diagnosis",
keywords = "Nature-inspired optimization algorithms",
keywords = "Wind turbines ",
abstract = "Abstract Fault detection, isolation and optimal control have long been applied to industry. These techniques have proven various successful theoretical results and industrial applications. Fault diagnosis is considered as the merge of fault detection (that indicates if there is a fault) and fault isolation (that determines where the fault is), and it has important effects on the operation of complex dynamical systems specific to modern industry applications such as industrial electronics, business management systems, energy, and public sectors. Since the resources are always limited in real-world industrial applications, the solutions to optimally use them under various constraints are of high actuality. In this context, the optimal tuning of linear and nonlinear controllers is a systematic way to meet the performance specifications expressed as optimization problems that target the minimization of integral- or sum-type objective functions, where the tuning parameters of the controllers are the vector variables of the objective functions. The nature-inspired optimization algorithms give efficient solutions to such optimization problems. This paper presents an overview on recent developments in machine learning, data mining and evolving soft computing techniques for fault diagnosis and on nature-inspired optimal control. The generic theory is discussed along with illustrative industrial process applications that include a real liquid level control application, wind turbines and a nonlinear servo system. New research challenges with strong industrial impact are highlighted. "
}
@article{Davidson2013203,
title = "Least-squares Fit of Measured Points for Square Line-profiles ",
journal = "Procedia \{CIRP\} ",
volume = "10",
number = "",
pages = "203 - 210",
year = "2013",
note = "The Twelfth \{CIRP\} Conference on Computer Aided Tolerancing ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.08.032",
url = "http://www.sciencedirect.com/science/article/pii/S2212827113005817",
author = "J. Davidson and S. Savaliya and Jami J. Shah",
keywords = "Least-squares",
keywords = "regression",
keywords = "pseudoinverse",
keywords = "fit",
keywords = "profile",
keywords = "point-cloud",
keywords = "CMM data reduction ",
abstract = "Abstract The pseudoinverse of a rectangular matrix is used to compute the least-squares fit of a set of points that have been measured along a line-profile. Tolerances on line profiles are used to control cross-sectional shapes of parts, such as turbine blades. The specified profile is treated as a moving platform of a hypothetical, redundant, and planar in-parallel-actuated robot, and all the measured points are presumed to be fixed in it. The locations of the linear actuators are represented with screw (torsor) coordinates, and these are arranged in a matrix equation that relates the three small displacements of the platform to the corresponding deviations (treated as small displacements) of the measured points. The Moore-Penrose (pseudoinverse) solution uniquely produces displacements of the platform which correspond to the least-squares minimum for the deviations at all of the measured points. "
}
@incollection{Perez201321,
title = "Chapter 2 - Semi-Empirical Satellite Models ",
editor = "Kleissl, Jan ",
booktitle = "Solar Energy Forecasting and Resource Assessment ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2013",
pages = "21 - 48",
isbn = "978-0-12-397177-7",
doi = "https://doi.org/10.1016/B978-0-12-397177-7.00002-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780123971777000024",
author = "Richard Perez and Tomáš Cebecauer and Marcel Šúri",
keywords = "satellite solar resource",
keywords = "SolarAnywhere",
keywords = "GOES",
keywords = "Meteosat",
keywords = "GeoModel",
keywords = "topographic shading",
keywords = "cloud index ",
abstract = "Abstract This chapter discusses the basic principles of solar-irradiance modeling based on the use of input data from geostationary satellites and atmospheric models. Two operational approaches (SUNY/SolarAnywhere and SolarGIS), which are based on the use of semi-empirical models, are presented in the context of recent developments. "
}
@incollection{Rahman201647,
title = "Chapter Two - Privacy Challenges and Goals in mHealth Systems ",
editor = "Ali R. Hurson and Maziar Goudarzi",
booktitle = "",
publisher = "Elsevier",
year = "2016",
volume = "102",
pages = "47 - 62",
series = "Advances in Computers ",
issn = "0065-2458",
doi = "https://doi.org/10.1016/bs.adcom.2016.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0065245816300328",
author = "F. Rahman and I.D. Addo and S.I. Ahamed and J.-J. Yang and Q. Wang",
keywords = "Privacy in mHealth",
keywords = "Privacy ubiquitous computing",
keywords = "RFID privacy ",
abstract = "Abstract The global phenomena of mobile technology have encouraged collaborations between national governments and diverse international stakeholders in applying mobile-based health (mHealth) solutions as a powerful opportunity for improving health and development in rural and remote areas. A significant impact offered by modern mHealth technologies includes the potential to transform various aspects of healthcare, improving accessibility, quality, and affordability. Over the years, mHealth has become important in the field of healthcare information technology as patients begin to use mobile-based medical sensors to record their daily activities and vital signs. The rapid expansion of mobile information and communications technologies within health service delivery and public health systems has created a range of new opportunities to deliver new forms of interactive health services to patients, clinicians, and caregivers alike. The scope and scale of mHealth interventions range from simple direct-to-individual consumer and interactive patient-provider communications to more complex computer-based systems facilitating coordinated patient care and management. "
}
@incollection{Gudivada2016169,
title = "Chapter 5 - Cognitive Analytics: Going Beyond Big Data Analytics and Machine Learning ",
editor = "Venkat N. Gudivada, Vijay V. Raghavan, Venu Govindaraju and C.R. Rao",
booktitle = "Cognitive Computing: Theory and Applications",
publisher = "Elsevier",
year = "2016",
volume = "35",
pages = "169 - 205",
series = "Handbook of Statistics ",
issn = "0169-7161",
doi = "https://doi.org/10.1016/bs.host.2016.07.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169716116300517",
author = "V.N. Gudivada and M.T. Irfan and E. Fathi and D.L. Rao",
keywords = "Cognitive analytics",
keywords = "Text analytics",
keywords = "Learning analytics",
keywords = "Educational data mining",
keywords = "Cognitive systems",
keywords = "Cognitive computing",
keywords = "Personalized learning",
keywords = "Data science",
keywords = "Machine learning",
keywords = "Big data analytics",
keywords = "Business analytics ",
abstract = "Abstract This chapter defines analytics and traces its evolution from its origin in 1988 to its current stage—cognitive analytics. We discuss types of learning and describe classes of machine learning algorithms. Given this backdrop, we propose a reference architecture for cognitive analytics and indicate ways to implement the architecture. A few cognitive analytics applications are briefly described. The chapter concludes by indicating current trends and future research direction. "
}
@article{Petit2017187,
title = "Tracking elastic deformable objects with an RGB-D sensor for a pizza chef robot ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "187 - 201",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305395",
author = "Antoine Petit and Vincenzo Lippiello and Giuseppe Andrea Fontanelli and Bruno Siciliano",
keywords = "Perception",
keywords = "Deformable object modeling",
keywords = "Registration",
keywords = "Robotic manipulation ",
abstract = "Abstract This paper presents a method for tracking a 3D textureless object which undergoes elastic deformations, using the point cloud data provided by an RGB-D sensor and in real-time. This solution is expected to be useful for enhanced manipulation of humanoid robotic systems, especially in the case of pizza dough to be ideally manipulated by a pizza chef robot. Our tracking framework relies on a prior visual segmentation of the object in the image. The segmented point cloud is registered first in a rigid manner and then by non-rigidly fitting the mesh, based on the Finite Element Method to model elasticity, and on geometrical point-to-point correspondences to compute external forces exerted on the mesh. The system has been evaluated on synthetic and real data, and by integrating it into manipulation experiments on the RoDyMan1 1 http://www.rodyman.eu/. The research leading to these results has been supported by the RoDyMan project, which has received funding from the European Research Council(FP7 IDEAS) under Advanced Grant agreement number 320992. The authors are solely responsible for its content. It does not represent the opinion of the European Community and the Community is not responsible for any use that might be made of the information contained therein. humanoid robotic platform. "
}
@incollection{Luxton2016137,
title = "Chapter 6 - Intelligent Mobile, Wearable, and Ambient Technologies for Behavioral Health Care ",
editor = "Luxton, David D. ",
booktitle = "Artificial Intelligence in Behavioral and Mental Health Care ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2016",
pages = "137 - 162",
isbn = "978-0-12-420248-1",
doi = "https://doi.org/10.1016/B978-0-12-420248-1.00006-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780124202481000064",
author = "David D. Luxton and Jennifer D. June and Akane Sano and Timothy Bickmore",
keywords = "Mobile",
keywords = "mHealth",
keywords = "apps",
keywords = "affective wearables",
keywords = "ambient intelligence",
keywords = "context awareness",
keywords = "smart environments",
keywords = "pervasive computing ",
abstract = "This chapter provides an overview of intelligent mobile, wearable, and ambient device applications for behavioral health care. Several of the latest advancements in these technologies are presented and descriptions of applicable artificial intelligence methods and technologies are provided. Examples of their practical applications in behavioral and mental health care are also provided. Design recommendations are given and relevant security, privacy and ethical considerations specific to the use of these technologies are discussed. The chapter concludes with a discussion of emerging technologies and opportunities. "
}
@article{Barbero2011188,
title = "Comparative study of different digitization techniques and their accuracy ",
journal = "Computer-Aided Design ",
volume = "43",
number = "2",
pages = "188 - 206",
year = "2011",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2010.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0010448510002150",
author = "Basilio Ramos Barbero and Elena Santos Ureta",
keywords = "Reverse engineering (RE)",
keywords = "Tomography",
keywords = "CT",
keywords = "Surface mesh",
keywords = "3D CAD",
keywords = "Laser scanner",
keywords = "3D point cloud",
keywords = "Reconstruction mesh",
keywords = "Point cloud data reduction",
keywords = "Accuracy ",
abstract = "The various manufacturers of digitization systems speak of the effectiveness and accuracy of their tools under optimal conditions, but actual experimentation with simple or complex objects and different materials yields results that on occasions refute the effectiveness of those systems. In order to help choose a digitization system on the basis of its accuracy and the quality of the distribution of points and triangular meshes, in the field of reverse engineering, we compared five digitization techniques (three versions of the laser scanner, a fringe projection version and an X-ray version): (1) an ordered point cloud obtained with a laser incorporated in a CMM, (2) a disordered point cloud obtained with a manual laser the position of which is determined with a Krypton Camera, (3) an Exascan manual laser with targets, (4) an ordered point cloud obtained by high precision Computerized Tomography (CT) and (5) an Atos fringe projection scanner with targets. Each of the three calibrated pieces (a sphere, a cylinder and a gauge block) was measured five times by the five digitization systems to confirm the accuracy of the measurement. A comparison was also made of the meshes generated by the five software packages (Focus-Inspection, Metris, VxScan, Mimics and Atos) of the five digitization systems for the three calibrated pieces and two more complex pieces (a bone and an automobile window winder pulley) to determine meshing quality. Finally, all the pieces were meshed by triangulation in the Catia \{V5\} \{DSE\} (Digitized Shape Editor) module in order to test the quality of the points distribution. "
}
@article{Zhu201596,
title = "Calculating the medial axis of a \{CAD\} model by multi-CPU based parallel computation ",
journal = "Advances in Engineering Software ",
volume = "85",
number = "",
pages = "96 - 107",
year = "2015",
note = "",
issn = "0965-9978",
doi = "https://doi.org/10.1016/j.advengsoft.2015.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S096599781500040X",
author = "Housheng Zhu and Yusheng Liu and Jianjun Zhao and Hongwei Wang",
keywords = "Medial axis",
keywords = "CAD models",
keywords = "Distance dilation",
keywords = "Parallel computing",
keywords = "Model simplication",
keywords = "Voxelization-based method ",
abstract = "Abstract Computational efficiency is still a great challenge for the generation of the Medial Axis (MA) for complicated \{CAD\} models. Current research mainly focuses on CPU-based \{MA\} generation methods. However, most of the methods emphasize using a single CPU. The highly-efficient methods based on parallel computing are still missing. In this study, a parallel method based on multi-CPU is proposed for the efficient \{MA\} generation of \{CAD\} models using distance dilation. By dividing the whole model into several parts for which \{MAs\} are calculated in parallel and then combined, computational efficiency can be greatly improved in theory and the computation time can be reduced nearly K times if K \{CPUs\} are used. Firstly, an adaptive division method is proposed to divide the voxelized model into blocks which have nearly the same number of voxels to balance the computational burden. Secondly, the local Euclidean Distance Transform (EDT) is calculated for each block based on the existing distance dilation method. Thirdly, the complete inter-dilation method is proposed to compute the influence between different blocks to get a global \{EDT\} for each block. Finally, each block generates a sub-MA separately and then all the generated \{MAs\} are combined to obtain the final MA. The last three processes can be efficiently conducted in parallel by using multiple CPUs. Several groups of experiments are conducted which demonstrate the good performance of the proposed methods in terms of efficiency. "
}
@article{Simond2008777,
title = "What can be done with an embedded stereo-rig in urban environments? ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "9",
pages = "777 - 789",
year = "2008",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2007.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889007001753",
author = "Nicolas Simond and Patrick Rives",
keywords = "Stereo-vision",
keywords = "Mobile robotics",
keywords = "Urban environment",
keywords = "Super-homography",
keywords = "Trajectography",
keywords = "2.5D reconstruction ",
abstract = "The development of the Autonomous Guided Vehicles (AGVs) with urban applications are now possible due to the recent solutions (DARPA Grand Challenge) developed to solve the Simultaneous Localization And Mapping (SLAM) problem: perception, path planning and control. For the last decade, the introduction of \{GPS\} systems and vision have been allowed the transposition of \{SLAM\} methods dedicated to indoor environments to outdoor ones. When the \{GPS\} data are unavailable, the current position of the mobile robot can be estimated by the fusion of data from odometer and/or Inertial Navigation System (INS). We detail in this article what can be done with an uncalibrated stereo-rig, when it is embedded in a vehicle which is going through urban roads. The methodology is based on features extracted on planes: we mainly assume the road at the foreground as the plane common to all the urban scenes but other planes like vertical frontages of buildings can be used if the features extracted on the road are not enough relevant. The relative motions of the coplanar features tracked with both cameras allow us to estimate the vehicle ego-motion with a high precision. Futhermore, the features which don’t check the relative motion of the considered plane can be assumed as obstacles. "
}
@article{Viswanathan20161,
title = "Simulation-assisted exploration of charging infrastructure requirements for electric vehicles in urban environments ",
journal = "Journal of Computational Science ",
volume = "12",
number = "",
pages = "1 - 10",
year = "2016",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2015.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S187775031530034X",
author = "Vaisagh Viswanathan and Daniel Zehe and Jordan Ivanchev and Dominik Pelzer and Alois Knoll and Heiko Aydt",
keywords = "Traffic simulation",
keywords = "Charging station placement",
keywords = "Agent based modelling",
keywords = "Nanoscopic simulation",
keywords = "Data driven computing ",
abstract = "Abstract High population densities in today's cities are leading to increasing congestion and air pollution. Sustainable cities of the future will require a large scale transition to electro-mobility. The development of electric vehicle charging infrastructure is necessary to enable this transition. Existing methods for determining charging infrastructure take an optimization approach that ignores existing traffic demands and infrastructure. Moreover, the dynamics of vehicle movement like stop-and-go traffic, congestion and the effect of traffic lights are not considered in determining energy consumption. In this paper, we propose a novel nanoscopic city-scale traffic simulation based method for determining charging infrastructure locations; subsequently, we demonstrate its usefulness in spatio-temporal planning through a case-study of Singapore. Through this method, existing traffic and road network data and the dynamics of individual vehicle movement can be taken into consideration in planning. "
}
@article{Fontmarty2007361,
title = "\{IMPLEMENTATION\} \{OF\} \{HUMAN\} \{PERCEPTION\} \{ALGORITHMS\} \{ON\} A \{MOBILE\} \{ROBOT\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "361 - 366",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00062",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346870",
author = "Mathias Fontmarty and Thierry Germa and Brice Burger and Luis Felipe Marin and Steffen Knoop",
keywords = "Mobile Robotics",
keywords = "Integration",
keywords = "Human Perception ",
abstract = "Abstract During last years, a lot of works in robotic research have explored Human-Robot interactions. Hence, a great challenge in next future will be the personal robot, with perception faculties which will enable a wide range of activities such as human localization and tracking, gesture recognition and interpretation, or object manipulation. In this paper, we will focus on human perception and we will present a human aware system implemented on a mobile robot. This system uses data from various sensors to be able to localize and to track a human presence in a wide range of distances. An exploitation of all these modalities is presented in a demo showing the robot giving an object to a person. "
}
@article{Bi2010403,
title = "Advances in 3D data acquisition and processing for industrial applications ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "26",
number = "5",
pages = "403 - 413",
year = "2010",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S073658451000013X",
author = "Z.M. Bi and Lihui Wang",
keywords = "Vision-based system",
keywords = "Data acquisition",
keywords = "Data processing",
keywords = "3D images",
keywords = "Point clouds",
keywords = "Surface reconstruction. ",
abstract = "A critical task of vision-based manufacturing applications is to generate a virtual representation of a physical object from a dataset of point clouds. Its success relies on reliable algorithms and tools. Many effective technologies have been developed to solve various problems involved in data acquisition and processing. Some articles are available on evaluating and reviewing these technologies and underlying methodologies. However, for most practitioners who lack a strong background on mathematics and computer science, it is hard to understand theoretical fundamentals of the methodologies. In this paper, we intend to survey and evaluate recent advances in data acquisition and progressing, and provide an overview from a manufacturing perspective. Some potential manufacturing applications have been introduced, the technical gaps between the practical requirements and existing technologies discussed, and research opportunities identified. "
}
@article{deFilippo2013471,
title = "Reproducible Noninvasive Method for Evaluation of Glenoid Bone Loss by Multiplanar Reconstruction Curved Computed Tomographic Imaging Using a Cadaveric Model ",
journal = "Arthroscopy: The Journal of Arthroscopic & Related Surgery ",
volume = "29",
number = "3",
pages = "471 - 477",
year = "2013",
note = "",
issn = "0749-8063",
doi = "https://doi.org/10.1016/j.arthro.2012.10.017",
url = "http://www.sciencedirect.com/science/article/pii/S0749806312017604",
author = "Massimo de Filippo and Alessandro Castagna and Lynne Susan Steinbach and Mario Silva and Giorgio Concari and Giuseppe Pedrazzi and Francesco Pogliacomi and Nicola Sverzellati and Dario Petriccioli and Marco Vitale and Francesco Ceccarelli and Maurizio Zompatori and Cristina Rossi",
abstract = "Purpose To determine if the measurement of the glenoid surface by computed tomography (CT) with curved multiplanar reconstructions (cMPR) in a cadaveric model is an accurate and reproducible technique. Methods Ten dried cadaveric glenoid specimens were used. Two glenoids were subsequently modified mechanically to induce a bony Bankart lesion. Three skilled musculoskeletal radiologists performed cMPR on computed tomographic images of the glenoids; one of the radiologists repeated the same measurements after 3 months. Two of the 3 operators used the traditional “flat” \{MPR\} method as a control. An optical scanning system using a high-precision laser (CAM2 Laser Line Probe, Faro Technologies, Lake Mary, FL) was used as a reference. From the data obtained, an evaluation was performed for variability, degree of interoperator and intraoperator agreement, and degree of agreement between the laser and \{CT\} methods. Statistical analysis was performed with PASW-SPSS, version 18 (IBM, Armonk, NY) and R, version 2.12 statistical package. Results The average difference between the 2 sets of cMPR measurements was approximately 1%, and maximum and minimum values were between 6.02% and −0.29%. The flat \{MPR\} method showed mean differences of 16% when compared with laser scanning, and maximum and minimum values were 31% and 8%, respectively. The interoperator variability for the “curved” method was limited and showed a coefficient of variation ranging from 0.78% to 2.82%. The Cronbach alpha coefficient for this set of measurements was alpha = 0.995. There was little intraoperator variability with the coefficient of variation between 0% and 2% and an intraclass correlation coefficient of 0.989. Conclusions The use of cMPR computed tomographic imaging of the glenoid in a cadaveric model was found to be significantly more accurate than conventional \{MPR\} (flat MPR). Moreover, cMPR \{CT\} is a reproducible technique providing reliable information despite the relevant variable anatomy of the glenoid surface. This technique could reasonably also be used in a clinical setting as a more accurate noninvasive method. Clinical of Relevance This technique could also reasonably be used in a clinical setting as a more accurate noninvasive method. "
}
@article{ChandranRamesh2007463,
title = "\{ASSESSING\} \{MAP\} \{QUALITY\} \{AND\} \{ERROR\} \{CAUSATION\} \{USING\} \{CONDITIONAL\} \{RANDOM\} \{FIELDS\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "463 - 468",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00079",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016347048",
author = "Manjari Chandran-Ramesh and Paul Newman",
keywords = "Mapping",
keywords = "Map Quality",
keywords = "Navigation",
keywords = "Mobile Robotics ",
abstract = "Abstract This paper is about assessing the quality of maps built by a mobile robot. We extend previous work, which used solely geometric considerations, and use both temporal and spatial properties of the map to perform a binary classification of “plausible” and “suspicious”. The use of the former allows the existence of low quality areas of the map to be attributed to missed loop closure events or local, online mapping errors. With an eye on our intended domain of urban operation, we adopt a Conditional Random Field as the probabilistic framework in which to model the spatial and temporal relationships between planar patches. The map quality labels are derived by using standard graph cuts optimization techniques. The approach is then illustrated with map created of an urban environment using data from a 3D laser range scanner mounted on a mobile robot. "
}
@article{Jiang2015141,
title = "Big Data Analytics as a Service for Affective Humanoid Service Robots ",
journal = "Procedia Computer Science ",
volume = "53",
number = "",
pages = "141 - 148",
year = "2015",
note = "\{INNS\} Conference on Big Data 2015 Program San Francisco, CA, \{USA\} 8-10 August 2015 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.07.288",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915017913",
author = "Ming Jiang and Li Zhang",
keywords = "Affective Computing",
keywords = "Big Data Analytics",
keywords = "Continuous Learning",
keywords = "Distributed Collaboration",
keywords = "Humanoid",
keywords = "Service Robots ",
abstract = "Abstract This paper identifies and analyses the advanced capability requirements for humanoid service robots to serve in highly complicated and intelligence demanding applications, such as children education and home care, in future smart home environments. In particular, a Distributed Collaboration and Continuous Learning (DCCL) mechanism is identified as the key capability of a humanoid service robot to succeed in these applications. Based on the latest Big Data Analytics tools with distributed machine learning technologies integrated as services, a novel \{DCCL\} middleware platform is developed to facilitate the realisation of the \{DCCL\} mechanism. A user preference based children toy recommendation application is introduced as a use case study of the \{DCCL\} mechanism and platform. "
}
@article{Boissenin20071107,
title = "Computer vision methods for optical microscopes ",
journal = "Image and Vision Computing ",
volume = "25",
number = "7",
pages = "1107 - 1116",
year = "2007",
note = "Computer Vision Applications ",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2006.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0262885606002794",
author = "M. Boissenin and J. Wedekind and A.N. Selvan and B.P. Amavasai and F. Caparrelli and J.R. Travis",
keywords = "Computer vision",
keywords = "Microscope imaging",
keywords = "Micro-robotics",
keywords = "Tracking",
keywords = "Depth estimation ",
abstract = "As the fields of micro- and nano-technology mature, there will be an increased need to build tools that are able to work in these areas. Industry will require solutions for assembling and manipulating components, much as it has done in the macro range. With this need in mind, a new set of challenges requiring novel solutions have to be met. One of them is the ability to provide closed-loop feedback control for manipulators. We foresee that machine vision will play a leading role in this area. This paper introduces a technique for integrating machine vision into the field of micro-technology including two methods, one for tracking and one for depth reconstruction under an optical microscope. "
}
@article{Ghose2012262,
title = "A survey of prostate segmentation methodologies in ultrasound, magnetic resonance and computed tomography images ",
journal = "Computer Methods and Programs in Biomedicine ",
volume = "108",
number = "1",
pages = "262 - 287",
year = "2012",
note = "",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2012.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S0169260712001083",
author = "Soumya Ghose and Arnau Oliver and Robert Martí and Xavier Lladó and Joan C. Vilanova and Jordi Freixenet and Jhimli Mitra and Désiré Sidibé and Fabrice Meriaudeau",
keywords = "Prostate gland segmentation methods",
keywords = "TRUS images",
keywords = "MR images",
keywords = "CT images ",
abstract = "Prostate segmentation is a challenging task, and the challenges significantly differ from one imaging modality to another. Low contrast, speckle, micro-calcifications and imaging artifacts like shadow poses serious challenges to accurate prostate segmentation in transrectal ultrasound (TRUS) images. However in magnetic resonance (MR) images, superior soft tissue contrast highlights large variability in shape, size and texture information inside the prostate. In contrast poor soft tissue contrast between prostate and surrounding tissues in computed tomography (CT) images pose a challenge in accurate prostate segmentation. This article reviews the methods developed for prostate gland segmentation TRUS, \{MR\} and \{CT\} images, the three primary imaging modalities that aids prostate cancer diagnosis and treatment. The objective of this work is to study the key similarities and differences among the different methods, highlighting their strengths and weaknesses in order to assist in the choice of an appropriate segmentation methodology. We define a new taxonomy for prostate segmentation strategies that allows first to group the algorithms and then to point out the main advantages and drawbacks of each strategy. We provide a comprehensive description of the existing methods in all TRUS, \{MR\} and \{CT\} modalities, highlighting their key-points and features. Finally, a discussion on choosing the most appropriate segmentation strategy for a given imaging modality is provided. A quantitative comparison of the results as reported in literature is also presented. "
}
@article{Isa2012480,
title = "Secure System Architecture for Wide Area Surveillance Using Security, Trust and Privacy (STP) Framework ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "480 - 485",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.201",
url = "http://www.sciencedirect.com/science/article/pii/S187770581202601X",
author = "Mohd Anuar Mat Isa and Habibah Hashim and Jamalul-lail Ab Manan and Ramlan Mahmod and Mohd Saufy Rohmad and Abdul Hafiz Hamzah and Meor Mohd Azreen Meor Hamzah and Lucyantie Mazalan and Hanunah Othman and Lukman Adnan",
keywords = "Trusted Computing",
keywords = "Surveillance",
keywords = "Heartbeat",
keywords = "Security",
keywords = "Trust",
keywords = "Privacy",
keywords = "STP",
keywords = "TPM",
keywords = "AMT",
keywords = "Attestation",
keywords = "Secure System",
keywords = "Sensor",
keywords = "Beacon",
keywords = "Energy",
keywords = "Power ",
abstract = "Mobile computing emerged in the market for the past few years to provide solution for various platforms that range from smart phone, tablet, laptop, desktop computer, server to virtual computing systems such as cloud computing. The design approach and development of solutions for mobile computing continues to evolve in fulfilling the needs of diverse applications that run on various platforms. Recently, a new framework was introduced to provide a unified approach to resolve Security, Trust and Privacy (STP) enhancement on these platforms. This new framework emerged to enable a better way of dealing with security, trust and privacy conflicting aspects in pervasive environment such as mobile computing. This framework will be useful for system architects, engineers, designers and developers that are still struggling to create a secure, trustworthy, and privacy preserved environment to create confidence amongst users to do business transactions and collaborations especially in a more challenging environment such as cloud computing. In this paper, we discuss and propose new Secure System Architecture for strengthening surveillance activities in Wide Area using a combination of Trusted Computing (TC) via mutual attestation process to ensure integrity of components of the system, and Surveillance System. We further propose using Intel \{AMT\} chip that will generate a heartbeat pulse and transmit the signal through network interface to detect any possible physical intrusion. A failure to provide this pulse within a given time frame will trigger an action by the trusted security system for further analysis such as thievery detection. "
}
@incollection{Loménie2011255,
title = "Chapter 4 - Point Set Analysis ",
editor = "Peter W. Hawkes",
booktitle = "Advances in Imaging and Electron Physics",
publisher = "Elsevier",
year = "2011",
volume = "167",
pages = "255 - 294",
series = "Advances in Imaging and Electron Physics ",
issn = "1076-5670",
doi = "https://doi.org/10.1016/B978-0-12-385985-3.00004-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780123859853000043",
author = "Nicolas Loménie and Georges Stamon",
keywords = "Point set",
keywords = "point cloud",
keywords = "mathematical morphology",
keywords = "mesh",
keywords = "Delaunay triangulation",
keywords = "image analysis",
keywords = "sparse representation",
keywords = "nonlinear filtering ",
abstract = "Abstract Dealing with imaging issues usually entails handling digital radiometric images. However, visual data can be efficiently handled as geometric point sets either due to the nature of the acquisition device or the intrinsic redundancy within large amounts of radiometric data. Most research works about geometric structures are related to computer graphics and image synthesis; meshes as graph representations have been involved only in a few image analysis issues to date. Yet, much room remains for completing the visual analysis tools as most image analysis algorithms are designed ro radiometric data distributed over a regular grid. We propose to extend the standard image analysis toolbox to unstructured point sets usually connected via mesh structures such as Delaunay triangulations. A particular focus on mathematical morphology sheds light on the potential applications of these ideas. More specifically, applications to digital microscopy imaging issues are discussed and preliminary results are presented. "
}
@incollection{Bowker2015186,
title = "Science and Technology, Social Study of: Computers and Information Technology ",
editor = "Wright, James D. ",
booktitle = "International Encyclopedia of the Social & Behavioral Sciences (Second Edition) ",
publisher = "Elsevier",
edition = "Second Edition",
address = "Oxford",
year = "2015",
pages = "186 - 191",
isbn = "978-0-08-097087-5",
doi = "https://doi.org/10.1016/B978-0-08-097086-8.85024-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780080970868850242",
author = "Geoffrey C. Bowker and Susan Leigh Star",
keywords = "Computer Supported Co-operative Work",
keywords = "Computers",
keywords = "Cyber-infrastructure",
keywords = "Digital libraries",
keywords = "Human computer interaction",
keywords = "Information infrastructure",
keywords = "Information technology",
keywords = "Internet",
keywords = "Knowledge infrastructure",
keywords = "Mobile technology",
keywords = "Pervasive computing",
keywords = "Social studies of science and technology",
keywords = "Ubicomp ",
abstract = "This article is a revision of the previous edition article by S.L. Star, volume 20, pp. 13638–13644, © 2001, Elsevier Ltd. Abstract Computers and information technology have over the past 50 years moved from being a social and engineering form which ‘impacted’ society to being core to our social fabric – much as we cannot study an ecosystem without considering water supply, so we cannot study any part of society without considering the flow of bits and bytes. The richly textured fabric of this fundamental social change has been studied at various levels, without there being as yet a single integrating vision. This article identifies some key levels and points to possibilities for an integrated understanding. "
}
@article{Nüchter2010963,
title = "Study of parameterizations for the rigid body transformations of the scan registration problem ",
journal = "Computer Vision and Image Understanding ",
volume = "114",
number = "8",
pages = "963 - 980",
year = "2010",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2010.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S107731421000072X",
author = "Andreas Nüchter and Jan Elseberg and Peter Schneider and Dietrich Paulus",
keywords = "3D scan matching",
keywords = "3D point cloud registration",
keywords = "ICP algorithm ",
abstract = "The iterative closest point (ICP) algorithm is the de facto standard for geometric alignment of three-dimensional models when an initial relative pose estimate is available. The basis of the algorithm is the minimization of an error function that takes point correspondences into account. Four closed-form solution methods are known for minimizing this function. This paper presents novel linear solutions to the scan registration problem, i.e., to the problem of putting and aligning 3D scans in a common coordinate system. We extend the methods for registering n-scans in a global and simultaneous fashion, such that the registration of the nth scan influences all previous registrations in one step. "
}
@article{Söchting2015193,
title = "Development of Tests to Evaluate the Sensory Abilities of Children with Autism Spectrum Disorder ",
journal = "Procedia Computer Science ",
volume = "67",
number = "",
pages = "193 - 203",
year = "2015",
note = "Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.09.263",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915031099",
author = "Elisabeth Söchting and Johannes Hartl and Martin Riederer and Christian Schönauer and Hannes Kaufmann and Claus Lamm",
keywords = "autism spectrum disorder",
keywords = "proprioception",
keywords = "kineshesia",
keywords = "pervasive computing",
keywords = "mobile healthcare",
keywords = "wireless sensors",
keywords = "RGB-D sensor ",
abstract = "Abstract An emerging line of research attempts to reveal underlying mechanisms of Autism Spectrum Disorder (ASD) by studying differences in sensory processing in individuals with ASD. One sense that has not been studied well yet in this context is proprioception, a sensory system that processes information from muscles and joints about body position and force, and is hypothesized to feed into a body schema that is the foundation for motor planning and purposeful action (praxis). In this paper, we introduce new methods to measure proprioceptive functions of children with ASD. The instruments use force, touch and RGB-D sensors to retrieve data in different test scenarios. Data are transferred to a mobile device or \{PC\} and analyzed close to real-time with specifically developed software tools. The instruments were pilot tested with typically developing children to test for functionality and usability of the instruments. They will be used in a larger study with children with ASD. "
}
@article{Hendrix2014418,
title = "CAMP: Community Access \{MODIS\} Pipeline ",
journal = "Future Generation Computer Systems ",
volume = "36",
number = "",
pages = "418 - 429",
year = "2014",
note = "Special Section: Energy-efficiency in Large Distributed Computing Architectures ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.09.023",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13002021",
author = "Valerie Hendrix and Lavanya Ramakrishnan and Youngryel Ryu and Catharine van Ingen and Keith R. Jackson and Deborah Agarwal",
keywords = "MODIS",
keywords = "Data-intensive",
keywords = "High Performance computing ",
abstract = "Abstract The Moderate Resolution Imaging Spectroradiometer (MODIS) instrument’s land and atmosphere data are important to many scientific analyses that study processes at both local and global scales. The Terra and Aqua \{MODIS\} satellites acquire data of the entire Earth’s surface every one or two days in 36 spectral bands. \{MODIS\} data provide information to complement many of the ground-based observations but are extremely critical when studying global phenomena such as gross photosynthesis and evapotranspiration. However, data procurement and processing can be challenging and cumbersome due to difficulties in volume, size of data and scale of analyses. For example, the very first step in \{MODIS\} data processing is to ensure that all products are in the same resolution and coordinate system. The reprojection step involves a complex inverse gridding algorithm and involves downloading tens of thousands of files for a single year that is often infeasible to perform on a scientist’s desktop. Thus, use of large-scale resource environments such as high performance computing (HPC) environments are becoming crucial for processing of \{MODIS\} data. However, \{HPC\} environments have traditionally been used for tightly coupled applications and present several challenges for managing data-intensive pipelines. We have developed a data-processing pipeline that downloads the \{MODIS\} swath products and reprojects the data to a sinusoidal system on an \{HPC\} system. The 10 year archive of the reprojected data generated using the pipeline is made available through a web portal. In this paper, we detail a system architecture (CAMP) to manage the lifecycle of \{MODIS\} data that includes procurement, storage, processing and dissemination. Our system architecture was developed in the context of the \{MODIS\} reprojection pipeline but is extensible to other analyses of \{MODIS\} data. Additionally, our work provides a framework and valuable experiences for future developments and deployments of data-intensive pipelines from other scientific domains on \{HPC\} systems. "
}
@article{Zając2014151,
title = "Online fault detection of a mobile robot with a parallelized particle filter ",
journal = "Neurocomputing ",
volume = "126",
number = "",
pages = "151 - 165",
year = "2014",
note = "Recent trends in Intelligent Data AnalysisOnline Data ProcessingSelected papers of the The 6th International Conference on Hybrid Artificial Intelligence Systems (HAIS 2011)Including a selection of papers from the International Conference on Adaptive and Intelligent Systems 2011 (ICAIS 2011) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2012.11.049",
url = "http://www.sciencedirect.com/science/article/pii/S0925231213005316",
author = "Michał Zając",
keywords = "Particle filter",
keywords = "Mobile robots",
keywords = "Fault detection",
keywords = "Parallel computing ",
abstract = "Abstract Fault diagnosis is one of the most challenging problems, which have to be solved if one considers real-life applications of mobile robots. In this paper, we present a particle filtering-based approach combined with the negative log-likelihood test to address the fault detection task. The major disadvantage of the method is its high computational burden closely related to the number of particles used, which can be computationally too expensive to be processed online by the onboard computer of the robot. In order to address this problem, a solution, in which a part of computations are delegated to an external parallel computing environment such as a computer cluster, is presented. The proposed methods of parallelizing particle filters are aimed at improving their performance in terms of efficiency, estimation error and execution time, which are vital factors in an online setup. To depict the performance benefits of the presented methods, they are confronted with some other existing approaches in a series of experiments. "
}
@article{Briceño20131705,
title = "Robust static resource allocation of \{DAGs\} in a heterogeneous multicore system ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "73",
number = "12",
pages = "1705 - 1717",
year = "2013",
note = "Heterogeneity in Parallel and Distributed Computing ",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2013.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0743731513001627",
author = "Luis Diego Briceño and Jay Smith and Howard Jay Siegel and Anthony A. Maciejewski and Paul Maxwell and Russ Wakefield and Abdulla Al-Qawasmeh and Ron C. Chiang and Jiayin Li",
keywords = "Directed acyclical graph",
keywords = "Heterogeneous computing",
keywords = "Resource allocation ",
abstract = "Abstract In this study, we consider an environment composed of a heterogeneous cluster of multicore-based machines used to analyze satellite data. The workload involves large data sets and is subject to a deadline constraint. Multiple applications, each represented by a directed acyclic graph (DAG), are allocated to a dedicated heterogeneous distributed computing system. Each vertex in the \{DAG\} represents a task that needs to be executed and task execution times vary substantially across machines. The goal of this research is to assign the tasks in applications to a heterogeneous multicore-based parallel system in such a way that all applications complete before a common deadline, and their completion times are robust against uncertainties in execution times. We define a measure that quantifies robustness in this environment. We design, compare, and evaluate five static resource allocation heuristics that attempt to maximize robustness. We consider six different scenarios with different ratios of computation versus communication, and loose and tight deadlines. "
}
@article{Stahl201335,
title = "Virtual suicide and other ethical issues of emerging information technologies ",
journal = "Futures ",
volume = "50",
number = "",
pages = "35 - 43",
year = "2013",
note = "Exploring Future Business Visions Using Creative Fictional Prototypes ",
issn = "0016-3287",
doi = "https://doi.org/10.1016/j.futures.2013.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S001632871300044X",
author = "Bernd Carsten Stahl",
keywords = "Information and communication technology",
keywords = "Ethics",
keywords = "Foresight",
keywords = "ETICA project",
keywords = "Avatar",
keywords = "Affective computing",
keywords = "Ambient intelligence ",
abstract = "Abstract This paper uses the fictional account of a personal avatar (PETRA) and its interactions with a normal family in the future to explore some of the ethical issues of emerging information and communication technologies (ICTs). It is based on a foresight research project which investigated the ethical issues of such emerging ICTs. The findings of this research suggest that there are numerous well established ethical issues that are currently being discussed and that will remain relevant. These include questions of privacy and intellectual property. In addition, however, there are numerous possible ethical issues that relate to human individual and collective identity that are likely to be affected by novel technical developments. These issues currently are not discussed in academic or policy discourses. In order to render them more tangible and thus promote academic and policy discourses, fictional accounts play an important role. The present paper should therefore be understood as an attempt to translate the research findings on the ethics of emerging \{ICTs\} to a broader audience. "
}
@article{Macêdo2013420,
title = "Enhancing group communication with self-manageable behavior ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "73",
number = "4",
pages = "420 - 433",
year = "2013",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2012.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0743731512002869",
author = "Raimundo José de Araújo Macêdo and Allan Edgard Silva Freitas and Alírio Santos de Sá",
keywords = "Group communication",
keywords = "Self-management",
keywords = "Autonomic computing",
keywords = "Dependability",
keywords = "Dynamic adaptation ",
abstract = "Group communication protocols (GCPs) play an important role in the design of modern distributed systems. A typical \{GCP\} exchanges control messages to provide message delivery guarantees, and a key point in the configuration of such a protocol is to establish the right trade-off between message overhead and delivery latency. This trade-off becomes even a greater challenge in systems where computing resources and application requirements may change at runtime. In such scenarios, the configuration of a \{GCP\} must be continuously re-adjusted to attain certain performance goals, or to adapt to current resource availability. This paper addresses this challenge by proposing self-managing mechanisms based on feedback control theory to a \{GCP\} especially designed to be self-manageable; in the proposed protocol, message overhead and delivery latency can be adjusted at runtime to follow some new operating set-point. The evaluation performed under varied scenarios shows the effectiveness of our approach. "
}
@article{A˚ström20143,
title = "Control: A perspective ",
journal = "Automatica ",
volume = "50",
number = "1",
pages = "3 - 43",
year = "2014",
note = "",
issn = "0005-1098",
doi = "https://doi.org/10.1016/j.automatica.2013.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0005109813005037",
author = "Karl J. A˚ström and P.R. Kumar",
keywords = "Feedback",
keywords = "Control",
keywords = "Computing",
keywords = "Communication",
keywords = "Theory",
keywords = "Applications ",
abstract = "Abstract Feedback is an ancient idea, but feedback control is a young field. Nature long ago discovered feedback since it is essential for homeostasis and life. It was the key for harnessing power in the industrial revolution and is today found everywhere around us. Its development as a field involved contributions from engineers, mathematicians, economists and physicists. It is the first systems discipline; it represented a paradigm shift because it cut across the traditional engineering disciplines of aeronautical, chemical, civil, electrical and mechanical engineering, as well as economics and operations research. The scope of control makes it the quintessential multidisciplinary field. Its complex story of evolution is fascinating, and a perspective on its growth is presented in this paper. The interplay of industry, applications, technology, theory and research is discussed. "
}
@article{Browning2009320,
title = "A neural model of how the brain computes heading from optic flow in realistic scenes ",
journal = "Cognitive Psychology ",
volume = "59",
number = "4",
pages = "320 - 356",
year = "2009",
note = "",
issn = "0010-0285",
doi = "https://doi.org/10.1016/j.cogpsych.2009.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0010028509000425",
author = "N. Andrew Browning and Stephen Grossberg and Ennio Mingolla",
keywords = "Navigation",
keywords = "Optic flow",
keywords = "Heading",
keywords = "Motion",
keywords = "Visual cortex",
keywords = "V1",
keywords = "MT",
keywords = "MST",
keywords = "Neural model ",
abstract = "Visually-based navigation is a key competence during spatial cognition. Animals avoid obstacles and approach goals in novel cluttered environments using optic flow to compute heading with respect to the environment. Most navigation models try either explain data, or to demonstrate navigational competence in real-world environments without regard to behavioral and neural substrates. The current article develops a model that does both. The ViSTARS neural model describes interactions among neurons in the primate magnocellular pathway, including V1, MT+, and MSTd. Model outputs are quantitatively similar to human heading data in response to complex natural scenes. The model estimates heading to within 1.5° in random dot or photo-realistically rendered scenes, and within 3° in video streams from driving in real-world environments. Simulated rotations of less than 1°/s do not affect heading estimates, but faster simulated rotation rates do, as in humans. The model is part of a larger navigational system that identifies and tracks objects while navigating in cluttered environments. "
}
@article{Kaiiali20131909,
title = "Grid Authorization Graph ",
journal = "Future Generation Computer Systems ",
volume = "29",
number = "8",
pages = "1909 - 1918",
year = "2013",
note = "Including Special sections: Advanced Cloud Monitoring Systems &amp; The fourth \{IEEE\} International Conference on e-Science 2011 — e-Science Applications and Tools &amp; Cluster, Grid, and Cloud Computing ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2013.04.010",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13000708",
author = "Mustafa Kaiiali and Rajeev Wankar and C.R. Rao and Arun Agarwal and Rajkumar Buyya",
keywords = "Grid computing",
keywords = "Grid authorization",
keywords = "Access control",
keywords = "Hierarchical Clustering Mechanism",
keywords = "Grid Authorization Graph ",
abstract = "Abstract The heterogeneous and dynamic nature of a grid environment demands a scalable authorization system. This brings out the need for a fast fine-grained access control mechanism for authorizing grid resources. Existing grid authorization systems adopt inefficient mechanisms for storing resources’ security policies. This leads to a large number of repetitions in checking security rules. One of the efficient mechanisms that handle these repetitions is the Hierarchical Clustering Mechanism (HCM). \{HCM\} reduces the redundancy in checking security rules compared to the Brute Force Approach (BFA) as well as the Primitive Clustering Mechanism (PCM). Further enhancement is done to \{HCM\} to increase the scalability of the authorization process. However, \{HCM\} is not totally free of repetitions and cannot easily describe the OR-based security policies. A novel Grid Authorization Graph (GAG) is proposed to overcome \{HCM\} limitations. \{GAG\} introduces special types of edges named “Correspondence Edge”/“Discrepancy Edge” which can be used to entirely eliminate the redundancy and handle the cases where a set of security rules are mutually exclusive. Comparative studies are made in a simulated environment using the Grid Authorization Simulator (GAS) developed by the authors. It simulates the authorization process of the existing mechanisms like BFA, PCM, \{HCM\} and the proposed novel GAG. It also enables a comparative analysis to be done between these approaches. "
}
@article{AlJaroodi2012211,
title = "Service-oriented middleware: A survey ",
journal = "Journal of Network and Computer Applications ",
volume = "35",
number = "1",
pages = "211 - 220",
year = "2012",
note = "Collaborative Computing and Applications ",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2011.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S1084804511001512",
author = "Jameela Al-Jaroodi and Nader Mohamed",
keywords = "Service-oriented middleware",
keywords = "Service-oriented computing",
keywords = "Service provider",
keywords = "Middleware",
keywords = "Interoperability ",
abstract = "Service-oriented computing aims to make services available and easily accessible through standardized models and protocols without having to worry about the underlying infrastructures, development models or implementation details. This helps achieve interoperability and loose coupling among distributed application components and also among user processes. In addition, this model offers users an on-demand usage model where they only use the services needed for the time needed, which relieves them from having to build and maintain a complete system in house. However, the design and implementation of robust and efficient service-oriented applications are still as complex and demanding as any other type of distributed application. Thus middleware can play an important role in facilitating the design, development and implementation of service-oriented systems. Furthermore, middleware approaches will provision non-functional requirements like performance, scalability, reliability, flexibility and quality of service (QoS) assurance. A lot of work has been done in this area and in this paper we survey some of this work in service-oriented middleware (SOM). As we study the different projects we develop a list of the main requirements that \{SOM\} should support. We also discuss the main objectives and characteristics of the surveyed approaches, and then we highlight the challenges to be addressed when designing and developing \{SOM\} solutions that satisfy the requirements of different application domains. "
}
@article{Madsen1998277,
title = "Optimal landmark selection for triangulation of robot position ",
journal = "Robotics and Autonomous Systems ",
volume = "23",
number = "4",
pages = "277 - 292",
year = "1998",
note = "Intelligent Robotics Systems - SIRS'97 ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/S0921-8890(98)00014-1",
url = "http://www.sciencedirect.com/science/article/pii/S0921889098000141",
author = "Claus B. Madsen and Claus S. Andersen",
keywords = "Triangulation",
keywords = "Self-positioning",
keywords = "Landmarks",
keywords = "Performance characterization",
keywords = "Robustness",
keywords = "Navigation",
keywords = "Mobile robotics",
keywords = "Template matching ",
abstract = "A mobile robot can identify its own position relative to a global environment model by using triangulation based on three landmarks in the environment. It is shown that this procedure may be very sensitive to noise depending on spatial landmark configuration, and relative position between robot and landmarks. A general analysis is presented which permits prediction of the uncertainty in the triangulated position. In addition an algorithm is presented for automatic selection of optimal landmarks. This algorithm enables a robot to continuously base its position computation on the set of available landmarks, which provides the least noise sensitive position estimate. It is demonstrated that using this algorithm can result in more than one order of magnitude reduction in uncertainty. "
}
@article{Atzori20123594,
title = "The Social Internet of Things (SIoT) – When social networks meet the Internet of Things: Concept, architecture and network characterization ",
journal = "Computer Networks ",
volume = "56",
number = "16",
pages = "3594 - 3608",
year = "2012",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2012.07.010",
url = "http://www.sciencedirect.com/science/article/pii/S1389128612002654",
author = "Luigi Atzori and Antonio Iera and Giacomo Morabito and Michele Nitti",
keywords = "Ubiquitous computing",
keywords = "Internet of Things",
keywords = "Social networks ",
abstract = "Recently there has been quite a number of independent research activities that investigated the potentialities of integrating social networking concepts into Internet of Things (IoT) solutions. The resulting paradigm, named Social Internet of Things (SIoT), has the potential to support novel applications and networking services for the IoT in more effective and efficient ways. In this context, the main contributions of this paper are the following: (i) we identify appropriate policies for the establishment and the management of social relationships between objects in such a way that the resulting social network is navigable; (ii) we describe a possible architecture for the IoT that includes the functionalities required to integrate things into a social network; (iii) we analyze the characteristics of the \{SIoT\} network structure by means of simulations. "
}
@article{Apopei2012990,
title = "Automatic parallelisation for \{LTI\} \{MIMO\} state space systems using FPGAs. An optimisation for cost &amp; performance ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "72",
number = "8",
pages = "990 - 1007",
year = "2012",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/j.jpdc.2012.04.009",
url = "http://www.sciencedirect.com/science/article/pii/S0743731512001050",
author = "B. Apopei and T.J. Dodd",
keywords = "FPGA",
keywords = "Automation",
keywords = "State space",
keywords = "Control systems",
keywords = "Optimisation",
keywords = "Pipelining",
keywords = "Parallel computing",
keywords = "Resource sharing ",
abstract = "The parallelism attained by the use of Field Programmable Gate Arrays (FPGAs) has shown remarkable potential for accelerating control systems applications. This comes at a time when well established methods based on inherited serial Central Processor Units (CPUs) cannot guarantee solutions for the increasing execution speed demands. However, the transition from serial to parallel architectures represents a tremendous challenge due to overwhelming numbers of unexplored options and conflicting factors. The work presented achieves a parallelisation characterisation for generic \{MIMO\} systems using stand-alone \{FPGA\} implementations. The main contribution is that a very fine subset of possible serial/parallel implementations is obtained. This is used to achieve a flexible trade-off between cost and performance. Automatic optimisation of latency, occupied \{FPGA\} area and execution speed is attained and justified in respect to most of the feasible scenarios. "
}
@article{Moody2007337,
title = "Northern Hemisphere five-year average (2000–2004) spectral albedos of surfaces in the presence of snow: Statistics computed from Terra \{MODIS\} land products ",
journal = "Remote Sensing of Environment ",
volume = "111",
number = "2–3",
pages = "337 - 345",
year = "2007",
note = "Remote Sensing of the Cryosphere Special Issue ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2007.03.026",
url = "http://www.sciencedirect.com/science/article/pii/S0034425707002891",
author = "Eric G. Moody and Michael D. King and Crystal B. Schaaf and Dorothy K. Hall and Steven Platnick",
keywords = "Moderate Resolution Imaging Spectroradiometer (MODIS)",
keywords = "Radiative transfer",
keywords = "Remote sensing",
keywords = "Satellite applications",
keywords = "Spectral surface albedo",
keywords = "Terra",
keywords = "Vegetation",
keywords = "Ecosystem",
keywords = "Modeling",
keywords = "Snow ",
abstract = "In this paper, we present five-year (2000–2004) climatological statistics of Northern Hemisphere spectral white-sky albedo for the 16 International Geosphere–Biosphere Program (IGBP) ecosystem classes when accompanied by the presence of snow on the ground. These statistics are obtained using validated, high quality Moderate Resolution Imaging Spectroradiometer (MODIS) land surface albedo (MOD43B3) data flagged as snow in the associated Quality Assurance (QA) fields. Near Real-Time Ice and Snow Extent (NISE) data are used as an additional discriminator of snow extent. Statistics are provided for the first seven \{MODIS\} bands, ranging from 0.47 to 2.1 μm, and for three broadbands, 0.3–0.7, 0.3–5.0 and 0.7–5.0 μm. The statistics demonstrate that each ecosystem classification has a discernible spectral albedo signature when accompanied by snow on the ground. This indicates that winter canopy and the underlying surface radiative properties are impacted by the presence of snow overlying these surfaces. For example, the 0.47 μm albedo of winter snow-free evergreen needleleaf forests increases from 0.03 to 0.36 in the presence of snow, compared to an increase of 0.04 to 0.76 for croplands. In general, the albedo of snow-covered ecosystems with some winter canopy has lower albedos than ecosystems with little to no winter canopy; for example the 0.47 μm albedo of snow-covered mixed forests is 0.39 compared to 0.87 for barren/deserts and 0.95 for permanent snow. These statistics can be used within land surface models in a stand-alone mode, to prescribe albedo values in atmospheric General Circulation Models (GCMs), or be incorporated into research and operational projects. They are intended to provide researchers with representative spectral albedo values of \{IGBP\} ecosystems in the presence of snow that are derived from validated satellite data. "
}
@article{Yoon201633,
title = "Trend estimates of AERONET-observed and model-simulated \{AOTs\} between 1993 and 2013 ",
journal = "Atmospheric Environment ",
volume = "125, Part A",
number = "",
pages = "33 - 47",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.10.058",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015304738",
author = "J. Yoon and A. Pozzer and D.Y. Chang and J. Lelieveld and J. Kim and M. Kim and Y.G. Lee and J.-H. Koo and J. Lee and K.J. Moon",
keywords = "Aerosol optical thickness",
keywords = "AErosol \{RObotic\} NETwork",
keywords = "ECHAM/MESSy atmospheric chemistry model",
keywords = "Trend estimates",
keywords = "Monthly percentiles",
keywords = "Monthly cumulative distributions ",
abstract = "Abstract Recently, temporal changes in Aerosol Optical Thickness (AOT) have been investigated based on model simulations, satellite and ground-based observations. Most \{AOT\} trend studies used monthly or annual arithmetic means that discard details of the generally right-skewed \{AOT\} distributions. Potentially, such results can be biased by extreme values (including outliers). This study additionally uses percentiles (i.e., the lowest 5%, 25%, 50%, 75% and 95% of the monthly cumulative distributions fitted to Aerosol Robotic Network (AERONET)-observed and ECHAM/MESSy Atmospheric Chemistry (EMAC)-model simulated AOTs) that are less affected by outliers caused by measurement error, cloud contamination and occasional extreme aerosol events. Since the limited statistical representativeness of monthly percentiles and means can lead to bias, this study adopts the number of observations as a weighting factor, which improves the statistical robustness of trend estimates. By analyzing the aerosol composition of AERONET-observed and EMAC-simulated \{AOTs\} in selected regions of interest, we distinguish the dominant aerosol types and investigate the causes of regional \{AOT\} trends. The simulated and observed trends are generally consistent with a high correlation coefficient (R = 0.89) and small bias (slope±2σ = 0.75 ± 0.19). A significant decrease in EMAC-decomposed \{AOTs\} by water-soluble compounds and black carbon is found over the \{USA\} and the \{EU\} due to environmental regulation. In particular, a clear reversal in the \{AERONET\} \{AOT\} trend percentiles is found over the USA, probably related to the \{AOT\} diurnal cycle and the frequency of wildfires. In most of the selected regions of interest, EMAC-simulated trends are mainly attributed to the significant changes of the dominant aerosols; e.g., significant decrease in sea salt and water soluble compounds over Central America, increase in dust over Northern Africa and Middle East, and decrease in black carbon and organic carbon over Australia. "
}
@article{Parikh19991389,
title = "An evolutionary system for recognition and tracking of synoptic-scale storm systems ",
journal = "Pattern Recognition Letters ",
volume = "20",
number = "11–13",
pages = "1389 - 1396",
year = "1999",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/S0167-8655(99)00110-5",
url = "http://www.sciencedirect.com/science/article/pii/S0167865599001105",
author = "J.A Parikh and J.S DaPonte and J.N Vitale and G Tselioudis",
keywords = "Cloud tracking",
keywords = "Evolutionary computation",
keywords = "Optical flow",
keywords = "Self-organizing maps",
keywords = "k-nearest neighbor analysis ",
abstract = "An evolutionary system was developed for generation of complete tracks of northern midlatitude synoptic-scale storm systems based on optical flow and cloud motion analyses of global satellite-based datasets produced by the International Satellite Cloud Climatology Project (ISCCP). The tracking results were compared with low sea level pressure anomaly (SLPA) tracks obtained from the \{NASA\} Goddard Institute for Space Studies (GISS). The \{SLPA\} tracks were produced at \{GISS\} by analysis of meteorological, ground-based National Center for Environmental Prediction (NCEP) datasets. Results from the evolutionary system were also compared with results from using (a) the k-nearest neighbor rule (k-NN) and (b) self-organizing maps (SOM) to determine correspondences between consecutive locations within a track. The consistency of our evolutionary storm tracking results with the behavior of the low sea level pressure anomaly tracks, the ability of our evolutionary system to generate and evaluate complete tracks, and the close comparison between the results obtained by the evolutionary, k-NN, and \{SOM\} analyses of the ISCCP-derived datasets at tracking steps in which proximity or optical flow information sufficed to determine movement, demonstrate the applicability and the potential of evolutionary systems for tracking midlatitude storm systems through low-resolution \{ISCCP\} cloud product datasets. "
}
@article{Zhang20112348,
title = "P2P-based multidimensional indexing methods: A survey ",
journal = "Journal of Systems and Software ",
volume = "84",
number = "12",
pages = "2348 - 2362",
year = "2011",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2011.07.027",
url = "http://www.sciencedirect.com/science/article/pii/S0164121211001968",
author = "Chong Zhang and Weidong Xiao and Daquan Tang and Jiuyang Tang",
keywords = "Multidimensional index",
keywords = "Peer-to-peer computing",
keywords = "Survey ",
abstract = "P2P-based multidimensional index (MI) is a hotspot which absorbs many researchers to dedicate them into. However, no summarization or review on this technology has been made at present. To the best of our knowledge, this is the first work on reviewing P2P-based MI. This paper innovatively adopts visualization technique to show the research groups and then analyzes investigating style of research groups. Based on evolution of P2P-based \{MI\} inheriting from centralized \{MI\} and P2P, we divide P2P-based \{MI\} methods into 4 categories: extending centralized MI, extending P2P, combining centralized \{MI\} and P2P, and miscellaneous. For each category, the paper selects classical techniques and describes them in detail. This is the first time of doing the classification job over massive related works. Finally, load balancing and update strategies are described and discussed for they are important factors related to performance. We believe many researchers will get benefits from our work for further studies. "
}
@article{Wu2011397,
title = "From wireless sensor networks towards cyber physical systems ",
journal = "Pervasive and Mobile Computing ",
volume = "7",
number = "4",
pages = "397 - 413",
year = "2011",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2011.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1574119211000368",
author = "Fang-Jing Wu and Yu-Fen Kao and Yu-Chee Tseng",
keywords = "Cyber physical system",
keywords = "Internet technology",
keywords = "Mobile ad hoc network",
keywords = "Pervasive computing",
keywords = "Sensing and actuation",
keywords = "Wireless sensor network ",
abstract = "In the past two decades, a lot of research activities have been dedicated to the fields of mobile ad hoc network (MANET) and wireless sensor networks (WSN). More recently, the cyber physical system (CPS) has emerged as a promising direction to enrich the interactions between physical and virtual worlds. In this article, we first review some research activities in WSN, including networking issues and coverage and deployment issues. Then, we review some \{CPS\} platforms and systems that have been developed recently, including health care, navigation, rescue, intelligent transportation, social networking, and gaming applications. Through these reviews, we hope to demonstrate how \{CPS\} applications exploit the physical information collected by \{WSNs\} to bridge real and cyber spaces and identify important research challenges related to \{CPS\} designs. "
}
@article{Vernadat2010139,
title = "Technical, semantic and organizational issues of enterprise interoperability and networking ",
journal = "Annual Reviews in Control ",
volume = "34",
number = "1",
pages = "139 - 144",
year = "2010",
note = "",
issn = "1367-5788",
doi = "https://doi.org/10.1016/j.arcontrol.2010.02.009",
url = "http://www.sciencedirect.com/science/article/pii/S1367578810000155",
author = "François B. Vernadat",
keywords = "Enterprise networking",
keywords = "Enterprise integration",
keywords = "Enterprise Interoperability Framework",
keywords = "EIF",
keywords = "Systems interoperability",
keywords = "Semantic interoperability",
keywords = "Internet computing ",
abstract = "Enterprise networking refers to any kind of organization structures in which two or more geographically dispersed business entities need to work in interaction. This can happen within a single distributed enterprise (networked enterprise) or among several enterprises (network of enterprises), including the extended enterprise or virtual organizations. This concerns any kind of organizations, e.g. industrial firms, public organizations or large government agencies. Enterprise interoperability is a sine qua non-condition for enterprise integration and networking. It largely relies on information and communication technologies (ICT), especially Internet computing. The paper uses the European Interoperability Framework (EIF) as a foundational baseline to first discuss technical, semantic and organizational aspects of enterprise interoperability and networking and finally to address some open research issues. "
}
@article{Schrauwen20081159,
title = "Improving reservoirs using intrinsic plasticity ",
journal = "Neurocomputing ",
volume = "71",
number = "7–9",
pages = "1159 - 1171",
year = "2008",
note = "Progress in Modeling, Theory, and Application of Computational Intelligenc15th European Symposium on Artificial Neural Networks 200715th European Symposium on Artificial Neural Networks 2007 ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2007.12.020",
url = "http://www.sciencedirect.com/science/article/pii/S0925231208000519",
author = "Benjamin Schrauwen and Marion Wardermann and David Verstraeten and Jochen J. Steil and Dirk Stroobandt",
keywords = "Reservoir computing",
keywords = "Intrinsic plasticity",
keywords = "Information maximization ",
abstract = "The benefits of using intrinsic plasticity (IP), an unsupervised, local, biologically inspired adaptation rule that tunes the probability density of a neuron's output towards an exponential distribution—thereby realizing an information maximization—have already been demonstrated. In this work, we extend the ideas of this adaptation method to a more commonly used non-linearity and a Gaussian output distribution. After deriving the learning rules, we show the effects of the bounded output of the transfer function on the moments of the actual output distribution. This allows us to show that the rule converges to the expected distributions, even in random recurrent networks. The \{IP\} rule is evaluated in a reservoir computing setting, which is a temporal processing technique which uses random, untrained recurrent networks as excitable media, where the network's state is fed to a linear regressor used to calculate the desired output. We present an experimental comparison of the different \{IP\} rules on three benchmark tasks with different characteristics. Furthermore, we show that this unsupervised reservoir adaptation is able to adapt networks with very constrained topologies, such as a 1D lattice which generally shows quite unsuitable dynamic behavior, to a reservoir that can be used to solve complex tasks. We clearly demonstrate that \{IP\} is able to make reservoir computing more robust: the internal dynamics can autonomously tune themselves—irrespective of initial weights or input scaling—to the dynamic regime which is optimal for a given task. "
}
@article{Eizicovits20141208,
title = "Efficient sensory-grounded grasp pose quality mapping for gripper design and online grasp planning ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "8",
pages = "1208 - 1219",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000554",
author = "Danny Eizicovits and Sigal Berman",
keywords = "Robotic manipulators",
keywords = "Grasping",
keywords = "Graspability map ",
abstract = "Abstract The gentle grasping and manipulation of objects in dense un-structured environments, such as the agricultural, food processing, or home environments constitute a formidable challenge for robotic systems. Knowledge regarding wrist poses (wrist positions and orientations) that may lead to successful grasps is especially important in such environments for both gripper design and online grasp planning. Graspability maps store grasp quality grades at different wrist poses in object-centered coordinates. Previously graspability maps were derived based on object models in a lengthy, offline process and thus had limited usability. We have developed geometry-based grasp quality measures related to classical grasp quality measures, which can be determined directly from a 3D point cloud. This facilitates embedding agent perception capabilities within the grasp quality determination. Additionally by scanning the object’s surface for finger contact points rather than scanning the volume of the bounding box about the object, and by using parallel computation, graspability map computation-time is considerably reduced, facilitating online computation of multiple measures. We validate the developed measures in a physical environment, show that computation-time can be reduced by more than 90% with very low reduction in map quality, and show the applicability of the developed methods for both simple and complex objects. "
}
@article{Nahangi201536,
title = "Automated assembly discrepancy feedback using 3D imaging and forward kinematics ",
journal = "Automation in Construction ",
volume = "56",
number = "",
pages = "36 - 46",
year = "2015",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2015.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0926580515000837",
author = "Mohammad Nahangi and Jamie Yeung and Carl T. Haas and Scott Walbridge and Jeffrey West",
keywords = "Realignment feedback",
keywords = "Fabrication error",
keywords = "Deviation analysis",
keywords = "Refit and plumbness",
keywords = "Robotic forward kinematics",
keywords = "3D imaging",
keywords = "Laser scanning",
keywords = "Pipelines",
keywords = "Pipe spools ",
abstract = "Abstract Assembly of steel structures, modules, and pipe spools requires cycles of fitting and alignment in fabrication facilities and on construction sites. To minimize this work, good discrepancy feedback for automated refitting and realignment is required. A framework for such feedback is presented here that overcomes current limitations. It commences with a constrained registration step to overcome the incapabilities of the current discrepancy analysis approaches. By borrowing concepts from robotic kinematics and 3D image alignment theories, forward kinematics models are generated link by link, and thus provide the means for a local discrepancy analysis for quantifying the deviations autonomously. Experiments show that the proposed approach is suitably accurate and sufficiently fast to be employed for real-time feedback in order to systematically and automatically develop the realignment plans required for refitting and realigning assemblies, which is the key contribution of the work presented in this paper. "
}
@article{Brad2015498,
title = "Employing Smart Units and Servitization towards Reconfigurability of Manufacturing Processes ",
journal = "Procedia \{CIRP\} ",
volume = "30",
number = "",
pages = "498 - 503",
year = "2015",
note = "7th Industrial Product-Service Systems Conference - PSS, industry transformation for sustainability and business ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.02.154",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115004679",
author = "Stelian Brad and Mircea Murar",
keywords = "sevicization",
keywords = "reconfigurability",
keywords = "smart units",
keywords = "robotic systems",
keywords = "embedded systems ",
abstract = "Abstract Increasing environmental concerns together with the need for sustainable consumption and production gave birth to the concept of product service-system. This paperwork presents how the concept of product-service systems (PSS), also known as servitization, can increase performance within the value creation chain in the manufacturing environment by deployingits key features within smart manufacturing units to provide them withreconfigurabilityproperties. Highlights on how thekey feature of a product-service system can be used to enable the deployment of reconfigurability within smart manufacturing units towards achieving the concept of reconfigurable manufacturing systems are revealed in the first part of the paper.Considering the new economic models, the ever changing society needs and the effects of disruptive innovations, a business model for manufacturing environmentis further proposed. The business model deploys small scale reconfigurable manufacturing systems by means of smart manufacturing units, intelligent information management platforms, cloud computing services and Internet of Things. An experimental test bench is afterwards presentedin this context. Three similar manufacturing scenarios are considered and reproduced viaa mix ofsix smart manufacturing units and interfaces. The goal of these scenarios isto test the feasibility of servitization towards achieving reconfigurability of smart units.Several industrial equipment among which a dual-arm industrial robot, two electro-mechanical grippers, two electro-mechanical axes and two proximity sensors areintegrated with the embedded system to enable the deployment of \{PSS\} features. Also, how servitization is deployed within available smart units, their generic architecture and how they are interconnected is presented in the paper,together with advantages and constraints of the proposed experimental approach. The paper ends with conclusions, remarks regarding the experimental tests and further research directions. "
}
@article{Staranowicz2015102,
title = "Practical and accurate calibration of RGB-D cameras using spheres ",
journal = "Computer Vision and Image Understanding ",
volume = "137",
number = "",
pages = "102 - 114",
year = "2015",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215000703",
author = "Aaron N. Staranowicz and Garrett R. Brown and Fabio Morbidi and Gian-Luca Mariottini",
keywords = "RGB-D cameras",
keywords = "Camera calibration",
keywords = "Robotic vision ",
abstract = "Abstract RGB-Depth (or RGB-D) cameras are increasingly being adopted in robotic and vision applications, including mobile robot localization and mapping, gesture recognition, and at-home healthcare monitoring. As with any other sensor, calibrating RGB-D cameras is needed to increase their sensing accuracy, especially since the manufacturer’s calibration parameters might change between models. In this paper, we present a novel RGB-D camera-calibration algorithm for the estimation of the full set of intrinsic and extrinsic parameters. Our method is easy to use, can be utilized with any arrangement of \{RGB\} and depth sensors, and only requires that a spherical object (e.g., a basketball) is moved in front of the camera for a few seconds. Our image-processing pipeline automatically and robustly detects the moving calibration object while rejecting noise and outliers in the image data. Our calibration method uses all the frames of the detected sphere and leverages novel analytical results on the multi-view projection of spheres to accurately estimate all the calibration parameters. Extensive numerical simulations and real-world experiments have been conducted to validate our algorithm and compare its performance with that of other state-of-the-art calibration methods. An RGB-D Calibration Toolbox for \{MATLAB\} is also made freely available for the scientific community. "
}
@article{Paul20151,
title = "INVERITAS: A facility for hardware-in-the-loop long distance movement simulation for rendezvous and capture of satellites and other autonomous objects ",
journal = "Acta Astronautica ",
volume = "116",
number = "",
pages = "1 - 24",
year = "2015",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2015.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515002374",
author = "J. Paul and A. Dettmann and B. Girault and J. Hilljegerdes and F. Kirchner and I. Ahrns and J. Sommer",
keywords = "Orbital servicing",
keywords = "Hardware-in-the-loop",
keywords = "Robotic manipulation",
keywords = "GNC",
keywords = "Pose estimation ",
abstract = "Abstract This paper describes the hardware-in-the-loop (HIL) long distance movement simulation system that was designed and built at the \{DFKI\} \{RIC\} for the \{INVERITAS\} project. It can simulate rendezvous and capture maneuvers between a Client satellite and a Servicer satellite in Earth orbit for scenarios where the semi-autonomous Servicer repairs, refuels, or re-orbits the Client which can otherwise become inoperable and eventually end up as space debris. The simulation system is a hardware-in-the-loop simulation system, meaning it incorporates real hardware like mock-ups of the Client and the Servicer, real sensors like stereocamera systems, a LIDAR, as well as sensor data processing hardware. Controlled by the simulation, the mock-ups are moved in reality so that the Servicer׳s sensors perceive the Client like in the real situation. One of the main tasks in the development of the simulator was the reduction of the twelve unconstrained degrees of freedom of two free-floating objects to ten constrained degrees of freedom of the \{INVERITAS\} movement hardware. A number of behaviors of the control system described in this paper enable it to use the given workspace efficiently to fit trajectories of the two satellites into it. The system reaches an accuracy of a few centimeters that is sufficient to test sensor data processing and navigation algorithms of the Servicer in closed-loop, meaning that the autonomous decisions of the Servicer can be based on the real sensor input. We also present methods and \{HIL\} test results concerning the sensors, sensory data processing and \{GNC\} (guidance, navigation and control) software of the functional Servicer mock-up that was developed in the \{INVERITAS\} project. Finally, the paper includes future plans of how the \{HIL\} simulator can be improved in accuracy and flexibility. "
}
@article{Friedewald2005221,
title = "Perspectives of ambient intelligence in the home environment ",
journal = "Telematics and Informatics ",
volume = "22",
number = "3",
pages = "221 - 238",
year = "2005",
note = "",
issn = "0736-5853",
doi = "https://doi.org/10.1016/j.tele.2004.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736585304000590",
author = "Michael Friedewald and Olivier Da Costa and Yves Punie and Petteri Alahuhta and Sirkka Heinonen",
keywords = "Ambient intelligence",
keywords = "Ubiquitous computing",
keywords = "Smart home",
keywords = "House automation",
keywords = "Information society ",
abstract = "Ambient Intelligence is a vision of the future information society stemming from the convergence of ubiquitous computing, ubiquitous communication and intelligent user-friendly interfaces. It offers an opportunity to realise an old dream, i.e. the smart or intelligent home. Will it fulfil the promises or is it just an illusion—offering apparently easy living while actually increasing the complexity of life? This article touches upon this question by discussing the technologies, applications and social implications of ambient intelligence in the home environment. It explores how Ambient Intelligence may change our way of life. It concludes that there are great opportunities for Ambient Intelligence to support social developments and modern lifestyles. However, in order to gain wide acceptance a delicate balance is needed: the technology should enhance the quality of life but not be seeking domination. It should be reliable and controllable but nevertheless adaptive to human habits and changing contexts. "
}
@article{Ridao2015227,
title = "Intervention AUVs: The next challenge ",
journal = "Annual Reviews in Control ",
volume = "40",
number = "",
pages = "227 - 241",
year = "2015",
note = "",
issn = "1367-5788",
doi = "https://doi.org/10.1016/j.arcontrol.2015.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S1367578815000541",
author = "Pere Ridao and Marc Carreras and David Ribas and Pedro J. Sanz and Gabriel Oliver",
keywords = "Autonomous Vehicles",
keywords = "Robotic Manipulators",
keywords = "Marine Systems ",
abstract = "Abstract While commercially available \{AUVs\} are routinely used in survey missions, a new set of applications exist which clearly demand intervention capabilities. The maintenance of permanent underwater observatories, submerged oil wells, cabled sensor networks, pipes and the deployment and recovery of benthic stations are a few of them. These tasks are addressed nowadays using manned submersibles or work-class ROVs, equipped with teleoperated arms under human supervision. Although researchers have recently opened the door to future I-AUVs, a long path is still necessary to achieve autonomous underwater interventions. This paper reviews the evolution timeline in autonomous underwater intervention systems. Milestone projects in the state of the art are reviewed, highlighting their principal contributions to the field. To the best of the authors’ knowledge, only three vehicles have demonstrated some autonomous intervention capabilities so far: ALIVE, \{SAUVIM\} and \{GIRONA\} 500, being the last one the lightest one. In this paper \{GIRONA\} 500 I-AUV is presented and its software architecture discussed. Recent results in different scenarios are reported: (1) valve turning and connector plugging/unplugging while docked to a subsea panel, (2) free floating valve turning using learning by demonstration, and (3) multipurpose free-floating object recovery. The paper ends discussing the lessons learned so far. "
}
@article{Ridao201412146,
title = "Intervention AUVs: The Next Challenge ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "12146 - 12159",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02819",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016435494",
author = "Pere Ridao and Marc Carreras and David Ribas and Pedro J. Sanz and Gabriel Oliver",
keywords = "Autonomous Vehicles",
keywords = "Robotic Manipulators",
keywords = "Marine Systems ",
abstract = "Abstract While commercially available \{AUVs\} are routinely used in survey missions, a new set of applications exists which clearly demand intervention capabilities. The maintenance of: permanent observatories underwater; submerged oil wells; cabled sensor networks; pipes; and the deployment and recovery of benthic stations are but a few of them. These tasks are addressed nowadays using manned submersibles or work-class ROVs, equipped with teleoperated arms under human supervision. Although researchers have recently opened the door to future I-AUVs, a long path is still necessary to pave the way to underwater intervention applications performed in an autonomous way. This paper reviews the evolution timeline in autonomous underwater intervention systems. Milestone projects in the state of the art are reviewed, highlighting their principal contributions to the field. To the best of the authors knowledge only three vehicles have demonstrated some autonomous intervention capabilities so far: ALIVE, \{SAUVIM\} and \{GIRONA\} 500 I-AUV. Next, \{GIRONA\} 500 I-AUV is presented and its software architecture discussed. Recent results in different scenarios are reported: 1) Valve turning and connector plugging/unplugging while docked to a sub-sea panel, 2) Free floating valve turning using learning by demonstration, and 3) Free floating multipurpose multisensory based object recovery. The paper ends discussing the lessons learned so far and presenting the authors view of the future. "
}
@article{Touvet2012473,
title = "A biomimetic reach and grasp approach for mechanical hands ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "473 - 486",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001497",
author = "F. Touvet and N. Daoud and J.-P. Gazeau and S. Zeghloul and M.A. Maier and S. Eskiizmirliler",
keywords = "Reach",
keywords = "Grasp",
keywords = "Movement kinematics",
keywords = "LWPR",
keywords = "Robotic hand",
keywords = "Matching Units ",
abstract = "Reach and grasp are the two key functions of human prehension. The Central Nervous System controls these two functions in a separate but interdependent way. The choice between different solutions to reach and grasp an object–provided by multiple and redundant degrees of freedom (dof)–depends both on the properties and on the use (affordance) of the object to be manipulated. This same control paradigm, i.e. subdivision of prehension into reach and grasp as well as the corresponding multimodal (sensory/motor) information fusion schemes, can also be applied to a mechanical hand carried by a robotic arm. The robotic arm will then be responsible for positioning the hand with respect to the object, and the hand will then grasp and manipulate the object. In this article, we present a biomimetic sensory–motor control scheme in the aim of providing an object-dependent and intelligent reach and grasp ability to such systems. The proposed model is based on a multi-network architecture which incorporates multiple Matching Units trained by a statistical learning algorithm (LWPR). Matching Units perform a multimodal signal integration by correlating sensory and motor information analogous to that observed in cerebral neuronal networks. The simulated network of multiple Matching Units provided estimations of object-dependent 5-finger grasp configurations with endpoint positional errors in the order of a few millimeters. For validation, these estimations were then applied to the control of movement kinematics on an experimental robot composed of a 6 dof robot arm carrying a 16 dof mechanical 4-finger hand. Precision of the kinematics control was such that successful reach, grasp and lift was obtained in all the tests. "
}
@article{AliAbbood2017,
title = "Voxelisation in the 3-D Fly Algorithm for \{PET\} ",
journal = "Swarm and Evolutionary Computation ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "2210-6502",
doi = "https://doi.org/10.1016/j.swevo.2017.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S2210650216300931",
author = "Zainab Ali Abbood and Julien Lavauzelle and Évelyne Lutton and Jean-Marie Rocchisani and Jean Louchet and Franck P. Vidal",
keywords = "Fly Algorithm",
keywords = "Evolutionary computation",
keywords = "Tomography",
keywords = "Reconstruction algorithms",
keywords = "Iterative algorithms",
keywords = "Inverse problems",
keywords = "Iterative reconstruction",
keywords = "Co-operative co-evolution ",
abstract = "Abstract The Fly Algorithm was initially developed for 3-D robot vision applications. It consists in solving the inverse problem of shape reconstruction from projections by evolving a population of 3-D points in space (the ‘flies’), using an evolutionary optimisation strategy. Here, in its version dedicated to tomographic reconstruction in medical imaging, the flies are mimicking radioactive photon sources. Evolution is controlled using a fitness function based on the discrepancy of the projections simulated by the flies with the actual pattern received by the sensors. The reconstructed radioactive concentration is derived from the population of flies, i.e. a collection of points in the 3-D Euclidean space, after convergence. ‘Good’ flies were previously binned into voxels. In this paper, we study which flies to include in the final solution and how this information can be sampled to provide more accurate datasets in a reduced computation time. We investigate the use of density fields, based on Metaballs and on Gaussian functions respectively, to obtain a realistic output. The spread of each Gaussian kernel is modulated in function of the corresponding fly fitness. The resulting volumes are compared with previous work in terms of normalised-cross correlation. In our test-cases, data fidelity increases by more than 10% when density fields are used instead of binning. Our method also provides reconstructions comparable to those obtained using well-established techniques used in medicine (filtered back-projection and ordered subset expectation-maximisation). "
}
@article{Cortés2012673,
title = "Cooperative detection of areas of rapid change in spatial fields ",
journal = "Automatica ",
volume = "48",
number = "4",
pages = "673 - 681",
year = "2012",
note = "",
issn = "0005-1098",
doi = "https://doi.org/10.1016/j.automatica.2012.01.014",
url = "http://www.sciencedirect.com/science/article/pii/S0005109812000295",
author = "Jorge Cortés",
keywords = "Robotic sensor networks",
keywords = "Hybrid systems",
keywords = "Distributed detection",
keywords = "Spatial fields",
keywords = "Wombling ",
abstract = "This paper proposes a distributed coordination algorithm for robotic sensor networks to detect boundaries that separate areas of rapid change of planar spatial phenomena. We consider an aggregate objective function, termed wombliness, to measure the change of the spatial field along the closed polygonal curve defined by the location of the sensors. We encode the network task as the optimization of the wombliness and characterize the smoothness properties of the objective function. In general, the complexity of the spatial phenomena may make the gradient flow cause self-intersections in the polygonal curve described by the network. We design the hybrid wombling algorithm that allows for network splitting and merging and guarantees local convergence to the critical configurations of the wombliness, while monotonically optimizing it. The technical approach combines ideas from statistical estimation, dynamical systems, and hybrid modeling and design. "
}
@article{Ishikawa2013259,
title = "An automated mineral classifier using Raman spectra ",
journal = "Computers & Geosciences ",
volume = "54",
number = "",
pages = "259 - 268",
year = "2013",
note = "",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2013.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S0098300413000253",
author = "Sascha T. Ishikawa and Virginia C. Gulick",
keywords = "Mineral classification",
keywords = "Raman spectroscopy",
keywords = "Machine learning",
keywords = "Mars",
keywords = "Robotic exploration",
keywords = "Igneous rocks ",
abstract = "We present a robust and autonomous mineral classifier for analyzing igneous rocks. Our study shows that machine learning methods, specifically artificial neural networks, can be trained using spectral data acquired by in situ Raman spectroscopy in order to accurately distinguish among key minerals for characterizing the composition of igneous rocks. These minerals include olivine, quartz, plagioclase, potassium feldspar, mica, and several pyroxenes. On average, our classifier performed with 83 percent accuracy. Quartz and olivine, as well as the pyroxenes, were classified with 100 percent accuracy. In addition to using traditional features such as the location of spectral bands and their shapes, our automated mineral classifier was able to incorporate fluorescence patterns, which are not as easily perceived by humans, into its classification scheme. The latter was able to improve the classification accuracy and is an example of the robustness of our classifier. "
}
@article{Cheng20111173,
title = "Performance evaluation of ultra wideband technology for construction resource location tracking in harsh environments ",
journal = "Automation in Construction ",
volume = "20",
number = "8",
pages = "1173 - 1184",
year = "2011",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000732",
author = "T. Cheng and M. Venugopal and J. Teizer and P.A. Vela",
keywords = "3D",
keywords = "Accuracy",
keywords = "Error analysis",
keywords = "Laser scanning",
keywords = "Location tracking",
keywords = "Ultra wideband",
keywords = "Robotic Total Station",
keywords = "RFID",
keywords = "Safety",
keywords = "Visualization ",
abstract = "Emerging wireless remote sensing technologies offer significant potential to advance the management of construction processes by providing real-time access to the locations of workers, materials, and equipment. Unfortunately, little is known regarding the accuracy, reliability, and practical benefits of an emerging technology, effectively impeding widespread adoption. This paper evaluates a commercially-available Ultra Wideband (UWB) system for real-time, mobile resource location tracking in harsh construction environments. A focus of this paper is to measure the performance of the \{UWB\} technology for tracking mobile resources in real-world construction settings. To assess tracking accuracy, location error rates for select \{UWB\} track signals are obtained by automatically tracking a single entity using a Robotic Total Station (RTS) for ground truth. Furthermore, to demonstrate the benefits of \{UWB\} technology, the paper provides case studies of resource tracking for analysis of worksite operations. The work demonstrates the applicability of \{UWB\} for the design of construction management support tools. "
}
@article{Niola2010543,
title = "A new real-time shape acquisition with a laser scanner: first test results ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "26",
number = "6",
pages = "543 - 550",
year = "2010",
note = "19th International Conference on Flexible Automation and Intelligent ManufacturingLean manufacturing and Services ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.06.026",
url = "http://www.sciencedirect.com/science/article/pii/S0736584510000773",
author = "Vincenzo Niola and Cesare Rossi and Sergio Savino",
keywords = "Shape acquisition",
keywords = "Laser scanner",
keywords = "Robotic application ",
abstract = "The first results of a new method for real-time shape acquisition with a laser scanner are presented. The new method is essentially based on the use of a laser beam and a web-cam. A digital filter parameters identification was studied for the laser line detection in the image. After this, a model for the reconstruction in real-time of the laser line in the space was developed. The first test rig was just conceived to validate the method; hence, no high resolution cameras were adopted. Nevertheless, the tests have showed encouraging results. Tests were made on both plane and non-plane surfaces. First of all, it was confirmed that it is possible to calibrate the intrinsic parameters of the video system, the position of the image plane and the laser plane in a given frame, all in the same time. Moreover the surface shapes were recognized and recorded with an appreciable accuracy. The tests also showed that the proposed method can be used for robotic applications, such as robotic kinematic calibration and 3D surfaces recognition and recording. For this last purpose, the test rig is fitted on a robot arm that permits to the scanner device to ‘observe’ the 3D object from different and known positions. "
}
@article{Neves2011399,
title = "An efficient omnidirectional vision system for soccer robots: From calibration to object detection ",
journal = "Mechatronics ",
volume = "21",
number = "2",
pages = "399 - 410",
year = "2011",
note = "Special Issue on Advances in intelligent robot design for the Robocup Middle Size League ",
issn = "0957-4158",
doi = "https://doi.org/10.1016/j.mechatronics.2010.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0957415810000863",
author = "António J.R. Neves and Armando J. Pinho and Daniel A. Martins and Bernardo Cunha",
keywords = "Robotic vision",
keywords = "Omnidirectional vision systems",
keywords = "Color-based object detection",
keywords = "Shape-based object detection",
keywords = "Vision system calibration ",
abstract = "Robotic soccer is nowadays a popular research domain in the area of multi-robot systems. In the context of RoboCup, the Middle Size League is one of the most challenging. This paper presents an efficient omnidirectional vision system for real-time object detection, developed for the robotic soccer team of the University of Aveiro, CAMBADA. The vision system is used to find the ball and white lines, which are used for self-localization, as well as to find the presence of obstacles. Algorithms for detecting these objects and also for calibrating most of the parameters of the vision system are presented in this paper. We also propose an efficient approach for detecting arbitrary \{FIFA\} balls, which is an important topic of research in the Middle Size League. The experimental results that we present show the effectiveness of our algorithms, both in terms of accuracy and processing time, as well as the results that the team has been achieving: 1st place in RoboCup 2008, 3rd place in 2009 and 1st place in the mandatory technical challenge in RoboCup 2009, where the robots have to play with an arbitrary standard \{FIFA\} ball. "
}
@article{Bohg2012779,
title = "Task-based Grasp Adaptation on a Humanoid Robot ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "779 - 786",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00174",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016337041",
author = "Jeannette Bohg and Kai Welke and Beatriz León and Martin Do and Dan Song and Walter Wohlkinger and Marianna Madry and Aitor Aldóma and Markus Przybylski and Tamim Asfour and Higinio Martí and Danica Kragic and Antonio Morales and Markus Vincze",
keywords = "Robotic Grasping and Manipulation",
keywords = "Task-based Grasp Synthesis",
keywords = "Visual Servoing",
keywords = "Attention",
keywords = "Segmentation",
keywords = "Object categorization",
keywords = "System Integration ",
abstract = "Abstract In this paper, we present an approach towards autonomous grasping of objects according to their category and a given task. Recent advances in the field of object segmentation and categorization as well as task-based grasp inference have been leveraged by integrating them into one pipeline. This allows us to transfer task-specific grasp experience between objects of the same category. The effectiveness of the approach is demonstrated on the humanoid robot ARMAR-IIIa. "
}
@article{LaasBourez20091270,
title = "A new algorithm for optical observations of space debris with the \{TAROT\} telescopes ",
journal = "Advances in Space Research ",
volume = "44",
number = "11",
pages = "1270 - 1278",
year = "2009",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2009.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0273117709003895",
author = "Myrtille Laas-Bourez and Gwendoline Blanchet and Michel Boër and Etienne Ducrotté and Alain Klotz",
keywords = "Space debris",
keywords = "Image processing",
keywords = "Robotic telescopes",
keywords = "Mathematical morphology ",
abstract = "Since 2004, we observe satellites in the geostationary orbit with a network of robotic ground based fully automated telescopes called TAROT. One of them is located in France and the second at ESO, La Silla, Chile. The system processes the data in real time. Its wide field of view is useful for the discovery, the systematic survey and for the tracking of both catalogued and un-catalogued objects. We present a new source extraction algorithm based on morphological mathematic, which has been tested and is currently under implementation in the standard pipeline. Using this method, the observation strategy will correlate the measurements of the same object on successive images and give better detection rate and false alarm rate than the previous one. The overall efficiency and quality of the survey of the geostationary orbit has drastically improved and we can now detect satellites and debris in different orbits like Geostationary Transfer Orbit (GTO). Results obtained in real conditions with \{TAROT\} are presented. "
}
@article{Herman2009344,
title = "Development and First In Vivo Trial of EvoLap, an Active Laparoscope Positioner ",
journal = "Journal of Minimally Invasive Gynecology ",
volume = "16",
number = "3",
pages = "344 - 349",
year = "2009",
note = "",
issn = "1553-4650",
doi = "https://doi.org/10.1016/j.jmig.2009.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S1553465009001204",
author = "Benoît Herman and Khanh Tran Duy and Bruno Dehez and Roland Polet and Benoit Raucent and Etienne Dombre and Jacques Donnez",
keywords = "Compact laparoscope manipulator",
keywords = "Ergonomic control interface",
keywords = "Robotic assistant ",
abstract = "To determine essential specifications for an active endoscope holder, a survey of laparoscopic procedures was conducted. A review of the literature highlighted the advantages and limitations of existing scope-holding systems. From this analysis, basic requirements were listed for such devices. Pursuant to this, an ergonomic and user-friendly laparoscope manipulator was designed to assist the surgeon. A first in vivo procedure demonstrated feasibility of the device and its value in clinical practice, enabling surgeons to work more comfortably. "
}
@article{Savva2016120,
title = "Geometry-based vs. intensity-based medical image registration: A comparative study on 3D \{CT\} data ",
journal = "Computers in Biology and Medicine ",
volume = "69",
number = "",
pages = "120 - 133",
year = "2016",
note = "",
issn = "0010-4825",
doi = "https://doi.org/10.1016/j.compbiomed.2015.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0010482515004060",
author = "Antonis D. Savva and Theodore L. Economopoulos and George K. Matsopoulos",
keywords = "Image registration",
keywords = "Geometry-based registration",
keywords = "Geometrical descriptors",
keywords = "Computed Tomography ",
abstract = "Abstract Spatial alignment of Computed Tomography (CT) data sets is often required in numerous medical applications and it is usually achieved by applying conventional exhaustive registration techniques, which are mainly based on the intensity of the subject data sets. Those techniques consider the full range of data points composing the data, thus negatively affecting the required processing time. Alternatively, alignment can be performed using the correspondence of extracted data points from both sets. Moreover, various geometrical characteristics of those data points can be used, instead of their chromatic properties, for uniquely characterizing each point, by forming a specific geometrical descriptor. This paper presents a comparative study reviewing variations of geometry-based, descriptor-oriented registration techniques, as well as conventional, exhaustive, intensity-based methods for aligning three-dimensional (3D) \{CT\} data pairs. In this context, three general image registration frameworks were examined: a geometry-based methodology featuring three distinct geometrical descriptors, an intensity-based methodology using three different similarity metrics, as well as the commonly used Iterative Closest Point algorithm. All techniques were applied on a total of thirty 3D \{CT\} data pairs with both known and unknown initial spatial differences. After an extensive qualitative and quantitative assessment, it was concluded that the proposed geometry-based registration framework performed similarly to the examined exhaustive registration techniques. In addition, geometry-based methods dramatically improved processing time over conventional exhaustive registration. "
}
@article{Mamei2006443,
title = "Case studies for self-organization in computer science ",
journal = "Journal of Systems Architecture ",
volume = "52",
number = "8–9",
pages = "443 - 460",
year = "2006",
note = "Nature-Inspired Applications and Systems ",
issn = "1383-7621",
doi = "https://doi.org/10.1016/j.sysarc.2006.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S1383762106000166",
author = "Marco Mamei and Ronaldo Menezes and Robert Tolksdorf and Franco Zambonelli",
keywords = "Self-organization metaphors",
keywords = "Middleware",
keywords = "Information systems and management",
keywords = "Security",
keywords = "Robotic system",
keywords = "Networks ",
abstract = "Self-organization is bound to greatly affect computer science. The simplicity and yet power of self-organized models will allow researchers to propose efficient solutions to problems never before thought possible to be addressed efficiently. The published works in the field clearly demonstrate the potential of this approach. This paper first reviews a number of interesting self-organization phenomena found in nature, then it discusses their potential applicability in several computer science application scenarios. "
}
@article{Tagliaferri20042739,
title = "REM/ROSS: a powerful tool for monitoring the prompt afterglow of γ-ray bursts ",
journal = "Advances in Space Research ",
volume = "34",
number = "12",
pages = "2739 - 2743",
year = "2004",
note = "New X-Ray Results, the Next Generation of X-Ray Observatories and Gamma Ray Burst Afterglow Physics ",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2003.03.072",
url = "http://www.sciencedirect.com/science/article/pii/S0273117704006349",
author = "G. Tagliaferri and F.M. Zerbi and G. Chincarini and G. Ghisellini and M. Rodonò and E. Palazzi and L.A. Antonelli and P. Conconi and S. Covino and G. Cutispoto and E. Molinari and L. Nicastro and G. Tosti",
keywords = "γ-ray bursts afterglow",
keywords = "Robotic telescopes",
keywords = "IR astronomy ",
abstract = "Observations of the prompt afterglow of γ-ray burst events are unanimously considered of paramount importance for \{GRB\} science and cosmology. Such observations at \{NIR\} wavelengths are even more promising allowing the monitoring of high-z Ly-α absorbed bursts as well as events occurring in dusty star-forming regions. In these pages we present rapid eye mount (REM), a fully robotized fast slewing telescope equipped with a high throughput \{NIR\} (Z, J, H, K) camera dedicated to detecting the prompt \{IR\} afterglow. \{REM\} can discover objects at extremely high redshift and trigger large telescopes to observe them. The \{REM\} telescope will simultaneously feed \{REM\} optical slitless spectrograph (ROSS) via a dichroic. \{ROSS\} will intensively monitor the prompt optical continuum of \{GRB\} afterglows. The synergy between the REM-IR camera and the \{ROSS\} spectrograph makes \{REM\} a powerful observing tool for any kind of fast transient phenomena. Beside its ambitious scientific goals, \{REM\} is also technically challenging since it represent the first attempt to locate a \{NIR\} camera on a small telescope providing, with ROSS, unprecedented simultaneous wavelength coverage on a telescope of this size. "
}
@article{Li2014116,
title = "Contrast agents for preclinical targeted X-ray imaging ",
journal = "Advanced Drug Delivery Reviews ",
volume = "76",
number = "",
pages = "116 - 133",
year = "2014",
note = "Targeted imaging ",
issn = "0169-409X",
doi = "https://doi.org/10.1016/j.addr.2014.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0169409X14001549",
author = "Xiang Li and Nicolas Anton and Guy Zuber and Thierry Vandamme",
keywords = "Computed tomography",
keywords = "Micro-CT",
keywords = "X-ray imaging",
keywords = "Contrast agent",
keywords = "Targeting",
keywords = "EPR ",
abstract = "Abstract Micro-computed tomography (micro-CT) is an X-ray based instrument that it is specifically designed for biomedical research at a preclinical stage for live imaging of small animals. This imaging modality is cost-effective, fast, and produces remarkable high-resolution images of X-ray opaque skeleton. Administration of biocompatible X-ray opaque contrast agent allows delineation of the blood vessels, and internal organs and even detection of tumor metastases as small as 300 μm. However, the main limitation of micro-CT lies in the poor efficacy or toxicity of the contrast agents. Moreover, contrast agents for micro-CT have to be stealth nanoparticulate systems, i.e. preventing their rapid renal clearance. The chemical composition and physicochemical properties will condition their uptake and elimination pathways, and therefore all the biological fluids, organs, and tissues trough this elimination route of the nanoparticles will be contrasted. Furthermore, several technologies playing on the nanoparticle properties, aim to influence these biological pathways in order to induce their accumulation onto given targeted sites, organs of tumors. In function of the methodologies carried out, taking benefit or not of the action of immune system, of the natural response of the organism like hepatocyte uptake or enhanced permeation and retention effect, or even accumulation due to ligand/receptor interactions, the technologies are called passive or active targeted imaging. The present review presents the most recent advances in the development of specific contrast agents for targeted X-ray imaging micro-CT, discussing the recent advance of in vivo targeting of nanoparticulate contrast agents, and the influence of the formulations, nature of the nanocarrier, nature and concentration of the X-ray contrasting materials, effect of the surface properties, functionalization and bioconjugation. The pharmacokinetic and versatility of nanometric systems appear particularly advantageous for addressing the versatile biomedical research needs. State of the art investigations are on going to propose contrast agents with tumor accumulating properties and will contribute for development of safer cancer medicine having detection and therapeutic modalities. "
}
@article{Wiemann2016218,
title = "Optimizing Triangle Mesh Reconstructions of Planar Environments ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "218 - 223",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.735",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316310114",
author = "Thomas Wiemann and Kai Lingemann and Joachim Hertzberg",
keywords = "3D Mapping",
keywords = "Surface Reconstruction",
keywords = "Mesh Optimization",
keywords = "Segmentation ",
abstract = "Abstract Automatic surface reconstruction from point cloud data is an active field of research in robotics, as polygonal representations are compact and geometrically precise. Standard meshing algorithms produce many redundant triangles. Therefore methods for optimization are required. In this paper we present and evaluate a mesh optimization algorithm for robotic applications that was specially designed to exploit the planar structure of typical indoor environments. "
}
@article{Litany2017284,
title = "ASIST: Automatic semantically invariant scene transformation ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "284 - 299",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216301102",
author = "Or Litany and Tal Remez and Daniel Freedman and Lior Shapira and Alex Bronstein and Ran Gal",
keywords = "Semantic segmentation",
keywords = "Object recognition",
keywords = "Random forest",
keywords = "Iterative closest point",
keywords = "Alternating minimization",
keywords = "Pose estimation",
keywords = "Registration ",
abstract = "Abstract We present ASIST, a technique for transforming point clouds by replacing objects with their semantically equivalent counterparts. Transformations of this kind have applications in virtual reality, repair of fused scans, and robotics. \{ASIST\} is based on a unified formulation of semantic labeling and object replacement; both result from minimizing a single objective. We present numerical tools for the efficient solution of this optimization problem. The method is experimentally assessed on new datasets of both synthetic and real point clouds, and is additionally compared to two recent works on object replacement on data from the corresponding papers. "
}
@article{Marceglia20091027,
title = "Modulation of beta oscillations in the subthalamic area during action observation in Parkinson's disease ",
journal = "Neuroscience ",
volume = "161",
number = "4",
pages = "1027 - 1036",
year = "2009",
note = "",
issn = "0306-4522",
doi = "https://doi.org/10.1016/j.neuroscience.2009.04.018",
url = "http://www.sciencedirect.com/science/article/pii/S0306452209006125",
author = "S. Marceglia and M. Fiorio and G. Foffani and S. Mrakic-Sposta and M. Tiriticco and M. Locatelli and E. Caputo and M. Tinazzi and A. Priori",
keywords = "local field potentials",
keywords = "action observation",
keywords = "basal ganglia",
keywords = "action understanding",
keywords = "Parkinson's disease ",
abstract = "Mapping observed actions into the onlooker's motor system seems to provide the neurofunctional mechanisms for action understanding. Subthalamic nucleus (STN) local field potential (LFP) recordings in patients with movement disorders disclosed that network oscillations in the beta range are involved in conveying motor and non-motor information across the cortico-basal ganglia–thalamo-cortical loop. This evidence, together with the existence of connections between the \{STN\} and cortical areas active during observation of actions performed by other people, suggests that the \{STN\} oscillatory activity in specific frequency bands could encode not only motor information, but also information related to action observation. To test this hypothesis we directly recorded \{STN\} oscillations through electrodes for deep brain stimulation in patients with Parkinson's disease during observation of actions and of static objects. We found selective action-related oscillatory modulations in two functionally distinct beta bands: whereas low-beta oscillations (10–18 Hz) selectively desynchronized only during action-observation, high-beta oscillations (20–30 Hz) synchronized both during the observation of action and action-related objects. Low-beta modulations are therefore specific to action observation and high-beta modulations are related to the action scene. Our findings show that in the basal ganglia there are functional changes spreading to the action environment, probably presetting the motor system in relation to the motor context and suggesting that the dynamics of beta oscillations can contribute to action understanding mechanisms. "
}
@article{Fanello2017151,
title = "Visual recognition for humanoid robots ",
journal = "Robotics and Autonomous Systems ",
volume = "91",
number = "",
pages = "151 - 168",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015301810",
author = "Sean Ryan Fanello and Carlo Ciliberto and Nicoletta Noceti and Giorgio Metta and Francesca Odone",
keywords = "Human–Robot Interaction",
keywords = "Learning and interaction",
keywords = "Visual recognition",
keywords = "Sparse representations",
keywords = "iCub ",
abstract = "Abstract Visual perception is a fundamental component for most robotics systems operating in human environments. Specifically, visual recognition is a prerequisite to a large variety of tasks such as tracking, manipulation, human–robot interaction. As a consequence, the lack of successful recognition often becomes a bottleneck for the application of robotics system to real-world situations. In this paper we aim at improving the robot visual perception capabilities in a natural, human-like fashion, with a very limited amount of constraints to the acquisition scenario. In particular our goal is to build and analyze a learning system that can rapidly be re-trained in order to incorporate new evidence if available. To this purpose, we review the state-of-the-art coding–pooling pipelines for visual recognition and propose two modifications which allow us to improve the quality of the representation, while maintaining real-time performances: a coding scheme, Best Code Entries (BCE), and a new pooling operator, Mid-Level Classification Weights (MLCW). The former focuses entirely on sparsity and improves the stability and computational efficiency of the coding phase, the latter increases the discriminability of the visual representation, and therefore the overall recognition accuracy of the system, by exploiting data supervision. The proposed pipeline is assessed from a qualitative perspective on a Human–Robot Interaction (HRI) application on the iCub platform. Quantitative evaluation of the proposed system is performed both on in-house robotics data-sets (iCubWorld) and on established computer vision benchmarks (Caltech-256, \{PASCAL\} \{VOC\} 2007). As a byproduct of this work, we provide for the robotics community an implementation of the proposed visual recognition pipeline which can be used as perceptual layer for more complex robotics applications. "
}
@article{Seif2016159,
title = "Autonomous Driving in the iCity—HD Maps as a Key Challenge of the Automotive Industry ",
journal = "Engineering ",
volume = "2",
number = "2",
pages = "159 - 162",
year = "2016",
note = "",
issn = "2095-8099",
doi = "https://doi.org/10.1016/J.ENG.2016.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S2095809916309432",
author = "Heiko G. Seif and Xiaolong Hu",
keywords = "Autonomous driving",
keywords = "Traffic infrastructure",
keywords = "iCity",
keywords = "Car-to-X communication",
keywords = "Connected vehicle",
keywords = "HD maps ",
abstract = "\{ABSTRACT\} This article provides in-depth insights into the necessary technologies for automated driving in future cities. State of science is reflected from different perspectives such as in-car computing and data management, road side infrastructure, and cloud solutions. Especially the challenges for the application of \{HD\} maps as core technology for automated driving are depicted in this article. "
}
@article{Kopacek201267,
title = "Roboethics ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "10",
pages = "67 - 72",
year = "2012",
note = "14th \{IFAC\} Workshop on International Stability and Systems Engineering ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120611-3-IE-4029.00015",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015337137",
author = "P. Kopacek",
keywords = "Robots, Artificial Intelligence, Ethics, Social Aspects. ",
abstract = "Abstract Robotics is a very fast growing field especially in the last years. Begin of the 90's a new generation of mobile, intelligent, cooperative robots grows up. This new generation opens new applications areas like in the household, for medical and rehabilitation applications, in the entertainment industry as well as for leisure and hobby. Current developing trends are humanoid robots and robots supporting the human in everyday life. Other intensive research areas are cooperative robots, bio inspired robots, ubiquitous robots and cloud robots. Robotics is a new science as well as a branch or a field of application of Engineering. Some decades ago social aspects of robotics were discussed. Because of the results and the rapid development of this field ethical issues became more and more important. Therefore the term Roboethics was introduced in the literature. In this contribution a first overview from a practical viewpoint will be given. "
}
@article{Kasaei2016312,
title = "GOOD: A global orthographic object descriptor for 3D object recognition and manipulation ",
journal = "Pattern Recognition Letters ",
volume = "83, Part 3",
number = "",
pages = "312 - 320",
year = "2016",
note = "Efficient Shape Representation, Matching, Ranking, and its Applications ",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2016.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167865516301684",
author = "S. Hamidreza Kasaei and Ana Maria Tomé and Luís Seabra Lopes and Miguel Oliveira",
keywords = "3D object recognition",
keywords = "Object Perception",
keywords = "Orthographic projection ",
abstract = "Abstract Object representation is one of the most challenging tasks in robotics because it must provide reliable information in real-time to enable the robot to physically interact with the objects in its environment. To ensure robustness, a global object descriptor must be computed based on a unique and repeatable object reference frame. Moreover, the descriptor should contain enough information enabling to recognize the same or similar objects seen from different perspectives. This paper presents a new object descriptor named Global Orthographic Object Descriptor (GOOD) designed to be robust, descriptive and efficient to compute and use. We propose a novel sign disambiguation method, for computing a unique reference frame from the eigenvectors obtained through Principal Component Analysis of the point cloud of the target object view captured by a 3D sensor. Three principal orthographic projections and their distribution matrices are computed by exploiting the object reference frame. The descriptor is finally obtained by concatenating the distribution matrices in a sequence determined by entropy and variance features of the projections. Experimental results show that the overall classification performance obtained with \{GOOD\} is comparable to the best performances obtained with the state-of-the-art descriptors. Concerning memory and computation time, \{GOOD\} clearly outperforms the other descriptors. Therefore, \{GOOD\} is especially suited for real-time applications. The estimated object’s pose is precise enough for real-time object manipulation tasks. "
}
@article{Navarrete2016550,
title = "3DCOMET: 3D compression methods test dataset ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "550 - 557",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002237",
author = "Javier Navarrete and Vicente Morell and Miguel Cazorla and Diego Viejo and José García-Rodríguez and Sergio Orts-Escolano",
keywords = "3D data",
keywords = "Data compression",
keywords = "Dataset ",
abstract = "Abstract The use of 3D data in mobile robotics applications provides valuable information about the robot’s environment. However usually the huge amount of 3D information is difficult to manage due to the fact that the robot storage system and computing capabilities are insufficient. Therefore, a data compression method is necessary to store and process this information while preserving as much information as possible. A few methods have been proposed to compress 3D information. Nevertheless, there does not exist a consistent public benchmark for comparing the results (compression level, distance reconstructed error, etc.) obtained with different methods. In this paper, we propose a dataset composed of a set of 3D point clouds with different structure and texture variability to evaluate the results obtained from 3D data compression methods. We also provide useful tools for comparing compression methods, using as a baseline the results obtained by existing relevant compression methods. "
}
@article{Carnevale2016144,
title = "Will robots know us better than we know ourselves? ",
journal = "Robotics and Autonomous Systems ",
volume = "86",
number = "",
pages = "144 - 151",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.027",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305449",
author = "Antonio Carnevale",
keywords = "Robots",
keywords = "Privacy",
keywords = "Techno-regulation",
keywords = "Philosophy of technology",
keywords = "Critical culture of technology ",
abstract = "Abstract This paper aims to highlight some conceptual aspects on the impact of robotics on our concept of privacy. In those areas where robotics applications will invade the privacy of individuals as computers or mobile phones do today, the current idea of privacy will no longer suffice to ensure the right level of people’s protection. If we think to answer or stop the forthcoming controversies only relying on self-regulation of private parties, we will escape the real challenge: the next generation of robots does not affect solely persons and their individual rights, but the entire structure of society. This article assumes the robotics–privacy relationship as a clear illustration of how the technology–society nexus should be regulated in the future. We need approaches that are contextual–normativeand that should be politically addressed to the creation of a critical culture of technology. "
}
@article{Kopacek201411425,
title = "Ethical and social aspects of robots ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "11425 - 11430",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00857",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016434324",
author = "P. Kopacek",
keywords = "Robots",
keywords = "Ethics",
keywords = "Social Aspects",
keywords = "System “Human-Robot”",
keywords = "EoL of robots ",
abstract = "Abstract Robotics is a very fast growing field especially in the last years and is a discipline based on: mechanics, physics/mathematics, control engineering, electr(on)ics, computer science. Therefore robots are frequently used as examples for Mechatronic Systems. Robotics unifies two cultures: Science and humanities. The effort to design roboethics should make the unity of these two cultures a primary assumption. This means that experts shall view Robotics as a whole - in spite of the current early stage which recalls a melting pot. Some decades ago social aspects of robotics were discussed. Because of the results and the rapid development of this field ethical issues became more and more important. Therefore the term roboethics was introduced in the literature. The main goal of this contribution is to present and discuss this subject, probably at the first time, from the viewpoint of robotics. First an overview from a practical, robotics viewpoint will be given. Then a short presentation of currently and in the future available robots and some ideas about the ethical problems are discussed. Special emphasis is on the ethical behavior of the system “human-robot” and “End of Life – EoL” management. "
}
@incollection{Kangovi2017273,
title = "9 - Next Steps in Peering Carrier Ethernet Networks ",
editor = "Kangovi, Sachidananda ",
booktitle = "Peering Carrier Ethernet Networks ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "2017",
pages = "273 - 278",
isbn = "978-0-12-805319-5",
doi = "https://doi.org/10.1016/B978-0-12-805319-5.00009-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128053195000095",
author = "Sachidananda Kangovi",
keywords = "Automatic protection switching mechanism",
keywords = "Ethernet interconnect points (EIP)",
keywords = "Network function virtualization",
keywords = "Next steps in operations and business support systems (OSS/BSS)",
keywords = "Next steps in peering Carrier Ethernet networks (CENs)",
keywords = "Smart connected planet",
keywords = "Virtual reality ",
abstract = "Abstract We now have come to the last chapter of this book, journeying through the changing landscape beginning with the invention of telephone in 1876 to the present state of information and communication technology in 2016 where peering carrier Ethernet networks (CENs) are poised to play an important role in \{IP\} backhaul, mobile backhaul, streaming and switched video transport, site-to-site connectivity, and connections for cloud computing services to facilitate network connectivity for existing as well as emerging applications like cyber-physical systems, robotics, and virtual reality. In this journey, we have seen how Ethernet evolved as the most adopted protocol in layer 2, resulting in over 90% of \{LAN\} traffic around the globe on Ethernet today. Further enhancements in Ethernet led to Ethernet over \{DWDM\} at layer 1 which extended its reach beyond \{LAN\} to MAN, RAN, and WAN. In this journey, we also saw that to leverage benefits of Ethernet technology including higher bandwidth, low frame delay, low frame delay variation, and low frame loss probability as well as elimination of multiple protocol translations, MEF-defined and standardized carrier Ethernet services, making them reliable, scalable, and carrier grade resulting in CENs. The expansion of \{CENs\} has now necessitated peering of CENs. Demands of higher bandwidth and performance by emerging applications on data networks and the push by operators to lower Capex and Opex are propelling \{CENs\} and peering \{CENs\} right in the front and the center. In this chapter, we will examine some of the next steps needed in the Ethernet technology and peering \{CENs\} and also in operations and business support systems (OSS/BSS) to meet the growing demands because these provide important foundation for subscriber applications and are critical to the operations of the service providing and access providing operators. "
}
@incollection{Klančar2017207,
title = "Chapter 5 - Sensors Used in Mobile Systems ",
editor = "Klančar, Gregor and , and Zdešar, Andrej and , and Blažič, Sašo and ,  and Škrjanc, Igor ",
booktitle = "Wheeled Mobile Robotics ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2017",
pages = "207 - 288",
isbn = "978-0-12-804204-5",
doi = "https://doi.org/10.1016/B978-0-12-804204-5.00005-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128042045000056",
author = "Gregor Klančar and Andrej Zdešar and Sašo Blažič and Igor Škrjanc",
keywords = "Sensors",
keywords = "Pose estimation",
keywords = "Transformations",
keywords = "Dead reckoning",
keywords = "Active markers",
keywords = "Features ",
abstract = "Abstract Sensors are one of the key elements in mobile robotics. Together with other essential elements, they enable mobile robots to autonomously perform their actions, such as trajectory tracking, to locate and track targets, act safely by preventing collisions, and to localize and map the environment. Although they play a vital role they are also a limiting factor in mobile robotics because perfect, robust, and available sensors that would directly measure robot location are usually not available. Therefore, this chapter starts by introducing the different transformations that are later needed to relate local sensor-measured information to the information in robot coordinates. Then the main methods and sensors used to estimate robot pose are presented. They need to be a part of every robot localization system. The chapter ends with brief overview of sensors, their classifications, and main characteristics. "
}
@article{Christensen2017,
title = "Approximation and online algorithms for multidimensional bin packing: A survey ",
journal = "Computer Science Review ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1574-0137",
doi = "https://doi.org/10.1016/j.cosrev.2016.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S1574013716301356",
author = "Henrik I. Christensen and Arindam Khan and Sebastian Pokutta and Prasad Tetali",
keywords = "Approximation algorithms",
keywords = "Online algorithms",
keywords = "Multidimensional packing and covering",
keywords = "Bin packing",
keywords = "Multidimensional scheduling",
keywords = "Geometric packing ",
abstract = "Abstract The bin packing problem is a well-studied problem in combinatorial optimization. In the classical bin packing problem, we are given a list of real numbers in ( 0 , 1 ] and the goal is to place them in a minimum number of bins so that no bin holds numbers summing to more than 1. The problem is extremely important in practice and finds numerous applications in scheduling, routing and resource allocation problems. Theoretically the problem has rich connections with discrepancy theory, iterative methods, entropy rounding and has led to the development of several algorithmic techniques. In this survey we consider approximation and online algorithms for several classical generalizations of bin packing problem such as geometric bin packing, vector bin packing and various other related problems. There is also a vast literature on mathematical models and exact algorithms for bin packing. However, this survey does not address such exact algorithms. In two-dimensional geometric bin packing, we are given a collection of rectangular items to be packed into a minimum number of unit size square bins. This variant has a lot of applications in cutting stock, vehicle loading, pallet packing, memory allocation and several other logistics and robotics related problems. In d -dimensional vector bin packing, each item is a d -dimensional vector that needs to be packed into unit vector bins. This problem is of great significance in resource constrained scheduling and in recent virtual machine placement in cloud computing. We also consider several other generalizations of bin packing such as geometric knapsack, strip packing and other related problems such as vector scheduling, vector covering etc. We survey algorithms for these problems in offline and online setting, and also mention results for several important special cases. We briefly mention related techniques used in the design and analysis of these algorithms. In the end we conclude with a list of open problems. "
}
@article{Kim2015306,
title = "Adaptive buffer control for distributed autonomous robust routing in mobile surveillance robots ",
journal = "Computers & Electrical Engineering ",
volume = "43",
number = "",
pages = "306 - 316",
year = "2015",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2014.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S0045790614002602",
author = "Joongheon Kim and Song-Nam Hong",
keywords = "60 GHz",
keywords = "Wireless video streaming",
keywords = "Stochastic optimization",
keywords = "Buffer management",
keywords = "Distributed autonomous robust routing",
keywords = "Mobile surveillance robots ",
abstract = "Abstract This paper proposes a distributed and autonomous routing algorithm for distributed mobile surveillance robotics platforms using 60 \{GHz\} wireless technologies. According to the fact that 60 \{GHz\} wireless signals are too weak to survive in long-distance or non-line-of-sight situations due to high attenuation, advanced communication algorithms are required including beamforming, beam training, and multi-hop routing. For multi-hop robust distributed routing, each robotics platform computes the amounts of power allocation for transmitting packets from its own buffer. The amount of power allocation is determined by solving joint stochastic optimization of (i) the minimization of the summation of time average expected power consumption and (ii) the buffer stability in each unit time slot. The performance of the proposed algorithm is evaluated and it is observed that the proposed algorithm achieves desired performance. "
}
@article{Yang201545,
title = "Hierarchical extraction of urban objects from mobile laser scanning data ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "99",
number = "",
pages = "45 - 57",
year = "2015",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.10.005",
url = "http://www.sciencedirect.com/science/article/pii/S092427161400255X",
author = "Bisheng Yang and Zhen Dong and Gang Zhao and Wenxia Dai",
keywords = "Mobile laser scanning",
keywords = "Multi-scale supervoxel",
keywords = "Segmentation",
keywords = "Object extraction",
keywords = "Classification",
keywords = "Filtering ",
abstract = "Abstract Point clouds collected in urban scenes contain a huge number of points (e.g., billions), numerous objects with significant size variability, complex and incomplete structures, and variable point densities, raising great challenges for the automated extraction of urban objects in the field of photogrammetry, computer vision, and robotics. This paper addresses these challenges by proposing an automated method to extract urban objects robustly and efficiently. The proposed method generates multi-scale supervoxels from 3D point clouds using the point attributes (e.g., colors, intensities) and spatial distances between points, and then segments the supervoxels rather than individual points by combining graph based segmentation with multiple cues (e.g., principal direction, colors) of the supervoxels. The proposed method defines a set of rules for merging segments into meaningful units according to types of urban objects and forms the semantic knowledge of urban objects for the classification of objects. Finally, the proposed method extracts and classifies urban objects in a hierarchical order ranked by the saliency of the segments. Experiments show that the proposed method is efficient and robust for extracting buildings, streetlamps, trees, telegraph poles, traffic signs, cars, and enclosures from mobile laser scanning (MLS) point clouds, with an overall accuracy of 92.3%. "
}
@article{Yu201670,
title = "Scene parsing using graph matching on street-view data ",
journal = "Computer Vision and Image Understanding ",
volume = "145",
number = "",
pages = "70 - 80",
year = "2016",
note = "Light Field for Computer Vision ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216000175",
author = "Tianshu Yu and Ruisheng Wang",
keywords = "Scene parsing",
keywords = "Graph matching",
keywords = "Markov random field",
keywords = "Street view ",
abstract = "Abstract Scene parsing, using both images and range data, is one of the key problems in computer vision and robotics. In this paper, a street scene parsing scheme that takes advantages of images from perspective cameras and range data from LiDAR is presented. First, pre-processing on the image set is performed and the corresponding point cloud is segmented according to semantics and transformed into an image pose. A graph matching approach is introduced into our parsing framework, in order to identify similar sub-regions from training and test images in terms of both local appearance and spatial structure. By using the sub-graphs inherited from training images, as well as the cues obtained from point clouds, this approach can effectively interpret the street scene via a guided \{MRF\} inference. Experimental results show a promising performance of our approach. "
}
@incollection{Anwar2017531,
title = "Chapter Eight - Software Development and Application for the Analysis of Cross-Sections ",
editor = "Anwar, Naveed  and Najam, Fawad Ahmed ",
booktitle = "Structural Cross Sections ",
publisher = "Butterworth-Heinemann",
edition = "",
address = "",
year = "2017",
pages = "531 - 564",
isbn = "978-0-12-804443-8",
doi = "https://doi.org/10.1016/B978-0-12-804443-8.00008-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128044438000087",
author = "Naveed Anwar and Fawad Ahmed Najam",
keywords = "Software development",
keywords = "CSiCOL",
keywords = "mobile applications",
keywords = "computer software",
keywords = "CAD/CAE ",
abstract = "Abstract This chapter deals with computer-aided analysis of cross-sections. It provides an overview of various software applications available for cross-section design and analysis. A framework for the development of a general-purpose cross-section analysis software (based on theoretical formulations developed in Chapters 2 and 3) is presented. A brief introduction of \{CSiCOL\} (a comprehensive software package for the analysis and design of reinforced and composite column sections) is also included. This chapter also introduces various new ideas and scopes related to the development of mobile applications for structural analysis on both Android and iOS platforms. Various applications of cloud computing and component-based software engineering in analysis and design of structures are also introduced. "
}
@article{RomeroGonzález2017181,
title = "On robot indoor scene classification based on descriptor quality and efficiency ",
journal = "Expert Systems with Applications ",
volume = "79",
number = "",
pages = "181 - 193",
year = "2017",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.02.040",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417301318",
author = "Cristina Romero-González and Jesus Martínez-Gómez and Ismael García-Varea and Luis Rodríguez-Ruiz",
keywords = "Indoor scenes",
keywords = "Semantic classification",
keywords = "Multi-source classification",
keywords = "Descriptor combination",
keywords = "Spatial pyramid technique ",
abstract = "Abstract Indoor scene classification is usually approached from a computer vision perspective. However, in some fields like robotics, additional constraints must be taken into account. Specifically, in systems with low resources, state-of-the-art techniques (CNNs) cannot be successfully deployed. In this paper, we try to close this gap between theoretical approaches and real world solutions by performing an in-depth study of the factors that influence classifiers performance, that is, size and descriptor quality. To this end, we perform a thorough evaluation of the visual and depth data obtained with an RGB-D sensor to propose techniques to build robust descriptors that can enable real-time indoor scene classification. Those descriptors are obtained by properly selecting and combining visual and depth information sources. "
}
@article{Chen20161,
title = "Analyzing and visual programming internet of things and autonomous decentralized systems ",
journal = "Simulation Modelling Practice and Theory ",
volume = "65",
number = "",
pages = "1 - 10",
year = "2016",
note = "Analyzing and Visual Programming Internet of Things ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X16301800",
author = "Yinong Chen",
keywords = "Internet of Things",
keywords = "autonomous decentralized system",
keywords = "Visual programming",
keywords = "IoT education ",
abstract = "Abstract The development of Internet of Things, fueled by cloud computing and big data processing from upper level, and by ubiquitous sensory and actuator devices from the lower level, has taken a sharp turn towards integrating the entire information, computing, communication, and control systems. This special issue selected seven papers from the 2015 \{IEEE\} twelfth International Symposium on Autonomous Decentralized Systems (ISADS). These papers cover the latest research on IoT and \{ADS\} based system science and system engineering methods; the wearable sensor network development and applications; and data analysis for security and reliability in IoT and \{ADS\} applications. As an addition to these selected topics, this guest editorial paper also adds IoT education and dissemination aspects to this special issue. As the IoT research and applications expand explosively into all the domains, schools and universities must prepare students to understand and to be able to program the IoT devices. This paper presents a visual programming environment that allows students without programming background to learn the key concepts of computing and IoT devices, and to program IoT devices into different application systems. "
}
@article{Woods2016298,
title = "Lidar-based relative navigation with respect to non-cooperative objects ",
journal = "Acta Astronautica ",
volume = "126",
number = "",
pages = "298 - 311",
year = "2016",
note = "Space Flight Safety ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2016.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0094576515301661",
author = "John O. Woods and John A. Christian",
keywords = "Relative navigation",
keywords = "Spacecraft rendezvous",
keywords = "LIDAR",
keywords = "OUR-CVFH ",
abstract = "Abstract Most navigation solutions which make use of lidar for proximity operations with respect to non-cooperative objects rely on the iterative closest point, or icp, algorithm. For correct convergence, icp requires a good initial guess as to the 6 degree-of-freedom relative pose of a client object. Some solutions require manual pose initialization; and template matching — refined by icp — was recently demonstrated as an automated solution for initialization. Additionally, some have used the output of one icp iteration as the initial guess for the next, which is inherently dangerous (since bad icp poses are propagated forward in time by the filter, by icp, or by both; and because it introduces measurement errors that are correlated with the a priori state errors). We demonstrate the use of a method borrowed from personal robotics, our-cvfh (for Oriented, Unique, and Repeatable Clustered Viewpoint Feature Histograms), for rendezvous with a tumbling object in low earth orbit as well as an asteroid in a heliocentric orbit. Our strategy requires no initial pose estimate, and refines our-cvfh results with icp; we demonstrate its utility as part of a full navigation solution with a dual-state inertial extended Kalman filter. "
}
@article{Hassan2015129,
title = "Coefficients of an analytical aerosol forcing equation determined with a Monte-Carlo radiation model ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "164",
number = "",
pages = "129 - 136",
year = "2015",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2015.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0022407315002009",
author = "Taufiq Hassan and H. Moosmüller and Chul E. Chung",
keywords = "Aerosol forcing",
keywords = "Radiation model",
keywords = "MACR model",
keywords = "Monte-Carlo",
keywords = "Analytical equation ",
abstract = "Abstract Simple analytical equations for global-average direct aerosol radiative forcing are useful to quickly estimate aerosol forcing changes as function of key atmosphere, surface and aerosol parameters. The surface and atmosphere parameters in these analytical equations are the globally uniform atmospheric transmittance and surface albedo, and have so far been estimated from simplified observations under untested assumptions. In the present study, we take the state-of-the-art analytical equation and write the aerosol forcing as a linear function of the single scattering albedo (SSA) and replace the average upscatter fraction with the asymmetry parameter (ASY). Then we determine the surface and atmosphere parameter values of this equation using the output from the global \{MACR\} (Monte-Carlo Aerosol Cloud Radiation) model, as well as testing the validity of the equation. The \{MACR\} model incorporated spatio-temporally varying observations for surface albedo, cloud optical depth, water vapor, stratosphere column ozone, etc., instead of assuming as in the analytical equation that the atmosphere and surface parameters are globally uniform, and should thus be viewed as providing realistic radiation simulations. The modified analytical equation needs globally uniform aerosol parameters that consist of \{AOD\} (Aerosol Optical Depth), SSA, and ASY. The \{MACR\} model is run here with the same globally uniform aerosol parameters. The \{MACR\} model is also run without cloud to test the cloud effect. In both cloudy and cloud-free runs, the equation fits in the model output well whether \{SSA\} or \{ASY\} varies. This means the equation is an excellent approximation for the atmospheric radiation. On the other hand, the determined parameter values are somewhat realistic for the cloud-free runs but unrealistic for the cloudy runs. The global atmospheric transmittance, one of the determined parameters, is found to be around 0.74 in case of the cloud-free conditions and around 1.03 with cloud. The surface albedo, another determined parameter, is found to be around 0.18 and 0.28 in case of cloud-free and cloudy-sky conditions respectively. Because the cloudy-sky runs yield unrealistic parameter values, we conclude that the equation is more adequate for cloud-free conditions. "
}
@article{Zhao201737,
title = "A scientometric review of global \{BIM\} research: Analysis and visualization ",
journal = "Automation in Construction ",
volume = "80",
number = "",
pages = "37 - 47",
year = "2017",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2017.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0926580517301334",
author = "Xianbo Zhao",
keywords = "Building information modeling",
keywords = "Co-citation",
keywords = "Research trend",
keywords = "Scientometrics",
keywords = "Visualization ",
abstract = "Abstract In the recent years, building information modeling (BIM) has transformed the architecture, engineering, and construction industry, and attracted attentions from both researchers and practitioners. However, few studies have attempted to map the global research on BIM. This study conducts a scientometric review of global \{BIM\} research in 2005–2016, through co-author analysis, co-word analysis and co-citation analysis. A total of 614 bibliographic records from the Web of Science core collection database were analyzed. The results indicated that Charles M. Eastman received the most co-citations and that the most significant development in \{BIM\} research occurred primarily in the USA, South Korea and China. Additionally, \{BIM\} research has primarily focused on the subject categories of engineering, civil engineering and construction &amp; building technology, and the keywords “visualization” and “industry foundation classes (IFC)” received citation bursts in the recent years. Furthermore, 10 co-citation clusters were identified, and the hot topics of \{BIM\} research were: mobile and cloud computing, laser scan, augmented reality, ontology, safety rule and code checking, semantic web technology, and automated generation. This study provides researchers and practitioners with an in-depth understanding of the status quo and trend of the \{BIM\} research in the world. "
}
@article{Janjai20152356,
title = "Modeling the ratio of photosynthetically active radiation to broadband global solar radiation using ground and satellite-based data in the tropics ",
journal = "Advances in Space Research ",
volume = "56",
number = "11",
pages = "2356 - 2364",
year = "2015",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2015.09.020",
url = "http://www.sciencedirect.com/science/article/pii/S0273117715006626",
author = "S. Janjai and R. Wattan and A. Sripradit",
keywords = "Photosynthetically active radiation",
keywords = "Solar radiation",
keywords = "Ratio",
keywords = "Tropics ",
abstract = "Abstract Data from four stations in Thailand are used to model the ratio of photosynthetically active radiation (PAR) to broadband global solar radiation. The model expresses the ratio of PAR-to-broadband global solar radiation as a function of cloud index, aerosol optical depth, precipitable water, total ozone column and solar zenith angle. Data from the MTSAT-1R and OMI/AURA satellites are used to estimate the cloud index and total ozone column, respectively at each of the four stations, while aerosol optical depth and precipitable water are retrieved from Aerosol Robotic Network (AERONET) sunphotometer measurements, also available at each station. When tested against hourly measurements, the model exhibits a coefficient of variance (R2) equal to or better than 0.96, and root mean square difference (RMSD) in the range of 7.3–7.9% and mean bias difference (MBD) of −4.5% to 3.5%. The model compares favorably with other existing models. "
}
@article{Vuolo2017202,
title = "Smoothing and gap-filling of high resolution multi-spectral time series: Example of Landsat data ",
journal = "International Journal of Applied Earth Observation and Geoinformation ",
volume = "57",
number = "",
pages = "202 - 213",
year = "2017",
note = "",
issn = "0303-2434",
doi = "https://doi.org/10.1016/j.jag.2016.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S0303243416302100",
author = "Francesco Vuolo and Wai-Tim Ng and Clement Atzberger",
keywords = "Time series",
keywords = "Gap-filling",
keywords = "Filtering ",
abstract = "Abstract This paper introduces a novel methodology for generating 15-day, smoothed and gap-filled time series of high spatial resolution data. The approach is based on templates from high quality observations to fill data gaps that are subsequently filtered. We tested our method for one large contiguous area (Bavaria, Germany) and for nine smaller test sites in different ecoregions of Europe using Landsat data. Overall, our results match the validation dataset to a high degree of accuracy with a mean absolute error (MAE) of 0.01 for visible bands, 0.03 for near-infrared and 0.02 for short-wave-infrared. Occasionally, the reconstructed time series are affected by artefacts due to undetected clouds. Less frequently, larger uncertainties occur as a result of extended periods of missing data. Reliable cloud masks are highly warranted for making full use of time series. "
}
@article{MartínezGómez2016641,
title = "Semantic localization in the \{PCL\} library ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "641 - 648",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001943",
author = "Jesus Martínez-Gómez and Vicente Morell and Miguel Cazorla and Ismael García-Varea",
keywords = "Semantic localization",
keywords = "PCL",
keywords = "3D features",
keywords = "Classification ",
abstract = "Abstract The semantic localization problem in robotics consists in determining the place where a robot is located by means of semantic categories. The problem is usually addressed as a supervised classification process, where input data correspond to robot perceptions while classes to semantic categories, like kitchen or corridor. In this paper we propose a framework, implemented in the \{PCL\} library, which provides a set of valuable tools to easily develop and evaluate semantic localization systems. The implementation includes the generation of 3D global descriptors following a Bag-of-Words approach. This allows the generation of fixed-dimensionality descriptors from any type of keypoint detector and feature extractor combinations. The framework has been designed, structured and implemented to be easily extended with different keypoint detectors, feature extractors as well as classification models. The proposed framework has also been used to evaluate the performance of a set of already implemented descriptors, when used as input for a specific semantic localization system. The obtained results are discussed paying special attention to the internal parameters of the BoW descriptor generation process. Moreover, we also review the combination of some keypoint detectors with different 3D descriptor generation techniques. "
}
@article{Lourenço2017210,
title = "Uncertainty characterization of the orthogonal Procrustes problem with arbitrary covariance matrices ",
journal = "Pattern Recognition ",
volume = "61",
number = "",
pages = "210 - 220",
year = "2017",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.07.037",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316301960",
author = "Pedro Lourenço and Bruno J. Guerreiro and Pedro Batista and Paulo Oliveira and Carlos Silvestre",
keywords = "Weighted Procrustes statistics",
keywords = "Perturbation theory",
keywords = "Uncertainty characterization",
keywords = "Map transformation ",
abstract = "Abstract This paper addresses the weighted orthogonal Procrustes problem of matching stochastically perturbed point clouds, formulated as an optimization problem with a closed-form solution. A novel uncertainty characterization of the solution of this problem is proposed resorting to perturbation theory concepts, which admits arbitrary transformations between point clouds and individual covariance and cross-covariance matrices for the points of each cloud. The method is thoroughly validated through extensive Monte Carlo simulations, and particularly interesting cases where nonlinearities may arise are further analyzed. "
}
@article{Biever201217,
title = "Robot software revolution brings droids to life ",
journal = "New Scientist ",
volume = "213",
number = "2848",
pages = "17 - 18",
year = "2012",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(12)60158-4",
url = "http://www.sciencedirect.com/science/article/pii/S0262407912601584",
author = "Celeste Biever",
abstract = "Software and apps are about to do for robots what they did for personal computing "
}
@article{Lee20147104,
title = "New Thinking Paradigm for Maintenance Innovation Design ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "7104 - 7109",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02519",
url = "http://www.sciencedirect.com/science/article/pii/S147466701642731X",
author = "Jay Lee and Maria Holgado and Hung-An Kao and Marco Macchi",
abstract = "Abstract Meanwhile the manufacturing paradigm changes towards predictive manufacturing, the role of maintenance function within manufacturing needs to be refined as a value creation function for achieving more sustainable operations. With the advent of internet of things (IoT), cloud computing, big data, PHM, and cyber-physical systems, e-maintenance necessitates new transformation. These changes are driving a new thinking paradigm for maintenance. This paper introduces new perspectives for maintenance innovation and proposes the value creation paths for maintenance transformation. "
}
@article{Stumm2016269,
title = "Human-Machine Interaction for Intuitive Programming of Assembly Tasks in Construction ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "269 - 274",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.02.108",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116003905",
author = "Sven Stumm and Johannes Braumann and Sigrid Brell-Cokcan",
keywords = "Robot programming",
keywords = "Skill based programming",
keywords = "Visual programming",
keywords = "CAD based programming",
keywords = "Gesture recognition",
keywords = "Construction ",
abstract = "Abstract A variety of robot programming techniques exists ranging from constraint based over skill based programming to learning by demonstration. In order to extend their applicability propose to join some of these approaches. We therefore combine visual \{CAD\} based programming with skill based programming through demonstration. This constitutes the basis of the outlines strategy. We then employ human feedback through hand gestures for incremental parameter modification. We propose this approach in order to potentially lower times to production for new products and allow efficient use of robotics in low lot-sizes especially in the context of assembly for construction. "
}
@article{Yang2017169,
title = "Modern software cybernetics: New trends ",
journal = "Journal of Systems and Software ",
volume = "124",
number = "",
pages = "169 - 186",
year = "2017",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.08.095",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216301595",
author = "Hongji Yang and Feng Chen and Suleiman Aliyu",
keywords = "Software cybernetics",
keywords = "Control engineering",
keywords = "Software engineering",
keywords = "Computer science",
keywords = "Artificial intelligence ",
abstract = "Abstract Software cybernetics research is to apply a variety of techniques from cybernetics research to software engineering research. For more than fifteen years since 2001, there has been a dramatic increase in work relating to software cybernetics. From cybernetics viewpoint, the work is mainly on the first-order level, namely, the software under observation and control. Beyond the first-order cybernetics, the software, developers/users, and running environments influence each other and thus create feedback to form more complicated systems. We classify software cybernetics as Software Cybernetics I based on the first-order cybernetics, and as Software Cybernetics \{II\} based on the higher order cybernetics. This paper provides a review of the literature on software cybernetics, particularly focusing on the transition from Software Cybernetics I to Software Cybernetics II. The results of the survey indicate that some new research areas such as Internet of Things, big data, cloud computing, cyber-physical systems, and even creative computing are related to Software Cybernetics II. The paper identifies the relationships between the techniques of Software Cybernetics \{II\} applied and the new research areas to which they have been applied, formulates research problems and challenges of software cybernetics with the application of principles of Phase \{II\} of software cybernetics; identifies and highlights new research trends of software cybernetic for further research. "
}
@article{Wittenberg2016420,
title = "Human-CPS Interaction - requirements and human-machine interaction methods for the Industry 4.0 ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "19",
pages = "420 - 425",
year = "2016",
note = "13th \{IFAC\} Symposium on Analysis, Design, and Evaluation ofHuman-Machine Systems \{HMS\} 2016Kyoto, Japan, 30 August—2 September 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.602",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316321930",
author = "Carsten Wittenberg",
keywords = "Human-centered design",
keywords = "cyber-physical systems",
keywords = "user requirements",
keywords = "mobile systems",
keywords = "Industry 4.0 ",
abstract = "Abstract Cyber-Physical Systems (CPS) and ideas from the internet of things leaded to the concept of the industry 4.0. The so-called Industry 4.0 implicates techniques like cloud-computing and self-organizing machines. The degree of technological complexity increases. Beside the technological innovation the use context and the tasks for the users will also be changed. In the design phase the engineers have to handle the increased complexity. In the operating phase the operators and also the service and maintenance technicians have to keep the production systems running. This paper discusses the effects of Industry 4.0 and shows the results of the research on mobile applications for supporting service and maintenance technicians under the influence of the CPS/Smart Factories/Industry 4.0. "
}
@article{Sand2013341,
title = "Closing the loops: An industrial perspective on the present and future impact of control ",
journal = "European Journal of Control ",
volume = "19",
number = "5",
pages = "341 - 350",
year = "2013",
note = "The Path of Control ",
issn = "0947-3580",
doi = "https://doi.org/10.1016/j.ejcon.2013.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0947358013000897",
author = "Guido Sand and Peter Terwiesch",
abstract = "Abstract This paper provides an industrial perspective on the present and future trends and impact of control. Applications in power systems, process automation and robotics are discussed against business, environmental, and technology trends, so as to outline current and future fields of control research and application. "
}
@article{Yang2016,
title = "Modern Software Cybernetics: Trends with New Cybernetics ",
journal = "Journal of Systems and Software ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.05.044",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216300656",
author = "Hongji Yang and Feng Chen and Suleiman Aliyu",
keywords = "Software Cybernetics",
keywords = "New Cybernetics",
keywords = "Control Engineering",
keywords = "Software Engineering",
keywords = "Computer Science",
keywords = "Artificial Intelligence ",
abstract = "Abstract Software cybernetics research is to apply a variety of techniques from cybernetics research to software engineering research. For more than fifteen years since 2001, there has been a dramatic increase in work on software cybernetics. From cybernetics viewpoint, the work is mainly on the first-order level, namely, the software under observation and control. Beyond the first-order cybernetics, the software, developers/users, and running environments influence each other and thus create feedback to form a more complicated system. We classify software cybernetics as classical software cybernetics based on the first-order cybernetics, and as modern software cybernetics based on the higher order cybernetics (new cybernetics). This paper provides a review of literature on software cybernetics, especially focuses on the transition from classical software cybernetics to modern software cybernetics. The results of the survey indicate that some new research areas such as Internet of Things, big data, cloud computing, cyber-physical systems, and even creative computing are related to modern software cybernetics. The paper identifies the relationships between the techniques of new cybernetics applied and the new research areas to which they have been applied; formulates research problems and challenges of software cybernetics with the application of principles of new cybernetics; identifies and highlights new research trends of modern software cybernetic for further research. "
}
@article{Hyyti2013248,
title = "Feature Based Modeling and Mapping of Tree Trunks and Natural Terrain Using 3D Laser Scanner Measurement System ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "248 - 255",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00065",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349405",
author = "Heikki Hyyti and Arto Visala",
abstract = "Abstract This paper presents a novel approach to measure tree trunks and to model the ground using a 3D laser scanner. The 3D scanner, self-build using two 2D Sick scanners on a rotating base, measures each scan line approximately at 45° angle towards the ground and the trees. Single scan lines are segmented to find ground and tree returns. 3D point clouds from the surrounding forest are recorded while the measuring vehicle is moving. Sequential scan lines are joined together as the pose changes are reduced from the older buffered measurements. Laser odometry and inertial measurements are used to measure the pose changes. The ground is modeled by fitting a 1m grid to 3D point cloud extracted using a ground return detector. Tree trunks are searched from the 3D point cloud using a histogram approach to segment measurements into separate point clouds for each tree trunk. Tree trunks are modeled using ten circle features one on the other using the extracted point cloud. Instead of using the whole point cloud, mapping is done only for the extracted features and the travelled path to save computation time. Our method can detect nearly all tree trunks and measure them on short ranges of less than 8m with errors less than 4cm in diameter. "
}
@article{RuizSarmiento2015131,
title = "Exploiting semantic knowledge for robot object recognition ",
journal = "Knowledge-Based Systems ",
volume = "86",
number = "",
pages = "131 - 142",
year = "2015",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2015.05.032",
url = "http://www.sciencedirect.com/science/article/pii/S0950705115002191",
author = "José-Raúl Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Semantic knowledge",
keywords = "Human elicitation",
keywords = "Object recognition",
keywords = "Probabilistic Graphical Models",
keywords = "Autonomous robots ",
abstract = "Abstract This paper presents a novel approach that exploits semantic knowledge to enhance the object recognition capability of autonomous robots. Semantic knowledge is a rich source of information, naturally gathered from humans (elicitation), which can encode both objects’ geometrical/appearance properties and contextual relations. This kind of information can be exploited in a variety of robotics skills, especially for robots performing in human environments. In this paper we propose the use of semantic knowledge to eliminate the need of collecting large datasets for the training stages required in typical recognition approaches. Concretely, semantic knowledge encoded in an ontology is used to synthetically and effortless generate an arbitrary number of training samples for tuning Probabilistic Graphical Models (PGMs). We then employ these \{PGMs\} to classify patches extracted from 3D point clouds gathered from office environments within the UMA-offices dataset, achieving a ∼90% of recognition success, and from office and home scenes within the \{NYU2\} dataset, yielding a success of ∼81% and ∼69.5% respectively. Additionally, a comparison with state-of-the-art recognition methods also based on graphical models has been carried out, revealing that our semantic-based training approach can compete with, and even outperform, those trained with a considerable number of real samples. "
}
@article{Zheng2016107,
title = "A multi-frame graph matching algorithm for low-bandwidth RGB-D \{SLAM\} ",
journal = "Computer-Aided Design ",
volume = "78",
number = "",
pages = "107 - 117",
year = "2016",
note = "\{SPM\} 2016 ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2016.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S001044851630029X",
author = "Shuai Zheng and Jun Hong and Kang Zhang and Baotong Li and Xin Li",
keywords = "Multi-frame graph matching",
keywords = "Partial matching",
keywords = "Low-bandwidth SLAM",
keywords = "RGB-D reconstruction ",
abstract = "Abstract This paper presents a novel multi-frame graph matching algorithm for reliable partial alignments among point clouds. We use this algorithm to stitch frames for 3D environment reconstruction. The idea is to utilize both descriptor similarity and mutual spatial coherency of features existed in multiple frames to match these frames. The proposed multi-frame matching algorithm can extract coarse correspondence among multiple point clouds more reliably than pairwise matching algorithms, especially when the data are noisy and the overlap is relatively small. When there are insufficient consistent features that appeared in all these frames, our algorithm reduces the number of frames to match to deal with it adaptively. Hence, it is particularly suitable for cost-efficient robotic Simultaneous Localization and Mapping (SLAM). We design a prototype system integrating our matching and reconstruction algorithm on a remotely controlled navigation iRobot, equipped with a Kinect and a Raspberry Pi. Our reconstruction experiments demonstrate the effectiveness of our algorithm and design. "
}
@article{Jin201559,
title = "Significance and Challenges of Big Data Research ",
journal = "Big Data Research ",
volume = "2",
number = "2",
pages = "59 - 64",
year = "2015",
note = "Visions on Big Data ",
issn = "2214-5796",
doi = "https://doi.org/10.1016/j.bdr.2015.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S2214579615000076",
author = "Xiaolong Jin and Benjamin W. Wah and Xueqi Cheng and Yuanzhuo Wang",
keywords = "Big data",
keywords = "Data complexity",
keywords = "Computational complexity",
keywords = "System complexity ",
abstract = "Abstract In recent years, the rapid development of Internet, Internet of Things, and Cloud Computing have led to the explosive growth of data in almost every industry and business area. Big data has rapidly developed into a hot topic that attracts extensive attention from academia, industry, and governments around the world. In this position paper, we first briefly introduce the concept of big data, including its definition, features, and value. We then identify from different perspectives the significance and opportunities that big data brings to us. Next, we present representative big data initiatives all over the world. We describe the grand challenges (namely, data complexity, computational complexity, and system complexity), as well as possible solutions to address these challenges. Finally, we conclude the paper by presenting several suggestions on carrying out big data projects. "
}
@article{Mazitov2016305,
title = "Using Bee Algorithm in the Problem of Mapping ",
journal = "Procedia Engineering ",
volume = "149",
number = "",
pages = "305 - 312",
year = "2016",
note = "International Conference on Manufacturing Engineering and Materials, \{ICMEM\} 2016, 6-10 June 2016, Nový Smokovec, Slovakia ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.06.671",
url = "http://www.sciencedirect.com/science/article/pii/S187770581631181X",
author = "Timur Mazitov and Pavol Božek and Andrey Abramov and Yuri Nikitin and Ivan Abramov",
keywords = "SLAM",
keywords = "ICP",
keywords = "swarm algoritms",
keywords = "bee algorithm",
keywords = "location",
keywords = "mapping. ",
abstract = "Abstract Innovative algorithm for solving simultaneous location and mapping problem in unknown environment is considered. The algorithm is based on the comparison of point clouds with bee swarm algorithm. The algorithm obtained was experimentally tested. The algorithm increases the number of calculations in several times as compared to standard methods of minimization (algorithm of gradient descent and others), but the function calculations in random points are similar operations and it enables the efficient application of parallel computations, thus resulting in increased performance. "
}
@incollection{Kelley2014343,
title = "Chapter 14 - Intent Recognition for Human–Robot Interaction ",
editor = "Sukthankar, Gita and , and Geib, Christopher and , and Bui, Hung Hai and , and Pynadath, David V. and ,  and Goldman, Robert P. ",
booktitle = "Plan, Activity, and Intent Recognition ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2014",
pages = "343 - 365",
isbn = "978-0-12-398532-3",
doi = "https://doi.org/10.1016/B978-0-12-398532-3.00014-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780123985323000142",
author = "Richard Kelley and Alireza Tavakkoli and Christopher King and Amol Ambardekar and Liesl Wigand and Monica Nicolescu and Mircea Nicolescu",
keywords = "Intent",
keywords = "Hidden Markov model",
keywords = "Context",
keywords = "Lexical graph",
keywords = "Human–robot interaction ",
abstract = "Abstract For robots to operate in social environments, they must be able to recognize human intentions. In the context of social robotics, intent recognition must rely on imperfect sensors, such as depth cameras, and must operate in real time. This chapter introduces several approaches for recognizing intentions by physical robots. We show how such systems can use sensors, such as the Microsoft Kinect, as well as temporal and contextual information obtained from resources such as Wikipedia. "
}
@article{Li2016352,
title = "Dexterous grasping under shape uncertainty ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "352 - 364",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001967",
author = "Miao Li and Kaiyu Hang and Danica Kragic and Aude Billard",
keywords = "Dexterous grasping",
keywords = "Shape uncertainty",
keywords = "Grasp control",
keywords = "Grasp learning ",
abstract = "Abstract An important challenge in robotics is to achieve robust performance in object grasping and manipulation, dealing with noise and uncertainty. This paper presents an approach for addressing the performance of dexterous grasping under shape uncertainty. In our approach, the uncertainty in object shape is parametrized and incorporated as a constraint into grasp planning. The proposed approach is used to plan feasible hand configurations for realizing planned contacts using different robotic hands. A compliant finger closing scheme is devised by exploiting both the object shape uncertainty and tactile sensing at fingertips. Experimental evaluation demonstrates that our method improves the performance of dexterous grasping under shape uncertainty. "
}
@article{Kopacek201521,
title = "Automation and \{TECIS\} ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "24",
pages = "21 - 27",
year = "2015",
note = "16th \{IFAC\} Conference on Technology, Culture and International Stability \{TECIS\} 2015Sozopol, Bulgaria, 24–27 September 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.12.050",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315026749",
author = "P. Kopacek",
keywords = "Process Automation",
keywords = "Manufacturing Automation",
keywords = "Robots",
keywords = "Social aspects",
keywords = "Ethics ",
abstract = "Abstract Process - and manufacturing automation as well as robotics are currently one of the fast growing fields in automation. Advanced process control, cyber-physical systems, industry 4.0 and “advanced robots” are not longer a headline. They are in realization. As a consequence of these developments new social, ethical and human questions appear. Therefore this contribution is a first trial to merge selected items from the scope of the \{IF\} \{AC\} \{TC\} \{TECIS\} with these new questions. As a result first ideas to solve these problems are presented and shortly discussed. Finally suggestions for further research topics are given "
}
@article{Charalampous201785,
title = "Recent trends in social aware robot navigation: A survey ",
journal = "Robotics and Autonomous Systems ",
volume = "93",
number = "",
pages = "85 - 104",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016302287",
author = "Konstantinos Charalampous and Ioannis Kostavelis and Antonios Gasteratos",
keywords = "Metric mapping",
keywords = "Semantic mapping",
keywords = "Proxemics",
keywords = "Social mapping ",
abstract = "Abstract With the robots tending to accumulate more and more capabilities beyond the level of acting in a deterministic fashion, the idea of introducing them into our every day lives seems to be closer now. Robotics systems and techniques appeared during the recent years have achieved astonishing potential to perceive and interpret their surrounding not only as low level features but also close to human understandable concepts. Such advances, in conjunction with the aspiration to incorporate robots into domestic or public places, led to the flourishing of fields dealing with their response in human presence. Following this notion, the field of social mapping was recently introduced in order to manage the shared space among robots and individuals in an ordinary fashion. This manuscript aims to systemize the recent literature by describing the required levels of robot perception, focusing on methods related to robot’s social awareness, the availability of datasets these methods can be compared with, as well as issues that remain open and need to be confronted when robots operate in close proximity with humans. "
}
@article{Pan2015046,
title = "Efficient Configuration Space Construction and Optimization for Motion Planning ",
journal = "Engineering ",
volume = "1",
number = "1",
pages = "046 - 057",
year = "2015",
note = "Special Section: Robotics ",
issn = "2095-8099",
doi = "https://doi.org/10.15302/J-ENG-2015009",
url = "http://www.sciencedirect.com/science/article/pii/S2095809916300443",
author = "Jia Pan and Dinesh Manocha",
keywords = "configuration space",
keywords = "motion planning",
keywords = "GPU parallel algorithm ",
abstract = "\{ABSTRACT\} The configuration space is a fundamental concept that is widely used in algorithmic robotics. Many applications in robotics, computer-aided design, and related areas can be reduced to computational problems in terms of configuration spaces. In this paper, we survey some of our recent work on solving two important challenges related to configuration spaces: how to efficiently compute an approximate representation of high-dimensional configuration spaces; and how to efficiently perform geometric proximity and motion planning queries in high-dimensional configuration spaces. We present new configuration space construction algorithms based on machine learning and geometric approximation techniques. These algorithms perform collision queries on many configuration samples. The collision query results are used to compute an approximate representation for the configuration space, which quickly converges to the exact configuration space. We also present parallel GPU-based algorithms to accelerate the performance of optimization and search computations in configuration spaces. In particular, we design efficient GPU-based parallel k-nearest neighbor and parallel collision detection algorithms and use these algorithms to accelerate motion planning. "
}
@article{Cutter201628,
title = "Image-based Registration for a Neurosurgical Robot: Comparison Using Iterative Closest Point and Coherent Point Drift Algorithms ",
journal = "Procedia Computer Science ",
volume = "90",
number = "",
pages = "28 - 34",
year = "2016",
note = "20th Conference on Medical Image Understanding and Analysis (MIUA 2016) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S187705091631184X",
author = "Jennifer R. Cutter and Iain B. Styles and Aleš Leonardis and Hamid Dehghani",
keywords = "Registration",
keywords = "ICP",
keywords = "CPD",
keywords = "neurosurgery",
keywords = "robot ; ",
abstract = "Abstract Stereotactic neurosurgical robots allow quick, accurate location of small targets within the brain, relying on accurate registration of pre-operative MRI/CT images with patient and robot coordinate systems during surgery. Fiducial markers or a stereotactic frame are used as registration landmarks; the patient's head is fixed in position throughout surgery. An image-based system could be quicker and less invasive, allowing the head to be moved during surgery to give greater ease of access, but would be required to retain a surgical precision of ∼1 mm at the target point. We compare two registration algorithms, iterative closest point (ICP) and coherent point drift (CPD), by registering ideal point clouds taken from \{MRI\} data with re-meshed, noisy and smoothed versions. We find that \{ICP\} generally gives better and more consistent registration accuracy for the region of interest than CPD, with a best \{RMS\} distance of 0.884±0.050 mm between aligned point clouds, as compared to 0.995±0.170 mm or worse for CPD. "
}
@article{MahdaviHezavehi2017,
title = "A systematic literature review onmethods that handle multiple quality attributes in architecture-based self-adaptive systems ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0950584917302860",
author = "Sara Mahdavi-Hezavehi and Vinicius H.S. Durelli and Danny Weyns and Paris Avgeriou",
abstract = "AbstractContext : Handling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill \{QAs\} of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the \{QAs\} of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods. Objective : In this paper we review the state-of-the-art of architecture-based methods for handling multiple \{QAs\} in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature. Method : We conducted a systematic literature review by performing an automatic search on twenty-eight selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis. Results : Performance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple \{QAs\} mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify \{QAs\} sets are \{QA\} data variables. After \{QA\} data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple \{QAs\} are \{PRISM\} and IBM's autonomic computing toolkit. \{KLAPER\} is the only language that has been specifically developed to deal with quality properties analysis. Conclusions : Our results help researchers to understand the current state of research regarding architecture-based methods for handling multiple \{QAs\} in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple \{QAs\} and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime. "
}
@article{Kazala2015231,
title = "Wireless Network for Mobile Robot Applications ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "24",
pages = "231 - 236",
year = "2015",
note = "16th \{IFAC\} Conference on Technology, Culture and International Stability \{TECIS\} 2015Sozopol, Bulgaria, 24–27 September 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.12.088",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315027123",
author = "R. Kazala and A. Taneva and M. Petrov and St. Penkov",
keywords = "networks",
keywords = "IoT",
keywords = "Ethernet",
keywords = "MQTT protocol",
keywords = "mobile robots ",
abstract = "Abstract The paper presents a concept of wireless network for data exchange between mobile robot nodes. It could be used for monitoring and control applications. Each node is equipped with sensors and communication hardware. The so called nodes can collect data from sensors and send to central one. This can be a host computer connected to a cloud network. It is known as Wireless Sensor Network (WSN). The main goal is to find a way to reduce energy consumption and computing power of robot nodes. The solution is based on choosing proper communication protocols. The article presents description of standards and networks. In the developed solution \{MQ\} Telemetry Transport (MQTT) for data exchange was used. The communication organization between networked nodes is given. As a part of system verification the messages between nodes and central system were exchanged. The advantages of presented network are also included. "
}
@article{Faria2014794,
title = "Knowledge-based reasoning from human grasp demonstrations for robot grasp synthesis ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "794 - 817",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000347",
author = "Diego R. Faria and Pedro Trindade and Jorge Lobo and Jorge Dias",
keywords = "Robot grasp synthesis",
keywords = "Human grasp demonstrations",
keywords = "Object shape representation",
keywords = "Probabilistic inference ",
abstract = "Abstract Humans excel when dealing with everyday manipulation tasks, being able to learn new skills, and to adapt to different complex environments. This results from a lifelong learning, and also observation of other skilled humans. To obtain similar dexterity with robotic hands, cognitive capacity is needed to deal with uncertainty. By extracting relevant multi-sensor information from the environment (objects), knowledge from previous grasping tasks can be generalized to be applied within different contexts. Based on this strategy, we show in this paper that learning from human experiences is a way to accomplish our goal of robot grasp synthesis for unknown objects. In this article we address an artificial system that relies on knowledge from previous human object grasping demonstrations. A learning process is adopted to quantify probabilistic distributions and uncertainty. These distributions are combined with preliminary knowledge towards inference of proper grasps given a point cloud of an unknown object. In this article, we designed a method that comprises a twofold process: object decomposition and grasp synthesis. The decomposition of objects into primitives is used, across which similarities between past observations and new unknown objects can be made. The grasps are associated with the defined object primitives, so that feasible object regions for grasping can be determined. The hand pose relative to the object is computed for the pre-grasp and the selected grasp. We have validated our approach on a real robotic platform—a dexterous robotic hand. Results show that the segmentation of the object into primitives allows to identify the most suitable regions for grasping based on previous learning. The proposed approach provides suitable grasps, better than more time consuming analytical and geometrical approaches, contributing for autonomous grasping. "
}
@article{RoviraMás2008133,
title = "Stereo vision three-dimensional terrain maps for precision agriculture ",
journal = "Computers and Electronics in Agriculture ",
volume = "60",
number = "2",
pages = "133 - 143",
year = "2008",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2007.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S016816990700172X",
author = "Francisco Rovira-Más and Qin Zhang and John F. Reid",
keywords = "Autonomous navigation",
keywords = "Precision agriculture",
keywords = "Stereo vision",
keywords = "3D map",
keywords = "GPS",
keywords = "IMU",
keywords = "Terrain mapping ",
abstract = "The combined interest in precision agriculture, information technology, and autonomous navigation has led to a growing interest in the generation of 3D maps of mobile equipment surroundings. This article proposes a method to create 3D terrain maps by combining the information captured with a stereo camera, a localization sensor, and an inertial measurement unit, all installed on a mobile equipment platform. The perception engine comprises a compact stereo camera that captures field scenes and generates 3D point clouds, which are transformed to geodetic coordinates and assembled in a global field map. The results showed that stereo perception can provide the level of detail and accuracy needed in the construction of 3D field maps for precision agriculture and field robotics applications. "
}
@article{Swaid20153657,
title = "Bringing Computational Thinking to \{STEM\} Education ",
journal = "Procedia Manufacturing ",
volume = "3",
number = "",
pages = "3657 - 3662",
year = "2015",
note = "6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, \{AHFE\} 2015 ",
issn = "2351-9789",
doi = "https://doi.org/10.1016/j.promfg.2015.07.761",
url = "http://www.sciencedirect.com/science/article/pii/S2351978915007623",
author = "Samar I. Swaid",
keywords = "Computational thinking",
keywords = "STEM",
keywords = "Computational science",
keywords = "HBCU",
keywords = "Cyberinfrastructure ",
abstract = "Abstract Today, as advanced technologies and cloud computing tools emerge, it is imperative that such innovations are sustained with knowledge and skill set among \{STEM\} educators and practitioners. In this paper, the author reports on a project, HBCU-UP II, that works on bringing Computational Thinking to Science, Technology, Engineering, and Mathematics (STEM) disciplines. A Computational-Thinking based strategy is adopted to enforce thinking computationally in \{STEM\} gate-keeping courses. The paper presents framework, implementation and outcomes. This on-going project contributes to efforts to establish computational thinking as a universally applicable attitude that is meshed within \{STEM\} conversations, education, and curricula. This paper will be particularly useful for researchers interested in Computational Thinking and its applications in \{STEM\} education, in particular and higher education in general "
}
@article{Sakr201644,
title = "Towards a Comprehensive Data Analytics Framework for Smart Healthcare Services ",
journal = "Big Data Research ",
volume = "4",
number = "",
pages = "44 - 58",
year = "2016",
note = "",
issn = "2214-5796",
doi = "https://doi.org/10.1016/j.bdr.2016.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S221457961530023X",
author = "Sherif Sakr and Amal Elgammal",
abstract = "Abstract With the increasing volumes of information gathered via patient monitoring systems, physicians have been put on increasing pressure for making sophisticated analytical decisions that exploit the various types of data that is being gathered per patient. This phenomenon of continuously growing datasets is arising and gaining momentum in several application domains to what is now recognized in the business community as the Big Data challenge. In this article, we define and discuss some of the major challenges in the healthcare systems which can be effectively tackled by the recent advancement in \{ICT\} technologies. In particular, we focus on sensing technologies, cloud of computing, internet-of-things and big data analytics systems as emerging technologies which are made possible by the remarkable progress in various aspects including network communication speed, computational capabilities and data storage capacities that provide various advantages and characteristics that can contribute towards improving the efficiency and effectiveness of healthcare services. In addition, we describe the architectural components of our proposed framework, SmartHealth, for big data analytics services and describe its various applications in the healthcare domain. "
}
@article{Yang2017,
title = "Rotational contour signatures for both real-valued and binary feature representations of 3D local shape ",
journal = "Computer Vision and Image Understanding ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2017.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S1077314217300322",
author = "Jiaqi Yang and Qian Zhang and Ke Xian and Yang Xiao and Zhiguo Cao",
keywords = "Local shape descriptor",
keywords = "Rotation",
keywords = "Contour signature",
keywords = "Binary representation",
keywords = "Feature matching ",
abstract = "Abstract This paper presents a rotational contour signatures (RCS) method for both real-valued and binary descriptions of 3D local shape. \{RCS\} comprises several signatures that characterize the 2D contour information derived from 3D-to-2D projection of the local point cloud. The inspiration of our encoding technique comes from that when viewing towards an object, its contour is an effective and robust cue for representing its shape. In order to achieve a comprehensive geometry encoding, the local surface is continually rotated in a predefined local reference frame (LRF) so that multi-view information is obtained. A peculiar trait of our \{RCS\} method is its seamless extension to binary representations to accelerate feature matching and reduce storage consumption. Specifically, we resort to three techniques, i.e., thresholding, quantization and geometrical binary encoding, to generate \{RCS\} binary strings. In contrast to 2D image area, there are quite rare 3D binary descriptors yet in 3D computer vision. We deploy experiments on three standard datasets including shape retrieval, 3D object recognition and 2.5D point cloud view matching scenarios with a rigorous comparison with six state-of-the-art descriptors. The comparative outcomes confirm numerous merits of our \{RCS\} method, e.g., highly discriminative, compact, computational efficient and robust to many nuisances including noise, mesh resolution variation, clutter and occlusion. We also show the versatility of \{RCS\} in matching of both LiDAR and Kinect point clouds. "
}
@incollection{Combs201557,
title = "Chapter 7 - Disruptive Technologies Affecting Education and Their Implications for Curricular Redesign ",
editor = "Wartman, Steven A. ",
booktitle = "The Transformation of Academic Health Centers ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2015",
pages = "57 - 68",
isbn = "978-0-12-800762-4",
doi = "https://doi.org/10.1016/B978-0-12-800762-4.00007-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128007624000074",
author = "C. Donald Combs and Bertalan Meskó",
keywords = "Competency based education",
keywords = "Digital technologies",
keywords = "Disruptive innovation",
keywords = "Medical and health professions education",
keywords = "Personalization",
keywords = "Social media",
keywords = "Social networks ",
abstract = "Abstract This chapter discusses the impact of disruptive technologies on education, health care, and health professions education. There are six major categories of digital advances that have begun to disrupt the model of current health care—the cell phone, personal computers, the internet, smart digital devices, gene sequencing, and social networks. There is, within these categories, an amazing array of technologies that need to be incorporated into medical and health professions education programs. The characteristics of curricula that are successful in the future will, we believe, be based on business models that embrace the participatory, democratic culture emerging from ubiquitous digital devices and social networks; that take advantage of big data and cloud computing to increase the customization and personalization of educational programs; and that achieve balance between the constant connectivity afforded by digital devices and the need for offline reflection. "
}
@article{Prakhya201740,
title = "Low Bit-rate 3D feature descriptors for depth data from Kinect-style sensors ",
journal = "Signal Processing: Image Communication ",
volume = "51",
number = "",
pages = "40 - 49",
year = "2017",
note = "",
issn = "0923-5965",
doi = "https://doi.org/10.1016/j.image.2016.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0923596516301734",
author = "Sai Manoj Prakhya and Weisi Lin and Vijay Chandrasekhar and Bingbing Liu and Jie Lin",
keywords = "3D feature descriptors",
keywords = "Compression",
keywords = "Lattice quantization",
keywords = "3D keypoint matching ",
abstract = "Abstract In applications that require an input point cloud to be matched with a set of database point clouds present on a remote server, it is preferable to compress and transfer 3D feature descriptors online, rather than compressing and transferring the whole input point cloud. This is because the former would require much lesser bandwidth and does not require feature extraction on the server. Existing real valued 3D feature descriptors that offer good keypoint matching performance require higher bandwidth for their transfer over the network. On the other hand, the existing binary 3D feature descriptor requires relatively less bandwidth but offers reduced keypoint matching performance. In this paper, we propose to employ lattice quantization to efficiently compress 3D feature descriptors. These compressed 3D feature descriptors can be directly matched in compressed domain without any need for decompression, hence drastically reducing the memory footprint and computational requirements. We also propose double stage lattice quantization to achieve even more compression in the case of \{SHOT\} 3D feature descriptor. We provide a spectrum of possible bit rates and achievable keypoint matching performance for three state-of-the-art 3D feature descriptors. Experimental evaluation on publicly available benchmark dataset highlights that the compressed 3D feature descriptors require much lesser bandwidth and yet offer good keypoint matching performance. The source code is made publicly available for the benefit of the community. "
}
@article{Wang2015517,
title = "Current status and advancement of cyber-physical systems in manufacturing ",
journal = "Journal of Manufacturing Systems ",
volume = "37, Part 2",
number = "",
pages = "517 - 527",
year = "2015",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2015.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0278612515000400",
author = "Lihui Wang and Martin Törngren and Mauro Onori",
abstract = "Abstract This paper presents the current status and the latest advancement of cyber-physical systems (CPS) in manufacturing. In order to understand \{CPS\} and its future potential in manufacturing, definitions and characteristics of \{CPS\} are explained and compared with cloud manufacturing concept. Research and applications are outlined to highlight the latest advancement in the field. \{CPS\} shows great promise in factories of the future in the areas of future trends as identified at the end of this paper. "
}
@article{Loukas201783,
title = "Computation offloading of a vehicle’s continuous intrusion detection workload for energy efficiency and performance ",
journal = "Simulation Modelling Practice and Theory ",
volume = "73",
number = "",
pages = "83 - 94",
year = "2017",
note = "Smart Cities and Internet of Things ",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2016.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X16302234",
author = "George Loukas and Yongpil Yoon and Georgia Sakellari and Tuan Vuong and Ryan Heartfield",
keywords = "Computation offloading",
keywords = "Intrusion detection",
keywords = "Energy efficiency",
keywords = "Detection latency",
keywords = "Cyber-physical systems",
keywords = "Vehicular security ",
abstract = "Abstract Computation offloading has been used and studied extensively in relation to mobile devices. That is because their relatively limited processing power and reliance on a battery render the concept of offloading any processing/energy-hungry tasks to a remote server, cloudlet or cloud infrastructure particularly attractive. However, the mobile device’s tasks that are typically offloaded are not time-critical and tend to be one-off. We argue that the concept can be practical also for continuous tasks run on more powerful cyber-physical systems where timeliness is a priority. As case study, we use the process of real-time intrusion detection on a robotic vehicle. Typically, such detection would employ lightweight statistical learning techniques that can run onboard the vehicle without severely affecting its energy consumption. We show that by offloading this task to a remote server, we can utilse approaches of much greater complexity and detection strength based on deep learning. We show both mathematically and experimentally that this allows not only greater detection accuracy, but also significant energy savings, which improve the operational autonomy of the vehicle. In addition, the overall detection latency is reduced in most of our experiments. This can be very important for vehicles and other cyber-physical systems where cyber attacks can directly affect physical safety. In fact, in some cases, the reduction in detection latency thanks to offloading is not only beneficial but necessary. An example is when detection latency onboard the vehicle would be higher than the detection period, and as a result a detection run cannot complete before the next one is scheduled, increasingly delaying consecutive detection decisions. Offloading to a remote server is an effective and energy-efficient solution to this problem too. "
}
@article{Wolfert201769,
title = "Big Data in Smart Farming – A review ",
journal = "Agricultural Systems ",
volume = "153",
number = "",
pages = "69 - 80",
year = "2017",
note = "",
issn = "0308-521X",
doi = "https://doi.org/10.1016/j.agsy.2017.01.023",
url = "http://www.sciencedirect.com/science/article/pii/S0308521X16303754",
author = "Sjaak Wolfert and Lan Ge and Cor Verdouw and Marc-Jeroen Bogaardt",
keywords = "Agriculture",
keywords = "Data",
keywords = "Information and communication technology",
keywords = "Data infrastructure",
keywords = "Governance",
keywords = "Business modelling ",
abstract = "Abstract Smart Farming is a development that emphasizes the use of information and communication technology in the cyber-physical farm management cycle. New technologies such as the Internet of Things and Cloud Computing are expected to leverage this development and introduce more robots and artificial intelligence in farming. This is encompassed by the phenomenon of Big Data, massive volumes of data with a wide variety that can be captured, analysed and used for decision-making. This review aims to gain insight into the state-of-the-art of Big Data applications in Smart Farming and identify the related socio-economic challenges to be addressed. Following a structured approach, a conceptual framework for analysis was developed that can also be used for future studies on this topic. The review shows that the scope of Big Data applications in Smart Farming goes beyond primary production; it is influencing the entire food supply chain. Big data are being used to provide predictive insights in farming operations, drive real-time operational decisions, and redesign business processes for game-changing business models. Several authors therefore suggest that Big Data will cause major shifts in roles and power relations among different players in current food supply chain networks. The landscape of stakeholders exhibits an interesting game between powerful tech companies, venture capitalists and often small start-ups and new entrants. At the same time there are several public institutions that publish open data, under the condition that the privacy of persons must be guaranteed. The future of Smart Farming may unravel in a continuum of two extreme scenarios: 1) closed, proprietary systems in which the farmer is part of a highly integrated food supply chain or 2) open, collaborative systems in which the farmer and every other stakeholder in the chain network is flexible in choosing business partners as well for the technology as for the food production side. The further development of data and application infrastructures (platforms and standards) and their institutional embedment will play a crucial role in the battle between these scenarios. From a socio-economic perspective, the authors propose to give research priority to organizational issues concerning governance issues and suitable business models for data sharing in different supply chain scenarios. "
}
@article{Pütz2016212,
title = "3D Navigation Mesh Generation for Path Planning in Uneven Terrain ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "212 - 217",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.734",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316310102",
author = "Sebastian Pütz and Thomas Wiemann and Jochen Sprickerhof and Joachim Hertzberg",
keywords = "Robot Navigation",
keywords = "Path Planning",
keywords = "Surface Reconstruction",
keywords = "Mesh Generation ",
abstract = "Abstract We present a 3D mesh surface navigation system for mobile robots. This system uses a 3D point cloud to reconstruct a triangle mesh of the environment in real time that is enriched with a graph structure to represent local connectivity. This Navigation Mesh is then analyzed for roughness and trafficability and used for online path planning. The presented approach is evaluated with a VolksBot \{XT\} platform in a real life outdoor environment. "
}
@article{Liu201748,
title = "Online RGB-D person re-identification based on metric model update ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "2",
number = "1",
pages = "48 - 55",
year = "2017",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2017.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S2468232217300215",
author = "Hong Liu and Liang Hu and Liqian Ma",
keywords = "Person re-identification",
keywords = "Online metric model update",
keywords = "Face information",
keywords = "Skeleton information ",
abstract = "Abstract Person re-identification (re-id) on robot platform is an important application for human-robot-interaction (HRI), which aims at making the robot recognize the around persons in varying scenes. Although many effective methods have been proposed for surveillance re-id in recent years, re-id on robot platform is still a novel unsolved problem. Most existing methods adapt the supervised metric learning offline to improve the accuracy. However, these methods can not adapt to unknown scenes. To solve this problem, an online re-id framework is proposed. Considering that robotics can afford to use high-resolution RGB-D sensors and clear human face may be captured, face information is used to update the metric model. Firstly, the metric model is pre-trained offline using labeled data. Then during the online stage, we use face information to mine incorrect body matching pairs which are collected to update the metric model online. In addition, to make full use of both appearance and skeleton information provided by RGB-D sensors, a novel feature funnel model (FFM) is proposed. Comparison studies show our approach is more effective and adaptable to varying environments. "
}
@article{Holz2015318,
title = "Registration of non-uniform density 3D laser scans for mapping with micro aerial vehicles ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "318 - 330",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.07.021",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001682",
author = "Dirk Holz and Sven Behnke",
keywords = "Mapping",
keywords = "Registration",
keywords = "Micro aerial vehicles",
keywords = "Approximate surface reconstruction",
keywords = "Generalized-ICP ",
abstract = "Abstract Micro aerial vehicles (MAVs) pose specific constraints on onboard sensing, mainly limited payload and limited processing power. For accurate 3D mapping even in GPS-denied environments, we have designed a lightweight 3D laser scanner specifically for the application on MAVs. Similar to other custom-built 3D laser scanners composed of a rotating 2D laser range finder, it exhibits different point densities within and between individual scan lines. When rotated fast, such non-uniform point densities influence neighborhood searches which in turn may negatively affect local feature estimation and scan registration. We present a complete pipeline for 3D mapping including pair-wise registration and global alignment of such non-uniform density 3D point clouds acquired in-flight. For registration, we extend a state-of-the-art registration algorithm to include topological information from approximate surface reconstructions. For global alignment, we use a graph-based approach making use of the same error metric and iteratively refine the complete vehicle trajectory. In experiments, we show that our approach can compensate for the effects caused by different point densities up to very low angular resolutions and that we can build accurate and consistent 3D maps in-flight with a micro aerial vehicle. "
}
@article{Chen2016350,
title = "Building change detection with RGB-D map generated from \{UAV\} images ",
journal = "Neurocomputing ",
volume = "208",
number = "",
pages = "350 - 364",
year = "2016",
note = "SI: BridgingSemantic ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.11.118",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216304866",
author = "Baohua Chen and Zhixiang Chen and Lei Deng and Yueqi Duan and Jie Zhou",
keywords = "Building change detection",
keywords = "3D reconstruction",
keywords = "Coarse-to-fine registration",
keywords = "UAV aerial image ",
abstract = "Abstract Automatic change detection for urban buildings is very important for disaster assessment, map updating, etc. Height and color information is commonly used for change detection and existing methods use height information from 3D geometry model (e.g. Digital Surface Model, Geographic Information System) and color information from radiometric images captured by satellites or special aircrafts. However, they are either costly for timely change detection or sensitive to large illumination changes. With the rapid development of \{UAV\} technique, capturing the urban building images with high resolution camera at a low altitude becomes easier. In order to utilize these easily acquired aerial images, we propose a novel change detection framework with RGB-D map generated by 3D reconstruction, which can bear the large illumination change. Firstly, an image-based 3D reconstruction is applied to retrieve two point clouds and their related camera poses from two aerial image sets captured at different periods. Then, a RGB-D map could be generated from each 3D model, followed by a coarse-to-fine registration procedure to align the two reconstructed 3D point clouds together. At last, depth difference map and grayscale difference map could be generated from which we can use random forest classification and component connectivity analysis techniques to segment the changed building areas out. Experimental results have illustrated the effectiveness and applicability of the proposed framework. "
}
@article{Parisi2017208,
title = "Emergence of multimodal action representations from neural network self-organization ",
journal = "Cognitive Systems Research ",
volume = "43",
number = "",
pages = "208 - 221",
year = "2017",
note = "",
issn = "1389-0417",
doi = "https://doi.org/10.1016/j.cogsys.2016.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S138904171630050X",
author = "German I. Parisi and Jun Tani and Cornelius Weber and Stefan Wermter",
keywords = "Human action recognition",
keywords = "multimodal integration",
keywords = "self-organizing neural networks ",
abstract = "Abstract The integration of multisensory information plays a crucial role in autonomous robotics to forming robust and meaningful representations of the environment. In this work, we investigate how robust multimodal representations can naturally develop in a self-organizing manner from co-occurring multisensory inputs. We propose a hierarchical architecture with growing self-organizing neural networks for learning human actions from audiovisual inputs. The hierarchical processing of visual inputs allows to obtain progressively specialized neurons encoding latent spatiotemporal dynamics of the input, consistent with neurophysiological evidence for increasingly large temporal receptive windows in the human cortex. Associative links to bind unimodal representations are incrementally learned by a semi-supervised algorithm with bidirectional connectivity. Multimodal representations of actions are obtained using the co-activation of action features from video sequences and labels from automatic speech recognition. Experimental results on a dataset of 10 full-body actions show that our system achieves state-of-the-art classification performance without requiring the manual segmentation of training samples, and that congruent visual representations can be retrieved from recognized speech in the absence of visual stimuli. Together, these results show that our hierarchical neural architecture accounts for the development of robust multimodal representations from dynamic audiovisual inputs. "
}
@article{Ortega201027,
title = "A solution to the Path Planning problem using angle preprocessing ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "1",
pages = "27 - 36",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.07.028",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001183",
author = "Lidia M. Ortega and Antonio J. Rueda and Francisco R. Feito",
keywords = "Plane tessellation",
keywords = "Polar diagram",
keywords = "Visibility ",
abstract = "The Path Planning problem is a common topic for Robotics and Computational Geometry. Many important results have been found to this classic problem, some of them based on plane or space tessellation. The new approach we propose in this paper computes a partition of the plane called the Polar Diagram, using angle properties as criterion of construction. Compared to some other plane partitions as Voronoi Diagrams, this tessellation can be computed much more efficiently for different geometric objects. The polar diagram used as preprocessing can be applied to many geometric problems where the solution can be given by angle processing, such as Visibility or Path Planning problems. "
}
@article{Shean2016101,
title = "An automated, open-source pipeline for mass production of digital elevation models (DEMs) from very-high-resolution commercial stereo satellite imagery ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "116",
number = "",
pages = "101 - 117",
year = "2016",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2016.03.012",
url = "http://www.sciencedirect.com/science/article/pii/S0924271616300107",
author = "David E. Shean and Oleg Alexandrov and Zachary M. Moratto and Benjamin E. Smith and Ian R. Joughin and Claire Porter and Paul Morin",
keywords = "WorldView",
keywords = "Photogrammetry",
keywords = "Stereo reconstruction",
keywords = "Topography",
keywords = "Cryosphere",
keywords = "Ice sheet ",
abstract = "Abstract We adapted the automated, open source \{NASA\} Ames Stereo Pipeline (ASP) to generate digital elevation models (DEMs) and orthoimages from very-high-resolution (VHR) commercial imagery of the Earth. These modifications include support for rigorous and rational polynomial coefficient (RPC) sensor models, sensor geometry correction, bundle adjustment, point cloud co-registration, and significant improvements to the \{ASP\} code base. We outline a processing workflow for ∼0.5 m ground sample distance (GSD) DigitalGlobe WorldView-1 and WorldView-2 along-track stereo image data, with an overview of \{ASP\} capabilities, an evaluation of \{ASP\} correlator options, benchmark test results, and two case studies of \{DEM\} accuracy. Output \{DEM\} products are posted at ∼2 m with direct geolocation accuracy of &lt;5.0 m CE90/LE90. An automated iterative closest-point (ICP) co-registration tool reduces absolute vertical and horizontal error to &lt;0.5 m where appropriate ground-control data are available, with observed standard deviation of ∼0.1–0.5 m for overlapping, co-registered \{DEMs\} (n = 14, 17). While \{ASP\} can be used to process individual stereo pairs on a local workstation, the methods presented here were developed for large-scale batch processing in a high-performance computing environment. We are leveraging these resources to produce dense time series and regional mosaics for the Earth’s polar regions. "
}
@article{Chen2017228,
title = "Self-adaptive architecture evolution with model checking: A software cybernetics approach ",
journal = "Journal of Systems and Software ",
volume = "124",
number = "",
pages = "228 - 246",
year = "2017",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S0164121216000820",
author = "Luxi Chen and Linpeng Huang and Chen Li and Xiwen Wu",
keywords = "Self-adaptive software architecture",
keywords = "Model checking",
keywords = "Software cybernetics",
keywords = "Architecture evolution ",
abstract = "Abstract The cloud computing era requires software architecture to be self-adaptive to the dynamic environment. This autonomous feature brings uncertainty and makes software behavior difficult to control. The uncontrollable behavior is caused by ill-defined architecture and might lead to system disruption. To address this problem, we propose a novel framework which applies software cybernetics to guide self-adaptive architecture evolution. In our framework, we formulate the architecture evolution process as a feedback control process. In the process, we take the self-adaptive architecture model and the model checking technique as the controlled object and controller, respectively. First, the self-adaptive architecture is specified by Breeze/ADL. Second, the framework leverages model checking to validate adaptive Breeze/ADL specifications. Third, a learning algorithm is designed to regulate validation results to generate feedback rules – Productions to guide the architecture evolution. A smart phone application example is chosen to demonstrate the feasibility of our framework. The results show that our framework facilitates architects to detect undesired states which are caused by error-prone adaptation rules. "
}
@article{Bibi2017126,
title = "Characterization of absorbing aerosol types using ground and satellites based observations over an urban environment ",
journal = "Atmospheric Environment ",
volume = "150",
number = "",
pages = "126 - 135",
year = "2017",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.11.052",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016309438",
author = "Samina Bibi and Khan Alam and Farrukh Chishtie and Humera Bibi",
keywords = "FMF",
keywords = "AE",
keywords = "AI",
keywords = "AAE",
keywords = "SSA",
keywords = "Absorbing aerosol ",
abstract = "Abstract In this paper, for the first time, an effort has been made to seasonally characterize the absorbing aerosols into different types using ground and satellite based observations. For this purpose, optical properties of aerosol retrieved from \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) and Ozone Monitoring Instrument (OMI) were utilized over Karachi for the period 2012 to 2014. Firstly, \{OMI\} \{AODabs\} was validated with \{AERONET\} \{AODabs\} and found to have a high degree of correlation. Then, based on this validation, characterization was conducted by analyzing aerosol Fine Mode Fraction (FMF), Angstrom Exponent (AE), Absorption Angstrom Exponent (AAE), Single Scattering Albedo (SSA) and Aerosol Index (AI) and their mutual correlation, to identify the absorbing aerosol types and also to examine the variability in seasonal distribution. The absorbing aerosols were characterized into Mostly Black Carbon (BC), Mostly Dust and Mixed \{BC\} &amp; Dust. The results revealed that Mostly \{BC\} aerosols contributed dominantly during winter and postmonsoon whereas, Mostly Dust were dominant during summer and premonsoon. These types of absorbing aerosol were also confirmed with \{MODerate\} resolution Imaging Spectroradiometer (MODIS) and Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) observations. "
}
@article{Palomer2013286,
title = "A Comparison of \{G2o\} Graph \{SLAM\} and \{EKF\} Pose Based \{SLAM\} with Bathymetry Grids ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "33",
pages = "286 - 291",
year = "2013",
note = "9th \{IFAC\} Conference on Control Applications in Marine Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130918-4-JP-3022.00065",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016461720",
author = "Albert Palomer and Pere Ridao and David Ribas and Angelos Mallios and Guillem Vallicrosa",
abstract = "Abstract This paper address the Simultaneous Localization and Mapping (SLAM) problem of an \{AUV\} using bathymetric maps. The algorithm compounds swath profiles of the seafloor with \{DVL\} navigation(dead-reckoning) to build surface patches (3D point clouds). An initial guess of the location of these point clouds is known a priori by means of the dead-reckoning solution. Whenever there is a significant overlap of two or more point clouds, the corresponding surface patches are registered among themselves using a probabilistic \{ICP\} algorithm. The outcome of the registration procedure is a set of constrains defining the relative position of the overlapping surface patches. Next, these constrains are used to optimize a pose graph using the \{G2o\} optimizer. The results are compared against our prior EKF-pose-based \{SLAM\} solution. Our results suggest that a better performance is achieved using \{EKF\} global optimization with respect to the \{G2o\} graph-SLAM solution. "
}
@article{Kaddah2016117,
title = "Road marking features extraction using the VIAPIX® system ",
journal = "Optics Communications ",
volume = "371",
number = "",
pages = "117 - 127",
year = "2016",
note = "",
issn = "0030-4018",
doi = "https://doi.org/10.1016/j.optcom.2016.03.065",
url = "http://www.sciencedirect.com/science/article/pii/S003040181630236X",
author = "W. Kaddah and Y. Ouerhani and A. Alfalou and M. Desthieux and C. Brosseau and C. Gutierrez",
keywords = "Optical correlation",
keywords = "POF filter",
keywords = "VIAPIX system",
keywords = "Road marks ",
abstract = "Abstract Precise extraction of road marking features is a critical task for autonomous urban driving, augmented driver assistance, and robotics technologies. In this study, we consider an autonomous system allowing us lane detection for marked urban roads and analysis of their features. The task is to relate the georeferencing of road markings from images obtained using the VIAPIX® system. Based on inverse perspective mapping and color segmentation to detect all white objects existing on this road, the present algorithm enables us to examine these images automatically and rapidly and also to get information on road marks, their surface conditions, and their georeferencing. This algorithm allows detecting all road markings and identifying some of them by making use of a phase-only correlation filter (POF). We illustrate this algorithm and its robustness by applying it to a variety of relevant scenarios. "
}
@article{NorouzzadehRavari201632,
title = "Reconstruction of B-spline curves and surfaces by adaptive group testing ",
journal = "Computer-Aided Design ",
volume = "74",
number = "",
pages = "32 - 44",
year = "2016",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2016.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S001044851600004X",
author = "Alireza Norouzzadeh Ravari and Hamid D. Taghirad",
keywords = "B-spline curve and surface fitting",
keywords = "Akaike Information Criterion",
keywords = "Salient points",
keywords = "Iterative approximation",
keywords = "Group testing ",
abstract = "Abstract Point clouds as measurements of 3D sensors have many applications in various fields such as object modeling, environment mapping and surface representation. Storage and processing of raw point clouds is time consuming and computationally expensive. In addition, their high dimensionality shall be considered, which results in the well known curse of dimensionality. Conventional methods either apply reduction or approximation to the captured point clouds in order to make the data processing tractable. B-spline curves and surfaces can effectively represent 2D data points and 3D point clouds for most applications. Since processing all available data for B-spline curve or surface fitting is not efficient, based on the Group Testing theory an algorithm is developed that finds salient points sequentially. The B-spline curve or surface models are updated by adding a new salient point to the fitting process iteratively until the Akaike Information Criterion (AIC) is met. Also, it has been proved that the proposed method finds a unique solution so as what is defined in the group testing theory. From the experimental results the applicability and performance improvement of the proposed method in relation to some state-of-the-art B-spline curve and surface fitting methods, may be concluded. "
}
@article{Correal20142043,
title = "Automatic expert system for 3D terrain reconstruction based on stereo vision and histogram matching ",
journal = "Expert Systems with Applications ",
volume = "41",
number = "4, Part 2",
pages = "2043 - 2051",
year = "2014",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2013.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0957417413007227",
author = "R. Correal and G. Pajares and J.J. Ruz",
keywords = "Expert system",
keywords = "Terrain reconstruction",
keywords = "Histogram matching",
keywords = "Stereo vision",
keywords = "Image processing ",
abstract = "Abstract This paper proposes an automatic expert system for 3D terrain reconstruction and automatic intensity correction in stereo pairs of images based on histogram matching. Different applications in robotics, particularly those based on autonomous navigation in rough and natural environments, require a high-quality reconstruction of the surface. The stereo vision system is designed with a defined geometry and installed onboard a mobile robot, together with other sensors such as an Inertial Measurement Unit (IMU), necessary for sensor fusion. It is generally assumed the intensities of corresponding points in two images of a stereo pair are equal. However, this assumption is often false, even though they are acquired from a vision system composed of two identical cameras. We have also found this issue in our dataset. Because of the above undesired effects the stereo matching process is significantly affected, as many correspondence algorithms are very sensitive to these deviations in the brightness pattern, resulting in an inaccurate terrain reconstruction. The proposed expert system exploits the human knowledge which is mapped into three modules based on image processing techniques. The first one is intended for correcting intensities of the stereo pair coordinately, adjusting one as a function of the other. The second one is based in computing disparity, obtaining a set of correspondences. The last one computes a reconstruction of the terrain by reprojecting the computed points to 2D and applying a series of geometrical transformations. The performance of this method is verified favorably. "
}
@article{Bohan2017,
title = "Next-Generation Global Biomonitoring: Large-scale, Automated Reconstruction of Ecological Networks ",
journal = "Trends in Ecology & Evolution ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0169-5347",
doi = "https://doi.org/10.1016/j.tree.2017.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169534717300605",
author = "David A. Bohan and Corinne Vacher and Alireza Tamaddoni-Nezhad and Alan Raybould and Alex J. Dumbrell and Guy Woodward",
abstract = "We foresee a new global-scale, ecological approach to biomonitoring emerging within the next decade that can detect ecosystem change accurately, cheaply, and generically. Next-generation sequencing of \{DNA\} sampled from the Earth’s environments would provide data for the relative abundance of operational taxonomic units or ecological functions. Machine-learning methods would then be used to reconstruct the ecological networks of interactions implicit in the raw \{NGS\} data. Ultimately, we envision the development of autonomous samplers that would sample nucleic acids and upload \{NGS\} sequence data to the cloud for network reconstruction. Large numbers of these samplers, in a global array, would allow sensitive automated biomonitoring of the Earth’s major ecosystems at high spatial and temporal resolution, revolutionising our understanding of ecosystem change. "
}
@article{Wan2017,
title = "Teaching robots to do object assembly using multi-modal 3D vision ",
journal = "Neurocomputing ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.01.077",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217302497",
author = "Weiwei Wan and Feng Lu and Zepei Wu and Kensuke Harada",
keywords = "3D visual detection",
keywords = "Robot manipulation",
keywords = "Motion planning ",
abstract = "Abstract The motivation of this paper is to develop an intelligent robot assembly system using multi-modal vision for next-generation industrial assembly. The system includes two phases where in the first phase human beings demonstrate assembly to robots and in the second phase robots detect objects, plan grasps, and assemble objects following human demonstration using \{AI\} searching. A notorious difficulty to implement such a system is the bad precision of 3D visual detection. This paper presents multi-modal approaches to overcome the difficulty: It uses \{AR\} markers in the teaching phase to detect human operation, and uses point clouds and geometric constraints in the robot execution phase to avoid unexpected occlusion and noises. The paper presents several experiments to examine the precision and correctness of the approaches. It demonstrates the applicability of the approaches by integrating them with graph model-based motion planning, and by executing the results on industrial robots in real-world scenarios. "
}
@article{Hongbo201679,
title = "Relay navigation strategy study on intelligent drive on urban roads ",
journal = "The Journal of China Universities of Posts and Telecommunications ",
volume = "23",
number = "2",
pages = "79 - 90",
year = "2016",
note = "",
issn = "1005-8885",
doi = "https://doi.org/10.1016/S1005-8885(16)60024-9",
url = "http://www.sciencedirect.com/science/article/pii/S1005888516600249",
author = "Gao Hongbo and Zhang Xinyu and An Lifeng and Liu Yuchao and Li Deyi",
keywords = "intelligent vehicle",
keywords = "intelligent drive",
keywords = "urban roads",
keywords = "relay navigation",
keywords = "strategy ",
abstract = "Abstract In order to solve navigation problem of intelligent vehicle driving on urban roads and to achieve the navigation in intersection area, intersection transition area and section area. The relay navigation strategy and algorithm can solve the navigation problem of intelligent vehicle driving in typical urban roads such as intersection area, intersection transition area and section area, realizing seamless handover among different typical areas. Bezier curve function model was introduced to different typical areas, which solved the self-adaption recognition problem in different typical areas and revised positional accuracy with the help of cloud computing positioning service. In order to explain the strategy implement, an instance based on the strategy was adopted. Instance analysis indicates that as for the navigation problem in intersection area, intersection transition area and section area, if the relay navigation strategy is utilized, the self-adaption recognition problem in different typical areas can be handled. Based on the relay navigation strategy, the drive of intelligent vehicle on urban roads can effectively solve the self-adaption recognition problem in different typical areas in urban and further solve driving problems of intelligent vehicle of the same category in urban roads. "
}
@article{Roca2013128,
title = "Low-cost aerial unit for outdoor inspection of building façades ",
journal = "Automation in Construction ",
volume = "36",
number = "",
pages = "128 - 135",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2013.08.020",
url = "http://www.sciencedirect.com/science/article/pii/S0926580513001477",
author = "D. Roca and S. Lagüela and L. Díaz-Vilariño and J. Armesto and P. Arias",
keywords = "UAV",
keywords = "3D modeling",
keywords = "Scanning sensors",
keywords = "Building envelope",
keywords = "Building openings ",
abstract = "Abstract Geometry of buildings is an essential measurement during energy inspections, since it has a great influence in the energy performance of the building. Given the difficult access presented to some areas of the buildings that make impossible their complete geometric characterization with terrestrial devices, Unmanned Aerial Vehicles (UAVs) stand as the solution for the acquisition of data both from façades and roofs. In this paper, the potential of \{UAV\} to building geometric inspection is analyzed by mounting a Kinect sensor for geometric data acquisition in three-dimensions. The resulting point cloud and 3D model are evaluated in order to validate the performance of the complete system. "
}
@article{DiCicco2015309,
title = "Non-parametric calibration for depth sensors ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "309 - 317",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001724",
author = "Maurilio Di Cicco and Luca Iocchi and Giorgio Grisetti",
keywords = "Calibration",
keywords = "Mobile robots",
keywords = "Depth camera ",
abstract = "Abstract \{RGBD\} sensors are commonly used in robotics applications for many purposes, including 3D reconstruction of the environment and mapping. In these tasks, uncalibrated sensors can generate poor quality results. In this paper we propose a quick and easy to use approach to estimate the undistortion function of \{RGBD\} sensors. Our approach does not rely on the knowledge of the sensor model, on the use of a specific calibration pattern or on external \{SLAM\} systems to track the device position. We compute an extensive representation of the undistortion function as well as its statistics and use machine learning methods for approximation of the undistortion function. We validated our approach on datasets acquired from different kinds of \{RGBD\} sensors and using a precise 3D ground truth. We also provide a procedure for evaluating the quality of the calibration using a mobile robot and a 2D laser range finder. The results clearly show the advantages in using sensor data calibrated with the method described in this paper. "
}
@article{Getuli2016542,
title = "A BIM-based Construction Supply Chain Framework for Monitoring Progress and Coordination of Site Activities ",
journal = "Procedia Engineering ",
volume = "164",
number = "",
pages = "542 - 549",
year = "2016",
note = "Selected papers from Creative Construction Conference 2016 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.11.656",
url = "http://www.sciencedirect.com/science/article/pii/S1877705816339972",
author = "Vito Getuli and Silvia Mastrolembo Ventura and Pietro Capone and Angelo L.C. Ciribini",
keywords = "building information modeling",
keywords = "field BIM",
keywords = "monitoring system",
keywords = "site management and control",
keywords = "supply chain management ",
abstract = "Abstract In spite of the growing implementation of Computer-aided technologies and Building Information Modeling (BIM) in \{AEC\} industry, building activities in construction sites are ineffectively monitored even now. Current formats of reporting and communicating the construction progress (e.g., textual progress reports, progress lines, and photographs) may not properly and quickly communicate the construction progress. In the proposed research the capability to communicate progress information right away and to share an Interactive Building Model (IBModel) are identified as the key components for successful management of the site and the supply chain network. This is carried out establishing the involved actors (Owner, Site Director, Site Safety Coordinator, Construction Companies and Suppliers) and setting them several options for the information management and visualization within the \{BIM\} environment. The monitoring system comes from the integration of the building and construction site model bestowing the visualization of site conditions on a set of graphical parametric rules, such as: chromatic visualization of building components referred to objects’ completion percentage; thematic views, automatically extracted and updated, representing the real site conditions; and so forth. The monitoring system, supported by the BIM-based visualization model and managed in a Cloud computing seems to be one of the right directions for improving safety condition on one hand and site productivity and control on the other one. "
}
@article{Piqueux2015332,
title = "Enumeration of Mars years and seasons since the beginning of telescopic exploration ",
journal = "Icarus ",
volume = "251",
number = "",
pages = "332 - 338",
year = "2015",
note = "Dynamic Mars ",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0019103514006940",
author = "Sylvain Piqueux and Shane Byrne and Hugh H. Kieffer and Timothy N. Titus and Candice J. Hansen",
keywords = "Mars",
keywords = "Mars, polar caps",
keywords = "Mars, atmosphere",
keywords = "Mars, climate ",
abstract = "Abstract A clarification for the enumeration of Mars years prior to 1955 is presented, along with a table providing the Julian Dates associated with Ls = 0° for Mars years −183 (beginning of the telescopic study of Mars) to 100. A practical algorithm for computing Ls as a function of the Julian Date is provided. No new science results are presented. "
}
@article{Pandey2010336,
title = "Extrinsic Calibration of a 3D Laser Scanner and an Omnidirectional Camera ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "16",
pages = "336 - 341",
year = "2010",
note = "7th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100906-3-IT-2019.00059",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016350790",
author = "Gaurav Pandey and James McBride and Silvio Savarese and Ryan Eustice",
keywords = "Sensor Calibration",
keywords = "3D Laser Scanner",
keywords = "Omnidirectional Camera ",
abstract = "Abstract We propose an approach for external calibration of a 3D laser scanner with an omnidirectional camera system. The utility of an accurate calibration is that it allows for precise co-registration between the camera imagery and the 3D point cloud. This association can be used to enhance various state of the art algorithms in computer vision and robotics. The extrinsic calibration technique used here is similar to the calibration of a 2D laser range finder and a single camera as proposed by Zhang (2004), but has been extended to the case where we have a 3D laser scanner and an omnidirectional camera system. The procedure requires a planar checkerboard pattern to be observed simultaneously from the laser scanner and the camera system from a minimum of 3 views. The normal of the planar surface and 3D points lying on the surface constrain the relative position and orientation of the laser scanner and the omnidirectional camera system. These constraints can be used to form a non-linear optimization problem that is solved for the extrinsic calibration parameters and the covariance associated with the estimated parameters. Results are presented for a real world data set collected by a vehicle mounted with a 3D laser scanner and an omnidirectional camera system. "
}
@article{Yang2017175,
title = "TOLDI: An effective and robust approach for 3D local shape description ",
journal = "Pattern Recognition ",
volume = "65",
number = "",
pages = "175 - 187",
year = "2017",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.11.019",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316303776",
author = "Jiaqi Yang and Qian Zhang and Yang Xiao and Zhiguo Cao",
keywords = "Local reference frame",
keywords = "Local feature descriptor",
keywords = "Shape retrieval",
keywords = "Object recognition",
keywords = "3D registration ",
abstract = "Abstract Feature description for the 3D local shape in the presence of noise, varying mesh resolutions, clutter and occlusion is a quite challenging task in 3D computer vision. This paper tackles the problem by proposing a new local reference frame (LRF) together with a novel triple orthogonal local depth images (TOLDI) representation, forming the \{TOLDI\} method for local shape description. Compared with previous methods, \{TOLDI\} manages to perform efficient, distinctive and robust description for the 3D local surface simultaneously under various feature matching contexts. The proposed \{LRF\} differs from many prior ones in its calculation of the z-axis and x-axis, the z-axis is calculated using the normal of the keypoint and the x-axis is computed by aggregating the weighted projection vectors of the radius neighbors. \{TOLDI\} feature descriptors are then obtained by concatenating three local depth images (LDI) captured from three orthogonal view planes in the \{LRF\} into feature vectors. The performance of our \{TOLDI\} approach is rigorously evaluated on several public datasets, which contain three major surface matching scenarios, namely shape retrieval, object recognition and 3D registration. Experimental results and comparisons with the state-of-the-arts validate the effectiveness, robustness, high efficiency, and overall superiority of our method. Our method is also applied to aligning 3D object and indoor scene point clouds obtained by different devices (i.e., LiDAR and Kinect), the accurate outcomes further confirm the effectiveness of our method. "
}
@article{Watanabe201661,
title = "A Framework to Evaluate the Performance of a New Industrial Business Model ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "31",
pages = "61 - 66",
year = "2016",
note = "12th \{IFAC\} Workshop on Intelligent Manufacturing Systems \{IMS\} 2016Austin, Texas, USA, 5—7 December 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.12.162",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316328336",
author = "Edson H. Watanabe and Robson M. da Silva and Marcos S.G. Tsuzuki and Fabricio Junqueira and Diolino J. dos Santos Filho and Paulo E. Miyagi",
keywords = "Sustainable manufacturing",
keywords = "performance evaluation",
keywords = "cyber physical system",
keywords = "business model ",
abstract = "Abstract: In a new industrial business model, all aspects of sustainability, i.e. (i) environmental for reduction of negative impacts of using resources, (ii) economic for viability and profitability of business, (iii) social for assuring the safety of employees, communities and consumers, and (iv) technological for efficient and safe use of production resources, need to be effectively incorporated in the productive activities. On the other hand, existing decision-making structures in industries do not explicitly consider how to deal with sustainability indicators when developing a productive system (PS) and its control system. Therefore, this paper discusses the components of a framework and their interactions to apply new concepts to evaluate performance in industrial \{PSs\} considering the indicators to qualify and to quantify their sustainability. The framework adopts the Petri net technique and extensions of the ANSI/ISA 95 standard to systemize the evaluation process. This approach assures a formal way to verify and to validate the system sustainability. Besides, the framework considers information processing, storage and access flows between each system component under Cyber Physical System (CPS) and Cloud Computing concepts. "
}
@article{Bibi2016106,
title = "In-depth discrimination of aerosol types using multiple clustering techniques over four locations in Indo-Gangetic plains ",
journal = "Atmospheric Research ",
volume = "181",
number = "",
pages = "106 - 114",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.06.017",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516301703",
author = "Humera Bibi and Khan Alam and Samina Bibi",
keywords = "Aerosol Optical Depth",
keywords = "Angstrom Exponent",
keywords = "Single Scattering Albedo",
keywords = "Refractive Index",
keywords = "Dust",
keywords = "Biomass burning",
keywords = "Urban industrial ",
abstract = "Abstract Discrimination of aerosol types is essential over the Indo-Gangetic plain (IGP) because several aerosol types originate from different sources having different atmospheric impacts. In this paper, we analyzed a seasonal discrimination of aerosol types by multiple clustering techniques using \{AERosol\} \{RObotic\} \{NETwork\} (AERONET) datasets for the period 2007–2013 over Karachi, Lahore, Jaipur and Kanpur. We discriminated the aerosols into three major types; dust, biomass burning and urban/industrial. The discrimination was carried out by analyzing different aerosol optical properties such as Aerosol Optical Depth (AOD), Angstrom Exponent (AE), Extinction Angstrom Exponent (EAE), Abortion Angstrom Exponent (AAE), Single Scattering Albedo (SSA) and Real Refractive Index (RRI) and their interrelationship to investigate the dominant aerosol types and to examine the variation in their seasonal distribution. The results revealed that during summer and pre-monsoon, dust aerosols were dominant while during winter and post-monsoon prevailing aerosols were biomass burning and urban industrial, and the mixed type of aerosols were present in all seasons. These types of aerosol discriminated from \{AERONET\} were in good agreement with \{CALIPSO\} (the Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation) measurement. "
}
@article{Vermote201646,
title = "Preliminary analysis of the performance of the Landsat 8/OLI land surface reflectance product ",
journal = "Remote Sensing of Environment ",
volume = "185",
number = "",
pages = "46 - 56",
year = "2016",
note = "Landsat 8 Science Results ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716301572",
author = "Eric Vermote and Chris Justice and Martin Claverie and Belen Franch",
abstract = "Abstract The surface reflectance, i.e., satellite derived top of atmosphere (TOA) reflectance corrected for the temporally, spatially and spectrally varying scattering and absorbing effects of atmospheric gases and aerosols, is needed to monitor the land surface reliably. For this reason, the surface reflectance, and not \{TOA\} reflectance, is used to generate the greater majority of global land products, for example, from the Moderate Resolution Imaging Spectroradiometer (MODIS) and Visible Infrared Imaging Radiometer Suite (VIIRS) sensors. Even if atmospheric effects are minimized by sensor design, atmospheric effects are still challenging to correct. In particular, the strong impact of aerosols in the visible and near infrared spectral range can be difficult to correct, because they can be highly discrete in space and time (e.g., smoke plumes) and because of the complex scattering and absorbing properties of aerosols that vary spectrally and with aerosol size, shape, chemistry and density. This paper presents the Landsat 8 Operational Land Imager (OLI) atmospheric correction algorithm that has been developed using the Second Simulation of the Satellite Signal in the Solar Spectrum Vectorial (6SV) model, refined to take advantage of the narrow \{OLI\} spectral bands (compared to Thematic Mapper/Enhanced Thematic Mapper (TM/ETM +)), improved radiometric resolution and signal-to-noise. In addition, the algorithm uses the new \{OLI\} Coastal aerosol band (0.433–0.450 μm), which is particularly helpful for retrieving aerosol properties, as it covers shorter wavelengths than the conventional Landsat, \{TM\} and \{ETM\} + blue bands. A cloud and cloud shadow mask has also been developed using the “cirrus” band (1.360–1.390 μm) available on OLI, and the thermal infrared bands from the Thermal Infrared Sensor (TIRS) instrument. The performance of the surface reflectance product from \{OLI\} is analyzed over the Aerosol Robotic Network (AERONET) sites using accurate atmospheric correction (based on in situ measurements of the atmospheric properties), by comparison with the \{MODIS\} Bidirectional Reflectance Distribution Function (BRDF) adjusted surface reflectance product and by comparison of \{OLI\} derived broadband albedo from United States Surface Radiation Budget Network (US SURFRAD) measurements. The results presented clearly show an improvement of Landsat 8 surface reflectance product over the ad-hoc Landsat 5/7 \{LEDAPS\} product. "
}
@article{Uddin2017,
title = "A facial expression recognition system using robust face features from depth videos and deep learning ",
journal = "Computers & Electrical Engineering ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2017.04.019",
url = "http://www.sciencedirect.com/science/article/pii/S0045790617310613",
author = "Md. Zia Uddin and Mohammed Mehedi Hassan and Ahmad Almogren and Mansour Zuair and Giancarlo Fortino and Jim Torresen",
keywords = "Depth image",
keywords = "Facial expression recognition",
keywords = "Modified local directional patterns",
keywords = "Generalized discriminant analysis",
keywords = "Deep belief network ",
abstract = "Abstract This work proposes a depth camera-based robust facial expression recognition (FER) system that can be adopted for better human machine interaction. Although video-based facial expression analysis has been focused on by many researchers, there are still various problems to be solved in this regard such as noise due to illumination variations over time. Depth video data in the helps to make an \{FER\} system person-independent as pixel values in depth images are distributed based on distances from a depth camera. Besides, depth images should resolve some privacy issues as real identity of a user can be hidden. The accuracy of an \{FER\} system is much dependent on the extraction of robust features. Here, we propose a novel method to extract salient features from depth faces that are further combined with deep learning for efficient training and recognition. Eight directional strengths are obtained for each pixel in a depth image where signs of some top strengths are arranged to represent unique as well as robust face features, which can be denoted as Modified Local Directional Patterns (MLDP). The \{MLDP\} features are further processed by Generalized Discriminant Analysis (GDA) for better face feature extraction. \{GDA\} is an efficient tool that helps distinguishing \{MLDP\} features of different facial expressions by clustering the features from the same expression as close as possible and separating the features from different expressions as much as possible in a non-linear space. Then, MLDP-GDA features are applied with Deep Belief Network (DBN) for training different facial expressions. Finally, the trained \{DBN\} is used to recognize facial expressions in a depth video for testing. The proposed approach was compared with other traditional approaches in a standalone system where the proposed one showed its superiority by achieving mean recognition rate of 96.25% where the other approaches could make 91.67% at the best. The deep learning-based training and recognition of the facial expression features can also be undertaken with cloud computing to support many users and make the system faster than a standalone system. "
}
@article{Huang2014497,
title = "Occlusion-aware multi-view reconstruction of articulated objects for manipulation ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "4",
pages = "497 - 505",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013002340",
author = "Xiaoxia Huang and Ian Walker and Stan Birchfield",
keywords = "Articulated reconstruction",
keywords = "3D reconstruction",
keywords = "Procrustes analysis",
keywords = "Locally optimized \{RANSAC\} ",
abstract = "Abstract We present an algorithm called Procrustes-Lo-RANSAC (PLR) to recover complete 3D models of articulated objects. Structure-from-motion techniques are used to capture 3D point cloud models of an object in two different configurations. Procrustes analysis, combined with a locally optimized \{RANSAC\} sampling strategy, facilitates a straightforward geometric approach to recovering the joint axes, as well as classifying them automatically as either revolute or prismatic. With the resulting articulated model, a robotic system is then able to manipulate the object along its joint axes at a specified grasp point in order to exercise its degrees of freedom. Because the models capture all sides of the object, they are occlusion-aware, meaning that the robot has knowledge of parts of the object that are not visible in the current view. Our algorithm does not require prior knowledge of the object, nor does it make any assumptions about the planarity of the object or scene. Experiments with a PUMA 500 robotic arm demonstrate the effectiveness of the approach on a variety of real-world objects containing both revolute and prismatic joints. "
}
@incollection{Brecher2017321,
title = "Chapter 21 - The Need of Dynamic and Adaptive Data Models for Cyber-Physical Production Systems ",
editor = "Song, Houbing and Rawat, Danda B. and Jeschke, Sabina  and Brecher, Christian ",
booktitle = "Cyber-Physical Systems ",
publisher = "Academic Press",
edition = "",
address = "Boston",
year = "2017",
pages = "321 - 338",
series = "Intelligent Data-Centric Systems",
isbn = "978-0-12-803801-7",
doi = "https://doi.org/10.1016/B978-0-12-803801-7.00021-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128038017000213",
author = "C. Brecher and C. Ecker and W. Herfs and M. Obdenbusch and S. Jeschke and M. Hoffmann and T. Meisen",
keywords = "Cyber-physical production systems",
keywords = "Industrie 4.0",
keywords = "Automation",
keywords = "Industrial communication",
keywords = "Assembly",
keywords = "Condition monitoring",
keywords = "Big data",
keywords = "Product life cycle management",
keywords = "Human-robot interaction ",
abstract = "Abstract Cyber-physical production systems (CPPSs) are the fundamental basis for the realization of the German initiative “Industrie 4.0,” which covers not only the usage of intelligent embedded devices and their interconnectedness, but also models for describing different processes according to the product’s life cycle. This article focuses on challenges regarding the integration of different views on urgent aspects, technologies, and paradigms to formulate one consistent modeling approach. Different use cases then describe the application of modeling and implementation concepts as well as benefits of new possibilities for process control. These are: model-based human-robot interaction for flexible assembly automation, a cloud-based approach for advanced condition monitoring, and product-centered control in the Laboratory for Machine Tools and Production Engineering (WZL)’s Smart Automation Lab. "
}
@article{Zhang2016281,
title = "Local Surface Geometric Feature for 3D human action recognition ",
journal = "Neurocomputing ",
volume = "208",
number = "",
pages = "281 - 289",
year = "2016",
note = "SI: BridgingSemantic ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.12.122",
url = "http://www.sciencedirect.com/science/article/pii/S092523121630460X",
author = "Erhu Zhang and Wanjun Chen and Zhuomin Zhang and Yan Zhang",
keywords = "Human action recognition",
keywords = "Depth map",
keywords = "Skeleton joint",
keywords = "Local Surface Geometric Feature (LSGF)",
keywords = "Covariance descriptor ",
abstract = "Abstract This paper presents a novel Local Surface Geometric Feature (LSGF) for human action recognition from video sequences captured by a depth camera. The \{LSGF\} is extracted from each skeleton joint in point cloud space to capture the static appearance and pose cues, which includes joint position, normal, and local curvature. A temporal pyramid of covariance matrix is exploited to model both pairwise relations of features instead of features themselves and the temporal evolution. Finally, Fisher vector encoding is imported as a global representation for a video sequence and \{SVM\} classifier is used for classification. In the extensive experiments, we achieve classification results superior to most of previous published results on three public benchmark datasets, i.e., MSR-Action3D, \{MSR\} DailyActivity3D, and \{UTKinect\} Action. "
}
@article{Chavez2017,
title = "Measurements of pCO2 and pH from an autonomous surface vehicle in a coastal upwelling system ",
journal = "Deep Sea Research Part II: Topical Studies in Oceanography ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0967-0645",
doi = "https://doi.org/10.1016/j.dsr2.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S0967064516302338",
author = "Francisco P. Chavez and Jeff Sevadjian and Chris Wahl and Jules Friederich and Gernot E. Friederich",
keywords = "Carbon dioxide",
keywords = "pH",
keywords = "Upwelling",
keywords = "Autonomous surface vehicle",
keywords = "Wave Glider",
keywords = "USA",
keywords = "California",
keywords = "Monterey Bay ",
abstract = "Abstract Anthropogenic input of carbon dioxide (CO2) into the atmosphere and its uptake by the ocean with associated changes in ocean chemistry have created an urgent need to expand coverage of sea surface and atmospheric carbon dioxide observations. Conventional sampling platforms (e.g. ships and moorings) do not provide the spatial and temporal resolution needed to assess the effects of rapidly changing carbon dioxide conditions and are expensive to operate. Through a series of deployments beginning in March 2012, two versions of the Wave Glider autonomous surface vehicles from Liquid Robotics, Inc. have been instrumented with sensors to measure pH, partial pressure of \{CO2\} (pCO2) of the atmosphere and sea surface, and wind speed and direction, from which instantaneous sea-air fluxes of \{CO2\} can be calculated. These deployments, most near Monterey Bay, California, were highly correlated with ΔpCO2 measurements obtained from the Monterey Bay Aquarium Research Institute's (MBARI) long-term mooring station M1, as well as from shipboard observations. In the central California upwelling system with highly variable pCO2 levels, the gliders captured large spatial gradients associated with upwelling fronts. Differences in sea surface pCO2 as large as 470 μatm over &lt; 0.5 km were observed. Unlike traditional ship sampling methods, however, this new generation of sampling platforms is capable of continuous long-term (months) deployments at a fraction of the cost. The vehicles thus have the potential of filling important gaps in present understanding of the effects of global change on ocean chemistry. "
}
@article{Büttner201693,
title = "Automatic scene parsing for generic object descriptions using shape primitives ",
journal = "Robotics and Autonomous Systems ",
volume = "76",
number = "",
pages = "93 - 112",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002584",
author = "Stefan Büttner and Zoltán-Csaba Márton and Katharina Hertkorn",
keywords = "Sample consensus",
keywords = "Shape primitives",
keywords = "3D models",
keywords = "Task specification ",
abstract = "Abstract Autonomous robots need to generate complete 3D models from a limited range of view when trying to manipulate objects for which no model is known a priori. This can be achieved by detecting symmetrical parts of an object, thus, creating an estimate of the invisible back sides. These symmetrical parts are typically modeled as primitive shapes (cylinders, spheres, cones, etc.), and fitted to noisy sensor data using sample consensus methods. This has the advantage that feasible grasps can be chosen from a precomputed set based on the estimated model, instead of a time-consuming random sampling approach. This article will look at fitting such analytic models to noisy 3D data in the context of robotic manipulation. State of the art methods from the Point Cloud Library (PCL) were extended to include additional relevant shapes (e.g. boxes), constraints (e.g. on size and orientation), and to consider additional information like knowledge about free space or proprioceptive information. A core part of the approach is the development of a scene parsing language, that allows for an easy-to-use pipeline specification during autonomous operation as well as shared-autonomy scenarios. Experiments will be presented based on scenes captured using an Xtion sensor. "
}
@article{Chen20143,
title = "Machine-to-machine communications: Technologies and challenges ",
journal = "Ad Hoc Networks ",
volume = "18",
number = "",
pages = "3 - 23",
year = "2014",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2013.03.007",
url = "http://www.sciencedirect.com/science/article/pii/S1570870513000395",
author = "Kwang-Cheng Chen and Shao-Yu Lien",
keywords = "Machine-to-machine communications",
keywords = "Internet of Things",
keywords = "Cyber–physical systems",
keywords = "Multi-hop networks",
keywords = "Cognitive radio",
keywords = "Spectrum sharing",
keywords = "Swarm communications ",
abstract = "Abstract Machine-to-machine (M2M) communications emerge to autonomously operate to link interactions between Internet cyber world and physical systems. We present the technological scenario of \{M2M\} communications consisting of wireless infrastructure to cloud, and machine swarm of tremendous devices. Related technologies toward practical realization are explored to complete fundamental understanding and engineering knowledge of this new communication and networking technology front. "
}
@article{Mills2016615,
title = "Wearing safe: Physical and informational security in the age of the wearable device ",
journal = "Business Horizons ",
volume = "59",
number = "6",
pages = "615 - 622",
year = "2016",
note = "\{CYBERSECURITY\} \{IN\} 2016: PEOPLE, TECHNOLOGY, \{AND\} \{PROCESSES\} ",
issn = "0007-6813",
doi = "https://doi.org/10.1016/j.bushor.2016.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S0007681316300805",
author = "Adam J. Mills and Richard T. Watson and Leyland Pitt and Jan Kietzmann",
keywords = "Wearable technology",
keywords = "Wearables",
keywords = "Information security",
keywords = "Cybersecurity ",
abstract = "Abstract Wearable computing devices promise to deliver countless benefits to users. Moreover, they are among the most personal and unique computing devices of all, more so than laptops and tablets and even more so than smartphones. However, this uniqueness also brings with it a risk of security issues not encountered previously in information systems: the potential to not only compromise data, but also to physically harm the wearer. This article considers wearable device security from three perspectives: whether the threat is to the device and/or the individual, the role that the wearable device plays, and how holistic wearable device security strategies can be developed and monitored. "
}
@article{Zhang20161456,
title = "BIM-enabled Modular and Industrialized Construction in China ",
journal = "Procedia Engineering ",
volume = "145",
number = "",
pages = "1456 - 1461",
year = "2016",
note = "\{ICSDEC\} 2016 – Integrating Data Science, Construction and Sustainability ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2016.04.183",
url = "http://www.sciencedirect.com/science/article/pii/S1877705816301904",
author = "Jinyue Zhang and Yating Long and Siquan Lv and Yunchao Xiang",
keywords = "Modular Construction",
keywords = "Industrialization of Construction",
keywords = "BIM",
keywords = "China ",
abstract = "Abstract Old-fashioned construction methods in China lead to many issues such as low field productivity, unreliable quality, high resource and energy consumption, frequent safety accidents, and significant environmental pollution. The concept of industrialization of construction has been recognized since the 1950's, but was not well developed until recently when the industry came under the pressure of increasing labour costs and the demand for sustainable development. There was a surge of Building Information Modeling (BIM) application in the last few years in China, and the industry has seen the many benefits of virtual design and construction. Integrating \{BIM\} technology into the industrialization of construction is seen as a promising opportunity to improve the performance of modular and industrialized construction. This paper first reviews the history of the industrialization of the Chinese construction industry, and then discusses the recent \{BIM\} adoption in China. The main focus of this paper is using \{BIM\} to support modular design and industrialized construction and installation in China. The use of some advanced hardware tools is also discussed, including the use of 3D laser scanners to collect as-built data and establish a point cloud model for better \{MEP\} system coordination, and the use of a robotic total station for fast installation. "
}
@article{Bakambu2006103,
title = "3D \{MAP\} \{BUILDING\} \{FOR\} \{PLANETARY\} \{ROVER\} \{LOCALIZATION\} \{AND\} \{PATH\} \{PLANNING\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "39",
number = "15",
pages = "103 - 108",
year = "2006",
note = "8th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20060906-3-IT-2910.00019",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016384981",
author = "Joseph Nsasi Bakambu and Pierre Allard and Erick Dupuis",
keywords = "mobile robot",
keywords = "autonomous navigation",
keywords = "3D localization",
keywords = "path planning ",
abstract = "Abstract This paper considers the problem of constructing a 3D environment model for space robotics applications. We presented our approach to 3D environment reconstruction from large sparse range data sets. In space robotics applications an accurate and up-to-date model of the environment is very important for variety of reasons. In particular, the model can be used for safe tele-operation, path planning and mapping of points of interest. We propose an on-line reconstruction of the environment using data provided by an on-board 3D range sensor LIDAR. The experiment results demonstrated the effectiveness of our approach in localization, path planning and following scenario on the Mars Yard located at Canadian Space Agency. "
}
@article{Kim20096058,
title = "Weekly periodicities of meteorological variables and their possible association with aerosols in Korea ",
journal = "Atmospheric Environment ",
volume = "43",
number = "38",
pages = "6058 - 6065",
year = "2009",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2009.08.023",
url = "http://www.sciencedirect.com/science/article/pii/S1352231009007353",
author = "Byung-Gon Kim and Min-Hyeok Choi and Chang-Hoi Ho",
keywords = "Weekly periodicities",
keywords = "Diurnal temperature range",
keywords = "Meteorological variables",
keywords = "Aerosols",
keywords = "Korea ",
abstract = "The weekly periodicities in meteorological variables and its association with aerosols in Korea are investigated using long-term surface measurements of meteorology (1975–2005) and aerosols (1999–2005). Through an analysis of the annual (and/or seasonal) values averaged over 10 stations, we identified distinct weekly periodicities in the daily minimum temperature (Tmin), diurnal temperature range (DTR), cloud fraction, and solar insolation, although they have different characteristics from each other. The weekly association among variables is discussed in this study. Positive anomalies of the cloud fraction and Tmin and negative anomalies of solar insolation and \{DTR\} are seen for the second half of the week and the reverse for the first half of the week, i.e., more cloudiness and less insolation for Wednesday−Thursday and less cloudiness and more insolation for Monday−Tuesday. Furthermore, seasonal dependence of weekly anomalies shows that the weekly periodicities are enhanced especially in autumn, more than 2–3 times as great as those of the annual mean. The weekly cycles in such variables are most likely driven by changes in cloud fraction, possibly through aerosol–cloud interactions induced by aerosol variations between working weekdays and Sunday, which are clearly identified in \{PM10\} weekly cycles. This study also suggests that the weekly periodicities in meteorological variables are possibly associated with long-range transport of weekly periodicities, as well as aerosol–cloud-precipitation interactions over the region. "
}
@article{Kierzynka2017455,
title = "Energy efficiency of sequence alignment tools—Software and hardware perspectives ",
journal = "Future Generation Computer Systems ",
volume = "67",
number = "",
pages = "455 - 465",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16301169",
author = "Michał Kierzynka and Lars Kosmann and Micha vor dem Berge and Stefan Krupop and Jens Hagemeyer and René Griessl and Meysam Peykanu and Ariel Oleksiak",
keywords = "Sequence alignment",
keywords = "Energy efficiency",
keywords = "FiPS project",
keywords = "Heterogeneous hardware",
keywords = "Bioinformatics",
keywords = "FPGA ",
abstract = "Abstract Pairwise sequence alignment is ubiquitous in modern bioinformatics. It may be performed either explicitly, e.g. to find the most similar sequences in a database, or implicitly as a hidden building block of more complex methods, e.g. for reads mapping. The alignment algorithms have been widely investigated over the last few years, mainly with respect to their speed. However, no attention was given to their energy efficiency, which is becoming critical in high performance computing and cloud environment. We compare the energy efficiency of the most established software tools performing exact pairwise sequence alignment on various computational architectures: CPU, \{GPU\} and Intel Xeon Phi. The results show that the energy consumption may differ as much as nearly 5 times. Substantial differences are reported even for different implementations running on the same hardware. Moreover, we present an \{FPGA\} implementation of one of the tested tools—G-DNA, and show how it outperforms all the others on the energy efficiency front. Finally, some details regarding the special RECS® | Box servers used in our study are outlined. This hardware is designed and manufactured within the FiPS project by the Bielefeld University and christmann informationstechnik + medien with a special purpose to deliver highly heterogeneous computational environment supporting energy efficiency and green ICT. "
}
@article{Fischinger2012787,
title = "Shape based Learning for Grasping Novel Objects in Cluttered Scenes ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "787 - 792",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00176",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016337053",
author = "David Fischinger and Markus Vincze",
keywords = "Manipulation tasks",
keywords = "Grasping",
keywords = "Learning algorithms ",
abstract = "Abstract This paper presents a novel approach to clearing a table with a heap of objects. Form, size, position, orientation and constellation of the objects are a priori unknown. Coping with incomplete point cloud data is an additional challenge. There are three key contributions. First, we introduce Height Accumulated Features (HAF) which provide an efficient way of calculating grasp related feature values. The second contribution is an extensible machine learning system for binary classification of grasp hypotheses based on raw point cloud data. Finally, a practical heuristic for selection of the most robust grasp hypothesis is introduced. We evaluate our system in experiments where a robot was required to autonomously clear a table with a heap of unknown objects. Despite the complexity of the scenarios, our system cleared the table each time without human interaction and with a grasp failure rate below three percent. "
}
@article{Andújar201667,
title = "Using depth cameras to extract structural parameters to assess the growth state and yield of cauliflower crops ",
journal = "Computers and Electronics in Agriculture ",
volume = "122",
number = "",
pages = "67 - 73",
year = "2016",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2016.01.018",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916000235",
author = "Dionisio Andújar and Angela Ribeiro and César Fernández-Quintanilla and José Dorado",
keywords = "Kinect",
keywords = "Plant structure characterization",
keywords = "Weight estimation",
keywords = "Volume estimation ",
abstract = "Abstract The use of robotic systems for horticultural crops is widely known. However, the use of these systems in cruciferous vegetables remains a challenge. The case of cauliflower crops is of special relevance because it is a hand-harvested crop for which the cutting time is visually chosen. This methodology leads to a yield reduction, as some inflorescences are cut before ripening because the leaves hide their real state of maturity. This work proposes the use of depth cameras instead of visual estimation. Using Kinect Fusion algorithms, depth cameras create a 3D point cloud from the depth video stream and consequently generate solid 3D models, which have been compared to the actual structural parameters of cauliflower plants. The results show good consistency among depth image models and ground truth from the actual structural parameters. In addition, the best time for individual fruit cutting could be detected using these models, which enabled the optimization of harvesting and increased yields. The accuracy of the models deviated from the ground truth by less than 2 cm in diameter/height, whereas the fruit volume estimation showed an error below 0.6% overestimation. Analysis of the structural parameters revealed a significant correlation between estimated and actual values of the volume of plants and fruit weight. These results show the potential of depth cameras to be used as a precise tool in estimating the degree of ripeness during the harvesting of cauliflower and thereby optimizing the crop profitability. "
}
@article{Ervin201612,
title = "Technology in geodesign ",
journal = "Landscape and Urban Planning ",
volume = "156",
number = "",
pages = "12 - 16",
year = "2016",
note = "Geodesign—Changing the world, changing design ",
issn = "0169-2046",
doi = "https://doi.org/10.1016/j.landurbplan.2016.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169204616301888",
author = "Stephen M. Ervin",
keywords = "Geodesign",
keywords = "Algorithmic processes",
keywords = "Collaboration",
keywords = "Dynamic modeling",
keywords = "Simulation",
keywords = "Systems thinking ",
abstract = "Abstract Based on an idealized model with six distinguishing criteria of geodesign projects -- large areas, complex issues, and multi-person teams; digital computing, algorithmic processes, and communications technologies; collaborative, information-based projects; timely feedback about impacts and implications of proposals; dynamic modeling and simulation; and systems thinking -- the technological supports required for each of these criteria are described. "
}
@article{SavalCalvo2015572,
title = "Three-dimensional planar model estimation using multi-constraint knowledge based on k-means and \{RANSAC\} ",
journal = "Applied Soft Computing ",
volume = "34",
number = "",
pages = "572 - 586",
year = "2015",
note = "",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2015.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S1568494615003075",
author = "Marcelo Saval-Calvo and Jorge Azorin-Lopez and Andres Fuster-Guillo and Jose Garcia-Rodriguez",
keywords = "Computer vision",
keywords = "Model extraction",
keywords = "RANSAC multi-plane",
keywords = "Three-dimensional planes ",
abstract = "Abstract Plane model extraction from three-dimensional point clouds is a necessary step in many different applications such as planar object reconstruction, indoor mapping and indoor localization. Different \{RANdom\} \{SAmple\} Consensus (RANSAC)-based methods have been proposed for this purpose in recent years. In this study, we propose a novel method-based on \{RANSAC\} called Multiplane Model Estimation, which can estimate multiple plane models simultaneously from a noisy point cloud using the knowledge extracted from a scene (or an object) in order to reconstruct it accurately. This method comprises two steps: first, it clusters the data into planar faces that preserve some constraints defined by knowledge related to the object (e.g., the angles between faces); and second, the models of the planes are estimated based on these data using a novel multi-constraint RANSAC. We performed experiments in the clustering and \{RANSAC\} stages, which showed that the proposed method performed better than state-of-the-art methods. "
}
@article{d'Apolito201618,
title = "Control of a cost oriented humanoid robot ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "29",
pages = "18 - 23",
year = "2016",
note = "17th \{IFAC\} Conference on International Stability, Technology and Culture \{TECIS\} 2016Durrës, Albania, 26—28 October 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.064",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316324909",
author = "F. d'Apolito and Xh. Mehmeti and P. Kopacek",
keywords = "Robots",
keywords = "Control",
keywords = "Identification",
keywords = "Cost Orientation ",
abstract = "Abstract: The teen-sized humanoid robot "Archie" is developed by the Intelligent Handling and Robotics Department (IHRT) at the Technical University of Vienna. The main idea behind “Archie” is to develop a Cost Oriented Humanoid Robot (COHR) to assist humans in their daily life tasks. Currently, the robot consists of 18 degrees of freedom and is able to perform basic human-like walking motions. According to the scope of \{TECIS\} this robot is an excellent example for “Cost Orientation”. Until now the control of the joints was carried out by industrial controllers. These are expensive, heavy and have only limited possibilities for the implementation of advanced control algorithms. Therefore a new hard- and software control concept for the motors and the joints was developed. In order to find appropriate controller parameters the dynamic behavior of the joints is analyzed by means of a nonlinear system identification using a Hammerstein model. The result of the system identification shows that the dynamic behavior of the joints is \{PT1\} element with two nonlinearities, a dead zone and a nonlinear gain. Therefore a “piecewise linear” \{PI\} controller – the gain depends from the velocity – will be implemented on a \{COA\} processor. Finally an outlook on further works will be described. "
}
@article{Amunts2016574,
title = "The Human Brain Project: Creating a European Research Infrastructure to Decode the Human Brain ",
journal = "Neuron ",
volume = "92",
number = "3",
pages = "574 - 581",
year = "2016",
note = "",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2016.10.046",
url = "http://www.sciencedirect.com/science/article/pii/S0896627316307966",
author = "Katrin Amunts and Christoph Ebell and Jeff Muller and Martin Telefont and Alois Knoll and Thomas Lippert",
abstract = "Decoding the human brain is perhaps the most fascinating scientific challenge in the 21st century. The Human Brain Project (HBP), a 10-year European Flagship, targets the reconstruction of the brain’s multi-scale organization. It uses productive loops of experiments, medical, data, data analytics, and simulation on all levels that will eventually bridge the scales. The \{HBP\} \{IT\} architecture is unique, utilizing cloud-based collaboration and development platforms with databases, workflow systems, petabyte storage, and supercomputers. The \{HBP\} is developing toward a European research infrastructure advancing brain research, medicine, and brain-inspired information technology. "
}
@article{Jóźwiak2017202,
title = "Advanced mobile and wearable systems ",
journal = "Microprocessors and Microsystems ",
volume = "50",
number = "",
pages = "202 - 221",
year = "2017",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2017.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0141933117300741",
author = "Lech Jóźwiak",
keywords = "Cyber-physical systems",
keywords = "Mobile systems",
keywords = "Heterogeneous systems",
keywords = "Massively parallel systems",
keywords = "Multi-processor systems on a chip",
keywords = "Automated design technology ",
abstract = "Abstract The recent spectacular progress in the microelectronic, information, communication, material and sensor technologies created a big stimulus towards development of smart communicating cyber-physical systems (CPS) and Internet of Things (IoT). \{CPS\} and IoT are undergoing an explosive growth to a large degree related to advanced mobile systems like smart automotive and avionic systems, mobile robots and wearable devices. The huge and rapidly developing markets of sophisticated mobile cyber-physical systems represent great opportunities, but these opportunities come with a price of unusual system complexity, as well as, stringent and difficult to satisfy requirements of many modern applications. Specifically, smart cars and various wearable systems to a growing degree involve big instant data from multiple complex sensors or other systems, and are required to provide continuous autonomous service in a long time. In consequence, they demand a guaranteed (ultra-)high performance and/or (ultra-)low energy consumption, while requiring a high reliability, safety and security. To adequately address these demands, sophisticated embedded computing and embedded design technologies are needed. After an introduction to modern mobile systems, this paper discusses the huge heterogeneous area of these systems, and considers serious issues and challenges in their design. Subsequently, it discusses the embedded computing and design technologies needed to adequately address the issues and overcome the challenges in order to satisfy the stringent requirements of the modern mobile systems. "
}
@article{Metzger201677,
title = "Space development and space science together, an historic opportunity ",
journal = "Space Policy ",
volume = "37, Part 2",
number = "",
pages = "77 - 91",
year = "2016",
note = "The use of extraterrestrial resources to facilitate space science and exploration ",
issn = "0265-9646",
doi = "https://doi.org/10.1016/j.spacepol.2016.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0265964616300625",
author = "Philip T. Metzger",
keywords = "Space resources",
keywords = "Space mining",
keywords = "Space industry",
keywords = "Space development",
keywords = "Ethics ",
abstract = "Abstract The national space programs have an historic opportunity to help solve the global-scale economic and environmental problems of Earth while becoming more effective at science through the use of space resources. Space programs will be more cost-effective when they work to establish a supply chain in space, mining and manufacturing then replicating the assets of the supply chain so it grows to larger capacity. This has become achievable because of advances in robotics and artificial intelligence. It is roughly estimated that developing a lunar outpost that relies upon and also develops the supply chain will cost about 1/3 or less of the existing annual budgets of the national space programs. It will require a sustained commitment of several decades to complete, during which time science and exploration become increasingly effective. At the end, this space industry will capable of addressing global-scale challenges including limited resources, clean energy, economic development, and preservation of the environment. Other potential solutions, including nuclear fusion and terrestrial renewable energy sources, do not address the root problem of our limited globe and there are real questions whether they will be inadequate or too late. While industry in space likewise cannot provide perfect assurance, it is uniquely able to solve the root problem, and it gives us an important chance that we should grasp. What makes this such an historic opportunity is that the space-based solution is obtainable as a side-benefit of doing space science and exploration within their existing budgets. Thinking pragmatically, it may take some time for policymakers to agree that setting up a complete supply chain is an achievable goal, so this paper describes a strategy of incremental progress. The most crucial part of this strategy is establishing a water economy by mining on the Moon and asteroids to manufacture rocket propellant. Technologies that support a water economy will play an important role leading toward space development. "
}
@article{Li2012117,
title = "Temperature aware power allocation: An optimization framework and case studies ",
journal = "Sustainable Computing: Informatics and Systems ",
volume = "2",
number = "3",
pages = "117 - 127",
year = "2012",
note = "",
issn = "2210-5379",
doi = "https://doi.org/10.1016/j.suscom.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S2210537912000261",
author = "Shen Li and Shiguang Wang and Tarek Abdelzaher and Maria Kihl and Anders Robertsson",
keywords = "Data center",
keywords = "Map-reduce",
keywords = "Web-server",
keywords = "Thermal-aware optimization",
keywords = "Energy management ",
abstract = "In this paper, we propose a general power model along with a versatile optimization methodology that can be applied to different applications for minimizing service delay while satisfying power budget in data centers. We test our methodology on two totally different applications from both cloud computing and enterprise scenarios. Our solution is novel in that it takes into account the dependence of power consumption on temperature, attributed to temperature-induced changes in leakage current and fan speed. While this dependence is well-known, we are the first to consider it in the context of minimizing service delay. Accordingly, we implement our optimization strategies with Hadoop, Tomcat, and MySQL on a 40-node cluster. The experimental results show that our solution cannot only limit the power consumption to the power budget but also achieves smaller delay against static solutions and temperature oblivious \{DVFS\} solutions. "
}
@article{Nanni2016142,
title = "Ensemble of different approaches for a reliable person re-identification system ",
journal = "Applied Computing and Informatics ",
volume = "12",
number = "2",
pages = "142 - 153",
year = "2016",
note = "",
issn = "2210-8327",
doi = "https://doi.org/10.1016/j.aci.2015.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S2210832715000046",
author = "Loris Nanni and Matteo Munaro and Stefano Ghidoni and Emanuele Menegatti and Sheryl Brahnam",
keywords = "Person re-identification",
keywords = "Texture descriptors",
keywords = "Ensemble",
keywords = "Color space",
keywords = "Depth map ",
abstract = "Abstract An ensemble of approaches for reliable person re-identification is proposed in this paper. The proposed ensemble is built combining widely used person re-identification systems using different color spaces and some variants of state-of-the-art approaches that are proposed in this paper. Different descriptors are tested, and both texture and color features are extracted from the images; then the different descriptors are compared using different distance measures (e.g., the Euclidean distance, angle, and the Jeffrey distance). To improve performance, a method based on skeleton detection, extracted from the depth map, is also applied when the depth map is available. The proposed ensemble is validated on three widely used datasets (CAVIAR4REID, IAS, and VIPeR), keeping the same parameter set of each approach constant across all tests to avoid overfitting and to demonstrate that the proposed system can be considered a general-purpose person re-identification system. Our experimental results show that the proposed system offers significant improvements over baseline approaches. The source code used for the approaches tested in this paper will be available at https://www.dei.unipd.it/node/2357 and http://robotics.dei.unipd.it/reid/. "
}
@article{FernándezMoral2016649,
title = "Scene structure registration for localization and mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "649 - 660",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001979",
author = "Eduardo Fernández-Moral and Patrick Rives and Vicente Arévalo and Javier González-Jiménez",
keywords = "Scene registration",
keywords = "Scene recognition",
keywords = "Localization",
keywords = "Mapping",
keywords = "Planar segmentation ",
abstract = "Abstract Image registration, and more generally scene registration, needs to be solved in mobile robotics for a number of tasks including localization, mapping, object recognition, visual odometry and loop-closure. This paper presents a flexible strategy to register scenes based on its planar structure, which can be used with different sensors that acquire 3D data like LIDAR, time-of-flight cameras, RGB-D sensors and stereo vision. The proposed strategy is based on the segmentation of the planar surfaces from the scene, and its representation using a graph which stores the geometric relationships between neighbouring planar patches. Uncertainty information from the planar patches is exploited in a hierarchical fashion to improve both the robustness and the efficiency of registration. Quick registration is achieved in indoor structured scenarios, offering advantages like a compact representation, and flexibility to adapt to different environments and sensors. Our method is validated with different sensors: a hand-held RGB-D camera and an omnidirectional RGB-D sensor; and for different applications: from visual-range odometry to loop closure and SLAM. "
}
@article{Galambos201568,
title = "Design, programming and orchestration of heterogeneous manufacturing systems through VR-powered remote collaboration ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "33",
number = "",
pages = "68 - 77",
year = "2015",
note = "Special Issue on Knowledge Driven Robotics and Manufacturing ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2014.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0736584514000738",
author = "Péter Galambos and Ádám Csapó and Péter Zentay and István Marcell Fülöp and Tamás Haidegger and Péter Baranyi and Imre J. Rudas",
keywords = "Virtual reality/augmented reality",
keywords = "Mixed virtual and physical reality",
keywords = "Remote collaboration",
keywords = "Virtual commissioning",
keywords = "Future internet",
keywords = "Cognitive infocommunications ",
abstract = "Abstract Modern manufacturing systems are often composed of a variety of highly customized units and specifically designed manufacturing cells. Optimization of assembly and training of staff requires a series of demo installations and excessive use of costly operational resources. In some cases, components are located at different sites, making the orchestration of the whole system even more difficult. Virtual Reality (VR) collaboration environments offer a solution by enabling high fidelity testing and training of complex manufacturing systems. On the other hand, such platforms are difficult to implement in an engineering perspective, as they are required to provide reliable, standard interfaces towards both robotic components and human operators. The VirCA (Virtual Collaboration Arena) platform is a software framework that supports various means of collaboration through the use of 3D augmented/virtual reality as a communication medium. VirCA offers functions for the high-level interoperability of heterogeneous components in a wide range of domains, spanning from research &amp; development, through remote education to orchestration and management of industrial processes in manufacturing applications. This paper provides an overview of the industrial requirements behind high-fidelity virtual collaboration and demonstrates how the VirCA platform meets these requirements. Use cases are provided to illustrate the usability of the platform. "
}
@article{Azharuddin201626,
title = "Particle swarm optimization for maximizing lifetime of wireless sensor networks ",
journal = "Computers & Electrical Engineering ",
volume = "51",
number = "",
pages = "26 - 42",
year = "2016",
note = "",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0045790616300404",
author = "Md Azharuddin and Prasanta K. Jana",
keywords = "Wireless sensor networks",
keywords = "Routing",
keywords = "Unequal clustering",
keywords = "Network lifetime",
keywords = "Fault tolerance",
keywords = "Particle swarm optimization ",
abstract = "Abstract Particle swarm optimization (PSO) is a popular bio-inspired algorithm which is applied to solve various optimization problems in many areas including machine intelligence, data mining, robotics and computer networks. In this paper, we propose a PSO-based scheme to solve hot spot problem caused by multi-hop communication in a cluster-based wireless sensor network. The scheme consists of routing and clustering algorithms which are shown to be energy efficient. In the routing phase, traffic load over the cluster heads (CHs) is evenly distributed, whereas in the clustering phase, we take care of all the \{CHs\} whose energy is exhausted fast by assigning lesser number of sensor nodes. In addition to this, we also develop a distributed scheme to prevent the \{CHs\} from their quick death which is resulted from complete energy depletion. We perform extensive simulation on the proposed algorithms and compare the results with some existing algorithms to demonstrate its strength. "
}
@article{Song2016,
title = "TOLA: Topic-oriented learning assistance based on cyber-physical system and big data ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.05.040",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16301650",
author = "Jeungeun Song and Yin Zhang and Kui Duan and M. Shamim Hossain and Sk Md Mizanur Rahman",
keywords = "Massive open online courses",
keywords = "Big data",
keywords = "Cyber-physical system",
keywords = "Latent Dirichlet allocation",
keywords = "Collaborative filtering ",
abstract = "Abstract Massive open online courses (MOOC) is a novel educational model emerging in recent years, which is assisted by advanced techniques such as cloud computing, big data and Cyber-Physical Systems (CPS). Through adequate analysis assisted by big data, the quality of education is expected to be extensively improved. Unfortunately, the \{MOOC\} data are not fully utilized for educational innovation, because the existing research focuses on the data generated in the online learning but neglects other related data, such as the forum data. In this article, we propose a big-data-driven approach named \{TOLA\} for online learning evolution to discover students’ learning pattern and guide courses improvement. Specifically, topic feature is extracted from \{MOOC\} forum through Latent Dirichlet Allocation, which is incorporated with other hybrid features. Through experiments, \{TOLA\} exhibits good performance in terms of complexity, efficiency and accuracy, facilitating the improvement of the quality of online education. "
}
@article{Pastor20012497,
title = "3D wavelet-based multiresolution object representation ",
journal = "Pattern Recognition ",
volume = "34",
number = "12",
pages = "2497 - 2513",
year = "2001",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/S0031-3203(00)00170-9",
url = "http://www.sciencedirect.com/science/article/pii/S0031320300001709",
author = "Luis Pastor and Angel Rodrı́guez and J.Miguel Espadero and Luis Rincón",
keywords = "3D Modeling",
keywords = "Multiresolution representations",
keywords = "Wavelet-based representations",
keywords = "3D vision",
keywords = "Automatic shape extraction ",
abstract = "This paper presents a technique for computing multiresolution shape models of 3D objects acquired as clouds of 3D points. The procedure is fully automated and is able to compute approximations for any object, overcoming sampling irregularity if present (sampling irregularity is a common feature of most 3D acquisition techniques; a typical example is stereo vision). The method described here starts by computing an intermediate mesh that meets the subdivision connectivity requirement needed to allow the computation of the wavelet transform. The mesh is then adjusted to the 3D input data using an iterative deformation process. Finally, a spherical wavelet transform is computed to obtain the object's 3D multiresolution model. This paper shows a number of real objects acquired with different techniques, including hand-held 3D digitizers. The paper also gives some examples of how multiresolution representations can be used in tasks such as acquisition noise filtering, mesh simplification and shape labelling. "
}
@article{Lin2015254,
title = "Computer vision system R&amp;D for \{EAST\} Articulated Maintenance Arm robot ",
journal = "Fusion Engineering and Design ",
volume = "100",
number = "",
pages = "254 - 259",
year = "2015",
note = "",
issn = "0920-3796",
doi = "https://doi.org/10.1016/j.fusengdes.2015.06.017",
url = "http://www.sciencedirect.com/science/article/pii/S0920379615300557",
author = "Linglong Lin and Yuntao Song and Yang Yang and Hansheng Feng and Yong Cheng and Hongtao Pan",
keywords = "EAMA",
keywords = "Maintenance",
keywords = "Computer vision",
keywords = "Pick up",
keywords = "Fragment identification ",
abstract = "Abstract Experimental Advanced Superconducting Tokamak (EAST) is the first full superconducting tokamak device which was constructed at Institute of Plasma Physics Chinese Academy of Sciences (ASIPP). The \{EAST\} Articulated Maintenance Arm (EAMA) robot provides the means of the in-vessel maintenance such as inspection and picking up the fragments of first wall. This paper presents a method to identify and locate the fragments semi-automatically by using the computer vision. The use of computer vision in identification and location faces some difficult challenges such as shadows, poor contrast, low illumination level, less texture and so on. The method developed in this paper enables credible identification of objects with shadows through invariant image and edge detection. The proposed algorithms are validated through our \{ASIPP\} robotics and computer vision platform (ARVP). The results show that the method can provide a 3D pose with reference to robot base so that objects with different shapes and size can be picked up successfully. "
}
@article{Rathi2016231,
title = "Optimizing Sorting Algorithms Using Ubiquitous Multi-core Massively Parallel \{GPGPU\} Processors ",
journal = "Procedia Computer Science ",
volume = "79",
number = "",
pages = "231 - 237",
year = "2016",
note = "Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.03.030",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916001617",
author = "Sheetal Rathi",
keywords = "Bitonic sort",
keywords = "GPGPU",
keywords = "HPC ",
abstract = "Abstract While developing naive code is uncomplicated, optimizing extremely parallel algorithms requires deep understanding of the core architecture. Recent years have witnessed a phenomenal growth in the computational capabilities and applications of GPUs. High performance of modern Graphics Processing Units may be used not only for graphics related application but also for general computing. Out of the vast applications which require parallel computing, some broadly classified are real-world applications like scientific computing, numerical simulations, healthcare, energy, data-analysis, etc. All of these applications involve wide data-intensive tasks, often subject to time constraints and space complexity. One of the fundamental issues in computer science is ordering a list of items. Bitonic sort is one of the most basic computing problems which also play a very important role in plenty of algorithms commonly used in graphics applications, such as visibility ordering or collision detection. This paper makes use of the parallel property of \{GPU\} and accelerates the function of bitonic sort which in itself is designed explicitly for parallel networks. "
}
@article{Gomez2012218,
title = "RoboGuideDog: Guiding Blind users Through Physical Environments with Laser Range Scanners ",
journal = "Procedia Computer Science ",
volume = "14",
number = "",
pages = "218 - 225",
year = "2012",
note = "Proceedings of the 4th International Conference on Software Development for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2012) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S1877050912007879",
author = "Javier V. Gomez and Frode Eika Sandnes",
keywords = "guide system: laser range finder",
keywords = "intelligent system",
keywords = "haptic feedback ",
abstract = "In this paper we discuss initial concepts of the development of a fully automatic guide dog system for blind users. The physical scene is scanned using a laser range device, and the three dimensional point cloud measurements are analyzed and transformed into a description of the environment that is communicated to the user via synthetic speech and/or haptic feedback allowing the user to navigate around physical space. "
}
@article{Wang2016158,
title = "Towards smart factory for industry 4.0: a self-organized multi-agent system with big data based feedback and coordination ",
journal = "Computer Networks ",
volume = "101",
number = "",
pages = "158 - 168",
year = "2016",
note = "Industrial Technologies and Applications for the Internet of Things ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.12.017",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615005046",
author = "Shiyong Wang and Jiafu Wan and Daqiang Zhang and Di Li and Chunhua Zhang",
keywords = "Industry 4.0",
keywords = "Smart factory",
keywords = "Cyber-physical system",
keywords = "Multi-agent system",
keywords = "Deadlock prevention ",
abstract = "Abstract The proliferation of cyber-physical systems introduces the fourth stage of industrialization, commonly known as Industry 4.0. The vertical integration of various components inside a factory to implement a flexible and reconfigurable manufacturing system, i.e., smart factory, is one of the key features of Industry 4.0. In this paper, we present a smart factory framework that incorporates industrial network, cloud, and supervisory control terminals with smart shop-floor objects such as machines, conveyers, and products. Then, we provide a classification of the smart objects into various types of agents and define a coordinator in the cloud. The autonomous decision and distributed cooperation between agents lead to high flexibility. Moreover, this kind of self-organized system leverages the feedback and coordination by the central coordinator in order to achieve high efficiency. Thus, the smart factory is characterized by a self-organized multi-agent system assisted with big data based feedback and coordination. Based on this model, we propose an intelligent negotiation mechanism for agents to cooperate with each other. Furthermore, the study illustrates that complementary strategies can be designed to prevent deadlocks by improving the agents’ decision making and the coordinator's behavior. The simulation results assess the effectiveness of the proposed negotiation mechanism and deadlock prevention strategies. "
}
@article{Jackson2016274,
title = "Digital Manufacturing and Flexible Assembly Technologies for Reconfigurable Aerospace Production Systems ",
journal = "Procedia \{CIRP\} ",
volume = "52",
number = "",
pages = "274 - 279",
year = "2016",
note = "The Sixth International Conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2016) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.07.054",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116308046",
author = "Keith Jackson and Konstantinos Efthymiou and John Borton",
keywords = "Aerospace",
keywords = "Manufacturing",
keywords = "Reconfiguration",
keywords = "Digital Manufacturing",
keywords = "M4 ",
abstract = "Abstract Reconfigurability is an important aspect of modern manufacturing systems as it facilitates the seamless introduction of new products to production and the adaptation to demand volatility. Advanced manufacturing technologies broadly used in automotive industry have limited application for typical \{UK\} aerospace manufacturing, as they require production volume and repetition of operations to deliver value. This paper discusses a framework of key technologies ranging from digital manufacturing concepts to flexible fixturing that enable reconfigurability in aerospace manufacturing systems. Initially, the overall architecture of the framework is presented illustrating the key components such as a cloud based data storage mechanism, an intelligent multi-product assembly station, kitting boxes embedded with sensors, a manufacturing network management portal and a decision support tool that combines data analytics and discrete event simulation. Afterwards, the main functionalities and technologies of the components are described and finally an industrial application scenario for the proposed framework is presented. "
}
@article{Peng201685,
title = "Semantic Mapping of Orchards* ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "16",
pages = "85 - 89",
year = "2016",
note = "5th \{IFAC\} Conference on Sensing, Control and Automation Technologies for Agriculture \{AGRICONTROL\} 2016Seattle, WA, USA, 14—17 August 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.016",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316315786",
author = "Cheng Peng and Pravakar Roy and James Luby and Volkan Isler",
keywords = "computer vision",
keywords = "agriculture",
keywords = "image reconstruction",
keywords = "image recognition",
keywords = "object recognition ",
abstract = "Abstract: We present a method to construct a semantic map of an apple orchard using a \{LIDAR\} and a camera rigidly attached to each other. The system is able to capture the map as a standalone sensor which is light-weight and can be mounted on a variety of platforms. At the geometry level, we present a new method to associate image features captured by the camera with 3D points captured by the LIDAR. We then use this method to register 3D point-clouds onto a common frame. We show that our association method yields superior registration performance compared to common methods which work in indoor or urban settings. At the semantic level, the apples are identified as distinct objects. Their locations and diameters are extracted as relevant attributes. As an example, a semantic map of an orchard row is constructed. "
}
@article{Tateno2017138,
title = "Large scale and long standing simultaneous reconstruction and segmentation ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "138 - 150",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.05.013",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300662",
author = "Keisuke Tateno and Federico Tombari and Nassir Navab",
keywords = "Dense SLAM",
keywords = "Segmentation",
keywords = "Real-time",
keywords = "Scalable",
keywords = "Long standing",
keywords = "Relocalization",
keywords = "Loop-closure ",
abstract = "Abstract This work proposes a method to segment a 3D point cloud of a scene while simultaneously reconstructing it via Simultaneous Localization And Mapping (SLAM). The proposed method incrementally merges segments obtained from each input depth image in an unified global model leveraging the camera pose estimated via SLAM. Differently from other approaches, our method is able to yield segmentation of scenes reconstructed from multiple views in real-time and with a complexity that does not depend on the size of the global model. Moreover, we endow our system with two additional contributions: a loop closure approach and a failure recovery and re-localization approach, both specifically designed so to enforce global consistency between merged segments, thus making our system suitable for large scale and long standing reconstruction and segmentation. We validate our proposal against the state of the art in terms of computational efficiency and accuracy on several benchmark datasets, as well as by showing how our method enables real-time reconstruction and segmentation of diverse real indoor environments. "
}
@article{Walker2011327,
title = "Computers and Composition 20/20: A Conversation Piece, or What Some Very Smart People Have to Say about the Future ",
journal = "Computers and Composition ",
volume = "28",
number = "4",
pages = "327 - 346",
year = "2011",
note = "Composition 20/20: How the Future of the Web Could Sharpen the Teaching of Writing ",
issn = "8755-4615",
doi = "https://doi.org/10.1016/j.compcom.2011.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S8755461511000703",
author = "Janice R. Walker and Kristine L. Blair and Douglas Eyman and Bill Hart-Davidson and Mike McLeod and Jeff Grabill and Fred Kemp and Mike Palmquist and James P. Purdy and Madeleine Sorapure and Christine Tulley and Victor J. Vitanza",
keywords = "Writing, teaching writing, writing assessment, publishing, robots, mobility, literacy, Web 3.0 ",
abstract = "At the 2011 Computers and Writing Conference, Town Hall speakers were asked to envision the future. This piece extends that conversation, with contributors presenting a range of ideas, often looking backward at our history before gazing into their crystal balls to envision what the future might bring. The pieces included here discuss writing, teaching writing, writing assessment, publishing, robotics, mobility, and other aspects of the field loosely termed computers and composition as it was, is, or may come to be in what we hope will be only the start of an ongoing conversation. "
}
@incollection{Adaniya201543,
title = "Chapter 3 - Firefly Algorithm in Telecommunications ",
editor = "Yang, Xin-She and , and Chien, Su Fong and ,  and Ting, Tiew On ",
booktitle = "Bio-Inspired Computation in Telecommunications ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2015",
pages = "43 - 72",
isbn = "978-0-12-801538-4",
doi = "https://doi.org/10.1016/B978-0-12-801538-4.00003-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780128015384000033",
author = "Mario H.A.C. Adaniya and Luiz F. Carvalho and Bruno B. Zarpelão and Lucas D.H. Sampaio and Taufik Abrão and Paul Jean E. Jeszensky and Mario Lemes Proença Jr.",
keywords = "Firefly algorithm",
keywords = "Swarm intelligence",
keywords = "Wireless network",
keywords = "Cooperative network",
keywords = "Resource allocation",
keywords = "Multicarrier systems",
keywords = "Code division multiple access system ",
abstract = "Abstract This chapter discusses the nature-inspired metaheuristic firefly algorithm (FA) applied in telecommunications. \{FA\} has been developed based on the behavior of the fireflies and the light emitted, where the brightest firefly attracts the others in his direction. Besides combining stochastic behavior and a population-based multimodal characteristic, the \{FA\} approach is able to solve optimization problems in different areas of knowledge such as engineering, robotics, combinatorial optimization, and so on. This chapter aims to show the \{FA\} performance in two distinct network optimization problems: traffic characterization and energy-efficient cooperative networks. In the first optimization problem, \{FA\} is applied as a clustering algorithm to create a network traffic pattern called Digital Signature of Network Segment using Flow analysis (DSNSF); in the second, \{FA\} has been applied to the energy-efficiency maximization problem in multicarrier direct sequence code division multiple access (MC-DS/CDMA) cooperative networks. "
}
@article{Maiolino2017188,
title = "Flexible robot sealant dispensing cell using RGB-D sensor and off-line programming ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "188 - 195",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516302253",
author = "Perla Maiolino and Richard Woolley and David Branson and Panorios Benardos and Atanas Popov and Svetan Ratchev",
keywords = "AOLP",
keywords = "RGB-D sensor",
keywords = "Sealant dispensing ",
abstract = "Abstract In aerospace manufacture the accurate and robust application of sealant is an integral and challenging part of the manufacturing process that is still performed by human operator. Automation of this process is difficult and not cost effective due to the high variability in the parts to operate and also the difficulty associated with programming industrial robotic systems. This work tries to overcome these problems by presenting an \{AOLP\} (Automatic Off-Line Programming) system for sealant dispensing through the integration of the ABB's proprietary \{OLP\} (Off-Line Programming) system RobotStudio with a relatively new RBG-D sensor technology based on structured light and the development of a RobotStudio add-on. The integration of the vision system in the generation of the robot program overcomes the current problems related to \{AOLP\} systems that rely on a known model of the work environment. This enables the ability to dynamically adapt the model according to sensor data, thus coping with environmental and parts variability during operation. Furthermore it exploits the advantages of an \{OLP\} system simplifying the robot programming allowing for faster automation of the process. "
}
@article{Varga20177,
title = "New approaches for cement-based prophylactic augmentation of the osteoporotic proximal femur provide enhanced reinforcement as predicted by non-linear finite element simulations ",
journal = "Clinical Biomechanics ",
volume = "44",
number = "",
pages = "7 - 13",
year = "2017",
note = "",
issn = "0268-0033",
doi = "https://doi.org/10.1016/j.clinbiomech.2017.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0268003317300591",
author = "Peter Varga and Jason A. Inzana and Jakob Schwiedrzik and Philippe K. Zysset and Boyko Gueorguiev and Michael Blauth and Markus Windolf",
keywords = "Prophylactic augmentation",
keywords = "Proximal femur",
keywords = "Femoroplasty",
keywords = "Osteoporosis",
keywords = "Finite element analysis ",
abstract = "AbstractBackground High incidence and increased mortality related to secondary, contralateral proximal femoral fractures may justify invasive prophylactic augmentation that reinforces the osteoporotic proximal femur to reduce fracture risk. Bone cement-based approaches (femoroplasty) may deliver the required strengthening effect; however, the significant variation in the results of previous studies calls for a systematic analysis and optimization of this method. Our hypothesis was that efficient generalized augmentation strategies can be identified via computational optimization. Methods This study investigated, by means of finite element analysis, the effect of cement location and volume on the biomechanical properties of fifteen proximal femora in sideways fall. Novel cement cloud locations were developed using the principles of bone remodeling and compared to the “single central” location that was previously reported to be optimal. Findings The new augmentation strategies provided significantly greater biomechanical benefits compared to the “single central” cement location. Augmenting with approximately 12 ml of cement in the newly identified location achieved increases of 11% in stiffness, 64% in yield force, 156% in yield energy and 59% in maximum force, on average, compared to the non-augmented state. The weaker bones experienced a greater biomechanical benefit from augmentation than stronger bones. The effect of cement volume on the biomechanical properties was approximately linear. Results of the “single central” model showed good agreement with previous experimental studies. Interpretation These findings indicate enhanced potential of cement-based prophylactic augmentation using the newly developed cementing strategy. Future studies should determine the required level of strengthening and confirm these numerical results experimentally. "
}
@article{Nad2012224,
title = "Distributed Systems in Control and Navigation of Small Underwater Vehicles ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "224 - 228",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00168",
url = "http://www.sciencedirect.com/science/article/pii/S147466701633614X",
author = "Dula Nad and Nikola Misković and Tomislav Lugarić and Zoran Vukić",
keywords = "Distributed systems",
keywords = "low-level control",
keywords = "MOOS",
keywords = "ROS ",
abstract = "Abstract Distributed systems are pervasive in the process industry but less so in underwater robotics. Development of open-source frameworks, targeted at mobile systems, increases applicability of distributed techniques in vehicle control. Most often supervisory control is implemented in a distributed framework while low-level control is kept in the embedded system. This approach allows sharing of sensor data, logging and increased reconfigurability of high level controllers. Meantime, the embedded system offers precise timing and reliable behaviour. Alternatively, the low-level control can be moved into the distributed framework to allow easier reconfiguration and prototyping. In this paper we describe the architecture used for low-level control and analyze its performance in the \{MOOS\} and \{ROS\} distributed frameworks. "
}
@article{Ali2016173,
title = "Mobile device power models for energy efficient dynamic offloading at runtime ",
journal = "Journal of Systems and Software ",
volume = "113",
number = "",
pages = "173 - 187",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.11.042",
url = "http://www.sciencedirect.com/science/article/pii/S0164121215002666",
author = "Farhan Azmat Ali and Pieter Simoens and Tim Verbelen and Piet Demeester and Bart Dhoedt",
keywords = "Power model",
keywords = "Energy consumption",
keywords = "Energy-aware dynamic offloading ",
abstract = "Abstract Spectacular advances in hardware and software technologies have resulted in powerful mobile devices, equipped with advanced processing, storage and network capabilities. Therefore, using resource-intensive applications has become a commodity in many contexts. However, the rapid evolution in hardware and software capabilities has not been paralleled by a similar advance in battery technology. A potential avenue to cope with the device energy resource limitation is to offload computational tasks to cloud infrastructure in the network. In order to offload tasks in an energy-aware manner, we present a detailed model of mobile device energy consumption, addressing the main power consuming subsystems, including CPU, display unit, wireless network interface and memory. Applying this model allows to estimate the power consumed by the application when executed locally, remotely or hybridly (i.e. partly on the device and partly in the cloud infrastructure). Offloading parts of the application can subsequently be decided at runtime based on these energy consumption estimates, also taking into account the power consumed by the device-to-cloud communication over the wireless network. The dynamic offloading has been validated with computational and communication intensive applications. Results show that 18–55% energy gains on the mobile device can be achieved, depending on different conditions. "
}
@article{Wang2015918,
title = "Performance Evaluation of Automatically Generated \{BIM\} from Laser Scanner Data for Sustainability Analyses ",
journal = "Procedia Engineering ",
volume = "118",
number = "",
pages = "918 - 925",
year = "2015",
note = "Defining the future of sustainability and resilience in design, engineering and construction ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2015.08.531",
url = "http://www.sciencedirect.com/science/article/pii/S1877705815021864",
author = "Chao Wang and Yong K. Cho",
keywords = "Laser scanning",
keywords = "Energy efficiency",
keywords = "As-is BIM",
keywords = "Decision support ; ",
abstract = "Abstract Existing buildings now represent the greatest opportunity to improve building energy efficiency. Building performance analysis is becoming increasingly important because decision makers can have a better visualization of their building's performance and quickly make the solution for improving building energy efficiency and reducing environmental impacts. Nowadays, building information models (BIMs) have been widely created during the design phase of new buildings, and it can be easily imported to third party software to conduct various analyses. However, a \{BIM\} is not always available for all existing buildings. Even if a \{BIM\} is available during the design and construction phases, it is very challenging to keep updating it while a building is aged. A manual process to create or update a \{BIM\} is very time consuming and labor intensive. A laser scanning technology has been a popular tool to create as-is BIM. However it still needs labor-intensive manual processes to create a \{BIM\} out of point clouds. This paper introduces automatic as-is simplified \{BIM\} creation from point clouds for energy simulations. A framework of decision support system that can assist decision makers on retrofits for existing buildings is introduced as well. A case study on a residential house was tested in this study to validate the proposed framework, and the technical feasibility of the developed system was positively demonstrated. "
}
@article{Wang2016237,
title = "An effective multivariate time series classification approach using echo state network and adaptive differential evolution algorithm ",
journal = "Expert Systems with Applications ",
volume = "43",
number = "",
pages = "237 - 249",
year = "2016",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.08.055",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415006120",
author = "Lin Wang and Zhigang Wang and Shan Liu",
keywords = "Multivariate time series classification",
keywords = "Recurrent neural network",
keywords = "Adaptive differential evolution algorithm ",
abstract = "Abstract The multivariate time series (MTS) classification is a very difficult process because of the complexity of the \{MTS\} data type. Among all the methods to resolve this problem, the attribute–value representation classification approaches are the most popular. Despite their proven effectiveness of these however, these approaches are time consuming, sensitive to noise, or prone to damage of inner data properties as well as capable of producing undesirable accuracy. In this paper, we propose a new approach (CADE) for \{MTS\} classification that utilizes recurrent neural network (RNN) and adaptive differential evolution (ADE) algorithm. The approach can effectively overcome specific shortcomings of the attribute–value representation approaches. The principle of this approach adheres to three steps. First, an \{RNN\} is used to project the training \{MTS\} samples into different state clouds (samples in the same class are projected into a state cloud). Second, classifiers from these state clouds are induced for different classes. Third, the final \{MTS\} classifiers are obtained using \{ADE\} for parameter optimization. This approach makes full use of the network state space of a given \{RNN\} to induce classifiers rather than to train the network. Experimental results performed on 18 data sets demonstrate the accuracy and robustness of the proposed approach for \{MTS\} classification. As a new and universal approach, \{CADE\} can be very effective and stable for handling a variety of complex classification problems. "
}
@article{Huebner2012367,
title = "BADGr—A toolbox for box-based approximation, decomposition and \{GRasping\} ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "367 - 376",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.021",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001539",
author = "Kai Huebner",
keywords = "Part-based grasping",
keywords = "3D shape approximation",
keywords = "Grasp database generation",
keywords = "Open source software ",
abstract = "In this paper, we conclude our work on shape approximation by box primitives for the goal of simple and efficient grasping. As a main product of our research, we present the \{BADGr\} toolbox for Box-based Approximation, Decomposition and Grasping of objects. The contributions of the work presented here are twofold: in terms of shape approximation, we provide an algorithm for creating a 3D box primitive representation to identify object parts from 3D point clouds. We motivate and evaluate this choice particularly towards the task of grasping. As a contribution in the field of grasping, we further provide a grasp hypothesis generation framework that utilizes the chosen box presentation in a flexible manner. "
}
@article{Tarokh201351,
title = "Solving inverse problems by decomposition, classification and simple modeling ",
journal = "Information Sciences ",
volume = "218",
number = "",
pages = "51 - 60",
year = "2013",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2012.07.037",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512005099",
author = "Mahmoud Tarokh",
keywords = "Inverse problems",
keywords = "Classification",
keywords = "Decomposition ",
abstract = "Inverse problems appear in many areas ranging from microwave circuits to environmental studies and to robotics, just to mention a few. In this paper we propose a new approach to solving inverse problems based on decomposition of output space into cells, with the corresponding regions in the input space. Solutions are identified using a clustering method and the relationship between data in an output cell and the corresponding input region is modeled by a simple polynomial. It is shown that the proposed method achieves very high accuracy even with relatively high number of inputs and outputs. It is also extremely fast and is suitable for real-time control, where needed. The method is applied to a highly complex inverse problem in robot kinematics and its performance is demonstrated. "
}
@article{Yan20111489,
title = "Comparison of \{CERES\} surface radiation fluxes with surface observations over Loess Plateau ",
journal = "Remote Sensing of Environment ",
volume = "115",
number = "6",
pages = "1489 - 1500",
year = "2011",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2011.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0034425711000514",
author = "Hongru Yan and Jianping Huang and Patrick Minnis and Tianhe Wang and Jianrong Bi",
keywords = "surface radiative fluxes",
keywords = "CERES/SSF",
keywords = "validation ",
abstract = "Surface energy budget is an important factor in weather and climate processes. To estimate the errors in satellite-retrieved surface radiation budget over the interior of China, instantaneous-footprint surface radiation fluxes from the Terra/Aqua \{FLASHFlux\} \{SSF\} product are compared with the measurements taken at the Semi-Arid Climate and Environment Observatory of Lanzhou University (SACOL) from July 2008 to March 2010. Validation is performed separately for different conditions: clear-sky and cloudy-sky, daytime and nighttime for four seasons. Differences between the \{FLASHFlux\} \{CERES\} shortwave radiation flux and surface measurements have larger standard deviations in cloudy-sky conditions than in clear-sky conditions, indicating that cloud contamination increases uncertainty in the retrieval algorithm. Upward shortwave radiation flux (USW) is overestimated in cloudy conditions suggesting that the cloud parameters and surface scene type in the retrieval process are not optimal for northwestern China. The \{CERES\} downward longwave radiation fluxes (DLW) accurately follow the variation of surface measurements during daytime, but are slightly underestimated during nighttime due to the coarse sounding profile and undetected low clouds at nighttime. The \{CERES\} upwelling longwave radiation fluxes (ULW) are strongly underestimated during daytime but are slightly underestimated during nighttime regardless of cloud coverage. This large bias could be caused by an underestimate of surface skin temperature and/or surface emissivity, or spatial inhomogeneity around the site. Generally, except for diurnal ULW, other components of the surface radiative fluxes obtained from \{CERES\} \{SSF\} datasets are close to meeting the accuracy requirements for climate research. "
}
@article{Munaro2016525,
title = "OpenPTrack: Open source multi-camera calibration and people tracking for RGB-D camera networks ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "525 - 538",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002304",
author = "Matteo Munaro and Filippo Basso and Emanuele Menegatti",
keywords = "OpenPTrack",
keywords = "People tracking",
keywords = "RGB-D",
keywords = "Open source",
keywords = "Multi-camera",
keywords = "Network calibration",
keywords = "Human–robot interaction",
keywords = "Microsoft Kinect",
keywords = "Mesa SwissRanger",
keywords = "Stereo ",
abstract = "Abstract OpenPTrack is an open source software for multi-camera calibration and people tracking in RGB-D camera networks. It allows to track people in big volumes at sensor frame rate and currently supports a heterogeneous set of 3D sensors. In this work, we describe its user-friendly calibration procedure, which consists of simple steps with real-time feedback that allow to obtain accurate results in estimating the camera poses that are then used for tracking people. On top of a calibration based on moving a checkerboard within the tracking space and on a global optimization of cameras and checkerboards poses, a novel procedure which aligns people detections coming from all sensors in a x - y - t i m e space is used for refining camera poses. While people detection is executed locally, in the machines connected to each sensor, tracking is performed by a single node which takes into account detections from all over the network. Here we detail how a cascade of algorithms working on depth point clouds and color, infrared and disparity images is used to perform people detection from different types of sensors and in any indoor light condition. We present experiments showing that a considerable improvement can be obtained with the proposed calibration refinement procedure that exploits people detections and we compare Kinect v1, Kinect v2 and Mesa \{SR4500\} performance for people tracking applications. OpenPTrack is based on the Robot Operating System and the Point Cloud Library and has already been adopted in networks composed of up to ten imagers for interactive arts, education, culture and human–robot interaction applications. "
}
@article{Baruch1992399,
title = "Robots in astronomy ",
journal = "Vistas in Astronomy ",
volume = "35, Part 4",
number = "",
pages = "399 - 438",
year = "1992",
note = "",
issn = "0083-6656",
doi = "https://doi.org/10.1016/0083-6656(92)90002-N",
url = "http://www.sciencedirect.com/science/article/pii/008366569290002N",
author = "John E.F. Baruch",
abstract = "This paper follows the growth of robotics and automation in industry and astronomy. It discusses the different purposes for which automation is used in observational astronomy and compares the problems of robot development in industry with the experiences in astronomy. The disillusionment with robotics after the excitement and promise of the sixties is evaluated. Modern ideas of the robot as a personal assistant are developed for application in astronomy. The paper discusses how technology steers our direction of investigations in astronomy, and colours our views of the universe. It is argued that robotics in astronomy will open up whole new areas of investigation that are as likely to be as surprising and exciting as many other new avenues which astronomy has taken. It reviews the most fertile areas for robotic observing and develops an outline design. The necessary technological developments for specific types of observational investigations are detailed. Current programmes of robotic and automated telescopes are listed and the case made for international cooperation to agree formats, interfaces and standards. With standard data formats robotic telescopes can be a world resource that can be addressed by any observer, robotic or human. Standard interfaces will ensure that robotic systems can be broken down into units, particularly software units, that can be made freely available to encourage collaboration. Alternatively new software can be developed to link to standard interfaces by those who wish to improve the systems and compete. The paper concludes with a brief look at the future for robotic systems in astronomy. "
}
@article{Ozog2017329,
title = "Mapping underwater ship hulls using a model-assisted bundle adjustment framework ",
journal = "Robotics and Autonomous Systems ",
volume = "87",
number = "",
pages = "329 - 347",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302219",
author = "Paul Ozog and Matthew Johnson-Roberson and Ryan M. Eustice",
keywords = "SLAM",
keywords = "AUVs",
keywords = "Underwater inspection",
keywords = "Mapping",
keywords = "Visualization ",
abstract = "Abstract This paper reports on a model-assisted bundle adjustment (BA) framework in which visually-derived features are fused with an underlying three-dimensional (3D) mesh provided a priori. By using an approach inspired by the expectation–maximization (EM) class of algorithms, we introduce a hidden binary label for each visual feature that indicates if that feature is considered part of the nominal model, or if the feature corresponds to 3D structure that is absent from the model. Therefore, in addition to improved estimates of the feature locations, we can identify visual features that correspond to foreign structure on the ship hull. We show that this framework is a special case of the Gaussian max-mixtures framework, which can be efficiently incorporated into state-of-the-art graph-based simultaneous localization and mapping (SLAM) solvers. In addition, the precision of our bundle adjustment framework allows the identification of structural deviations between 3D structure inferred from bundle-adjusted camera imagery and the prior model. These structural deviations are clustered into shapes, which allow us to fuse camera-derived structure back into the 3D mesh. This augmented model can be used within a 3D photomosaicing pipeline, providing a visually intuitive 3D reconstruction of the ship hull. We evaluate our pipeline using the Bluefin Robotics hovering autonomous underwater vehicle (HAUV) surveying the SS Curtiss, where a 3D mesh derived from computer aided design (CAD) drawings serves as the prior model. In addition to more consistent visual reconstructions, we can update the prior mesh with 3D information corresponding to underwater structure, such as biofouling or manually-placed cylindrical shapes with known dimensions. "
}
@article{Xuehe2016104,
title = "\{GPU\} based real-time \{SLAM\} of six-legged robot ",
journal = "Microprocessors and Microsystems ",
volume = "47, Part A",
number = "",
pages = "104 - 111",
year = "2016",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.10.008",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001635",
author = "Zhang Xuehe and Li Ge and Liu Gangfeng and Zhao Jie and Hou ZhenXiu",
keywords = "Feature detection",
keywords = "Graphics processing unit (GPU)",
keywords = "Parallel Processing",
keywords = "SLAM ",
abstract = "Abstract Vision and \{AHRS\} (attitude and heading reference system) sensors fusion strategy is prevalent in recent years for the legged robot's \{SLAM\} (Simultaneous Localization and Mapping), due to its low cost and effectiveness in the global positioning system. In this paper, a new adaptive estimation algorithm is proposed to achieve the robot \{SLAM\} by fusing binocular vision and \{AHRS\} sensors. A novel acceleration algorithm for \{SIFT\} implementation based on Compute Unified Device Architecture (CUDA) is presented to detect the matching feature points in 2D images. All the steps of \{SIFT\} were specifically distributed and implemented by \{CPU\} or GPU, according to the step's characteristics to make full use of computational resources. The registration of the 3D feature point cloud is performed by using the iterative closest point (ICP) algorithm. Our GPU-based \{SIFT\} implementation can run at the speed of 30 frames per second (fps) on most images with 900 × 750 resolution in the test. Compared to other methods, our algorithm is simple to implement and suitable for parallel processing. It can be easily integrated into mobile robot’s tasks like navigation or object tracking, which need the real-time localization information. Experiments results showed that in the unknown indoor environments, the proposed algorithm`s operation is stable and the positioning accuracy is high. "
}
@article{Beegum2016185,
title = "Simulating aerosols over Arabian Peninsula with CHIMERE: Sensitivity to soil, surface parameters and anthropogenic emission inventories ",
journal = "Atmospheric Environment ",
volume = "128",
number = "",
pages = "185 - 197",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016300188",
author = "S. Naseema Beegum and Imen Gherboudj and Naira Chaouch and Florian Couvidat and Laurent Menut and Hosni Ghedira",
keywords = "CHIMERE",
keywords = "Chemistry transport model",
keywords = "Aerosol optical depth",
keywords = "EDGAR-HTAP emissions",
keywords = "Surface roughness length",
keywords = "Soil erodibility ",
abstract = "Abstract A three dimensional chemistry transport model, CHIMERE, was used to simulate the aerosol optical depths (AOD) over the Arabian Peninsula desert with an offline coupling of Weather Research and Forecasting (WRF) model. The simulations were undertaken with: (i) different horizontal and vertical configurations, (ii) new datasets derived for soil/surface properties, and (iii) EDGAR-HTAP anthropogenic emissions inventories. The model performance evaluations were assessed: (i) qualitatively using \{MODIS\} (Moderate-Resolution Imaging Spectroradiometer) deep blue (DB) \{AOD\} data for the two local dust events of August 6th and 23rd (2013), and (ii) quantitatively using \{AERONET\} (Aerosol Robotic Network) \{AOD\} observations, \{CALIPSO\} (Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation) aerosol extinction profiles, and \{AOD\} simulations from various forecast models. The model results were observed to be highly sensitive to erodibility and aerodynamic surface roughness length. The use of new datasets on soil erodibility, derived from the \{MODIS\} reflectance, and aerodynamic surface roughness length (z0), derived from the ERA-Interim datasets, significantly improved the simulation results. Simulations with the global EDGAR-HTAP anthropogenic emission inventories brought the simulated \{AOD\} values closer to the observations. Performance testing of the adapted model for the Arabian Peninsula domain with improved datasets showed good agreement between \{AERONET\} \{AOD\} measurements and \{CHIMERE\} simulations, where the correlation coefficient (R) is 0.6. Higher values of the correlation coefficients and slopes were observed for the dusty periods compared to the non-dusty periods. "
}
@article{Radhakrishna2017,
title = "A novel fuzzy similarity measure and prevalence estimation approach for similarity profiled temporal association pattern mining ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.03.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17303795",
author = "Vangipuram Radhakrishna and Shadi A. Aljawarneh and P.V. Kumar and V. Janaki",
keywords = "Prevalence value",
keywords = "Spatial",
keywords = "Temporal",
keywords = "Fuzzy dissimilarity",
keywords = "Association pattern ",
abstract = "Abstract Data generated from Sensors, IoT environment and many real time applications is mainly spatial, temporal, or spatio-temporal. Some of them include data generated from geospatial, geographical, medical, weather, finance and environmental applications. Such data objects changes over time. Conventional knowledge discovery techniques available do not address the need for analyzing such complex datasets and hence data analysis has become increasingly complex and challenging. Soft computing principles such as fuzzy logic, evolutionary and nature inspired computations may be applied to analyze dynamically varying data. Analyzing temporal trends of association patterns requires handling the temporal data, as prevalence values of temporal patterns are implicitly vectors. Finding Prevalence values of temporal association patterns and validating them for similarity using conventional approach increases the computational complexity. This makes it challenging as the conventional data mining algorithms do not address this need. In this research, we propose a novel approach for estimation of temporal association pattern prevalence values and a novel temporal fuzzy similarity measure which holds monotonicity to find similarity between any two temporal patterns. Experiments are performed considering naive, sequential, spamine and proposed approach. The results obtained show the proposed approach is promising and reduces computational complexity in terms of computing true prevalence and optimizing execution times. "
}
@article{Last201748,
title = "Global Commons in the Global Brain ",
journal = "Technological Forecasting and Social Change ",
volume = "114",
number = "",
pages = "48 - 64",
year = "2017",
note = "",
issn = "0040-1625",
doi = "https://doi.org/10.1016/j.techfore.2016.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0040162516301226",
author = "Cadell Last",
keywords = "Global Brain",
keywords = "Futures",
keywords = "Technology",
keywords = "Evolution",
keywords = "Internet",
keywords = "Commons",
keywords = "Politics ",
abstract = "Abstract The next decade (present to ~ 2020–2025) could be characterized by large-scale labour disruption and further acceleration of income and wealth inequality due to the widespread introduction of general-purpose robotics, machine-learning software/artificial intelligence (AI) and their various interconnections within the emerging infrastructure of the ‘Internet of Things’ (IoT). In this paper I argue that such technological changes and their socioeconomic consequences signal the emergence of a global metasystem (i.e. control organization beyond markets and nation-states) and may require a qualitatively new level of political organization to guide a process of self-organization. Consequently, this paper proposes and attempts to develop a conceptual framework with the potential to aid an international political transition towards a ‘post-capitalist’ ‘post-nation state’ global world. This conceptual framework is grounded within sociotechnological theory of the ‘Global Brain’ (GB), which describes a potential future planetary organizational structure founded on distributed and open-ended intelligence; and the socioeconomic theory of the ‘Commons’, which is a paradigm describing distributed modes of organization founded upon principles of democratic management and open access. In the integration of \{GB\} theory and Commons theory this paper ultimately argues that an appropriate international response to the emerging technological revolution should include the creation of networks with both automated and collaborative components that function on ‘Global Commons’ (GC) logic (i.e. beyond both state and market logic). "
}
@article{Bibi2015113,
title = "Intercomparison of MODIS, MISR, OMI, and \{CALIPSO\} aerosol optical depth retrievals for four locations on the Indo-Gangetic plains and validation against \{AERONET\} data ",
journal = "Atmospheric Environment ",
volume = "111",
number = "",
pages = "113 - 126",
year = "2015",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015300169",
author = "Humera Bibi and Khan Alam and Farrukh Chishtie and Samina Bibi and Imran Shahid and Thomas Blaschke",
keywords = "AOD",
keywords = "MODIS",
keywords = "MISR",
keywords = "OMI",
keywords = "CALIPSO",
keywords = "AERONET ",
abstract = "Abstract This study provides an intercomparison of aerosol optical depth (AOD) retrievals from satellite-based Moderate Resolution Imaging Spectroradiometer (MODIS), Multiangle Imaging Spectroradiometer (MISR), Ozone Monitoring Instrument (OMI), and Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) instrumentation over Karachi, Lahore, Jaipur, and Kanpur between 2007 and 2013, with validation against \{AOD\} observations from the ground-based Aerosol Robotic Network (AERONET). Both \{MODIS\} Deep Blue (MODISDB) and \{MODIS\} Standard (MODISSTD) products were compared with the \{AERONET\} products. The MODISSTD–AERONET comparisons revealed a high degree of correlation for the four investigated sites at Karachi, Lahore, Jaipur, and Kanpur, the MODISDB–AERONET comparisons revealed even better correlations, and the MISR–AERONET comparisons also indicated strong correlations, as did the OMI–AERONET comparisons, while the CALIPSO–AERONET comparisons revealed only poor correlations due to the limited number of data points available. We also computed figures for root mean square error (RMSE), mean absolute error (MAE) and root mean bias (RMB). Using \{AERONET\} data to validate MODISSTD, MODISDB, MISR, OMI, and \{CALIPSO\} data revealed that \{MODISSTD\} data was more accurate over vegetated locations than over un-vegetated locations, while \{MISR\} data was more accurate over areas close to the ocean than over other areas. The \{MISR\} instrument performed better than the other instruments over Karachi and Kanpur, while the \{MODISSTD\} \{AOD\} retrievals were better than those from the other instruments over Lahore and Jaipur. We also computed the expected error bounds (EEBs) for both \{MODIS\} retrievals and found that \{MODISSTD\} consistently outperformed \{MODISDB\} in all of the investigated areas. High \{AOD\} values were observed by the MODISSTD, MODISDB, MISR, and \{OMI\} instruments during the summer months (April–August); these ranged from 0.32 to 0.78, possibly due to human activity and biomass burning. In contrast, high \{AOD\} values were observed by the \{CALIPSO\} instrument between September and December, due to high concentrations of smoke and soot aerosols. The variable monthly \{AOD\} figures obtained with different sensors indicate overestimation by MODISSTD, MODISDB, OMI, and \{CALIPSO\} instruments over Karachi, Lahore, Jaipur and Kanpur, relative to the \{AERONET\} data, but underestimation by the \{MISR\} instrument. "
}
@article{vanDonkelaar20116225,
title = "Satellite-based estimates of ground-level fine particulate matter during extreme events: A case study of the Moscow fires in 2010 ",
journal = "Atmospheric Environment ",
volume = "45",
number = "34",
pages = "6225 - 6232",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.07.068",
url = "http://www.sciencedirect.com/science/article/pii/S135223101100851X",
author = "Aaron van Donkelaar and Randall V. Martin and Robert C. Levy and Arlindo M. da Silva and Michal Krzyzanowski and Natalia E. Chubarova and Eugenia Semutnikova and Aaron J. Cohen",
keywords = "MODIS",
keywords = "PM2.5",
keywords = "Moscow wildfires",
keywords = "Aerosol optical depth ",
abstract = "We estimate fine particulate matter (PM2.5) concentrations daily using \{MODIS\} satellite observations of aerosol optical depth (AOD) for a major biomass burning event around Moscow during summer 2010. Evaluation of \{MODIS\} \{AOD\} with the Moscow \{AERONET\} site supports a MODIS-AOD error estimate of ±(0.05 + 0.2 × AOD) for this event. However, since the smoke was often thick (AOD &gt; 4.0) and spatially variable, the standard \{MODIS\} algorithm incorrectly identifies some aerosol as cloud. We test relaxed cloud screening criteria that increase \{MODIS\} coverage by 21% and find excellent agreement with coincident operational retrievals (r2 = 0.994, slope = 1.01) with no evidence of false aerosol detection. We relate the resultant \{MODIS\} \{AOD\} to PM2.5 using aerosol vertical profiles from the GEOS-Chem chemical transport model. Our estimates are in good agreement with PM2.5 values estimated from in-situ \{PM10\} (r2 = 0.85, slope = 1.06), and we find that the relationship between \{AOD\} and PM2.5 is insensitive to uncertainties in biomass burning emissions. The satellite-derived and in-situ values both indicate that peak daily mean concentrations of approximately 600 μg m−3 occurred on August 7, 2010 in the Moscow region of the Russian Federation. We estimate that exposure to air pollution from the Moscow wildfires may have caused hundreds of excess deaths. "
}
@article{Guenard2012939,
title = "The \{AETOURNOS\} Project: Using a Flock of \{UAVs\} as a Cyber Physical System and Platform for Application-driven Research ",
journal = "Procedia Computer Science ",
volume = "10",
number = "",
pages = "939 - 945",
year = "2012",
note = "\{ANT\} 2012 and MobiWIS 2012 ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2012.06.127",
url = "http://www.sciencedirect.com/science/article/pii/S187705091200484X",
author = "Adrien Guenard and Laurent Ciarletta",
keywords = "Flocking",
keywords = "UAV platform",
keywords = "Cyber Physical Systems",
keywords = "Co-simulation",
keywords = "Sensor and Actuator Networks ",
abstract = "This position paper presents the Airborne Embedded auTonomOUs Robust Network of Objects and Sensors (AE-TOURNOS) platform. We have two main goals: ﬁrstly conducting research in swarming/flocking of UAVs, mixing robotics, wireless sensor and actuator networks, and secondly using this as an application domain and a challenge/demo platform for other researches. After giving an overview of the project context, questions and contributions, we give details about our ﬁrst attempt to implement an autonomous flocking behavior based on a spring-damper model in sim–ulation, combining our ﬁrst physical experiments and developments with the potential hardware. The lessons learned help us build a research and action plan for the year to come. "
}
@article{Tang2012306,
title = "Formalization of workflows for extracting bridge surveying goals from laser-scanned data ",
journal = "Automation in Construction ",
volume = "22",
number = "",
pages = "306 - 319",
year = "2012",
note = "Planning Future Cities-Selected papers from the 2010 eCAADe Conference ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2011.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511001671",
author = "Pingbo Tang and Burcu Akinci",
keywords = "Surveying goal",
keywords = "Inspection automation",
keywords = "Scientific workflow",
keywords = "Geometric data collection",
keywords = "Geometric assessment",
keywords = "Information retrieval",
keywords = "Laser scanning",
keywords = "Bridge inspection",
keywords = "3D data processing ",
abstract = "Laser scanners enable bridge inspectors to collect dense 3D point clouds, which capture detailed geometries of bridges. While these data sets contain rich geometric information, they bring unique challenges related to geometric information retrieval. This paper describes a case study to show the necessity and potential value of automating the manual data processing workflows being executed for extracting geometric data items (surveying goals) from 3D point clouds, and presents an approach for formalizing these workflows to enable such automation. We analyzed manual procedures of taking measurements on 3D point clouds and as-built models for obtaining bridge inspection related surveying goals, synthesized and categorized all data processing operations into nine generic operations. These nine categories of operations can be formalized using &lt; operator, inputs, output, parameters, constraints&gt; tuples. Using these tuples, we formalized an operation library and workflow construction mechanisms for enabling inspectors to semi-automatically construct executable workflows. This formalism also incorporates several mechanisms for facilitating extensions to the existing operation library to accommodate additional surveying goals that have not been covered. The developed approach is validated for its generality to support workflows needed for all surveying goals required by the National Bridge Inventory (NBI) program, and for its extensibility to support workflows needed to support a variety of other surveying goals identified in the Architecture/Engineering/Construction domain. "
}
@article{Marion2001275,
title = "Calculation of solar radiation using a methodology with worldwide potential ",
journal = "Solar Energy ",
volume = "71",
number = "4",
pages = "275 - 283",
year = "2001",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/S0038-092X(01)00044-5",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X01000445",
author = "W. Marion and R. George",
abstract = "Surface meteorological observations from the \{DATSAV2\} database provide the capability to use the \{METSTAT\} (meteorological/statistical) model to calculate hourly values of direct normal, diffuse horizontal, and global horizontal solar radiation for locations throughout the world. Opaque cloud cover, a key input parameter to the \{METSTAT\} model, is derived from the \{DATSAV2\} layered cloud cover information. Resulting multiyear data sets include solar radiation and other meteorological data such as dry bulb temperature, dew point temperature, wind speed, and atmospheric pressure. Data filling procedures ensure that the multiyear data sets are serially complete. A minor revision to \{METSTAT\} improved solar radiation estimates for conditions of high cloud amounts and low ceiling heights. The methodology was applied to regions of Southern Africa and Saudi Arabia. "
}
@article{Tariq2015969,
title = "Analysis of optical and physical properties of aerosols during crop residue burning event of October 2010 over Lahore, Pakistan ",
journal = "Atmospheric Pollution Research ",
volume = "6",
number = "6",
pages = "969 - 978",
year = "2015",
note = "",
issn = "1309-1042",
doi = "https://doi.org/10.1016/j.apr.2015.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1309104215000082",
author = "Salman Tariq and Zia ul-Haq and Muhammad Ali",
keywords = "Crop residue burning",
keywords = "AERONET",
keywords = "Aerosol properties",
keywords = "Lahore ",
abstract = "Abstract Aerosols released from biomass burning affect the tropospheric chemistry, radiation budget and cloud processes and hence can cause significant climate modifications. Due to certain economical reasons, the open burning of crop residue has become popular in Pakistan. In the present work we have analyzed the optical and physical properties of aerosols during crop residue burning over Lahore, a central location of Pakistan. The data from ground based Aerosol Robotic Network (AERONET), satellite based \{MODIS\} and \{CALIPSO\} remote sensing instruments have been used for the characterization of aerosols during crop residue burning event of October 2010. The maximum value (2.75) of daily mean \{AOD\} was observed on 20 October 2010 and the next highest value of 2.64 was observed on 19 October 2010, indicating heavy aerosol loading over Lahore on both days due to intense crop residue burning. The fine mode \{AOD\} values ranged from 0.14 to 2.68 (on 20 October 2010) with average value of 0.87 during October 2010 over Lahore. It was found that fine mode aerosols have greater contribution than coarse mode aerosols towards total aerosol burden indicating the presence of fine mode (crop residue burning) aerosols over Lahore. Cluster analysis showed that the mixed aerosols (biomass burning and urban-industrial) were present during the heavy aerosol loading period over Lahore. The highest volume concentration of fine mode occurred on 19 and 20 October 2010 representing the dominance of fine mode aerosols. Due to scattering of incoming solar radiation by intense smoke observed on 19 and 20 October 2010 high values of \{SSA\} (∼0.95) were found. \{HYSPLIT\} model backward trajectories showed that the winds transported aerosols from southeast and northwest directions. "
}
@incollection{Chirikjian201199,
title = "Chapter four - Modeling Loop Entropy ",
editor = "Michael L. Johnson and Ludwig Brand",
booktitle = "Computer Methods, Part C",
publisher = "Academic Press",
year = "2011",
volume = "487",
pages = "99 - 132",
series = "Methods in Enzymology ",
issn = "0076-6879",
doi = "https://doi.org/10.1016/B978-0-12-381270-4.00004-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780123812704000044",
author = "Gregory S. Chirikjian",
keywords = "Protein folding",
keywords = "Entropy",
keywords = "Conformation",
keywords = "Ensemble",
keywords = "Convolution",
keywords = "Rigid-body motion",
keywords = "Probability density function",
keywords = "Polymer",
keywords = "Information theory ",
abstract = "Abstract Proteins fold from a highly disordered state into a highly ordered one. Traditionally, the folding problem has been stated as one of predicting “the” tertiary structure from sequential information. However, new evidence suggests that the ensemble of unfolded forms may not be as disordered as once believed, and that the native form of many proteins may not be described by a single conformation, but rather an ensemble of its own. Quantifying the relative disorder in the folded and unfolded ensembles as an entropy difference may therefore shed light on the folding process. One issue that clouds discussions of “entropy” is that many different kinds of entropy can be defined: entropy associated with overall translational and rotational Brownian motion, configurational entropy, vibrational entropy, conformational entropy computed in internal or Cartesian coordinates (which can even be different from each other), conformational entropy computed on a lattice, each of the above with different solvation and solvent models, thermodynamic entropy measured experimentally, etc. The focus of this work is the conformational entropy of coil/loop regions in proteins. New mathematical modeling tools for the approximation of changes in conformational entropy during transition from unfolded to folded ensembles are introduced. In particular, models for computing lower and upper bounds on entropy for polymer models of polypeptide coils both with and without end constraints are presented. The methods reviewed here include kinematics (the mathematics of rigid-body motions), classical statistical mechanics, and information theory. "
}
@article{So20131237,
title = "3DComplete: Efficient completeness inspection using a 2.5D color scanner ",
journal = "Computers in Industry ",
volume = "64",
number = "9",
pages = "1237 - 1252",
year = "2013",
note = "Special Issue: 3D Imaging in Industry ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2013.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S0166361513000675",
author = "Edmond Wai Yan So and Matteo Munaro and Stefano Michieletto and Stefano Tonello and Emanuele Menegatti",
keywords = "Completeness inspection",
keywords = "Laser triangulation",
keywords = "Image and range data fusion",
keywords = "3D reconstruction ",
abstract = "Abstract In this paper, we present a low-cost and highly configurable quality inspection system capable of capturing 2.5D color data, created using off-the-shelf machine vision components, open-source software libraries, and a combination of standard and novel algorithms for 2.5D data processing. The system uses laser triangulation to capture 3D depth, in parallel with a color camera and a line light projector to capture color texture, which are then combined into a color 2.5D model in real-time. Using many examples of completeness inspection tasks that are extremely difficult to solve with current 2D-based methods, we demonstrate how the 2.5D images and point clouds generated by our system can be used to solve these complex tasks effectively and efficiently. Our system is currently being integrated into a real production environment, showing that completeness inspection incorporating 3D technology can be readily achieved in a short time at low costs. "
}
@article{Karimi2017223,
title = "Semi-supervised classification in stratified spaces by considering non-interior points using Laplacian behavior ",
journal = "Neurocomputing ",
volume = "239",
number = "",
pages = "223 - 231",
year = "2017",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217302898",
author = "Zohre Karimi and Saeed Shiry Ghidary",
keywords = "Manifold",
keywords = "Semi-supervised",
keywords = "Laplacian",
keywords = "Stratified space ",
abstract = "Abstract Manifold-based semi-supervised classifiers have attracted increasing interest in recent years. However, they suffer from over learning of locality and cannot be applied to the point cloud sampled from a stratified space. This problem is resolved in this paper by using the fact that the smoothness assumption must be satisfied with the interior points of the manifolds and may be violated in the non-interior points. Distinction of interior and non-interior points is based on the behavior of graph Laplacian in the ϵ -neighborhood of the intersection points. First, this property was generalized to \{KNN\} graph representing the stratified space and then a new algorithm was proposed that penalizes the smoothness on the non-interior points of the manifolds by modifying the edge weights of the graph. Compared to some recent multi-manifold semi-supervised classifiers, the proposed method does not require neither knowing the dimensions of the manifolds nor large amount of unlabeled points to estimate the underling manifolds and does not assume similar properties for neighbors of all data points. Some experiments have been conducted in order to show that it improves the classification accuracy on a number of artificial and real benchmark data sets. "
}
@article{GutierrezGomez2015299,
title = "Curve-graph odometry: Orientation-free error parameterisations for loop closure problems ",
journal = "Robotics and Autonomous Systems ",
volume = "74, Part B",
number = "",
pages = "299 - 308",
year = "2015",
note = "Intelligent Autonomous Systems (IAS-13) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001645",
author = "Daniel Gutierrez-Gomez and J.J. Guerrero",
keywords = "Pose-graph optimisation",
keywords = "Loop closure",
keywords = "SLAM",
keywords = "Robot odometry ",
abstract = "Abstract During incremental odometry estimation in robotics and vision applications, the accumulation of estimation error produces a drift in the trajectory. This drift becomes observable when returning to previously visited areas, where it is possible to correct it by applying loop closing techniques. Ultimately a loop closing process leads to an optimisation problem where new constraints between poses obtained from loop detection are applied to the initial incremental estimate of the trajectory. Typically this optimisation is jointly applied on the position and orientation of each pose of the robot using the state-of-the-art pose graph optimisation scheme on the manifold of the rigid body motions. In this paper we propose to address the loop closure problem using only the positions and thus removing the orientations from the optimisation vector. The novelty in our approach is that, instead of treating trajectory as a set of poses, we look at it as a curve in its pure mathematical meaning. We define an observation function which computes the estimate of one constraint in a local reference frame using only the robot positions. Our proposed method is compared against state-of-the-art pose graph optimisation algorithms in 2 and 3 dimensions. The benefit of eliminating orientations is twofold. First, the objective function in the optimisation does not mix translation and rotation terms, which may have different scales. Second, computational performance can be improved due to the reduction in the state dimension of the nodes of the graph. "
}
@article{Będkowski201478,
title = "Towards terrestrial 3D data registration improved by parallel programming and evaluated with geodetic precision ",
journal = "Automation in Construction ",
volume = "47",
number = "",
pages = "78 - 91",
year = "2014",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2014.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0926580514001642",
author = "Janusz Będkowski and Karol Majek and Pawel Musialik and Artur Adamek and Dariusz Andrzejewski and Damian Czekaj",
keywords = "Iterative closest point",
keywords = "Data registration",
keywords = "Mobile mapping",
keywords = "CUDA parallel programming",
keywords = "Spatial design support ",
abstract = "Abstract In this paper a quantitative and qualitative evaluation of proposed ICP-based data registration algorithm, improved by parallel programming in \{CUDA\} (compute unified device architecture), is shown. The algorithm was tested on data collected with a 3D terrestrial laser scanner Z + F Imager 5010 mounted on the mobile platform \{PIONNER\} 3AT. Parallel implementation enables data registration on-line, even using a laptop with a standard hardware configuration (graphic card \{NVIDIA\} GeForce 6XX/7XX series). Robustness is assured by the use of CUDA-enhanced fast \{NNS\} (nearest neighbor search) applied for \{ICP\} (iterative closest point) with \{SVD\} (singular value decomposition) solver. The evaluation is based on the reference ground truth data registered with geodetic precision. The geodetic approach extends our previous work and gives an accurate benchmark for the algorithm. The data were collected in an urban area under a demolition scenario in a real environment. We compared four registration strategies concerning data preprocessing, such as subsampling and vegetation removal. The result is the analysis of measured performance and the accuracy of the geometric maps. The system provides accurate metric maps on-line and can be used in several applications such as mobile robotics for construction area modelling or spatial design support. It is a core component for our future work on mobile mapping systems. "
}
@article{Carozza201319,
title = "Error analysis of satellite attitude determination using a vision-based approach ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "83",
number = "",
pages = "19 - 29",
year = "2013",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2013.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0924271613001354",
author = "Ludovico Carozza and Alessandro Bevilacqua",
keywords = "Vision",
keywords = "Image registration",
keywords = "Error analysis",
keywords = "Accuracy analysis",
keywords = "Satellite",
keywords = "Feature tracking ",
abstract = "Abstract Improvements in communication and processing technologies have opened the doors to exploit on-board cameras to compute objects’ spatial attitude using only the visual information from sequences of remote sensed images. The strategies and the algorithmic approach used to extract such information affect the estimation accuracy of the three-axis orientation of the object. This work presents a method for analyzing the most relevant error sources, including numerical ones, possible drift effects and their influence on the overall accuracy, referring to vision-based approaches. The method in particular focuses on the analysis of the image registration algorithm, carried out through on-purpose simulations. The overall accuracy has been assessed on a challenging case study, for which accuracy represents the fundamental requirement. In particular, attitude determination has been analyzed for small satellites, by comparing theoretical findings to metric results from simulations on realistic ground-truth data. Significant laboratory experiments, using a numerical control unit, have further confirmed the outcome. We believe that our analysis approach, as well as our findings in terms of error characterization, can be useful at proof-of-concept design and planning levels, since they emphasize the main sources of error for visual based approaches employed for satellite attitude estimation. Nevertheless, the approach we present is also of general interest for all the affine applicative domains which require an accurate estimation of three-dimensional orientation parameters (i.e., robotics, airborne stabilization). "
}
@article{Chao201325,
title = "Virtual Interactive Musculoskeletal System (VIMS) in orthopaedic translational research ",
journal = "Journal of Orthopaedic Translation ",
volume = "1",
number = "1",
pages = "25 - 40",
year = "2013",
note = "",
issn = "2214-031X",
doi = "https://doi.org/10.1016/j.jot.2013.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S2214031X13000107",
author = "Edmund Y.S. Chao and Jonathan Lim",
keywords = "Graphic-based modelling",
keywords = "Musculoskeletal biomechanical analyses",
keywords = "Simulation and animation",
keywords = "Translational research",
keywords = "Visualisation ",
abstract = "Summary The ability to combine physiology and engineering analyses with computer sciences has opened the door to the possibility of creating the “Virtual Human.” This paper presents a broad foundation for a full-featured biomechanical simulator for the human musculoskeletal system. This simulation technology unites the expertise in engineering sciences and graphic modelling to investigate joint and connective tissue mechanics at the structural level and to visualize the results in both static and animated dynamic forms. Adaptable anatomical models including prosthetic implants and fracture fixation devices and a robust computational infrastructure for static, kinematic, kinetic, and stress analyses under varying boundary and loading conditions are incorporated on a platform, the Virtual Interactive Musculoskeletal System (VIMS), ideal for a cloud computing environment. A deployable database containing long bone dimensions, connective tissue material properties, and a library of skeletal joint system functional activities and loading conditions are also available that can be modified, updated, and expanded. An application software is available that allows end users to perform biomechanical analyses interactively. An example using the forearm and hand bone models plus a unilateral external fixator to study the distal radius fracture reduction in a virtual laboratory environment is highlighted to demonstrate this unique simulation technology in the field of orthopaedics. "
}
@article{Bobka2016187,
title = "Simulation Platform to Investigate Safe Operation of Human-Robot Collaboration Systems ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "187 - 192",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.01.199",
url = "http://www.sciencedirect.com/science/article/pii/S221282711600439X",
author = "Paul Bobka and Tomas Germann and Jakob K. Heyn and Roman Gerbers and Franz Dietrich and Klaus Dröder",
keywords = "Simulation",
keywords = "Human-Robot-Collaboration",
keywords = "Safety ",
abstract = "Abstract In industrial human-robot collaboration (HRC) the question, how can such systems be designed safely is paramount. In general, it is difficult to assess those systems with all their capabilities prior to commissioning. In this paper we propose specialized simulation tools as one potential solution to this issue. We use real-world geometrical data to investigate different algorithms and safety strategies. One strategy is the use of a genetic algorithm for collision avoidance to deal with amounts of data in short computing times. This is a solution to find a safe distance with adaptive speed in \{HRC\} assembly applications. "
}
@article{Barki2009525,
title = "Contributing vertices-based Minkowski sum computation of convex polyhedra ",
journal = "Computer-Aided Design ",
volume = "41",
number = "7",
pages = "525 - 538",
year = "2009",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2009.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0010448509000724",
author = "Hichem Barki and Florence Denis and Florent Dupont",
keywords = "Minkowski sum",
keywords = "Contributing vertices",
keywords = "Slope diagram",
keywords = "Convex hull",
keywords = "Computer-aided design ",
abstract = "Minkowski sum is an important operation. It is used in many domains such as: computer-aided design, robotics, spatial planning, mathematical morphology, and image processing. We propose a novel algorithm, named the Contributing Vertices-based Minkowski Sum (CVMS) algorithm for the computation of the Minkowski sum of convex polyhedra. The \{CVMS\} algorithm allows to easily obtain all the facets of the Minkowski sum polyhedron only by examining the contributing vertices—a concept we introduce in this work, for each input facet. We exploit the concept of contributing vertices to propose the Enhanced and Simplified Slope Diagram-based Minkowski Sum (ESSDMS) algorithm, a slope diagram-based Minkowski sum algorithm sharing some common points with the approach proposed by Wu et al. [Wu Y, Shah J, Davidson J. Improvements to algorithms for computing the Minkowski sum of 3-polytopes. Comput Aided Des. 2003; 35(13): 1181–92]. The \{ESSDMS\} algorithm does not embed input polyhedra on the unit sphere and does not need to perform stereographic projections. Moreover, the use of contributing vertices brings up more simplifications and improves the overall performance. The implementations for the mentioned algorithms are straightforward, use exact number types, produce exact results, and are based on CGAL, the Computational Geometry Algorithms Library. More examples and results of the \{CVMS\} algorithm for several convex polyhedra can be found at http://liris.cnrs.fr/hichem.barki/mksum/CVMS-convex. "
}
@article{Colomina201479,
title = "Unmanned aerial systems for photogrammetry and remote sensing: A review ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "92",
number = "",
pages = "79 - 97",
year = "2014",
note = "",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2014.02.013",
url = "http://www.sciencedirect.com/science/article/pii/S0924271614000501",
author = "I. Colomina and P. Molina",
keywords = "UAV",
keywords = "Review",
keywords = "Photogrammetry",
keywords = "Remote sensing ",
abstract = "Abstract We discuss the evolution and state-of-the-art of the use of Unmanned Aerial Systems (UAS) in the field of Photogrammetry and Remote Sensing (PaRS). UAS, Remotely-Piloted Aerial Systems, Unmanned Aerial Vehicles or simply, drones are a hot topic comprising a diverse array of aspects including technology, privacy rights, safety and regulations, and even war and peace. Modern photogrammetry and remote sensing identified the potential of UAS-sourced imagery more than thirty years ago. In the last five years, these two sister disciplines have developed technology and methods that challenge the current aeronautical regulatory framework and their own traditional acquisition and processing methods. Navety and ingenuity have combined off-the-shelf, low-cost equipment with sophisticated computer vision, robotics and geomatic engineering. The results are cm-level resolution and accuracy products that can be generated even with cameras costing a few-hundred euros. In this review article, following a brief historic background and regulatory status analysis, we review the recent unmanned aircraft, sensing, navigation, orientation and general data processing developments for \{UAS\} photogrammetry and remote sensing with emphasis on the nano-micro-mini \{UAS\} segment. "
}
@article{Bayat2010503,
title = "\{SLAM\} for an \{AUV\} using vision and an acoustic beacon ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "16",
pages = "503 - 508",
year = "2010",
note = "7th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20100906-3-IT-2019.00087",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016351072",
author = "M. Bayat and A. Pedro Aguiar",
keywords = "Underwater Vision",
keywords = "IMU",
keywords = "Extended Kalman Filter",
keywords = "Multiple Model Adaptive Estimator",
keywords = "Simultaneous Localization And Mapping",
keywords = "Pose Estimation ",
abstract = "Abstract The estimation of the position and attitude of an autonomous underwater vehicle (AUV) is a challenging and important problem in marine robotics. It is well known that the underwater environment posses considerable problems, that include i) the fact that there is no \{GPS\} signal, ii) the communication is usually done through acoustic signals, which suffers from faults, delays and low bandwidth, and iii) the use of vision and/or laser is very limited due to poor visibility. In this paper, we combine a multiple set of sensors to address the full state 6DOF pose estimation of an AUV. The problem is formulated assuming that we have partial measurements from an Inertial Measurement Unit (IMU), an acoustic ranging from a single beacon buoy, and a monocular camera attached to the AUV. Using multiple model estimation techniques and the concept of Extended Kalman Filters with Simultaneous Localization and Mapping (EKF-SLAM), we propose an algorithm that integrates the \{AUV\} measurements (that arrive at different sampling-times) and compute in real time an estimate of the position and attitude of the AUV. Simulation results are presented and discussed. "
}
@article{Bradley201557,
title = "The Internet of Things – The future or the end of mechatronics ",
journal = "Mechatronics ",
volume = "27",
number = "",
pages = "57 - 74",
year = "2015",
note = "",
issn = "0957-4158",
doi = "https://doi.org/10.1016/j.mechatronics.2015.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0957415815000215",
author = "David Bradley and David Russell and Ian Ferguson and John Isaacs and Allan MacLeod and Roger White",
keywords = "Internet of Things",
keywords = "Mechatronics",
keywords = "Design",
keywords = "Education",
keywords = "System security",
keywords = "Participatory systems ",
abstract = "Abstract The advent and increasing implementation of user configured and user oriented systems structured around the use of cloud configured information and the Internet of Things is presenting a new range and class of challenges to the underlying concepts of integration and transfer of functionality around which mechatronics is structured. It is suggested that the ways in which system designers and educators in particular respond to and manage these changes and challenges is going to have a significant impact on the way in which both the Internet of Things and mechatronics develop over time. The paper places the relationship between the Internet of Things and mechatronics into perspective and considers the issues and challenges facing systems designers and implementers in relation to managing the dynamics of the changes required. "
}
@article{Holz20141282,
title = "Approximate triangulation and region growing for efficient segmentation and smoothing of range images ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "9",
pages = "1282 - 1293",
year = "2014",
note = "Intelligent Autonomous Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000578",
author = "Dirk Holz and Sven Behnke",
keywords = "Scene understanding",
keywords = "Range image segmentation",
keywords = "Approximate triangulation",
keywords = "Multilateral smoothing ",
abstract = "Abstract Decomposing sensory measurements into coherent parts is a fundamental prerequisite for scene understanding that is required for solving complex tasks, e.g., in the field of mobile manipulation. In this article, we describe methods for efficient segmentation of range images and organized point clouds. In order to achieve real-time performance in complex environments, we focus our approach on simple but robust solutions. We present a fast approach to surface reconstruction in range images and organized point clouds by means of approximate polygonal meshing. The obtained local surface information and neighborhoods are then used to (1) smooth the underlying measurements, and (2) segment the image into planar regions and other geometric primitives. A comparative evaluation using publicly available data sets shows that our approach achieves state-of-the-art performance while being significantly faster than other methods. "
}
@article{Dimenstein2013448,
title = "Development of a laboratory niche Web site ",
journal = "Annals of Diagnostic Pathology ",
volume = "17",
number = "5",
pages = "448 - 456",
year = "2013",
note = "",
issn = "1092-9134",
doi = "https://doi.org/10.1016/j.anndiagpath.2013.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1092913413000567",
author = "Izak B. Dimenstein and Simon I. Dimenstein",
keywords = "Niche website",
keywords = "Nested doll principle",
keywords = "Websites portal ",
abstract = "Abstract This technical note presents the development of a methodological laboratory niche Web site. The “Grossing Technology in Surgical Pathology” (www.grossing-technology.com) Web site is used as an example. Although common steps in creation of most Web sites are followed, there are particular requirements for structuring the template's menu on methodological laboratory Web sites. The “nested doll principle,” in which one object is placed inside another, most adequately describes the methodological approach to laboratory Web site design. Fragmentation in presenting the Web site's material highlights the discrete parts of the laboratory procedure. An optimally minimal triad of components can be recommended for the creation of a laboratory niche Web site: a main set of media, a blog, and an ancillary component (host, contact, and links). The inclusion of a blog makes the Web site a dynamic forum for professional communication. By forming links and portals, cloud computing opens opportunities for connecting a niche Web site with other Web sites and professional organizations. As an additional source of information exchange, methodological laboratory niche Web sites are destined to parallel both traditional and new forms, such as books, journals, seminars, webinars, and internal educational materials. "
}
@article{Krupitzer2015184,
title = "A survey on engineering approaches for self-adaptive systems ",
journal = "Pervasive and Mobile Computing ",
volume = "17, Part B",
number = "",
pages = "184 - 206",
year = "2015",
note = "10 years of Pervasive Computing' In Honor of Chatschik Bisdikian ",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2014.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S157411921400162X",
author = "Christian Krupitzer and Felix Maximilian Roth and Sebastian VanSyckel and Gregor Schiele and Christian Becker",
keywords = "Taxonomy",
keywords = "Self-adaptation",
keywords = "Survey",
keywords = "Self-adaptive systems",
keywords = "Context adaptation ",
abstract = "Abstract The complexity of information systems is increasing in recent years, leading to increased effort for maintenance and configuration. Self-adaptive systems (SASs) address this issue. Due to new computing trends, such as pervasive computing, miniaturization of \{IT\} leads to mobile devices with the emerging need for context adaptation. Therefore, it is beneficial that devices are able to adapt context. Hence, we propose to extend the definition of \{SASs\} and include context adaptation. This paper presents a taxonomy of self-adaptation and a survey on engineering SASs. Based on the taxonomy and the survey, we motivate a new perspective on \{SAS\} including context adaptation. "
}
@article{Gaftea2014336,
title = "Socio-economic Major Risks Related to the Information Technology ",
journal = "Procedia Economics and Finance ",
volume = "8",
number = "",
pages = "336 - 345",
year = "2014",
note = "1st International Conference 'Economic Scientific Research - Theoretical, Empirical and Practical Approaches', \{ESPERA\} 2013 ",
issn = "2212-5671",
doi = "https://doi.org/10.1016/S2212-5671(14)00099-9",
url = "http://www.sciencedirect.com/science/article/pii/S2212567114000999",
author = "Viorel Gaftea",
keywords = "cyber security",
keywords = "national impact",
keywords = "major risks ",
abstract = "Abstract Economy underwent a strong transformation in the last decade. Computerization, cybernetics, industrial robotics, communication and management are activities depending by IT.Society is knowledge based on \{IT\} and depending by online. Threats in the online reaches fever. Targets are critical infrastructure, telecommunications, energy, health, government and banking systems. Now there are on the pressure of cyber-attacks by multiple entities. Hackers evolve from “classic” e-mail infiltration or break websites of governmental institutions, to the cyber war as one of the newest and irregular forms of modern conflicts. The Risks are major and affect at nationally level and require preventive actions.Research is directed towards technology development, high level of computer usage and modern solutions for information management, risk control and total computerization of all activities. In social, educationalarea the man isin user position, as target or initiator ofthe own actions but sometimes author of the risk generating actions.IT these generates major risks and required standards, policies, procedures and risk protection, “instruments for systems in public and privatearea and for communicationequipment's using IT”. Todayeconomy is based on all these elements and the evaluation of major risks related to the information technology become main priority. "
}
@article{Castelli2014603,
title = "The HelioMont method for assessing solar irradiance over complex terrain: Validation and improvements ",
journal = "Remote Sensing of Environment ",
volume = "152",
number = "",
pages = "603 - 613",
year = "2014",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2014.07.018",
url = "http://www.sciencedirect.com/science/article/pii/S0034425714002673",
author = "M. Castelli and R. Stöckli and D. Zardi and A. Tetzlaff and J.E. Wagner and G. Belluardo and M. Zebisch and M. Petitta",
keywords = "Solar surface irradiance",
keywords = "Diffuse radiation",
keywords = "Aerosols",
keywords = "Radiative transfer modeling",
keywords = "Remote sensing ",
abstract = "Abstract This study evaluates the suitability of the method HelioMont, developed by MeteoSwiss, for estimating solar radiation from geostationary satellite data over the Alpine region. The algorithm accounts for the influence of topography, clouds, snow cover and the atmosphere on incoming solar radiation. The main error sources are investigated for both direct and diffuse solar radiation components by comparison with ground-based measurement taken at three sites, namely Bolzano (IT), Davos (CH) and Payerne (CH), encompassing different topographic conditions. The comparison shows that the method provides high accuracy of the yearly cycle: the Mean Absolute Bias (MAB) is below 5 W m− 2 at the lowland station Payerne and below 12 W m− 2 at the other two mountainous stations for the monthly averages of global and diffuse radiation. For diffuse radiation the \{MAB\} is in the range 11–15 W m− 2 for daily means and 34–40 W m− 2 for hourly means. It is found that the largest errors in diffuse and direct radiation components on shorter time scales occur during summer and for cloud-free days. In both Bolzano and Davos the errors for daily-mean diffuse radiation can exceed 50 W m− 2 under such conditions. As HelioMont uses monthly climatological values of atmospheric aerosol characteristics, the effects of this approximation are investigated by simulating clear-sky solar radiation with the radiative transfer model (RTM) libRadtran using instantaneous aerosol measurements. Both ground-based and satellite-based data on aerosol optical properties and water vapor column amount are evaluated. When using daily atmospheric input the estimation of the hourly averages improves significantly and the mean error is reduced to 10–20 W m− 2. These results suggest the need for a more detailed characterization of the local-scale clear-sky atmospheric conditions for modeling solar radiation on daily and hourly time scales. "
}
@article{Magalhães201342,
title = "Autonomous Vehicle Navigation in Semi-Structured Urban Environment ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "42 - 47",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00051",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349077",
author = "André Chaves Magalhães and Marcos Prado and Valdir Grassi Jr and Denis Fernando Wolf",
keywords = "autonomous vehicle",
keywords = "lattice planner",
keywords = "autonomous navigation ",
abstract = "Abstract Recent advances in mobile robotic research have contributed to the development of autonomous driving systems for intelligent robotic vehicles. The motion planner is the component of the intelligent system responsible for planning a path that leads the vehicle from its current state to the desired goal state avoiding obstacles in the environment. This paper describes the use of a motion planning method based on lattice state space and anytime dynamic A* applied to our autonomous vehicle for navigation in a semi-structured urban environment. We created a 3D simulation model of our vehicle, implemented the motion planner approach described here and conducted experiments in both simulated and real parking lots. "
}
@article{Lee201431,
title = "Improved volcanic ash detection based on a hybrid reverse absorption technique ",
journal = "Atmospheric Research ",
volume = "143",
number = "",
pages = "31 - 42",
year = "2014",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2014.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S0169809514000210",
author = "Kwon Ho Lee and Man Sing Wong and Sung-Rae Chung and Eunha Sohn",
keywords = "Volcanic ash",
keywords = "Reverse absorption",
keywords = "Hybrid algorithm",
keywords = "MODIS",
keywords = "Brightness temperature ",
abstract = "Abstract A noble volcanic ash (VA) detection method based on a hybrid reverse absorption technique was successfully applied in the analysis of major volcanic eruptions that occurred in Russia, Iceland, Chile, Italy, and Japan by using the MODerate-resolution Imaging Spectroradiometer (MODIS) observation data. Sensitivity studies using radiative-transfer simulations by using various environmental parameters such as ash loadings, sizes, layer heights, and surface emissions, revealed that \{VA\} effects on brightness temperatures (BT) can reach up to 40 K. The advantage of the hybrid algorithm is its ability to detect distinct \{VA\} pixels during the day and night from satellite observations. The results showed that the hybrid algorithm can minimize the false detection of \{VA\} pixels, while well-known reverse absorption methods show abundant false \{VA\} pixels over bright surfaces and cloud formations. Further, the time-and-space distribution of the \{VA\} pixels is in good agreement with the data pertaining to operational aerosol products obtained from the scanning imaging absorption spectrometer for atmospheric cartography (SCIAMACHY) instrument on board ESA's Envisat and the cloud-aerosol Lidar and infrared pathfinder satellite observations (CALIPSO). This novel algorithm is expected to provide a fine spatial and temporal resolution of \{VA\} monitoring from high spectral or geostationary satellite observation data. "
}
@article{Wörn2001753,
title = "Computer- and robot-based operation theatre of the future in cranio-facial surgery ",
journal = "International Congress Series ",
volume = "1230",
number = "",
pages = "753 - 759",
year = "2001",
note = "Computer Assisted Radiology and Surgery ",
issn = "0531-5131",
doi = "https://doi.org/10.1016/S0531-5131(01)00127-3",
url = "http://www.sciencedirect.com/science/article/pii/S0531513101001273",
author = "Heinz Wörn and Joachim Mühling",
keywords = "Operation theatre",
keywords = "Cranio-facial surgery",
keywords = "3D surface models",
keywords = "Operation planning",
keywords = "Augmented reality",
keywords = "Robot system ",
abstract = "This paper presents an overview of our research in medical high-tech computing and robot-based surgical intervention in cranio facial surgery defining an operation theatre of the future. Our overall goal is to provide improved operation methods and workflows—high-quality, safer and more economical due to shorter operation time and less postoperative treatment. Our operation theatre of the future includes workflow definition as well as high-tech hardware and software systems for pre- and intraoperative steps and the operation room itself. The system's workflow consists of dedicated tasks for image acquisition up to intraoperative application, which jointly integrates to a workflow attending conventional surgical proceeding. Thus, managing highly complex systems like surgical robots or operation planning tools is easy as we follow the surgeon's well-known pre- and intraoperative processes. Modules within the workflow can be categorized by image acquisition, data modeling, operation planning and simulation, and supervision of surgery or intraoperative execution, respectively. The intraoperative setting of the operation theatre of the future involves, e.g. visualization techniques for Virtual and Augmented Reality, heart–lung machine control and the application of surgical robotics. The workflow settings with first-system modules of our operation theatre of the future already showed its potential during the initial clinical evaluation and have been presented at the largest German exhibition for medical systems called \{MEDICA\} in 2000. "
}
@article{MorenoGarcía201650,
title = "Consensus of multiple correspondences between sets of elements ",
journal = "Computer Vision and Image Understanding ",
volume = "142",
number = "",
pages = "50 - 64",
year = "2016",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215001836",
author = "Carlos Francisco Moreno-García and Francesc Serratosa",
keywords = "Consensus",
keywords = "Points’ correspondence",
keywords = "Feature extraction",
keywords = "Linear solver",
keywords = "Hamming distance",
keywords = "Image registration ",
abstract = "Abstract In many pattern recognition and computer vision problems, it is often necessary to compare multiple sets of elements that are completely or partially overlapping and possibly corrupted by noise. Finding a correspondence between elements from the different sets is one of the crucial tasks that several computer vision, robotics or image registration methods have to cope with. The aim of this paper is to find a consensus correspondence between two sets of points, given several initial correspondences between these two sets. We present three different methods: iterative, voting and agglomerative. If the noise randomly affects the original data, we suppose that, while using the deducted correspondence, the process obtains better results than each individual correspondence. The different correspondences between two sets of points are obtained through different feature extractors or matching algorithms. Experimental validation shows the runtime and accuracy for the three methodologies. The agglomerative method obtains the highest accuracy compared to the other consensus methods and also the individual ones, while obtaining an acceptable runtime. "
}
@article{Zambonelli20051,
title = "Spray computers: Explorations in self-organization ",
journal = "Pervasive and Mobile Computing ",
volume = "1",
number = "1",
pages = "1 - 20",
year = "2005",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2005.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S1574119205000027",
author = "Franco Zambonelli and Marie-Pierre Gleizes and Marco Mamei and Robert Tolksdorf",
keywords = "Spray computers",
keywords = "Bottom-up software engineering",
keywords = "Self-organization ",
abstract = "We envision a future in which clouds of microcomputers can be sprayed in an environment to provide, by spontaneously networking with each other, an endlessly range of futuristic applications. However, beside the vision, spraying may also act as a powerful metaphor for a range of other scenarios that are already under formation, from ad hoc networks of embedded and mobile devices to worldwide distributed computing. After having detailed the different spray computers scenarios and their applications, this paper discusses the issues related to the design and development of spray computer applications, issues which call for novel autonomic approaches exploiting self-organization as first-class tools. Finally, this paper presents the key research efforts being taken in the area and attempts at defining a rough research agenda. "
}
@article{Lee20163,
title = "RGB-D camera based wearable navigation system for the visually impaired ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "3 - 20",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - "Assistive Solutions for Mobility, Communication and HMI" ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.019",
url = "http://www.sciencedirect.com/science/article/pii/S1077314216300248",
author = "Young Hoon Lee and Gérard Medioni",
keywords = "Wearable navigation system",
keywords = "Visual SLAM",
keywords = "Assistive technologies for the visually impaired ",
abstract = "Abstract In this paper, a novel wearable RGB-D camera based indoor navigation system for the visually impaired is presented. The system guides the visually impaired user from one location to another location without a prior map or \{GPS\} information. Accurate real-time egomotion estimation, mapping, and path planning in the presence of obstacles are essential for such a system. We perform real-time 6-DOF egomotion estimation using sparse visual features, dense point clouds, and the ground plane to reduce drift from a head-mounted RGB-D camera. The system also builds 2D probabilistic occupancy grid map for efficient traversability analysis which is a basis for dynamic path planning and obstacle avoidance. The system can store and reload maps generated by the system while traveling and continually expand the coverage area of navigation. Next, the shortest path between the start location to destination is generated. The system generates a safe and efficient way point based on the traversability analysis result and the shortest path and updates the way point while a user is constantly moving. Appropriate cues are generated and delivered to a tactile feedback system to guide the visually impaired user to the way point. The proposed wearable system prototype is composed of multiple modules including a head-mounted RGB-D camera, standard laptop that runs a navigation software, smart phone user interface, and haptic feedback vest. The proposed system achieves real-time navigation performance at 28.6Hz in average on a laptop, and helps the visually impaired extends the range of their activities and improve the orientation and mobility performance in a cluttered environment. We have evaluated the performance of the proposed system in mapping and localization with blind-folded and the visually impaired subjects. The mobility experiment results show that navigation in indoor environments with the proposed system avoids collisions successfully and improves mobility performance of the user compared to conventional and state-of-the-art mobility aid devices. "
}
@article{Vinayak|Ramani2016143,
title = "Extracting hand grasp and motion for intent expression in mid-air shape deformation: A concrete and iterative exploration through a virtual pottery application ",
journal = "Computers & Graphics ",
volume = "55",
number = "",
pages = "143 - 156",
year = "2016",
note = "",
issn = "0097-8493",
doi = "https://doi.org/10.1016/j.cag.2015.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S009784931500179X",
author = "Vinayak and Karthik Ramani",
keywords = "Mid-air gestures",
keywords = "Depth sensor",
keywords = "Virtual pottery",
keywords = "Shape deformation",
keywords = "Hand grasp ",
abstract = "Abstract We describe the iterative design and evaluation of a geometric interaction technique for bare-hand mid-air virtual pottery. We model the shaping of a pot as a gradual and progressive convergence of the pot-profile to the shape of the user׳s hand represented as a point-cloud (PCL). Our pottery-inspired application served as a platform for systematically revealing how users use their hands to express the intent of deformation during a pot shaping process. Our approach involved three stages: (a) clutching by proximal-attraction, (b) shaping by proximal-attraction, and (c) shaping by grasp+motion. The design and implementation of each stage was informed by user evaluations of the previous stage. Our work evidently demonstrates that it is possible to enable users to express their intent for shape deformation without the need for a fixed set of gestures for clutching and deforming a shape. We found that the expressive capability of hand articulation can be effectively harnessed for controllable shaping by organizing the deformation process in broad classes of intended operations such as pulling, pushing, and fairing. After minimal practice with the pottery application, users could figure out their own strategy for reaching, grasping, and deforming the pot. Users particularly enjoyed using day-to-day physical objects as tools for shaping pots. "
}
@article{Alletto2017274,
title = "Video registration in egocentric vision under day and night illumination changes ",
journal = "Computer Vision and Image Understanding ",
volume = "157",
number = "",
pages = "274 - 283",
year = "2017",
note = "Large-Scale 3D Modeling of Urban Indoor or Outdoor Scenes from Images and Range Scans ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S107731421630145X",
author = "Stefano Alletto and Giuseppe Serra and Rita Cucchiara",
keywords = "Video registration",
keywords = "Egocentric vision",
keywords = "Visual matching ",
abstract = "Abstract With the spread of wearable devices and head mounted cameras, a wide range of application requiring precise user localization is now possible. In this paper we propose to treat the problem of obtaining the user position with respect to a known environment as a video registration problem. Video registration, i.e. the task of aligning an input video sequence to a pre-built 3D model, relies on a matching process of local keypoints extracted on the query sequence to a 3D point cloud. The overall registration performance is strictly tied to the actual quality of this 2D-3D matching, and can degrade if environmental conditions such as steep changes in lighting like the ones between day and night occur. To effectively register an egocentric video sequence under these conditions, we propose to tackle the source of the problem: the matching process. To overcome the shortcomings of standard matching techniques, we introduce a novel embedding space that allows us to obtain robust matches by jointly taking into account local descriptors, their spatial arrangement and their temporal robustness. The proposal is evaluated using unconstrained egocentric video sequences both in terms of matching quality and resulting registration performance using different 3D models of historical landmarks. The results show that the proposed method can outperform state of the art registration algorithms, in particular when dealing with the challenges of night and day sequences. "
}
@incollection{Yang2013817,
title = "Chapter 23 - Programming for I/O and Storage ",
editor = "Oshana, Robert and ,  and Kraeling, Mark ",
booktitle = "Software Engineering for Embedded Systems ",
publisher = "Newnes",
edition = "",
address = "Oxford",
year = "2013",
pages = "817 - 877",
isbn = "978-0-12-415917-4",
doi = "https://doi.org/10.1016/B978-0-12-415917-4.00023-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780124159174000232",
author = "Xin-Xin Yang",
keywords = "input and output (I/O) devices",
keywords = "flash",
keywords = "SD/SDHC",
keywords = "disk drive",
keywords = "Linux device driver",
keywords = "storage programming",
keywords = "storage performance optimization",
keywords = "case studies ",
abstract = "Input and output (I/O) devices are very important components in embedded systems. I/O diversity makes I/O management in embedded systems a very complicated process. One of the basic functions of an embedded operating system is to control and manage all of the I/O devices, and to coordinate multiple processes accessing I/O devices simultaneously. The key function for device management is to control I/O implementation between the \{CPU\} and the devices. The operating system must send commands to the devices, respond to interrupts and handle exceptions from the devices. It should also provide a simple and easy-to-use interface between the devices and other parts of the system. The I/O management module needs to improve parallel processing capabilities between the \{CPU\} and I/O devices as well between I/O devices. To get the best utilization efficiency of the system resources, I/O management modules should provide a unified, transparent, independent and scalable I/O interface. Storage in this book refers to external storage devices such as NOR/NAND flash, eSDHC, U-Disk, \{HDD\} and SSD, which are commonly used in embedded systems. With the recent development of cloud computing, storage technology plays an increasingly important role in systems. This chapter will discuss data transfer modes between \{CPU\} and I/O devices, interrupt technology, I/O control processes and the corresponding device driver implementation process. The programming model of storage devices is also discussed, including feature support and performance optimization. "
}
@article{Lu201683,
title = "Where am I in the dark: Exploring active transfer learning on the use of indoor localization based on thermal imaging ",
journal = "Neurocomputing ",
volume = "173, Part 1",
number = "",
pages = "83 - 92",
year = "2016",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.07.106",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215011261",
author = "Guoyu Lu and Yan Yan and Li Ren and Philip Saponaro and Nicu Sebe and Chandra Kambhamettu",
keywords = "Image-based localization",
keywords = "Active transfer learning",
keywords = "Thermal imaging ",
abstract = "Abstract Indoor localization is one of the key problems in robotics research. Most current localization systems use cellular base stations and Wifi signals, whose localization accuracy is largely dependent on the signal strength and is sensitive to environmental changes. With the development of camera-based technologies, image-based localization may be employed in an indoor environment where the \{GPS\} signal is weak. Most of the existing image-based localization systems are based on color images captured by cameras, but this is only feasible in environments with adequate lighting conditions. In this paper, we introduce an image-based localization system based on thermal imaging to make the system independent of light sources, which are especially useful during emergencies such as a sudden power outage in a building. As thermal images are not obtained as easily as color images, we apply active transfer learning to enrich the thermal image classification learning, where normal \{RGB\} images are treated as the source domain, and thermal images are the target domain. The application of active transfer learning avoids random target training sample selection and chooses the most informative samples in the learning process. Through the proposed active transfer learning, the query thermal images can be accurately used to indicate the location. Experiments show that our system can be efficiently deployed to perform indoor localization in a dark environment. "
}
@incollection{Chuvakin201371,
title = "Chapter 4 - Log Storage Technologies ",
editor = "Chuvakin, Anton and , and Schmidt, Kevin and ,  and Phillips, Chris ",
booktitle = "Logging and Log Management ",
publisher = "Syngress",
edition = "",
address = "Boston",
year = "2013",
pages = "71 - 91",
isbn = "978-1-59749-635-3",
doi = "https://doi.org/10.1016/B978-1-59-749635-3.00004-X",
url = "http://www.sciencedirect.com/science/article/pii/B978159749635300004X",
author = "Anton Chuvakin and Kevin Schmidt and Chris Phillips",
abstract = "Abstract This chapter provides details on developing a log retention policy and the storage techniques for log information. The idea is to expose the reader to the broad spectrum of storage techniques and provide retention guidance for the log information commonly found in environments and detail some of the inherit challenges and benefits in retention and storage of this information. This chapter will lay the groundwork for reviewing the many open source and commercial toolsets available for log management and retention and their viability in retaining the many types of log information the reader has in their environment today. Key concepts in this chapter will broaden the reader’s perspective for later planning chapters and help them develop a plan that accommodates future growth and compliance log retention policy needs. Keywords Syslog, Database, RDBMS, Hadoop, Amazon Elastic MapReduce (EMR), Amazon Simple Storage Service (S3), Amazon Elastic Compute Cloud (EC2), Pig, Pig Latin, Log rotation, Log compression "
}
@article{ElHajj2016202,
title = "Soil moisture retrieval over irrigated grassland using X-band \{SAR\} data ",
journal = "Remote Sensing of Environment ",
volume = "176",
number = "",
pages = "202 - 218",
year = "2016",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.01.027",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716300281",
author = "Mohammad El Hajj and Nicolas Baghdadi and Mehrez Zribi and Gilles Belaud and Bruno Cheviron and Dominique Courault and François Charron",
keywords = "grassland",
keywords = "TerraSAR-X",
keywords = "COSMO-SkyMED",
keywords = "neural networks",
keywords = "inversion",
keywords = "soil moisture",
keywords = "vegetation indices ",
abstract = "Abstract The aim of this study was to develop an inversion approach to estimate surface soil moisture from X-band \{SAR\} data over irrigated grassland areas. This approach simulates a coupling scenario between Synthetic Aperture Radar (SAR) and optical images through the Water Cloud Model (WCM). A time series of \{SAR\} (TerraSAR-X and COSMO-SkyMed) and optical (SPOT 4/5 and \{LANDSAT\} 7/8) images were acquired over an irrigated grassland region in southeastern France. An inversion technique based on multi-layer perceptron neural networks (NNs) was used to invert the Water Cloud Model (WCM) for soil moisture estimation. Three inversion configurations based on \{SAR\} and optical images were defined: (1) \{HH\} polarization, (2) \{HV\} polarization, and (3) both \{HH\} and \{HV\} polarizations, all with one vegetation descriptor derived from optical data. The investigated vegetation descriptors were the Normalized Difference Vegetation Index “NDVI”, Leaf Area Index “LAI”, Fraction of Absorbed Photosynthetically Active Radiation “FAPAR”, and the Fractional vegetation \{COVER\} “FCOVER”. These vegetation descriptors were derived from optical images. For the three inversion configurations, the \{NNs\} were trained and validated using a noisy synthetic dataset generated by the \{WCM\} for a wide range of soil moisture and vegetation descriptor values. The trained \{NNs\} were then validated from a real dataset composed of X-band \{SAR\} backscattering coefficients and vegetation descriptor derived from optical images. The use of X-band \{SAR\} measurements in \{HH\} polarization (in addition to one vegetation descriptor derived from optical images) yields more precise results on soil moisture (Mv) estimates. In the case of \{NDVI\} derived from optical images as the vegetation descriptor, the Root Mean Square Error on Mv estimates was 3.6 Vol.% for \{NDVI\} values between 0.45 and 0.75, and 6.1 Vol.% for \{NDVI\} between 0.75 and 0.90. Similar results were obtained regardless of the other vegetation descriptor used. "
}
@article{Reid2013403,
title = "Observing and understanding the Southeast Asian aerosol system by remote sensing: An initial review and analysis for the Seven Southeast Asian Studies (7SEAS) program ",
journal = "Atmospheric Research ",
volume = "122",
number = "",
pages = "403 - 468",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512001809",
author = "Jeffrey S. Reid and Edward J. Hyer and Randall S. Johnson and Brent N. Holben and Robert J. Yokelson and Jianglong Zhang and James R. Campbell and Sundar A. Christopher and Larry Di Girolamo and Louis Giglio and Robert E. Holz and Courtney Kearney and Jukka Miettinen and Elizabeth A. Reid and F. Joseph Turk and Jun Wang and Peng Xian and Guangyu Zhao and Rajasekhar Balasubramanian and Boon Ning Chew and Serm Janjai and Nofel Lagrosas and Puji Lestari and Neng-Huei Lin and Mastura Mahmud and Anh X. Nguyen and Bethany Norris and Nguyen T.K. Oanh and Min Oo and Santo V. Salinas and E. Judd Welton and Soo Chin Liew",
keywords = "Southeast Asia",
keywords = "Maritime Continent",
keywords = "Meteorology",
keywords = "Aerosol",
keywords = "Remote Sensing",
keywords = "Biomass Burning",
keywords = "Air Pollution ",
abstract = "Southeast Asia (SEA) hosts one of the most complex aerosol systems in the world, with convoluted meteorological scales, sharp geographic and socioeconomic features, high biological productivity, mixtures of a wide range of atmospheric pollutants, and likely a significant susceptibility to global climate change. This physical complexity of \{SEA\} is coupled with one of the world's most challenging environments for both in situ and remote sensing observation. The 7-Southeast Asian Studies (7SEAS) program was formed to facilitate interdisciplinary research into the integrated \{SEA\} aerosol environment via grass roots style collaboration. In support of the early 7SEAS program and the affiliated Southeast Asia Composition, Cloud, Climate Coupling Regional Study (SEAC4RS), this review was created to outline the network of connections linking aerosol particles in \{SEA\} with meteorology, climate and the total earth system. In this review, we focus on and repeatedly link back to our primary data source: satellite aerosol remote sensing and associated observability issues. We begin with a brief rationale for the program, outlining key aerosol impacts and, comparing their magnitudes to the relative uncertainty of observations. We then discuss aspects of SEA's physical, socio-economic and biological geography relevant to meteorology and observability issues associated with clouds and precipitation. We show that not only does \{SEA\} pose significant observability challenges for aerosol particles, but for clouds and precipitation as well. With the fundamentals of the environment outlined, we explore SEA's most studied aerosol issue: biomass burning. We summarize research on bulk aerosol properties for SEA, including a short synopsis of recent \{AERONET\} observations. We describe long range transport patterns. Finally, considerable attention is paid to satellite aerosol observability issues, with a face value comparison of common aerosol products in the region including passive and active aerosol products as well as fluxes. We show that satellite data products diverge greatly due to a host of known artifacts. These artifacts have important implications for how research is conducted, and care must be taken when using satellite products to study aerosol problems. The paper ends with a discussion of how the community can approach this complex and important environment. "
}
@article{Kwok2014678,
title = "Volumetric template fitting for human body reconstruction from incomplete data ",
journal = "Journal of Manufacturing Systems ",
volume = "33",
number = "4",
pages = "678 - 689",
year = "2014",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2014.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0278612514000624",
author = "Tsz-Ho Kwok and Kwok-Yun Yeung and Charlie C.L. Wang",
keywords = "Template fitting",
keywords = "Volumetric mesh",
keywords = "Incomplete data",
keywords = "Human body reconstruction",
keywords = "RGB-D camera ",
abstract = "Abstract In this paper, we present a method for reconstructing 3D human body from incomplete data, which are point clouds captured by inexpensive RGB-D cameras. Making use of the volumetric mesh in a template, the fitting process is robust. This method produces high quality fitting results on incomplete data, which are hard to be offered by the surface fitting based methods. The method is formulated as an optimization procedure, so that the results of volumetric fitting rely on the quality of initial shape (i.e., the shape of template). In order to find a good initial shape, we develop a template selection algorithm to choose a template in an iterative manner by using the statistical models of human bodies. Experimental results show that our method can successfully reconstruct human body with good quality to be used in design and manufacturing applications. "
}
@article{Fleck2009141,
title = "Graph cut based panoramic 3D modeling and ground truth comparison with a mobile platform – The Wägele ",
journal = "Image and Vision Computing ",
volume = "27",
number = "1–2",
pages = "141 - 152",
year = "2009",
note = "Canadian Robotic Vision 2005 and 2006 ",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2008.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0262885608001212",
author = "Sven Fleck and Florian Busch and Peter Biber and Wolfgang Straßer",
keywords = "Graph cut",
keywords = "3D model acquisition",
keywords = "3DTV ",
abstract = "Efficient and comfortable acquisition of large 3D scenes is an important topic for many current and future applications in the field of robotics, factory and office visualization, 3DTV and cultural heritage. In this paper we present both an omnidirectional stereo vision approach for 3D modeling based on graph cut techniques and also a new mobile 3D model acquisition platform where it is employed. The platform comprises a panoramic camera and a 2D laser range scanner for self localization by scan matching. 3D models are acquired just by moving the platform around and recording images in regular intervals. Additionally, we concurrently build 3D models using two supplementary laser range scanners. This enables the investigation of the stereo algorithm’s quality by comparing it with the laser scanner based 3D model as ground truth. This offers a more objective point of view on the achieved 3D model quality. "
}
@article{Summan2015189,
title = "Spatial calibration of large volume photogrammetry based metrology systems ",
journal = "Measurement ",
volume = "68",
number = "",
pages = "189 - 200",
year = "2015",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2015.02.054",
url = "http://www.sciencedirect.com/science/article/pii/S0263224115001189",
author = "R. Summan and S.G. Pierce and C.N. Macleod and G. Dobie and T. Gears and W. Lester and P. Pritchett and P. Smyth",
keywords = "Photogrammetry",
keywords = "Calibration",
keywords = "Laser tracker",
keywords = "Accuracy study ",
abstract = "Abstract Photogrammetry systems are used extensively as volumetric measurement tools in a diverse range of applications including gait analysis, robotics and computer generated animation. For precision applications the spatial inaccuracies of these systems are of interest. In this paper, an experimental characterisation of a six camera Vicon \{T160\} photogrammetry system using a high accuracy laser tracker is presented. The study was motivated by empirical observations of the accuracy of the photogrammetry system varying as a function of location within a measurement volume of approximately 100 m3. Error quantification was implemented through simultaneously tracking a target scanned through a sub-volume (27 m3) using both systems. The position of the target was measured at each point of a grid in four planes at different heights. In addition, the effect of the use of passive and active calibration artefacts upon system accuracy was investigated. A convex surface was obtained when considering error as a function of position for a fixed height setting confirming the empirical observations when using either calibration artefact. Average errors of 1.48 mm and 3.95 mm were obtained for the active and passive calibration artefacts respectively. However, it was found that through estimating and applying an unknown scale factor relating measurements, the overall accuracy could be improved with average errors reducing to 0.51 mm and 0.59 mm for the active and passive datasets respectively. The precision in the measurements was found to be less than 10 μm for each axis. "
}
@article{Häselich20131051,
title = "Probabilistic terrain classification in unstructured environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1051 - 1059",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001285",
author = "Marcel Häselich and Marc Arends and Nicolai Wojke and Frank Neuhaus and Dietrich Paulus",
keywords = "Markov random fields",
keywords = "Terrain classification",
keywords = "Sensor fusion ",
abstract = "Autonomous navigation in unstructured environments is a complex task and an active area of research in mobile robotics. Unlike urban areas with lanes, road signs, and maps, the environment around our robot is unknown and unstructured. Such an environment requires careful examination as it is random, continuous, and the number of perceptions and possible actions are infinite. We describe a terrain classification approach for our autonomous robot based on Markov Random Fields (MRFs ) on fused 3D laser and camera image data. Our primary data structure is a 2D grid whose cells carry information extracted from sensor readings. All cells within the grid are classified and their surface is analyzed in regard to negotiability for wheeled robots. Knowledge of our robot’s egomotion allows fusion of previous classification results with current sensor data in order to fill data gaps and regions outside the visibility of the sensors. We estimate egomotion by integrating information of an IMU, \{GPS\} measurements, and wheel odometry in an extended Kalman filter. In our experiments we achieve a recall ratio of about 90% for detecting streets and obstacles. We show that our approach is fast enough to be used on autonomous mobile robots in real time. "
}
@article{Rosen1989281,
title = "The characterization and modelling of the diffuse radiance distribution under partly cloudy skies ",
journal = "Solar Energy ",
volume = "43",
number = "5",
pages = "281 - 290",
year = "1989",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/0038-092X(89)90115-1",
url = "http://www.sciencedirect.com/science/article/pii/0038092X89901151",
author = "M.A. Rosen and F.C. Hooper and A.P. Brunger",
abstract = "Results are presented of a detailed analysis of a large set of sky radiance measurements taken in 1982 by an automated robot system built and operated at the University of Toronto, which takes narrow field-of-view sky radiance measurements with a precision and frequency adequate for most analysis and modelling purposes. The analysis of these data has confirmed the supposition that clouds strongly affect the distribution of the diffuse radiance, and has shown that the spatial distribution of the radiance for skies categorized according to cloud type and amount is statistically influenced in an orderly manner by the presence of the clouds. It was observed that the distribution across the sky of the time mean values of the diffuse radiance exhibits circumsolar and horizon brightening, the degree of which depends primarily on cloud type and amount, and on solar zenith angle. Trends were identified in the changes in the sky radiance distributions corresponding to variations in solar zenith angle, cloud amount and cloud group. The measured data appeared to be generally compatible with a model of the form of the Three-Component Continuous Distribution (TCCD) model introduced by Hooper and Brunger, and it was concluded that successful descriptors of the sky radiance could be developed based on that model, or on similar formulations. "
}
@article{Asvadi2016299,
title = "3D Lidar-based static and moving obstacle detection in driving environments: An approach based on voxels and multi-region ground planes ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "299 - 311",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016300483",
author = "Alireza Asvadi and Cristiano Premebida and Paulo Peixoto and Urbano Nunes",
keywords = "\{LIDAR\} perception",
keywords = "Scene understanding",
keywords = "3D representation",
keywords = "Obstacle detection ",
abstract = "Abstract Artificial perception, in the context of autonomous driving, is the process by which an intelligent system translates sensory data into an effective model of the environment surrounding a vehicle. In this paper, and considering data from a 3D-LIDAR mounted onboard an intelligent vehicle, a 3D perception system based on voxels and planes is proposed for ground modeling and obstacle detection in urban environments. The system, which incorporates time-dependent data, is composed of two main modules: (i) an effective ground surface estimation using a piecewise plane fitting algorithm and RANSAC-method, and (ii) a voxel-grid model for static and moving obstacles detection using discriminative analysis and ego-motion information. This perception system has direct application in safety systems for intelligent vehicles, particularly in collision avoidance and vulnerable road users detection, namely pedestrians and cyclists. Experiments, using point-cloud data from a Velodyne \{LIDAR\} and localization data from an Inertial Navigation System were conducted for both a quantitative and a qualitative assessment of the static/moving obstacle detection module and for the surface estimation approach. Reported results, from experiments using the \{KITTI\} database, demonstrate the applicability and efficiency of the proposed approach in urban scenarios. "
}
@article{Qiu2016,
title = "iFrame: Dynamic indoor map construction through automatic mobile sensing ",
journal = "Pervasive and Mobile Computing ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2016.12.008",
url = "http://www.sciencedirect.com/science/article/pii/S1574119216304552",
author = "Chen Qiu and Matt W. Mutka",
keywords = "Indoor map construction",
keywords = "Smartphone",
keywords = "Mobile sensing ",
abstract = "Abstract Many pervasive computing applications depend upon maps for support of location based services. Individuals can determine their location outdoors on these maps via GPS. Indoor pervasive applications may also need to know the layout of buildings, however indoor maps are less prevalent. This paper presents iFrame, a dynamic approach that leverages existing mobile sensing capabilities for constructing indoor floor plans. We explore how iFrame users may collaborate and contribute to constructing 2-dimensional indoor maps by merely carrying smartphones. A deployment study shows iFrame is an unattended approach that provides a skeleton map of a real building effectively and automatically. "
}
@article{Mano2016178,
title = "Exploiting IoT technologies for enhancing Health Smart Homes through patient identification and emotion recognition ",
journal = "Computer Communications ",
volume = "89–90",
number = "",
pages = "178 - 190",
year = "2016",
note = "Internet of Things\: Research challenges and Solutions ",
issn = "0140-3664",
doi = "https://doi.org/10.1016/j.comcom.2016.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S0140366416300688",
author = "Leandro Y. Mano and Bruno S. Faiçal and Luis H.V. Nakamura and Pedro H. Gomes and Giampaolo L. Libralon and Rodolfo I. Meneguete and Geraldo P.R. Filho and Gabriel T. Giancristofaro and Gustavo Pessin and Bhaskar Krishnamachari and Jó Ueyama",
keywords = "Smart Home",
keywords = "E-health",
keywords = "Internet of Things",
keywords = "Face recognition",
keywords = "Emotion detection ",
abstract = "Abstract Currently, there is an increasing number of patients that are treated in-home, mainly in countries such as Japan, \{USA\} and Europe. As well as this, the number of elderly people has increased significantly in the last 15 years and these people are often treated in-home and at times enter into a critical situation that may require help (e.g. when facing an accident, or becoming depressed). Advances in ubiquitous computing and the Internet of Things (IoT) have provided efficient and cheap equipments that include wireless communication and cameras, such as smartphones or embedded devices like Raspberry Pi. Embedded computing enables the deployment of Health Smart Homes (HSH) that can enhance in-home medical treatment. The use of camera and image processing on IoT is still an application that has not been fully explored in the literature, especially in the context of HSH. Although use of images has been widely exploited to address issues such as safety and surveillance in the house, they have been little employed to assist patients and/or elderly people as part of the home-care systems. In our view, these images can help nurses or caregivers to assist patients in need of timely help, and the implementation of this application can be extremely easy and cheap when aided by IoT technologies. This article discusses the use of patient images and emotional detection to assist patients and elderly people within an in-home healthcare context. We also discuss the existing literature and show that most of the studies in this area do not make use of images for the purpose of monitoring patients. In addition, there are few studies that take into account the patient’s emotional state, which is crucial for them to be able to recover from a disease. Finally, we outline our prototype which runs on multiple computing platforms and show results that demonstrate the feasibility of our approach. "
}
@article{Li20161,
title = "Large eddy simulation of unsteady shedding behavior in cavitating flows with time-average validation ",
journal = "Ocean Engineering ",
volume = "125",
number = "",
pages = "1 - 11",
year = "2016",
note = "",
issn = "0029-8018",
doi = "https://doi.org/10.1016/j.oceaneng.2016.07.065",
url = "http://www.sciencedirect.com/science/article/pii/S0029801816303109",
author = "Linmin Li and Baokuan Li and Zhiqiang Hu and Yang Lin and Sherman C.P. Cheung",
keywords = "Unsteady cavitating flows",
keywords = "Large eddy simulation",
keywords = "Time-average method",
keywords = "Periodic shedding ",
abstract = "Abstract Cavitation always leads to complex gas–liquid interactions and turbulence structures with multi-scale eddies and vortices. It usually involves cavity growth, break-off and collapse processes; posing great challenges in modeling. This paper focuses on modeling instantaneous cavitating flows using the large eddy simulation (LES) and validating the predictions against experimental data using the time-average method. The volume of fluid (VOF) model was adopted to describe phase equations and coupled with the Schnerr–Sauer cavitation model for describing the evaporation-condensation mass transfer. Simulations were performed to predict the unsteady cavitating flows of both the cylinder and Clark-Y hydrofoil configurations. Firstly, the mechanisms of cavity shedding, vapor cloud forming and collapsing were well revealed. The time-averaged pressure distribution and cavity length around the cylinder were in good agreement with experimental data. Moreover, the periodic cavity shedding and pressure fluctuation around the Clark-Y hydrofoil were also predicted. Different cavity patterns were clearly identified in a typical cycle, and the effect of cavity pattern on hydrodynamic forces was investigated. The computational results of cavity patterns, velocity profiles, drag and lift coefficients were compared with experimental results and good agreements were obtained. The present work provides a valid numerical modeling framework for various cavitating flows. "
}
@article{Jun2016325,
title = "Pose estimation-based path planning for a tracked mobile robot traversing uneven terrains ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "325 - 339",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S092188901500202X",
author = "Jae-Yun Jun and Jean-Philippe Saut and Faïz Benamar",
keywords = "Path planning",
keywords = "Rough terrain",
keywords = "Sampling-based motion planning",
keywords = "Mobile robot",
keywords = "Tip-over stability ",
abstract = "Abstract A novel path-planning algorithm is proposed for a tracked mobile robot to traverse uneven terrains, which can efficiently search for stability sub-optimal paths. This algorithm consists of combining two RRT-like algorithms (the Transition-based \{RRT\} (T-RRT) and the Dynamic-Domain \{RRT\} (DD-RRT) algorithms) bidirectionally and of representing the robot–terrain interaction with the robot’s quasi-static tip-over stability measure (assuming that the robot traverses uneven terrains at low speed for safety). The robot’s stability is computed by first estimating the robot’s pose, which in turn is interpreted as a contact problem, formulated as a linear complementarity problem (LCP), and solved using the Lemke’s method (which guarantees a fast convergence). The present work compares the performance of the proposed algorithm to other RRT-like algorithms (in terms of planning time, rate of success in finding solutions and the associated cost values) over various uneven terrains and shows that the proposed algorithm can be advantageous over its counterparts in various aspects of the planning performance. "
}
@article{Mourtzis2014213,
title = "Simulation in Manufacturing: Review and Challenges ",
journal = "Procedia \{CIRP\} ",
volume = "25",
number = "",
pages = "213 - 229",
year = "2014",
note = "8th International Conference on Digital Enterprise Technology - \{DET\} 2014 Disruptive Innovation in Manufacturing Engineering towards the 4th Industrial Revolution ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2014.10.032",
url = "http://www.sciencedirect.com/science/article/pii/S2212827114010634",
author = "D. Mourtzis and M. Doukas and D. Bernidaki",
keywords = "Manufacturing",
keywords = "Simulation",
keywords = "Information and Communication Technologies ",
abstract = "Abstract Simulation comprises an indispensable set of technological tools and methods for the successful implementation of digital manufacturing, since it allows for the experimentation and validation of product, process and system design and configuration. Especially in todays’ turbulent manufacturing environment, which is affected by megatrends such as globalisation and ever-increasing requirements for higher degree of product customisation and personalisation, the value of simulation is evident. This keynote paper investigates the major milestones in the evolution of simulation technologies and examines recent industrial and research applications and findings. Based on this review, the identification of gaps in current practices is presented, and future trends and challenges to be met on the field are outlined. The considered simulation methods and tools include CAx, Factory layout design, Material and Information flow design, Manufacturing Networks Design, Manufacturing Systems Planning and Control, Manufacturing Networks Planning and Control, Augmented and Virtual Reality in product and process design, planning and verification (ergonomics, robotics, etc.). The evolution, advances, current practices and future trends of these technologies, industrial applications and research results are discussed in the context of the contemporary manufacturing industry. "
}
@article{Favorskaya2014851,
title = "Distributed System for Crossroads Traffic Surveillance with Prediction of Incidents ",
journal = "Procedia Computer Science ",
volume = "35",
number = "",
pages = "851 - 860",
year = "2014",
note = "Knowledge-Based and Intelligent Information &amp; Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2014.08.252",
url = "http://www.sciencedirect.com/science/article/pii/S1877050914012174",
author = "Margarita Favorskaya and Euvgenii Kazmiruk and Aleksei Popov",
keywords = "Kalman filter",
keywords = "clustering",
keywords = "particle filter",
keywords = "motion estimation",
keywords = "motion prediction ",
abstract = "Abstract The development of traffic surveillance systems is one of the crucial tasks in intelligent urban surveillance. The visual tracking techniques become more complex with a high computational cost. At the same time, they provide the wide possibilities for motion estimation and prediction in cluttered video sequences. Our contribution is a reasonable application of fast motion estimation with additional using of the clustering procedure. Then the Kalman filter is applied for vehicles’ motion analysis, and the particle filter is used for analysis of pedestrians’ behavior assuming that pedestrians are the weakly predictable objects on the crossroads. Also the distributed surveillance system based on the cloud and fog technologies was designed to process large volumes of video information provided from several IP-cameras in a real-time mode, when six full frames per s are transmitted. "
}
@article{Cadena20101207,
title = "\{SLAM\} in with the Combined Kalman-Information Filter ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "11",
pages = "1207 - 1219",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2010.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S092188901000148X",
author = "C. Cadena and J. Neira",
keywords = "SLAM",
keywords = "Extended Kalman Filter",
keywords = "Extended Information Filter",
keywords = "Data association ",
abstract = "In this paper11 This research has been funded by the Dirección General de Investigación of Spain under the projects DPI2009-13710 and DPI2009-07130. Preliminary versions of this work were presented in the Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems 2009, St. Louis, MO, USA, October 2009, and in the European Conference on Mobile Robotics 2009, Mlini/Dubrovnik, Croatia, September 2009. we describe the Combined Kalman-Information Filter \{SLAM\} algorithm (CF SLAM), a judicious combination of Extended Kalman (EKF) and Extended Information Filters (EIF) that can be used to execute highly efficient \{SLAM\} in large environments. \{CF\} \{SLAM\} is always more efficient than any other \{EKF\} or \{EIF\} algorithm: filter updates can be executed in as low as O ( log n ) as compared with O ( n 2 ) for Map Joining SLAM, O ( n ) for Divide and Conquer (D&amp;C) SLAM, and the Sparse Local Submap Joining Filter (SLSJF). In the worst cases, updates are executed in O ( n ) for \{CF\} \{SLAM\} as compared with O ( n 2 ) for all others. We also study an often overlooked problem in computationally efficient \{SLAM\} algorithms: data association. In situations in which only uncertain geometrical information is available for data association, \{CF\} \{SLAM\} is as efficient as D&amp;C SLAM, and much more efficient than Map Joining \{SLAM\} or SLSJF. If alternative information is available for data association, such as texture in visual SLAM, \{CF\} \{SLAM\} outperforms all other algorithms. In large scale situations, both algorithms based on Extended Information filters, \{CF\} \{SLAM\} and SLSJF, avoid computing the full covariance matrix and thus require less memory, but still \{CF\} \{SLAM\} is the most computationally efficient. Both simulations and experiments with the Victoria Park dataset, the \{DLR\} dataset, and an experiment using visual stereo are used to illustrate the algorithms’ advantages, also with respect to non filtering alternatives such as iSAM, the Treemap and Tectonic SAM. "
}
@article{Zhang20152095,
title = "Integrated Ontologies in Support of Factory Systems Design ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "3",
pages = "2095 - 2102",
year = "2015",
note = "15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.398",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315006370",
author = "J. Zhang and K. Agyapong-Kodua",
keywords = "Product (P)-Process (P) and Resource (R) ontologies",
keywords = "Semantic Technologies",
keywords = "Factory systems",
keywords = "Digital Factory ",
abstract = "Abstract Digital factory modelling based on virtual design and simulation has emerged as part of the mainstream activities geared towards reducing product design cycle. Some basic industrial systems are currently integrated via semantic modelling technologies so that products matching processes and resource requirements are integrated to fulfil customer demands. Despite these achievements, product design is still dependent on the knowledge of designers and do not benefit from existing process and resource knowledge, which are in separate domains. This paper therefore presents an integration method based on semantic technologies and \{PPR\} ontologies to enable the reuse of known and unknown knowledge. The method relies on the use of cloud manufacturing to improve the efficiency of responsesgenerated by querying the \{PPR\} ontology. "
}
@article{Posner2008901,
title = "Online generation of scene descriptions in urban environments ",
journal = "Robotics and Autonomous Systems ",
volume = "56",
number = "11",
pages = "901 - 914",
year = "2008",
note = "Semantic Knowledge in Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001139",
author = "Ingmar Posner and Derik Schroeter and Paul Newman",
keywords = "Semantic robot maps",
keywords = "Outdoor mapping",
keywords = "Support vector machine ",
abstract = "The ability to extract a rich set of semantic workspace labels from sensor data gathered in complex environments is a fundamental prerequisite to any form of semantic reasoning in mobile robotics. In this paper, we present an online system for the augmentation of maps of outdoor urban environments with such higher-order, semantic labels. The system employs a shallow supervised classification hierarchy to classify scene attributes, consisting of a mixture of 2D/3D geometric and visual scene information, into a range of different workspace classes. The union of classifier responses yields a rich, composite description of the local workspace. We present extensive experimental results, using two large urban data sets collected by our research platform. "
}
@article{Maiseli201795,
title = "Recent developments and trends in point set registration methods ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "46",
number = "",
pages = "95 - 106",
year = "2017",
note = "",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2017.03.012",
url = "http://www.sciencedirect.com/science/article/pii/S1047320317300743",
author = "Baraka Maiseli and Yanfeng Gu and Huijun Gao",
keywords = "Point matching",
keywords = "Registration",
keywords = "Performance",
keywords = "Optimization",
keywords = "Point set ",
abstract = "Abstract Point set registration (PSR) is the process of computing a spatial transformation that optimally aligns pairs of point sets. The method helps to amalgamate multiple datasets into a common coordinate system. Because of their immense practical applications, several studies have attempted to address challenges inherent in the \{PSR\} problem. However, limited works exist to discuss recent developments, failures, and trends of the \{PSR\} methods. To date, a classical work of Tam et al., published in 2013, can be regarded as a comprehensive review paper for registration methods. Nevertheless, this work has inadequately revealed a range of possible knowledge gaps of the previous studies. Additionally, since the publication year of their work, more superior and state-of-the-art methods have been proposed. The present study surveys \{PSR\} approaches until 2017, and our primary focus is to expose central ideas and limitations of the methods to facilitate experts and practitioners advance the field. "
}
@article{Sommer201648,
title = "Multi-contact haptic exploration and grasping with tactile sensors ",
journal = "Robotics and Autonomous Systems ",
volume = "85",
number = "",
pages = "48 - 61",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016301610",
author = "Nicolas Sommer and Aude Billard",
keywords = "Tactile sensing",
keywords = "Haptic exploration",
keywords = "Multiple contacts",
keywords = "Compliant grasping ",
abstract = "Abstract Haptic exploration has received a great deal of attention of late thanks to the variety of commercially available tactile sensors. While the majority of previous works consider control of a single contact point at a time, we tackle simultaneous control of multiple contact points on several links. In addition, we use information from the existing tactile signals to increase the number of points in contact. We demonstrate the usefulness of this form of control to speed up exploration, scanning and to compliantly grasp unknown objects. Our controller requires to know only the parts of the robot on which it is desirable to make contact and does not need a model of the environment besides the robot itself. We validate the algorithm in a set of experiments using a robotic hand covered with tactile sensors and arm. In a grasping application, the active adaptation of the fingers to the shape of the object ensures that the hand encloses the object with multiple contact points. We show that this improves the robustness of the grasp compared to simple enclosing strategies. When combined with an exploration strategy, our multi-contact approach offers an efficient use of tactile sensors on the whole surface of robotic fingers, and enables the robot to perform a rapid exploration of complex, non convex shapes while maintaining low contact forces. It is robust to variation in the approach angle and to changes in the geometry and orientation of the object. "
}
@article{Moura201767,
title = "Formulation of a Control and Path Planning Approach for a Cab front Cleaning Robot ",
journal = "Procedia \{CIRP\} ",
volume = "59",
number = "",
pages = "67 - 71",
year = "2017",
note = "Proceedings of the 5th International Conference in Through-life Engineering Services Cranfield University, 1st and 2nd November 2016 ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116309581",
author = "João Moura and Mustafa Suphi Erden",
keywords = "Cleaning robot",
keywords = "simultaneous force and position control",
keywords = "operational space formulation. ",
abstract = "Abstract This paper formulates a control and path planning approach for a Cab Front Cleaning Robot. Currently, the operation of cleaning the front part of a train cab is performed manually under challenging conditions. The aim of this work is to formulate a control and path planning solution for the employment of a robot manipulator for such cleaning activity. The proposed solution comprises the study of the interaction between the robotic manipulator and an unknown surface, and consists in using an Operational Space Formulation implementation of simultaneous force and position control. The end-effector trajectory results from projecting a raster scan onto the surface to be cleaned, in real-time, with path adaptation to local surface geometry nuances. This paper also presents a list of criteria to validate future results. "
}
@article{Hernandez201561,
title = "Near laser-scan quality 3-D face reconstruction from a low-quality depth stream ",
journal = "Image and Vision Computing ",
volume = "36",
number = "",
pages = "61 - 69",
year = "2015",
note = "",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2014.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0262885615000165",
author = "Matthias Hernandez and Jongmoo Choi and Gérard Medioni",
keywords = "Kinect",
keywords = "3D reconstruction",
keywords = "Face modeling ",
abstract = "Abstract We propose a method to produce near laser-scan quality 3-D face models of a freely moving user with a low-cost, low resolution range sensor in real-time. Our approach does not require any prior knowledge about the geometry of a face and can produce faithful geometric models of any star-shaped object. We use a cylindrical representation, which enables us to efficiently process the 3-D mesh by applying 2-D filters. We use the first frame as a reference and incrementally build the model by registering each subsequent cloud of 3-D points to the reference using the \{ICP\} (Iterative Closest Point) algorithm implemented on a \{GPU\} (Graphics Processing Unit). The registered point clouds are merged into a single image through a cylindrical representation. The noise from the sensor and from the pose estimation error is removed with a temporal integration and a spatial smoothing of the successively incremented model. To validate our approach, we quantitatively compare our model to laser scans, and show comparable accuracy.11 This paper extends the method presented in [15]. "
}
@article{Haghighi201615,
title = "Method for automating digital fixture-setups that are optimal for machining castings to minimize scrap ",
journal = "Journal of Manufacturing Systems ",
volume = "40, Part 2",
number = "",
pages = "15 - 24",
year = "2016",
note = "SI:Challenges in Smart Manufacturing ",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2016.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0278612516300176",
author = "Payam Haghighi and Satchit Ramnath and Nathan Kalish and Jiten V. Shah and Jami J. Shah and Joseph K. Davidson",
keywords = "Automation",
keywords = "Fixture adjustments",
keywords = "Casting",
keywords = "Machining",
keywords = "Manufacturing ",
abstract = "Abstract The motivation for this paper is to describe a method for lowering the cost of finishing large castings that have machined surfaces for attaching other components. Considerable time is required to set-up each cast part on a machine-tool, sometimes taking longer than the machining itself, and errors in set-up can result in scrapping expensive parts or attempts to salvage them by rework. Although the focus of the paper is to demonstrate a new technology and software for set-up prior to the machining of iron/aluminum/steel sand castings, the same technology also is applicable to large welded assemblies on which finished machining occurs. In this paper, we outline a method, currently being implemented, that can predictively, and off-line, identify the adjustments needed to position and orient each part in its fixture before machining operations begin so that, after machining, all finished features will lie in their tolerance zones. Computer models first simulate all the to-be-machined (TBM) surfaces and any contact points with the fixture by feature-fitting point clouds taken from selective scanning of the raw casting. The locations of these features are compared with their locations on the \{CAD\} model of the part. Then, by using the T-Map model for tolerances, all possible locations of the part in its machining fixture are identified so that all \{TBM\} faces lie in their tolerance-zones. An optimum location may then be chosen. "
}
@article{Prankl2013718,
title = "Interactive object modelling based on piecewise planar surface patches ",
journal = "Computer Vision and Image Understanding ",
volume = "117",
number = "6",
pages = "718 - 731",
year = "2013",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S107731421300026X",
author = "Johann Prankl and Michael Zillich and Markus Vincze",
keywords = "Plane detection",
keywords = "Object modelling",
keywords = "Reconstruction",
keywords = "Multiple structure from motion ",
abstract = "Abstract Detecting elements such as planes in 3D is essential to describe objects for applications such as robotics and augmented reality. While plane estimation is well studied, table-top scenes exhibit a large number of planes and methods often lock onto a dominant plane or do not estimate 3D object structure but only homographies of individual planes. In this paper we introduce \{MDL\} to the problem of incrementally detecting multiple planar patches in a scene using tracked interest points in image sequences. Planar patches are reconstructed and stored in a keyframe-based graph structure. In case different motions occur, separate object hypotheses are modelled from currently visible patches and patches seen in previous frames. We evaluate our approach on a standard data set published by the Visual Geometry Group at the University of Oxford [24] and on our own data set containing table-top scenes. Results indicate that our approach significantly improves over the state-of-the-art algorithms. "
}
@article{Louchet2002335,
title = "Dynamic flies: a new pattern recognition tool applied to stereo sequence processing ",
journal = "Pattern Recognition Letters ",
volume = "23",
number = "1–3",
pages = "335 - 345",
year = "2002",
note = "",
issn = "0167-8655",
doi = "https://doi.org/10.1016/S0167-8655(01)00129-5",
url = "http://www.sciencedirect.com/science/article/pii/S0167865501001295",
author = "Jean Louchet and Maud Guyon and Marie-Jeanne Lesot and Amine Boumaza",
keywords = "Artificial evolution",
keywords = "Pattern recognition",
keywords = "Computer vision",
keywords = "Image processing",
keywords = "Parameter space exploration ",
abstract = "The “fly algorithm” is a fast artificial evolution-based technique devised for the exploration of parameter space in pattern recognition applications. In the application described, we evolve a population which constitutes a particle-based three-dimensional representation of the scene. Each individual represents a three-dimensional point in the scene and may be fitted with optional velocity parameters. Evolution is controlled by a fitness function which contains all pixel-level calculations, and uses classical evolutionary operators (sharing, mutation, crossover). The combined individual approach and low complexity fitness function allow fast processing. Test results and an application to mobile robotics are presented. "
}
@article{Romano20165,
title = "Experimental determination of short- and long-wave dust radiative effects in the Central Mediterranean and comparison with model results ",
journal = "Atmospheric Research ",
volume = "171",
number = "",
pages = "5 - 20",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.11.019",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515003907",
author = "S. Romano and P. Burlizzi and M.R. Perrone",
keywords = "Desert dust aerosol",
keywords = "Irradiance measurements",
keywords = "Direct radiative forcing",
keywords = "Surface albedo",
keywords = "Land surface temperature ",
abstract = "Abstract Downward and upward irradiance measurements, in the short-wave (SW) and long-wave (LW) spectral range, have been used in combination with simultaneous aerosol optical depths (AODs) to experimentally determine the instantaneous and clear-sky aerosol Direct Radiative Forcing (DRF) at the surface, during a desert dust outbreak which affected the Central Mediterranean from 9 to 13 July 2012. \{AODs\} were retrieved from \{AERONET\} (AErosol \{RObotic\} NETwork) sun/sky photometer measurements collocated in space and time. The importance of downward and upward radiative flux measurements to properly account for both the surface albedo dependence on the solar zenith angle, and the land surface temperature (TLS) has been highlighted. Measured radiative fluxes were in reasonable agreement with the \{CERES\} (Clouds and the Earth's Radiant Energy System) and \{AERONET\} corresponding ones collocated in space and time. \{SW\} and \{LW\} downward fluxes at the surface decreased up to 9% and increased up to 13%, respectively, as a consequence of a factor 5 increase of the \{AOD\} at 675 nm (AOD675). This is due to the cooling and warming effect of desert dust in the \{SW\} and \{LW\} spectral range, respectively. In fact, we have also found that the \{TLS\} increased at a rate of about 250 K per unit increase of the AOD675. The aerosol \{DRF\} at the surface varied from − 8 to − 74 W m− 2 and from + 1.2 to + 9.6 W m− 2 in the \{SW\} and \{LW\} spectral domains, respectively. In particular, we have found that the LW-DRF on average offsets 14% of the related \{SW\} component. It is shown that a two-stream radiative transfer model can reproduce the experimental findings at the surface by replacing the refractive indices typical of dust particles with the ones obtained for a mixture made of dust and soot particles. The dust contamination by anthropogenic particles during its transport to the monitoring site located several hundred kilometers away from the source region was responsible for this last result. We have also found by model simulations that the LW-DRF increased linearly with \{TLS\} both at the surface and at the top of the atmosphere. "
}
@article{Esmaeilian201679,
title = "The evolution and future of manufacturing: A review ",
journal = "Journal of Manufacturing Systems ",
volume = "39",
number = "",
pages = "79 - 100",
year = "2016",
note = "",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2016.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0278612516300024",
author = "Behzad Esmaeilian and Sara Behdad and Ben Wang",
keywords = "Advanced manufacturing",
keywords = "Data analytics in manufacturing",
keywords = "Sustainable manufacturing",
keywords = "Design for manufacturing",
keywords = "Remanufacturing ",
abstract = "Abstract Manufacturing is continuously evolving from concept development to methods and tools available for the production of goods for use or sale. Traditionally, manufacturing refers to an industrial production process through which raw materials are transformed into finished products to be sold in the market. However, these days manufacturing is considered to be an integrated concept at all levels from machines to production systems to an entire business level operation. Although there have been considerable developments in manufacturing technologies and processes, the actual scope and elements of manufacturing systems are complex and not adequately defined. This paper provides a review of both the tangible and intangible elements of manufacturing systems and presents a state-of-the-art survey of published work. It studies the evolution of research in manufacturing starting from past and current trends to future developments. How manufacturing systems have been classified is also presented. Through this extensive survey of the literature, future directions of this changing field are suggested. "
}
@article{Ning2016504,
title = "Cybermatics: Cyber–physical–social–thinking hyperspace based science and technology ",
journal = "Future Generation Computer Systems ",
volume = "56",
number = "",
pages = "504 - 522",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2015.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15002356",
author = "Huansheng Ning and Hong Liu and Jianhua Ma and Laurence T. Yang and Runhe Huang",
keywords = "Cybermatics",
keywords = "Cyber–physical–social–thinking hyperspace",
keywords = "Internet of Things (IoT) ",
abstract = "Abstract The Internet of Things (IoT) is becoming an attractive system paradigm, in which physical perceptions, cyber interactions, social correlations, and even cognitive thinking can be intertwined in the ubiquitous things’ interconnections. It realizes a perfect integration of a new cyber–physical–social–thinking (CPST) hyperspace, which has profound implications for the future IoT. In this article, a novel concept Cybermatics is put forward as a broader vision of the IoT (called hyper IoT) to address science and technology issues in the heterogeneous \{CPST\} hyperspace. This article covers a broaden research field and presents a preliminary study focusing on its three main features (i.e., interconnection, intelligence, and greenness). Concretely, interconnected Cybermatics refers to the variants of Internet of anything, such as physical objects, cyber services, social people, and human thinking; intelligent Cybermatics considers the cyber–physical–social–thinking computing to provide algorithmic support for system infrastructures; green Cybermatics addresses energy issues to ensure efficient communications and networking. Finally, open challenging science and technology issues are discussed in the field of Cybermatics. "
}
@article{Barfoot2011101,
title = "Pose estimation using linearized rotations and quaternion algebra ",
journal = "Acta Astronautica ",
volume = "68",
number = "1–2",
pages = "101 - 112",
year = "2011",
note = "",
issn = "0094-5765",
doi = "https://doi.org/10.1016/j.actaastro.2010.06.049",
url = "http://www.sciencedirect.com/science/article/pii/S0094576510002407",
author = "Timothy Barfoot and James R. Forbes and Paul T. Furgale",
keywords = "Pose estimation",
keywords = "Linearized rotations",
keywords = "Quaternion algebra ",
abstract = "In this paper we revisit the topic of how to formulate error terms for estimation problems that involve rotational state variables. We present a first-principles linearization approach that yields multiplicative error terms for unit-length quaternion representations of rotations, as well as for canonical rotation matrices. Quaternion algebra is employed throughout our derivations. We show the utility of our approach through two examples: (i) linearizing a sun sensor measurement error term, and (ii) weighted-least-squares point-cloud alignment. "
}
@article{Dalvandi2015249,
title = "Power-efficient resource-guaranteed \{VM\} placement and routing for time-aware data center applications ",
journal = "Computer Networks ",
volume = "88",
number = "",
pages = "249 - 268",
year = "2015",
note = "",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2015.06.017",
url = "http://www.sciencedirect.com/science/article/pii/S1389128615002182",
author = "Aissan Dalvandi and Mohan Gurusamy and Kee Chaing Chua",
keywords = "Power efficient data centers",
keywords = "VM placement",
keywords = "Bandwidth guarantees",
keywords = "Optimization",
keywords = "Multi-tier applications",
keywords = "Time-aware tenant requests ",
abstract = "Abstract Power efficiency and performance guarantees have become major concerns of data center cloud providers as they significantly affect providers’ economic benefits. Providing guaranteed resources necessitates developing a user-friendly and concise request model which accurately abstracts the required server and network resources for a tenant application. We propose a time-aware tenant application (TTA) request model which enables a tenant to express an application request by specifying its resource requirement graph (server resources for \{VMs\} and bandwidth) associated with its estimated required time duration. We investigate the power-efficient resource-guaranteed virtual machine (VM)-placement and routing problem for dynamically arriving \{TTA\} requests. The problem requires provisioning of the specified resources in a data center for the required time duration of requests by selecting an appropriate set of servers for \{VM\} placement and routes for their communication, so as to maximize the number of accepted requests while consuming as low power as possible. We develop a mixed integer linear programming optimization problem formulation based on the multi-component utilization-based power model. Since this problem which is a combination of routing and VM-placement problem, is computationally prohibitive, we develop two algorithms which select servers and routes based on: (1) our proposed goodness function and pre-computed candidate paths, and (2) minimum power cost paths, respectively. We demonstrate the effectiveness of the proposed algorithms in terms of power saving and acceptance ratio through simulation results. "
}
@article{Han2017,
title = "A fast propagation scheme for approximate geodesic paths ",
journal = "Graphical Models ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1524-0703",
doi = "https://doi.org/10.1016/j.gmod.2017.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S1524070317300115",
author = "Xiaoguang Han and Hongchuan Yu and Yizhou Yu and Jianjun Zhang",
keywords = "Discrete geodesic computation",
keywords = "Continuous Dijkstra strategy",
keywords = "Fast Path Propagation ",
abstract = "Abstract Geodesic paths on surfaces are indispensable in many research and industrial areas, including architectural and aircraft design, human body animation, robotic path planning, terrain navigation, and reverse engineering. 3D models in these applications are typically large and complex. It is challenging for existing geodesic path algorithms to process large-scale models with millions of vertices. In this paper, we focus on the single-source geodesic path problem, and present a novel framework for efficient and approximate geodesic path computation over triangle meshes. The algorithm finds and propagates paths based on a continuous Dijkstra strategy with a two-stage approach to compute a path for each propagating step. Starting from an initial path for each step, its shape is firstly optimized by solving a sparse linear system and then the output floating path is projected to the surface to obtain the refined one for further propagation. We have extensively evaluated our algorithms on a number of 3D models and also compared their performance against existing algorithms. Such evaluation and comparisons indicate our algorithm is fast and produces acceptable accuracy. "
}
@article{FernándezPeruchena2015425,
title = "A comparison of one-minute probability density distributions of global horizontal solar irradiance conditioned to the optical air mass and hourly averages in different climate zones ",
journal = "Solar Energy ",
volume = "112",
number = "",
pages = "425 - 436",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2014.11.030",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X1400574X",
author = "Carlos M. Fernández-Peruchena and Ana Bernardos",
keywords = "Solar energy",
keywords = "Optical air mass",
keywords = "High frequency solar radiation",
keywords = "Clearness index",
keywords = "Climate zones",
keywords = "Aerosol optical depth ",
abstract = "Abstract In this study, one-minute global horizontal solar irradiance distributions conditioned to the optical air mass, m, and hourly average of global horizontal solar irradiance were studied at sites in five different climate regions. For this purpose, the clearness index, kt, which accounts for the atmospheric transmittance, has been used. These distributions are fitted by functions based on the Boltzmann statistic. The one-minute distributions of kt conditioned to m found are either unimodal or bimodal, depending on the location and the value of m. These distributions are different for each of the locations analyzed. The one-minute distributions of kt conditioned to their hourly value (kth) are unimodal, and are in turn different at each of the locations analyzed. The one-minute kt distributions conditioned to both m and kth analyzed are also unimodal. These distributions were found to be the same (Kolmogorov–Smirnov test, p &gt; 0.05) at different sites in 5% of the cases compared, the majority of which show very cloudy sky conditions and decrease monotonically at clearer-sky conditions. These results point to the importance of local distribution and type of clouds in one-minute solar irradiance distributions, and highlight the role of local atmospheric clear sky transparency in differentiating these distributions. "
}
@article{Huang201532,
title = "Trends in extreme learning machines: A review ",
journal = "Neural Networks ",
volume = "61",
number = "",
pages = "32 - 48",
year = "2015",
note = "",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2014.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0893608014002214",
author = "Gao Huang and Guang-Bin Huang and Shiji Song and Keyou You",
keywords = "Extreme learning machine",
keywords = "Classification",
keywords = "Clustering",
keywords = "Feature learning",
keywords = "Regression ",
abstract = "Abstract Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of \{ELM\} from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to \{ELM\} which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, \{ELM\} has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, \{ELM\} have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in \{ELM\} together with its future perspectives. "
}
@article{Lien2008652,
title = "Covering Minkowski sum boundary using points with applications ",
journal = "Computer Aided Geometric Design ",
volume = "25",
number = "8",
pages = "652 - 666",
year = "2008",
note = "Computer Graphics and ApplicationsSelected papers from the 15th Pacific Conference on Computer Graphics and Applications (Pacific Graphics 2007)15th Pacific Conference on Computer Graphics and Applications ",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2008.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167839608000423",
author = "Jyh-Ming Lien",
keywords = "Point-based representation",
keywords = "Minkowski sum approximation",
keywords = "Parallelization",
keywords = "Geometric modeling",
keywords = "Motion planning",
keywords = "Penetration depth estimation ",
abstract = "Minkowski sum is a fundamental operation in many geometric applications, including robotic motion planning, penetration depth estimation, solid modeling, and virtual prototyping. However, due to its high computational complexity and several non-trivial implementation issues, computing the exact boundary of the Minkowski sum of two arbitrary polyhedra is generally a difficult task. In this work, we propose to represent the boundary of the Minkowski sum approximately using only points. Our results show that this point-based representation can be generated efficiently. An important feature of our method is its straightforward implementation and parallelization. We demonstrate that the point-based representation of the Minkowski sum boundary can indeed provide similar functionality as the mesh-based representations can. We show several applications in motion planning, penetration depth approximation and geometric modeling. An implementation of the proposed method can be obtained from our project webpage. "
}
@article{Roy2016667,
title = "Continuous maintenance and the future – Foundations and technological challenges ",
journal = "\{CIRP\} Annals - Manufacturing Technology ",
volume = "65",
number = "2",
pages = "667 - 688",
year = "2016",
note = "",
issn = "0007-8506",
doi = "https://doi.org/10.1016/j.cirp.2016.06.006",
url = "http://www.sciencedirect.com/science/article/pii/S0007850616301986",
author = "R. Roy and R. Stark and K. Tracht and S. Takata and M. Mori",
keywords = "Maintenance",
keywords = "Lifecycle",
keywords = "Service ",
abstract = "Abstract High value and long life products require continuous maintenance throughout their life cycle to achieve required performance with optimum through-life cost. This paper presents foundations and technologies required to offer the maintenance service. Component and system level degradation science, assessment and modelling along with life cycle ‘big data’ analytics are the two most important knowledge and skill base required for the continuous maintenance. Advanced computing and visualisation technologies will improve efficiency of the maintenance and reduce through-life cost of the product. Future of continuous maintenance within the Industry 4.0 context also identifies the role of IoT, standards and cyber security. "
}
@article{Brenner20084,
title = "Coarse orientation of terrestrial laser scans in urban environments ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "63",
number = "1",
pages = "4 - 18",
year = "2008",
note = "Theme Issue: Terrestrial Laser Scanning ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2007.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0924271607000457",
author = "C. Brenner and C. Dold and N. Ripperda",
keywords = "Terrestrial laser scanning",
keywords = "Orientation",
keywords = "Registration",
keywords = "Coarse alignment",
keywords = "Initial values ",
abstract = "The use of terrestrial laser scanners is becoming increasingly popular. For the acquisition of larger scenes, it is usually necessary to align all scans to a common reference frame. While there are methods using direct measurement of the orientation, due to simplicity and costs, mostly artificial targets are used. This works reliably, but usually adds a substantial amount of time to the acquisition process. Methods to align scans using the scan data itself have been known for a long time, however, being iterative, they need good initial values. In this paper, we investigate two different methods targeted at the determination of suitable initial values. The first one is based on a symbolic approach, using corresponding features to compute the orientation. The second one is based on an iterative alignment scheme originally proposed in the robotics domain. To assess the performance of both methods, a set of 20 scans has been acquired systematically along a trajectory in a downtown area. Reference orientations were obtained by a standard procedure using artificial targets. We present the results of both methods regarding convergence and accuracy, and compare their performance. "
}
@article{Mizrahi201576,
title = "Detection of critical points of multivariate piecewise polynomial systems ",
journal = "Computer Aided Geometric Design ",
volume = "40",
number = "",
pages = "76 - 87",
year = "2015",
note = "",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2015.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0167839615001193",
author = "Jonathan Mizrahi and Gershon Elber",
keywords = "Critical points",
keywords = "Subdivision solvers",
keywords = "B-spline basis functions",
keywords = "Singular points ",
abstract = "Abstract We propose a general scheme for detecting critical locations (of dimension zero) of piecewise polynomial multivariate equation systems. Our approach generalizes previously known methods for locating tangency events or self-intersections, in contexts such as surface–surface intersection (SSI) problems and the problem of tracing implicit plane curves. Given the algebraic constraints of the original problem, we formulate additional constraints, seeking locations where the differential matrix of the original problem has a non-maximal rank. This makes the method independent of a specific geometric application, as well as of dimensionality. Within the framework of subdivision based solvers, test results are demonstrated for non-linear systems with three and four unknowns. "
}
@article{Shi2011663,
title = "Attitude-sensor-aided in-process registration of multi-view surface measurement ",
journal = "Measurement ",
volume = "44",
number = "4",
pages = "663 - 673",
year = "2011",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2010.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0263224110003283",
author = "Chunqin Shi and Liyan Zhang and Hu Wei and Shenglan Liu",
keywords = "3D surface measurement",
keywords = "Range image registration",
keywords = "Attitude sensor",
keywords = "Geometric transformation ",
abstract = "A novel method for in-process registration of 3D point clouds scanned from different views is presented. A miniature attitude sensor, which can output its pitch, roll and yaw angles in real-time, is mounted on the scanner. The relative pose between the attitude sensor and the scanner is calibrated in advance by a simple yet effective algorithm. When the scanner is moved from one standpoint to another in a measuring process, the real-time readings of the attitude sensor is utilized to compute the rotation movement of the scanner. After applying the rotation transformation to the current point dataset, the translation movement is efficiently determined by exploiting the normal vector constraint between the correspondence points. The rigid transformation obtained fully automatically can serve as a qualified initial estimate for further fine registration. Experiments demonstrate the applicability of the proposed method. "
}
@article{Lin2016375,
title = "Real-time automatic registration in optical surgical navigation ",
journal = "Infrared Physics & Technology ",
volume = "76",
number = "",
pages = "375 - 385",
year = "2016",
note = "",
issn = "1350-4495",
doi = "https://doi.org/10.1016/j.infrared.2016.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S1350449515300487",
author = "Qinyong Lin and Rongqian Yang and Ken Cai and Xuan Si and Xiuwen Chen and Xiaoming Wu",
keywords = "Automatic registration",
keywords = "Fiducial marker localization",
keywords = "Image guidance",
keywords = "Optical tracking",
keywords = "Real time ",
abstract = "Abstract An image-guided surgical navigation system requires the improvement of the patient-to-image registration time to enhance the convenience of the registration procedure. A critical step in achieving this aim is performing a fully automatic patient-to-image registration. This study reports on a design of custom fiducial markers and the performance of a real-time automatic patient-to-image registration method using these markers on the basis of an optical tracking system for rigid anatomy. The custom fiducial markers are designed to be automatically localized in both patient and image spaces. An automatic localization method is performed by registering a point cloud sampled from the three dimensional (3D) pedestal model surface of a fiducial marker to each pedestal of fiducial markers searched in image space. A head phantom is constructed to estimate the performance of the real-time automatic registration method under four fiducial configurations. The head phantom experimental results demonstrate that the real-time automatic registration method is more convenient, rapid, and accurate than the manual method. The time required for each registration is approximately 0.1 s. The automatic localization method precisely localizes the fiducial markers in image space. The averaged target registration error for the four configurations is approximately 0.7 mm. The automatic registration performance is independent of the positions relative to the tracking system and the movement of the patient during the operation. "
}
@article{Ulas201111602,
title = "A 3D Scan Matching Method Based On Multi-Layered Normal Distribution Transform ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11602 - 11607",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.02865",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016454790",
author = "Cihan Ulas and Hakan Temeltas",
abstract = "Abstract Scan matching plays a significant role for 3D simultaneously localization and mapping (SLAM). Before applying the \{SLAM\} methods, two 3D data which belong to highly correlated scene has to be registered by finding the correct transformation. In this paper, we introduce a multi-layered (ML) extension of 3D Normal Distribution Transform based scan matching. In this method, point cloud is subdivided into 8n equally sized cells, where n stands for the level of layer. Unlike the NDT, the score function is described as the Mahalanobis distance. In addition, Newton and Levenberg-Marquardt methods are used to optimize the score function. The proposed method is compared with original NDT, and the optimization methods are discussed. Finally, the performance evaluation is given for experimentally obtained datasets. The approximation provides much faster and long distance measurement capabilities than ordinary NDT. "
}
@article{Tesar2015107,
title = "Open architecture vehicles of the future ",
journal = "Mechanism and Machine Theory ",
volume = "89",
number = "",
pages = "107 - 127",
year = "2015",
note = "100th Birthday of Professor F.R. Erskine Crossley ",
issn = "0094-114X",
doi = "https://doi.org/10.1016/j.mechmachtheory.2014.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0094114X14002729",
author = "D. Tesar",
keywords = "Vehicles",
keywords = "Open architecture",
keywords = "Interfaces",
keywords = "Operating system",
keywords = "Actuator",
keywords = "Standardization",
keywords = "Certification",
keywords = "Real time",
keywords = "Decision theory",
keywords = "Performance maps ",
abstract = "Overview The last four decades have seen an explosion of open architecture electronics, computers, social media, modular operating systems, sensors, communication links, etc., all based on standardized highly certified and cost effective modules provided by a responsive supply chain. Virtually no progress of a similar nature for electro-mechanical systems (orthotics, aircraft, vehicles, surgery, manufacturing cells, etc.) has occurred [1]. A companion paper [2] on the Next Wave of Technology shows that the previous electronics wave was necessary to prepare the foundation to this emerging technology to continuously enhance performance-to-cost ratios for a very wide range of applications that form the core of the discipline of mechanical engineering. Major government agencies (especially in Europe and the U.S.) have begun to structure their programs on “popular” ideas reinforced by the news media. Solid science for a multitude of electro-mechanical applications (see the \{NWT\} paper) is being displaced in favor of cloud computing, big data, neuro-science, nano-science, etc. The result is now becoming severe. The weakness of any one technology (in this case, the mechanicals) forms a weak link to make the resulting systems of technologies weak. The large failed investment of $30 billion for the Future Combat System (FCS) by the Army is proof of this continuing and growing imbalance. In this paper, we illustrate this large view development objective by concentrating on open architecture vehicles. As may be understood, only a portion of the required development can be described in this short paper. "
}
@article{Hehenberger2016273,
title = "Design, modelling, simulation and integration of cyber physical systems: Methods and applications ",
journal = "Computers in Industry ",
volume = "82",
number = "",
pages = "273 - 289",
year = "2016",
note = "",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2016.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0166361516300902",
author = "P. Hehenberger and B. Vogel-Heuser and D. Bradley and B. Eynard and T. Tomiyama and S. Achiche",
keywords = "Cyber physical systems",
keywords = "Mechatronics",
keywords = "Design",
keywords = "Modelling",
keywords = "CPS-paradigm",
keywords = "System classification ",
abstract = "Abstract The main drivers for the development and evolution of Cyber Physical Systems (CPS) are the reduction of development costs and time along with the enhancement of the designed products. The aim of this survey paper is to provide an overview of different types of system and the associated transition process from mechatronics to \{CPS\} and cloud-based (IoT) systems. It will further consider the requirement that methodologies for CPS-design should be part of a multi-disciplinary development process within which designers should focus not only on the separate physical and computational components, but also on their integration and interaction. Challenges related to CPS-design are therefore considered in the paper from the perspectives of the physical processes, computation and integration respectively. Illustrative case studies are selected from different system levels starting with the description of the overlaying concept of Cyber Physical Production Systems (CPPSs). The analysis and evaluation of the specific properties of a sub-system using a condition monitoring system, important for the maintenance purposes, is then given for a wind turbine. "
}
@article{Leong2007568,
title = "Automatic body feature extraction from a marker-less scanned human body ",
journal = "Computer-Aided Design ",
volume = "39",
number = "7",
pages = "568 - 582",
year = "2007",
note = "Human Modeling and Applications ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2007.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S0010448507000759",
author = "Iat-Fai Leong and Jing-Jing Fang and Ming-June Tsai",
keywords = "Feature identification",
keywords = "Body scanner",
keywords = "Computational geometry ",
abstract = "In this paper, we propose a novel method of body feature extraction from a marker-less scanned body. The descriptions of human body features mostly defined in \{ASTM\} (1999) and \{ISO\} (1989) are interpreted into logical mathematical definitions. Using these significant definitions, we employ image processing and computational geometry techniques to identify, automatically, body features from the torso cloud points. We have currently extracted 21 feature points and 35 feature lines on the human torso; this number may be extended if necessary. Moreover, less than 2 min processing time is taken for body feature extraction starting from the raw point cloud. This algorithm is successfully tested on several Asian female adults who are aged from 18 to 60. "
}
@article{Perrone2011438,
title = "Aerosol products by \{CALIOP\} at 532 nm and by a ground-based Raman lidar at 355 nm: Intercomparison methodology ",
journal = "Atmospheric Research ",
volume = "101",
number = "1–2",
pages = "438 - 449",
year = "2011",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2011.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0169809511000986",
author = "M.R. Perrone and F. De Tomasi and P. Burlizzi",
keywords = "Ground-based lidar",
keywords = "Satellite-based lidar",
keywords = "Aerosol profile",
keywords = "Lidar ratio",
keywords = "Extinction coefficient",
keywords = "Backscatter coefficient ",
abstract = "A methodology has been implemented to compare ground-based Raman lidar measurements at 355 nm to measurements at 532 nm with the Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) onboard the Cloud-Aerosol-Lidar and Infrared-Pathfinder-Satellite-Observation (CALIPSO) and contribute to the validation of level 2 (version 2) aerosol products. In particular, lidar measurements performed at Lecce (40°20′N, 18°6′E) in 2006, 2008, and 2009 within the European Aerosol Research Lidar Network have been compared to \{CALIOP\} measurements co-located in time and performed at radial distances from Lecce varying from 6 up to 19 km. Extinction- and backscatter-related Ångström exponents from sun/sky photometer measurements have synergistically been used to calculate aerosol extinction (α(z)) and backscatter (β(z)) coefficients at 532 nm from the ones at 355 nm retrieved from ground-based lidar measurements. Selected clear-sky study-cases have been analyzed to illustrate the implemented methodology and address the difficulties that may occur to fill the missing information of ground based measurements at 532 nm. Direct profile-to-profile comparisons have demonstrated either the reliability of the implemented methodology and the \{CALIOP\} capability to detect aerosol at least up to ~ 0.3 km from ground in cloud-free conditions. The agreement on the aerosol layer top height is within ± 0.1 km for the selected study cases. It has been shown that the spatial variability of aerosols can greatly complicate the validation of \{CALIOP\} backscatter and extinction coefficient profiles by direct comparison with corresponding profiles from ground-based instruments co-located in time, but not in space. "
}
@article{Canal201665,
title = "A real-time Human-Robot Interaction system based on gestures for assistive scenarios ",
journal = "Computer Vision and Image Understanding ",
volume = "149",
number = "",
pages = "65 - 77",
year = "2016",
note = "Special issue on Assistive Computer Vision and Robotics - "Assistive Solutions for Mobility, Communication and HMI" ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S107731421600076X",
author = "Gerard Canal and Sergio Escalera and Cecilio Angulo",
keywords = "Gesture recognition",
keywords = "Human Robot Interaction",
keywords = "Dynamic Time Warping",
keywords = "Pointing location estimation ",
abstract = "Abstract Natural and intuitive human interaction with robotic systems is a key point to develop robots assisting people in an easy and effective way. In this paper, a Human Robot Interaction (HRI) system able to recognize gestures usually employed in human non-verbal communication is introduced, and an in-depth study of its usability is performed. The system deals with dynamic gestures such as waving or nodding which are recognized using a Dynamic Time Warping approach based on gesture specific features computed from depth maps. A static gesture consisting in pointing at an object is also recognized. The pointed location is then estimated in order to detect candidate objects the user may refer to. When the pointed object is unclear for the robot, a disambiguation procedure by means of either a verbal or gestural dialogue is performed. This skill would lead to the robot picking an object in behalf of the user, which could present difficulties to do it by itself. The overall system — which is composed by a \{NAO\} and Wifibot robots, a KinectTM v2 sensor and two laptops — is firstly evaluated in a structured lab setup. Then, a broad set of user tests has been completed, which allows to assess correct performance in terms of recognition rates, easiness of use and response times. "
}
@article{Gehlot2015154,
title = "Impact of Sahara dust on solar radiation at Cape Verde Islands derived from \{MODIS\} and surface measurements ",
journal = "Remote Sensing of Environment ",
volume = "166",
number = "",
pages = "154 - 162",
year = "2015",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.05.026",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715300298",
author = "Swati Gehlot and Peter J. Minnett and Detlef Stammer",
keywords = "Sahara dust",
keywords = "Radiation",
keywords = "MODIS",
keywords = "Aeronet",
keywords = "AOD ",
abstract = "Abstract Based on radiometer measurements of solar irradiance (direct and diffuse light) and Aeronet-based aerosol optical depth (AOD) obtained at the Cape Verde atmospheric observatory during a major cloud-free dust outbreak event on February 7, 2012, the relationship between Saharan mineral dust outbreaks and a reduction of solar irradiance is quantified. The investigation is representative of the eastern subtropical North Atlantic region where the wind mobilization of mineral desert dust from the Sahara results in aerosol signals that are large enough to outweigh those from other aerosol types such as anthropogenic and marine aerosols. Ground-based estimates of \{AOD\} show frequency dependence as is expected from Mie theory. Our \{AOD\} signals agree well with satellite-based \{MODIS\} products and reveal \{AOD\} values exceeding 2.5 during the investigated dust storm event. We also demonstrate the use of satellite imagery with an atmospheric trajectory model to simulate time series of measurements at a given location. Using this approach, variations in \{AOD\} observed during February 7, 2012 can be rationalized as spatial inhomogeneities in the atmospheric dust load being advected laterally over the observing site. Our measurements suggest a dust forcing efficiency of around − 90 W/m2/AOD at a wavelength of 380 nm, which is about 10–15% greater than reported in the literature indicative of a possible non-linear behavior at high AODs. "
}
@article{Dirafzoon201779,
title = "A framework for mapping with biobotic insect networks: From local to global maps ",
journal = "Robotics and Autonomous Systems ",
volume = "88",
number = "",
pages = "79 - 96",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S092188901530289X",
author = "Alireza Dirafzoon and Alper Bozkurt and Edgar Lobaton",
keywords = "Topological mapping",
keywords = "Metric estimation",
keywords = "Manifold learning",
keywords = "Cyborg insects",
keywords = "Topological data analysis",
keywords = "Emergency response ",
abstract = "Abstract We present an approach for global exploration and mapping of unknown environments using a swarm of cyborg insects, known as biobots, for emergency response scenarios under minimal sensing and localization constraints. We exploit natural stochastic motion models and controlled locomotion of biobots in conjunction with an aerial leader to explore and map a domain of interest. A sliding window strategy is adopted to construct local maps from coordinate free encounter information of the agents by means of local metric estimation. Robust topological features from these local representations are extracted using topological data analysis and a classification scheme. These maps are then merged into a global map which can be visualized using a graphical representation, that integrates geometric as well as topological features of the environment. Simulation and experimental results with biologically inspired robotic platform are presented to illustrate and verify the correctness of our approach, which provides building blocks for \{SLAM\} with biobotic insects. "
}
@article{Palleja20101420,
title = "Sensitivity of tree volume measurement to trajectory errors from a terrestrial \{LIDAR\} scanner ",
journal = "Agricultural and Forest Meteorology ",
volume = "150",
number = "11",
pages = "1420 - 1427",
year = "2010",
note = "",
issn = "0168-1923",
doi = "https://doi.org/10.1016/j.agrformet.2010.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S0168192310001942",
author = "T. Palleja and M. Tresanchez and M. Teixido and R. Sanz and J.R. Rosell and J. Palacin",
keywords = "Terrestrial LIDAR",
keywords = "Crop modeling",
keywords = "Dose control ",
abstract = "The use of terrestrial \{LIDARs\} in agriculture enables the measurement of structural parameters of the orchards such as the volume of the trees. The sequence of two-dimensional scans performed with a \{LIDAR\} attached to a tractor can be interpreted as the three-dimensional silhouette of the trees of the grove and used to estimate their volume. In this work, the sensitivity of the tree volume estimates relative to different error sources in the estimated spatial trajectory of the \{LIDAR\} is analyzed. Tests with pear trees have demonstrated that the estimation of the volume is very sensitive to errors in the determination of the distance from the \{LIDAR\} to the center of the trees (with errors up to 30% for an error of 50 mm) and in the determination of the angle of orientation of the \{LIDAR\} (with errors up to 30% for misalignments of 2°). Therefore, any experimental procedure for tree volume estimate based on a motorized terrestrial \{LIDAR\} scanner must include additional devices or procedures to control or estimate and correct these error sources. "
}
@article{Wettergreen1993171,
title = "Exploring Mount Erebus by walking robot ",
journal = "Robotics and Autonomous Systems ",
volume = "11",
number = "3–4",
pages = "171 - 185",
year = "1993",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/0921-8890(93)90022-5",
url = "http://www.sciencedirect.com/science/article/pii/0921889093900225",
author = "David Wettergreen and Chuck Thorpe and Red Whittaker",
keywords = "Walking",
keywords = "Legged",
keywords = "Autonomous",
keywords = "Robot",
keywords = "Volcanoes ",
abstract = "Dante is a tethered walking robot capable of climbing steep slopes. In 1992 it was created at Carnegie Mellon University and deployed in Antarctica to explore an active volcano, Mount Erebus. The Dante project's robot science objectives were to demonstrate a real exploration mission, rough terrain locomotion, environmental survival, and self-sustained operation in the harsh Antarctic climate. The volcano science objective was to study the unique convecting magma lake inside Mount Erebus' inner crater. The expedition demonstrated the advancing state-of-art in mobile robotics and the future potential of robotic explorers. This paper details our objectives, describes the Dante robot, overviews what happened on the expedition and discusses what did and didn't work. "
}
@incollection{Sun2015341,
title = "Chapter 5.1 - The State of the Art in Grasping and Manipulation for Household Service ",
editor = "Xu, Yangsheng and Qian, Huihuan  and Wu, Xinyu ",
booktitle = "Household Service Robotics ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2015",
pages = "341 - 356",
isbn = "978-0-12-800881-2",
doi = "https://doi.org/10.1016/B978-0-12-800881-2.00016-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128008812000165",
author = "Yuandong Sun and Huihuan Qian and Yangsheng Xu",
keywords = "Control",
keywords = "Grasping and manipulation of objects",
keywords = "Planning",
keywords = "Target detection ",
abstract = "Abstract Robotic grasping and manipulation comprise three subtasks, i.e., target detection, planning, and control. The robot first needs to detect the target. Here “detect” means to find (or recognize) the target and locate it. The target could be the object to be manipulated (e.g., electrical plugs) or the destination of the object (electrical sockets). Then the robot approaches the target in an optimized trajectory. In the process of approaching and grasping, the robot should be controlled to perform the task correctly and smoothly. In this chapter, we review the approaches to accomplish these three subtasks, i.e., target detection, planning, and control. "
}
@article{Fisch201290,
title = "Learning from others: Exchange of classification rules in intelligent distributed systems ",
journal = "Artificial Intelligence ",
volume = "187–188",
number = "",
pages = "90 - 114",
year = "2012",
note = "",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S0004370212000410",
author = "Dominik Fisch and Martin Jänicke and Edgar Kalkowski and Bernhard Sick",
keywords = "Classification",
keywords = "Rule exchange",
keywords = "Collaborative learning",
keywords = "Uncertain knowledge",
keywords = "Probabilistic modeling",
keywords = "Collective intelligence",
keywords = "Interestingness ",
abstract = "Learning by an exchange of knowledge and experiences enables humans to act efficiently in a very dynamic environment. Thus, it would be highly desirable to enable intelligent distributed systems to behave in a way which follows that biological archetype. We believe that knowledge exchange will become increasingly important in many application areas such as intrusion detection, driver assistance, or robotics. Constituents of a distributed system such as software agents, cars equipped with smart sensors, or intelligent robots may learn from each other by exchanging knowledge in form of classification rules, for instance. This article proposes techniques for the exchange of classification rules that represent uncertain knowledge. For that purpose, we introduce methods for knowledge acquisition in dynamic environments, for gathering and using meta-knowledge about rules (i.e., experience), and for rule exchange in distributed systems. The methods are based on a probabilistic knowledge modeling approach. We describe the results of two case studies where we show that knowledge exchange (exchange of learned rules) may be superior to information exchange (exchange of raw observations, i.e. samples) and demonstrate that the use of experiences (meta-knowledge concerning the rules) may improve that rule exchange process further. Some possible real application scenarios are sketched briefly and an application in the field of intrusion detection in computer networks is elaborated in more detail. "
}
@article{Igelbrink2016126,
title = "Online Mesh Optimization for Large Scale KinectFusion Meshes ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "126 - 131",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.720",
url = "http://www.sciencedirect.com/science/article/pii/S240589631630996X",
author = "Tristan Igelbrink and Thomas Wiemann and Joachim Hertzberg",
keywords = "Mapping",
keywords = "Surface Reconstruction",
keywords = "Optimization",
keywords = "Camera Tracking ",
abstract = "Abstract In this paper we present an extension of Large Scale Kinect Fusion to compute optimized triangle meshes on-the-fly by removing redundant triangles on planar surfaces. The optimization is integrated into the reconstruction pipeline to compute the optimized meshes asynchronously to the reconstruction process in real time. The computed reconstructions can be extracted directly without the need of any post processing. "
}
@article{Srinivasan2012358,
title = "A survey of sensory data boundary estimation, covering and tracking techniques using collaborating sensors ",
journal = "Pervasive and Mobile Computing ",
volume = "8",
number = "3",
pages = "358 - 375",
year = "2012",
note = "",
issn = "1574-1192",
doi = "https://doi.org/10.1016/j.pmcj.2012.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S1574119212000430",
author = "Sumana Srinivasan and Subhasri Dattagupta and Purushottam Kulkarni and Krithi Ramamritham",
keywords = "Boundary estimation",
keywords = "Boundary tracking",
keywords = "Boundary covering",
keywords = "Wireless sensor networks",
keywords = "Mobile sensors",
keywords = "Contour covering",
keywords = "Contour estimation ",
abstract = "Boundary estimation and tracking have important applications in the areas of environmental monitoring and disaster management. A boundary separates two regions of interest in a phenomenon. It can be visualized as an edge if there is a sharp change in the field value between the two regions or alternatively, as a contour with a field value f = τ separating two regions with field values f &gt; τ and f &lt; τ . Examples include contours/boundaries of hazardous concentration in a pollutant spill, frontal boundary of a forest fire, isotherms, isohalines etc. Recent advances in the area of embedded sensor devices and robotics have led to deployments of networks of sensors capable of sensing, computing, communication and mobility. They are used to estimate the boundaries of interest in physical phenomena, monitor or track them over time and also in some cases, mitigate the spatial spread of the phenomena. Since these sensors work autonomously in the environment, minimizing the energy consumed while maximizing the accuracy of estimation or tracking is the main challenge for algorithms for boundary estimation and tracking. Several algorithms with these objectives have been proposed in the literature. In this work, we focus on the algorithms that estimate and cover boundaries found in the sensory data in a field and not the topological boundary of the sensor network per se, which is beyond the scope of this paper. Here, our objective is to provide a comprehensive survey of the algorithms for boundary estimation and tracking by providing a taxonomy based on two broad categories — (i) Boundary estimation and tracking, where the sensors estimate the boundary without physically covering the boundary and (ii) Boundary covering — where the sensors not only predict the location and estimate the entire boundary but also physically cover the boundary by surrounding and bounding it. We further classify the techniques based on (a) sensing capabilities —in situ, range or remote sensing (b) movement capabilities — static or mobile sensors and (c) boundary type — static or dynamic and (d) type of estimation — field estimation where the entire field is sampled to search for contours and localized estimation where sampling is done near the boundary and (e) different types of mobility models in the case of mobile sensors. We believe that such a survey has not been performed before. By capturing and classifying the current state-of-the-art and identifying open research problems, we hope to ignite interest and stimulate efforts towards promising solutions for real-world boundary estimation and tracking problems. "
}
@incollection{McCrie2016325,
title = "10 - Operating Physical Security- and Technology-Centered Programs ",
editor = "McCrie, Robert ",
booktitle = "Security Operations Management (Third Edition) ",
publisher = "Butterworth-Heinemann",
edition = "Third Edition",
address = "Boston",
year = "2016",
pages = "325 - 362",
isbn = "978-0-12-802396-9",
doi = "https://doi.org/10.1016/B978-0-12-802396-9.00010-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780128023969000104",
author = "Robert McCrie",
keywords = "physical security",
keywords = "crime prevention through environmental design (CPTED)",
keywords = "risk versus cost ratio",
keywords = "designing security systems",
keywords = "security systems",
keywords = "radio-frequency identification (RFID)",
keywords = "burglar alarm certification ",
abstract = "Abstract Technology is a leading factor in achieving greater security for organizations, the public sector, and residential spaces. Internet processing and handheld computing devices have been particularly important in lowering risk. Integrating surveillance and communications with a monitoring system has produced measureable changes in greater security. Technology also is powerful with after-the-fact resolution of crimes or other incidents. This chapter begins with a widely recognized theory of achieving security through environmental design. It also discusses nonmechanical means of protection through electronic measures that are designed into systems. Technology enhances the capacity to authenticate persons or tokens and raise the level of confidence in identification. "
}
@article{RahmaniAsl2015401,
title = "BPOpt: A framework for BIM-based performance optimization ",
journal = "Energy and Buildings ",
volume = "108",
number = "",
pages = "401 - 412",
year = "2015",
note = "",
issn = "0378-7788",
doi = "https://doi.org/10.1016/j.enbuild.2015.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S0378778815302528",
author = "Mohammad Rahmani Asl and Saied Zarrinmehr and Michael Bergin and Wei Yan",
keywords = "Building information modeling (BIM)",
keywords = "Performance-based design",
keywords = "Building performance optimization",
keywords = "Multi-objective optimization",
keywords = "Parametric modeling",
keywords = "Visual programming ",
abstract = "Abstract The increase in global environmental concerns as well as the advancement of computational tools and methods have had significant impacts on the way in which buildings are being designed. Building professionals are increasingly expected to improve energy performance of their design. To achieve a high level of energy performance, multidisciplinary simulation-based optimization can be utilized to help designers in exploring more design alternatives and making informed decisions. Because of the high complexity in setting up a building model for multi-objective design optimization, there is a great demand of utilizing and integrating the advanced modeling and simulation technologies, including BIM, parametric modeling, cloud-based simulation, and optimization algorithms, as well as a new user interface that facilitates the setup of building parameters (decision variables) and performance fitness functions (design objectives) for automatically generating, evaluating, and optimizing multiple design options. This paper presents an integrated framework for building information modeling (BIM)-based performance optimization, BPOpt. This framework enables designers to explore design alternatives using an open-source, visual programming user interface on the top of a widely used \{BIM\} platform, to generate models of building design options, assess the environmental performance of the models through cloud-based simulation, and search for the most appropriate design alternatives. This paper details the process of the development of \{BPOpt\} and also provides a case study to show its application. The case study demonstrates the use of \{BPOpt\} in minimizing the energy consumption while maximizing the appropriate daylighting level for a residential building. Finally, strengths, limitations, current adoption by academia and industry, and future improvements of \{BPOpt\} for high-performance building design are discussed. "
}
@article{ZeibakShini2016312,
title = "Towards generation of as-damaged \{BIM\} models using laser-scanning and as-built BIM: First estimate of as-damaged locations of reinforced concrete frame members in masonry infill structures ",
journal = "Advanced Engineering Informatics ",
volume = "30",
number = "3",
pages = "312 - 326",
year = "2016",
note = "",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2016.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S1474034616300490",
author = "Reem Zeibak-Shini and Rafael Sacks and Ling Ma and Sagi Filin",
keywords = "BIM",
keywords = "Earthquake damage",
keywords = "Laser scanning",
keywords = "Reinforced concrete",
keywords = "Search and rescue",
keywords = "Structural frame ",
abstract = "Abstract After an earthquake, Terrestrial Laser Scanning (TLS) can capture point clouds of the damaged state of building facades rapidly, remotely and accurately. A long-term research effort aims to develop applications that can reconstruct ‘as-damaged’ \{BIM\} models of reinforced concrete (RC) framed buildings based on their ‘as-built’ \{BIM\} models and scans of their ‘as-damaged’ states. This paper focuses on a crucial step: generating an initial ‘best-guess’ for the new locations of the façade structural members. The output serves as the seed for a recursive process in which the location and damage to each object is refined in turn. Locating the ‘as-built’ structural members in the ‘as-damaged’ scan is challenging because each member may have different displacement and damage. An algorithm was developed and tested for the case of reinforced concrete frames with masonry infill walls. It exploits the topology of the frames to map the original structural grid onto the damaged façade. The tests used synthetic datasets prepared from records of two earthquake-damaged buildings. In both cases, the results were sufficiently accurate to allow progress to the following step, assessment of the individual structural members. "
}
@article{Weber201723,
title = "Temporal dynamics of ‘HoBi’-like pestivirus quasispecies in persistently infected calves generated under experimental conditions ",
journal = "Virus Research ",
volume = "227",
number = "",
pages = "23 - 33",
year = "2017",
note = "",
issn = "0168-1702",
doi = "https://doi.org/10.1016/j.virusres.2016.09.018",
url = "http://www.sciencedirect.com/science/article/pii/S0168170216305019",
author = "Matheus N. Weber and Fernando V. Bauermann and Cláudio W. Canal and Darrell O. Bayles and John D. Neill and Julia F. Ridpath",
keywords = "Pestivirus",
keywords = "Persistent infection",
keywords = "Quasispecies",
keywords = "‘HoBi’-like ",
abstract = "Abstract ‘HoBi’-like virus is an atypical group within the Pestivirus genus that is implicated in economic losses for cattle producers due to both acute and persistent infections. Pestivirus strains exist as quasispecies (swarms of individual viruses) in infected animals and the viral populations making up the quasispecies differ widely in size and diversity in each animal. In the present study the viral quasispecies circulating in persistently infected (PI) calves, generated and maintained under experimental conditions using two different ‘HoBi’-like strains, was observed over time. An increase in genetic variability and the development of certain mutations was observed over time. Mutations observed included the loss of a putative N-linked glycosylation site in the \{E2\} region and the change of specific residues in E1/E2. It is hypothesized that these changes may be the results on continued adaption of the pestivirus to individual hosts. This is the first study characterizing variation in the viral swarms of animals persistently infected with HoBi-like viruses over time. Studies of the shifts in \{PI\} viral swarms will contribute to our understanding of the host and viral mechanisms that function in the maintenance of pestivirus persistent infections. "
}
@article{Kowadlo2009723,
title = "Improving the robustness of naïve physics airflow mapping, using Bayesian reasoning on a multiple hypothesis tree ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "6–7",
pages = "723 - 737",
year = "2009",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.10.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008002029",
author = "Gideon Kowadlo and R. Andrew Russell",
keywords = "Odour localisation",
keywords = "Odor localization",
keywords = "Naive physics",
keywords = "Airflow modelling",
keywords = "Bayesian",
keywords = "Multiple hypothesis ",
abstract = "Previous work on robotic odour localisation in enclosed environments, relying on an airflow model, has faced significant limitations due to the fact that large differences between airflow topologies are predicted for only small variations in a physical map. This is due to uncertainties in the map and approximations in the modelling process. Furthermore, there are uncertainties regarding the flow direction through inlet/outlet ducts. We present a method for dealing with these uncertainties through the generation of multiple airflow hypotheses. As the robot performs odour localisation, airflow in the environment is measured and used to adjust the confidences of the hypotheses using Bayesian inference. The best hypothesis is then selected, which allows the completion of the localisation task. Experimental results show that this method is capable of improving the robustness of odour localisation in the presence of uncertainties, where previously it was incapable. The results further demonstrate the usefulness of naïve physics for practical robotics applications. "
}
@article{Wei2016261,
title = "Plane-based scan registration with moving vehicles exclusion ",
journal = "Robotics and Autonomous Systems ",
volume = "83",
number = "",
pages = "261 - 274",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015301330",
author = "Chongyang Wei and Ruili Wang and Tao Wu and Tongtong Chen and Yuqiang Fang and Hao Fu",
keywords = "Scan registration",
keywords = "Moving vehicle detection",
keywords = "Likelihood-field-based model",
keywords = "Plane-based criterion",
keywords = "Autonomous vehicles ",
abstract = "Abstract Moving vehicles have a considerable negative effect on the accuracy of scan registration and lidar odometry. To remove the negative effect, we propose an extended 2D virtual scan to obtain all moving objects in the sensing range of lidar by a scan differencing operation between two consecutive scans. The dynamic objects’ poses are estimated with our proposed likelihood-field-based vehicle measurement model and the motion evidence is utilized to classify the objects as moving vehicles or not. In this way, the moving/dynamic vehicles are detected and the points hitting them are removed. The remaining points are then taken as an input into the alignment. In the registration, we adjust the raw distorted points by modeling the lidar motion as the constant angular and linear velocities within a scan interval, and then exploit the probabilistic framework to model the local plane structure of the matched feature points instead of the original point-to-point mode. The transform is achieved by the combination of coarse motion estimation and fine batch adjustment. The algorithm has been validated by a large set of qualitative tests on our collected point clouds and quantitative comparisons with the excellent methods on the public Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) odometry datasets. "
}
@article{Figueroa2013580,
title = "Joint origin identification of articulated robots with marker-based multi-camera optical tracking systems ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "6",
pages = "580 - 592",
year = "2013",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000444",
author = "Nadia B. Figueroa and Florian Schmidt and Haider Ali and Nikolaos Mavridis",
keywords = "Joint identification",
keywords = "Marker-based multi-camera optical tracking system",
keywords = "Calibration",
keywords = "Articulated robots ",
abstract = "Abstract Marker-based multi-camera optical tracking systems are being used in the robotics field to track robots for validation, verification, and calibration of their kinematic and dynamic models. These tracking systems estimate the pose of tracking bodies attached to objects within a tracking volume. In this work, we explore the case of tracking the origins of joints of articulated robots when the tracking bodies are mounted on limbs or structures relative to the joints. This configuration leads to an unknown relative pose between the tracking body and the joint origin. The identification of this relative pose is essential for an accurate representation of the kinematic model. We propose an approach for the identification of the origin of joints relative to tracking bodies by using state-of-the-art center of rotation (CoR) and axis of rotation (AoR) estimation methods. The applicability and effectiveness of our approach is demonstrated in two successful case studies: (i) the verification of the upper body kinematics of DLR’s humanoid Rollin’ Justin and (ii) the identification of the kinematic parameters of an \{ST\} Robot arm relative to its environment for the embodiment of a situated conversational assistant. "
}
@article{Xia201472,
title = "A critical assessment of direct radiative effects of different aerosol types on surface global radiation and its components ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "149",
number = "",
pages = "72 - 80",
year = "2014",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.07.020",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003264",
author = "Xiangao Xia",
keywords = "Aerosol",
keywords = "Direct radiative effect",
keywords = "Aerosol type ",
abstract = "Abstract A critical assessment of direct radiative effects of different aerosol types on surface global, direct and diffuse radiation is presented. The analysis is based on measurements of aerosol optical properties and surface solar radiation (SSR) of cloud-free days at the Baseline Surface Radiation Network (BSRN) and Aerosol Robotic Network station (AERONET) of Xianghe over the North China Plain between October 2004 and May 2012. Six aerosol types are classified based on aerosol size and absorption from the \{AERONET\} retrieval products, including two coarse-mode dominated aerosol types: dust (DU: fine mode fraction (FMF)&lt;0.4) and polluted dust (PD: \{FMF\} within 0.4–0.7) and four fine-mode dominated aerosol types (FMF&gt;0.7) but with different single scattering albedo (SSA): highly absorbing (HA: SSA&lt;0.85), moderately absorbing (MA: \{SSA\} within 0.85–0.90), slightly absorbing (SA: \{SSA\} within 0.90–0.95) and very weakly absorbing (WA: SSA&gt;0.95). Dramatic differences in aerosol direct radiative effect (ADRE) on global \{SSR\} and its components between the six aerosol types have been revealed. \{ADRE\} efficiency on global \{SSR\} for solar zenight angle (SZA) between 55° and 65° ranges from −106 W m−2 for \{WA\} to −181 W m−2 for HA. The minimum \{ADRE\} efficiency on diffuse \{SSR\} is derived for \{HA\} aerosols, being 113 W m−2 that is about half of that by DU, the maximum value of six aerosol types. \{ADRE\} efficiency on global \{SSR\} by \{DU\} and \{PD\} (−141 to −150 W m−2 for \{SZA\} between 55° and 65°) is comparable to that by MA, although 100 W m−2 more direct \{SSR\} is extincted by \{DU\} and \{PD\} than by MA. \{DU\} and \{PD\} induce more diffuse \{SSR\} than \{MA\} that offsets larger reduction of direct \{SSR\} by \{DU\} and PD. Implications of the results to related researches are detailed discussed. The results are derived from aerosol and radiation data in the North China Plain, however the method can be used to any other stations with similar measurements. "
}
@article{Kaupp2010444,
title = "Human–robot communication for collaborative decision making — A probabilistic approach ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "5",
pages = "444 - 456",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2010.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889010000400",
author = "Tobias Kaupp and Alexei Makarenko and Hugh Durrant-Whyte",
keywords = "Human–robot communication",
keywords = "Information fusion",
keywords = "Collaborative control",
keywords = "Adjustable autonomy",
keywords = "Semi-autonomous systems ",
abstract = "Humans and robots need to exchange information if the objective is to achieve a task collaboratively. Two questions are considered in this paper: what and when to communicate. To answer these questions, we developed a human–robot communication framework which makes use of common probabilistic robotics representations. The data stored in the representation determines what to communicate, and probabilistic inference mechanisms determine when to communicate. One application domain of the framework is collaborative human–robot decision making: robots use decision theory to select actions based on perceptual information gathered from their sensors and human operators. In this paper, operators are regarded as remotely located, valuable information sources which need to be managed carefully. Robots decide when to query operators using Value-Of-Information theory, i.e. humans are only queried if the expected benefit of their observation exceeds the cost of obtaining it. This can be seen as a mechanism for adjustable autonomy whereby adjustments are triggered at run-time based on the uncertainty in the robots’ beliefs related to their task. This semi-autonomous system is demonstrated using a navigation task and evaluated by a user study. Participants navigated a robot in simulation using the proposed system and via classical teleoperation. Results show that our system has a number of advantages over teleoperation with respect to performance, operator workload, usability, and the users’ perception of the robot. We also show that despite these advantages, teleoperation may still be a preferable driving mode depending on the mission priorities. "
}
@article{Stückler20131106,
title = "Efficient 3D object perception and grasp planning for mobile manipulation in domestic environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1106 - 1115",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001297",
author = "Jörg Stückler and Ricarda Steffens and Dirk Holz and Sven Behnke",
keywords = "Scene segmentation",
keywords = "Grasp planning",
keywords = "Mobile manipulation ",
abstract = "In this article, we describe efficient methods for tackling everyday mobile manipulation tasks that require object pick-up. In order to achieve real-time performance in complex environments, we focus our approach on fast yet robust solutions. For 3D perception of objects on planar surfaces, we develop scene segmentation methods that process depth images in real-time at high frame rates. We efficiently plan feasible, collision-free grasps for the segmented objects directly from the perceived point clouds to achieve fast execution times. We evaluate our approaches quantitatively in lab experiments and also report on the successful integration of our methods in public demonstrations at RoboCup@Home competitions in 2011 and 2012. "
}
@article{Garambaki2016197,
title = "Opportunistic inspection planning for Railway eMaintenance ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "28",
pages = "197 - 202",
year = "2016",
note = "3rd \{IFAC\} Workshop on Advanced Maintenance Engineering, Services and Technology \{AMEST\} 2016Biarritz, France, 19—21 October 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.034",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316324582",
author = "A.H.S. Garambaki and Adithya Thaduri and A.M.N.D.B. Seneviratne and Uday Kumar",
keywords = "eMaintenance",
keywords = "Opportunistic Inspection planning",
keywords = "Switches",
keywords = "crossings",
keywords = "Swedish railway",
keywords = "Intelligent functional test ",
abstract = "Abstract: Railway infrastructure is a complex system that comprises of several subsystems which interacts in hierarchical, multi-distributive and multi-user environment. It is a difficult task to perform inspections for all the assets at an instant because the train management system decides when to conduct different types of inspection techniques on several assets in a particular track section. There are two main wastes of resources for inspection planning occurred in maintenance; under usage due to inaccurate prediction of failure and over usage because the necessary information already has been acquired from other sources. These irregularities lead to wastage of resources, for instance, human, machine and time that has tremendous implications on cost, availability and manpower. This paper proposes a methodology by using intelligent functional test outcome to assess the performability of an asset and integrating the data to the eMaintenance cloud platform of Swedish railway infrastructure. By implementing this methodology, we can achieve better planning of resources for optimal performance of assets. A case study is performed on Switches and Crossings of Swedish railway infrastructure for the applicability of the proposed methodology. "
}
@article{Faria2012247,
title = "A Probabilistic Framework to Detect Suitable Grasping Regions on Objects ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "45",
number = "22",
pages = "247 - 252",
year = "2012",
note = "10th \{IFAC\} Symposium on Robot Control ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20120905-3-HR-2030.00090",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016336187",
author = "Diego R. Faria and Ricardo Martins and Jorge Lobo and Jorge Dias",
keywords = "Human demonstration",
keywords = "object representation",
keywords = "probabilistic framework",
keywords = "grasping ",
abstract = "Abstract This work relies on a probabilistic framework to search for suitable grasping regions on objects. In this approach, the object model is acquired based on occupancy grid representation that deals with the sensor uncertainty allowing later the decomposition of the object global shape into components. Through mixture distribution-based representation we achieve the object segmentation where the outputs are the point cloud clustering. Each object component is matched to a geometrical primitive. The advantage of representing object components into geometrical primitives is due to the simplification and approximation of the shape that facilitates the search for suitable object region for grasping given a context. Human demonstrations of predefined grasp are recorded and then overlaid on the object surface given by the probabilistic volumetric map to find the contact points of stable grasps. By observing the human choice during the object grasping, we perform the learning phase. Bayesian theory is used to identify a potential object region for grasping in a specific context when the artificial system faces a new object that is taken as a familiar object due to the primitives approximation into known components. "
}
@article{Schaap20082187,
title = "Evaluation of \{MODIS\} aerosol optical thickness over Europe using sun photometer observations ",
journal = "Atmospheric Environment ",
volume = "42",
number = "9",
pages = "2187 - 2197",
year = "2008",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2007.11.044",
url = "http://www.sciencedirect.com/science/article/pii/S1352231007010941",
author = "M. Schaap and R.M.A. Timmermans and R.B.A. Koelemeijer and G. de Leeuw and P.J.H. Builtjes",
keywords = "Aerosol optical thickness",
keywords = "Europe",
keywords = "Remote sensing",
keywords = "Verification ",
abstract = "Satellite retrieved aerosol optical thickness (AOT) may be useful to improve the insight in \{PM\} distributions in Europe in combination with models and ground-based measurements. To use \{AOT\} in mapping or assimilation experiments, it requires well-validated satellite data. We have compared the \{AOT\} retrieved by \{MODIS\} (collection 4) to sun photometer data from the \{AERONET\} network in Europe and found a good temporal correlation between \{MODIS\} and AERONET. However, we also found a large positive bias of about 50% in the \{MODIS\} \{AOT\} data, which is in accordance with earlier findings. We highlight the strong seasonal signature in the overestimation of \{AOT\} by \{MODIS\} with a maximum during summer. After correction for the bias, the accuracy of \{MODIS\} \{AOT\} retrievals agrees with reported uncertainties and the residuals show a normal distribution. We have introduced a simple method for the evaluation of the possible extent of cloud contamination and hypothesise that on average, up to one-third of the \{MODIS\} retrievals may be cloud contaminated. For some stations in central Europe, this percentage was found to be larger than &gt;50%. The consequences of a bias between satellite and in situ data for their use in the mapping of aerosol levels are discussed. "
}
@article{Kim2014176,
title = "Improvement of aerosol optical depth retrieval over Hong Kong from a geostationary meteorological satellite using critical reflectance with background optical depth correction ",
journal = "Remote Sensing of Environment ",
volume = "142",
number = "",
pages = "176 - 187",
year = "2014",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2013.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0034425713004379",
author = "Mijin Kim and Jhoon Kim and Man Sing Wong and Jongmin Yoon and Jaehwa Lee and Dong Wu and P.W. Chan and Janet E. Nichol and Chu-Yong Chung and Mi-Lim Ou",
keywords = "Remote sensing",
keywords = "Algorithm",
keywords = "Aerosol optical depth",
keywords = "Critical reflectance",
keywords = "Background aerosol optical depth",
keywords = "Geostationary ",
abstract = "Abstract Despite continuous efforts to retrieve aerosol optical depth (AOD) using a conventional 5-channel meteorological imager in geostationary orbit, the accuracy in urban areas has been poorer than other areas primarily due to complex urban surface properties and mixed aerosol types from different emission sources. The two largest error sources in aerosol retrieval have been aerosol type selection and surface reflectance. In selecting the aerosol type from a single visible channel, the season-dependent aerosol optical properties were adopted from long-term measurements of Aerosol Robotic Network (AERONET) sun-photometers. With the aerosol optical properties obtained from the \{AERONET\} inversion data, look-up tables were calculated by using a radiative transfer code: the Second Simulation of the Satellite Signal in the Solar Spectrum (6S). Surface reflectance was estimated using the clear sky composite method, a widely used technique for geostationary retrievals. Over East Asia, the \{AOD\} retrieved from the Meteorological Imager showed good agreement, although the values were affected by cloud contamination errors. However, the conventional retrieval of the \{AOD\} over Hong Kong was largely underestimated due to the lack of information on the aerosol type and surface properties. To detect spatial and temporal variation of aerosol type over the area, the critical reflectance method, a technique to retrieve single scattering albedo (SSA), was applied. Additionally, the background aerosol effect was corrected to improve the accuracy of the surface reflectance over Hong Kong. The \{AOD\} retrieved from a modified algorithm was compared to the collocated data measured by \{AERONET\} in Hong Kong. The comparison showed that the new aerosol type selection using the critical reflectance and the corrected surface reflectance significantly improved the accuracy of \{AODs\} in Hong Kong areas, with a correlation coefficient increase from 0.65 to 0.76 and a regression line change from τMI [basic algorithm] = 0.41τAERONET + 0.16 to τMI [new algorithm] = 0.70τAERONET + 0.01. "
}
@article{Shi2017130,
title = "Synergy of \{MODIS\} and \{AATSR\} for better retrieval of aerosol optical depth and land surface directional reflectance ",
journal = "Remote Sensing of Environment ",
volume = "195",
number = "",
pages = "130 - 141",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2017.04.010",
url = "http://www.sciencedirect.com/science/article/pii/S0034425717301608",
author = "Shuaiyi Shi and Tianhai Cheng and Xingfa Gu and Hao Chen and Hong Guo and Ying Wang and Fangwen Bao and Binren Xu and Wannan Wang and Xin Zuo and Can Meng and Xiaochuan Zhang",
keywords = "AATSR",
keywords = "AOD",
keywords = "BRDF",
keywords = "Individual swath retrieval",
keywords = "Gradient optimization method",
keywords = "Remote sensing ",
abstract = "Abstract This paper presents a new algorithm to simultaneously retrieve Aerosol Optical Depth (AOD) and land surface Bidirectional Reflectance Distribution Function (BRDF) from Advanced Along-Track Scanning Radiometer (AATSR) by adopting gradient optimization method. Different from traditional method the approach presented here can perform simultaneous retrieval from each individual \{AATSR\} swath rather than multiple days. A theoretical sensitivity study proves the proposed method is insensitive to the distortion of initial BRDF. The presented algorithm is tested on \{AATSR\} data around four different Aerosol Robotic Network (AERONET) sites representing various types of land surface. Compared with the four selected \{AERONET\} sites' \{AOD\} and BRDF-derived albedo from AERONET-based Surface Reflectance Validation Network (ASRVN) data in corresponding four \{AERONET\} sites, the presented algorithm proves considerable accuracy for various type of land surface with correlation of \{AOD\} ranging from 0.647 to 0.911 and correlation of BRDF-derived albedo ranging from 0.483 to 0.944. The intersensor comparison with Moderate Resolution Imaging Spectroradiometer (MODIS) 3 km \{AOD\} dark target product reveals high coverage rate of the presented method especially in bright surface or nonvegetation area and the correlation between the two sensors reaches up to 0.967. The improved estimation of \{BRDF\} from \{AATSR\} retrieval in \{AERONET\} Beijing site is compared with \{MODIS\} \{MCD43B1\} product. The relative differences in hemispherical albedo calculated from average \{BRDF\} shape function parameters between \{AATSR\} and \{MODIS\} product are 1.33%, 1.52%, 2.60% and 4.28% at 550 nm, 670 nm, 870 nm and 1600 nm respectively. "
}
@article{Medvidovic2010885,
title = "Software architecture and mobility: A roadmap ",
journal = "Journal of Systems and Software ",
volume = "83",
number = "6",
pages = "885 - 898",
year = "2010",
note = "Software Architecture and Mobility ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2009.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0164121209002854",
author = "Nenad Medvidovic and George Edwards",
keywords = "Software architecture",
keywords = "Mobility ",
abstract = "Modern software-intensive systems are characterized not only by the movement of data, as has been the case in traditional distributed systems, but also by the movement of users, devices, and code. Developing effective, efficient, and dependable systems in the mobile setting is challenging. Existing architectural principles need to be adapted and novel architectural paradigms devised. In this paper, we give an overview of the intersection of the areas of software architecture and mobility. We consider mobility from two related perspectives: (1) mobile software, which represents the computing functionality designed to migrate across hardware devices at runtime and execute on mobile hardware platforms, and (2) mobile systems, which are computing applications that include mobile software and hardware elements. We study the advances in both these areas, highlight representative existing solutions, and identify several remaining research challenges. "
}
@article{Puente20132127,
title = "Review of mobile mapping and surveying technologies ",
journal = "Measurement ",
volume = "46",
number = "7",
pages = "2127 - 2145",
year = "2013",
note = "",
issn = "0263-2241",
doi = "https://doi.org/10.1016/j.measurement.2013.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0263224113000730",
author = "I. Puente and H. González-Jorge and J. Martínez-Sánchez and P. Arias",
keywords = "Mobile mapping",
keywords = "Photogrammetry",
keywords = "Surveying",
keywords = "Laser scanning",
keywords = "LiDAR ",
abstract = "Abstract Mobile surveying is currently one of the most popular topics in the LiDAR industry. The collection of highly precise point cloud data is provided by laser scanning systems on moving platforms with an integrated navigation solution. The potential of LiDAR based mobile surveying technology is now well proven. This article introduces an analysis on the current performance of some outstanding mobile terrestrial laser scanning systems. In this work, an overview of the positioning, scanning and imaging devices integrated into these systems is also presented. As part of this study, a systematic comparison of the navigation and LiDAR specifications provided by the manufacturers is provided. Our review suggests that mobile laser scanning systems can mainly be divided into two categories (mapping and surveying) depending on their final purpose, accuracy, range and resolution requirements. A refined integrated analysis based on hardware components could be expected to cause further improvements on these results. "
}
@article{Alsadik2013515,
title = "Automated camera network design for 3D modeling of cultural heritage objects ",
journal = "Journal of Cultural Heritage ",
volume = "14",
number = "6",
pages = "515 - 526",
year = "2013",
note = "",
issn = "1296-2074",
doi = "https://doi.org/10.1016/j.culher.2012.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S1296207412001872",
author = "Bashar Alsadik and Markus Gerke and George Vosselman",
keywords = "3D models",
keywords = "SFM",
keywords = "Synthetic image",
keywords = "SIFT",
keywords = "Optimization",
keywords = "Image orientation",
keywords = "Camera calibration ",
abstract = "Image-based modeling is an appropriate technique to create 3D models of cultural heritage objects, which starts with the basic task of designing the camera network. This task is, however, quite crucial in practical applications because it needs a thorough planning and a certain level of experience. The optimal camera network is designed when certain accuracy demands are fulfilled with a reasonable effort, namely keeping the number of camera shots at a minimum. In this study, we report on the development of an automated method for designing the optimal camera network for a given cultural heritage building or statue. Starting from a rough point cloud derived from a video image stream, the initial configuration of the camera network is designed, assuming a high-resolution \{HR\} state-of-the-art non-metric camera. To improve the image coverage and accuracy, we use a mathematical non-linear optimization with constraints. Furthermore, synthetic images are created to guide the camera operator to the designed images. From the first experimental test, we found that a target accuracy of 10 mm could be maintained although the initial number of more than 300 high-resolution images got reduced to less than 90 for the final, optimized network. "
}
@article{Balakhontceva20162455,
title = "Multi-agent Simulation of Passenger Evacuation from a Damaged Ship under Storm Conditions ",
journal = "Procedia Computer Science ",
volume = "80",
number = "",
pages = "2455 - 2464",
year = "2016",
note = "International Conference on Computational Science 2016, \{ICCS\} 2016, 6-8 June 2016, San Diego, California, \{USA\} ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.05.547",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916310389",
author = "Marina Balakhontceva and Vladislav Karbovskii and Serge Sutulo and Alexander Boukhanovsky",
keywords = "evacuation processes",
keywords = "multi-agent simulation",
keywords = "ship motions",
keywords = "crowd dynamic models ",
abstract = "Abstract We present a multi-agent model for the simulation of evacuation processes considering ship motions and a method for modeling crowd dynamics. To take into account all aspects of the specifics of evacuation in storm conditions, an information model has been developed. This model is based on three interrelated processes: sea waves dynamics, ship motions under the influence of sea, crowd dynamics affected by ship motions. In our research, we developed a combined method for simulating agents’ movements on the inclined decks of the ship. Our approach combines the well-known implementation of the Social Force model with the possibility of collisions with obstacles. Depending on the specific requirements, it is possible to use various models for ship dynamics in irregular seas. To better support this versatility, a distributed test bench based on the \{CLAVIRE\} cloud platform was developed for simulation of passenger evacuation and testing simulations were carried out. The obtained results demonstrate that the developed simulation system could be used for designing contingency plans to assist crew members in the framework of decision support systems (DSS). "
}
@article{Kim2003871,
title = "Minimum distance between a canal surface and a simple surface ",
journal = "Computer-Aided Design ",
volume = "35",
number = "10",
pages = "871 - 879",
year = "2003",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(02)00123-9",
url = "http://www.sciencedirect.com/science/article/pii/S0010448502001239",
author = "Ku-Jin Kim",
keywords = "Minimum distance",
keywords = "Canal surface",
keywords = "Simple surface",
keywords = "Collision detection",
keywords = "Haptic rendering ",
abstract = "The computation of the minimum distance between two objects is an important problem in the applications such as haptic rendering, CAD/CAM, \{NC\} verification, robotics and computer graphics. This paper presents a method to compute the minimum distance between a canal surface and a simple surface (i.e. a plane, a natural quadric, or a torus) by finding roots of a function of a single parameter. We utilize the fact that the normals at the closest points between two surfaces are collinear. Given the spine curve C(t), tmin≤t≤tmax, and the radius function r(t) for a canal surface, a point on the spine curve C(t∗) uniquely determines a characteristic circle K(t∗) on the surface. Normals to the canal surface at points on K(t∗) form a cone with a vertex C(t∗) and an axis which is parallel to C′(t∗). Then we construct a function of t which expresses the condition that the perpendicular from C(t) to a given simple surface is embedded in the cone of normals to the canal surface at points on K(t). By solving this equation, we find characteristic circles which contain the points of locally minimum distance from the simple surface. Based on these circles, we can compute the minimum distance between given surfaces. "
}
@article{Pellegrinelli2015159,
title = "Design and Inspection of Multi-fixturing Pallets for Mixed Part Types ",
journal = "Procedia \{CIRP\} ",
volume = "36",
number = "",
pages = "159 - 164",
year = "2015",
note = "\{CIRP\} 25th Design Conference Innovative Product Creation ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115000098",
author = "Stefania Pellegrinelli and Claudio Cenati and Luca Cevasco and Franca Giannini and Katia Lupinetti and Marina Monti and Diego Parazzoli",
keywords = "Process planning",
keywords = "Multi-fixturing pallet",
keywords = "Pallet inspection ",
abstract = "Abstract Over the last decades, manufacturing market has been characterized by small batch size, high variability in the part types and part type demand, continuous evolution of the products. In order to quickly answer the new and changing production requirements, the rapid redesign of the pallet in terms of number of parts and part types and the verification of physical mounted pallet became essential. Thus, this paper aims at (i) developing a dynamic process planning approach automatically providing multi-part pallet designs and (ii) identifying flexible techniques for the inspection of the physical pallet before its machining. Specifically, the approach analyzes the solution space generated by all the possible combination of part type setups in terms of number and position on the pallet. The number of produced part types per pallet is maximized, while the setup accessibility and an equal number of part types for each setup are granted. The 3D design of the pallet is compared with the scanned pallet cloud of points in order to identify possible error sources, e.g. part missing, incorrectly closed fixture, part type in wrong position. A test case will be provided in order to show the advantages deriving from the approach employment. "
}
@article{Sayer2012177,
title = "Use of MODIS-derived surface reflectance data in the ORAC-AATSR aerosol retrieval algorithm: Impact of differences between sensor spectral response functions ",
journal = "Remote Sensing of Environment ",
volume = "116",
number = "",
pages = "177 - 188",
year = "2012",
note = "Advanced Along Track Scanning Radiometer(AATSR) Special Issue ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2011.02.029",
url = "http://www.sciencedirect.com/science/article/pii/S0034425711002203",
author = "Andrew M. Sayer and Gareth E. Thomas and Roy G. Grainger and Elisa Carboni and Caroline Poulsen and Richard Siddans",
keywords = "Aerosol",
keywords = "AATSR",
keywords = "BRDF",
keywords = "MODIS",
keywords = "Optimal estimation",
keywords = "ORAC",
keywords = "Retrieval",
keywords = "Surface albedo ",
abstract = "The aerosol component of the Oxford-Rutherford Appleton Laboratory (RAL) Aerosol and Clouds (ORAC) retrieval scheme for the Advanced Along-Track Scanning Radiometer (AATSR) uses data derived from the Moderate Resolution Imaging Spectroradiometer (MODIS) to constrain the brightness of the surface. However, the spectral response functions of the channels used (centred near 550 nm, 660 nm, 870 nm, and 1.6 μm) do not exactly match between the two sensors. It is shown that failure to account for differences between the instruments' spectral response functions leads to errors of typically 0.001–0.01 in spectral surface albedo, and distinct biases, dependent on wavelength and surface type. A technique based on singular value decomposition (SVD) is used to reduce these random errors by an average of 35% at 670 nm and over 60% at the other wavelengths used. The technique reduces the biases so that they are negligible. In principle, the method can be extended to any combination of sensors. The SVD-based scheme is applied to \{AATSR\} data from the month of July 2008 and found to increase the number of successful aerosol retrievals, the speed of retrieval convergence, and improve the level of consistency between the measurements and the retrieved state. Additionally, retrieved aerosol optical depth at 550 nm shows an improvement in correspondence when compared to Aerosol Robotic Network (AERONET) data. "
}
@article{Mišković2015125,
title = "\{CADDY\} Project, Year 1: Overview of Technological Developments and Cooperative Behaviours★ ",
journal = "IFAC-PapersOnLine ",
volume = "48",
number = "2",
pages = "125 - 130",
year = "2015",
note = "4th \{IFAC\} Workshop onNavigation, Guidance and Controlof Underwater VehiclesNGCUV 2015Dedicated to the memory of Professor Geoff Roberts ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2015.06.020",
url = "http://www.sciencedirect.com/science/article/pii/S2405896315002591",
author = "Nikola Mišković and Antonio Pascoal and Marco Bibuli and Massimo Caccia and Jeffrey A. Neasham and Andreas Birk and Murat Egi and Karl Grammer and Alessandro Marroni and Antonio Vasilijević and Zoran Vukić",
keywords = "Marine systems",
keywords = "Cognitive systems",
keywords = "Autonomous mobile robots",
keywords = "Man/machine interaction ",
abstract = "Abstract”CADDY - Cognitive Autonomous Diving Buddy” is an \{FP7\} project that started in January 2014. Seven partner institutions have joined their efforts towards developing a cognitive underwater robotic system that will help divers during their activities in this hazardous environment. The resulting system will play a threefold role similar to those that a human buddy diver should have: buddy ’’observer”, buddy ”slave”, and buddy ”guide”. This paper gives an outline of the \{CADDY\} project results during the first year of execution. We focus only on the technical developments and cooperative behaviours that have taken place, in order to keep the overview concise and in line with the workshop topics. Special attention is given to the fleet of new and adapted autonomous marine vehicles used in the project, as well as technologies for perceiving the diver. In addition to that, we give a short overview of cooperative robotic behaviours and present initial results with autonomous surface marine vehicles tracking divers. "
}
@article{Pire201727,
title = "S-PTAM: Stereo Parallel Tracking and Mapping ",
journal = "Robotics and Autonomous Systems ",
volume = "93",
number = "",
pages = "27 - 42",
year = "2017",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2017.03.019",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015302955",
author = "Taihú Pire and Thomas Fischer and Gastón Castro and Pablo De Cristóforis and Javier Civera and Julio Jacobo Berlles",
keywords = "SLAM",
keywords = "Visual SLAM",
keywords = "Stereo SLAM",
keywords = "Stereo vision",
keywords = "Loop closure ",
abstract = "Abstract This paper describes a real-time feature-based stereo \{SLAM\} system that is robust and accurate in a wide variety of conditions – indoors, outdoors, with dynamic objects, changing light conditions, fast robot motions and large-scale loops. Our system follows a parallel-tracking-and-mapping strategy: a tracking thread estimates the camera pose at frame rate; and a mapping thread updates a keyframe-based map at a lower frequency. The stereo constraints of our system allow a robust initialization – avoiding the well-known bootstrapping problem in monocular systems–and the recovery of the real scale. Both aspects are essential for its practical use in real robotic systems that interact with the physical world. In this paper we provide the implementation details, an exhaustive evaluation of the system in public datasets and a comparison of most state-of-the-art feature detectors and descriptors on the presented system. For the benefit of the community, its code for \{ROS\} (Robot Operating System) has been released. "
}
@article{Phung201111514,
title = "Get Out of the Way – Obstacle Avoidance and Learning by Demonstration for Manipulation ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "44",
number = "1",
pages = "11514 - 11519",
year = "2011",
note = "18th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20110828-6-IT-1002.01363",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016454650",
author = "A.S. Phung and J. Malzahn and F. Hoffmann and T. Bertram",
keywords = "Robots manipulators",
keywords = "perception and sensing",
keywords = "obstacle avoidance",
keywords = "movement primitives",
keywords = "image processing ",
abstract = "Abstract Humans acquire manipulation skills by trial and error within a few trials, whereas programming a robot to perform the same task requires robotic expertise and effort. This paper presents a robot which learns a movement from demonstrations with the ability to generalize the movement to new goal poses and avoid the collision with obstacles in the workspace. The general movement is represented by dynamic movement primitives (DMP) augmented by potential fields in order to modulate the motion in the presence of obstacles. The approach is validated in experiments with a robotic arm in which dynamic obstacles partially blocking the movement are detected by a Photonic-Mixer-Devices (PMD) camera. "
}
@article{Nabavi2017115,
title = "Sensitivity of WRF-chem predictions to dust source function specification in West Asia ",
journal = "Aeolian Research ",
volume = "24",
number = "",
pages = "115 - 131",
year = "2017",
note = "",
issn = "1875-9637",
doi = "https://doi.org/10.1016/j.aeolia.2016.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S1875963716301240",
author = "Seyed Omid Nabavi and Leopold Haimberger and Cyrus Samimi",
keywords = "WRF-chem",
keywords = "Source function",
keywords = "Dust storms",
keywords = "West Asia ",
abstract = "Abstract Dust storms tend to form in sparsely populated areas covered by only few observations. Dust source maps, known as source functions, are used in dust models to allocate a certain potential of dust release to each place. Recent research showed that the well known Ginoux source function (GSF), currently used in Weather Research and Forecasting Model coupled with Chemistry (WRF-chem), exhibits large errors over some regions in West Asia, particularly near the IRAQ/Syrian border. This study aims to improve the specification of this critical part of dust forecasts. A new source function based on multi-year analysis of satellite observations, called West Asia source function (WASF), is therefore proposed to raise the quality of WRF-chem predictions in the region. \{WASF\} has been implemented in three dust schemes of WRF-chem. Remotely sensed and ground-based observations have been used to verify the horizontal and vertical extent and location of simulated dust clouds. Results indicate that WRF-chem performance is significantly improved in many areas after the implementation of WASF. The modified runs (long term simulations over the summers 2008–2012, using nudging) have yielded an average increase of Spearman correlation between observed and forecast aerosol optical thickness by 12–16 percent points compared to control runs with standard source functions. They even outperform \{MACC\} and \{DREAM\} dust simulations over many dust source regions. However, the quality of the forecasts decreased with distance from sources, probably due to deficiencies in the transport and deposition characteristics of the forecast model in these areas. "
}
@article{Zhong20147855,
title = "Dynamic Lines of Collaboration in \{CPS\} Disruption Response ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "7855 - 7860",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02403",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016428508",
author = "Hao Zhong and Shimon Y. Nof and Florin G. Filip",
keywords = "Collaborative control",
keywords = "Incidence management",
keywords = "Multi-agent system",
keywords = "Sensor network ",
abstract = "Abstract Cyber-physical systems (CPSs) are emerging future engineered systems with combined efforts in cybernetics and advanced physical components. They are often designed for large and mission-critical systems, e.g., smart grids. The continuous availability of functionality is one of the important concerns by \{CPS\} stakeholders. Currently \{CPSs\} are still vulnerable to major disruptions. In this research we design the Dynamic Lines for Collaboration (DLOC) protocol for responding to disruptions in CPS. \{DLOC\} utilizes current advantages in a centralized computing model, HUB-CI (high performance computing \{HUB\} with collaborative intelligence tools), and facility sensor networks deployed in physical and cyber domains with active middleware. Based on the hybrid centralized/distributed \{CPS\} structure, \{DLOC\} is hypothesized to be a better protocol for \{CPS\} disruption response than conventional centralized protocols. Experiments with an agent-based model are performed to test the \{DLOC\} effectiveness. The results indicate that by using \{DLOC\} protocol, \{CPS\} can have 12% lower emergency responder workload, 80% reduced subsystem downtime, 82% shorter disruption response time, and 30% increased link availability compared with the conventional centralized protocol. The performance advantages of \{DLOC\} over the common centralized methods demonstrate that a high performance computing center approach to disruption response is not sufficient. \{DLOC\} can also have a relatively higher information triage efficiency and increased robustness to network dynamics and information overload. "
}
@article{Lau20131116,
title = "Efficient grid-based spatial representations for robot navigation in dynamic environments ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "10",
pages = "1116 - 1130",
year = "2013",
note = "Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011) ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S092188901200142X",
author = "Boris Lau and Christoph Sprunk and Wolfram Burgard",
keywords = "Incremental algorithms",
keywords = "Voronoi diagrams",
keywords = "Distance maps",
keywords = "Configuration space",
keywords = "Collision checking",
keywords = "Robot navigation ",
abstract = "In robotics, grid maps are often used for solving tasks like collision checking, path planning, and localization. Many approaches to these problems use Euclidean distance maps (DMs), generalized Voronoi diagrams (GVDs), or configuration space (c-space) maps. A key challenge for their application in dynamic environments is the efficient update after potential changes due to moving obstacles or when mapping a previously unknown area. To this end, this paper presents novel algorithms that perform incremental updates that only visit cells affected by changes. Furthermore, we propose incremental update algorithms for \{DMs\} and \{GVDs\} in the configuration space of non-circular robots. These approaches can be used to implement highly efficient collision checking and holonomic path planning for these platforms. Our c-space representations benefit from parallelization on multi-core \{CPUs\} and can also be integrated with other state-of-the-art path planners such as rapidly-exploring random trees. In various experiments using real-world data we show that our update strategies for \{DMs\} and \{GVDs\} require substantially less cell visits and computation time compared to previous approaches. Furthermore, we demonstrate that our \{GVD\} algorithm deals better with non-convex structures, such as indoor areas. All our algorithms consider actual Euclidean distances rather than grid steps and are easy to implement. An open source implementation is available online. "
}
@article{Zhang2014143,
title = "A hybrid approach to self-management in a pervasive service middleware ",
journal = "Knowledge-Based Systems ",
volume = "67",
number = "",
pages = "143 - 161",
year = "2014",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2014.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0950705114002202",
author = "Weishan Zhang and Klaus Marius Hansen and Mads Ingstrup",
keywords = "Self-management",
keywords = "Architectural styles",
keywords = "Component control",
keywords = "Goal Management",
keywords = "Change Management ",
abstract = "Abstract Self-management capabilities for pervasive computing systems are critical in improving dependability, usability, and autonomicity. However, realizing self-management is not an easy task due to complexities of implementing autonomous behaviors. It has been recognized that a single autonomicity handling mechanism is not sufficient to realize comprehensive self-management capabilities when different technologies are involved. Therefore, we propose a hybrid approach, the ‘LinkSmart Three Layered architectural (LinkSmart-3L) style’, in which different architecture styles are incorporated. The LinkSmart-3L style enables self-management at an architectural level. In our approach, semantic web technologies are used to achieve comprehensive context-awareness and extensibility of self-management capabilities, genetic algorithms are used to achieve configuration optimizations, and a planner is used to compute planning procedures on how to arrive at an optimum system configuration based on current architectural structure of the underlying system using an architectural query language. These technologies are integrated seamlessly based on the service oriented computing (SoC) paradigm. We have extensively evaluated both runtime and development time qualities of our implementation of the style. These evaluations can serve as guidelines for evaluating other middleware systems. We conclude that our approach is usable and effective in achieving these quality attributes. "
}
@article{Serhani2016137,
title = "SME2EM: Smart mobile end-to-end monitoring architecture for life-long diseases ",
journal = "Computers in Biology and Medicine ",
volume = "68",
number = "",
pages = "137 - 154",
year = "2016",
note = "",
issn = "0010-4825",
doi = "https://doi.org/10.1016/j.compbiomed.2015.11.009",
url = "http://www.sciencedirect.com/science/article/pii/S0010482515003777",
author = "Mohamed Adel Serhani and Mohamed El Menshawy and Abdelghani Benharref",
keywords = "Model checking",
keywords = "Smart mobile monitoring",
keywords = "Data as a service",
keywords = "Visualization as a service",
keywords = "SOA ",
abstract = "Abstract Monitoring life-long diseases requires continuous measurements and recording of physical vital signs. Most of these diseases are manifested through unexpected and non-uniform occurrences and behaviors. It is impractical to keep patients in hospitals, health-care institutions, or even at home for long periods of time. Monitoring solutions based on smartphones combined with mobile sensors and wireless communication technologies are a potential candidate to support complete mobility-freedom, not only for patients, but also for physicians. However, existing monitoring architectures based on smartphones and modern communication technologies are not suitable to address some challenging issues, such as intensive and big data, resource constraints, data integration, and context awareness in an integrated framework. This manuscript provides a novel mobile-based end-to-end architecture for live monitoring and visualization of life-long diseases. The proposed architecture provides smartness features to cope with continuous monitoring, data explosion, dynamic adaptation, unlimited mobility, and constrained devices resources. The integration of the architecture׳s components provides information about diseases׳ recurrences as soon as they occur to expedite taking necessary actions, and thus prevent severe consequences. Our architecture system is formally model-checked to automatically verify its correctness against designers׳ desirable properties at design time. Its components are fully implemented as Web services with respect to the \{SOA\} architecture to be easy to deploy and integrate, and supported by Cloud infrastructure and services to allow high scalability, availability of processes and data being stored and exchanged. The architecture׳s applicability is evaluated through concrete experimental scenarios on monitoring and visualizing states of epileptic diseases. The obtained theoretical and experimental results are very promising and efficiently satisfy the proposed architecture׳s objectives, including resource awareness, smart data integration and visualization, cost reduction, and performance guarantee. "
}
@article{Paritala2017982,
title = "Digital Manufacturing- Applications Past, Current, and Future Trends ",
journal = "Procedia Engineering ",
volume = "174",
number = "",
pages = "982 - 991",
year = "2017",
note = "13th Global Congress on Manufacturing and Management Zhengzhou, China 28-30 November, 2016 ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2017.01.250",
url = "http://www.sciencedirect.com/science/article/pii/S1877705817302503",
author = "Phani Kumari Paritala and Shalini Manchikatla and Prasad K.D.V. Yarlagadda",
keywords = "Digital manufacturing",
keywords = "Additive manufacturing",
keywords = "Digital transformation",
keywords = "3D Printing ",
abstract = "Abstract Increasingly the convergence of natural environment (land, water, air and life), built environment (housing, buildings, transportation and infrastructure) and digital environment (computing power, the internet, big data, and technology) is shaping the economies and societies. Smart living is taking root. Mass customization of products and services is preferred over mass production. Businesses wish to serve an individual customer at a competitive cost comparable to the mass production cost, with shortest possible development time and production time. This requires manufacturing to change from a more labour intensive processes to information technology enabled mechanical processes. Digital manufacturing is a broader concept of manufacturing innovation in which the digital and material advancements enable the company to conceive products in a desired style and quantity in time scales shorter than the conventional methods while efficiently managing the entire product lifecycle. It is about defining manufacturing processes and managing manufacturing process information via full digital product definition. It encompasses visualization, manufacturing simulation, ergonomic and human factor analyses, holistic view of product and process design, and product design sensitive to the process constraints and capabilities. This article emphasizes the need and driving forces for adopting digital manufacturing, transformation of manufacturing to smart manufacturing, present applications and future scope of digital manufacturing. "
}
@article{Zlot2014670,
title = "Efficiently capturing large, complex cultural heritage sites with a handheld mobile 3D laser mapping system ",
journal = "Journal of Cultural Heritage ",
volume = "15",
number = "6",
pages = "670 - 678",
year = "2014",
note = "",
issn = "1296-2074",
doi = "https://doi.org/10.1016/j.culher.2013.11.009",
url = "http://www.sciencedirect.com/science/article/pii/S1296207413002185",
author = "Robert Zlot and Michael Bosse and Kelly Greenop and Zbigniew Jarzab and Emily Juckes and Jonathan Roberts",
keywords = "3D digitisation",
keywords = "Laser scanning",
keywords = "Mobile mapping",
keywords = "Heritage sites",
keywords = "Documentation",
keywords = "Large-scale scenes",
keywords = "Peel Island ",
abstract = "Abstract Accurate three-dimensional representations of cultural heritage sites are highly valuable for scientific study, conservation, and educational purposes. In addition to their use for archival purposes, 3D models enable efficient and precise measurement of relevant natural and architectural features. Many cultural heritage sites are large and complex, consisting of multiple structures spatially distributed over tens of thousands of square metres. The process of effectively digitising such geometrically complex locations requires measurements to be acquired from a variety of viewpoints. While several technologies exist for capturing the 3D structure of objects and environments, none are ideally suited to complex, large-scale sites, mainly due to their limited coverage or acquisition efficiency. We explore the use of a recently developed handheld mobile mapping system called Zebedee in cultural heritage applications. The Zebedee system is capable of efficiently mapping an environment in three dimensions by continually acquiring data as an operator holding the device traverses through the site. The system was deployed at the former Peel Island Lazaret, a culturally significant site in Queensland, Australia, consisting of dozens of buildings of various sizes spread across an area of approximately 400 × 250 m. With the Zebedee system, the site was scanned in half a day, and a detailed 3D point cloud model (with over 520 million points) was generated from the 3.6 hours of acquired data in 2.6 hours. We present results demonstrating that Zebedee was able to accurately capture both site context and building detail comparable in accuracy to manual measurement techniques, and at a greatly increased level of efficiency and scope. The scan allowed us to record derelict buildings that previously could not be measured because of the scale and complexity of the site. The resulting 3D model captures both interior and exterior features of buildings, including structure, materials, and the contents of rooms. "
}
@article{Bonci2016249,
title = "A database-centric approach for the modeling, simulation and control of cyber-physical systems in the factory of the future. ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "12",
pages = "249 - 254",
year = "2016",
note = "8th \{IFAC\} Conference on Manufacturing Modelling, Management and Control \{MIM\} 2016Troyes, France, 28—30 June 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.608",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316308722",
author = "Andrea Bonci and Massimiliano Pirani and Sauro Longhi",
keywords = "Computational methods",
keywords = "Database management systems",
keywords = "Distributed computer control systems",
keywords = "Embedded systems",
keywords = "Industry automation",
keywords = "Intelligent manufacturing systems",
keywords = "Simulators ",
abstract = "Abstract The path towards Industrie 4.0, requires that factory automation problems cope with the cyber-physical system complexity and its challenges. Some practical experiences and literature in the field testify that the role of the database management systems is becoming central for control and automation technology in the new industrial scenario. This article proposes database-centric technology and architectures that seamlessly integrate networking, artificial intelligence and real-time control issues into a unified model of computing. The proposed methodology is also viable for the development of simulation and rapid prototyping tools for smart and advanced industrial automation. "
}
@article{Corsi2007192,
title = "Smart Sensors ",
journal = "Infrared Physics & Technology ",
volume = "49",
number = "3",
pages = "192 - 197",
year = "2007",
note = "Workshop on Advanced Infrared Technology and Applications ",
issn = "1350-4495",
doi = "https://doi.org/10.1016/j.infrared.2006.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S1350449506000739",
author = "C. Corsi",
keywords = "Smart",
keywords = "Infrared",
keywords = "Sensors",
keywords = "Fly-eye",
keywords = "Surveillance",
keywords = "Staring systems",
keywords = "Warning",
keywords = "Collision avoidance ",
abstract = "The term “Smart Sensors” refers to sensors which contain both sensing and signal processing capabilities with objectives ranging from simple viewing to sophisticated remote sensing, surveillance, search/track, weapon guidance, robotics, perceptronics and intelligence applications. Recently this approach is achieving higher goals by a new and revolutionary sensors concept which introduced inside the sensor some of the basic functions of living eyes, such as dynamic stare, non-uniformity compensation, spatial and temporal filtering. New objectives and requirements are presented for this type of new infrared smart sensor systems. This paper is concerned with the front end of \{FPA\} microbolometers processing, namely, the enhancement of target-to-noise ratio by background clutter suppression and the improvement in target detection by “smart” and pattern correlation thresholding. "
}
@article{Potthast2014148,
title = "A probabilistic framework for next best view estimation in a cluttered environment ",
journal = "Journal of Visual Communication and Image Representation ",
volume = "25",
number = "1",
pages = "148 - 164",
year = "2014",
note = "Visual Understanding and Applications with RGB-D Cameras ",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2013.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S1047320313001387",
author = "Christian Potthast and Gaurav S. Sukhatme",
keywords = "Next best view estimation",
keywords = "Sensor placement",
keywords = "Sensor planning",
keywords = "View planning",
keywords = "Robot exploration",
keywords = "3-D perception",
keywords = "Cluttered environments",
keywords = "Missing points ",
abstract = "Abstract In this article, we present an information gain-based variant of the next best view problem for occluded environment. Our proposed method utilizes a belief model of the unobserved space to estimate the expected information gain of each possible viewpoint. More precise, this belief model allows a more precise estimation of the visibility of occluded space and with that a more accurate prediction of the potential information gain of new viewing positions. We present experimental evaluation on a robotic platform for active data acquisition, however due to the generality of our approach it also applies to a wide variety of 3D reconstruction problems. With the evaluation done in simulation and on a real robotic platform, exploring and acquiring data from different environments we demonstrate the generality and usefulness of our approach for next best view estimation and autonomous data acquisition. "
}
@article{Proestakis201666,
title = "Lightning activity and aerosols in the Mediterranean region ",
journal = "Atmospheric Research ",
volume = "170",
number = "",
pages = "66 - 75",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.11.010",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515003798",
author = "E. Proestakis and S. Kazadzis and K. Lagouvardos and V. Kotroni and A. Kazantzidis",
keywords = "Lightning",
keywords = "Aerosol atmospheric optical depth",
keywords = "Mediterranean Sea",
keywords = "ZEUS lightning detection network",
keywords = "MODIS ",
abstract = "Abstract In the framework of this study, the effect of aerosols on lightning activity has been investigated for the first time over the broader Mediterranean Sea. Atmospheric optical depth data retrieved by \{MODIS\} on board Aqua satellite and cloud to ground lightning activity data provided by \{ZEUS\} network operated by the National Observatory of Athens were analyzed for a time period spanning from 01/01/2005 up to 31/12/2013. The results indicate the importance of aerosols in lightning modulation. The mean aerosol optical depth (AOD) values of the days with lightning activity were found to be higher than the mean seasonal \{AOD\} in 90% of the under study domain. Furthermore, the increasing rate of lightning activity with increasing aerosol loading was found to be more pronounced during summertime and for \{AOD\} values up to 0.4. Additionally, the spatial analysis showed that the percentage of days with lightning activity during summertime is increasing with increasing AOD. Finally, time series showed similar temporal behavior between \{AOD\} seasonal anomalies and days with lightning activity differences. Both the spatial and temporal analysis showed that lightning activity is correlated to AOD, a characteristic consistent for all seasons. "
}
@article{Li201514,
title = "A method for estimating hourly photosynthetically active radiation (PAR) in China by combining geostationary and polar-orbiting satellite data ",
journal = "Remote Sensing of Environment ",
volume = "165",
number = "",
pages = "14 - 26",
year = "2015",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.03.034",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715001467",
author = "Li Li and Xiaozhou Xin and Hailong Zhang and Jiangfeng Yu and Qinhuo Liu and Shanshan Yu and Jianguang Wen",
keywords = "\{PAR\} estimation",
keywords = "MTSAT",
keywords = "MODIS",
keywords = "6SV",
keywords = "SBDART",
keywords = "Look-up table ",
abstract = "Abstract Photosynthetically active radiation (PAR) is an important parameter in ecosystem and land surface models. \{PAR\} represents the amount of solar radiation in the spectral range of 400–700 nm that travels through the atmosphere to the top of the vegetation canopy. In recent years, various methods using different input data to estimate \{PAR\} and produce different \{PAR\} products have been developed. However, most of the algorithms used in these state-of-the-art studies have not fully compensated for the low spatial and temporal resolution of the data, which affects the accuracy of the \{PAR\} estimates. In this study, we have developed a method for estimating hourly \{PAR\} based on a combination of geostationary and polar-orbiting satellite data. The Multifunctional Transport Satellite (MTSAT) was selected to retrieve cloud optical depth (COD) with a higher spatial resolution, and the polar orbit satellite data of the Moderate Resolution Imaging Spectroradiometer (MODIS) products were used to derive surface parameters based on multispectral characteristics. A look-up table was established by the Second Simulation of a Satellite Signal in the Solar Spectrum-Vector (6SV) model and the Santa Barbara \{DISORT\} Atmospheric Radiative Transfer (SBDART) model consisting the following parameters: solar zenith angle, total water vapor, total ozone column, aerosol optical depth (AOD), COD, surface elevation, surface albedo and PAR. The instantaneous \{PAR\} was linearly interpolated from the input data for the selected parameters and the look-up table. The root mean square error (RMSE) between the estimated and observed instantaneous \{PAR\} at the Huailai station was 45.72 W/m2 for all sky conditions. The \{RMSE\} between the estimated and observed daily \{PAR\} at the meteorological stations was 17% in the eastern regions of China. The mean bias error (MBE) was between − 2.83 and 32.43 W/m2 for the Tibetan Plateau. These results indicated that the proposed method can significantly improve the accuracy of \{PAR\} estimates and can be used to produce \{PAR\} products with high spatial and temporal resolution. However, the method requires further improvement, especially with respect to cloudy conditions. "
}
@article{Campbell201540,
title = "Metric-based detection of robot kidnapping with an \{SVM\} classifier ",
journal = "Robotics and Autonomous Systems ",
volume = "69",
number = "",
pages = "40 - 51",
year = "2015",
note = "Selected papers from 6th European Conference on Mobile Robots ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001626",
author = "Dylan Campbell and Mark Whitty",
keywords = "Mobile robots",
keywords = "Failure detection",
keywords = "Robot programming",
keywords = "Support Vector Machine ",
abstract = "Abstract Kidnapping occurs when a robot is unaware that it has not correctly ascertained its position, potentially causing severe map deformation and reducing the robot’s functionality. This paper presents metric-based techniques for real-time kidnap detection, utilising either linear or \{SVM\} classifiers to identify all kidnapping events during the autonomous operation of a mobile robot. In contrast, existing techniques either solve specific cases of kidnapping, such as elevator motion, without addressing the general case or remove dependence on local pose estimation entirely, an inefficient and computationally expensive approach. Three metrics that measured the quality of a pose estimate were evaluated and a joint classifier was constructed by combining the most discriminative quality metric with a fourth metric that measured the discrepancy between two independent pose estimates. A multi-class Support Vector Machine classifier was also trained using all four metrics and produced better classification results than the simpler joint classifier, at the cost of requiring a larger training dataset. While metrics specific to 3D point clouds were used, the approach can be generalised to other forms of data, including visual, provided that two independent ways of estimating pose are available. "
}
@article{Gemignani20161,
title = "Living with robots: Interactive environmental knowledge acquisition ",
journal = "Robotics and Autonomous Systems ",
volume = "78",
number = "",
pages = "1 - 16",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002468",
author = "Guglielmo Gemignani and Roberto Capobianco and Emanuele Bastianelli and Domenico Daniele Bloisi and Luca Iocchi and Daniele Nardi",
keywords = "Semantic mapping",
keywords = "Knowledge representation",
keywords = "Human–robot interaction ",
abstract = "Abstract Robots, in order to properly interact with people and effectively perform the requested tasks, should have a deep and specific knowledge of the environment they live in. Current capabilities of robotic platforms in understanding the surrounding environment and the assigned tasks are limited, despite the recent progress in robotic perception. Moreover, novel improvements in human–robot interaction support the view that robots should be regarded as intelligent agents that can request the help of the user to improve their knowledge and performance. In this paper, we present a novel approach to semantic mapping. Instead of requiring our robots to autonomously learn every possible aspect of the environment, we propose a shift in perspective, allowing non-expert users to shape robot knowledge through human–robot interaction. Thus, we present a fully operational prototype system that is able to incrementally and on-line build a rich and specific representation of the environment. Such a novel representation combines the metric information needed for navigation tasks with the symbolic information that conveys meaning to the elements of the environment and the objects therein. Thanks to such a representation, we are able to exploit multiple \{AI\} techniques to solve spatial referring expressions and support task execution. The proposed approach has been experimentally validated on different kinds of environments, by several users, and on multiple robotic platforms. "
}
@article{Delmerico2013841,
title = "Building facade detection, segmentation, and parameter estimation for mobile robot stereo vision ",
journal = "Image and Vision Computing ",
volume = "31",
number = "11",
pages = "841 - 852",
year = "2013",
note = "",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2013.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0262885613001327",
author = "Jeffrey A. Delmerico and Philip David and Jason J. Corso",
keywords = "Stereo vision",
keywords = "Mobile robot perception",
keywords = "Hierarchical Markov random field",
keywords = "Building facade detection",
keywords = "Model-based stereo vision ",
abstract = "Abstract Building facade detection is an important problem in computer vision, with applications in mobile robotics and semantic scene understanding. In particular, mobile platform localization and guidance in urban environments can be enabled with accurate models of the various building facades in a scene. Toward that end, we present a system for detection, segmentation, and parameter estimation of building facades in stereo imagery. The proposed method incorporates multilevel appearance and disparity features in a binary discriminative model, and generates a set of candidate planes by sampling and clustering points from the image with Random Sample Consensus (RANSAC), using local normal estimates derived from Principal Component Analysis (PCA) to inform the planar models. These two models are incorporated into a two-layer Markov Random Field (MRF): an appearance- and disparity-based discriminative classifier at the mid-level, and a geometric model to segment the building pixels into facades at the high-level. By using object-specific stereo features, our discriminative classifier is able to achieve substantially higher accuracy than standard boosting or modeling with only appearance-based features. Furthermore, the results of our \{MRF\} classification indicate a strong improvement in accuracy for the binary building detection problem and the labeled planar surface models provide a good approximation to the ground truth planes. "
}
@article{Gaidos1999183,
title = "AIMStar: Antimatter initiated microfusion for pre-cursor interstellar missions ",
journal = "Acta Astronautica ",
volume = "44",
number = "2–4",
pages = "183 - 186",
year = "1999",
note = "Missions to the Outer Solar System and Beyond ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(99)00046-6",
url = "http://www.sciencedirect.com/science/article/pii/S0094576599000466",
author = "G. Gaidos and R.A. Lewis and K. Meyer and T. Schmidt and G.A. Smith",
abstract = "We address the challenge of delivering a scientific payload to 10,000 A.U. in 50 years. This mission may be viewed as a pre-cursor to later missions to Alpha Centauri and beyond. We consider a small, aneutronic nuclear fusion engine sparked by clouds of antiprotons, and describe the principle and operation of the engine and mission parameters. "
}
@incollection{Kumar2017413,
title = "14 - Wealth creation by Amazon ",
editor = "Kumar, Rajesh ",
booktitle = "Strategic Financial Management Casebook ",
publisher = "Academic Press",
edition = "",
address = "",
year = "2017",
pages = "413 - 440",
isbn = "978-0-12-805475-8",
doi = "https://doi.org/10.1016/B978-0-12-805475-8.00014-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780128054758000148",
author = "Rajesh Kumar",
keywords = "World wide web",
keywords = "content creators",
keywords = "Amazon Prime",
keywords = "Amazon Web Services",
keywords = "innovation strategy",
keywords = "Amazon Marketplace",
keywords = "stock split",
keywords = "cost of capital",
keywords = "Peter Lynch fair value model ",
abstract = "Abstract Amazon have emerged as the largest Internet-based retailer in the United States. In 2015, Amazon became the fastest company ever to reach $100 billion in annual sales. Amazon have over 40 subsidiaries. Amazon.com entered the World Wide Web in July 1995. Amazon business segment consists of consumers, sellers, developers, enterprises, and content creators. Amazon also provides advertising services and cobranded credit card agreements. Amazon offers platforms through its retail websites for selling dozens of product categories to millions of its consumers. Consumers are served directly through Amazon websites and through the mobile websites and applications. Amazon manufacture and sell electronic devices like Kindle e readers, Fire tablets, Fire TVs, and Echo. Amazon Prime through the annual membership program offers unlimited free shipping on millions of items and access to unlimited instant streaming of thousands of movies and \{TV\} episodes. Amazon created a new business platform that organized and managed the commerce engine, its reviewer database and community, the apps community, and the cloud capability. The Amazon ecosystem is made up of writers, reviewers, publishers, apps developers, and market of commentators, feature writers, and analysts. The pricing strategy of Amazon is to offer lowest prices possible to every product offering and improve operating efficiency. Amazon’s biggest acquisitions included the purchase of Twitch, Zappos, Kiva Systems, Exchange.com, and Quidsi. Amazon had provided aggregate funding of over $1.5 billion to micro, small, and medium business to regions like the United States, the United Kingdom, and Japan through the Amazon Lending program. Amazon’s revenue grew by approximately 10 times in 2015 compared to the revenues in 2006. The revenues increased from $10.711 billion in 2006 to $107.006 billion in 2015. The year-on-year growth rate analysis shows that the growth rate in revenues was highest in 2011 (41%) during the period 2006–2015. The average gross margin, operating margin, and net margin during the 10-year period 2006–2015 was 25%, 2.7%, and 1.7%, respectively. The stock price increased by approximately 420 times during the period 1997–2016. The cumulative weekly returns for Amazon during the 993 weeks were 725.54%. The average book value as percent of market value during the six-year period 2010–2015 was 7.08. Equity Spread for 2015 is estimated as $157.93 million. Value of Amazon per share is estimated as $691.23 according to free cash flow model. Amazon in the year end 2015 had a Z-score of 5.52 indicating that the company is in safe zone. According to Peter Lynch fair value model, the value of Amazon stock is $681.34. "
}
@article{Lalehpour201642,
title = "Post processing for Fused Deposition Modeling Parts with Acetone Vapour Bath ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "31",
pages = "42 - 48",
year = "2016",
note = "12th \{IFAC\} Workshop on Intelligent Manufacturing Systems \{IMS\} 2016Austin, Texas, USA, 5—7 December 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.12.159",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316328300",
author = "Amirali Lalehpour and Ahmad Barari",
keywords = "Additive manufacturing",
keywords = "surface roughness",
keywords = "fused deposition modeling",
keywords = "total least square fitting",
keywords = "acetone vapour smoothing ",
abstract = "Abstract: Additive Manufacturing (AM) has the benefit being capable to create very complex geometries, which could be impossible with traditional methods or fabricated at high cost. However, the manufacturing cost of \{AM\} is not directly related to the parts complexity. From material costs perspective, the cost of \{AM\} parts is mostly related to the size of the product. However, some \{AM\} techniques, such as Fused Deposition Modelling (FDM), suffers from poor surface roughness restricting its application in some areas requiring high surface integrity. Because of this issue, a post processing stage is required to improve the surface roughness of the \{AM\} parts. In this work, an acetone vapor bath smoothing post process is employed to improve the surface roughness of parts manufactured by FDM. The smoothing parameters are the number of smoothing cycles and the cycle duration. Eventually, the total time during which the part is in acetone vapour is found to be the main factor affecting the final surface roughness. The surface of the parts are digitized using a 3D microscope and the extracted point cloud was used to analyze the surface. A total least square plane is fitted to the points and the deviation of points from this plane is used for calculation of the surface roughness. The results of this study suggests the best smoothing parameters to get the best surface roughness for each set of design parameters. The final surface roughness can be predicted by the experimental models developed based on the build orientation and layer thickness. "
}
@article{Pierdicca201667,
title = "Smart maintenance of riverbanks using a standard data layer and Augmented Reality ",
journal = "Computers & Geosciences ",
volume = "95",
number = "",
pages = "67 - 74",
year = "2016",
note = "",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2016.06.018",
url = "http://www.sciencedirect.com/science/article/pii/S0098300416301662",
author = "Roberto Pierdicca and Emanuele Frontoni and Primo Zingaretti and Adriano Mancini and Eva Savina Malinverni and Anna Nora Tassetti and Ernesto Marcheggiani and Andrea Galli",
keywords = "Buffer strips",
keywords = "Augmented Reality",
keywords = "Environmental monitoring",
keywords = "Mobile visualization",
keywords = "GIS ",
abstract = "Abstract Linear buffer strips (BS) along watercourses are commonly adopted to reduce run-off, accumulation of bank-top sediments and the leaking of pesticides into fresh-waters, which strongly increase water pollution. However, the monitoring of their conditions is a difficult task because they are scattered over wide rural areas. This work demonstrates the benefits of using a standard data layer and Augmented Reality (AR) in watershed control and outlines the guideline of a novel approach for the health-check of linear BS. We designed a mobile environmental monitoring system for smart maintenance of riverbanks by embedding the \{AR\} technology within a Geographical Information System (GIS). From the technological point of view, the system's architecture consists of a cloud-based service for data sharing, using a standard data layer, and of a mobile device provided with a \{GPS\} based \{AR\} engine for augmented data visualization. The proposed solution aims to ease the overall inspection process by reducing the time required to run a survey. Indeed, ordinary operational survey conditions are usually performed basing the fieldwork on just classical digitized maps. Our application proposes to enrich inspections by superimposing information on the device screen with the same point of view of the camera, providing an intuitive visualization of buffer strip location. This way, the inspection officer can quickly and dynamically access relevant information overlaying geographic features, comments and other contents in real time. The solution has been tested in fieldwork to prove at what extent this cutting-edge technology contributes to an effective monitoring over large territorial settings. The aim is to encourage officers, land managers and practitioners toward more effective monitoring and management practices. "
}
@article{Wang201747,
title = "Multisensory fusion based virtual tool wear sensing for ubiquitous manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "47 - 58",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301855",
author = "Jinjiang Wang and Junyao Xie and Rui Zhao and Laibin Zhang and Lixiang Duan",
keywords = "Tool wear estimation",
keywords = "Virtual sensing",
keywords = "Feature fusion ",
abstract = "Abstract Pervasiveness of ubiquitous computing advances the manufacturing scheme into a ubiquitous manufacturing era which poses significant challenges on sensing technology and system reliability. To improve manufacturing system reliability, this paper presents a new virtual tool wear sensing technique based on multisensory data fusion and artificial intelligence model for tool condition monitoring. It infers the difficult-to-measure tool wear parameters (e.g. tool wear width) by fusing in-process multisensory data (e.g. force, vibration, etc.) with dimension reduction technique and support vector regression model. Different state-of-the-art dimension reduction techniques including kernel principal component analysis, locally linear embedding, isometric feature mapping, and minimum redundancy maximum relevant method have been investigated for feature fusion in a virtual sensing model, and the kernel principal component analysis performs best in terms of sensing accuracy. The effectiveness of the developed virtual tool wear sensing technique is experimentally validated in a set of machining tool run-to-failure tests on a computer numerical control milling machine. The results show that the estimated tool wear width through virtual sensing is comparable to that measured offline by a microscope instrument in terms of accuracy, moreover, in a more cost-effective manner. "
}
@article{Sellitto201777,
title = "The impact of Mount Etna sulfur emissions on the atmospheric composition and aerosol properties in the central Mediterranean: A statistical analysis over the period 2000–2013 based on observations and Lagrangian modelling ",
journal = "Atmospheric Environment ",
volume = "148",
number = "",
pages = "77 - 88",
year = "2017",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.10.032",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016308391",
author = "Pasquale Sellitto and Claudia Zanetel and Alcide di Sarra and Giuseppe Salerno and Andrea Tapparo and Daniela Meloni and Giandomenico Pace and Tommaso Caltabiano and Pierre Briole and Bernard Legras",
keywords = "Volcanic emissions",
keywords = "Sulfur cycle",
keywords = "Secondary sulfate aerosols",
keywords = "Regional climate",
keywords = "Mediterranean",
keywords = "Mount Etna ",
abstract = "Abstract The emission of gases and aerosols due to volcanic activity may impact significantly atmospheric composition, cloud occurrence and properties, and the regional and global climate. While the effects of strong explosive (stratospheric) eruptions are relatively well known, limited information on the impacts of small to moderate volcanic activities, including passive degassing, is available. In this paper, the downwind impact of Mount Etna's sulfur emissions on the central Mediterranean is investigated on a statistical basis over the period 2000–2013 using: (a) daily sulfur dioxide emission rates measured near crater at Mount Etna with ground-based ultraviolet spectrophotometers, (b) Lagrangian trajectories and simulated plume dispersion obtained with the \{FLEXPART\} (FLEXible \{PARTicle\} dispersion) model, and (c) long-term observations of column \{SO2\} concentration and aerosol Ångström exponent α at Lampedusa (35.5° N, 12.6° E). This statistical analysis has allowed, for the first time, the characterization of decadal impact of Mount Etna's sulfur emissions on the sulfur dioxide and the aerosol microphysical/optical properties in the central Mediterranean. On average, statistically significant higher \{SO2\} concentrations and smaller aerosol sizes are present when air masses from Mount Etna overpass Lampedusa. Despite being upwind of Lampedusa for only 5% of the time, Mount Etna is potentially responsible for up to 40% and 20% of the \{SO2\} and α extreme values (exceedances of a fixed threshold), respectively, at this location. The most important factor determining this perturbation is the prevailing dynamics, while the magnitude of the \{SO2\} emission rates from Mount Etna appears to be likely important only for relatively strong emissions. The observed perturbations to the aerosol size distribution are expected to produce a direct regional radiative effect in this area. "
}
@article{Kendrick201768,
title = "Strategies to realize decentralized manufacture through hybrid manufacturing platforms ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "43",
number = "",
pages = "68 - 78",
year = "2017",
note = "Special Issue: Extended Papers Selected from \{FAIM\} 2014 ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2015.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S073658451530137X",
author = "Blake A. Kendrick and Vimal Dhokia and Stephen T. Newman",
keywords = "Decentralized manufacture",
keywords = "Hybrid manufacture",
keywords = "Adaptive tool path",
keywords = "Artifact calibration ",
abstract = "Abstract Centralized factory dominance has led to optimization and set-up for manufacture of a sole product or product-range. In-house efficacy of such systems has been greatly improved due to lean six-sigma methodologies; however, wider scale distribution and supply has undergone little to no transformation over the past century. Research pertaining to distributed manufacture, cloud-manufacture and reconfigurable systems have provided several decentralized models using traditional manufacturing capabilities. Due to practical limitations they have not been fully realized to date. This paper outlines the emerging concept and scope for hybrid manufacturing platforms – systems using a plurality of processes on a single motion platform, to manufacture products in a decentralized network. Necessity of on-machine inspection is highlighted, outlining the potential of generic artifact machine calibration and verification of parts made. A robust experimental method using a novel hybrid manufacturing approach is used to realize the post-process adaptation of subsequent parts and demonstrates significant improvement with adapted features being cut within 15 μm of nominal position, compared to the original 300 μm error. Social, economic and environmental ramifications of adopting such a system are highlighted. The combination of several key processes will allow users to manufacture parts with minimal intervention. A move to personal fabrication would allow greater customization and convenience for the end user; however, the issues of copyright and loss of economy of scale would inhibit mass uptake in the near-future. Growing interest by enthusiasts and early adopters will continue to make an impact on the way the populace views manufacture. "
}
@article{Evett201670,
title = "A conceptual framework for a computer-assisted, morphometric-based phytolith analysis and classification system ",
journal = "Journal of Archaeological Science ",
volume = "68",
number = "",
pages = "70 - 78",
year = "2016",
note = "",
issn = "0305-4403",
doi = "https://doi.org/10.1016/j.jas.2015.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0305440315002708",
author = "Rand R. Evett and Rob Q. Cuthrell",
keywords = "Silica phytoliths",
keywords = "Emerging techniques",
keywords = "Multivariate analysis",
keywords = "Automated classification",
keywords = "Staining",
keywords = "Morphometrics",
keywords = "Elliptic Fourier analysis ",
abstract = "Abstract Although automated approaches to shape analysis and object classification have been widely applied in the biological sciences, technical and time considerations have limited their use in phytolith research. As advanced microscopy systems become more affordable and accessible and digital imaging software provides a wider range of sophisticated analytical tools, there is increased potential for effective use of machine-vision and automation in phytolith research. In this paper, we describe technical limitations of phytolith imaging and identify several techniques that might improve results. Drawing on examples of software developed for related disciplines, we then describe a conceptual framework for development and integration of automated phytolith analysis software for: separating phytoliths from non-phytolith material in digital images; segmentation of phytolith boundaries; quantitative phytolith feature extraction, including a discussion of potentially more powerful, non-traditional parameters of phytolith shape and texture; phytolith classification and identification; and phytolith database image retrieval. While recognizing the difficulty of implementing this framework and the need for extensive empirical testing of suggested approaches on phytoliths, we examine the possibility of aggregating quantitative phytolith data collected in studies worldwide to construct a cloud-based database of phytolith images with associated morphotype data. "
}
@article{Kordelas20103833,
title = "Viewpoint independent object recognition in cluttered scenes exploiting ray-triangle intersection and \{SIFT\} algorithms ",
journal = "Pattern Recognition ",
volume = "43",
number = "11",
pages = "3833 - 3845",
year = "2010",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2010.05.030",
url = "http://www.sciencedirect.com/science/article/pii/S003132031000258X",
author = "Georgios Kordelas and Petros Daras",
keywords = "3D object recognition",
keywords = "Distance maps",
keywords = "Ray-triangle intersection",
keywords = "Clutter",
keywords = "Occlusion ",
abstract = "Viewpoint independent recognition of free-form objects and estimation of their exact position are a complex procedure with applications in robotics, artificial intelligence, computer vision and many other scientific fields. In this paper a novel approach is presented that addresses recognition of objects lying in highly cluttered and occluded scenes. The proposed procedure relies on distance maps, which are extracted and stored off-line for each of the 3D objects that might be contained in the scene. During the on-line recognition procedure distance maps are extracted from the scene. Greyscale images, derived from scene's distance maps, are matched with those of the object under recognition by applying similarity measures to the descriptors that are extracted from the images. The similarity is then estimated from image patches, which are defined using the \{SIFT\} descriptor in an appropriate way. After finding the best similarities the position of the object in the scene is estimated. This process is repeated until all objects are successfully recognized. Multiple experiments, which were performed on both 2.5D synthetic and real scenes, proved that the proposed method is robust and highly efficient to a satisfactory degree of occlusion and clutter. "
}
@article{Mufti201216,
title = "Robust estimation of planar surfaces using spatio-temporal \{RANSAC\} for applications in autonomous vehicle navigation ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "1",
pages = "16 - 28",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001606",
author = "Faisal Mufti and Robert Mahony and Jochen Heinzmann",
keywords = "RANSAC",
keywords = "Time-of-flight cameras",
keywords = "Robustness",
keywords = "Navigation",
keywords = "Detection",
keywords = "Ground plane",
keywords = "Segmentation",
keywords = "Obstacle avoidance ",
abstract = "A fundamental problem in autonomous vehicle navigation is the identification of obstacle free space in cluttered and unstructured environments. Features such as walls, people, furniture, doors and stairs, etc are potential hazards. The approach taken in this paper is motivated by the recent development on infra-red time-of-flight cameras that provide video frame rate low resolution depth maps. We propose to exploit the temporal information content provided by the high refresh rate of such cameras to overcome the limitations due to low spatial resolution and high depth uncertainty and aim to provide robust and accurate estimates of planar surfaces in the environment. These surfaces’ estimates are then used to provide statistical tests to identify obstacles and dangers in the environment. Classical 3D spatial \{RANSAC\} is extended to 4D spatio-temporal \{RANSAC\} by developing spatio-temporal models of planar surfaces that incorporate a linear motion model as well as linear environment features. A 4D-vector product is used for hypotheses generation from data that is randomly sampled across both spatial and temporal variations. The algorithm is fully posed in the spatio-temporal representation and there is no need to correlate points or hypothesis between temporal images. The proposed algorithm is computationally fast and robust for estimation of planar surfaces in general and the ground plane in particular. There are potential applications in mobile robotics, autonomous vehicular navigation, and automotive safety systems. The claims of the paper are supported by experimental results obtained from real video data for a time-of-flight range sensor mounted on an automobile navigating in an undercover parking lot. "
}
@article{Roy201657,
title = "Characterization of Landsat-7 to Landsat-8 reflective wavelength and normalized difference vegetation index continuity ",
journal = "Remote Sensing of Environment ",
volume = "185",
number = "",
pages = "57 - 70",
year = "2016",
note = "Landsat 8 Science Results ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.12.024",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715302455",
author = "D.P. Roy and V. Kovalskyy and H.K. Zhang and E.F. Vermote and L. Yan and S.S. Kumar and A. Egorov",
keywords = "Landsat",
keywords = "Continuity",
keywords = "Reflectance",
keywords = "Ndvi",
keywords = "OLI",
keywords = "ETM + ",
abstract = "Abstract At over 40 years, the Landsat satellites provide the longest temporal record of space-based land surface observations, and the successful 2013 launch of the Landsat-8 is continuing this legacy. Ideally, the Landsat data record should be consistent over the Landsat sensor series. The Landsat-8 Operational Land Imager (OLI) has improved calibration, signal to noise characteristics, higher 12-bit radiometric resolution, and spectrally narrower wavebands than the previous Landsat-7 Enhanced Thematic Mapper (ETM +). Reflective wavelength differences between the two Landsat sensors depend also on the surface reflectance and atmospheric state which are difficult to model comprehensively. The orbit and sensing geometries of the Landsat-8 \{OLI\} and Landsat-7 \{ETM\} + provide swath edge overlapping paths sensed only one day apart. The overlap regions are sensed in alternating backscatter and forward scattering orientations so Landsat bi-directional reflectance effects are evident but approximately balanced between the two sensors when large amounts of time series data are considered. Taking advantage of this configuration a total of 59 million 30 m corresponding sensor observations extracted from 6317 Landsat-7 \{ETM\} + and Landsat-8 \{OLI\} images acquired over three winter and three summer months for all the conterminous United States (CONUS) are compared. Results considering different stages of cloud and saturation filtering, and filtering to reduce one day surface state differences, demonstrate the importance of appropriate per-pixel data screening. Top of atmosphere (TOA) and atmospherically corrected surface reflectance for the spectrally corresponding visible, near infrared and shortwave infrared bands, and derived normalized difference vegetation index (NDVI), are compared and their differences quantified. On average the \{OLI\} \{TOA\} reflectance is greater than the \{ETM\} + \{TOA\} reflectance for all bands, with greatest differences in the near-infrared (NIR) and the shortwave infrared bands due to the quite different spectral response functions between the sensors. The atmospheric correction reduces the mean difference in the \{NIR\} and shortwave infrared but increases the mean difference in the visible bands. Regardless of whether \{TOA\} or surface reflectance are used to generate NDVI, on average, for vegetated soil and vegetation surfaces (0 ≤ \{NDVI\} ≤ 1), the \{OLI\} \{NDVI\} is greater than the \{ETM\} + NDVI. Statistical functions to transform between the comparable sensor bands and sensor \{NDVI\} values are presented so that the user community may apply them in their own research to improve temporal continuity between the Landsat-7 \{ETM\} + and Landsat-8 \{OLI\} sensor data. The transformation functions were developed using ordinary least squares (OLS) regression and were fit quite reliably (r2 values &gt; 0.7 for the reflectance data and &gt; 0.9 for the \{NDVI\} data, p-values &lt; 0.0001). "
}
@article{deFigueiredo2015126,
title = "Efficient pose estimation of rotationally symmetric objects ",
journal = "Neurocomputing ",
volume = "150, Part A",
number = "",
pages = "126 - 135",
year = "2015",
note = "Bioinspired and knowledge based techniques and applicationsThe Vitality of Pattern Recognition and Image AnalysisData Stream Classification and Big Data AnalyticsSelected papers from the 16th International Conference on Knowledge-Based and Intelligent Information &amp; Engineering Systems (KES 2012)Selected papers from the 6th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA 2013) ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2014.07.070",
url = "http://www.sciencedirect.com/science/article/pii/S092523121401265X",
author = "Rui Pimentel de Figueiredo and Plinio Moreno and Alexandre Bernardino",
keywords = "3D pose estimation",
keywords = "3D object recognition",
keywords = "Symmetry",
keywords = "Voting",
keywords = "Real-time ",
abstract = "Abstract In this paper we propose algorithms for 3D object recognition from 3D point clouds of rotationally symmetric objects. We base our work in a recent method that represents objects using a hash table of shape features, which allows to match efficiently features that vote for object pose hypotheses. In the case of symmetric objects, the rotation angle about the axis of symmetry does not provide any information, so the hash table contains redundant information. We propose a way to remove redundant features by adding a weight factor for each set of symmetric features. The removal procedure leads to significant computational savings both in storage and time while keeping the recognition performance. We analyze the theoretical storage gains and compare them against the practical ones. We also compare the execution time gains in feature matching and pose clustering. The experiments show storage gains up to 100× and execution time savings up to 3500× with respect to state-of-the-art methods. "
}
@article{Murphy201389,
title = "Historic Building Information Modelling – Adding intelligence to laser and image based surveys of European classical architecture ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "76",
number = "",
pages = "89 - 102",
year = "2013",
note = "Terrestrial 3D modelling ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2012.11.006",
url = "http://www.sciencedirect.com/science/article/pii/S0924271612002079",
author = "Maurice Murphy and Eugene McGovern and Sara Pavia",
keywords = "CAD",
keywords = "Cultural heritage",
keywords = "Modelling",
keywords = "Architecture",
keywords = "Building",
keywords = "Software ",
abstract = "Historic Building Information Modelling (HBIM) is a novel prototype library of parametric objects, based on historic architectural data and a system of cross platform programmes for mapping parametric objects onto point cloud and image survey data. The \{HBIM\} process begins with remote collection of survey data using a terrestrial laser scanner combined with digital photo modelling. The next stage involves the design and construction of a parametric library of objects, which are based on the manuscripts ranging from Vitruvius to 18th century architectural pattern books. In building parametric objects, the problem of file format and exchange of data has been overcome within the \{BIM\} ArchiCAD software platform by using geometric descriptive language (GDL). The plotting of parametric objects onto the laser scan surveys as building components to create or form the entire building is the final stage in the reverse engineering process. The final \{HBIM\} product is the creation of full 3D models including detail behind the object’s surface concerning its methods of construction and material make-up. The resultant \{HBIM\} can automatically create cut sections, details and schedules in addition to the orthographic projections and 3D models (wire frame or textured) for both the analysis and conservation of historic objects, structures and environments. "
}
@article{Garrido2017334,
title = "Fast marching subjected to a vector field–path planning method for mars rovers ",
journal = "Expert Systems with Applications ",
volume = "78",
number = "",
pages = "334 - 346",
year = "2017",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S095741741730101X",
author = "Santiago Garrido and Luis Moreno and Fernando Martín and David Álvarez",
keywords = "Path planning",
keywords = "Fast Marching",
keywords = "Planetary exploration",
keywords = "Mars rovers ",
abstract = "Abstract Path planning is an essential tool for the robots that explore the surface of Mars or other celestial bodies such as dwarf planets, asteroids, or moons. These vehicles require expert and intelligent systems to adopt the best decisions in order to survive in a hostile environment. The planning module has to take into account multiple factors such as the obstacles, the slope of the terrain, the surface roughness, the type of ground (presence of sand), or the information uncertainty. This paper presents a path planning system for rovers based on an improved version of the Fast Marching (FM) method. Scalar and vectorial properties are considered when computing the potential field which is the basis of the proposed technique. Each position in the map of the environment has a cost value (potential) that is used to include different types of variables. The scalar properties can be introduced in a component of the cost function that can represent characteristics such as difficulty, slowness, viscosity, refraction index, or incertitude. The cost value can be computed in different ways depending on the information extracted from the surface and the sensor data of the rover. In this paper, the surface roughness, the slope of the terrain, and the changes in height have been chosen according to the available information. When the robot is navigating sandy terrain with a certain slope, there is a landslide that has to be considered and corrected in the path calculation. This landslide is similar to a lateral current or vector field in the direction of the negative gradient of the surface. Our technique is able to compensate this vector field by introducing the influence of this variable in the cost function. Because of this modification, the new method has been called Fast Marching (subjected to a) vector field (FMVF). Different experiments have been carried out in simulated and real maps to test the method performance. The proposed approach has been validated for multiple combinations of the cost function parameters. "
}
@article{He2012286,
title = "Estimation of surface albedo and directional reflectance from Moderate Resolution Imaging Spectroradiometer (MODIS) observations ",
journal = "Remote Sensing of Environment ",
volume = "119",
number = "",
pages = "286 - 300",
year = "2012",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2012.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S0034425712000168",
author = "Tao He and Shunlin Liang and Dongdong Wang and Hongyi Wu and Yunyue Yu and Jindi Wang",
keywords = "MODIS",
keywords = "Albedo",
keywords = "Directional reflectance",
keywords = "Radiative transfer",
keywords = "Aerosol optical depth ",
abstract = "Land surface albedo is one of the key geophysical variables controlling the surface radiation budget. In recent years, land surface albedo products have been generated using data from various satellites. However, some problems exist in those products due to either the failure of the current retrieving procedures resulting from persistent clouds and/or abrupt surface changes, or the reduced temporal or spatial coverage, which may limit their applications. Rapidly generated albedo products that help reduce the impacts of cloud contamination and improve the capture of events such as ephemeral snow and vegetation growth are in demand. In this study, we propose a method for estimating the land surface albedo from Moderate Resolution Imaging Spectroradiometer (MODIS) data using a short temporal window. Instead of executing the atmospheric correction first and then fitting the surface reflectance in the current \{MODIS\} albedo procedure, the atmospheric properties (e.g., aerosol optical depth) and surface properties (e.g., surface bidirectional reflectance) were estimated simultaneously. Validations were carried out using various data sources including ground measurements (e.g., from the Surface Radiation (SURFRAD) Network and Greenland Climate Network (GC-Net)) and \{MODIS\} AERONET-based Surface Reflectance Validation Network (MODASRVN) data. The results showed comparable albedo estimates with both \{MODIS\} data and ground measurements, and the \{MODASRVN\} instantaneous surface reflectance was in good agreement with the reflectance estimation from our method. Aerosol optical depth (AOD) retrievals over \{SURFRAD\} and \{MODASRVN\} sites were also compared with ground measurements. Validation results showed estimation accuracies similar to those of \{MODIS\} aerosol products. "
}
@article{Wang2016355,
title = "Research progress of artificial psychology and artificial emotion in China ",
journal = "\{CAAI\} Transactions on Intelligence Technology ",
volume = "1",
number = "4",
pages = "355 - 365",
year = "2016",
note = "",
issn = "2468-2322",
doi = "https://doi.org/10.1016/j.trit.2016.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S2468232216300804",
author = "Zhiliang Wang and Lun Xie and Ting Lu",
keywords = "Artificial psychology",
keywords = "Artificial emotion",
keywords = "Intelligent interaction",
keywords = "Psychological assistive technology",
keywords = "Aging service ",
abstract = "Abstract Since the concept of artificial psychology and artificial emotion was first presented, it has become a topic of interest in academic circles and enterprises. In this article, we first briefly introduce the basic concepts and principles of artificial psychology and artificial emotion, analyzing the unified macro-model of the cross-disciplinary system architecture against the need-motivation-behavior framework. Second, we discuss the origin of artificial psychology and artificial emotion, its course of development, and its present situation in China. We also present a review of the published papers and research endeavors of Chinese universities and research institutions and the technical engineering applications of artificial psychology and artificial emotion. Finally, we summarize the challenges to the further development of artificial psychology and artificial emotion and our recommendations for improving the cognitive computing model of psychological states and developing reliable and accurate humanoid interaction and cooperation technology, robot platforms with emotions and humanoid interaction and cooperation capabilities, and humanoid robots for the elderly and the disabled in smart homes. We believe that, with intensive research, artificial psychology and artificial emotion may be developed further and may eventually reach maturity. "
}
@article{Corney2010243,
title = "Putting the crowd to work in a knowledge-based factory ",
journal = "Advanced Engineering Informatics ",
volume = "24",
number = "3",
pages = "243 - 250",
year = "2010",
note = "The Cognitive Factory ",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2010.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S1474034610000388",
author = "J.R. Corney and C. Torres-Sánchez and A.P. Jagadeesan and X.T. Yan and W.C. Regli and H. Medellin",
keywords = "Crowdsourcing",
keywords = "Machine learning",
keywords = "Geometric reasoning",
keywords = "Canonical views",
keywords = "Shape similarity",
keywords = "2D nesting ",
abstract = "Although researchers have developed numerous computational approaches to reasoning and knowledge representation, their implementations are always limited to specific applications (e.g. assembly planning, fault diagnosis or production scheduling) for which bespoke knowledge bases or algorithms have been created. However, “cloud computing” has made irrelevant both the physical location and internal processes used by machine intelligence. In other words, the Internet encourages functional processes to be treated as ‘black boxes’ with which users need only be concerned with posing the right question and interpreting the response. The system asking the questions does not need to know how answers are generated, only that they are available in an appropriate time frame. This paper proposes that Crowdsourcing could provide on-line, ‘black-box’, reasoning capabilities that could far exceed the capabilities of current \{AI\} technologies (i.e. genetic algorithms, neural-nets, case-based reasoning) in terms of flexibility and scope. This paper describes how Crowdsourcing has been deployed in three different reasoning scenarios to carry out industrial tasks that involve significant amounts of tacit (e.g. unformalised) knowledge. The first study reports the application of Crowdsourcing to identify canonical view of 3D \{CAD\} models. The qualitative results suggest that the anonymous, Internet, workforce have a good comprehension of 3D geometry. Having established this basic competence the second experiment assesses the Crowd’s ability to judge the similarity of 3D components. Comparison of the results with published benchmarks shows a high degree of correspondence. Lastly the performance of the Internet labourers is quantified in a 2D nesting task, where their performance is found to be superior to reported computational algorithms. In all these cases results were returned within a couple of hours and the paper concludes that there is potential for broad application of Crowdsourcing to geometric problem solving in CAD/CAM. "
}
@article{Caruso2017174,
title = "Microsoft Kinect \{V2\} vision system in a manufacturing application ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "48",
number = "",
pages = "174 - 181",
year = "2017",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2017.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516304082",
author = "L. Caruso and R. Russo and S. Savino",
keywords = "Microsoft kinect",
keywords = "Vision systems",
keywords = "Manufacturing robots ",
abstract = "Abstract In this paper an application for the Kinect \{V2\} sensor is described in the robotic field. The sensor is used as a vision device for detecting position, shape and dimensions of an object on the working space of a robot in order to planning the end effector path. The algorithms used for the recognition of contour and spatial position of planar shapes are described. The technique adopted for the recognition of 3D objects are presented. The first results provided by a prototype of gluing robot for the bonding of leather patches and shoe soles are presented. The results confirm the possibility of using the Kinect \{V2\} sensor as an alternative to the well consolidated 3D measuring devices which are definitely more accurate, but also much more expensive. "
}
@article{Mls201758,
title = "Interactive evolutionary optimization of fuzzy cognitive maps ",
journal = "Neurocomputing ",
volume = "232",
number = "",
pages = "58 - 68",
year = "2017",
note = "Advances in Fuzzy Cognitive Maps Theory ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2016.10.068",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216315636",
author = "Karel Mls and Richard Cimler and Ján Vaščák and Michal Puheim",
keywords = "Fuzzy cognitive map",
keywords = "Interactive evolutionary optimization",
keywords = "Expert knowledge ",
abstract = "Abstract Modeling dynamic systems with Fuzzy Cognitive Maps (FCMs) is characterized by the simplicity of the model representation and its execution. Furthermore, \{FCMs\} can easily incorporate human knowledge from the given domain. Despite the many advantages of FCMs, there are some drawbacks, too. The quality of knowledge obtained from the domain experts, and any differences and uncertainties in their opinions, has to be improved by different methods. We propose a new approach for handling incompleteness and natural uncertainty in expert evaluation of the connection matrix of a particular FCM. It is based on partial expert estimations and evolutionary algorithms in the role of an expert-driven optimization and outside of the \{FCM\} optimization (adaptation) research area known as Interactive Evolutionary Computing (IEC). In the present paper, a modification of \{IEC\} for the purposes of \{FCM\} optimization is presented, referred to as the IEO-FCM method, i.e., the Interactive Evolutionary Optimization of Fuzzy Cognitive Maps. Experimental results on two control problems suggest that the IEO-FCM method can improve the quality of an \{FCM\} even in situations without any measured data necessary for other known learning algorithms. "
}
@article{Sun20131190,
title = "Object detection, shape recovery, and 3D modelling by depth-encoded hough voting ",
journal = "Computer Vision and Image Understanding ",
volume = "117",
number = "9",
pages = "1190 - 1202",
year = "2013",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S1077314213000969",
author = "Min Sun and Shyam Sunder Kumar and Gary Bradski and Silvio Savarese",
keywords = "Object recognition",
keywords = "Object detection",
keywords = "Viewpoint estimation",
keywords = "Shape recovery",
keywords = "3D reconstruction",
keywords = "Shape completion",
keywords = "Texture completion ",
abstract = "Abstract Detecting objects, estimating their pose, and recovering their 3D shape are critical problems in many vision and robotics applications. This paper addresses the above needs using a two stages approach. In the first stage, we propose a new method called \{DEHV\} – Depth-Encoded Hough Voting. \{DEHV\} jointly detects objects, infers their categories, estimates their pose, and infers/decodes objects depth maps from either a single image (when no depth maps are available in testing) or a single image augmented with depth map (when this is available in testing). Inspired by the Hough voting scheme introduced in [1], \{DEHV\} incorporates depth information into the process of learning distributions of image features (patches) representing an object category. \{DEHV\} takes advantage of the interplay between the scale of each object patch in the image and its distance (depth) from the corresponding physical patch attached to the 3D object. Once the depth map is given, a full reconstruction is achieved in a second (3D modelling) stage, where modified or state-of-the-art 3D shape and texture completion techniques are used to recover the complete 3D model. Extensive quantitative and qualitative experimental analysis on existing datasets [2–4] and a newly proposed 3D table-top object category dataset shows that our \{DEHV\} scheme obtains competitive detection and pose estimation results. Finally, the quality of 3D modelling in terms of both shape completion and texture completion is evaluated on a 3D modelling dataset containing both in-door and out-door object categories. We demonstrate that our overall algorithm can obtain convincing 3D shape reconstruction from just one single uncalibrated image. "
}
@article{Yang2011S52,
title = "Fusion of camera images and laser scans for wide baseline 3D scene alignment in urban environments ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "66",
number = "6, Supplement",
pages = "S52 - S61",
year = "2011",
note = "Advances in \{LIDAR\} Data Processing and Applications ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2011.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0924271611001018",
author = "Michael Ying Yang and Yanpeng Cao and John McDonald",
keywords = "Senor fusion",
keywords = "Terrestrial laser scan",
keywords = "Wide baseline alignment",
keywords = "Viewpoint invariant feature",
keywords = "Plane extraction",
keywords = "Feature extraction ",
abstract = "In this paper we address the problem of automatic laser scan registration in urban environments. This represents a challenging problem for two major reasons. First, two individual laser scans might be captured at significantly changed viewpoints (wide baseline) and have very little overlap. Second, man-made buildings usually contain many structures of similar appearances. This will result in considerable aliasing in the matching process. By sensor fusion of laser data with camera images, we propose a novel improvement to the existing 2D feature techniques to enable automatic 3D alignment between two widely separated scans. The key idea consists of extracting dominant planar structures from 3D point clouds and then utilizing the recovered 3D geometry to improve the performance of 2D image feature for wide baseline matching. The resulting feature descriptors become more robust to camera viewpoint changes after the procedure of viewpoint normalization. Moreover, the viewpoint normalized 2D features provide robust local feature information including patch scale and dominant orientation for effective repetitive structure matching in man-made environments. Comprehensive experimental evaluations with real data demonstrate the potential of the proposed method for automatic wide baseline 3D scan alignment in urban environments. "
}
@article{Chen20163,
title = "Information from imagery: \{ISPRS\} scientific vision and research agenda ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "115",
number = "",
pages = "3 - 21",
year = "2016",
note = "Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science' ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2015.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S092427161500218X",
author = "Jun Chen and Ian Dowman and Songnian Li and Zhilin Li and Marguerite Madden and Jon Mills and Nicolas Paparoditis and Franz Rottensteiner and Monika Sester and Charles Toth and John Trinder and Christian Heipke",
keywords = "Research agenda",
keywords = "Photogrammetry",
keywords = "Remote sensing",
keywords = "Spatial information science",
keywords = "ISPRS ",
abstract = "Abstract With the increased availability of very high-resolution satellite imagery, terrain based imaging and participatory sensing, inexpensive platforms, and advanced information and communication technologies, the application of imagery is now ubiquitous, playing an important role in many aspects of life and work today. As a leading organisation in this field, the International Society for Photogrammetry and Remote Sensing (ISPRS) has been devoted to effectively and efficiently obtaining and utilising information from imagery since its foundation in the year 1910. This paper examines the significant challenges currently facing \{ISPRS\} and its communities, such as providing high-quality information, enabling advanced geospatial computing, and supporting collaborative problem solving. The state-of-the-art in \{ISPRS\} related research and development is reviewed and the trends and topics for future work are identified. By providing an overarching scientific vision and research agenda, we hope to call on and mobilise all \{ISPRS\} scientists, practitioners and other stakeholders to continue improving our understanding and capacity on information from imagery and to deliver advanced geospatial knowledge that enables humankind to better deal with the challenges ahead, posed for example by global change, ubiquitous sensing, and a demand for real-time information generation. "
}
@article{Konstantinidis2015124,
title = "A lightweight framework for transparent cross platform communication of controller data in ambient assisted living environments ",
journal = "Information Sciences ",
volume = "300",
number = "",
pages = "124 - 139",
year = "2015",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.10.070",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514011906",
author = "Evdokimos I. Konstantinidis and Panagiotis E. Antoniou and Giorgos Bamparopoulos and Panagiotis D. Bamidis",
keywords = "Elderly care",
keywords = "Ambient assisted living",
keywords = "Human computer interaction",
keywords = "Cross device communication",
keywords = "Ubiquitous communication technology",
keywords = "Exergaming serious gaming ",
abstract = "Abstract Elderly support ambient assisted living environments are focal in healthcare computing. Critical to their implementation is transparent integration of diverse hardware and its ubiquitous communication with multiple software components. Modern controllers (Wii family, Microsoft Kinect, Neurosky Mindwave) are especially useful in elderly smart homes, being used, for healthcare monitoring and exercise gaming interventions. Presented herein is a novel Controller Application Communication (CAC) framework for cross device, application independent transmission of controller data to multiple software components. For the first time, a framework supports multiple modern controllers concurrently communicating with multiple, device naïve, requesting applications, utilizing standard, real time, internet communication technologies, as opposed to current practices which focus merely on one device. The framework consists of uniform schemas for encapsulating controllers’ data and of services necessary for communicating these data to the requesting software components. The framework’s architecture is based on distributed computing principles, delegating server duties to use-site gateways for reducing main server load. This framework was utilized in the \{USEFIL\} project for simultaneous use of multiple controllers and sensors by different software components of the platform. The framework’s design principles align with the Internet of Things (IoT) paradigm. Future work, enriching this framework, aims to facilitate a more diverse controller set, adhering to an IoT architecture implementation, as well as, allowing on-demand online data streaming, thereby enabling interested parties to test algorithms with data from ecologically valid environments. "
}
@article{GutierrezGomez2016571,
title = "Dense RGB-D visual odometry using inverse depth ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "571 - 583",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.026",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002213",
author = "Daniel Gutierrez-Gomez and Walterio Mayol-Cuevas and J.J. Guerrero",
keywords = "RGB-D",
keywords = "Visual odometry ",
abstract = "Abstract In this paper we present a dense visual odometry system for RGB-D cameras performing both photometric and geometric error minimisation to estimate the camera motion between frames. Contrary to most works in the literature, we parametrise the geometric error by the inverse depth instead of the depth, which translates into a better fit of the distribution of the geometric error to the used robust cost functions. To improve the accuracy we propose to use a keyframe switching strategy based on a visibility criteria between frames. For the comparison of our approach with state-of-the-art approaches we use the popular datasets from the \{TUM\} for RGB-D benchmarking as well as two synthetic datasets. Our approach shows to be competitive with state-of-the-art methods in terms of drift in metres per second, even compared to methods performing loop closure too. When comparing to approaches performing pure odometry like ours, our method outperforms them in the majority of the tested datasets. Additionally we show that our approach is able to work in real time and we provide a qualitative evaluation on our own sequences showing a low drift in the 3D reconstructions. We have implemented this method within the scope of \{PCL\} (Point Cloud Library) as a branch of the code for large scale KinectFusion, where the original \{ICP\} system for odometry estimation has been completely substituted by our method. A \{PCL\} fork including the modified method is available for download. "
}
@article{Mishchenko2010540,
title = "Toward unified satellite climatology of aerosol properties.: 3. \{MODIS\} versus \{MISR\} versus \{AERONET\} ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "111",
number = "4",
pages = "540 - 552",
year = "2010",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2009.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0022407309003343",
author = "Michael I. Mishchenko and Li Liu and Igor V. Geogdzhayev and Larry D. Travis and Brian Cairns and Andrew A. Lacis",
keywords = "Tropospheric aerosols",
keywords = "Remote sensing ",
abstract = "We use the full duration of collocated pixel-level MODIS-Terra and \{MISR\} aerosol optical thickness (AOT) retrievals and level 2 cloud-screened quality-assured \{AERONET\} measurements to evaluate the likely individual \{MODIS\} and \{MISR\} retrieval accuracies globally over oceans and land. We show that the use of quality-assured \{MODIS\} \{AOTs\} as opposed to the use of all \{MODIS\} \{AOTs\} has little effect on the resulting accuracy. The \{MODIS\} and \{MISR\} relative standard deviations (RSTDs) with respect to \{AERONET\} are remarkably stable over the entire measurement record and reveal nearly identical overall \{AOT\} performances of \{MODIS\} and \{MISR\} over the entire suite of \{AERONET\} sites. This result is used to evaluate the likely pixel-level \{MODIS\} and \{MISR\} performances on the global basis with respect to the (unknown) actual AOTs. For this purpose, we use only fully compatible \{MISR\} and \{MODIS\} aerosol pixels. We conclude that the likely \{RSTDs\} for this subset of \{MODIS\} and \{MISR\} \{AOTs\} are ∼73% over land and ∼30% over oceans. The average \{RSTDs\} for the combined [AOT(MODIS)+AOT(MISR)]/2 pixel-level product are close to 66% and 27%, respectively, which allows us to recommend this simple blend as a better alternative to the original \{MODIS\} and \{MISR\} data. These accuracy estimates still do not represent the totality of \{MISR\} and quality-assured \{MODIS\} pixel-level \{AOTs\} since an unaccounted for and potentially significant source of errors is imperfect cloud screening. Furthermore, many collocated pixels for which one of the datasets reports a retrieval, whereas the other one does not may also be problematic. "
}
@article{Campbell2013520,
title = "Characterizing the vertical profile of aerosol particle extinction and linear depolarization over Southeast Asia and the Maritime Continent: The 2007–2009 view from \{CALIOP\} ",
journal = "Atmospheric Research ",
volume = "122",
number = "",
pages = "520 - 543",
year = "2013",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2012.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0169809512001366",
author = "James R. Campbell and Jeffrey S. Reid and Douglas L. Westphal and Jianglong Zhang and Jason L. Tackett and Boon Ning Chew and Ellsworth J. Welton and Atsushi Shimizu and Nobuo Sugimoto and Kazuma Aoki and David M. Winker",
keywords = "CALIPSO",
keywords = "Lidar",
keywords = "Southeast Asia",
keywords = "Maritime Continent",
keywords = "Aerosol particle scattering",
keywords = "Aerosol composition ",
abstract = "Vertical profiles of 0.532 μm aerosol particle extinction coefficient and linear volume depolarization ratio are described for Southeast Asia and the Maritime Continent. Quality-screened and cloud-cleared Version 3.01 Level 2 \{NASA\} Cloud Aerosol Lidar with Orthogonal Polarization (CALIOP) 5-km Aerosol Profile datasets are analyzed from 2007 to 2009. Numerical simulations from the U.S. Naval Aerosol Analysis and Predictive System (NAAPS), featuring two-dimensional variational assimilation of \{NASA\} Moderate Resolution Imaging Spectroradiometer and Multi-angle Imaging SpectroRadiometer quality-assured datasets, combined with regional ground-based lidar measurements, are considered for assessing \{CALIOP\} retrieval performance, identifying bias, and evaluating regional representativeness. \{CALIOP\} retrievals of aerosol particle extinction coefficient and aerosol optical depth (AOD) are high over land and low over open waters relative to \{NAAPS\} (0.412/0.312 over land for all data points inclusive, 0.310/0.235 when the per bin average is used and each is treated as single data points; 0.102/0.151 and 0.086/0.124, respectively, over ocean). Regional means, however, are very similar (0.180/0.193 for all data points and 0.155/0.159 when averaged per normalized bin), as the two factors offset one another. The land/ocean offset is investigated, and discrepancies attributed to interpretation of particle composition and a-priori assignment of the extinction-to-backscatter ratio (“lidar ratio”) necessary for retrieving the extinction coefficient from \{CALIOP\} signals. Over land, \{NAAPS\} indicates more dust present than \{CALIOP\} algorithms are identifying, indicating a likely assignment of a higher lidar ratio representative of more absorptive particles. \{NAAPS\} resolves more smoke over water than identified with CALIOP, indicating likely usage of a lidar ratio characteristic of less absorptive particles to be applied that biases low \{AOD\} there. Over open waters except within the Bay of Bengal, aerosol particle scattering is largely capped below 1.5 km MSL, though ground-based lidar measurements at Singapore differ slightly from this finding. Significant aerosol particle presence over land is similarly capped near 3.0 km \{MSL\} over most regions. Particle presence at low levels regionally, except over India, is dominated by relatively non-depolarizing particles. Industrial haze, sea salt droplets and fresh smoke are thus most likely present. "
}
@article{Bosché2015201,
title = "The value of integrating Scan-to-BIM and Scan-vs-BIM techniques for construction monitoring using laser scanning and BIM: The case of cylindrical \{MEP\} components ",
journal = "Automation in Construction ",
volume = "49, Part B",
number = "",
pages = "201 - 213",
year = "2015",
note = "30th \{ISARC\} Special Issue ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2014.05.014",
url = "http://www.sciencedirect.com/science/article/pii/S0926580514001319",
author = "Frédéric Bosché and Mahmoud Ahmed and Yelda Turkan and Carl T. Haas and Ralph Haas",
keywords = "MEP",
keywords = "3D laser scanning",
keywords = "BIM",
keywords = "Scan-vs-BIM",
keywords = "Scan-to-BIM",
keywords = "Hough transform",
keywords = "Progress tracking",
keywords = "Percent built as planned ",
abstract = "Abstract There is a growing need for tools automating the processing of as-built 3D laser scanned data, and more particularly the comparison of this as-built data with planned works. This paper particularly considers the case of tracking \{MEP\} components with circular cross-sections, which essentially include pipes, and some conduits and ducts. Discrepancies between the as-built and as-planned status of pipes, conduit and ductwork result from changes that occur in the field and that are either unnoticed (human error) or not reflected in the 3D model. Previous research has shown that the Hough transform, with judiciously applied domain constraints, is a practical and cost-effective approach to find, recognize and reconstruct cylindrical \{MEP\} works within point clouds automatically. Previous research has also shown that “Scan-vs-BIM” systems that are based on the geometric alignment and comparison of as-built laser scans with as-designed \{BIM\} models can effectively recognize and identify \{MEP\} components as long as they are constructed near their as-planned locations. The research presented in this paper combines the two techniques in a unified approach for more robust automated comparison of as-built and as-planned cylindrical \{MEP\} works, thereby providing the basis for automated earned value tracking, automated percent-built-as-planned measures, and assistance for the delivery of as-built \{BIM\} models from as-designed ones. The proposed approach and its improved performance are validated using data acquired from an actual construction site. The results are very encouraging and demonstrate the added value of the proposed integrated approach over the rather simpler Scan-vs-BIM system. The two main areas of improved performance are: (1) the enabled recognition and identification of objects that are not built at their as-planned locations; and (2) the consideration for pipe completeness in the pipe recognition and identification metric. "
}
@article{Liu2016147,
title = "A closed-form formulation of HRBF-based surface reconstruction by approximate solution ",
journal = "Computer-Aided Design ",
volume = "78",
number = "",
pages = "147 - 157",
year = "2016",
note = "\{SPM\} 2016 ",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2016.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0010448516300215",
author = "Shengjun Liu and Charlie C.L. Wang and Guido Brunnett and Jun Wang",
keywords = "Hermite Radial Basis Functions",
keywords = "Quasi-solution",
keywords = "Closed-form",
keywords = "Surface reconstruction ",
abstract = "Abstract The Hermite radial basis functions (HRBFs) implicits have been used to reconstruct surfaces from scattered Hermite data points. In this work, we propose a closed-form formulation to construct HRBF-based implicits by a quasi-solution to approximate the exact one. A scheme is developed to automatically adjust the support sizes of basis functions to hold the error bound of a quasi-solution. Our method can generate an implicit function from positions and normals of scattered points without taking any global operation. Robust and efficient reconstructions are observed in our experimental tests on real data captured from a variety of scenes. "
}
@article{Dobkin1985381,
title = "A linear algorithm for determining the separation of convex polyhedra ",
journal = "Journal of Algorithms ",
volume = "6",
number = "3",
pages = "381 - 392",
year = "1985",
note = "",
issn = "0196-6774",
doi = "https://doi.org/10.1016/0196-6774(85)90007-0",
url = "http://www.sciencedirect.com/science/article/pii/0196677485900070",
author = "David P Dobkin and David G Kirkpatrick",
abstract = "The separation of two convex polyhedra is defined to be the minimum distance from a point (not necessarily an extreme point) of one to a point of the other. A linear time algorithm is presented for constructing a pair of points that realize the separation of two convex polyhedra in three dimensions. This algorithm is based on a simple hierarchical description of polyhedra that is of interest in its own right. The result provides a linear algorithm for detecting the intersection of convex polyhedra. Separation and intersection detection algorithms have applications in clustering, the intersection of half-spaces, linear programming, and robotics. "
}
@article{Breitkreuz20071377,
title = "A case study to prepare for the utilization of aerosol forecasts in solar energy industries ",
journal = "Solar Energy ",
volume = "81",
number = "11",
pages = "1377 - 1385",
year = "2007",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2007.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X07000278",
author = "H. Breitkreuz and M. Schroedter-Homscheidt and T. Holzer-Popp",
keywords = "Irradiance forecast",
keywords = "Aerosols",
keywords = "Direct and diffuse irradiance",
keywords = "Air quality modelling ",
abstract = "Precise aerosol information is indispensable in providing accurate clear sky irradiance forecasts, which is a very important aspect in solar facility management as well as in solar and conventional power load prediction. In order to demonstrate the need of detailed aerosol information, direct irradiance derived from Aerosol Robotic Network (AERONET) ground based measurements of aerosol optical depth (AOD) was compared in a case study over Europe to irradiance calculated using a standard aerosol scenario. The analysis shows an underestimation of measurement-derived direct irradiance by the scenario-derived direct irradiance for locations in Northern Europe and an overestimation for the Mediterranean region. Forecasted \{AOD\} of the European Dispersion and Deposition Model (EURAD) system was validated against ground based \{AERONET\} clear sky \{AOD\} measurements for the same test period of February 15th to 22nd, 2004. For the time period analyzed, the modelled \{AOD\} forecasts of the \{EURAD\} system slightly underestimate ground based \{AERONET\} measurements. To quantify the effects of varying \{AOD\} forecast quality in their impact on the application in solar energy industry, measured and forecasted \{AOD\} were used to calculate and compare direct, diffuse, and global irradiance. All other influencing variables (mainly clouds and water vapour) are assumed to be modelled and measured correctly for this analysis which is dedicated to the specific error introduced by aerosol forecasting. The underestimated \{AOD\} results in a mean overestimation of direct irradiance of +28 W/m2 (+12%), whereas diffuse irradiance is generally underestimated (−19 W/m2 or −14%). Mean global irradiance values where direct and diffuse irradiance errors compensate each other are very well represented (on average +9 W/m2 or +2%). "
}
@article{Molleda20131186,
title = "An improved 3D imaging system for dimensional quality inspection of rolled products in the metal industry ",
journal = "Computers in Industry ",
volume = "64",
number = "9",
pages = "1186 - 1200",
year = "2013",
note = "Special Issue: 3D Imaging in Industry ",
issn = "0166-3615",
doi = "https://doi.org/10.1016/j.compind.2013.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0166361513000973",
author = "Julio Molleda and Rubén Usamentiaga and Daniel F. García and Francisco G. Bulnes and Adrián Espina and Bassiru Dieye and Lyndon N. Smith",
keywords = "Dimensional quality inspection",
keywords = "3D imaging in industry",
keywords = "3D surface reconstruction",
keywords = "Line detection and extraction",
keywords = "Active triangulation ",
abstract = "Abstract Measurement, inspection and quality control in industry have benefited from 3D techniques for imaging and visualization in recent years. The development of machine vision devices at decreased costs, as well as their miniaturization and integration in industrial processes, have accelerated the use of 3D imaging systems in industry. In this paper we describe how to improve the performance of a 3D imaging system for inline dimensional quality inspection of long, flat-rolled metal products manufactured in rolling mills we designed and developed in previous works. Two dimensional characteristics of rolled products are measured by the system: width and flatness. The system is based on active triangulation using a single-line pattern projected onto the surface of the product under inspection for range image acquisition. Taking the system calibration into account the range images are transformed into a calibrated point cloud representing the 3D surface reconstruction of the product. Two approaches to improve the line detection and extraction method used in the original system are discussed, one intended for high-speed processing with lower accuracy, and the other providing high accuracy while incurring higher computational time expenses. A mechanism to remove, or at least reduce, the effects of product movements while manufacturing, such as bouncing and flapping, is also proposed to improve the performance of the system. "
}
@article{Park20094174,
title = "Vision-based global localization for mobile robots with hybrid maps of objects and spatial layouts ",
journal = "Information Sciences ",
volume = "179",
number = "24",
pages = "4174 - 4198",
year = "2009",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2009.06.030",
url = "http://www.sciencedirect.com/science/article/pii/S0020025509002989",
author = "Soonyong Park and Soohwan Kim and Mignon Park and Sung-Kee Park",
keywords = "Hybrid map",
keywords = "Global localization",
keywords = "Mobile robot",
keywords = "Stereo vision",
keywords = "Object recognition ",
abstract = "This paper presents a novel vision-based global localization that uses hybrid maps of objects and spatial layouts. We model indoor environments with a stereo camera using the following visual cues: local invariant features for object recognition and their 3D positions for object pose estimation. We also use the depth information at the horizontal centerline of image where the optical axis passes through, which is similar to the data from a 2D laser range finder. This allows us to build our topological node that is composed of a horizontal depth map and an object location map. The horizontal depth map describes the explicit spatial layout of each local space and provides metric information to compute the spatial relationships between adjacent spaces, while the object location map contains the pose information of objects found in each local space and the visual features for object recognition. Based on this map representation, we suggest a coarse-to-fine strategy for global localization. The coarse pose is estimated by means of object recognition and SVD-based point cloud fitting, and then is refined by stochastic scan matching. Experimental results show that our approaches can be used for an effective vision-based map representation as well as for global localization methods. "
}
@article{tagkey201198,
title = "Calendar ",
journal = "Automation in Construction ",
volume = "20",
number = "1",
pages = "98 - ",
year = "2011",
note = "Global convergence in construction ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/S0926-5805(10)00177-9",
url = "http://www.sciencedirect.com/science/article/pii/S0926580510001779",
key = "tagkey201198"
}
@article{Azevedo20172,
title = "Supporting the entire life-cycle of the extended manufacturing enterprise ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "43",
number = "",
pages = "2 - 11",
year = "2017",
note = "Special Issue: Extended Papers Selected from \{FAIM\} 2014 ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516301697",
author = "Americo Azevedo and José Faria and Filipe Ferreira",
keywords = "Extended manufacturing enterprise",
keywords = "One-of-a-kind manufacturing",
keywords = "Engineer-to-order environment",
keywords = "Manufacturing reference model",
keywords = "Manufacturing life-cycle framework ",
abstract = "Abstract This paper presents a framework to support the full life-cycle of extended manufacturing enterprises, from creation to operation and dissolution phases. The deployment and operation of such enterprises can be compared with the concept of ‘plug-and-play’, as the internal processes and legacy systems of the companies involved are smoothly integrated within an overall business process designed, validated and executed according to a specific business opportunity. During the plug phase, the specific business requirements are elicited and integrated with the design of the extended business processes. On the other hand, in the play phase, those predefined processes are executed in order to run the extended enterprise successfully. The paper describes an application case regarding an engineer-to-order and one-of-a-kind engineering product. This scenario is common to a large number of technology-driven SMEs, and illustrates the value of the framework to exploit business opportunities that require a combination of skills and resources that do not exist in-house. The case shows how the platform addresses the two main challenges in the deployment of an extended enterprise. The first challenge is finding the right set of partners to address a new business opportunity and the design of the underlying collaborative processes. The second challenge is mostly technical, and focuses on the integration of the legacy systems of the partners participating in the network so that cooperation can take place quickly and seamlessly. "
}
@article{Chen20171,
title = "Ubiquitous manufacturing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "45",
number = "",
pages = "1 - 2",
year = "2017",
note = "Special Issue on Ubiquitous Manufacturing (UbiM) ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0736584516303246",
author = "Tin-Chih Toly Chen and T. Warren Liao and Dong-Ho Lee and Grzegorz Bocewicz"
}
@article{Cheng20122860,
title = "Stitch: A language for architecture-based self-adaptation ",
journal = "Journal of Systems and Software ",
volume = "85",
number = "12",
pages = "2860 - 2875",
year = "2012",
note = "Self-Adaptive Systems ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2012.02.060",
url = "http://www.sciencedirect.com/science/article/pii/S0164121212000714",
author = "Shang-Wen Cheng and David Garlan",
keywords = "Rainbow",
keywords = "Self-adaptation",
keywords = "Strategy",
keywords = "Tactic",
keywords = "Uncertainty",
keywords = "Utility ",
abstract = "Requirements for high availability in computing systems today demand that systems be self-adaptive to maintain expected qualities-of-service in the presence of system faults, variable environmental conditions, and changing user requirements. Autonomic computing tackles the challenge of automating tasks that humans would otherwise have to perform to achieve this goal. However, existing approaches to autonomic computing lack the ability to capture routine human repair tasks in a way that takes into account the business context humans use in selecting an appropriate form of adaptation, while dealing with timing delays and uncertainties in outcome of repair actions. In this article, we present Stitch, a language for representing repair strategies within the context of an architecture-based self-adaptation framework. Stitch supports the explicit representation of repair decision trees together with the ability to express business objectives, allowing a self-adaptive system to select a strategy that has optimal utility in a given context, even in the presence of potential timing delays and outcome uncertainty. "
}
@article{tagkey20101106,
title = "Calendar ",
journal = "Automation in Construction ",
volume = "19",
number = "8",
pages = "1106 - ",
year = "2010",
note = "The role of \{VR\} and \{BIM\} to manage the construction and design processes ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/S0926-5805(10)00153-6",
url = "http://www.sciencedirect.com/science/article/pii/S0926580510001536",
key = "tagkey20101106"
}
@article{Knoop2009321,
title = "Fusion of 2d and 3d sensor data for articulated body tracking ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "3",
pages = "321 - 329",
year = "2009",
note = "Selected papers from 2006 \{IEEE\} International Conference on Multisensor Fusion and Integration (MFI 2006)2006 \{IEEE\} International Conference on Multisensor Fusion and Integration ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.10.017",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001711",
author = "Steffen Knoop and Stefan Vacek and Rüdiger Dillmann",
keywords = "Human motion capture",
keywords = "Sensor fusion",
keywords = "Time-of-flight",
keywords = "3D body model",
keywords = "Human robot interaction ",
abstract = "In this article, we present an approach for the fusion of 2d and 3d measurements for model-based person tracking, also known as Human Motion Capture. The applied body model is defined geometrically with generalized cylinders, and is set up hierarchically with connecting joints of different types. The joint model can be parameterized to control the degrees of freedom, adhesion and stiffness. This results in an articulated body model with constrained kinematic degrees of freedom. The fusion approach incorporates this model knowledge together with the measurements, and tracks the target body iteratively with an extended Iterative Closest Point (ICP) approach. Generally, the \{ICP\} is based on the concept of correspondences between measurements and model, which is normally exploited to incorporate 3d point cloud measurements. The concept has been generalized to represent and incorporate also 2d image space features. Together with the 3D point cloud from a 3d time-of-flight (ToF) camera, arbitrary features, derived from 2D camera images, are used in the fusion algorithm for tracking of the body. This gives complementary information about the tracked body, enabling not only tracking of depth motions but also turning movements of the human body, which is normally a hard problem for markerless human motion capture systems. The resulting tracking system, named VooDoo is used to track humans in a Human–Robot Interaction (HRI) context. We only rely on sensors on board the robot, i.e. the color camera, the ToF camera and a laser range finder. The system runs in realtime (∼20 Hz) and is able to robustly track a human in the vicinity of the robot. "
}
@article{Şenkal20091222,
title = "Estimation of solar radiation over Turkey using artificial neural network and satellite data ",
journal = "Applied Energy ",
volume = "86",
number = "7–8",
pages = "1222 - 1228",
year = "2009",
note = "",
issn = "0306-2619",
doi = "https://doi.org/10.1016/j.apenergy.2008.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0306261908001578",
author = "Ozan Şenkal and Tuncay Kuleli",
keywords = "Solar radiation",
keywords = "Artificial neural network",
keywords = "Satellite data",
keywords = "Physical technique",
keywords = "Turkey ",
abstract = "This study introduces artificial neural networks (ANNs) for the estimation of solar radiation in Turkey (26–45 E and 36–42 N). Resilient propagation (RP), Scale conjugate gradient (SCG) learning algorithms and logistic sigmoid transfer function were used in the network. In order to train the neural network, meteorological data for the period from August 1997 to December 1997 for 12 cities (Antalya, Artvin, Edirne, Kayseri, Kütahya, Van, Adana, Ankara, İstanbul, Samsun, İzmir, Diyarbakır) spread over Turkey were used as training (nine stations) and testing (three stations) data. Meteorological and geographical data (latitude, longitude, altitude, month, mean diffuse radiation and mean beam radiation) are used in the input layer of the network. Solar radiation is the output. However, solar radiation has been estimated as monthly mean daily sum by using Meteosat-6 satellite \{C3\} D data in the visible range over 12 cities in Turkey. Digital counts of satellite data were converted into radiances and these are used to calculate the albedos. Using the albedo, the cloud cover index of each pixel was constructed. Diffuse and direct component of horizontal irradiation were calculated as a function of optical air mass, turbidity factor and Rayleigh optical thickness for clear-sky. Using the relation between clear-sky index and cloud cover index, the solar irradiance for any pixel is calculated for Physical method. \{RMS\} between the estimated and ground values for monthly mean daily sum with \{ANN\} and Physical method values have been found as 2.32 \{MJ\} m−2 (54 W/m2) and 2.75 \{MJ\} m−2 (64 W/m2) (training cities), 3.94 \{MJ\} m−2 (91 W/m2) and 5.37 \{MJ\} m−2 (125 W/m2) (testing cities), respectively. "
}
@article{Vasiljević20161,
title = "High-accuracy vehicle localization for autonomous warehousing ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "42",
number = "",
pages = "1 - 16",
year = "2016",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2016.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0736584515300314",
author = "Goran Vasiljević and Damjan Miklić and Ivica Draganjac and Zdenko Kovačić and Paolo Lista",
keywords = "High-accuracy localization",
keywords = "Autonomous warehousing",
keywords = "Autonomous ground vehicle ",
abstract = "Abstract The research presented in this paper aims to bridge the gap between the latest scientific advances in autonomous vehicle localization and the industrial state of the art in autonomous warehousing. Notwithstanding great scientific progress in the past decades, industrial autonomous warehousing systems still rely on external infrastructure for obtaining their precise location. This approach increases warehouse installation costs and decreases system reliability, as it is sensitive to measurement outliers and the external localization infrastructure can get dirty or damaged. Several approaches, well studied in scientific literature, are capable of determining vehicle position based only on information provided by on board sensors, most commonly wheel encoders and laser scanners. However, scientific results published to date either do not provide sufficient accuracy for industrial applications, or have not been extensively tested in realistic, industrial-like operating conditions. In this paper, we combine several well established algorithms into a high-precision localization pipeline, capable of computing the pose of an autonomous forklift to sub-centimeter precision. The algorithms use only odometry information from wheel encoders and range readings from an on board laser scanner. The effectiveness of the proposed solution is evaluated by an extensive experiment that lasted for several days, and was performed in a realistic industrial-like environment. "
}
@article{tagkey2010975,
title = "Calendar ",
journal = "Automation in Construction ",
volume = "19",
number = "7",
pages = "975 - ",
year = "2010",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/S0926-5805(10)00124-X",
url = "http://www.sciencedirect.com/science/article/pii/S092658051000124X",
key = "tagkey2010975"
}
@article{Pottmann2005751,
title = "Industrial geometry: recent advances and applications in \{CAD\} ",
journal = "Computer-Aided Design ",
volume = "37",
number = "7",
pages = "751 - 766",
year = "2005",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2004.08.013",
url = "http://www.sciencedirect.com/science/article/pii/S0010448504001988",
author = "H. Pottmann and S. Leopoldseder and M. Hofer and T. Steiner and W. Wang",
keywords = "Geometric optimization",
keywords = "Distance function",
keywords = "Curve approximation",
keywords = "Surface approximation",
keywords = "Active contours",
keywords = "Registration",
keywords = "Feature sensitivity",
keywords = "Mathematical morphology ",
abstract = "Industrial Geometry aims at unifying existing and developing new methods and algorithms for a variety of application areas with a strong geometric component. These include CAD, CAM, Geometric Modelling, Robotics, Computer Vision and Image Processing, Computer Graphics and Scientific Visualization. In this paper, Industrial Geometry is illustrated via the fruitful interplay of the areas indicated above in the context of novel solutions of \{CAD\} related, geometric optimization problems involving distance functions: approximation with general B-spline curves and surfaces or with subdivision surfaces, approximation with special surfaces for applications in architecture or manufacturing, approximate conversion from implicit to parametric (NURBS) representation, and registration problems for industrial inspection and 3D model generation from measurement data. Moreover, we describe a ‘feature sensitive’ metric on surfaces, whose definition relies on the concept of an image manifold, introduced into Computer Vision and Image Processing by Kimmel, Malladi and Sochen. This metric is sensitive to features such as smoothed edges, which are characterized by a significant deviation of the two principal curvatures. We illustrate its applications at hand of feature sensitive curve design on surfaces and local neighborhood definition and region growing as an aid in the segmentation process for reverse engineering of geometric objects. "
}
@article{Borgia20141,
title = "The Internet of Things vision: Key features, applications and open issues ",
journal = "Computer Communications ",
volume = "54",
number = "",
pages = "1 - 31",
year = "2014",
note = "",
issn = "0140-3664",
doi = "https://doi.org/10.1016/j.comcom.2014.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0140366414003168",
author = "Eleonora Borgia",
keywords = "Internet of Things (IoT)",
keywords = "RFIDs",
keywords = "Sensors",
keywords = "Machine-to-Machine (M2M) communications",
keywords = "Standardization ",
abstract = "Abstract The Internet of Things (IoT) is a new paradigm that combines aspects and technologies coming from different approaches. Ubiquitous computing, pervasive computing, Internet Protocol, sensing technologies, communication technologies, and embedded devices are merged together in order to form a system where the real and digital worlds meet and are continuously in symbiotic interaction. The smart object is the building block of the IoT vision. By putting intelligence into everyday objects, they are turned into smart objects able not only to collect information from the environment and interact/control the physical world, but also to be interconnected, to each other, through Internet to exchange data and information. The expected huge number of interconnected devices and the significant amount of available data open new opportunities to create services that will bring tangible benefits to the society, environment, economy and individual citizens. In this paper we present the key features and the driver technologies of IoT. In addition to identifying the application scenarios and the correspondent potential applications, we focus on research challenges and open issues to be faced for the IoT realization in the real world. "
}
@article{Ghidoni201745,
title = "A multi-viewpoint feature-based re-identification system driven by skeleton keypoints ",
journal = "Robotics and Autonomous Systems ",
volume = "90",
number = "",
pages = "45 - 54",
year = "2017",
note = "Special Issue on New Research Frontiers for Intelligent Autonomous Systems ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2016.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0921889016305073",
author = "Stefano Ghidoni and Matteo Munaro",
keywords = "People re-identification",
keywords = "People tracking",
keywords = "Body pose estimation",
keywords = "Camera networks",
keywords = "Multi-view skeletal tracker ",
abstract = "Abstract Thanks to the increasing popularity of 3D sensors, robotic vision has experienced huge improvements in a wide range of applications and systems in the last years. Besides the many benefits, this migration caused some incompatibilities with those systems that cannot be based on range sensors, like intelligent video surveillance systems, since the two kinds of sensor data lead to different representations of people and objects. This work goes in the direction of bridging the gap, and presents a novel re-identification system that takes advantage of multiple video flows in order to enhance the performance of a skeletal tracking algorithm, which is in turn exploited for driving the re-identification. A new, geometry-based method for joining together the detections provided by the skeletal tracker from multiple video flows is introduced, which is capable of dealing with many people in the scene, coping with the errors introduced in each view by the skeletal tracker. Such method has a high degree of generality, and can be applied to any kind of body pose estimation algorithm. The system was tested on a public dataset for video surveillance applications, demonstrating the improvements achieved by the multi-viewpoint approach in the accuracy of both body pose estimation and re-identification. The proposed approach was also compared with a skeletal tracking system working on 3D data: the comparison assessed the good performance level of the multi-viewpoint approach. This means that the lack of the rich information provided by 3D sensors can be compensated by the availability of more than one viewpoint. "
}
@article{Laszlo20081882,
title = "Remote sensing of aerosol and radiation from geostationary satellites ",
journal = "Advances in Space Research ",
volume = "41",
number = "11",
pages = "1882 - 1893",
year = "2008",
note = "",
issn = "0273-1177",
doi = "https://doi.org/10.1016/j.asr.2007.06.047",
url = "http://www.sciencedirect.com/science/article/pii/S0273117707007156",
author = "Istvan Laszlo and Pubu Ciren and Hongqing Liu and Shobha Kondragunta and J. Dan Tarpley and Mitchell D. Goldberg",
keywords = "Aerosol",
keywords = "Shortwave radiation budget",
keywords = "Geostationary satellite ",
abstract = "The paper presents a high-level overview of current and future remote sensing of aerosol and shortwave radiation budget carried out at the \{US\} National Oceanic and Atmospheric Administration (NOAA) from the \{US\} Geostationary Operational Environmental Satellite (GOES) series. The retrievals from the current \{GOES\} imagers are based on physical principles. Aerosol and radiation are estimated in separate processing from the comparison of satellite-observed reflectances derived from a single visible channel with those calculated from detailed radiative transfer. The radiative transfer calculation accounts for multiple scattering by molecules, aerosol and cloud and absorption by the major atmospheric gases. The retrievals are performed operationally every 30 min for aerosol and every hour for radiation for pixel sizes of 4-km (aerosol) and 15- to 50-km (radiation). Both retrievals estimate the surface reflectance as a byproduct from the time composite of clear visible reflectances assuming fixed values of the aerosol optical depth. With the launch of GOES-R \{NOAA\} will begin a new era of geostationary remote sensing. The Advanced Baseline Imager (ABI) onboard GOES-R will offer capabilities for aerosol remote sensing similar to those currently provided by the Moderate Resolution Imaging Spectroradiometer (MODIS) flown on the \{NASA\} Earth Observing System (EOS) satellites. The \{ABI\} aerosol algorithm currently under development uses a multi-channel approach to estimate the aerosol optical depth and aerosol model simultaneously, both over water and land. Its design is strongly inspired by the \{MODIS\} aerosol algorithm. The \{ABI\} shortwave radiation budget algorithm is based on the successful \{GOES\} Surface and Insolation Product system of \{NOAA\} and the \{NASA\} Clouds and the Earth’s Radiant Energy System (CERES), Surface and Atmospheric Radiation Budget (SARB) algorithm. In all phases of the development, the algorithms are tested with proxy data generated from existing satellite observations and forward simulations. Final assessment of the performance will be made after the launch of GOES-R scheduled in 2012. "
}
@article{BenlarbiDelaï1995239,
title = "Telemetric sensors by microwave interferometry ",
journal = "Sensors and Actuators A: Physical ",
volume = "46",
number = "1–3",
pages = "239 - 243",
year = "1995",
note = "",
issn = "0924-4247",
doi = "https://doi.org/10.1016/0924-4247(94)00897-Q",
url = "http://www.sciencedirect.com/science/article/pii/092442479400897Q",
author = "A. Benlarbi-Delaï and J.P. Covillers and Y. Leroy",
keywords = "Anti-collision processes",
keywords = "Localisation",
keywords = "Microwave interferometry",
keywords = "Telemetric sensors ",
abstract = "This paper presents some possibilities offered by a specific microwave sensor called an I-Q demodulator or complex correlator. It is shown that this narrow-band complex correlator is able to provide information about the velocity profile and the position of a monochromatic transmitter which is inside a predefined area; this situation is qualified as cooperative configuration. Nevertheless, this complex correlator can also be used in the situation where only reflected signals are considered — non cooperative configuration — such as in anticollision and level measurement processes. Such sensors can naturally be used in many industrial application fields like robotics, tank gauging and berthing aid. Therefore, to answer industrial requirements, we show in this paper that the necessary compromise between good performance and low cost can be reached. "
}
@article{Myers20122771,
title = "Direct beam and hemispherical terrestrial solar spectral distributions derived from broadband hourly solar radiation data ",
journal = "Solar Energy ",
volume = "86",
number = "9",
pages = "2771 - 2782",
year = "2012",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2012.06.014",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X12002265",
author = "Daryl R. Myers",
keywords = "Spectral distribution",
keywords = "Broadband irradiance",
keywords = "Spectral model",
keywords = "Conversion",
keywords = "TMY",
keywords = "Photovoltaic ",
abstract = "Multiple junction and thin film photovoltaic (PV) technologies respond differently to varying terrestrial spectral distributions of solar energy. \{PV\} device and system designers are concerned with the impact of spectral variation on \{PV\} specific technologies. Spectral distribution data are generally very rare, expensive, and difficult to obtain. We modified an existing empirical spectral conversion model to convert hourly broadband global (total hemispherical) horizontal and direct normal solar radiation to representative spectral distributions. Hourly average total hemispherical and direct normal beam solar radiation, such as provided in Typical Meteorological Year (TMY) data, are spectral model input data. Default or prescribed atmospheric aerosols and water vapor are possible inputs. Individual hourly and monthly and annual average spectral distributions are computed for a specified tilted surface. The spectral range is from 300 nm to 1800 nm. The model is a modified version of the Nann and Riordan \{SEDES2\} model. Measured hemispherical spectral distributions for a wide variety of conditions at the Solar Radiation Research Laboratory at the National Renewable Energy Laboratory, Golden, Co. and Florida Solar Energy Center (Cocoa, FL) show that reasonable spectral accuracy of about ±10% is obtainable with exceptions for weather events such as snow. Differing cloud climatology and variable albedo and aerosol optical depth atmospheric conditions can lead to spectral model differences of 30–40%. "
}
@article{Woods20061390,
title = "Exploring the design space of robots: Children's perspectives ",
journal = "Interacting with Computers ",
volume = "18",
number = "6",
pages = "1390 - 1418",
year = "2006",
note = "Special Issue: Symbiotic Performance between Humans and Intelligent Systems ",
issn = "0953-5438",
doi = "https://doi.org/10.1016/j.intcom.2006.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S095354380600066X",
author = "Sarah Woods",
keywords = "Robots",
keywords = "Child evaluations",
keywords = "Attitudes",
keywords = "Personality",
keywords = "Emotions",
keywords = "Uncanny valley ",
abstract = "Children's perceptions and evaluations of different robot designs are an important unexplored area within robotics research considering that many robots are specifically designed for children. To examine children's feelings and attitudes towards robots, a large sample of children (N = 159) evaluated 40 robot images by completing a questionnaire for each image, which enquired about robot appearance, robot personality dimensions and robot emotions. Results showed that depending on a robot's appearance children clearly distinguished robots in terms of their intentions (i.e. friendly vs. unfriendly), their capability to understand, and their emotional expression. Results of a principal components analysis of the children's ratings of the robots' personality attributes revealed two dimensions labelled ‘Behavioural Intention’ and ‘Emotional Expression’. Robots were classified according to their scores on these two dimensions and a content analysis of their appearance was conducted in an attempt to identify salient features of different robot personalities. Children judged human-like robots as aggressive, but human–machine robots as friendly. Results on children's perceptions of the robots' behavioural intentions provided tentative empirical support for the Uncanny Valley, hypothesized by (Mori, M., 1970), reflecting a situation where robots are very human-like, but still distinguishable from humans, evoking a feeling of discomfort or repulsion. The paper concludes with a discussion of design implications for robots, and the use of robots in educational contexts. "
}
@incollection{Förster2017159,
title = "Chapter 10 - Effects of the Neuro-Turn: The Neural Network as a Paradigm for Human Self-Understanding ",
editor = "Leefmann, Jon  and Hildt, Elisabeth ",
booktitle = "The Human Sciences after the Decade of the Brain ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2017",
pages = "159 - 177",
isbn = "978-0-12-804205-2",
doi = "https://doi.org/10.1016/B978-0-12-804205-2.00010-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780128042052000100",
author = "Y. Förster",
keywords = "Neuroscientific turn",
keywords = "embodiment",
keywords = "ontology",
keywords = "film",
keywords = "philosophy of mind",
keywords = "image",
keywords = "art",
keywords = "human self-understanding ",
abstract = "Abstract This chapter discusses the image of the neural net and its impact on human self-understanding. Neuroscientific imaging techniques produce a wide range of images of the inside of the skull, which not only serve a medical purpose but also begin to fuel our imagination and give the interdisciplinary discussion a new edge. I will elaborate on how philosophy adopts neuroscientific thinking and how art incorporates artificial life. Based on an analysis of the movies Her (2013) and Transcendence (2014), two highly successful Hollywood movies and recent examples from popular culture, I show that these movies invoke a net structure as their leading image, and that it makes a difference whether the image of the brain (body-bound) or of the neural net (not body-bound) is used. Furthermore, the neural net represents an image that suggests the emergence of intelligence, self-organization, and infinity. It is closely intertwined with the Internet, advanced computing, and utopias of immortality. These images, I argue, ultimately suggest a new metaphysical dimension of an omni-present consciousness that permeates being itself. "
}
@article{Zempila2016240,
title = "Modeling the relationship between photosynthetically active radiation and global horizontal irradiance using singular spectrum analysis ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "182",
number = "",
pages = "240 - 263",
year = "2016",
note = "",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0022407316301121",
author = "Melina-Maria Zempila and Michael Taylor and Alkiviadis Bais and Stelios Kazadzis",
keywords = "Photosynthetically active radiation",
keywords = "Global horizontal irradiance",
keywords = "Neural networks",
keywords = "Singular spectrum analysis",
keywords = "Radiative transfer ",
abstract = "Abstract We report on the construction of generic models to calculate photosynthetically active radiation (PAR) from global horizontal irradiance (GHI), and vice versa. Our study took place at stations of the Greek \{UV\} network (UVNET) and the Hellenic solar energy network (HNSE) with measurements from NILU-UV multi-filter radiometers and \{CM\} pyranometers, chosen due to their long (≈1 M record/site) high temporal resolution (≈1 min) record that captures a broad range of atmospheric environments and cloudiness conditions. The uncertainty of the \{PAR\} measurements is quantified to be ±6.5% while the uncertainty involved in \{GHI\} measurements is up to ≈±7% according to the manufacturer. We show how multi-linear regression and nonlinear neural network (NN) models, trained at a calibration site (Thessaloniki) can be made generic provided that the input–output time series are processed with multi-channel singular spectrum analysis (M-SSA). Without M-SSA, both linear and nonlinear models perform well only locally. M-SSA with 50 time-lags is found to be sufficient for identification of trend, periodic and noise components in aerosol, cloud parameters and irradiance, and to construct regularized noise models of \{PAR\} from \{GHI\} irradiances. Reconstructed \{PAR\} and \{GHI\} time series capture ≈95% of the variance of the cross-validated target measurements and have median absolute percentage errors &lt;2%. The intra-site median absolute error of M-SSA processed models were ≈8.2±1.7 W/m2 for \{PAR\} and ≈9.2±4.2 W/m2 for GHI. When applying the models trained at Thessaloniki to other stations, the average absolute mean bias between the model estimates and measured values was found to be ≈1.2 W/m2 for \{PAR\} and ≈0.8 W/m2 for GHI. For the models, percentage errors are well within the uncertainty of the measurements at all sites. Generic \{NN\} models were found to perform marginally better than their linear counterparts. "
}
@article{Roa2009536,
title = "Finding locally optimum force-closure grasps ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "25",
number = "3",
pages = "536 - 544",
year = "2009",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2008.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0736584508000240",
author = "Máximo A. Roa and Raúl Suárez",
keywords = "Grasp planning",
keywords = "Force-closure grasps ",
abstract = "This paper presents an iterative procedure to find locally optimum force-closure grasps on 3D objects, with or without friction and with any number of fingers. The object surface is discretized in a cloud of points, so the approach is applicable to objects with any arbitrary shape. The approach finds an initial force-closure grasp that is then iteratively improved through an oriented search procedure. The grasp quality is measured considering the largest perturbation wrench that the grasp can resist with independence of the direction of perturbation. The efficiency of the algorithm is illustrated through numerical examples. "
}
@article{Simonetto2009138,
title = "Recent Developments in Distributed Particle Filtering: Towards Fast and Accurate Algorithms ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "42",
number = "20",
pages = "138 - 143",
year = "2009",
note = "1st \{IFAC\} Workshop on Estimation and Control of Networked Systems ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090924-3-IT-4005.00024",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015361498",
author = "Andrea Simonetto and Tamás Keviczky",
keywords = "Particle filters",
keywords = "distributed estimation algorithms",
keywords = "distributed particle filters",
keywords = "consensus filters",
keywords = "distributed computation",
keywords = "mobile robot tracking",
keywords = "general purpose \{GPU\} ",
abstract = "Abstract Particle filters have been widely used for the solution of optimal estimation problems in nonlinear non-Gaussian environments. One of their drawbacks is that these methods are computationally expensive. In the past few years, new developments have been made in trying to distribute the particle filter algorithm among different computing agents in order to make the underlying computations tractable. This period also witnessed the rise of general purpose \{GPU\} devices, which are making massive code parallelization possible. These developments have the potential to make the particle filter a viable alternative for real-time implementations in the near future, even when the number of required particles is high. In this paper we review the state-of-the-art in distributed particle filtering and propose a method that is applicable to distributed computing architectures. "
}
@article{Au201630,
title = "Path planning and assembly mode-changes of 6-DOF Stewart-Gough-type parallel manipulators ",
journal = "Mechanism and Machine Theory ",
volume = "106",
number = "",
pages = "30 - 49",
year = "2016",
note = "",
issn = "0094-114X",
doi = "https://doi.org/10.1016/j.mechmachtheory.2016.08.010",
url = "http://www.sciencedirect.com/science/article/pii/S0094114X16301835",
author = "Wesley Au and Hoam Chung and Chao Chen",
keywords = "Stewart-Gough platform",
keywords = "Assembly modes",
keywords = "Path planning",
keywords = "Workspace analysis ",
abstract = "Abstract The Stewart-Gough platform (SGP) is a six degree-of-freedom (DOF) parallel manipulator whose reachable workspace is complex due to its closed-loop configuration and six \{DOF\} outputs. As such, methods of path planning that involve storing the entire reachable workspace in memory at high resolutions are not feasible due to this six-dimensional workspace. In addition, complete path planning algorithms struggle in higher dimensional applications without significant customisations. As a result, many workspace analysis algorithms and path planning schemes use iterative techniques, particularly when tracking the manipulator's many direct kinematic solutions. The aim of this paper is to present the viability of singularity-free path planning in the Stewart-Gough platform's 6-dimensional workspace on modern-day computing systems by demonstrating its assembly mode-changing capability. The entire workspace volume is found using flood-fill algorithms with smooth and singularity-free trajectories generated within this known workspace. Workspace volume analysis was also performed with results comparable to other works. "
}
@article{Dupont2016571,
title = "Role of the boundary layer dynamics effects on an extreme air pollution event in Paris ",
journal = "Atmospheric Environment ",
volume = "141",
number = "",
pages = "571 - 579",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.06.061",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016304940",
author = "J.-C. Dupont and M. Haeffelin and J. Badosa and T. Elias and O. Favez and J.E. Petit and F. Meleux and J. Sciare and V. Crenn and J.L. Bonne",
keywords = "Pollution",
keywords = "Dynamics",
keywords = "Boundary layer depth ",
abstract = "Abstract The physical and chemical aerosol properties are explored here based on ground-based observations in the Paris region to better understand the role of clouds, radiative fluxes and dynamics on aerosol loading during a heavy regional air pollution that occurred in March 2014 over North-Western Europe. This event is primarily characterized by a fine particle mass (PM2.5) increase from 10 to more than 120 μg m−3 and a simultaneous decrease of the horizontal visibility from 40 to 1 km, mainly due to significant formation of ammonium nitrate particles. The aerosol optical depth (AOD) at 550 nm increased steadily from about 0.06 on March 6 to more than 0.9 five days later. The scattering of the solar radiation by polluted particles induced, at the peak of the heavy pollution event, an instantaneous shortwave flux decrease of about 300 W m−2 for direct irradiance and an increase of about 150 W m−2 for diffuse irradiance (only scattering). The mean surface aerosol effect efficiency (effect per unit optical depth) is of about −80 W m−2 with a mean aerosol direct radiative effect of −23 W m−2. The dynamical and radiative processes that can be responsible for the diurnal cycle of PM2.5 in terms of amplitude and timing are investigated. A comparative analysis is performed for 4 consecutive days (between March 11 and 14), showing that the PM2.5 diurnal cycle can be modulated in time and amplitude by local processes such as the boundary layer depth development (ranging from 100 m to 1350 m), surface relative humidity (100%–35%), thermal structure (10 °C–16 °C for day/night amplitude), dynamics (wind speed ranging from 4 m s−1 to 1.5 m s−1) and turbulence (turbulent kinetic energy reaching 2 m2 s−2) near the surface and wind shear along the vertical. Finally, modeled and measured surface PM2.5 loadings are also compared here, notably illustrating the need of accurate boundary layer depth data for efficient air quality forecasts. "
}
@article{Felber2016,
title = "Preface ",
journal = "Information and Computation ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0890-5401",
doi = "https://doi.org/10.1016/j.ic.2015.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0890540116300700",
author = "Pascal Felber and Vijay K. Garg"
}
@article{Aouina20147604,
title = "3D Modeling with a Moving Tilting Laser Sensor for Indoor Environments ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "7604 - 7609",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.00460",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016428119",
author = "A. Aouina and M. Devy and A. Marin Hernandez",
abstract = "Abstract Many works are devoted to 3D modeling of indoor environments from mobile sensors. This function has been performed using multiple robotic platforms, equipped with different types of 3D sensors; many theoretical approaches have been proposed to refine these models, either based on \{SLAM\} algorithms when considering only sparse features, or based of ICP-based methods when a dense model is made from the registration of raw 3D data. This paper presents an approach to build a 3D surfacic model based on planar surfaces, using a tilting \{LRF\} (Laser Range Finder) mounted on the \{PR2\} mobile robot, by the fusion of ribbons (sequence of aligned surfels) extracted from the successive scan lines. These lines are acquired on the fly from the LRF, avoiding a stop and go strategy. The ribbons are aggregated using the robot positions given by a 2D \{SLAM\} process executed independantly and simultaneously; all required information are memorized so that the surfacic model can be corrected when the \{SLAM\} process corrects the robot trajectory after a loop closure. "
}
@article{Tang20091070,
title = "Quantification of edge loss of laser scanned data at spatial discontinuities ",
journal = "Automation in Construction ",
volume = "18",
number = "8",
pages = "1070 - 1083",
year = "2009",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2009.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0926580509001174",
author = "Pingbo Tang and Burcu Akinci and Daniel Huber",
keywords = "Inspection",
keywords = "Quality control",
keywords = "Laser scanning",
keywords = "Mixed-pixel",
keywords = "Spatial discontinuity",
keywords = "Accuracy analysis ",
abstract = "Laser scanning is a promising geometric data collection tool for construction, facility, and infrastructure management due to its fast sampling rate (tens of thousands of measurements per second) and millimeter-level accuracy. However, laser scanned data contains inaccurate data points at spatial discontinuities (object edges). These inaccurate points, known as mixed-pixels, are commonly removed from the data prior to geometric modeling or other downstream processes. The removal of points at the edges of objects introduces error in the geometry of the objects, and object dimensions extracted from the data, such as widths and heights, are usually smaller than the actual values. In many cases, these losses due to removal of points at edges can exceed measurement accuracy tolerances specified in inspection manuals. This paper proposes a model for estimating edge loss in laser scanned data by considering the impacts of various factors, such as scanning distance, density of data and incidence angle on the edge loss. Results from a series of controlled experiments showed that the developed model successfully predicted edge losses in most test cases. Evaluation results using data collected from job sites showed that this model reduced the measurement error due to edge loss by an average of 80% for dense point clouds collected by an amplitude modulated continuous wave (AMCW) scanner, and 38% for relatively sparse point clouds collected by a pulsed time of flight (PTOF) scanner. By adding the estimated edge losses back into the raw dimensional measurements using the developed model, it is possible to significantly improve the accuracy of related measurements and hence improve the accuracy of the geometric information extracted from laser scanned data. "
}
@article{Schlenoff20131159,
title = "Ubiquitous robots (UBIROBOTS) workshop at the \{UBICOMP\} 2012 conference ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "11",
pages = "1159 - 1161",
year = "2013",
note = "Ubiquitous Robotics ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.04.018",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013000808",
author = "Craig Schlenoff and Abdelghani Chibani and Edson Prestes and Yacine Amirat"
}
@article{Keller2009967,
title = "Real-time simulation of time-of-flight sensors ",
journal = "Simulation Modelling Practice and Theory ",
volume = "17",
number = "5",
pages = "967 - 978",
year = "2009",
note = "",
issn = "1569-190X",
doi = "https://doi.org/10.1016/j.simpat.2009.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S1569190X09000331",
author = "Maik Keller and Andreas Kolb",
keywords = "Sensor simulation",
keywords = "Time-of-flight",
keywords = "Photonic Mixing Device",
keywords = "Real-time simulation",
keywords = "GPU programming ",
abstract = "Today’s time-of-flight (TOF) sensors measure full-range distance information by estimating the elapsed time between emission and receiving of active light in real-time. Such sensors are inexpensive, compact, and they have a high performance, which especially fits real-time applications, e.g. in the fields of automotive, robotics, 3D imaging, and visualization. The simulation of such sensors is an essential building block for hardware design and application development. Therefore, the simulation data must capture the major sensor characteristics. This paper introduces a simulation approach, which is motivated by physics, for the Photonic Mixing Device (PMD) sensor which is a specific type of time-of-flight sensor. Dynamic motion blurring and resolution artifacts such as flying pixels as well as the typical deviation error are prominent effects of real world systems. Flying pixels arise when an area of inhomogeneous depth is covered by a single PMD-pixel whereas the deviation error is based on the anharmonic properties of the optical signal. The modeling of these artifacts is essential for an authentic simulation approach. We present a detailed comparison between a real PMD-device and the simulation data regarding the sensor characteristics. The proposed algorithms are implemented in a hardware accelerated solution which makes use of the programmability of modern Graphics Processing Units (GPUs). This way, an interactive simulation feedback is provided for applications and further data processing. The simulation takes place in real-time and thus all required control mechanisms are accessible in real-time, too. "
}
@article{Choi2016595,
title = "RGB-D object pose estimation in unstructured environments ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
number = "",
pages = "595 - 613",
year = "2016",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.09.020",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015002158",
author = "Changhyun Choi and Henrik I. Christensen",
keywords = "Pose estimation",
keywords = "RGB-D",
keywords = "Voting scheme",
keywords = "Hough transform",
keywords = "Range sensing",
keywords = "GPU",
keywords = "Parallelization",
keywords = "Bin-picking ",
abstract = "Abstract We present an object pose estimation approach exploiting both geometric depth and photometric color information available from an RGB-D sensor. In contrast to various efforts relying on object segmentation with a known background structure, our approach does not depend on the segmentation and thus exhibits superior performance in unstructured environments. Inspired by a voting-based approach employing an oriented point pair feature, we present a voting-based approach which further incorporates color information from the RGB-D sensor and which exploits parallel power of the modern parallel computing architecture. The proposed approach is extensively evaluated with three state-of-the-art approaches on both synthetic and real datasets, and our approach outperforms the other approaches in terms of both computation time and accuracy. "
}
@article{Scherer20121545,
title = "Autonomous landing at unprepared sites by a full-scale helicopter ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "12",
pages = "1545 - 1562",
year = "2012",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001509",
author = "Sebastian Scherer and Lyle Chamberlain and Sanjiv Singh",
keywords = "UAV",
keywords = "Rotorcraft",
keywords = "3D perception",
keywords = "Lidar",
keywords = "Landing zone selection ",
abstract = "Helicopters are valuable since they can land at unprepared sites; however, current unmanned helicopters are unable to select or validate landing zones (LZs) and approach paths. For operation in unknown terrain it is necessary to assess the safety of a LZ. In this paper, we describe a lidar-based perception system that enables a full-scale autonomous helicopter to identify and land in previously unmapped terrain with no human input. We describe the problem, real-time algorithms, perception hardware, and results. Our approach has extended the state of the art in terrain assessment by incorporating not only plane fitting, but by also considering factors such as terrain/skid interaction, rotor and tail clearance, wind direction, clear approach/abort paths, and ground paths. In results from urban and natural environments we were able to successfully classify \{LZs\} from point cloud maps. We also present results from 8 successful landing experiments with varying ground clutter and approach directions. The helicopter selected its own landing site, approaches, and then proceeds to land. To our knowledge, these experiments were the first demonstration of a full-scale autonomous helicopter that selected its own landing zones and landed. "
}
@article{Busis2010395,
title = "Mobile Phones to Improve the Practice of Neurology ",
journal = "Neurologic Clinics ",
volume = "28",
number = "2",
pages = "395 - 410",
year = "2010",
note = "Practice Management in Neurology ",
issn = "0733-8619",
doi = "https://doi.org/10.1016/j.ncl.2009.11.001",
url = "http://www.sciencedirect.com/science/article/pii/S0733861909001091",
author = "Neil Busis",
keywords = "Mobile phones",
keywords = "Smartphones",
keywords = "Information technology",
keywords = "Neurology practice "
}
@article{Zhang201444,
title = "Estimation of forest aboveground biomass in California using canopy height and leaf area index estimated from satellite data ",
journal = "Remote Sensing of Environment ",
volume = "151",
number = "",
pages = "44 - 56",
year = "2014",
note = "Special Issue on 2012 ForestSAT ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2014.01.025",
url = "http://www.sciencedirect.com/science/article/pii/S0034425714000558",
author = "Gong Zhang and Sangram Ganguly and Ramakrishna R. Nemani and Michael A. White and Cristina Milesi and Hirofumi Hashimoto and Weile Wang and Sassan Saatchi and Yifan Yu and Ranga B. Myneni",
keywords = "Aboveground biomass",
keywords = "Leaf area index",
keywords = "Canopy height",
keywords = "Landsat",
keywords = "Uncertainty assessment ",
abstract = "Abstract Accurate characterization of variability and trends in forest biomass at local to national scales is required for accounting of global carbon sources and sinks and monitoring their dynamics. Here we present a new remote sensing based approach for estimating live forest aboveground biomass (AGB) based on a simple parametric model that combines high-resolution estimates of leaf area index (LAI) from the Landsat Thematic Mapper sensor and canopy maximum height from the Geoscience Laser Altimeter System (GLAS) sensor onboard ICESat, the Ice, Cloud, and land Elevation Satellite. We tested our approach with a preliminary uncertainty assessment over the forested areas of California spanning a broad range of climatic and land-use conditions and find our \{AGB\} estimates to be comparable to estimates of \{AGB\} from inventory records and other available satellite-estimated \{AGB\} maps at aggregated scales. Our study offers a high-resolution approach to map forest aboveground biomass at regional-to-continental scales and assess sources of uncertainties in the estimates. "
}
@article{Heldmann2015262,
title = "Evolution of the dust and water ice plume components as observed by the \{LCROSS\} visible camera and UV–visible spectrometer ",
journal = "Icarus ",
volume = "254",
number = "",
pages = "262 - 275",
year = "2015",
note = "",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2015.02.026",
url = "http://www.sciencedirect.com/science/article/pii/S0019103515000780",
author = "Jennifer L. Heldmann and Justin Lamb and Daniel Asturias and Anthony Colaprete and David B. Goldstein and Laurence M. Trafton and Philip L. Varghese",
keywords = "Moon",
keywords = "Spectroscopy",
keywords = "Moon, surface",
keywords = "Regoliths",
keywords = "Ices ",
abstract = "Abstract The \{LCROSS\} (Lunar Crater Observation and Sensing Satellite) impacted the Cabeus crater near the lunar South Pole on 9 October 2009 and created an impact plume that was observed by the \{LCROSS\} Shepherding Spacecraft. Here we analyze data from the ultraviolet–visible spectrometer and visible context camera aboard the spacecraft. We use these data to constrain a numerical model to understand the physical evolution of the resultant plume. The UV–visible light curve peaks in brightness 18 s after impact and then decreases in radiance but never returns to the pre-impact radiance value for the ∼4 min of observation by the Shepherding Spacecraft. The blue:red spectral ratio increases in the first 10 s, decreases over the following 50 s, remains constant for approximately 150 s, and then begins to increase again ∼180 s after impact. Constraining the modeling results with spacecraft observations, we conclude that lofted dust grains remained suspended above the lunar surface for the entire 250 s of observation after impact. The impact plume was composed of both a high angle spike and low angle plume component. Numerical modeling is used to evaluate the relative effects of various plume parameters to further constrain the plume properties when compared with the observational data. Dust particle sizes lofted above the lunar surface were micron to sub-micron in size. Water ice particles were also contained within the ejecta cloud and simultaneously photo-dissociated and sublimated after reaching sunlight. "
}
@article{Viejo2012138,
title = "Using \{GNG\} to improve 3D feature extraction—Application to 6DoF egomotion ",
journal = "Neural Networks ",
volume = "32",
number = "",
pages = "138 - 146",
year = "2012",
note = "Selected Papers from \{IJCNN\} 2011 ",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2012.02.014",
url = "http://www.sciencedirect.com/science/article/pii/S0893608012000433",
author = "Diego Viejo and Jose Garcia and Miguel Cazorla and David Gil and Magnus Johnsson",
keywords = "Egomotion",
keywords = "GNG",
keywords = "3D feature extraction",
keywords = "6DoF registration ",
abstract = "Several recent works deal with 3D data in mobile robotic problems, e.g. mapping or egomotion. Data comes from any kind of sensor such as stereo vision systems, time of flight cameras or 3D lasers, providing a huge amount of unorganized 3D data. In this paper, we describe an efficient method to build complete 3D models from a Growing Neural Gas (GNG). The \{GNG\} is applied to the 3D raw data and it reduces both the subjacent error and the number of points, keeping the topology of the 3D data. The \{GNG\} output is then used in a 3D feature extraction method. We have performed a deep study in which we quantitatively show that the use of \{GNG\} improves the 3D feature extraction method. We also show that our method can be applied to any kind of 3D data. The 3D features obtained are used as input in an Iterative Closest Point (ICP)-like method to compute the 6DoF movement performed by a mobile robot. A comparison with standard \{ICP\} is performed, showing that the use of \{GNG\} improves the results. Final results of 3D mapping from the egomotion calculated are also shown. "
}
@article{Ramisa2014246,
title = "Learning RGB-D descriptors of garment parts for informed robot grasping ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "35",
number = "",
pages = "246 - 258",
year = "2014",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2014.06.025",
url = "http://www.sciencedirect.com/science/article/pii/S095219761400147X",
author = "Arnau Ramisa and Guillem Alenyà and Francesc Moreno-Noguer and Carme Torras",
keywords = "Computer vision",
keywords = "Pattern recognition",
keywords = "Machine learning",
keywords = "Garment part detection",
keywords = "Classification",
keywords = "Bag of Visual Words ",
abstract = "Abstract Robotic handling of textile objects in household environments is an emerging application that has recently received considerable attention thanks to the development of domestic robots. Most current approaches follow a multiple re-grasp strategy for this purpose, in which clothes are sequentially grasped from different points until one of them yields a desired configuration. In this work we propose a vision-based method, built on the Bag of Visual Words approach, that combines appearance and 3D information to detect parts suitable for grasping in clothes, even when they are highly wrinkled. We also contribute a new, annotated, garment part dataset that can be used for benchmarking classification, part detection, and segmentation algorithms. The dataset is used to evaluate our approach and several state-of-the-art 3D descriptors for the task of garment part detection. Results indicate that appearance is a reliable source of information, but that augmenting it with 3D information can help the method perform better with new clothing items. "
}
@article{DurgaPrasad201210,
title = "An ambient light sensing module for wireless sensor networks for planetary exploration ",
journal = "Planetary and Space Science ",
volume = "70",
number = "1",
pages = "10 - 19",
year = "2012",
note = "",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2012.06.012",
url = "http://www.sciencedirect.com/science/article/pii/S0032063312001833",
author = "K. Durga Prasad and A. Bhattacharya and S.V.S. Murty",
keywords = "Ambient light sensing",
keywords = "Planetary exploration",
keywords = "Wireless sensor networks",
keywords = "Moon light variations ",
abstract = "A sensitive ambient light sensing module with wide dynamic range has been designed for planetary wireless sensor networks. Its performance has been evaluated under different illumination conditions. Variations in ambient light intensities from &lt;1 to 1.2×105 lx could be detected from dawn to dusk, including cloud obstructions during monsoon. Moon light variations during the waning phase and total lunar eclipse have been monitored to demonstrate detection of finer variations. The module is capable of registering the fine variations in ambient light expected on different planetary surfaces. This module along with other sensors integrated into a Wireless Sensor Network (WSN) would be a suitable prospective tool for many future planetary exploration tasks. "
}
@incollection{Bedkowski2011591,
title = "26 - Using the \{NVIDIA\} \{CUDA\} programme to develop cognitive supervision of multi robot systems ",
editor = "Baudoin, Y. and ,  and Habib, Maki K. ",
booktitle = "Using Robots in Hazardous Environments ",
publisher = "Woodhead Publishing",
edition = "",
address = "",
year = "2011",
pages = "591 - 598",
isbn = "978-1-84569-786-0",
doi = "https://doi.org/10.1533/9780857090201.5.591",
url = "http://www.sciencedirect.com/science/article/pii/B9781845697860500265",
author = "J. Bedkowski and A. Masłowski",
keywords = "mobile robot control",
keywords = "supervision ",
abstract = "Abstract: This chapter describes the \{CUDA\} application in the cognitive theory-based approach to multi mobile robot control. The model of the cognitive supervisor and its main role in the robotic system is described. The new capabilities derived from the usage of \{GPU\} architecture give an opportunity for real time computation in 3D map building. The idea of real time 3D map reconstruction and analysis by autonomous navigation module is also shown. The need for supervision of the navigation module is presented. The experiments based on simulated and real environment prove the advantage of cognitive supervision. Furthermore the \{CUDA\} application shows new capabilities for robotic applications. The robot’s task can be achieved quickly and the environmental map can be stored and reconstructed with high precision. The robot can be navigated autonomously in a complex and unstructured environment even from an onboard \{PC\} or remotely, therefore the approach supports the autonomous tele-operation of a remotely controlled robot by the robot assistant. Thus, any problems in communication with the base station can be partially managed. "
}
@article{Kang201629,
title = "Long-term (2002–2014) evolution and trend in Collection 5.1 Level-2 aerosol products derived from the \{MODIS\} and \{MISR\} sensors over the Chinese Yangtze River Delta ",
journal = "Atmospheric Research ",
volume = "181",
number = "",
pages = "29 - 43",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2016.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0169809516301612",
author = "Na Kang and K. Raghavendra Kumar and Kang Hu and Xingna Yu and Yan Yin",
keywords = "MODIS",
keywords = "Aerosol optical depth",
keywords = "Trend analysis",
keywords = "Aerosol type",
keywords = "HYSPLIT",
keywords = "East China ",
abstract = "Abstract The present study aims to investigate spatio-temporal evolution and trend in the aerosol optical properties (aerosol optical depth, AOD; Ångström exponent, AE), qualitatively identify different types and origin of aerosols over an urban city, Nanjing in the Yangtze River Delta, East China. For this purpose, the Collection 5.1 Level-2 data obtained from the Moderate resolution Imaging Spectroradiometer (MODIS) sensor onboard Terra and Aqua satellites and the Multi-angle Imaging Spectroradiometer (MISR) instrument for the period between 2002 and 2014 have been analyzed. An inter-comparison and validation of \{AOD\} were performed against the \{AOD\} measurements obtained from the ground-based Aerosol Robotic Network (AERONET) sunphotometer. The \{MODIS\} \{AOD550\} exhibited wide spatial and temporal distributions over East China, while \{MISR\} \{AOD555\} was consistently lower than that of Terra and Aqua \{AOD550\} values. The temporal variations (monthly and seasonal mean) of \{MODIS\} (Terra and Aqua) and \{MISR\} \{AOD\} values exhibited a similar pattern. The seasonal mean \{AOD550\} (AE470–660) was found to be maximum with 0.97 ± 0.48 during summer (1.16 ± 0.33 in summer) and a minimum of 0.61 ± 0.28 during the winter season (0.80 ± 0.28 in spring). The annual mean Terra \{AOD550\} at Nanjing showed a strong decreasing trend (− 0.70% year− 1), while the Aqua exhibited a slight increasing trend (+ 0.01 year− 1) during the study period. Seasonal air mass back-trajectories obtained from the Hybrid Single Particle Lagrangian Integrated Trajectory (HYSPLIT) model were also computed to infer on the transport component over the study region. Different aerosol types were identified via the relationship between \{AOD550\} and fine mode fraction, which reveals that the biomass burning/urban-industrial type aerosols (desert dust) are abundant over the region in summer (spring), apart from the mixed aerosol type. "
}
@article{Li2016142,
title = "Design and application of parallel stereo matching algorithm based on \{CUDA\} ",
journal = "Microprocessors and Microsystems ",
volume = "47, Part A",
number = "",
pages = "142 - 150",
year = "2016",
note = "",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2015.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0141933115001489",
author = "Ge Li and Xuehe Zhang and Changle Li and Hongzhe Jin and Jie Zhao",
keywords = "CUDA",
keywords = "Parallel processing",
keywords = "Stereo matching",
keywords = "Binocular vision",
keywords = "Bayes",
keywords = "Adaptive weight ",
abstract = "Abstract To accurately construct the topographic information of a six-legged walking robot in real time, this study proposes a stereo matching algorithm that can conduct disparity estimation on each pixel by using the Bayesian posterior probability model based on GPU-accelerated parallel processing. In the proposed algorithm, supporting points construct a disparity space to obtain the prior distribution probability density of each pixel and then substitute it into the Bayesian posterior probability model to establish the energy function of the disparity. The estimated disparity value of the unknown pixel can be obtained by minimizing the energy function. By performing a consistency check on the left and right sides of an image, the mismatching pixel can be eliminated. According to the disparity value of the supporting point, the disparity filling of the mismatching area can be achieved by applying the adaptive weight method on the basis of cross extending to obtain the accurate density of the disparity map. Parallel computing in each stage of the proposed algorithm is performed by using the compute unified device architecture to reduce the running time. Experimental results show that the proposed algorithm has good robustness for different illuminations and texture curved surface reconstruction. The algorithm can also adapt to the fast matching of images in different sizes and reconstruct the disparity map of scenes in real time under the resolution ratio of 640 × 480. The stereoscopic vision test board is employed to construct the disparity map of real scenes and verify the practical application effect of the algorithm. Good experiment effect is achieved. "
}
@article{Stocker201427,
title = "Representing situational knowledge acquired from sensor data for atmospheric phenomena ",
journal = "Environmental Modelling & Software ",
volume = "58",
number = "",
pages = "27 - 47",
year = "2014",
note = "",
issn = "1364-8152",
doi = "https://doi.org/10.1016/j.envsoft.2014.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S1364815214001108",
author = "Markus Stocker and Elham Baranizadeh and Harri Portin and Mika Komppula and Mauno Rönkkö and Amar Hamed and Annele Virtanen and Kari Lehtinen and Ari Laaksonen and Mikko Kolehmainen",
keywords = "Environmental sensor networks",
keywords = "Sensor data",
keywords = "Knowledge acquisition",
keywords = "Knowledge representation",
keywords = "Atmospheric phenomena ",
abstract = "Abstract A recurrent problem in applications that build on environmental sensor networks is that of sensor data organization and interpretation. Organization focuses on, for instance, resolving the syntactic and semantic heterogeneity of sensor data. The distinguishing factor between organization and interpretation is the abstraction from sensor data with information acquired from sensor data. Such information may be situational knowledge for environmental phenomena. We discuss a generic software framework for the organization and interpretation of sensor data and demonstrate its application to data of a large scale sensor network for the monitoring of atmospheric phenomena. The results show that software support for the organization and interpretation of sensor data is valuable to scientists in scientific computing workflows. Explicitly represented situational knowledge is also useful to client software systems as it can be queried, integrated, reasoned, visualized, or annotated. "
}
@article{Delhaye201748,
title = "The \{MERMOSE\} project: Characterization of particulate matter emissions of a commercial aircraft engine ",
journal = "Journal of Aerosol Science ",
volume = "105",
number = "",
pages = "48 - 63",
year = "2017",
note = "",
issn = "0021-8502",
doi = "https://doi.org/10.1016/j.jaerosci.2016.11.018",
url = "http://www.sciencedirect.com/science/article/pii/S0021850216302233",
author = "David Delhaye and François-Xavier Ouf and Daniel Ferry and Ismael K. Ortega and Olivier Penanhoat and Samuel Peillon and François Salm and Xavier Vancassel and Cristian Focsa and Cornelia Irimiea and Nadine Harivel and Bruno Perez and Etienne Quinton and Jérôme Yon and Daniel Gaffie",
keywords = "Aircraft engine \{PM\} emission",
keywords = "Soot",
keywords = "Size distributions",
keywords = "Physico-chemical characterization ",
abstract = "Abstract The French national project \{MERMOSE\} gathers the capabilities of seven organizations to better characterize commercial aircraft engine emissions and to better understand their impact on nucleation processes in the atmosphere. In this frame, a measurement campaign has been performed on a Snecma/NPO Saturn SaM146-1S17 turbofan. During this work, we used a complete set of on-line and off-line techniques to measure radial and angular profiles of particulate matter (PM) properties in the engine exhaust hot flow. We studied different engine thrust settings, selected to match the aircraft main operating conditions (idle, climb, take-off, approach and “ground” cruise). The mode of the emitted particles size distribution ranged from 17 nm to 55 nm and was sensitive to the thrust. The sampled \{PM\} showed a complex morphology and were formed by primary nanoparticles of about 15 nm in diameter. They were mainly composed of carbon (with traces of oxygen, sulfur and calcium) and their organic carbon to total carbon ratio (OC/TC) ratio showed a decrease as a function of the maximum thrust from ~80% for 30% thrust setting to ~12% for 100%. "
}
@article{Vijayakumar2014650,
title = "Type-segregated aerosol effects on regional monsoon activity: A study using ground-based experiments and model simulations ",
journal = "Atmospheric Environment ",
volume = "99",
number = "",
pages = "650 - 659",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.10.022",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014008115",
author = "K. Vijayakumar and P.C.S. Devara and S.M. Sonbawne",
keywords = "Cimel sun-sky radiometer",
keywords = "Aerosol types",
keywords = "Monsoon rainfall",
keywords = "MACC aerosol reanalysis",
keywords = "Cluster trajectory analysis",
keywords = "DREAM simulations ",
abstract = "Abstract Classification of observed aerosols into key types [e.g., clean-maritime (CM), desert-dust (DD), urban-industrial/biomass-burning (UI/BB), black carbon (BC), organic carbon (OC) and mixed-type aerosols (MA)] would facilitate to infer aerosol sources, effects, and feedback mechanisms, not only to improve the accuracy of satellite retrievals but also to quantify the assessment of aerosol radiative impacts on climate. In this paper, we report the results of a study conducted in this direction, employing a Cimel Sun-sky radiometer at the Indian Institute of Tropical Meteorology (IITM), Pune, India during 2008 and 2009, which represent two successive contrasting monsoon years. The study provided an observational evidence to show that the local sources are subject to heavy loading of absorbing aerosols (dust and black carbon), with strong seasonality closely linked to the monsoon annual rainfall cycle over Pune, a tropical urban station in India. The results revealed the absence of \{CM\} aerosols in the pre-monsoon as well as in the monsoon seasons of 2009 as opposed to 2008. Higher loading of dust aerosols is observed in the pre-monsoon and monsoon seasons of 2009; majority may be coated with fine \{BC\} aerosols from local emissions, leading to reduction in regional rainfall. Further, significant decrease in coarse-mode \{AOD\} and presence of carbonaceous aerosols, affecting the aerosol–cloud interaction and monsoon-rain processes via microphysics and dynamics, is considered responsible for the reduction in rainfall during 2009. Additionally, we discuss how optical depth, contributed by different types of aerosols, influences the distribution of monsoon rainfall over an urban region using the Monitoring Atmospheric Composition and Climate (MACC) aerosol reanalysis. Furthermore, predictions of the Dust \{REgional\} Atmospheric Model (DREAM) simulations combined with \{HYSPLIT\} (HYbrid Single Particle Lagrangian Integrated Trajectory) cluster model are also discussed in support of the observed features. "
}
@article{Guzzi20015079,
title = "Aerosol maps from \{GOME\} data ",
journal = "Atmospheric Environment ",
volume = "35",
number = "30",
pages = "5079 - 5091",
year = "2001",
note = "Visibility, Aerosol and Atmospheric Optics ",
issn = "1352-2310",
doi = "https://doi.org/10.1016/S1352-2310(01)00324-7",
url = "http://www.sciencedirect.com/science/article/pii/S1352231001003247",
author = "Rodolfo Guzzi and Giovanni Ballista and Walter Di Nicolantonio and Elisa Carboni",
keywords = "Aerosol optical depth",
keywords = "Atmospheric radiative transfer",
keywords = "Earth observation",
keywords = "Remote-sensing calibration",
keywords = "Sea reflectance ",
abstract = "In this paper, we present a methodology to calibrate the surface reflectance seen by satellite and validate the aerosol optical properties retrieved by the \{GOME\} instrument. Data are also visualized in maps by a tool properly developed, named GOMEView. The validation procedure is based on ground measurements obtained by sunphotometers. Results show that calibration of the surface reflectance is crucial to obtain the best results, i.e. in agreement with the ground measurements. Aerosol data have also been classified on the basis of their optical properties evidencing for instance, the presence of desert aerosol over the sea along the west coast of Sahara. Cloud retrievals were also analyzed in terms of their occurrence and amount. "
}
@article{Wang201686,
title = "Evolution of particulate sulfate and nitrate along the Asian dust pathway: Secondary transformation and primary pollutants via long-range transport ",
journal = "Atmospheric Research ",
volume = "169, Part A",
number = "",
pages = "86 - 95",
year = "2016",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2015.09.013",
url = "http://www.sciencedirect.com/science/article/pii/S0169809515002938",
author = "Qiongzhen Wang and Guoshun Zhuang and Kan Huang and Tingna Liu and Yanfen Lin and Congrui Deng and Qingyan Fu and Joshua S. Fu and Jiakuan Chen and Wenjie Zhang and Mijiti Yiming",
keywords = "Sulfate",
keywords = "Nitrate",
keywords = "Source",
keywords = "Formation mechanism",
keywords = "Long-range/regional transport ",
abstract = "Abstract Both PM2.5 and \{TSP\} over Yulin, a rural site near the Asian dust source region, were collected from 2007 to 2009. Characteristics, sources, and formation mechanisms of sulfate and nitrate were investigated. \{SO42\} − displayed a distinct seasonal variation with the highest average concentration observed in summer when \{SO42\} − accounted for an average of 14.1% and 13.7% of the PM2.5 and \{PMcoarse\} mass concentrations, respectively. Ambient temperature and relative humidity were two important factors influencing the formation processes of \{SO42\} − and NO3−. In summer, the high concentrations of \{SO42\} − in PM2.5 were probably from the gas phase oxidation of SO2, while the low concentrations of NO3− in PM2.5 were attributed to the high temperature that was not favorable for the formation of NH4NO3. In spring, autumn, and winter, \{SO42\} − and NO3− were significantly enhanced in those days with high relative humidity, implying that in-cloud/aqueous processing dominated the formations of \{SO42\} − and NO3−. Different from PM2.5 in which NH4+ acted as the dominant neutralizer for acids, alkaline species such as Ca2 + and Mg2 + played an important role in the formation of sulfate and nitrate salts in coarse particles throughout the whole year. During the dust event days, \{SO42\} − in coarse particles significantly increased, while black carbon and NO3− largely decreased, suggesting that the primary mineral dust could be one of the major sources of \{SO42\} −. By comparing the mass ratio of \{SO42\} −/3/S in the dust aerosols of Yulin with different dust source regions (i.e., Taklimakan Desert and Gobi Desert) and the application of air mass backward trajectory analysis, it was found the long-range transported dust from the Taklimakan Desert, which was rich in primary sulfate due to its paleo-ocean characteristics, was a non-negligible source of \{SO42\} − over Yulin. In spring and winter, the prevailing northerlies and northwesterlies promoted chemical interaction between alkaline mineral dust and acid gaseous precursors from local and/or regional emissions. While in summer, regional transport facilitated by the southerlies and southeasterlies may contribute to the high secondary aerosol concentrations over Yulin. This study demonstrated that a considerable portion of aerosol over a Chinese rural area could be derived from complex chemical reactions via long-range/regional transport. "
}
@article{Xue2012387,
title = "Autonomous grasp and manipulation planning using a ToF camera ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "387 - 395",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001448",
author = "Zhixing Xue and Steffen W. Ruehl and Andreas Hermann and Thilo Kerscher and Ruediger Dillmann",
keywords = "Manipulation planning",
keywords = "Grasp planning",
keywords = "Time-of-flight sensors",
keywords = "Impedance control ",
abstract = "A time-of-flight camera can help a service robot to sense its 3D environment. In this paper, we introduce our methods for sensor calibration and 3D data segmentation to use it to automatically plan grasps and manipulation actions for a service robot. Impedance control is intensively used to further compensate the modeling error and to apply the computed forces. The methods are further demonstrated in three service robotic applications. Sensor-based motion planning allows the robot to move within dynamic and cluttered environment without collision. Unknown objects can be detected and grasped. In the autonomous ice cream serving scenario, the robot captures the surface of ice cream and plans a manipulation trajectory to scoop a portion of ice cream. "
}
@article{HarrisonIII2015110,
title = "Virtual Fusion: State of the Art in Component Simulation/Emulation for Manufacturing ",
journal = "Procedia Manufacturing ",
volume = "1",
number = "",
pages = "110 - 121",
year = "2015",
note = "43rd North American Manufacturing Research Conference, \{NAMRC\} 43, 8-12 June 2015, \{UNC\} Charlotte, North Carolina, United States ",
issn = "2351-9789",
doi = "https://doi.org/10.1016/j.promfg.2015.09.069",
url = "http://www.sciencedirect.com/science/article/pii/S2351978915010690",
author = "William S. Harrison III and Frederick Proctor",
keywords = "Simulation",
keywords = "Manufacturing",
keywords = "Virtual Fusion ",
abstract = "Abstract Simulation is an indispensable part of design and analysis in a near infinite space of applications. Every day, simulation is applied to new problems as well as giving further insight into existing ones. Additionally, advancements in computing have enabled simulation to continue contributing understanding in areas where it is already a ubiquitous tool. Manufacturing in particular has benefited a great deal from simulation techniques ranging from Finite Element Analysis (FEA) for product design, to Discrete Event Simulations (DES) for process planning. In recent times emulation has emerged as an effective means of process validation. Emulation typically refers to a testing process where the controllers or control code are in their final state, while the components they control are still virtual. Virtual Fusion takes this one step further in creating a Hybrid Process Simulation (HPS), where any component of the process may be physically present or completely simulated. This paper first defines and then discusses the characteristics necessary for the component simulations needed in an HPS. It then follows with a technological survey, a literature review of existing tools, and concludes with research challenges. "
}
@article{Dudai2014254,
title = "To Simulate or Not to Simulate: What Are the Questions? ",
journal = "Neuron ",
volume = "84",
number = "2",
pages = "254 - 261",
year = "2014",
note = "",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2014.09.031",
url = "http://www.sciencedirect.com/science/article/pii/S0896627314008514",
author = "Yadin Dudai and Kathinka Evers",
abstract = "Simulation is a powerful method in science and engineering. However, simulation is an umbrella term, and its meaning and goals differ among disciplines. Rapid advances in neuroscience and computing draw increasing attention to large-scale brain simulations. What is the meaning of simulation, and what should the method expect to achieve? We discuss the concept of simulation from an integrated scientific and philosophical vantage point and pinpoint selected issues that are specific to brain simulation. "
}
@article{Baraskar201636,
title = "An offline constrained data assimilation technique for aerosols: Improving \{GCM\} simulations over South Asia using observations from two satellite sensors ",
journal = "Atmospheric Environment ",
volume = "132",
number = "",
pages = "36 - 48",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.02.026",
url = "http://www.sciencedirect.com/science/article/pii/S135223101630139X",
author = "Ankit Baraskar and Mani Bhushan and Chandra Venkataraman and Ribu Cherian",
keywords = "Aerosol optical depth",
keywords = "Aerosol absorption optical depth",
keywords = "Data assimilation",
keywords = "Quadratic programming",
keywords = "Radiative forcing ",
abstract = "Abstract Aerosol properties simulated by general circulation models (GCMs) exhibit large uncertainties due to biases in model processes and inaccuracies in aerosol emission inputs. In this work, we propose an offline, constrained optimization based procedure to improve these simulations by assimilating them with observational data. The proposed approach explicitly incorporates the non-negativity constraint on the aerosol optical depth (AOD) which is a key metric to quantify aerosol distributions. The resulting optimization problem is quadratic programming in nature and can be easily solved by available optimization routines. The utility of the approach is demonstrated by performing offline assimilation of \{GCM\} simulated aerosol optical properties and radiative forcing over South Asia (40–120 E, 5–40 N), with satellite \{AOD\} measurements from two sensors, namely Moderate Resolution Imaging SpectroRadiometer (MODIS) and Multi-Angle Imaging SpectroRadiometer (MISR). Uncertainty in observational data used in the assimilation is computed by developing different error bands around regional \{AOD\} observations, based on their quality assurance flags. The assimilation, evaluated on monthly and daily scales, compares well with Aerosol Robotic Network (AERONET) observations as determined by goodness of fit statistics. Assimilation increased both model predicted atmospheric absorption and clear sky radiative forcing by factors consistent with recent estimates in literature. Thus, the constrained assimilation algorithm helps in systematically reducing uncertainties in aerosol simulations. "
}
@article{tagkey2016iii,
title = "Contents ",
journal = "Future Generation Computer Systems ",
volume = "64",
number = "",
pages = "iii - iv",
year = "2016",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/S0167-739X(16)30222-9",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16302229",
key = "tagkey2016iii"
}
@article{Kim2016131,
title = "Weighted joint-based human behavior recognition algorithm using only depth information for low-cost intelligent video-surveillance system ",
journal = "Expert Systems with Applications ",
volume = "45",
number = "",
pages = "131 - 141",
year = "2016",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2015.09.035",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415006648",
author = "Hanguen Kim and Sangwon Lee and Youngjae Kim and Serin Lee and Dongsung Lee and Jinsun Ju and Hyun Myung",
keywords = "Video-surveillance system",
keywords = "Human joint estimation",
keywords = "Behavior recognition",
keywords = "Human-computer interaction (HCI) ",
abstract = "Abstract Recent advances in 3D depth sensors have created many opportunities for security, surveillance, and entertainment. The 3D depth sensors provide more powerful monitoring systems for dangerous situations irrespective of lighting conditions in buildings or production facilities. To robustly recognize emergency actions or hazardous situations of workers at a production facility, we present human joint estimation and behavior recognition algorithms that solely use depth information in this paper. To estimate human joints on a low cost computing platform, we propose a human joint estimation algorithm that integrates a geodesic graph and a support vector machine (SVM). The human feature points are extracted within a range of geodesic distance from a geodesic graph. The geodesic graph is used for optimizing the estimation result. The SVM-based human joint estimator uses randomly selected human features to reduce computation. Body parts that typically involve many motions are then estimated by the geodesic distance value. The proposed algorithm can work for any human without calibration, and thus the system can be used with any subject immediately even with a low cost computing platform. In the case of the behavior recognition algorithm, the algorithm should have a simple behavior registration process, and it also should be robust to environmental changes. To meet these goals, we propose a template matching-based behavior recognition algorithm. Our method creates a behavior template set that consists of weighted human joint data with scale and rotation invariant properties. A single behavior template consists of the joint information that is estimated per frame. Additionally, we propose adaptive template rejection and a sliding window filter to prevent misrecognition between similar behaviors. The human joint estimation and behavior recognition algorithms are evaluated individually through several experiments and the performance is proven through a comparison with other algorithms. The experimental results show that our method performs well and is applicable in real environments. "
}
@article{Yue2014104,
title = "Fast 3D modeling in complex environments using a single Kinect sensor ",
journal = "Optics and Lasers in Engineering ",
volume = "53",
number = "",
pages = "104 - 111",
year = "2014",
note = "",
issn = "0143-8166",
doi = "https://doi.org/10.1016/j.optlaseng.2013.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S0143816613002522",
author = "Haosong Yue and Weihai Chen and Xingming Wu and Jingmeng Liu",
keywords = "3D modeling",
keywords = "Frame alignment",
keywords = "Feature extraction",
keywords = "Traversable areas analysis ",
abstract = "Abstract Three-dimensional (3D) modeling technology has been widely used in inverse engineering, urban planning, robot navigation, and many other applications. How to build a dense model of the environment with limited processing resources is still a challenging topic. A fast 3D modeling algorithm that only uses a single Kinect sensor is proposed in this paper. For every color image captured by Kinect, corner feature extraction is carried out first. Then a spiral search strategy is utilized to select the region of interest (ROI) that contains enough feature corners. Next, the iterative closest point (ICP) method is applied to the points in the \{ROI\} to align consecutive data frames. Finally, the analysis of which areas can be walked through by human beings is presented. Comparative experiments with the well-known KinectFusion algorithm have been done and the results demonstrate that the accuracy of the proposed algorithm is the same as KinectFusion but the computing speed is nearly twice of KinectFusion. 3D modeling of two scenes of a public garden and traversable areas analysis in these regions further verified the feasibility of our algorithm. "
}
@article{Wang20117406,
title = "Comparison of aerosol optical properties from Beijing and Kanpur ",
journal = "Atmospheric Environment ",
volume = "45",
number = "39",
pages = "7406 - 7414",
year = "2011",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.06.055",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011006674",
author = "Shupeng Wang and Li Fang and Xingfa Gu and Tao Yu and Jun Gao",
keywords = "Aerosol",
keywords = "Optical property",
keywords = "Single scattering albedo",
keywords = "Aerosol classification",
keywords = "Beijing",
keywords = "Kanpur ",
abstract = "Aerosol Robotic Network (AERONET) aerosol optical depth (AOD) and almucantar retrievals (single scattering albedo (SSA) and aerosol size distribution) from 2005–2009 in Beijing and Kanpur are used to analyze differences and similarities in aerosol optical properties over these two regions. The examination of monthly mean \{AOD\} (440 nm) shows that maximum and minimum values occurred in summer and winter, respectively, for Beijing, while the range in \{AOD\} in Kanpur was lower. Precipitation in both Beijing and Kanpur peaked in summer; however, the columnar water vapor (CWV) exhibited a high correlation with \{AOD\} in Beijing (R2 = 0.79) but had a weak relationship with \{AOD\} in Kanpur (R2 = 0.13). The Angstrom exponent (α, 440–870 nm) generally increased linearly as the fine mode fraction (FMF) of \{AOD\} (500 nm) increased for FMF &lt; 90% in both regions, with a high correlation of R2 &gt; 0.96. However a clear decrease in α for \{FMF\} &gt; 90% found in Beijing is not shown distinctly in Kanpur, and is mainly due to the higher aerosol loading in this \{FMF\} bin at Beijing (AOD at 440 nm &gt; 2.2) which results in a stronger coagulation of fine mode particles. Bimodal seasonally-averaged size distributions reveals similar aerosol mixtures composed of fine pollution particles and coarse dust particles in both regions. The analysis of spectral \{SSA\} as a function of α is emphasized in this paper. The average \{SSA\} at 440 nm in both regions shows a similar low dynamic range of ∼0.03 for α &lt; 1.4. The obvious increase in \{SSA\} at 440 nm for α &gt; 1.4 in both regions can be attributed to a higher \{FMF\} leading to fine mode coagulation. However, the distinctly smaller increase in Kanpur suggests that fine mode aerosols at Beijing are less absorbing than those at Kanpur. The visibly lower \{SSA\} at 675 nm at Kanpur compared to that at Beijing for α &gt; 0.4 is due to a larger find-coarse mode separation radius of ∼0.76 μm in Beijing versus a value lower than ∼0.58 μm in Kanpur. Another reason lies in the weaker absorption by fine mode aerosols in Beijing. The distinctly lower near-infrared \{SSA\} in Kanpur when α &lt; 1.4, compared to Beijing, may be attributed to lower aerosol concentrations in all α bins, resulting in less aggregation of absorbing black carbon particles on coarse particles in Kanpur. The classification of aerosol properties shows that the \{AOD\} accumulation mode in all seasons, even including spring, in Beijing and in post-monsoon and winter seasons in Kanpur can be attributed to fine particle coagulation or hygroscopic growth; during pre-monsoon and monsoon seasons in Kanpur, it is due to coarse mode particle accumulation or cloud contamination. "
}
@article{Carabali2017,
title = "Aerosol climatology over the Mexico City basin: Characterization of optical properties ",
journal = "Atmospheric Research ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2017.04.035",
url = "http://www.sciencedirect.com/science/article/pii/S0169809517304829",
author = "Giovanni Carabali and Héctor Raúl Estévez and Mauro Valdés-Barrón and Roberto Bonifaz-Alfonzo and David Riveros-Rosas and Víctor Manuel Velasco-Herrera and Felipe Adrián Vázquez-Gálvez",
keywords = "Mexico City",
keywords = "Aerosols",
keywords = "Climatology",
keywords = "AOD",
keywords = "Ångström exponent",
keywords = "Single Scattering Albedo (SSA) ",
abstract = "Abstract Climatology of Aerosol Optical Depth (AOD), Single Scattering Albedo (SSA), and aerosol particle-size distribution were analyzed using a 15-year (1999–2014) dataset from \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) observations over the Mexico City (MC) basin. The atmosphere over this site is dominated by two main aerosol types, represented by urban/industrial pollution and biomass-burning particles. Due to the specific meteorological conditions within the basin, seasons are usually classified into three as follows: Dry Winter (DW) (November–February); Dry Spring (DS) (March–April), and the \{RAiny\} season (RA) (May–October), which are mentioned throughout this article. Using a \{CIMEL\} sun photometer, we conducted continuous observations over the \{MC\} urban area from January 1999 to December 2014. Aerosol Optical Depth (AOD), Ångström exponent (α440–870), Single Scattering Albedo (SSA), and aerosol particle-size distribution were derived from the observational data. The overall mean \{AOD500\} during the 1999–2014 period was 0.34 ± 0.07. The monthly mean \{AOD\} reached a maximal value of 0.49 in May and a minimal value of 0.27 in February and March. The average α440–870 value for the period studied was 1.50 ± 0.16. The monthly average of α440–870 reached a minimal value of 1.32 in August and a maximal value of 1.61 in May. Average \{SSA\} at 440 nm was 0.89 throughout the observation period, indicating that aerosols over Mexico City are composed mainly of absorptive particles. Concentrations of fine- and coarse-mode aerosols over \{MC\} were highest in \{DS\} season compared with other seasons, especially for particles with radii measuring between 0.1 and 0.2 μm. Results from the Spectral De-convolution Algorithm (SDA) show that fine-mode aerosols dominated \{AOD\} variability in MC. In the final part of this article, we present a classification of aerosols in \{MC\} by using the graphical method proposed by Gobbi et al. (2007), which is based on the combined analysis of α and its spectral curvature δα. "
}
@article{Claverie2015390,
title = "Evaluation of the Landsat-5 \{TM\} and Landsat-7 \{ETM\} + surface reflectance products ",
journal = "Remote Sensing of Environment ",
volume = "169",
number = "",
pages = "390 - 403",
year = "2015",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2015.08.030",
url = "http://www.sciencedirect.com/science/article/pii/S0034425715301188",
author = "Martin Claverie and Eric F. Vermote and Belen Franch and Jeffrey G. Masek",
keywords = "Validation",
keywords = "Surface reflectance",
keywords = "BRDF",
keywords = "Landsat",
keywords = "MODIS ",
abstract = "Abstract Maintaining consistent datasets of Surface Reflectance (SR) is an important challenge to ensure long-term quality of Climate Data Records. The Landsat 5 and 7 archives offer a unique data source to monitor globally the land surface at high spatial resolution. The Landsat-5 \{TM\} and Landsat-7 \{ETM\} + \{SR\} products, derived from the on-demand processing Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS), require periodic evaluation to check the data consistency. Two evaluation approaches are presented in this paper. The first approach used the Aerosol Robotic Network (AERONET) data set for the period 2000 to 2013 over 489 sites with 3600 Landsat-5 \{TM\} and Landsat-7 \{ETM\} + scenes selected. For each scene, 10 × 10 km subsets of LEDAPS-derived Landsat \{SR\} and AERONET-derived \{SR\} are compared. The latter are computed using Landsat top of atmosphere reflectance, \{AERONET\} measurements of atmospheric parameters, and the 6S radiative transfer model. Second, we introduce a methodology to cross-compare Landsat data and \{MODIS\} data acquired on the same day. The analysis is based on 4000 random Landsat scenes globally distributed from 2000 to 2013. This method includes: (i) a surface anisotropy adjustment, based on the \{VJB\} Bidirectional Reflectance Distribution Function (BRDF) method, to adjust Terra and Aqua \{MODIS\} data to Landsat 5 and 7 sun-view geometry, (ii) a spectral adjustment based on an artificial neural network trained with the \{PROSAIL\} vegetation radiative transfer model, to adjust \{MODIS\} data to \{TM\} and \{ETM\} + spectral responses. The overall results of both approaches show a good match in over 80% of the scenes, i.e. the \{TM\} and \{ETM\} + \{SR\} uncertainty remained within the \{SR\} specification, defined as 0.05 × \{SR\} + 0.005. The worst results are found in the blue band used in \{LEDAPS\} to adjust the Aerosol Optical Thickness (AOT). The MODIS-Landsat \{SR\} cross-comparison confirms the utility of a \{BRDF\} adjustment method to decrease the scattering between Landsat sensors and \{MODIS\} sensors (Terra and Aqua). The spectral adjustment removes part of the biases related to spectral response differences. Global analysis is used to identify \{AOT\} retrieval issues over specific scenes, mostly over bright surfaces. From 2000 to 2013, no significant temporal variation of the performance is detected, which enhanced the consistency of LEDAPS-derived surface reflectance data set. "
}
@article{Obregón2015404,
title = "Aerosol radiative effects during two desert dust events in August 2012 over the Southwestern Iberian Peninsula ",
journal = "Atmospheric Research ",
volume = "153",
number = "",
pages = "404 - 415",
year = "2015",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2014.10.007",
url = "http://www.sciencedirect.com/science/article/pii/S0169809514003767",
author = "M.A. Obregón and S. Pereira and V. Salgueiro and M.J. Costa and A.M. Silva and A. Serrano and D. Bortoli",
keywords = "Dust aerosols",
keywords = "Radiative forcing",
keywords = "libRadtran model ",
abstract = "Abstract This study provides an analysis of desert dust aerosol radiative effects in the shortwave solar spectrum. For this purpose, the aerosol radiative forcing (ARF) at the earth's surface was calculated during two desert dust events that occurred during August 2012 over Badajoz (Spain) and Évora (Portugal), both stations are located in southwestern Iberian Peninsula. Aerosol properties from these two \{AERONET\} stations have been employed to feed the libRadtran model used to simulate irradiances in the shortwave range at the surface under cloud-free conditions. In addition, simulated irradiances for Évora have been compared with Eppley pyranometer measurements. Simulated irradiance values have been used to calculate \{ARF\} values at both sites. The overall mean simulated \{ARF\} values for Évora and Badajoz during the first event are − 43.03 and − 43.76 W m− 2, respectively, while, for the second event, the overall mean values are − 19.73 and − 26.07 W m− 2, respectively, indicating that the first event has a greater regional radiative impact than the second one, causing a more pronounced radiate cooling at the surface. The \{ARF\} per unit of aerosol optical depth (AOD), called the aerosol radiative forcing efficiency (ARFE), is also evaluated for this shortwave spectral range. The \{ARFE\} values obtained for Évora and Badajoz during the first event are − 112.93 ± 6.60 W m− 2 and − 101.63 ± 10.73 W m− 2 per unit of \{AOD\} (500 nm), respectively, and, for the second event, − 92.44 ± 9.82 W m− 2 and − 87.85 ± 10.19 W m− 2 per unit of \{AOD\} (500 nm), respectively. These values also confirm the previous results, i.e., the first event causes a greater radiate cooling than the second one in both stations, although the second desert dust event is more intense, i.e., with higher aerosol optical depth and \{PM10\} aerosol mass concentration. The presence of absorbing aerosols, together with dust, near the surface during the first event may explain the greater efficiency of this aerosol mixture to reduce the downward shortwave irradiance reaching the surface, inducing a greater radiative cooling than the second event. "
}
@article{Mandal2000479,
title = "A novel FEM-based dynamic framework for subdivision surfaces ",
journal = "Computer-Aided Design ",
volume = "32",
number = "8–9",
pages = "479 - 497",
year = "2000",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/S0010-4485(00)00037-3",
url = "http://www.sciencedirect.com/science/article/pii/S0010448500000373",
author = "C. Mandal and H. Qin and B.C. Vemuri",
keywords = "Physics-based modeling",
keywords = "Geometric modeling",
keywords = "Computer graphics",
keywords = "CAGD",
keywords = "Subdivision surfaces",
keywords = "Deformable models",
keywords = "Dynamics",
keywords = "Finite elements",
keywords = "Interactive techniques ",
abstract = "Recursive subdivision on an initial control mesh generates a visually pleasing smooth surface in the limit. Nevertheless, users must carefully specify the initial mesh and/or painstakingly manipulate the control vertices at different levels of subdivision hierarchy to satisfy a diverse set of functional requirements and aesthetic criteria in the limit shape. This modeling drawback results from the lack of direct manipulation tools for the limit geometric shape. To improve the efficiency of interactive geometric modeling and engineering design, in this paper we integrate novel physics-based modeling techniques with powerful geometric subdivision principles, and develop a unified finite element method (FEM)-based methodology for arbitrary subdivision schemes. Strongly inspired by the recent research on Dynamic Non-Uniform Rational B-Splines (D-NURBS), we formulate and develop a dynamic framework that permits users to directly manipulate the limit surface obtained from any subdivision procedure via simulated “force” tools. The most significant contribution of our unified approach is the formulation of the limit surface of an arbitrary subdivision scheme as being composed of a single type of novel finite element. The specific geometric and dynamic features of our subdivision-based finite elements depend on the subdivision scheme used. We present our novel \{FEM\} for the modified butterfly and Catmull–Clark subdivision schemes, and generalize our dynamic framework to be applicable to other subdivision schemes. Our FEM-based approach significantly advances the state-of-the-art in physics-based geometric modeling since it provides a universal physics-based framework for any subdivision scheme. In addition, we systematically devise a mechanism that allows users to directly (not via control meshes) deform any subdivision surface; finally, we represent the limit surface of any subdivision scheme using a collection of subdivision-based novel finite elements. Our experiments demonstrate that the new unified FEM-based framework not only promises a greater potential for subdivision techniques in solid modeling, finite element analysis, and engineering design, but that it will further foster the applicability of subdivision geometry in a wide range of visual computing applications such as visualization, virtual reality, computer graphics, computer vision, robotics, and medical imaging as well. "
}
@article{Lu2011320,
title = "Two-wavelength lidar inversion algorithm for determination of aerosol extinction-to-backscatter ratio and its application to \{CALIPSO\} lidar measurements ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "112",
number = "2",
pages = "320 - 328",
year = "2011",
note = "International Symposium on Atmospheric Light Scattering and Remote Sensing (ISALSaRS’09) ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2010.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0022407310003067",
author = "Xiaomei Lu and Yuesong Jiang and Xuguo Zhang and Xuan Wang and Nicola Spinelli",
keywords = "Lidar",
keywords = "Aerosols",
keywords = "Lidar ratio",
keywords = "Dust ",
abstract = "A modified two-wavelength lidar inversion algorithm is proposed to aid in the retrieval of aerosol extinction-to-backscatter ratios (lidar ratio) as well as backscatter coefficients and extinction color ratios from simultaneous two-wavelength elastic backscatter lidar measurements. To demonstrate the feasibility of the algorithm, both the Raman method and the two-wavelength method have been applied to the ground-based measurements at 355 and 532 nm; moreover, it has been applied to the data acquired by the Cloud Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) lidar, and to the simultaneous ground-based lidar measurements carried out at Napoli (southern Italy, 40.838 °N, 14.183 °E, 118 m above sea level). Three cases of Saharan dust transport towards Europe have been considered. From the comparison, it can be found that the values of lidar ratio and backscatter coefficient retrieved by the modified two-wavelength algorithm are in good agreement with those obtained by the Raman method. Moreover the retrieved mean values of the lidar ratios and color ratios are in agreement with those reported by other authors. "
}
@article{Perry2015167,
title = "Impact of a fire burn on solar irradiance and \{PV\} power ",
journal = "Solar Energy ",
volume = "114",
number = "",
pages = "167 - 173",
year = "2015",
note = "",
issn = "0038-092X",
doi = "https://doi.org/10.1016/j.solener.2015.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0038092X15000067",
author = "Matthew Perry and Alberto Troccoli",
keywords = "Smoke aerosols",
keywords = "Fire burn",
keywords = "Solar irradiance",
keywords = "Photovoltaic power ",
abstract = "Abstract Aerosols produced by fire burns can have marked impacts on \{PV\} power production. Here we take advantage of an isolated, short-lived but well monitored fire burn event during an otherwise clear sky day – a case of a serendipitous ‘earth experiment’ – to study its impact on both solar irradiance and solar power recorded at the nearby solar lab. The local council controlled burns happened at Black Mountain in Canberra, Australia. Evidence from the solar lab sky-camera images was used to confirm that the sky was clear of clouds during the late afternoon of 4th March 2014 so that the effect of the smoke plume could be isolated, and to observe the development of the plume. Global and direct irradiance observations were compared with those from analogous clear days, as well as with values obtained from a clear sky model, in order to estimate the reduction in irradiance due to the smoke plume. The results showed that global irradiance was reduced by 6.5% and direct irradiance by 9% during a 140 min afternoon period, with one-minute reductions of up to 26% and 32% respectively. The spectral global irradiance showed that the smoke had the greatest impact in the wavelength range from 400 to 500 nm. A spectral analysis of the impact of smoke on six different \{PV\} technologies revealed that the least impact was on the mono-silicon cells used in this study. The resulting effect of solar power output was an overall reduction of 7% during the study period and a peak reduction of 27%. "
}
@article{tagkey2011311,
title = "Calendar ",
journal = "Automation in Construction ",
volume = "20",
number = "3",
pages = "311 - ",
year = "2011",
note = "Augmented and Virtual Reality in Architecture, Engineering and Construction (CONVR2009) ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/S0926-5805(11)00025-2",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000252",
key = "tagkey2011311"
}
@article{tagkey2011225,
title = "Calendar ",
journal = "Automation in Construction ",
volume = "20",
number = "2",
pages = "225 - ",
year = "2011",
note = "Building Information Modeling and Changing Construction Practices ",
issn = "0926-5805",
doi = "https://doi.org/10.1016/S0926-5805(11)00011-2",
url = "http://www.sciencedirect.com/science/article/pii/S0926580511000112",
key = "tagkey2011225"
}
@article{Sturm2009536,
title = "An appearance-based visual compass for mobile robots ",
journal = "Robotics and Autonomous Systems ",
volume = "57",
number = "5",
pages = "536 - 545",
year = "2009",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001577",
author = "J. Sturm and A. Visser",
keywords = "Appearance-based",
keywords = "Mobile robot localization",
keywords = "Active vision",
keywords = "Machine learning ",
abstract = "Localization is one of the most important basic skills of a mobile robot. Most approaches, however, still rely either on special sensors or require artificial environments. In this article, a novel approach is presented that can provide compass information for localization, purely based on the visual appearance of a room. A robot using such a visual compass can quickly learn a cylindrical map of the environment, consisting of simple statistical features that can be computed very quickly. The visual compass algorithm is efficient, scalable and can therefore be used in real-time on almost any contemporary robotic platform. Extensive experiments on a Sony Aibo robot have validated that the approach works in a vast variety of environments. "
}
@article{Yin201595,
title = "Retrievals and uncertainty analysis of aerosol single scattering albedo from \{MFRSR\} measurements ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "150",
number = "",
pages = "95 - 106",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part I ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.08.012",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003562",
author = "Bangsheng Yin and Qilong Min and Everette Joseph",
keywords = "MFRSR",
keywords = "Single scattering albedo",
keywords = "Diffuse-direct ratio",
keywords = "Aerosol optical depth",
keywords = "Angstrom coefficient ",
abstract = "Abstract Aerosol single scattering albedo (SSA) can be retrieved from the ratio of diffuse horizontal and direct normal fluxes measured from multifilter rotating shadowband radiometer (MFRSR). In this study, the measurement channels at 415 nm and 870 nm are selected for aerosol optical depth (AOD) and Angstrom coefficient retrievals, and the measurements at 415 nm are used for aerosol \{SSA\} retrievals with the constraint of retrieved Angstrom coefficient. We extensively assessed various issues impacting on the accuracy of \{SSA\} retrieval from measurements to input parameters and assumptions. For cloud-free days with mean aerosol loading of 0.13–0.60, our sensitivity study indicated that: (1) 1% calibration uncertainty can result in 0.8–3.7% changes in retrieved SSA; (2) without considering the cosine respond correction and/or forward scattering correction will result in underestimation of 1.1–3.3% and/or 0.73% in retrieved SSA; (3) an overestimation of 0.1 in asymmetry factor can result in an underestimation of 2.54–3.4% in retrieved SSA; (4) for small aerosol loading (e.g., 0.13), the uncertainty associated with the choice of Rayleigh optical depth value can result in non-negligible change in retrieved \{SSA\} (e.g., 0.015); (5) an uncertainty of 0.05 for surface albedo can result in changes of 1.49–5.4% in retrieved SSA. We applied the retrieval algorithm to the \{MFRSR\} measurements at the Atmospheric Radiation Measurements (ARM) Southern Great Plains (SGP) site. The retrieved results of AOD, Angstrom coefficient, and \{SSA\} are basically consistent with other independent measurements from co-located instruments at the site. "
}
@article{Brownell20161238,
title = "From matter to x-matter: Exploring the newfound capacities of information-enhanced materials ",
journal = "Materials & Design ",
volume = "90",
number = "",
pages = "1238 - 1247",
year = "2016",
note = "",
issn = "0264-1275",
doi = "https://doi.org/10.1016/j.matdes.2015.03.027",
url = "http://www.sciencedirect.com/science/article/pii/S0261306915001168",
author = "Blaine Brownell",
keywords = "Information architecture",
keywords = "Internet of Things",
keywords = "Radical atoms",
keywords = "SPIME",
keywords = "Tangible bits ",
abstract = "Abstract The physical materials and processes used to design and construct the built environment reveal the growing application of information technology enhancements. Such materials and methods effectively represent a kind of expanded matter (x-matter), insofar as their functionality has been augmented with increased capabilities not found in their traditional, unembellished counterparts. Despite the importance of this transformation, which has been fueled by the growth of communications and computing technologies, there is a lack of scholarship concerning a holistic evaluation of this phenomenon and its future implications—particularly from the perspective of material-focused fields such as architecture and product design. This essay therefore offers a concise proposal for a comprehensive framework in which to understand the evolving relationships between matter and information, aimed towards individuals within built environment-related disciplines. Fundamental areas of material-information interaction, or capacities of x-matter, are illustrated by representative examples, in addition to considerations of historical precedents and future opportunities. "
}
@article{Cazacu201557,
title = "\{AERONET\} data investigation of the aerosol mixtures over Iasi area, One-year time scale overview ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "153",
number = "",
pages = "57 - 64",
year = "2015",
note = "Topical issue on optical particle characterization and remote sensing of the atmosphere: Part \{II\} ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2014.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022407314003756",
author = "Mihai Marius Cazacu and Adrian Timofte and Florin Unga and Bogdan Albina and Silviu Gurlui",
keywords = "AERONET",
keywords = "Meteorological data",
keywords = "Tropospheric aerosols",
keywords = "Optical-properties",
keywords = "Saharan dust",
keywords = "Atmospheric models ",
abstract = "Abstract In order to analyze the troposphere dynamics under particular conditions in North-East region of Romania, various types of aerosols chemical compositions have been studied using complementary techniques. Thus, the seasonal trends of aerosols and its external influences have been studied using aerosol optical properties retrieved from Aerosol Robotic Network (AERONET). Complementary studies were taken into account by using several meteorological factors, computational models and meteorological data. Moreover, this paper presents optical properties analysis of different types of aerosols and the seasonal variability of them in one year of measurements. The major categories of aerosol types are evidenced, such as urban/industrial aerosol, biomass burning and mineral dust. "
}
@article{Gandhi20151199,
title = "Ndvi: Vegetation Change Detection Using Remote Sensing and Gis – A Case Study of Vellore District ",
journal = "Procedia Computer Science ",
volume = "57",
number = "",
pages = "1199 - 1210",
year = "2015",
note = "3rd International Conference on Recent Trends in Computing 2015 (ICRTC-2015) ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.07.415",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915019444",
author = "G. Meera Gandhi and S. Parthiban and Nagaraj Thummalu and A. Christy",
keywords = "NDVI",
keywords = "Remote Sensing",
keywords = "Landsat images",
keywords = "Change Detection",
keywords = "vegetation Index ",
abstract = "Abstract This article presents an enhanced Change Detection method for the analysis of Satellite image based on Normalized Difference Vegetation Index (NDVI). \{NDVI\} employs the Multi-Spectral Remote Sensing data technique to find Vegetation Index, land cover classification, vegetation, water bodies, open area, scrub area, hilly areas, agricultural area, thick forest, thin forest with few band combinations of the remote sensed data. Land Resources are easily interpreted by computing their Normalized Difference Vegetation Index for Land Cover classification. Remote Sensing data from Landsat \{TM\} image along with \{NDVI\} and \{DEM\} data layers have been used to perform multi-source classification. The Change Detection method used was \{NDVI\} differencing. \{NDVI\} method is applied according to its characteristic like vegetation at different \{NDVI\} threshold values such as 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4 and 0.5. The Simulation results show that the \{NDVI\} is highly useful in detecting the surface features of the visible area which are extremely beneficial for policy makers in decision making. The Vegetation analysis can be helpful in predicting the unfortunate natural disasters to provide humanitarian aid, damage assessment and furthermore to device new protection strategies. From the empirical study, the forest or shrub land and Barren land cover types have decreased by about 6% and 23% from 2001 to 2006 respectively, while agricultural land, built-up and water areas have increased by about 19%, 4% and 7% respectively. Curvature, Plan curvature, Profile curvature and Wetness Index areas are also estimated. "
}
@incollection{Conway2017,
title = "Supramolecular \{DNA\} Nanotechnology ",
editor = "",
booktitle = "Reference Module in Chemistry, Molecular Sciences and Chemical Engineering ",
publisher = "Elsevier",
edition = "",
address = "",
year = "2017",
pages = " - ",
isbn = "978-0-12-409547-2",
doi = "https://doi.org/10.1016/B978-0-12-409547-2.12548-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012409547212548X",
author = "J.W. Conway and H. Sleiman",
keywords = "Amphiphilic molecules",
keywords = "Cholesterol",
keywords = "Displacement strands",
keywords = "DNA nanotechnology",
keywords = "DNA origami",
keywords = "Drug delivery",
keywords = "Hydrogen bond",
keywords = "Nanomaterials",
keywords = "Phospholipids",
keywords = "Supramolecular chemistry ",
abstract = "Abstract Deoxyribonucleic acid (DNA) has evolved in nature to store and transfer the genetic information of most life on earth. The fidelity of information processing relies on the precise pairing through noncovalent interactions of a molecular code consisting of four unique nucleobases. By using this programmability \{DNA\} can be taken out of its biological context and used as building material for the programmable assembly of nanostructures. The routine automated synthesis of \{DNA\} has allowed researchers to explore many different \{DNA\} architecture designs and applications leading to the creation of the diverse field now termed \{DNA\} nanotechnology. \{DNA\} nanotechnology has generated many examples of scaffolds, cages, and networks able to precisely position molecules for applications in therapeutics, diagnostics, light-harvesting devices, nanopatterning, and even molecular computing. This article begins by discussing the origins and evolution of the field of \{DNA\} nanotechnology and focuses on introducing the three major divisions of this field: \{DNA\} tile, origami, and supramolecular \{DNA\} assembly. Each of these respective divisions will be thoroughly discussed using specific case study examples demonstrating how \{DNA\} nanotechnology has developed and advanced in technological complexity and functionality. Following this discussion, we will examine \{DNA\} nanotechnology applications in various multidisciplinary scientific fields. Particular focus will be given to \{DNA\} nanotechnology interfaced with biological systems such as templating lipid bilayers for hierarchical self-assembly schemes and development of robust therapeutic delivery methods. "
}
@article{Marco2013205,
title = "Notes on a Robust Plane Detection Approach in 3D. ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "46",
number = "10",
pages = "205 - 210",
year = "2013",
note = "8th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20130626-3-AU-2035.00014",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015349338",
author = "Tommaso De Marco and Cosimo Distante and Giovanni Indiveri",
keywords = "Computer vision",
keywords = "Robust estimation",
keywords = "Entropy",
keywords = "Cameras",
keywords = "Parameter estimation ",
abstract = "Abstract This paper addresses the issue of plane detection in 3 dimensional (3D) range images. The identification of planar structures is a crucial task in many visual-aided autonomous robotic applications. The proposed method consists in implementing, in cascade, two algorithms: Random Sample and Consensus (RANSAC) and the more recent Least Entropy-like Estimator (LEL), a nonlinear prediction error estimator that minimizes a cost function inspired by the definition of Gibbs entropy. \{LEL\} estimators allow to improve \{RANSAC\} performances while maintaining its robustness; kernel density estimation is used to classify data into inliers and outliers. The method has been experimentally applied to 3D images acquired by a Time-Of-Flight camera and compared with a stand alone \{RANSAC\} solution. The proposed solution does not require an accurate estimation of the noise variance or outlier scale. This is of fundamental practical importance as the outlier scale, while severely influencing standard RANSAC, is usually unknown a priori and hard to estimate. "
}
@article{Morales201674,
title = "Safe and reliable navigation in crowded unstructured pedestrian areas ",
journal = "Engineering Applications of Artificial Intelligence ",
volume = "49",
number = "",
pages = "74 - 87",
year = "2016",
note = "",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2015.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0952197615002638",
author = "N. Morales and R. Arnay and J. Toledo and A. Morell and L. Acosta",
keywords = "Autonomous vehicles",
keywords = "Path planning",
keywords = "Unstructured environments",
keywords = "Obstacle avoidance ",
abstract = "Abstract In this paper, the navigation system of the autonomous vehicle prototype Verdino is introduced. Two navigation levels are considered. In the first level, a trajectory is generated from the current position toward a goal that considers two different approaches. In the first, the minimum cost path is obtained using a classical approach (used for regular navigation). The second approach is a little more complex, relying on a set of precomputed primitives representing the motion model of the vehicle, which are used as part of an ARA⁎ algorithm in order to find the best trajectory. This trajectory consists of both forward and backward motion segments for complex maneuvers. In the second level, a local planner is in charge of computing the commands sent to the vehicle in order to follow the trajectory. A set of tentative local trajectories is computed in the Frenét space and scored using several factors, described in this paper. Some results for the two navigation levels are shown at the end of this document. For the global planner, several examples of the maneuvers obtained are shown and certain related factors are quantified and compared. As for the local planner, a study on the influence of the defined weights on the vehicle׳s final behavior is presented. Also, from these tests several configurations have been chosen and ranked according to two different proposed behaviors. The navigation system shown has been tested both in simulated and in real conditions, and the attached video shows the vehicle׳s real-world performance. "
}
@article{Ros2014707,
title = "Adaptive human–robot interaction in sensorimotor task instruction: From human to robot dance tutors ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "6",
pages = "707 - 720",
year = "2014",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.03.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014000499",
author = "Raquel Ros and Ilaria Baroni and Yiannis Demiris",
keywords = "Child–robot interaction",
keywords = "Adaptive behavior",
keywords = "Dance",
keywords = "Involvement measure ",
abstract = "Abstract We explore the potential for humanoid robots to interact with children in a dance activity. In this context, the robot plays the role of an instructor to guide the child through several dance moves to learn a dance phrase. We participated in 30 dance sessions in schools to study human–human interaction between children and a human dance teacher, and to identify the applied methodologies. Based on the strategies observed, both social and task-dependent, we implemented a robotic system capable of autonomously instructing dance sequences to children while displaying basic social cues to engage the child in the task. Experiments were performed in a hospital with the Nao robot interacting with 12 children through multiple encounters, when possible (18 sessions, 236 min). Observational analysis through video recordings and survey evaluations were used to assess the quality of interaction. Moreover, we introduce an involvement measure based on the aggregation of observed behavioral cues to assess the level of interest in the interaction through time. The analysis revealed high levels of involvement, while highlighting the need for further research into social engagement and adaptation with robots over repeated sessions. "
}
@article{Eizicovits201698,
title = "Integration of perception capabilities in gripper design using graspability maps ",
journal = "Biosystems Engineering ",
volume = "146",
number = "",
pages = "98 - 113",
year = "2016",
note = "Special Issue: Advances in Robotic Agriculture for Crops ",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2015.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015001956",
author = "Danny Eizicovits and Bart van Tuijl and Sigal Berman and Yael Edan",
keywords = "Gripper design",
keywords = "Grasping",
keywords = "Sensing",
keywords = "Sweet-pepper harvesting",
keywords = "Agricultural robots ",
abstract = "Agricultural environments impose high demands on robotic grippers since the objects to be grasped (e.g., fruit) suffer from inherent uncertainties in size, shape, weight, and texture, are typically highly sensitive to excessive force, and tend to be partly or fully occluded. This paper presents a methodology for evaluating the influence of perception capabilities on grasping and on gripper design using graspability maps. Graspability maps are spatial representations of grasp quality grades from wrist poses (position and orientation) about an object and are generated using simulation. A new module was developed to enable the insertion of object pose errors for testing the effects of perception inaccuracies on grasping. The methodology was implemented for comparing two grippers (Fin-Ray and Lip-type) for harvesting two sweet-pepper cultivars. A 3D model of each gripper was constructed and suitable grasp quality measures were developed and validated in a physical environment. Task and gripper-specific grasp quality measures were developed for each implementation. Sensitivity analyses included varying pepper dimensions and perception inaccuracies. These were followed by analyses of the influence of gripper design parameters on grasp capabilities. Results indicate that the Lip-type gripper is less sensitive to inaccuracies in object orientation, while both grippers are similarly sensitive to inaccuracies in object position. Specific perception system demands and design recommendations are given for each gripper, and cultivar. The results illustrate the importance of integrating perception analysis in the gripper design phase and the utility of the graspability simulation tool for design analysis. "
}
@article{RuizSarmiento2017257,
title = "Building Multiversal Semantic Maps for Mobile Robot Operation ",
journal = "Knowledge-Based Systems ",
volume = "119",
number = "",
pages = "257 - 272",
year = "2017",
note = "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2016.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S0950705116305184",
author = "Jose-Raul Ruiz-Sarmiento and Cipriano Galindo and Javier Gonzalez-Jimenez",
keywords = "Semantic maps",
keywords = "Mobile robots",
keywords = "Symbol grounding",
keywords = "Conditional random fields",
keywords = "Ontologies",
keywords = "Uncertainty handling ",
abstract = "Abstract Semantic maps augment metric-topological maps with meta-information, i.e. l semantic knowledge aimed at the planning and execution of high-level robotic tasks. Semantic knowledge typically encodes human-like concepts, like types of objects and rooms, which are connected to sensory data when symbolic representations of percepts from the robot workspace are grounded to those concepts. Such a symbol grounding is usually carried out by algorithms that individually categorize each symbol and provide a crispy outcome – a symbol is either a member of a category or not. Such approach is valid for a variety of tasks, but it fails at: (i) dealing with the uncertainty inherent to the grounding process, and (ii) jointly exploiting the contextual relations among concepts (e.g. microwaves are usually in kitchens). This work provides a solution for probabilistic symbol grounding that overcomes these limitations. Concretely, we rely on Conditional Random Fields (CRFs) to model and exploit contextual relations, and to provide measurements about the uncertainty coming from the possible groundings in the form of beliefs (e.g. an object can be categorized (grounded) as a microwave or as a nightstand with beliefs 0.6 and 0.4, respectively). Our solution is integrated into a novel semantic map representation called Multiversal Semantic Map ( M v S m a p ), which keeps the sets of different groundings, or universes, as instances of ontologies annotated with the obtained beliefs for their posterior exploitation. The suitability of our proposal has been proven with the Robot@Home dataset, a repository that contains challenging multi-modal sensory information gathered by a mobile robot in home environments. "
}
@article{Balzarini2015604,
title = "WRF-Chem model sensitivity to chemical mechanisms choice in reconstructing aerosol optical properties ",
journal = "Atmospheric Environment ",
volume = "115",
number = "",
pages = "604 - 619",
year = "2015",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.12.033",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014009819",
author = "A. Balzarini and G. Pirovano and L. Honzak and R. Žabkar and G. Curci and R. Forkel and M. Hirtl and R. San José and P. Tuccella and G.A. Grell",
keywords = "CBMZ-MOSAIC",
keywords = "RADM2-MADE/SORGAM",
keywords = "Online coupled model",
keywords = "Model inter-comparison",
keywords = "Chemical mechanism",
keywords = "Optical properties ",
abstract = "Abstract In the framework of the \{AQMEII\} initiative WRF-Chem has been applied over Europe adopting two chemical configurations for the calendar year 2010. The first one employed the \{RADM2\} gas-phase chemistry and MADE/SORGAM aerosol module, while the second one implemented the CBM-Z gaseous parameterization and \{MOSAIC\} aerosol chemistry. Configurations shared the same domain, meteorological setups and input data. The Comparison demonstrated that CBM-Z has a more efficient ozone-NO titration than \{RADM2\} in regions with sufficiently high levels of \{NOx\} and VOCs. At the same time, CBM-Z is found to have a more effective NO2 + OH reaction. The parameterization of the relative humidity of deliquescence point has a strong impact on \{HNO3\} and \{NO3\} concentrations over Europe, particularly over the sea. The \{MADE\} approach showed to be more efficient than MOSAIC. Differently, particulate sulfate and \{SO2\} ground concentrations proved to be more influenced by the heterogeneous \{SO2\} cloud oxidation. \{PM10\} and PM2.5 have shown similar results for \{MOSAIC\} and MADE/SORGAM, even though some differences were found in the dust and sea salt size partitioning between modes and bins. Indeed, in \{MADE\} the sea salt was distributed only in the coarse fraction, while the dust emissions were distributed mainly in the fine fraction. Finally, different chemical mechanisms give different Aerosol Optical Depths (AOD). WRF-Chem is found to under predict the \{AODs\} in both configurations because of the misrepresentation of the dust coarse particle, as shown by the analysis of the relationship between the Angström exponent and the \{AOD\} bias. Differently, when the \{AOD\} is dominated by fine particles, the differences in model performance are more evident, with MADE/SORGAM generally performing better than MOSAIC. Indeed the higher availability of both sulfate and nitrate has a significant influence on reconstruction of the \{AOD\} estimations. This paper shows the great importance of chemical mechanisms in both gaseous and aerosols predictions, as well as in the calculation of aerosol optical properties. "
}
@article{Frisoli2013404,
title = "A new bounded jerk on-line trajectory planning for mimicking human movements in robot-aided neurorehabilitation ",
journal = "Robotics and Autonomous Systems ",
volume = "61",
number = "4",
pages = "404 - 415",
year = "2013",
note = "Models and Technologies for Multi-modal Skill Training ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2012.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889012001492",
author = "A. Frisoli and C. Loconsole and R. Bartalucci and M. Bergamasco",
keywords = "Trajectory planning",
keywords = "Exoskeleton",
keywords = "Stroke rehabilitation",
keywords = "Minimum jerk model ",
abstract = "In this paper we propose a new on-line control strategy that can generate motion primitives mimicking human movement for robot assistance in stroke neurorehabilitation. The proposed strategy, with respect to other methods, allows the generation of bounded jerk trajectories characterized by inter-joint synchronization, e.g. joint variables complete the same percentage of their trajectories at each instant of time. The algorithm can on-line automatically identify, localize and track target objects to be reached, and adapt the level of assistance to be provided to the patient, so that the robot assistance is provided to let the patient operate in a real world setting, where he/she can reach and grasp common everyday life objects, To evaluate the performance of the proposed algorithm, its implementation was derived to control the movement of an upper limb robotic exoskeleton, the L-Exos, and an experimental evaluation was conducted in a group of healthy subjects to assess the plausibility of generated trajectories in terms of similarity with human motion. "
}
@article{Campmany2010385,
title = "A comparison of total precipitable water measurements from radiosonde and sunphotometers ",
journal = "Atmospheric Research ",
volume = "97",
number = "3",
pages = "385 - 392",
year = "2010",
note = "",
issn = "0169-8095",
doi = "https://doi.org/10.1016/j.atmosres.2010.04.016",
url = "http://www.sciencedirect.com/science/article/pii/S0169809510001171",
author = "Elies Campmany and Joan Bech and Javier Rodríguez-Marcos and Yolanda Sola and Jerónimo Lorente",
keywords = "Total precipitable water",
keywords = "Radiosonde",
keywords = "Sunphotometer",
keywords = "Cimel",
keywords = "Microtops ",
abstract = "Atmospheric water vapour is an essential component of the terrestrial atmosphere and must be known precisely in a wide range of applications such as radiative transfer modelling or weather forecasting to mention just a few examples. Vertically integrated measurements, or total precipitable water (TPW) equivalent amounts traditionally derived from radiosonde measurements, are needed in many of these applications and can also be obtained from other methodologies such as sunphotometers or GPS-based techniques. This paper presents a study comparing different measurements of \{TPW\} from radiosonde and sunphotometer data recorded from 2001 to 2004 in Barcelona, Spain. Three collocated instruments were employed in this study: RS-80A Vaisala sondes and two types of commonly used sunphotometers (Cimel 318N-VBS7 and Microtops II). A cloud screening filter was applied to photometer data based on the quality control procedure of the \{AERONET\} database. A systematic comparison among the measurements indicates that bivariate correlations between different instruments were high, with correlation factors (r2) above 0.8 in all cases. Measurements covered all seasons allowing examining intra-annual variability, which generally did not exhibit statistically significant differences. Examination of 57 concurrent measurements of the three instruments indicated that radiosonde \{TPW\} measurements were the highest (15 mm on average) and Cimel and Microtops presented similar values (12 mm and 11 mm respectively). "
}
@article{Baddock20091511,
title = "Dust source identification using MODIS: A comparison of techniques applied to the Lake Eyre Basin, Australia ",
journal = "Remote Sensing of Environment ",
volume = "113",
number = "7",
pages = "1511 - 1528",
year = "2009",
note = "Monitoring Protected Areas ",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2009.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0034425709000820",
author = "Matthew C. Baddock and Joanna E. Bullard and Robert G. Bryant",
keywords = "MODIS",
keywords = "Deep Blue",
keywords = "OMI",
keywords = "Lake Eyre Basin",
keywords = "Australia",
keywords = "Mineral aerosol",
keywords = "Dust ",
abstract = "The impact of mineral aerosol (dust) in the Earth's system depends on particle characteristics which are initially determined by the terrestrial sources from which the sediments are entrained. Remote sensing is an established method for the detection and mapping of dust events, and has recently been used to identify dust source locations with varying degrees of success. This paper compares and evaluates five principal methods, using \{MODIS\} Level 1B and \{MODIS\} Level 2 aerosol data, to: (a) differentiate dust (mineral aerosol) from non-dust, and (2) determine the extent to which they enable the source of the dust to be discerned. The five \{MODIS\} \{L1B\} methods used here are: (1) un-processed false colour composite (FCC), (2) brightness temperature difference, (3) Ackerman's (1997: J.Geophys. Res., 102, 17069–17080) procedure, (4) Miller's (2003:Geophys. Res. Lett. 30, 20, art.no.2071) dust enhancement algorithm and (5) Roskovensky and Liou's (2005: Geophys. Res. Lett. 32, L12809) dust differentiation algorithm; the aerosol product is \{MODIS\} Deep Blue (Hsu et al., 2004: \{IEEE\} Trans. Geosci. Rem. Sensing, 42, 557–569), which is optimised for use over bright surfaces (i.e. deserts). These are applied to four significant dust events from the Lake Eyre Basin, Australia. \{OMI\} \{AI\} was also examined for each event to provide an independent assessment of dust presence and plume location. All of the techniques were successful in detecting dust when compared to FCCs, but the most effective technique for source determination varied from event to event depending on factors such as cloud cover, dust plume mineralogy and surface reflectance. Significantly, to optimise dust detection using the \{MODIS\} \{L1B\} approaches, the recommended dust/non-dust thresholds had to be considerably adjusted on an event by event basis. \{MODIS\} \{L2\} aerosol data retrievals were also found to vary in quality significantly between events; being affected in particular by cloud masking difficulties. In general, we find that \{OMI\} \{AI\} and \{MODIS\} \{AQUA\} \{L1B\} and \{L2\} data are complementary; the former are ideal for initial dust detection, the latter can be used to both identify plumes and sources at high spatial resolution. Overall, approaches using brightness temperature difference (BT10–11) are the most consistently reliable technique for dust source identification in the Lake Eyre Basin. One reason for this is that this enclosed basin contains multiple dust sources with contrasting geochemical signatures. In this instance, \{BTD\} data are not affected significantly by perturbations in dust mineralogy. However, the other algorithms tested (including \{MODIS\} Deep Blue) were all influenced by ground surface reflectance or dust mineralogy; making it impossible to use one single \{MODIS\} \{L1B\} or \{L2\} data type for all events (or even for a single multiple-plume event). There is, however, considerable potential to exploit this anomaly, and to use dust detection algorithms to obtain information about dust mineralogy. "
}
@article{Kelly2007197,
title = "\{AN\} \{EXPERIMENTAL\} \{STUDY\} \{OF\} \{AERIAL\} \{STEREO\} \{VISUAL\} \{ODOMETRY\} ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "40",
number = "15",
pages = "197 - 202",
year = "2007",
note = "6th \{IFAC\} Symposium on Intelligent Autonomous Vehicles ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20070903-3-FR-2921.00036",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016346614",
author = "Jonathan Kelly and Gaurav S. Sukhatme",
keywords = "Gaussian distributions",
keywords = "mobile robots",
keywords = "position estimation",
keywords = "stereo vision",
keywords = "unmanned aerial vehicles ",
abstract = "Abstract Unmanned aerial vehicles normally rely on \{GPS\} to provide pose information for navigation. In this work, we examine stereo visual odometry (SVO) as an alternative pose estimation method for situations in which \{GPS\} in unavailable. \{SVO\} is an incremental procedure that determines ego-motion by identifying and tracking visual landmarks in the environment, using cameras mounted on-board the vehicle. We present experiments demonstrating how \{SVO\} performance varies with camera pointing angle, for a robotic helicopter platform. Our results show that an oblique camera pointing angle produces better motion estimates than a nadir view angle, and that reliable navigation over distances of more than 200 meters is possible using visual information alone. "
}
@article{Joochim2010116,
title = "Mobile Robot Exploration Based On Three Dimension Cameras Acquisition ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "43",
number = "23",
pages = "116 - 121",
year = "2010",
note = "2nd \{IFAC\} Symposium on Telematics Applications ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20101005-4-RO-2018.00037",
url = "http://www.sciencedirect.com/science/article/pii/S1474667015343330",
author = "Chanin Joochim and Hubert Roth",
keywords = "\{PMD\} camera",
keywords = "SLAM",
keywords = "3D mapping",
keywords = "ICP and mobile robot ",
abstract = "Abstract The exploration and three dimension map building of mobile robot tasks in an unknown environment are normally do not have any future reference information. The mobile robot has to estimate positions and poses itself. Finding the distinguishable objects in environment are also required in order to create the pose reference points. Therefore, the selected sensors and register mapping algorithm are significant. The sensors which can provide both of depth and image data are still deficient. Recently, the Photonic Mixture Device camera (PMD) is a three dimension sensor which generates real-time high rate volume output of surrounding scenario as well as gray scale data. However, one \{PMD\} camera drawback is low resolution output. From this problem, the idea to fusion another high resolution \{CCD\} camera to \{PMD\} depth data is purposed. In this study hence presents the mobile robot exploration using integration of \{CCD\} and \{PMD\} camera in order to create the three dimension mapping. The Iterative Closest Point (ICP) algorithm is used for matching clouding points and minimizing the interval pose of the two scans. Eventually, the difference three dimension mapping output between fusion \{CCD\} camera and use only pure depth data are presented and evaluated. "
}
@incollection{Kai2002367,
title = "11 - Data Structure in Rapid Prototyping and Manufacturing ",
editor = "Leondes, Cornelius T. ",
booktitle = "Database and Data Communication Network Systems ",
publisher = "Academic Press",
edition = "",
address = "San Diego",
year = "2002",
pages = "367 - 416",
isbn = "978-0-12-443895-8",
doi = "https://doi.org/10.1016/B978-012443895-8/50013-1",
url = "http://www.sciencedirect.com/science/article/pii/B9780124438958500131",
author = "Chua Chee Kai and Jacob Gan and Du Zhaohui and Tong Mei",
abstract = "Publisher Summary The efficient management of geometric information, such as points, curves, or polyhedrons, is of significant importance in many engineering applications such as computer-aided design (CAD), computer-aided manufacturing (CAM), robotics, and rapid prototyping and manufacturing (RP&amp;M). A good representation scheme maps the original data objects into a set of objects to facilitate efficient storage and computation. A data structure is the form of organization imposed on the collection of those data elements. It is defined by specifying what kind of elements it contains, and stating the rules of how to store the elements and how to retrieve them when needed. Data structures may be classified into linear and nonlinear types. Linear structures are those elements that have a sequential relationship. It occupies a special place in the study of data structures because the addressing of storage locations in a computer is nearly always linear, so the set of memory storage locations in the machine itself constitutes a linear structure. Nonlinear data structures are of varied sorts. One category important to the software designer is that of hierarchical structures, in which each element is itself a data structure. A good data structure is vital to the reliability and efficiency of a program or software. "
}
@article{Scharl201663,
title = "Trend analysis of performance parameters of pre-packed columns for protein chromatography over a time span of ten years ",
journal = "Journal of Chromatography A ",
volume = "1465",
number = "",
pages = "63 - 70",
year = "2016",
note = "",
issn = "0021-9673",
doi = "https://doi.org/10.1016/j.chroma.2016.07.054",
url = "http://www.sciencedirect.com/science/article/pii/S0021967316309761",
author = "Theresa Scharl and Christian Jungreuthmayer and Astrid Dürauer and Susanne Schweiger and Tim Schröder and Alois Jungbauer",
keywords = "HETP",
keywords = "Porous media",
keywords = "Asymmetry",
keywords = "Packing",
keywords = "Disposable",
keywords = "Ready-to-use ",
abstract = "Abstract Pre-packed small scale chromatography columns are increasingly used for process development, for determination of design space in bioprocess development, and for post-licence process verifications. The packing quality of 30,000 pre-packed columns delivered to customers over a period 10 years has been analyzed by advanced statistical tools. First, the data were extracted and checked for inconsistencies, and then were tabulated and made ready for statistical processing using the programming language Perl (https://www.perl.org/) and the statistical computing environment R (https://www.r-project.org/). Reduced \{HETP\} and asymmetry were plotted over time to obtain a trend of packing quality over 10 years. The obtained data were used as a visualized coefficient of variation analysis (VCVA), a process that has often been applied in other industries such as semiconductor manufacturing. A typical fluctuation of reduced \{HETP\} was seen. A Tsunami effect in manufacturing, the effect of propagation of manufacturing deviations leading to out-of-specification products, was not observed with these pre-packed columns. Principal component analysis (PCA) showed that all packing materials cluster. Our data analysis showed that the current commercially available chromatography media used for biopharmaceutical manufacturing can be reproducibly and uniformly packed in polymer-based chromatography columns, which are designed for ready-to-use purposes. Although the number of packed columns has quadrupled over one decade the packing quality has remained stable. "
}
@article{Zimmerman201477,
title = "Grid-free 2D plasma simulations of the complex interaction between the solar wind and small, near-Earth asteroids ",
journal = "Icarus ",
volume = "238",
number = "",
pages = "77 - 85",
year = "2014",
note = "",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2014.02.029",
url = "http://www.sciencedirect.com/science/article/pii/S0019103514001158",
author = "M.I. Zimmerman and W.M. Farrell and A.R. Poppe",
keywords = "Asteroids",
keywords = "Solar wind ",
abstract = "Abstract We present results from a new grid-free 2D plasma simulation code applied to a small, unmagnetized body immersed in the streaming solar wind plasma. The body was purposely modeled as an irregular shape in order to examine photoemission and solar wind plasma flow in high detail on the dayside, nightside, terminator and surface-depressed ‘pocket’ regions. Our objective is to examine the overall morphology of the various plasma interaction regions that form around a small body like a small near-Earth asteroid (NEA). We find that the object obstructs the solar wind flow and creates a trailing wake region downstream, which involves the interplay between surface charging and ambipolar plasma expansion. Photoemission is modeled as a steady outflow of electrons from illuminated portions of the surface, and under direct illumination the surface forms a non-monotonic or “double-sheath” electric potential upstream of the body, which is important for understanding trajectories and equilibria of lofted dust grains in the presence of a complex asteroid geometry. The largest electric fields are found at the terminators, where ambipolar plasma expansion in the body-sized nightside wake merges seamlessly with the thin photoelectric sheath on the dayside. The pocket regions are found to be especially complex, with nearby sunlit regions of positive potential electrically connected to unlit negative potentials and forming adjacent natural electric dipoles. For objects near the surface, we find electrical dissipation times (through collection of local environmental solar wind currents) that vary over at least 5 orders of magnitude: from 39 μs inside the near-surface photoelectron cloud under direct sunlight to ≫1 s inside the particle-depleted nightside wake and shadowed pocket regions. "
}
@incollection{Ahamed20175,
title = "Chapter 1 - Knowledge and Wisdom Across Cultures ",
editor = "Ahamed, Syed V. ",
booktitle = "Evolution of Knowledge Science ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2017",
pages = "5 - 21",
isbn = "978-0-12-805478-9",
doi = "https://doi.org/10.1016/B978-0-12-805478-9.00001-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780128054789000017",
author = "Syed V. Ahamed",
keywords = "Social movement",
keywords = "Cultural impact",
keywords = "Knowledge revolution",
keywords = "Knowledge machines ",
abstract = "Chapter Summary This chapter covers a brief overview of the ancient trails of knowledge through the centers of learning. These trails have become genetic pathways for contemplation over many centuries in Kyoto, Japan; in Nalanda, India; in the Jewish kibotos in Apamea, Phrygia; and in Giza, Egypt. More recently (eighth to thirteenth centuries), astronomy, mathematics, and methodology have been introduced in shrines of learning for the disciples and inmates of these knowledge centers. These seeds of knowledge along the venues of meditation are still based on Aristotle’s notions of universal truisms, beauty and virtue in the minds of saints, gurus, and clergy. In the distant past, these seeds germinated into full blossoms of wisdom through the generations that have followed. Knowledge is many times compared to pristine water in the clouds, rain, and streams, and wisdom is likened to dew drops in the gardens of Eden. Refined thought, art, and generosity blossomed together. Wisdom deeply founded in social justice and fairness evolved much slowly in the prior generations. The very recent pragmatism in sciences has started to demand immediate wealth and ready cash from knowledge. The pathways to progress have become optical fibers in the modern age of digital switches and information highways. Unfortunately, human reflection and refinement of notions have become subservient to the artificial wisdom of machines. The dramatic use of machines and their abuse have replaced the contemplations of the scholars of the past. Historical data bring home the ironic fact that hand-held \{PDAs\} (personal digital assistants) are becoming more affable than the spirituality laden scripture of the monks and gurus. Digits have become their beads; micro-programs have become their mantras; and keypads have become the sitars for the Internet-based transformed Vedic scholars. The monuments of technology have become barriers to the vision that unify the pursuit of science with human betterment. Marxist’s concepts of scientific innovation are not slanted toward raw greed for power and wealth. The current uses of machines in the routine activities of individuals, societies, and communities are examined from the perspective of both progress and retreat of social change that machines can catalyze. Much as computers have hastened the financial swings in the stock market, the new wave of social machines is likely to hasten the social swings, as they are already evident by the Internet. Dishonest marketers and spammer quickly take most people into deception-lands. Both the positive and negative implications of the impending social machines are presented. The underlying object to direct the machines to social enhancement rather than its decay is emphasized in this part. As much as traditional computers have hastened the business and commercial activities in the modern societies, the well-primed social machines are poised to hasten the routine of peoples, both intellectually and culturally, and to enrich lives of the world community. Information and knowledge society has further hastened such cycles and accelerated the changes. The knowledge culture of this decade is no longer based on the social laws of the last decade! "
}
@article{Li201735,
title = "Modeling of path planning and needle steering with path tracking in anatomical soft tissues for minimally invasive surgery ",
journal = "Medical Engineering & Physics ",
volume = "41",
number = "",
pages = "35 - 45",
year = "2017",
note = "",
issn = "1350-4533",
doi = "https://doi.org/10.1016/j.medengphy.2017.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S1350453317300073",
author = "Pan Li and Shan Jiang and Dong Liang and Zhiyong Yang and Yan Yu and Wei Wang",
keywords = "Minimally invasive surgery",
keywords = "Steerable needle",
keywords = "Path planning",
keywords = "Needle steering",
keywords = "Duty-cycled spinning",
keywords = "Path tracking",
keywords = "Soft tissue ",
abstract = "Abstract Steerable needles can potentially improve the effectiveness of diagnostic and therapeutic procedures, such as biopsy and cancer treatment, by increasing the targeting accuracy and reaching previously inaccessible targets. A discrete potential field algorithm based on three dimensional (3D) anatomical structures is proposed in this paper to plan the needle path in minimally invasive surgery. A 3D kinematic model of needle steering is formulated using Lie group theory. Model parameters are fitted using experimental data acquired via a 2-degree of freedom robotic device and an ultrasound imaging device. To execute the paths with variable curvatures, the model is incorporated with duty cycled spinning. Empirical formula between needle curvature and duty cycled factor is obtained through insertion experiments. To improve the targeting accuracy, a path tracking algorithm is developed by correcting for the heading error and cross-track error of the needle tip. The targeting error of the simulation is 0.29 mm. We experimentally evaluate the path tracking model and it achieves an average targeting error of 1.15 ± 0.56 mm in 3D environments with anatomical obstacles. The results of simulation are in agreement with steering experiments, showing that the discrete potential field algorithm and path tracking model have the potential to improve targeting accuracy and advance the therapeutic and diagnostic procedures. "
}
@article{Dong201497,
title = "Efficient keyframe-based real-time camera tracking ",
journal = "Computer Vision and Image Understanding ",
volume = "118",
number = "",
pages = "97 - 110",
year = "2014",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2013.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S1077314213001562",
author = "Zilong Dong and Guofeng Zhang and Jiaya Jia and Hujun Bao",
keywords = "Keyframe selection",
keywords = "Real-time camera tracking",
keywords = "Global localization",
keywords = "Online map extension ",
abstract = "Abstract We present a novel keyframe-based global localization method for markerless real-time camera tracking. Our system contains an offline module to select features from a group of reference images and an online module to match them to the input live video for quickly estimating the camera pose. The main contribution lies in constructing an optimal set of keyframes from the input reference images, which are required to approximately cover the entire space and at the same time to minimize the content redundancy among the selected frames. This strategy not only greatly saves computation, but also helps significantly reduce the number of repeated features. For a large-scale scene, it requires a significant effort to capture sufficient reference images and reconstruct the 3D environment. In order to alleviate the effort of offline preprocessing and enhance the tracking ability in a larger scale scene, we also propose an online reference map extension module, which can real-time reconstruct new 3D features and select online keyframes to extend the keyframe set. In addition, we develop a parallel-computing framework that employs both \{GPUs\} and multi-threading for speedup. Experimental results show that our method dramatically enhances the computing efficiency and eliminates the jittering artifacts in real-time camera tracking. "
}
@article{Kim20132016,
title = "Cognitive multicast with partially overlapped channels in vehicular ad hoc networks ",
journal = "Ad Hoc Networks ",
volume = "11",
number = "7",
pages = "2016 - 2025",
year = "2013",
note = "Theory, Algorithms and Applications of Wireless Networked Robotics ",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2012.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S1570870512000066",
author = "Wooseong Kim and Mario Gerla",
keywords = "Vehicular ad hoc networks",
keywords = "Cognitive radio",
keywords = "Adjacent channel interference",
keywords = "Network coding ",
abstract = "Abstract Vehicle to many vehicles (V2MV) multicast is an attractive application to provide vehicle safety and traffic control information, urban sensing and multimedia content sharing in vehicular ad hoc networks. Due to the limitation of \{DSRC\} channels, Wi-Fi channels can be alternative to realize the multicast in the vehicular networks. However, the deployment using the Wi-Fi in \{ISM\} bands is challenging due to the interference from increasing residential Wi-Fi users as well as inter-vehicle interference. In this study, we propose a cognitive multi-channel, multi-radio multicast protocol, CoCast, borrowing concept of recently developed cognitive radio techniques, which can help overcome such interference, with spectrum sensing and multi-channel assignment. Unfortunately, number of orthogonal channels is very limited in the \{ISM\} band to avoid interference in urban Wi-Fi cloud. Therefore, we apply two additional features to use partially overlapped channels: parallel frame transmission over \{OFDM\} subchannels to exploit spectral diversity, and network coding for the subchannel frames. Our evaluation results show that the reliability of multicast communication among vehicles in a dense urban environment can be significantly improved with these protocol extensions. "
}
@article{Wood20079,
title = "Technologies for Guidance of Radiofrequency Ablation in the Multimodality Interventional Suite of the Future ",
journal = "Journal of Vascular and Interventional Radiology ",
volume = "18",
number = "1",
pages = "9 - 24",
year = "2007",
note = "",
issn = "1051-0443",
doi = "https://doi.org/10.1016/j.jvir.2006.10.013",
url = "http://www.sciencedirect.com/science/article/pii/S1051044306000108",
author = "Bradford J. Wood and Julia K. Locklin and Anand Viswanathan and Jochen Kruecker and Dieter Haemmerich and Juan Cebral and Ariela Sofer and Ruida Cheng and Evan McCreedy and Kevin Cleary and Matthew J. McAuliffe and Neil Glossop and Jeff Yanof",
abstract = "Several new image-guidance tools and devices are being prototyped, investigated, and compared. These tools are introduced and include prototype software for image registration and fusion, thermal modeling, electromagnetic tracking, semiautomated robotic needle guidance, and multimodality imaging. The integration of treatment planning with computed tomography robot systems or electromagnetic needle-tip tracking allows for seamless, iterative, “see-and-treat,” patient-specific tumor ablation. Such automation, navigation, and visualization tools could eventually optimize radiofrequency ablation and other needle-based ablation procedures and decrease variability among operators, thus facilitating the translation of novel image-guided therapies. Much of this new technology is in use or will be available to the interventional radiologist in the near future, and this brief introduction will hopefully encourage research in this emerging area. "
}
@article{Kocifaj20051481,
title = "Inversion of extinction data for irregularly shaped particles ",
journal = "Atmospheric Environment ",
volume = "39",
number = "8",
pages = "1481 - 1495",
year = "2005",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2004.11.032",
url = "http://www.sciencedirect.com/science/article/pii/S1352231004011045",
author = "M. Kocifaj and H. Horvath",
keywords = "Aerosol size distribution",
keywords = "Non-spherical particles",
keywords = "Solar radiation",
keywords = "Inverse problems ",
abstract = "The retrieval of extinction data in the highly urbanized region of Bratislava city is analyzed for both, strictly non-spherical particles and volume equivalent particles. Two most typical situations are discussed in more details: the summer time dusty atmosphere consisting of strongly scattering particles with refractive index about 1.59, and winter time atmosphere with usual occurrence of ice-phase aerosols. The attention is paid to more frequent continental polar air mass, with 54% occurrence probability in the Bratislava region. The root-mean-square error of measured optical data varies from 4% to 8%. When processing extinction data it is shown that there are no significant differences between modal radii computed under assumption of randomly oriented irregularly shaped particles and for Mie equivalents. However, the differences can occur in case on non-randomly oriented particles. The modal radius of equally oriented particles in the ice cloud can be about two times larger than a modal radius of the system volume of volume identical spheres. Particle irregularity and the roughness of its surface eliminate the interference structure and ripple typical for monodisperse scattering patterns. As a consequence the subsidiary mode within size distribution function disappears. Such a mode usually occurs with Mie particles. Assuming spherical particles for the computation yields a narrower size distribution compared to assuming irregularly shaped particles. "
}
@article{Pahlevan2017289,
title = "Landsat 8 remote sensing reflectance (Rrs) products: Evaluations, intercomparisons, and enhancements ",
journal = "Remote Sensing of Environment ",
volume = "190",
number = "",
pages = "289 - 301",
year = "2017",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2016.12.030",
url = "http://www.sciencedirect.com/science/article/pii/S0034425716305090",
author = "Nima Pahlevan and John R. Schott and Bryan A. Franz and Giuseppe Zibordi and Brian Markham and Sean Bailey and Crystal B. Schaaf and Michael Ondrusek and Steven Greb and Christopher M. Strait",
keywords = "Landsat 8",
keywords = "Aquatic science",
keywords = "Ocean color",
keywords = "Atmospheric correction",
keywords = "Calibration",
keywords = "Coastal/inland waters ",
abstract = "Abstract The Operational Land Imager (OLI) onboard Landsat-8 is generating high-quality aquatic science products, the most critical of which is the remote sensing reflectance (Rrs), defined as the ratio of water-leaving radiance to the total downwelling irradiance just above water. The quality of the Rrs products has not, however, been extensively assessed. This manuscript provides a comprehensive evaluation of Level-1B, i.e., top of atmosphere reflectance, and Rrs products available from \{OLI\} imagery under near-ideal atmospheric conditions in moderately turbid waters. The procedure includes a) evaluations of the Rrs products at sites included in the Ocean Color component of the Aerosol Robotic Network (AERONET-OC), b) intercomparisons and cross-calibrations against other ocean color products, and c) optimizations of vicarious calibration gains across the entire \{OLI\} observing swath. Results indicate that the near-infrared and shortwave infrared (NIR-SWIR) band combinations yield the most robust and stable Rrs retrievals in moderately turbid waters. Intercomparisons against products derived from the Visible Infrared Imaging Radiometer Suite (VIIRS) and the Moderate Resolution Imaging Spectroradiometer onboard the Aqua platform (MODISA) indicate slight across-track non-uniformities (&lt; 1%) associated with \{OLI\} scenes in the blue bands. In both product domains (TOA and Rrs), on average, the \{OLI\} products were found larger in radiometric responses in the blue channels. Following the implementation of updated vicarious calibration gains and accounting for across-track non-uniformities, matchup analyses using independent in-situ validation data confirmed improvements in Rrs products. These findings further support high-fidelity OLI-derived aquatic science products in terms of both demonstrating a robust atmospheric correction method and providing consistent products across OLI's imaging swath. "
}
@article{Anderson199991,
title = "Roadmap to a star ",
journal = "Acta Astronautica ",
volume = "44",
number = "2–4",
pages = "91 - 97",
year = "1999",
note = "Missions to the Outer Solar System and Beyond ",
issn = "0094-5765",
doi = "https://doi.org/10.1016/S0094-5765(99)00033-8",
url = "http://www.sciencedirect.com/science/article/pii/S0094576599000338",
author = "John L. Anderson",
abstract = "\{NASA\} is currently constructing an Interstellar Roadmap that will outline a progressive series of phased technology efforts over several decades that would enable new science beyond the solar system, leading to and culminating in robotics exploration of nearby stars. The Roadmap is structured around a decadal progression of science missions and enabling technologies in which each decadal cycle has an intrinsic value in itself. The Roadmap serves at least 5 functions: 1) it lays the foundation for the development of a broad new strategic thrust of space exploration and development; 2) it outlines a long term progressive program for which each phase has an intrinsic value and can be argued independently of a Star Mission itself; 3) it defines a phased approach that would culminate in a large- scale breakthrough beamed energy capability that would have broad planetary and terrestrial applicability; 4) it describes an endeavor that could provide the technological basis of a U.S. economic engine for the first half of the 21st century; and 5) it provides a focus and a structure around which new government/industry economic relationships may be established. This paper outlines the process for constructing the Roadmap which is due to be completed in Fall 1998. It also poses questions raised by a mission of such scale and suggests some of the strategic value of such a Roadmap. "
}
@article{Capelli2016140,
title = "A framework for early design and prototyping of service-oriented applications with design patterns ",
journal = "Computer Languages, Systems & Structures ",
volume = "46",
number = "",
pages = "140 - 166",
year = "2016",
note = "",
issn = "1477-8424",
doi = "https://doi.org/10.1016/j.cl.2016.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S1477842415300440",
author = "Steven Capelli and Patrizia Scandurra",
keywords = "Service modeling and prototyping",
keywords = "Design pattern languages",
keywords = "Service Component Architectures",
keywords = "Formal pattern specification ",
abstract = "Abstract Service-oriented computing is playing an important role in several domains. Today the biggest shift in mainstream design and programming is toward service-oriented applications. However, the service paradigm raises a bundle of problems that did not exist in traditional component-based development where abstraction, encapsulation, and modularity were the only main concerns. Due to their distributed, dynamic, and heterogeneous nature, service-oriented software applications require us to discover, document, and share new design patterns at the service- and architecture-level. Moreover, service-oriented applications are hard to design and validate, and demand for new foundational theories, modeling notations and analysis techniques. In line to such a vision, this article presents a framework, called SCA-PatternBox, to design and prototype service-oriented applications with design patterns. The framework relies on the \{OASIS\} standard Service Component Architecture (SCA) and on \{SCA\} component implementation types, such as SCA-Java, for supporting an “implementation-oriented” approach to service-oriented architecture modeling and to the definition and instantiation of design patterns. Moreover, in order to provide formally verified design patterns, SCA-PatternBox allows the formal specification and analysis of the functional behavioral aspects of a design pattern using a formal service specification language called SCA-ASM (Service Component Architecture-Abstract State Machine). As major evaluation of the framework, two case studies and lessons learned are presented. A final comparison of existing design pattern languages is also reported. "
}
@article{Sahbani2012326,
title = "An overview of 3D object grasp synthesis algorithms ",
journal = "Robotics and Autonomous Systems ",
volume = "60",
number = "3",
pages = "326 - 336",
year = "2012",
note = "Autonomous Grasping ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2011.07.016",
url = "http://www.sciencedirect.com/science/article/pii/S0921889011001485",
author = "A. Sahbani and S. El-Khoury and P. Bidaud",
keywords = "Grasp synthesis",
keywords = "Force-closure",
keywords = "Learning by demonstration",
keywords = "Task modeling ",
abstract = "This overview presents computational algorithms for generating 3D object grasps with autonomous multi-fingered robotic hands. Robotic grasping has been an active research subject for decades, and a great deal of effort has been spent on grasp synthesis algorithms. Existing papers focus on reviewing the mechanics of grasping and the finger–object contact interactions Bicchi and Kumar (2000) [12] or robot hand design and their control Al-Gallaf et al. (1993) [70]. Robot grasp synthesis algorithms have been reviewed in Shimoga (1996) [71], but since then an important progress has been made toward applying learning techniques to the grasping problem. This overview focuses on analytical as well as empirical grasp synthesis approaches. "
}
@article{Weise2011635,
title = "Online loop closure for real-time interactive 3D scanning ",
journal = "Computer Vision and Image Understanding ",
volume = "115",
number = "5",
pages = "635 - 648",
year = "2011",
note = "Special issue on 3D Imaging and Modelling ",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2010.11.023",
url = "http://www.sciencedirect.com/science/article/pii/S107731421000264X",
author = "Thibaut Weise and Thomas Wismer and Bastian Leibe and Luc Van Gool",
keywords = "3D modeling",
keywords = "3D scanning",
keywords = "Registration",
keywords = "Integration",
keywords = "Loop closure ",
abstract = "We present a real-time interactive 3D scanning system that allows users to scan complete object geometry by turning the object around in front of a real-time 3D range scanner. The incoming 3D surface patches are registered and integrated into an online 3D point cloud. In contrast to previous systems the online reconstructed 3D model also serves as final result. Registration error accumulation which leads to the well-known loop closure problem is addressed already during the scanning session by distorting the object as rigidly as possible. Scanning errors are removed by explicitly handling outliers based on visibility constraints. Thus, no additional post-processing is required which otherwise might lead to artifacts in the model reconstruction. Both geometry and texture are used for registration which allows for a wide range of objects with different geometric and photometric properties to be scanned. We show the results of our modeling approach on several difficult real-world objects. Qualitative and quantitative results are given for both synthetic and real data demonstrating the importance of online loop closure and outlier handling for model reconstruction. We show that our real-time scanning system has comparable accuracy to offline methods with the additional benefit of immediate feedback and results. "
}
@article{tagkey2015iii,
title = "Editors' Introduction ",
journal = "Digital Communications and Networks ",
volume = "1",
number = "1",
pages = "iii - iv",
year = "2015",
note = "",
issn = "2352-8648",
doi = "https://doi.org/10.1016/S2352-8648(15)00017-6",
url = "http://www.sciencedirect.com/science/article/pii/S2352864815000176",
key = "tagkey2015iii"
}
@incollection{Kuniavsky201027,
title = "Chapter 3 - Interaction Metaphors ",
editor = "Kuniavsky, Mike ",
booktitle = "Smart Things ",
publisher = "Morgan Kaufmann",
edition = "",
address = "Boston",
year = "2010",
pages = "27 - 42",
isbn = "978-0-12-374899-7",
doi = "https://doi.org/10.1016/B978-0-12-374899-7.00003-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780123748997000035",
author = "Mike Kuniavsky",
abstract = "Publisher Summary Metaphors have long been part of how people think about design. Metaphors already form the conceptual scaffolding for many prominent ubiquitous computing projects and products. Though rarely labeled as such in a project’s description, user experience metaphors guide many assumptions about a project’s value, desirability, and how people will use it. Metaphors are complicated tools. They inspire people to make new associations and can communicate complex ideas quickly, but they also constrain thought. Connections that may make sense in the metaphor’s source concept may not exist in the target. If its exploration metaphor is interpreted literally, browsers are more like boats, and search engines are the navigators. Despite the criticism, however, metaphors remain powerful and valuable tools. They are one of the most straightforward ways to tap into existing knowledge to create a familiar narrative out of novel functionality. "
}
@article{Mehta1995270,
title = "The physical, biologic, and clinical basis of radiosurgery ",
journal = "Current Problems in Cancer ",
volume = "19",
number = "5",
pages = "270 - 328",
year = "1995",
note = "",
issn = "0147-0272",
doi = "https://doi.org/10.1016/S0147-0272(06)80003-6",
url = "http://www.sciencedirect.com/science/article/pii/S0147027206800036",
author = "Minesh P. Mehta",
abstract = "Since Leksell's description of the concept of radiosurgery in 1951, probably more than 20,000 patients worldwide have been treated with this technique. Initially designed as a tool for functonal neurostereotaxis, it has found widespread applicability for conditions as diverse as vascular malformations, benign tumors such as acoustic neuroma, meningioma, pituitary adenoma, and also malignant tumors such as brain metastases and malignant glioma. From rudimentary knowledge of the ability to produce focal necrotic lesions, the biologic understanding of the process of single-fraction, small-volume, high-dose brain radiation has evolved into a multicompartmental model, with reasonable appreciation of the dose, volume, and time factors involved. With the explosion of technology on several fronts in the 1980s and 1990s, a multitude of devices for radiosurgery, ranging from cyclotron-generated particle beams to multisource cobalt-60 units to an immense variety of modified linear accelerators has become available. A parallel explosion of technology in the fields of imaging and computing will ensure that this is just the beginning; already, technologies for automated image segmentation and target identification, long the physician's monopoly, are around the corner; image fusion now allows simultaneous visualization of target and normal tissue anatomy, physiology, and other exciting possibilities such as chemical composition and vascular characteristics. Advances in physics and robotics have led to development of prototypical machines that will blur the distinction between radiosurgery and conformal radiotherapy. Already, several “first generation” devices to free stereotaxis from its fixation to frames are available. Substantial enthusiasm among clinicians has ensured that, unlike many fleetingly and momentarily exciting technologies of the last 2 decades, radiosurgery has made and will continue to make a strong commitment for clinical efficacy, satety, and cost-effectiveness through the process of thorough multiinstitutional clinical trials, as opposed to seeking validation from anecdotal experiences. In this regard, the Radiation Therapy Oncology Group (RTOG) and the Gamma Knife Users' Group (GKUG) are to be commended; if the plethora of radiosurgery-related publications is evidence of scientific interest, the field will likely continue to expand. In the future, issues pertaining to appropriate regulatory review, patient selection, quality assurance, and training will need to be addressed. Major clinical and biological studies still need to be undertaken. "
}
@article{Zhang2008489,
title = "Efficient distance computation in configuration space ",
journal = "Computer Aided Geometric Design ",
volume = "25",
number = "7",
pages = "489 - 502",
year = "2008",
note = "Solid and Physical ModelingSelected papers from the Solid and Physical Modeling and Applications Symposium 2007 (SPM 2007)Solid and Physical Modeling and Applications Symposium 2007 ",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2008.04.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167839608000320",
author = "Liangjun Zhang and Young J. Kim and Dinesh Manocha",
keywords = "Distance metric",
keywords = "Configuration space ",
abstract = "We address the problem of computing a measure of the distance between two configurations of a rigid or an articulated model. The underlying distance metric is defined as the maximum length of the displacement vectors over the vertices of the model between two configurations. Our algorithm is based on Chasles theorem from Screw theory, and we show that for a rigid model the maximum distance is realized by one of the vertices on the convex hull of the model. We use this formulation to compute the distance, and present two acceleration techniques: incremental walking on the dual space of the convex hull and culling vertices on the convex hull using a bounding volume hierarchy (BVH). Our algorithm can be easily extended to articulated models by maximizing the distance over its each link and we also present culling techniques to accelerate the computation. We highlight the performance of our algorithm on many complex models and demonstrate its applications to generalized penetration depth computation and motion planning. "
}
@article{Martins201535,
title = "Proto-object categorisation and local gist vision using low-level spatial features ",
journal = "Biosystems ",
volume = "135",
number = "",
pages = "35 - 49",
year = "2015",
note = "",
issn = "0303-2647",
doi = "https://doi.org/10.1016/j.biosystems.2015.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0303264715000945",
author = "Jaime A. Martins and J.M.F. Rodrigues and J.M.H. du Buf",
keywords = "Disparity",
keywords = "3D",
keywords = "Stereo vision",
keywords = "Colour",
keywords = "Population coding",
keywords = "Learning",
keywords = "Biological model",
keywords = "Figure-ground",
keywords = "Segregation",
keywords = "Object",
keywords = "Categorisation",
keywords = "Verification",
keywords = "Neural network",
keywords = "Visual cortex ",
abstract = "Abstract Object categorisation is a research area with significant challenges, especially in conditions with bad lighting, occlusions, different poses and similar objects. This makes systems that rely on precise information unable to perform efficiently, like a robotic arm that needs to know which objects it can reach. We propose a biologically inspired object detection and categorisation framework that relies on robust low-level object shape. Using only edge conspicuity and disparity features for scene figure-ground segregation and object categorisation, a trained neural network classifier can quickly categorise broad object families and consequently bootstrap a low-level scene gist system. We argue that similar processing is possibly located in the parietal pathway leading to the \{LIP\} cortex and, via areas V5/MT and MST, providing useful information to the superior colliculus for eye and head control. "
}
@article{AndradeCetto20151,
title = "ECMR’13 Special Issue ",
journal = "Robotics and Autonomous Systems ",
volume = "69",
number = "",
pages = "1 - 2",
year = "2015",
note = "Selected papers from 6th European Conference on Mobile Robots ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2014.09.005",
url = "http://www.sciencedirect.com/science/article/pii/S0921889014001808",
author = "Juan Andrade-Cetto and Udo Frese and Moritz Tenorth"
}
@article{Alvim2017,
title = "Aerosol distribution over Brazil with ECHAM-HAM and CAM5-MAM3 simulations and its comparison with ground-based and satellite data ",
journal = "Atmospheric Pollution Research ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "1309-1042",
doi = "https://doi.org/10.1016/j.apr.2017.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S1309104216302197",
author = "Débora Souza Alvim and Jayant Pendharkar and Vinicius Buscioli Capistrano and Ariane Frassoni and Diego Pereira Enoré and Otacílio Leandro de Menezes Neto and Enver Ramirez Gutierrez and Ayantika Dey Choudhury and Paulo Yoshio Kubota and Josiane da Silva and Sergio Machado Correa and Paulo Nobre and Silvio Nilo Figueroa",
keywords = "Aerosol optical depth",
keywords = "Climate change",
keywords = "Model assessment",
keywords = "Aerosol Brazil",
keywords = "ECHAM-HAM and CAM5-MAM3 models ",
abstract = "Abstract The accurate representation of the impacts of natural and anthropogenic aerosols in the climate system presents a challenge in General Circulation Models. This paper analyzes the performance of the aerosol component of two Atmospheric General Circulation Models (AGCM): the Europe Centre Hamburg Model - Hamburg Aerosol Model (ECHAM-HAM), and the Community Atmosphere Model - Modal Aerosol Model (CAM5-MAM3) and their comparison with aerosol observations. We analyzed the spatial distribution of aerosols over Brazil represented in terms of the aerosol optical depth (AOD) simulated by these models. The model results are compared to measurements from Aerosol Robotic Network (AERONET) ground station, and satellite observations provided by the Moderate Resolution Imaging Spectroradiometer (MODIS). While both the models provide \{AODs\} at 550 nm, only \{HAM\} provides the Angström exponent that is compared with \{AERONET\} measurements. The comparison between the model simulations and the satellite observations of \{AOD\} show that the models can reproduce the spatial and temporal distributions, however models underestimate \{AOD\} for the four cities and for almost every South American continent during all seasons. During the dry season, characterized by intense biomass burning, CAM5-MAM3 shows inconsistent, but comparatively better results that ECHAM-HAM, with negative biases over Northern and Northeastern regions of Brazil. The Angström parameter is reasonably reproduced by ECHAM-HAM, except for Cuiabá, indicating that the particle size distribution is correctly represented in most cities. "
}
@article{Xiao2015104,
title = "Retrieval of dust storm aerosols using an integrated Neural Network model ",
journal = "Computers & Geosciences ",
volume = "85, Part B",
number = "",
pages = "104 - 114",
year = "2015",
note = "Statistical learning in geoscience modelling: Novel algorithms and challenging case studies ",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2015.02.016",
url = "http://www.sciencedirect.com/science/article/pii/S0098300415000485",
author = "Fei Xiao and Man Sing Wong and Kwon Ho Lee and James R. Campbell and Yu-kai Shea",
keywords = "Dust storms",
keywords = "Integrated modeling",
keywords = "Neural Network",
keywords = "Reverse absorption",
keywords = "Satellite imagery",
keywords = "Trajectory model ",
abstract = "Abstract Dust storms are known to have adverse effects on public health. Atmospheric dust loading is also one of the major uncertainties in global climatic modeling as it is known to have a significant impact on the radiation budget and atmospheric stability. This study develops an integrated model for dust storm detection and retrieval based on the combination of geostationary satellite images and forward trajectory model. The proposed model consists of three components: (i) a Neural Network (NN) model for near real-time detection of dust storms; (ii) a \{NN\} model for dust Aerosol Optical Thickness (AOT) retrieval; and (iii) the Hybrid Single Particle Lagrangian Integrated Trajectory (HYSPLIT) model to analyze the transports of dust storms. These three components are combined using an event-driven active geo-processing workflow technique. The \{NN\} models were trained for the dust detection and validated using sunphotometer measurements from the \{AErosol\} \{RObotic\} \{NETwork\} (AERONET). The \{HYSPLIT\} model was applied in the regions with high probabilities of dust locations, and simulated the transport pathways of dust storms. This newly automated hybrid method can be used to give advance near real-time warning of dust storms, for both environmental authorities and public. The proposed methodology can be applied on early warning of adverse air quality conditions, and prediction of low visibility associated with dust storm events for port and airport authorities. "
}
@article{Carnevale201541,
title = "Impact of pollutant emission reductions on summertime aerosol feedbacks: A case study over the \{PO\} valley ",
journal = "Atmospheric Environment ",
volume = "122",
number = "",
pages = "41 - 57",
year = "2015",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2015.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S1352231015303563",
author = "C. Carnevale and G. Finzi and A. Pederzoli and E. Turrini and M. Volta and F. Ferrari and R. Gianfreda and G. Maffeis",
keywords = "On line models",
keywords = "Emission scenario",
keywords = "Aerosol feedbacks",
keywords = "Po valley ",
abstract = "Abstract This study presents an evaluation of the impact by future pollutant anthropogenic emission reductions on summertime aerosol feedbacks over the Po valley. The fully coupled on line model Wrf/Chem has been used to examine the air quality and meteorology response over the region to 2020 emission reductions with respect to a simulation base case (2013). Future changes in net short wave radiation flux (SW) are also analyzed. The model domain is a 6 × 6 km2 resolution grid over Northern Italy; the simulation period covers two summer months (July–August). The work is divided into two parts. In the first, model results for the Base Case simulation (BC) are evaluated by comparing Wrf/Chem output to surface observations provided by two monitoring networks. Approximately 25 sites belonging to the regional \{ARPA\} Lombardia Network are used for both chemistry (NO2, \{O3\} and \{PM10\} concentrations) and meteorology (wind speed and 2-meters temperature) evaluation; 4 stations part of the global \{AEROsol\} Robotic Network (AERONET) are used for the evaluation of Aerosol Optical Depth (AOD). In the second part, a Maximum Feasible Reduction (MFR) scenario at 2020 have been simulated for the same months; monthly direct, indirect and overall aerosols feedbacks for both \{BC\} and \{MFR\} have been computed and analyzed. The emission reductions in the \{MFR\} 2020 lead to a sensible change in the aerosol overall feedbacks for all variables; a drop of \{SW\} over the valley (cooling effect) is visible in both \{BC\} and MFR, but it is less significant in the \{MFR\} (−5 W m−2) compared to the \{BC\} (−45 W m−2). This difference is mainly due to the abatement of \{SO2\} primary emissions, which leads to lower sulfates concentrations scattering radiation, thus mitigates the cooling effect and favors the warming. As \{SW\} is higher in the MFR, \{T2\} also increases over land with respect to the \{BC\} (the cooling of −0.5 °C estimated in the Base Case almost disappears). The overall effects lead to an enhancement of \{PM10\} concentration in the BC; they are less efficient in the \{MFR\} because of lower secondary aerosol concentrations (associated to the reduction of primary \{PM10\} emissions by approximately 20%). Concerning NO2, some localized areas with high reductions in the \{BC\} are not visible in the MFR. This is consistent with the increase of T2, which leads to higher photolytic rates compared to the BC. Higher concentrations of \{NO2\} in the \{MFR\} with respect to the \{BC\} lead to lower \{O3\} concentrations (maximum \{O3\} values drop from +6 ppb to +3 ppb). "
}
@article{He2010711,
title = "The research of an automatic object reconstruction method based on limit visible region of the laser-scanning vision system ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "26",
number = "6",
pages = "711 - 719",
year = "2010",
note = "19th International Conference on Flexible Automation and Intelligent ManufacturingLean manufacturing and Services ",
issn = "0736-5845",
doi = "https://doi.org/10.1016/j.rcim.2010.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0736584510000219",
author = "B.W. He and Zhou Xiao Long and Y.F. Li",
keywords = "Vision system",
keywords = "Sensor planning",
keywords = "3D reconstruction",
keywords = "Next best view ",
abstract = "This paper presents an automatic multi-view selection approach for 3D reconstruction by means of a laser scanning vision system. It is realized based on the visual region of the laser scanning vision system. The candidate next best view (NBV) position is obtained by computing the unknown space area according to the limit visual region of the vision system. The final \{NBV\} position, which can acquire the maximal visual area, is obtained by comparing the above candidate’s view positions. Experimental results show successful implantation of the proposed view planning method for digitization and reconstruction of freeform objects. "
}
@article{Adesina20142459,
title = "Direct radiative forcing of urban aerosols over Pretoria (25.75°S, 28.28°E) using \{AERONET\} Sunphotometer data: First scientific results and environmental impact ",
journal = "Journal of Environmental Sciences ",
volume = "26",
number = "12",
pages = "2459 - 2474",
year = "2014",
note = "",
issn = "1001-0742",
doi = "https://doi.org/10.1016/j.jes.2014.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S1001074214001831",
author = "Ayodele Joseph Adesina and Kanike Raghavendra Kumar and Venkataraman Sivakumar and Derek Griffith",
keywords = "Pretoria",
keywords = "AERONET",
keywords = "Aerosol optical depth",
keywords = "Single scattering albedo",
keywords = "Radiative forcing ",
abstract = "Abstract The present study uses the data collected from Cimel Sunphotometer of Aerosol Robotic Network (AERONET) for the period from January to December, 2012 over an urban site, Pretoria (PTR; 25.75°S, 28.28°E, 1449 m above sea level), South Africa. We found that monthly mean aerosol optical depth (AOD, τa) exhibits two maxima that occurred in summer (February) and winter (August) having values of 0.36 ± 0.19 and 0.25 ± 0.14, respectively, high-to-moderate values in spring and thereafter, decreases from autumn with a minima in early winter (June) 0.12 ± 0.07. The Angstrom exponents (α440–870) likewise, have its peak in summer (January) 1.70 ± 0.21 and lowest in early winter (June) 1.38 ± 0.26, while the columnar water vapor (CWV) followed \{AOD\} pattern with high values (summer) at the beginning of the year (February, 2.10 ± 0.37 cm) and low values (winter) in the middle of the year (July, 0.66 ± 0.21 cm). The volume size distribution (VSD) in the fine-mode is higher in the summer and spring seasons, whereas in the coarse mode the \{VSD\} is higher in the winter and lower in the summer due to the hygroscopic growth of aerosol particles. The single scattering albedo (SSA) ranged from 0.85 to 0.96 at 440 nm over \{PTR\} for the entire study period. The averaged aerosol radiative forcing (ARF) computed using \{SBDART\} model at the top of the atmosphere (TOA) was − 8.78 ± 3.1 W/m2, while at the surface it was − 25.69 ± 8.1 W/m2 leading to an atmospheric forcing of + 16.91 ± 6.8 W/m2, indicating significant heating of the atmosphere with a mean of 0.47 K/day. "
}
@article{Antanas201475,
title = "There are plenty of places like home: Using relational representations in hierarchies for distance-based image understanding ",
journal = "Neurocomputing ",
volume = "123",
number = "",
pages = "75 - 85",
year = "2014",
note = "Contains Special issue articles: Advances in Pattern Recognition Applications and Methods ",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2012.10.037",
url = "http://www.sciencedirect.com/science/article/pii/S0925231213003688",
author = "Laura Antanas and Martijn van Otterlo and José Oramas Mogrovejo and Tinne Tuytelaars and Luc De Raedt",
keywords = "Relational representations",
keywords = "Relational instance-based learning",
keywords = "Hierarchical image understanding ",
abstract = "Abstract Understanding images in terms of logical and hierarchical structures is crucial for many semantic tasks, including image retrieval, scene understanding and robotic vision. This paper combines robust feature extraction, qualitative spatial relations, relational instance-based learning and compositional hierarchies in one framework. For each layer in the hierarchy, qualitative spatial structures in images are detected, classified and then employed one layer up the hierarchy to obtain higher-level semantic structures. We apply a four-layer hierarchy to street view images and subsequently detect corners, windows, doors, and individual houses. "
}
@article{Konstantellos2013351,
title = "A short overview of control in European R&amp;D programmes (1983–2013): From local loop designs, through networked and coordinated control, to stochastic, large scale and real time optimization systems ",
journal = "European Journal of Control ",
volume = "19",
number = "5",
pages = "351 - 357",
year = "2013",
note = "The Path of Control ",
issn = "0947-3580",
doi = "https://doi.org/10.1016/j.ejcon.2013.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0947358013001246",
author = "Alkis Konstantellos",
abstract = "Abstract The main purpose of this article is to summarize the activities related to control and control systems supported by the European Commission Research and Development (R&amp;D) programmes (so called Framework Programmes—FPs) with focus on the last two decades and to present and discuss the synergies, gaps and possible new challenges identified during several brainstorming and informal meetings and in related reports and position papers covering topics from loop performance improvements to distributed, stochastic and large scale systems of systems. A second goal is to serve as a small additional source of systems and control information, listing examples of funded projects and recommendations for future work grouped according to established control categories and the \{EC\} themes and areas in the published work programmes. This note also marks 12 years after the European Journal of Control special issue, back in 2001, which was dedicated to the results of a pioneering Verification of Hybrid Systems project (VHS) [60]. About the same time a special \{EC\} project, Awareness and Dissemination Activities for Advanced Control In Europe (ADACIE), supported three major control events i.e. \{IFAC\} in Barcelona, \{MED\} in Lisbon and \{ECC\} in Porto and Cambridge [1]. This is a collection of factual and personal reflections of the author, based on several years of following up public and industrial activities in systems and control. The qualitative interpretation of the project results and discussions presented however have to be complemented by the actual and detailed scientific and technological deliverables and papers published by the control teams involved. A small set of useful references is included. Open questions still remain and novel concepts and ideas may become part of new endeavors of the European and international communities in funded activities, or in independent work. Furthermore the reported activities also indicated that there are more unexplored synergies among these disciplines (e.g. control, computing, communications, cognition, complexity and mathematics), which would necessitate new ways of open and joint efforts. "
}
@article{Tannahill20142,
title = "System of Systems and Big Data analytics – Bridging the gap ",
journal = "Computers & Electrical Engineering ",
volume = "40",
number = "1",
pages = "2 - 15",
year = "2014",
note = "40th-year commemorative issue ",
issn = "0045-7906",
doi = "https://doi.org/10.1016/j.compeleceng.2013.11.016",
url = "http://www.sciencedirect.com/science/article/pii/S004579061300298X",
author = "Barnabas K. Tannahill and Mo Jamshidi",
abstract = "Abstract Large data has been accumulating in all aspects of our lives for quite some time. Advances in sensor technology, the Internet, wireless communication, and inexpensive memory have all contributed to an explosion of “Big Data”. System of Systems (SoS) integrate independently operating, non-homogeneous systems to achieve a higher goal than the sum of the parts. Today’s SoS are also contributing to the existence of unmanageable “Big Data”. Recent efforts have developed a promising approach, called “Data Analytics”, which uses statistical and computational intelligence (CI) tools such as principal component analysis (PCA), clustering, fuzzy logic, neuro-computing, evolutionary computation (such as genetic algorithms), Bayesian networks, etc. to reduce the size of “Big Data” to a manageable size and apply these tools to (a) extract information, (b) build a knowledge base using the derived data, and (c) eventually develop a non-parametric model for the “Big Data”. This paper demonstrates how to construct a bridge between SoS and Data Analytics to develop reliable models for such systems. The subject material for this demonstration is using data analytics to generate a model to forecast produced photovoltaic energy to assist in the optimization of a micro grid SoS. Tools like fuzzy interference, neural networks, PCA, and genetic algorithms are used. "
}
@article{Bonasoni2008252,
title = "The ABC-Pyramid Atmospheric Research Observatory in Himalaya for aerosol, ozone and halocarbon measurements ",
journal = "Science of The Total Environment ",
volume = "391",
number = "2–3",
pages = "252 - 261",
year = "2008",
note = "Research at Jungfraujoch - Contributions to the International conference in celebration of the 75th anniversary of the High Altitude Research Station Jungfraujoch at Interlaken, Switzerland (11-13 September, 2006) ",
issn = "0048-9697",
doi = "https://doi.org/10.1016/j.scitotenv.2007.10.024",
url = "http://www.sciencedirect.com/science/article/pii/S0048969707010856",
author = "P. Bonasoni and P. Laj and F. Angelini and J. Arduini and U. Bonafè and F. Calzolari and P. Cristofanelli and S. Decesari and M.C. Facchini and S. Fuzzi and G.P. Gobbi and M. Maione and A. Marinoni and A. Petzold and F. Roccato and J.C. Roger and K. Sellegri and M. Sprenger and H. Venzac and G.P. Verza and P. Villani and E. Vuillermoz",
abstract = "In this work we present the new ABC-Pyramid Atmospheric Research Observatory (Nepal, 27.95 N, 86.82 E) located in the Himalayas, specifically in the Khumbu valley at 5079 m a.s.l. This measurement station has been set-up with the aim of investigating natural and human-induced environmental changes at different scales (local, regional and global). After an accurate instrumental set-up at ISAC-CNR in Bologna (Italy) in autumn 2005, the ABC-Pyramid Observatory for aerosol (physical, chemical and optical properties) and trace gas measurements (ozone and climate altering halocarbons) was installed in the high Khumbu valley in February 2006. Since March 2006, continuous measurements of aerosol particles (optical and physical properties), ozone (O3) and meteorological parameters as well as weekly samplings of particulate matter (for chemical analyses) and grab air samples for the determination of 27 halocarbons, have been carried out. These measurements provide data on the typical atmospheric composition of the Himalayan area between India and China and make investigations of the principal differences and similarities between the monsoon and pre-monsoon seasons possible. The study is carried out within the framework of the Ev-K2-CNR “SHARE-Asia” (Stations at High Altitude for Research on the Environment in Asia) and UNEP—“ABC” (Atmospheric Brown Clouds) projects. With the name of “Nepal Climate Observatory—Pyramid” the station is now part of the Observatory program of the \{ABC\} project. "
}
@article{Liang20094328,
title = "Strength prediction of sheet to tube single sided resistance spot welding ",
journal = "Materials & Design ",
volume = "30",
number = "10",
pages = "4328 - 4334",
year = "2009",
note = "",
issn = "0261-3069",
doi = "https://doi.org/10.1016/j.matdes.2009.04.015",
url = "http://www.sciencedirect.com/science/article/pii/S0261306909001666",
author = "Caiping Liang and Xiaohang Liu",
keywords = "Strength prediction",
keywords = "Design of experiment",
keywords = "Sheet to tube welding ",
abstract = "Single-Sided Spot Welding (SSSW) procedure is considered as a feasible method to join hydroformed or closed section parts to others in vehicle productions. A ‘doughnut’ shaped or ring nugget can be formed between the two workpieces during this process. The strengths of conventional button spot welds can be determined by the attributes of weldments and many functions that link weld diameter, sheet thickness and material properties to weld strength have been established. For welds of sheet to tube joining, the strength prediction model is greatly different from that of conventional welds for the completely different nugget form. In this study, computer experiments were conduced using the concept of design of experiments (DOE) and the method of finite element used to simulate the tensile-shear tests. The stress and strain distribution contour clouds during tensile-shear process were analyzed and quantitative relationship models were established to link a weld’s geometric and material properties to its tensile-shear strength. The results can give a simple judgment whether a ring spot weld was good only by its appearance. "
}
@article{Six200483,
title = "Surface characterisation of the Dome Concordia area (Antarctica) as a potential satellite calibration site, using Spot 4/Vegetation instrument ",
journal = "Remote Sensing of Environment ",
volume = "89",
number = "1",
pages = "83 - 94",
year = "2004",
note = "",
issn = "0034-4257",
doi = "https://doi.org/10.1016/j.rse.2003.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0034425703002748",
author = "Delphine Six and Michel Fily and Séverine Alvain and Patrice Henry and Jean-Pierre Benoist",
keywords = "Surface characterisation",
keywords = "Dome Concordia area (Antarctica)",
keywords = "Satellite calibration",
keywords = "Spot 4/Vegetation instrument ",
abstract = "A good calibration of satellite sensors is necessary to derive reliable quantitative measurements of the surface parameters or to compare data obtained from different sensors. In this study, the snow surface of the high plateau of the East Antarctic ice sheet, particularly the Dome C area (75°S, 123°E), is used first to test the quality of this site as a ground calibration target and then to determine the inter-annual drift in the sensitivity of the \{VEGETATION\} sensor, onboard the \{SPOT4\} satellite. Dome C area has many good calibration site characteristics: The site is very flat and extremely homogeneous (only snow), there is little wind and a very small snow accumulation rate and therefore a small temporal variability, the elevation is 3200 m and the atmosphere is very clear most of the time. Finally, due to its location, it is frequently within view of many satellites. \{VEGETATION\} visible blue channel data (0.43–0.47 μm) of a 716×716 km2 area centred on the French–Italian Dome Concordia station, during the 1998–1999, 1999–2000, 2001–2001, and 2001–2002 austral summers were cloud masked and atmospherically corrected. The snow surface Bidirectional Reflectance Distribution Function is very high with little spatial and seasonal variability, which is a major advantage for sensor calibration. The inter-annual variation is found to be very small, proving that the stability of the site is very good. "
}
@article{Bohg2010362,
title = "Learning grasping points with shape context ",
journal = "Robotics and Autonomous Systems ",
volume = "58",
number = "4",
pages = "362 - 377",
year = "2010",
note = "",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2009.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0921889009001699",
author = "Jeannette Bohg and Danica Kragic",
keywords = "Grasping",
keywords = "Shape context",
keywords = "Affordances",
keywords = "SVM ",
abstract = "This paper presents work on vision based robotic grasping. The proposed method adopts a learning framework where prototypical grasping points are learnt from several examples and then used on novel objects. For representation purposes, we apply the concept of shape context and for learning we use a supervised learning approach in which the classifier is trained with labelled synthetic images. We evaluate and compare the performance of linear and non-linear classifiers. Our results show that a combination of a descriptor based on shape context with a non-linear classification algorithm leads to a stable detection of grasping points for a variety of objects. "
}
@article{Debei201264,
title = "Lutetia surface reconstruction and uncertainty analysis ",
journal = "Planetary and Space Science ",
volume = "71",
number = "1",
pages = "64 - 72",
year = "2012",
note = "",
issn = "0032-0633",
doi = "https://doi.org/10.1016/j.pss.2012.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0032063312002073",
author = "Stefano Debei and Alessio Aboudan and Giacomo Colombatti and Marco Pertile",
keywords = "Multiple view stereo",
keywords = "Photogrammetry",
keywords = "Bundle Adjustment",
keywords = "Uncertainty ",
abstract = "Multiple views of Lutetia taken from \{OSIRIS\} \{NAC\} payload can be used to perform a metric reconstruction of its shape. In this work a general photogrammetric processing pipeline is described and a detailed uncertainty analysis is performed according with the standard metrological procedures. The uncertainty associated with the following quantities are highlighted and evaluated: intrinsic and extrinsic parameters of the multi-view system; the selected image feature detector and descriptor, which contribute to uncertainties associated with the used feature positions in each image plane; the lighting of the scene, which causes a not negligible uncertainty contribution to 2D positions in the image plane. The Bundle Adjustment, at the core of the reconstruction process, allows the assignment of the covariance of each input parameter and the estimation of derived 3D points covariance. The output covariance matrices represent the spatial uncertainty (magnitude and direction) of each reconstructed point and can be used to derive bounds on the uncertainty of other products as dense surface models and other physical parameters. Presented model of Lutetia is derived using 14 \{NAC\} images at the closest approach, 8042 features are tracked between consecutive frames and a final point cloud of 2590 points is produced. From the adjusted camera parameters a dense model with (approximatively) 1.5 million of points is derived using two views. The dense model has a resolution which is approximatively 120 m/px and contains the surface topography up to 1 km scale. "
}
@article{Babaee201556,
title = "3-D object modeling from 2-D occluding contour correspondences by opti-acoustic stereo imaging ",
journal = "Computer Vision and Image Understanding ",
volume = "132",
number = "",
pages = "56 - 74",
year = "2015",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2014.10.007",
url = "http://www.sciencedirect.com/science/article/pii/S1077314214002112",
author = "M. Babaee and S. Negahdaripour",
keywords = "Opti-acoustic imaging",
keywords = "Stereo imaging",
keywords = "3-D object reconstruction and modeling",
keywords = "Occluding contours ",
abstract = "Abstract Utilizing in situ measurements to build 3-D volumetric object models under variety of turbidity conditions is highly desirable for marine sciences. To address the ineffectiveness of feature-based structure from motion and stereo methods under poor visibility, we explore a multi-modal stereo imaging technique that utilizes coincident optical and forward-scan sonar cameras, a so-called opti-acoustic stereo imaging system. The challenges of establishing dense feature correspondences in either opti-acoustic or low-contrast optical stereo images are avoided, by employing 2-D occluding contour correspondences, namely, the images of 3-D object occluding rims. Collecting opti-acoustic stereo pairs while circling an object, matching 2-D apparent contours in optical and sonar views to construct the 3-D occluding rim, and computing the stereo rig trajectory by opti-acoustic bundle adjustment, we generate registered samples of 3-D surface in a reference coordinate system. A surface interpolation gives the 3-D object model. In addition to the key advantage of utilizing range measurements from sonar, the proposed paradigm requires no assumption about local surface curvature as traditionally made in 3-D shape reconstruction from occluding contours. The reconstruction accuracy is improved by computing both the 3-D positions and local surface normals of sampled contours. We also present (1) a simple calibration method to estimate and correct for small discrepancy from the desired relative stereo pose; (2) an analytical analysis of the degenerate configuration that enables special treatment in mapping (tall) elongated objects with dominantly vertical edges. We demonstrate the performance of our method based on the 3-D surface rendering of certain objects, imaged by an underwater opti-acoustic stereo system. "
}
@article{Schatten2014576,
title = "Towards a Formal Conceptualization of Organizational Design Techniques for Large Scale Multi Agent Systems ",
journal = "Procedia Technology ",
volume = "15",
number = "",
pages = "576 - 585",
year = "2014",
note = "2nd International Conference on System-Integrated Intelligence: Challenges for Product and Production Engineering ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2014.09.018",
url = "http://www.sciencedirect.com/science/article/pii/S2212017314001339",
author = "Markus Schatten and Petra Grd and Mladen Konecki and Robert Kudelić",
keywords = "Large scale multi-agent systems",
keywords = "organizational design",
keywords = "semantic wiki",
keywords = "formalization",
keywords = "Internet of Things ",
abstract = "Abstract Computing in the Internet of Things is increasingly pervasive, with everyday items including clothes, smart-phones, cars and various household appliances gaining sophisticated communication and computing capacities. It seems to be just a matter of time before devices have to collaborate and compete mutually as well as with their users, in order to provide better services to mankind. These embedded computers are increasingly autonomous and connected, and can thus be modeled as agents within multi-agent systems (MAS). Only 30 years ago it was science fiction that over a billion of people will exchange billions of e-mails on a daily basis. Today a scenario of millions of collaborating agents embedded in gadgets and appliances, across various networks may also sound futuristic. However given the current rate of development in electronics, we will soon have to manage large scale \{MAS\} (LSMAS) where millions of agents exist, collaborate and compete with each other. While a recent study shows that there are at least 50 organizational structure, superstructure and architecture types employed in modern organizations, there is a lack of research that would apply organizational design methods to organizations composed entirely of agents and agent systems in order to achieve alignment of organizational structure, processes, and reward system with the goals and strategy of the organization. Our research is therefore aimed towards enriching formal design methods for the development of \{LSMAS\} to foster the development of self-organizing and adaptable networks of devices that will contribute towards a sustainable development of the information society. In this work-in-progress study we apply a collaborative semantic wiki approach towards formalizing organizational design techniques in order to provide a foundation for future studies of automated \{LSMAS\} development. "
}
@article{Nordström1992260,
title = "Using and designing massively parallel computers for artificial neural networks ",
journal = "Journal of Parallel and Distributed Computing ",
volume = "14",
number = "3",
pages = "260 - 285",
year = "1992",
note = "",
issn = "0743-7315",
doi = "https://doi.org/10.1016/0743-7315(92)90068-X",
url = "http://www.sciencedirect.com/science/article/pii/074373159290068X",
author = "Tomas Nordström and Bertil Svensson",
abstract = "During the past 10 years the fields of artificial neural networks (ANNs) and massively parallel computing have been evolving rapidly. In this paper we study the attempts to make \{ANN\} algorithms run on massively parallel computers as well as designs of new parallel systems tuned for \{ANN\} computing. Following a brief survey of the most commonly used models, the different dimensions of parallelism in \{ANN\} computing are identified, and the possibilities for mapping onto the structures of different parallel architectures are analyzed. Different classes of parallel architectures used or designed for \{ANN\} are identified. Reported implementations are reviewed and discussed. It is concluded that the regularity of \{ANN\} computations suits \{SIMD\} architectures perfectly and that broadcast or ring communication can be very efficiently utilized. Bit-serial processing is very interesting for ANN, but hardware support for multiplication should be included. Future artificial neural systems for real-time applications will require flexible processing modules that can be put together to form \{MIMSIMD\} systems. "
}
@article{Silva20142628,
title = "New Trends in Manufacturing: Converging to Service and Intelligent Systems ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "47",
number = "3",
pages = "2628 - 2633",
year = "2014",
note = "19th \{IFAC\} World Congress ",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20140824-6-ZA-1003.02823",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016420069",
author = "José Reinaldo Silva",
keywords = "manufacturing design",
keywords = "service design",
keywords = "manufacturing service",
keywords = "AI planning ",
abstract = "Abstract Manufacturing processes and models have been influenced by the linear approach, called Fordism, for almost a century, since the first automated devices and discrete control systems were introduced. At the same time, new ideas to organize manufacturing process have appeared that question the absolute dominance of gain in scale. More recently, new criteria invaded the scenario of manufacturing where quality led manufacturing process to a phase based on accurate supply chain and surrounded by ubiquitous computer and robotic devices. A very precise manufacturing processes can now be designed and implemented in almost all sectors of industry, where special sub-processes can be delivered by other players. In this new scenario, a new paradigm for manufacturing design emerged, based on a set of very specialized services that could be arranged to provide new creative and sustainable processes. In this paper we go into this new paradigm for manufacturing (process) design comparing it with the classic approach that relies on layers classified as production plant, control (software oriented) and supervisory. "
}
@article{Xiong2013325,
title = "Automatic creation of semantically rich 3D building models from laser scanner data ",
journal = "Automation in Construction ",
volume = "31",
number = "",
pages = "325 - 337",
year = "2013",
note = "",
issn = "0926-5805",
doi = "https://doi.org/10.1016/j.autcon.2012.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0926580512001732",
author = "Xuehan Xiong and Antonio Adan and Burcu Akinci and Daniel Huber",
keywords = "Interior modeling",
keywords = "3D modeling",
keywords = "Scan to BIM",
keywords = "Lidar object recognition",
keywords = "Wall analysis",
keywords = "Opening detection ",
abstract = "Abstract In the Architecture, Engineering, and Construction (AEC) domain, semantically rich 3D information models are increasingly used throughout a facility's life cycle for diverse applications, such as planning renovations, space usage planning, and managing building maintenance. These models, which are known as building information models (BIMs), are often constructed using dense, three dimensional (3D) point measurements obtained from laser scanners. Laser scanners can rapidly capture the “as-is” conditions of a facility, which may differ significantly from the design drawings. Currently, the conversion from laser scan data to \{BIM\} is primarily a manual operation, and it is labor-intensive and can be error-prone. This paper presents a method to automatically convert the raw 3D point data from a laser scanner positioned at multiple locations throughout a facility into a compact, semantically rich information model. Our algorithm is capable of identifying and modeling the main visible structural components of an indoor environment (walls, floors, ceilings, windows, and doorways) despite the presence of significant clutter and occlusion, which occur frequently in natural indoor environments. Our method begins by extracting planar patches from a voxelized version of the input point cloud. The algorithm learns the unique features of different types of surfaces and the contextual relationships between them and uses this knowledge to automatically label patches as walls, ceilings, or floors. Then, we perform a detailed analysis of the recognized surfaces to locate openings, such as windows and doorways. This process uses visibility reasoning to fuse measurements from different scan locations and to identify occluded regions and holes in the surface. Next, we use a learning algorithm to intelligently estimate the shape of window and doorway openings even when partially occluded. Finally, occluded surface regions are filled in using a 3D inpainting algorithm. We evaluated the method on a large, highly cluttered data set of a building with forty separate rooms. "
}
@article{Chu201667,
title = "Quantifying organic aerosol single scattering albedo over the tropical biomass burning regions ",
journal = "Atmospheric Environment ",
volume = "147",
number = "",
pages = "67 - 78",
year = "2016",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2016.09.069",
url = "http://www.sciencedirect.com/science/article/pii/S1352231016307889",
author = "Jung-Eun Chu and Kyung-Ja Ha",
keywords = "Aerosol light absorption",
keywords = "Brown carbon",
keywords = "Organic aerosol",
keywords = "Sulfate",
keywords = "Nitrate ",
abstract = "Abstract Despite growing evidence of light-absorbing organic aerosols (OAs), their contribution to the Earth's radiative budget is still poorly understood. In this study we derived a new empirical relationship that binds \{OA\} single scattering albedo (SSA), which is the ratio of light scattering to extinction, with sulfate + nitrate aerosol optical depth (AOD) and applied this method to estimate \{OA\} \{SSA\} over the tropical biomass burning regions. This method includes division of the attribution of black carbon (BC) and \{OA\} absorption aerosol optical depths from the Aerosol Robotic Network (AERONET) observation and determination of the fine-mode ratio of sea-salt and dust \{AODs\} from several atmospheric chemistry models. Our best estimate of \{OA\} \{SSA\} over the tropical biomass burning regions is 0.91 at 550 nm. Uncertainties associated with observations and models permit a value range of 0.82–0.93. Furthermore, by using the estimated \{OA\} \{SSA\} and comprehensive observations including AERONET, Moderate Resolution Imaging Spectroradiometer (MODIS) and Multi-angle Imaging Spectroradiometer (MISR), we examined the first global estimate of sulfate + nitrate \{AOD\} through a semi-observational approach. The global mean sulfate + nitrate \{AOD\} of 0.017 is in the lower range of the values obtained from 21 models participated in AeroCom phase II. The results imply that most aerosol models as well as climate models, which commonly use \{OA\} \{SSA\} of 0.96–1.0, have so far ignored light absorption by \{OAs\} and have overestimated light scattering by sulfate + nitrate aerosols. This indicates that the actual aerosol direct radiative forcing should be less negative than currently believed. "
}
@article{AntonanzasTorres2016122,
title = "Impact of atmospheric components on solar clear-sky models at different elevation: Case study Canary Islands ",
journal = "Energy Conversion and Management ",
volume = "109",
number = "",
pages = "122 - 129",
year = "2016",
note = "",
issn = "0196-8904",
doi = "https://doi.org/10.1016/j.enconman.2015.11.067",
url = "http://www.sciencedirect.com/science/article/pii/S0196890415010870",
author = "F. Antonanzas-Torres and J. Antonanzas and R. Urraca and M. Alia-Martinez and F.J. Martinez-de-Pison",
keywords = "REST2",
keywords = "ESRA",
keywords = "SOLIS",
keywords = "Clear-sky solar irradiance",
keywords = "High altitude ",
abstract = "Abstract The estimation of clear-sky solar irradiance via clear-sky models depends on reliable values of aerosol optical depth, water vapor and ozone content. These atmospheric variables are rarely on-site measured and are generally provided as gridded estimates in very low spatial resolution (1°). The high spatial variability of atmospheric variables within the grid resolution (pixel) leads to important errors in those areas with great atmospheric variability, such as in mountainous regions. In this paper, the performance of three clear-sky solar irradiance models was evaluated in a site with especially great elevation range, the Izana station from the Baseline Surface Radiation Network (Tenerife, Canary Islands) located at a high elevation (2373 m) and just 14 km from the ocean. Aerosols data were obtained from measurements from the Aerosol Robotic Network (AERONET) at the same site. The evaluation was also compared with global horizontal irradiance estimations with clear-sky models in the Guimar station, located at a lower elevation (156 m) and only 11.5 km away from Izana. Results showed a strong influence of elevation on solar radiation estimation under clear-sky conditions. "
}
@article{Marmulla2004642,
title = "Automated laser registration in image-guided surgery: evaluation of the correlation between laser scan resolution and navigation accuracy ",
journal = "International Journal of Oral and Maxillofacial Surgery ",
volume = "33",
number = "7",
pages = "642 - 648",
year = "2004",
note = "",
issn = "0901-5027",
doi = "https://doi.org/10.1016/j.ijom.2004.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0901502704000086",
author = "R. Marmulla and T. Lüth and J. Mühling and S. Hassfeld",
keywords = "laser scan",
keywords = "surface registration",
keywords = "image-guided surgery",
keywords = "cranio-maxillofacial surgery",
keywords = "surgical segment navigator ",
abstract = "Markerless patient registration based on the facial skin surface makes logistics prior to image-guided surgery much easier, as it is not necessary to place and measure registration markers. A laser scan registration of the surgical site takes the place of conventional marker-based registration. In a clinical study, the stability and accuracy of markerless patient registration was evaluated in 12 patients. Intraoral titanium markers served as targets for the infrared-pointer of the navigation system in order to check the accuracy of the markerless registration process. The correlation between laser scan resolution and navigation accuracy was checked using seven different laser scan resolutions (a cloud of 300,000 laser scan points down to 3750 laser scan points of the surgical site). The markerless patient registration was successful as long as high laser scan resolution was used (30,000 laser scan points and more): the titanium markers were detected with a mean deviation of 1.1±0.2 mm. Low resolution laser scans (6000 laser scan points of the surgical site and less) revealed inaccuracies up to 6 mm. "
}
@article{Dearden2014355,
title = "Manipulation planning using learned symbolic state abstractions ",
journal = "Robotics and Autonomous Systems ",
volume = "62",
number = "3",
pages = "355 - 365",
year = "2014",
note = "Advances in Autonomous Robotics — Selected extended papers of the joint 2012 \{TAROS\} Conference and the \{FIRA\} RoboWorld Congress, Bristol, \{UK\} ",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2013.09.015",
url = "http://www.sciencedirect.com/science/article/pii/S0921889013001905",
author = "Richard Dearden and Chris Burbridge",
keywords = "Intelligent robots",
keywords = "Supervised learning",
keywords = "Automatic planning",
keywords = "Symbolic reasoning ",
abstract = "Abstract We present an approach for planning robotic manipulation tasks that uses a learned mapping between geometric states and logical predicates. Manipulation planning, because it requires task-level and geometric reasoning, requires such a mapping to convert between the two. Consider a robot tasked with putting several cups on a tray. The robot needs to find positions for all the objects, and may need to nest one cup inside another to get them all on the tray. This requires translating back and forth between symbolic states that the planner uses, such as stacked (cup1,cup2), and geometric states representing the positions and poses of the objects. We learn the mapping from labelled examples, and importantly learn a representation that can be used in both the forward (from geometric to symbolic) and reverse directions. This enables us to build symbolic representations of scenes the robot observes, but also to translate a desired symbolic state from a plan into a geometric state that the robot can achieve through manipulation. We also show how such a mapping can be used for efficient manipulation planning: the planner first plans symbolically, then applies the mapping to generate geometric positions that are then sent to a path planner. "
}
@article{Rambani201450,
title = "Computer assisted navigation in orthopaedics and trauma surgery ",
journal = "Orthopaedics and Trauma ",
volume = "28",
number = "1",
pages = "50 - 57",
year = "2014",
note = "",
issn = "1877-1327",
doi = "https://doi.org/10.1016/j.mporth.2014.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S1877132714000037",
author = "Rohit Rambani and Mathew Varghese",
keywords = "computer",
keywords = "navigation",
keywords = "orthopaedic applications ",
abstract = "Abstract Computer assisted navigation was initially introduced into neurosurgical practice, and then orthopaedic spinal surgery, in the 1990's. It has gained momentum in recent years, finding applications in multiple branches of orthopaedic surgery including hip and knee arthroplasty, sports injuries, trauma, spinal surgery and bone tumour surgery. The technology provides the surgeon with real-time information regarding the position of surgical instruments and implants in relation to the skeleton and has the potential to improve surgical accuracy and outcome. Computer assisted navigation systems can be active, employing robotic surgeons, or passive where the surgeon remains in total control but computer software aids in the procedure. Computer assisted navigation has the potential to help surgeons perform procedures more accurately, with a view to improving outcome. This article reviews the multiple applications, limitations, and advantages of computer assisted navigation in orthopaedics in the operating theatre and beyond. "
}
@article{Wen201468,
title = "Hand gesture guided robot-assisted surgery based on a direct augmented reality interface ",
journal = "Computer Methods and Programs in Biomedicine ",
volume = "116",
number = "2",
pages = "68 - 80",
year = "2014",
note = "New methods of human-robot interaction in medical practice ",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2013.12.018",
url = "http://www.sciencedirect.com/science/article/pii/S0169260713004082",
author = "Rong Wen and Wei-Liang Tay and Binh P. Nguyen and Chin-Boon Chng and Chee-Kong Chui",
keywords = "Human–robot cooperation",
keywords = "Augmented reality",
keywords = "Augmented interaction",
keywords = "Visual guidance",
keywords = "Image-guided surgery",
keywords = "Projector-camera system ",
abstract = "Abstract Radiofrequency (RF) ablation is a good alternative to hepatic resection for treatment of liver tumors. However, accurate needle insertion requires precise hand-eye coordination and is also affected by the difficulty of \{RF\} needle navigation. This paper proposes a cooperative surgical robot system, guided by hand gestures and supported by an augmented reality (AR)-based surgical field, for robot-assisted percutaneous treatment. It establishes a robot-assisted natural \{AR\} guidance mechanism that incorporates the advantages of the following three aspects: \{AR\} visual guidance information, surgeon's experiences and accuracy of robotic surgery. A projector-based \{AR\} environment is directly overlaid on a patient to display preoperative and intraoperative information, while a mobile surgical robot system implements specified \{RF\} needle insertion plans. Natural hand gestures are used as an intuitive and robust method to interact with both the \{AR\} system and surgical robot. The proposed system was evaluated on a mannequin model. Experimental results demonstrated that hand gesture guidance was able to effectively guide the surgical robot, and the robot-assisted implementation was found to improve the accuracy of needle insertion. This human–robot cooperative mechanism is a promising approach for precise transcutaneous ablation therapy. "
}
@article{Tsarouchi2015254,
title = "\{ROS\} Based Coordination of Human Robot Cooperative Assembly Tasks-An Industrial Case Study ",
journal = "Procedia \{CIRP\} ",
volume = "37",
number = "",
pages = "254 - 259",
year = "2015",
note = "\{CIRPe\} 2015 - Understanding the life cycle implications of manufacturing ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2015.08.045",
url = "http://www.sciencedirect.com/science/article/pii/S2212827115008987",
author = "Panagiota Tsarouchi and Sotiris Makris and George Michalos and Alexandros-Stereos Matthaiakis and Xenofon Chatzigeorgiou and Athanasios Athanasatos and Michael Stefos and Panagiotis Aivaliotis and George Chryssolouris",
keywords = "Human Robot cooperation",
keywords = "ROS",
keywords = "Assembly. ",
abstract = "Abstract This paper discusses a method for the coordination of assembly tasks requiring the cooperation of humans with a robot. A \{ROS\} based architecture is used. The assembly sequence of these tasks and their characteristics are modeled in a neutral \{XML\} format generated off-line. A \{ROS\} based framework in order for different modules to communicate and coordinate their actions through the exchange of messages. The human is able to review the past and upcoming tasks in a graphical user interface. The human and robot coexist in a fenceless cell where safety is ensured using a certified camera system. This framework is applied to an automotive case study using the Process Simulate tool for the execution of assembly tasks. "
}
@article{Turk201722,
title = "Fresh face for sex robots ",
journal = "New Scientist ",
volume = "233",
number = "3113",
pages = "22 - 23",
year = "2017",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(17)30316-0",
url = "http://www.sciencedirect.com/science/article/pii/S0262407917303160",
author = "Victoria Turk",
abstract = "Will robot companions be second-rate surrogates, asks Victoria Turk – or will we break the mould? "
}
@article{Yang200545,
title = "A reverse engineering method based on haptic volume removing ",
journal = "Computer-Aided Design ",
volume = "37",
number = "1",
pages = "45 - 54",
year = "2005",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2004.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S0010448504000478",
author = "Zhengyi Yang and Yonghua Chen",
keywords = "Reverse engineering",
keywords = "Conceptual design",
keywords = "Volume sculpting",
keywords = "Haptic shape modeling ",
abstract = "This paper presents a new reverse engineering methodology that is based on haptic volume removing. When a physical object is to be digitized, it is first buried in a piece of virtual clay that is generated with the help of a fixture. Now digitizing the physical object is by simply chipping away the virtual clay with a position tracker that is attached to a haptic device PHANToM®. While chipping away the clay, the user can see on the computer monitor what is emerging and at the same time feel the chipping force from the haptic device. By so doing, reverse engineering is seamlessly integrated into haptic volume sculpting that is now widely used for conceptual design. Furthermore, the proposed method has eliminated the need to merge point clouds that are digitized from different views using current digitizers. The virtual clay volume is represented by a spatial run-length encoding scheme. A prototype system has been developed to demonstrate the feasibility of the proposed new method through a case study. The strengths and weaknesses of the presented method are analyzed and the applicability is discussed. "
}
@article{Cenati2013222,
title = "Low Cost Scanning Device Application for Footwear Industry ",
journal = "Procedia \{CIRP\} ",
volume = "12",
number = "",
pages = "222 - 227",
year = "2013",
note = "Eighth \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2013.09.039",
url = "http://www.sciencedirect.com/science/article/pii/S221282711300680X",
author = "C. Cenati and N. Pedrocchi and L. Molinari Tosatti",
keywords = "Automation",
keywords = "Open architecture",
keywords = "Opto-electronic ",
abstract = "Abstract Notwithstanding laser scanning technology is a mature technology used in widening application fields, a variety of barriers hinds its integration in robotized production lines. To face well know problems, as high-costs and not customizable solutions among others, the authors have developed a new family of laser scanning devices based on off the shelves and low cost hardware components and on a modular design that allow the customization of the device according to the specific application requirements. High accuracy is guaranteed through a computationally efficient non-parametric calibration procedure. Keeping limited the overall cost of the solution provided while increasing in general the sensing capabilities of an Industrial Robot (IR) and in particular the autonomous recognition of position, orientation and furthermore shape and geometrical features of objects within the robotic workspace, can boost the penetration of \{IRs\} in typical traditional industrial sectors where \{SMEs\} productive scenario is mainly characterized by manual fabrication processes, high product variability, small batches and little capital investments. High added value footwear industry is a paradigmatic example where hard automation is limited from one side by high variability of products and huge request of autonomous adaptation to cope with different loosely structured fabrication processes and from the other side by a low propensity towards high capital investment that make difficult the penetration of industrial robots. Within the framework of the European Project \{ROBOFOOT\} (EU-FP7-SMP), authors have conceived and developed a new family of low cost modular and reconfigurable laser scanners and successfully applied in the footwear fabrication scenario. Various operations should be improved by actual measure of the shoe being manufactured, and among the others, the identification of the relative positioning between the last (the plastic element on top of which is built the shoe) and the gripping device is extremely critical because it is still performed manually. Positioning errors in this phase are critical since all robot part-programs depend on the correct alignment of the last with the robot end-effector. To face this problem, a procedure, based on the Iterative Closest Points (ICP) optimization method, has been developed and integrated on board of the laser scanning device that directly communicates with the robot controller to adapt and autonomously correct the part-program to align the tool nominal path with the actual shoe being manufactured. Efficacy of the proposed methods has been proved by measuring the interaction forces between the tool and the last handled by a robot during different technological operations (roughing, polishing etc) typical of the shoe fabrication cycle. "
}
@article{Amiridis2012536,
title = "Impact of the 2009 Attica wild fires on the air quality in urban Athens ",
journal = "Atmospheric Environment ",
volume = "46",
number = "",
pages = "536 - 544",
year = "2012",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2011.07.056",
url = "http://www.sciencedirect.com/science/article/pii/S1352231011008004",
author = "V. Amiridis and C. Zerefos and S. Kazadzis and E. Gerasopoulos and K. Eleftheratos and M. Vrekoussis and A. Stohl and R.E. Mamouri and P. Kokkalis and A. Papayannis and K. Eleftheriadis and E. Diapouli and I. Keramitsoglou and C. Kontoes and V. Kotroni and K. Lagouvardos and E. Marinou and E. Giannakaki and E. Kostopoulou and C. Giannakopoulos and A. Richter and J.P. Burrows and N. Mihalopoulos",
keywords = "Pollution",
keywords = "Biomass burning",
keywords = "Aerosol",
keywords = "Photochemistry",
keywords = "Radiation ",
abstract = "At the end of August 2009, wild fires ravaged the north-eastern fringes of Athens destroying invaluable forest wealth of the Greek capital. In this work, the impact of these fires on the air quality of Athens and surface radiation levels is examined. Satellite imagery, smoke dispersion modeling and meteorological data confirm the advection of smoke under cloud-free conditions over the city of Athens. Lidar measurements showed that the smoke plume dispersed in the free troposphere and lofted over the city reaching heights between 2 and 4 km. Ground-based sunphotometric measurements showed extreme aerosol optical depth, reaching nearly 6 in the \{UV\} wavelength range, accompanied by a reduction up to 70% of solar irradiance at ground. The intensive aerosol optical properties, namely the Ångström exponent, the lidar ratio, and the single scattering albedo, showed typical values for highly absorbing fresh smoke particles. In-situ air quality measurements revealed the impact of the smoke plume down to the surface with a slight delay on both the particulate and gaseous phase. Surface aerosols increase was encountered mainly in the fine mode with prominent elevation of \{OC\} and \{EC\} levels. Photochemical processes, studied via \{NOx\} titration of O3, were also shown to be different compared to typical urban photochemistry. "
}
@article{Johnson2004423,
title = "Networking technologies enable advances in Earth Science ",
journal = "Computer Networks ",
volume = "46",
number = "3",
pages = "423 - 435",
year = "2004",
note = "Networking for the Earth Sciences ",
issn = "1389-1286",
doi = "https://doi.org/10.1016/j.comnet.2004.06.015",
url = "http://www.sciencedirect.com/science/article/pii/S1389128604001616",
author = "Marjory Johnson and Kenneth Freeman and Raymond Gilstrap and Richard Beck",
keywords = "Earth Science application",
keywords = "Field experiment",
keywords = "Portable satellite dish",
keywords = "NREN ",
abstract = "This paper describes an experiment to prototype a new way of conducting science by applying networking and distributed computing technologies to an Earth Science application. A combination of satellite, wireless, and terrestrial networking provided geologists at a remote field site with interactive access to supercomputer facilities at two \{NASA\} centers, thus enabling them to validate and calibrate remotely sensed geological data in near real time. This represents a fundamental shift in the way that Earth scientists analyze remotely sensed data. In this paper we describe the experiment and the network infrastructure that enabled it, analyze the data flow during the experiment, and discuss the scientific impact of the results. "
}
@article{Bhuiyan20171,
title = "Special issue on dependability in parallel and distributed systems and applications ",
journal = "Information Sciences ",
volume = "379",
number = "",
pages = "1 - 2",
year = "2017",
note = "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2016.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516316140",
author = "Md Zakirul Alam Bhuiyan and Sy-Yen Kuo and Jie Wu"
}
@article{Ahn201649,
title = "Becoming a network beyond boundaries: Brain-Machine Interfaces (BMIs) as the actor-networks after the internet of things ",
journal = "Technology in Society ",
volume = "47",
number = "",
pages = "49 - 59",
year = "2016",
note = "",
issn = "0160-791X",
doi = "https://doi.org/10.1016/j.techsoc.2016.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S0160791X16300926",
author = "Sungyong Ahn",
keywords = "Brain-Machine Interface",
keywords = "Actor-network",
keywords = "Neuroprosthetics",
keywords = "Internet of things",
keywords = "Nicolelis ",
abstract = "Abstract For the last few decades, actor-network theory has been usually criticized for its focus on Machiavellian human actors controlling the overall networking between other actors or blamed for its dissipation of human agencies within the global status of a network. However, at the moment of its development, the freshness of actor-network theory was more relevant to its focus on the meaning of what the hyphen signifies; not so much just a simple connection between two independent variables, but an ontological event itself, from which certain entities juxtaposed together become involved by exchanging stable influences each other thus settled down as the actors participating in a network being associated as the summing up of these settled influences. The aim of this paper is to refresh this bygone freshness of \{ANT\} from the recent development of the Internet of Things (IoT); which vividly exemplifies how a network and its actors are generated from a manifold technologically augmented entities—such as smart appliances in a house, migratory animals with \{RFID\} tags, and ensembles of neurons signaling beyond one's brain through a bundle of microwires—each of which is physiologically or algorithmically adaptable to the environmental signals from other entities thus able to be settled down together into “new sensor/processor/actuator affiliations.” Brain-Machine Interface (BMI), developed by Nicolelis Lab at Duke University as a prototype of the future neuroprosthetics, shows a specific example of these networks of things; in which mutual adaptations of the technologically augmented entities—namely neurons and robot limbs—associate artificial sensory-motor circuits, programming its human/animal users' possible motor behaviors as well as their motor intentions. "
}
@article{Rico2010933,
title = "Imprecise expectations for imprecise linear filtering ",
journal = "International Journal of Approximate Reasoning ",
volume = "51",
number = "8",
pages = "933 - 947",
year = "2010",
note = "North American Fuzzy Information Processing Society Annual Conference \{NAFIPS\} ’2007 ",
issn = "0888-613X",
doi = "https://doi.org/10.1016/j.ijar.2010.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X10000800",
author = "A. Rico and O. Strauss",
keywords = "Linear time-invariant filtering",
keywords = "Expectation",
keywords = "Interval valued signal",
keywords = "Choquet integral",
keywords = "Non-additive confidence measure ",
abstract = "In most sensor measure based applications, the raw sensor signal has to be processed by an appropriate filter to increase the signal-to-noise ratio or simply to recover the signal to be measured. In both cases, the filter output is obtained by convoluting the sensor signal with a supposedly known appropriate impulse response. However, in many real life situations, this impulse response cannot be precisely specified. The filtered value can thus be considered as biased by this arbitrary choice of one impulse response among all possible impulse responses considered in this specific context. In this paper, we propose a new approach to perform filtering that aims at computing an interval valued signal containing all outputs of filtering processes involving a coherent family of conventional linear filters. This approach is based on a very straightforward extension of the expectation operator involving appropriate concave capacities. "
}
@article{Noh2014305,
title = "Single-scattering albedo profiling of mixed Asian dust plumes with multiwavelength Raman lidar ",
journal = "Atmospheric Environment ",
volume = "95",
number = "",
pages = "305 - 317",
year = "2014",
note = "",
issn = "1352-2310",
doi = "https://doi.org/10.1016/j.atmosenv.2014.06.028",
url = "http://www.sciencedirect.com/science/article/pii/S1352231014004749",
author = "Young M. Noh",
keywords = "Single-scattering albedo",
keywords = "Depolarization ratios",
keywords = "Asian dust",
keywords = "Raman lidar ",
abstract = "Abstract This study presents results of vertically-resolved single-scattering albedo of mixed Asian dust plumes, i.e. the total single-scattering albedo. The mixed Asian dust plumes are comprised of a mixture of pure dust particles and the non-dust part, e.g. urban/industrial pollution and smoke from biomass burning. The mixed Asian dust plumes were observed with multiwavelength Raman lidar which provides vertical profiles of particle backscatter coefficients at 355, 532, and 1064 nm and extinction coefficients at 355 and 532 nm. The optical data serve as input for an inversion algorithm that provides profiles of microphysical particle properties which subsequently are used for computing single-scattering albedo. This study presents results of dust plumes observed on 24 February 2004, 9 and 18 March 2004, 2 April 2004, and 24 February and 4 May 2005. The lidar measurements were carried out at Gwangju (35.10° N, 126.53° E), South Korea. The optical data of the mixed-dust plumes were separated into the pure dust content and the non-dust part. We used the linear particle depolarization ratio measured at 532 nm for this separation. The backscatter and extinction coefficients then were used to derive single-scattering albedo of the non-dust part of the mixed-dust plumes. The value 0.96 ± 0.02 at 532 nm for the single-scattering albedo of pure dust part was used. This value was obtained from single-scattering albedo of dust observed in various dust source regions. In another step the “total” single-scattering albedo of these mixed-dust plumes was calculated by using the optical depth of the dust and the non-dust part as weighting function. The single-scattering albedo of the non-dust particles of the mixed-dust plume varied from 0.63 to 0.93 for all observations presented in this study. The single-scattering albedo of the mixed-dust plumes was 0.71–0.95, and it was always higher than the single-scattering albedo of the non-dust part of the mixed-dust plumes. Single-scattering albedo varied with height on each measurement day. These differences seem to be quantitatively related to the degree of mixing of dust with urban pollution and the light-absorption properties of the pollution (non-dust) particles in these plumes which traveled along different transport pathways to the lidar site. The layer-mean lidar-derived single-scattering albedos of the examples shown in this study were compared to single-scattering albedo derived from \{AERONET\} (Aerosol Robotic Network) Sun/sky radiometer observations. This radiometer is located next to the lidar. The total layer-mean lidar-derived single-scattering albedos (at 532 nm) on 18 March and 2 April 2004, and on 24 February and 4 May 2005 were 0.91 ± 0.02, 0.90 ± 0.03, 0.91 ± 0.02, and 0.92 ± 0.02, respectively. The lidar-derived single-scattering albedos are similar to those based on the Sun/sky radiometer data if the different measurement wavelengths of the lidar and Sun/sky radiometer are taken account of. "
}
@article{Luo201690,
title = "Vision-based extraction of spatial information in grape clusters for harvesting robots ",
journal = "Biosystems Engineering ",
volume = "151",
number = "",
pages = "90 - 104",
year = "2016",
note = "",
issn = "1537-5110",
doi = "https://doi.org/10.1016/j.biosystemseng.2016.08.026",
url = "http://www.sciencedirect.com/science/article/pii/S1537511015303901",
author = "Lufeng Luo and Yunchao Tang and Xiangjun Zou and Min Ye and Wenxian Feng and Guoqing Li",
keywords = "Binocular stereo vision",
keywords = "Grape cluster",
keywords = "Bounding volume",
keywords = "Cutting point",
keywords = "Harvesting robots ",
abstract = "Grapes are likely to have collisions and be damaged by manipulations when harvesting grape clusters. To conduct an undamaged robotic harvesting, this paper focuses mainly on locating the spatial coordinates of the cutting points on a peduncle of grape clusters for the end-effector and determining the bounding volume of the grape clusters for the motion planner of the manipulator. A method for acquiring spatial information from grape clusters is presented based on binocular stereo vision. This method includes four steps: (1) calibrating the binocular cameras and rectifying the images, (2) detecting the cutting points on the peduncle and the centres of the grape berries, (3) extracting three-dimensional spatial coordinates of the points detected in step 2, and (4) calculating the bounding volume of the grape clusters. A total of 300 images were captured in the vineyard and were tested to validate the method for the cutting point detection, and the success rate was approximately 87%. The accuracy of the localisation of the cutting points was determined under outdoor conditions, and the accuracy in the Z and X directions was 12 mm and 9 mm, respectively. The acquired bounding volume of the grape cluster was compared with manual measurements, and errors in the height and maximum diameter were less than 17 mm and 19 mm, respectively. The elapsed time of the whole algorithm was less than 0.7 s. The demonstrated performance of this developed method indicated that it could be used on harvesting robots. "
}
@article{Shah20161,
title = "A novel feature representation for automatic 3D object recognition in cluttered scenes ",
journal = "Neurocomputing ",
volume = "205",
number = "",
pages = "1 - 15",
year = "2016",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.11.019",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215017385",
author = "Syed Afaq Ali Shah and Mohammed Bennamoun and Farid Boussaid",
keywords = "3D object recognition",
keywords = "Keypoint detection",
keywords = "Local feature ",
abstract = "Abstract We present a novel local surface description technique for automatic three dimensional (3D) object recognition. In the proposed approach, highly repeatable keypoints are first detected by computing the divergence of the vector field at each point of the surface. Being a differential invariant of curves and surfaces, the divergence captures significant information about the surface variations at each point. The detected keypoints are pruned to only retain the keypoints which are associated with high divergence values. A keypoint saliency measure is proposed to rank these keypoints and select the best ones. A novel integral invariant local surface descriptor, called 3D-Vor, is built around each keypoint by exploiting the vorticity of the vector field at each point of the local surface. The proposed descriptor combines the strengths of signature-based methods and integral invariants to provide robust local surface description. The performance of the proposed fully automatic 3D object recognition technique was rigorously tested on three publicly available datasets. Our proposed technique is shown to exhibit superior performance compared to state-of-the-art techniques. Our keypoint detector and descriptor based algorithm achieves recognition rates of 100%, 99.35% and 96.2% respectively, when tested on the Bologna, \{UWA\} and Ca׳ Foscari Venezia datasets. "
}
@article{Hou2016400,
title = "An algorithm for hyperspectral remote sensing of aerosols: 1. Development of theoretical framework ",
journal = "Journal of Quantitative Spectroscopy and Radiative Transfer ",
volume = "178",
number = "",
pages = "400 - 415",
year = "2016",
note = "Electromagnetic and light scattering by nonspherical particles XV: Celebrating 150 years of Maxwell's electromagnetics ",
issn = "0022-4073",
doi = "https://doi.org/10.1016/j.jqsrt.2016.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S002240731530265X",
author = "Weizhen Hou and Jun Wang and Xiaoguang Xu and Jeffrey S. Reid and Dong Han",
keywords = "GEO-TASO",
keywords = "TEMPO",
keywords = "Principal Component Analysis (PCA)",
keywords = "Hyperspectral Remote Sensing",
keywords = "Aerosol Retrieval",
keywords = "Surface Reflectance Reconstruction ",
abstract = "Abstract This paper describes the first part of a series of investigations to develop algorithms for simultaneous retrieval of aerosol parameters and surface reflectance from a newly developed hyperspectral instrument, the \{GEOstationary\} Trace gas and Aerosol Sensor Optimization (GEO-TASO), by taking full advantage of available hyperspectral measurement information in the visible bands. We describe the theoretical framework of an inversion algorithm for the hyperspectral remote sensing of the aerosol optical properties, in which major principal components (PCs) for surface reflectance is assumed known, and the spectrally dependent aerosol refractive indices are assumed to follow a power-law approximation with four unknown parameters (two for real and two for imaginary part of refractive index). New capabilities for computing the Jacobians of four Stokes parameters of reflected solar radiation at the top of the atmosphere with respect to these unknown aerosol parameters and the weighting coefficients for each \{PC\} of surface reflectance are added into the \{UNified\} Linearized Vector Radiative Transfer Model (UNL-VRTM), which in turn facilitates the optimization in the inversion process. Theoretical derivations of the formulas for these new capabilities are provided, and the analytical solutions of Jacobians are validated against the finite-difference calculations with relative error less than 0.2%. Finally, self-consistency check of the inversion algorithm is conducted for the idealized green-vegetation and rangeland surfaces that were spectrally characterized by the U.S. Geological Survey digital spectral library. It shows that the first six \{PCs\} can yield the reconstruction of spectral surface reflectance with errors less than 1%. Assuming that aerosol properties can be accurately characterized, the inversion yields a retrieval of hyperspectral surface reflectance with an uncertainty of 2% (and root-mean-square error of less than 0.003), which suggests self-consistency in the inversion framework. The next step of using this framework to study the aerosol information content in GEO-TASO measurements is also discussed. "
}
@article{Maître1987443,
title = "Improving dynamic programming to solve image registration ",
journal = "Pattern Recognition ",
volume = "20",
number = "4",
pages = "443 - 462",
year = "1987",
note = "",
issn = "0031-3203",
doi = "https://doi.org/10.1016/0031-3203(87)90071-9",
url = "http://www.sciencedirect.com/science/article/pii/0031320387900719",
author = "Henri Maître and Yifeng Wu",
keywords = "Dynamic programming",
keywords = "Image registration",
keywords = "Correspondence problem",
keywords = "Viterbi algorithm",
keywords = "Elastic matching ",
abstract = "A new method of dynamic programming (DP) is presented. A picture is paired with a reference map. In order to arrive at picture registration, an ordered sequence of primitive patterns is formed from the map. An attempt is made to locate a similar sequence from the picture using classical picture processing methods. This yields a distorted and unordered sequence marked by noise. \{DP\} is then used to search for a common match to the two sequences. Both the initial and final registration states are, however, unknown. Moreover, the continuity of the path is frequently interrupted, due to shortcomings in detection, or perhaps occlusions. Thus, classical \{DP\} algorithms appear to give only poor results under practical conditions. When well-adapted to treat signals issued from a first order Markovian process, they can be used, as this method shows, to treat kth order processes. The concept of the “virtual state”, kept in memory, suspends broken paths until they can be reconnected, thus bridging the existing gaps between the different parts of the path. The proposed algorithm has been applied to satellite images with their contours sectioned by clouds. The result leads to the guarantee of very good registration, in spite of image contours badly hampered by noise and/or clouds. "
}
@article{Mariem2012881,
title = "Optimization of the Research of an Unknown Object in an Unknown Environment ",
journal = "Procedia Engineering ",
volume = "41",
number = "",
pages = "881 - 887",
year = "2012",
note = "International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012) ",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2012.07.258",
url = "http://www.sciencedirect.com/science/article/pii/S1877705812026586",
author = "Farhat Mariem and M’hiri Slim and Tagina Moncef",
keywords = "Visual servoing",
keywords = "Epipolar constraint",
keywords = "Object localization ",
abstract = "This article addresses the problem of the research of an unknown object in an unknown environment using visual servoing. The system is camera-in-hand system mounted directly on the robot manipulator, and a camera-fired system fixed on the top of the mobile platform and observes the scene from there. The method proposed is based on the epipolar constraint defined between the two cameras. While eye-in-hand camera covers the epipolar line, we compute the next best view to be observed. The system executes the task between two positions blindly, using a velocity control law which generates a safety movement for the manipulator robot. The proposed approach minimizes the computational time of the training and takes into account the safety and security of the environment. The paper first gives an overview of the existing approach for localizing an unknown object and evaluates some of those approaches and propose a novel approach. "
}
@article{Taylor2006375,
title = "On the sublimation of ice particles on the surface of Mars; with applications to the 2007/8 Phoenix Scout mission ",
journal = "Icarus ",
volume = "181",
number = "2",
pages = "375 - 387",
year = "2006",
note = "",
issn = "0019-1035",
doi = "https://doi.org/10.1016/j.icarus.2005.10.031",
url = "http://www.sciencedirect.com/science/article/pii/S0019103505004227",
author = "Peter A. Taylor and Konstantin Baibakov and Stephen Brown and Michael H. Hecht and Troy L. Hudson and P.-Y. Li and Carlos F. Lange and Luis Prieto and Sergiy Savelyev",
keywords = "Mars",
keywords = "surface",
keywords = "Mars",
keywords = "atmosphere",
keywords = "Mars",
keywords = "climate ",
abstract = "Experimental studies related to the sublimation of ice, in bulk or as small particles, alone or mixed with dust similar to that expected on the surface of Mars, are reported. The experiments, a cloud physics particle sublimation model, and a convection model presented by Ingersoll, all indicate a strong dependence of sublimation rate on temperature, and this appears to be the dominant factor, assuming that the relative humidity of the air is fairly low. In addition the rate of loss of water vapour appears to depend primarily on exposed surface area and less on particle size and the total mass of the sample, or the mass of ice in the sample. The 2007/8 Phoenix Scout mission plans to obtain and analyse samples of sub-surface ice from about 70° N on Mars. A concern is that these samples, in the form of ice chips of size about 1 mm diameter, could be prone to sublimation when exposed for prolonged periods (many hours) to a relatively warm and dry atmosphere. Our laboratory simulations confirm that this could be a problem if particles are simply left lying on the surface, but also indicate that samples kept suitably cold and collected together in confined piles will survive long enough for the collection and delivery (to the analysis instruments) procedure to be completed. "
}
@article{tagkey20171,
title = "Editorial ",
journal = "Procedia Computer Science ",
volume = "103",
number = "",
pages = "1 - 13",
year = "2017",
note = "\{XII\} International Symposium Intelligent Systems 2016, \{INTELS\} 2016, 5-7 October 2016, Moscow, Russia ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917300017",
key = "tagkey20171"
}
@article{Roggeman201694,
title = "Prediction of the scene quality for stereo vision-based autonomous navigation ",
journal = "IFAC-PapersOnLine ",
volume = "49",
number = "15",
pages = "94 - 99",
year = "2016",
note = "9th \{IFAC\} Symposium on Intelligent Autonomous Vehicles \{IAV\} 2016Leipzig, Germany, 29 June—1 July 2016 ",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.07.715",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316309910",
author = "Hélène Roggeman and Julien Marzat and Anthelme Bernard-Brunei and Guy Le Besnerais",
keywords = "Autonomous vehicles",
keywords = "Robot navigation",
keywords = "Stereo vision",
keywords = "Model Predictive Control ",
abstract = "Abstract This paper presents an autonomous navigation architecture for a robot using stereo vision-based localisation. The main contribution is the prediction of the quality of future localisation of the system in order to detect and avoid areas where vision-based localisation may fail, due to lack of texture in the scene. A criterion based on the estimation of future visible landmarks, considering uncertainties on landmarks and camera positions, is integrated in a Model Predictive Control loop to compute safe trajectories with respect to the visual localisation. The system was tested on a mobile robot and the obtained results demonstrate the effectiveness of our method. "
}
@article{Zhang201589,
title = "Factorization of view-object manifolds for joint object recognition and pose estimation ",
journal = "Computer Vision and Image Understanding ",
volume = "139",
number = "",
pages = "89 - 103",
year = "2015",
note = "",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2015.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S1077314215000715",
author = "Haopeng Zhang and Tarek El-Gaaly and Ahmed Elgammal and Zhiguo Jiang",
keywords = "Homeomorphic manifold analysis",
keywords = "Object categorization",
keywords = "Object recognition",
keywords = "Instance recognition",
keywords = "Pose estimation ",
abstract = "Abstract Due to large variations in shape, appearance, and viewing conditions, object recognition is a key precursory challenge in the fields of object manipulation and robotic/AI visual reasoning in general. Recognizing object categories, particular instances of objects and viewpoints/poses of objects are three critical subproblems robots must solve in order to accurately grasp/manipulate objects and reason about their environments. Multi-view images of the same object lie on intrinsic low-dimensional manifolds in descriptor spaces (e.g. visual/depth descriptor spaces). These object manifolds share the same topology despite being geometrically different. Each object manifold can be represented as a deformed version of a unified manifold. The object manifolds can thus be parameterized by its homeomorphic mapping/reconstruction from the unified manifold. In this work, we develop a novel framework to jointly solve the three challenging recognition sub-problems, by explicitly modeling the deformations of object manifolds and factorizing it in a view-invariant space for recognition. We perform extensive experiments on several challenging datasets and achieve state-of-the-art results. "
}
@article{Hamdani2012632,
title = "Study and Effect of Orientation Two Room of Buildings Located in Ghardaia, Algeria ",
journal = "Energy Procedia ",
volume = "18",
number = "",
pages = "632 - 639",
year = "2012",
note = "Terragreen 2012: Clean Energy Solutions for Sustainable Environment (CESSE) ",
issn = "1876-6102",
doi = "https://doi.org/10.1016/j.egypro.2012.05.076",
url = "http://www.sciencedirect.com/science/article/pii/S1876610212008466",
author = "M. Hamdani and S.M.A. Bekkouche and T. Benouaz and M.K. Cherier",
keywords = "Temperature",
keywords = "Thermal Insulation",
keywords = "Orientation",
keywords = "Thermal Comfort",
keywords = "Buildings",
keywords = "Numerical Simulation ",
abstract = "Abstract Thermal comfort plays a major factor in building infrastructure sector. It has a big impact on building interior temperature as well as on energy balance and environment. In the current paper the influence of thermal isolation, building orientation and thermal inertia of building envelop on interior ambient temperatures have been studied. To meet our objective, a methodological procedure has been followed. It consists of elaboration of computing program written in \{MATLAB\} code to simulate the proposed mathematical model. The main objective of the proposed mathematical proposed model is to compute different delivered temperatures under real climatic and environment conditions. Confrontation of the results found through simulation with those found experimentally shows a clear consistence. Thus the theoretical model is experimentally validated. It can be concluded that: The most effective measure to achieve a better results is thermal insulation. The orientation of thermally isolated building doesn’t have a considerable impact on interior temperature. Thermal inertia of buildings may thus generate thermal comfort. It was revealed that an adequate use of stone thermal inertia is essential to achieve a better building thermal comfort. "
}
@article{Cordero200744,
title = "Uncertainty evaluation of the spectral \{UV\} irradiance evaluated by using the \{UVSPEC\} radiative transfer model ",
journal = "Optics Communications ",
volume = "276",
number = "1",
pages = "44 - 53",
year = "2007",
note = "",
issn = "0030-4018",
doi = "https://doi.org/10.1016/j.optcom.2007.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0030401807003860",
author = "Raul R. Cordero and Gunther Seckmeyer and Darius Pissulla and Luis Dasilva and Fernando Labbe",
keywords = "\{UV\} irradiance",
keywords = "Radiative transfer models",
keywords = "Uncertainty evaluation ",
abstract = "The radiative transfer models allow calculating the spectral \{UV\} irradiance from some set of measured input quantities linked with the surface reflectivity, the solar zenith angle, the ozone column and the characteristics of clouds and aerosols. The spectral irradiance yielded by a model is influenced by errors in the measurement of the input quantities. In this paper, the influences of these errors are characterized and compared with other systematic effects through an uncertainty analysis. We evaluated the uncertainty of the spectral \{UV\} irradiance rendered by the \{UVSPEC\} model, under cloudless sky conditions. In order to express the uncertainty of the output quantities (the global, direct and diffuse irradiances) in terms of the standard uncertainties of the input quantities, we used a Monte Carlo-based uncertainty propagation technique. We found that the uncertainty of the irradiance in the UV-B part of the spectrum was strongly influenced by the uncertainty attributed to the ozone column datum. Moreover, the uncertainities associated with the aerosol parameters accounted for most of the UV-A global irradiance uncertainty; the latter increased from about 4% under low aerosol conditions, up to about 14% in case of polluted air. We conclude that the \{UV\} irradiance evaluation through radiative transfer models requires paying special attention to the assessment of the aerosols properties. "
}
@article{Andersson2016193,
title = "AR-Enhanced Human-Robot-Interaction - Methodologies, Algorithms, Tools ",
journal = "Procedia \{CIRP\} ",
volume = "44",
number = "",
pages = "193 - 198",
year = "2016",
note = "6th \{CIRP\} Conference on Assembly Technologies and Systems (CATS) ",
issn = "2212-8271",
doi = "https://doi.org/10.1016/j.procir.2016.03.022",
url = "http://www.sciencedirect.com/science/article/pii/S2212827116007241",
author = "Nils Andersson and Angelos Argyrou and Frank Nägele and Fernando Ubis and Urko Esnaola Campos and Maite Ortiz de Zarate and Robert Wilterdink",
keywords = "Augmented Reality",
keywords = "Virtual Reality",
keywords = "Human-Robot-Interaction",
keywords = "Head-Mounted-Display ",
abstract = "Abstract By using Augmented Reality in Human-Robot-Interaction scenarios we propose it is possible to improve training, programming, maintenance and process monitoring. \{AR\} Enhanced Human Robot Interaction means it is possible to conduct activities not only in a training facility with physical robot(s) but also in a complete virtual environment. By using virtual environments only a computer and possibly Head Mounting Display is required. This will reduce the bottlenecks for with overbooked physical training facilities. Physical environment for the activities with robot(s) will still be required, however using also virtual environments will increase flexibility and human operator can focus on training more complicated tasks. "
}

